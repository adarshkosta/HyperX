python test_resnet20.py --gpus='1,2,3' --dataset='cifar100' --nideal --mvm --pretrained='../pretrained_models/ideal/resnet20fp_cifar100.pth.tar' -b64
WARNING: crossbar sizes with different row annd column dimension not supported.

      ==> Arguments:
          batch_size: 64
          dataset: cifar100
          model: resnet20
          pretrained: ../pretrained_models/ideal/resnet20fp_cifar100.pth.tar
          mvm: True
          nideal: True
          input_size: None
          workers: 8
          gpus: 1,2,3
          half: False

      ==> Functional simulator configurations:
          weight_bits=16
          weight_bit_frac=12
          input_bits=16
          input_bit_frac=12
          xbar_row_size=128
          xbar_col_size=128
          tile_row=2
          tile_col=2
          bit_stream=1
          bit_slice=2
          adc_bit=14
          acm_bits=32
          acm_bit_frac=24
          mvm=True
          non-ideality=True
          
xbmodel=NN_model(
  (fc1): Linear(in_features=16512, out_features=500, bias=True)
  (relu1): ReLU(inplace=True)
  (do2): Dropout(p=0.5, inplace=False)
  (fc3): Linear(in_features=500, out_features=128, bias=True)
)
          
xbmodel_weight_path=../xb_models/XB_128_stream1slice207dropout50epochs.pth.tar
          inmax_test=1.4
          inmin_test=0.826


DEVICE: cuda:0
GPU Id(s) being used: 1,2,3
==> Building model and model_mvm for resnet20 ...
WARNING: crossbar sizes with different row annd column dimension not supported.
==> Initializing model parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20fp_cifar100.pth.tar ...
Pretrained model accuracy: 69.5999984741211
Files already downloaded and verified
[0/157(0%)]	Loss 3.6028 (3.6028)	Prec@1 32.812 (32.812)	Prec@5 50.000 (50.000)
[1/157(1%)]	Loss 3.3240 (3.4634)	Prec@1 29.688 (31.250)	Prec@5 59.375 (54.688)
[2/157(1%)]	Loss 4.1102 (3.6790)	Prec@1 21.875 (28.125)	Prec@5 45.312 (51.562)
[3/157(2%)]	Loss 3.6648 (3.6755)	Prec@1 26.562 (27.734)	Prec@5 60.938 (53.906)
[4/157(3%)]	Loss 4.5030 (3.8410)	Prec@1 25.000 (27.188)	Prec@5 45.312 (52.188)
[5/157(3%)]	Loss 4.0062 (3.8685)	Prec@1 25.000 (26.823)	Prec@5 50.000 (51.823)
[6/157(4%)]	Loss 3.5176 (3.8184)	Prec@1 23.438 (26.339)	Prec@5 51.562 (51.786)
[7/157(4%)]	Loss 4.0151 (3.8430)	Prec@1 23.438 (25.977)	Prec@5 43.750 (50.781)
[8/157(5%)]	Loss 4.9075 (3.9613)	Prec@1 18.750 (25.174)	Prec@5 43.750 (50.000)
[9/157(6%)]	Loss 3.7803 (3.9432)	Prec@1 21.875 (24.844)	Prec@5 53.125 (50.312)
[10/157(6%)]	Loss 4.6068 (4.0035)	Prec@1 25.000 (24.858)	Prec@5 50.000 (50.284)
[11/157(7%)]	Loss 3.8276 (3.9888)	Prec@1 25.000 (24.870)	Prec@5 51.562 (50.391)
[12/157(8%)]	Loss 4.1912 (4.0044)	Prec@1 21.875 (24.639)	Prec@5 50.000 (50.361)
[13/157(8%)]	Loss 3.3175 (3.9553)	Prec@1 28.125 (24.888)	Prec@5 57.812 (50.893)
[14/157(9%)]	Loss 3.8217 (3.9464)	Prec@1 28.125 (25.104)	Prec@5 59.375 (51.458)
[15/157(10%)]	Loss 4.5840 (3.9863)	Prec@1 17.188 (24.609)	Prec@5 46.875 (51.172)
[16/157(10%)]	Loss 3.3437 (3.9485)	Prec@1 23.438 (24.540)	Prec@5 64.062 (51.930)
[17/157(11%)]	Loss 3.4642 (3.9216)	Prec@1 23.438 (24.479)	Prec@5 62.500 (52.517)
[18/157(11%)]	Loss 4.3948 (3.9465)	Prec@1 14.062 (23.931)	Prec@5 40.625 (51.891)
[19/157(12%)]	Loss 4.1380 (3.9561)	Prec@1 14.062 (23.438)	Prec@5 51.562 (51.875)
[20/157(13%)]	Loss 3.5205 (3.9353)	Prec@1 28.125 (23.661)	Prec@5 54.688 (52.009)
[21/157(13%)]	Loss 3.9198 (3.9346)	Prec@1 29.688 (23.935)	Prec@5 51.562 (51.989)
[22/157(14%)]	Loss 4.1181 (3.9426)	Prec@1 25.000 (23.981)	Prec@5 51.562 (51.970)
[23/157(15%)]	Loss 3.9720 (3.9438)	Prec@1 26.562 (24.089)	Prec@5 51.562 (51.953)
[24/157(15%)]	Loss 3.6399 (3.9317)	Prec@1 28.125 (24.250)	Prec@5 56.250 (52.125)
[25/157(16%)]	Loss 4.1553 (3.9403)	Prec@1 20.312 (24.099)	Prec@5 53.125 (52.163)
