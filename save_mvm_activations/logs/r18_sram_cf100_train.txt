WARNING: crossbar sizes with different row annd column dimension not supported.

      ==> Arguments:
          batch_size: 40
          dataset: cifar100
          savedir: /home/nano01/a/esoufler/activations/x64/sram/multiple_batch/
          model: resnet18
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mvm: True
          nideal: None
          mode: train
          input_size: None
          workers: 8
          gpus: 0,1,2,3
          experiment: 64x64
          batch_start: 0

      ==> Functional simulator configurations:
          weight_bits=16
          weight_bit_frac=12
          input_bits=16
          input_bit_frac=12
          xbar_row_size=64
          xbar_col_size=64
          tile_row=custom
          tile_col=custom
          bit_stream=1
          bit_slice=2
          adc_bit=14
          acm_bits=32
          acm_bit_frac=24
          mvm=True
          non-ideality=False
          
xbmodel=NN_model(
  (fc1): Linear(in_features=4160, out_features=500, bias=True)
  (relu1): ReLU(inplace=True)
  (do2): Dropout(p=0.5, inplace=False)
  (fc3): Linear(in_features=500, out_features=64, bias=True)
)
          
xbmodel_weight_path=../xb_models/XB_64_stream1slice207dropout50epochs.pth.tar
          inmax_test=1.2
          inmin_test=0.857


DEVICE: cuda
4 GPU devices being used. ID(s) 0,1,2,3
==> Building model and model_mvm for resnet18 ...
WARNING: crossbar sizes with different row annd column dimension not supported.
==> Initializing model parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Pretrained model accuracy: 69.93189239501953
Files already downloaded and verified
Files already downloaded and verified
Saving activations to: /home/nano01/a/esoufler/activations/x64/sram/multiple_batch/cifar100/resnet18/train
Dry run for computing activation sizes...
Dry run finished...
relu1: torch.Size([10, 64, 112, 112])
relu2: torch.Size([10, 64, 56, 56])
relu3: torch.Size([10, 64, 56, 56])
relu4: torch.Size([10, 64, 56, 56])
relu5: torch.Size([10, 64, 56, 56])
relu6: torch.Size([10, 128, 28, 28])
relu7: torch.Size([10, 128, 28, 28])
relu8: torch.Size([10, 128, 28, 28])
relu9: torch.Size([10, 128, 28, 28])
relu10: torch.Size([10, 256, 14, 14])
relu11: torch.Size([10, 256, 14, 14])
relu12: torch.Size([10, 256, 14, 14])
relu13: torch.Size([10, 256, 14, 14])
relu14: torch.Size([10, 512, 7, 7])
relu15: torch.Size([10, 512, 7, 7])
relu16: torch.Size([10, 512, 7, 7])
relu17: torch.Size([10, 512, 7, 7])
fc: torch.Size([10, 100])
relu1: torch.Size([40, 64, 112, 112])
relu2: torch.Size([40, 64, 56, 56])
relu3: torch.Size([40, 64, 56, 56])
relu4: torch.Size([40, 64, 56, 56])
relu5: torch.Size([40, 64, 56, 56])
relu6: torch.Size([40, 128, 28, 28])
relu7: torch.Size([40, 128, 28, 28])
relu8: torch.Size([40, 128, 28, 28])
relu9: torch.Size([40, 128, 28, 28])
relu10: torch.Size([40, 256, 14, 14])
relu11: torch.Size([40, 256, 14, 14])
relu12: torch.Size([40, 256, 14, 14])
relu13: torch.Size([40, 256, 14, 14])
relu14: torch.Size([40, 512, 7, 7])
relu15: torch.Size([40, 512, 7, 7])
relu16: torch.Size([40, 512, 7, 7])
relu17: torch.Size([40, 512, 7, 7])
fc: torch.Size([40, 100])
Starting to save activations..
   0/1250 [....................] - ETA: 0s - DT: 0.0000e+00 - FpT: 0.0000e+00 - BT: 0.0000e+00   1/1250 [....................] - ETA: 98:12:19 - DT: 1.2272 - FpT: 134.7327 - BT: 141.5288     2/1250 [....................] - ETA: 72:45:04 - DT: 1.0235 - FpT: 134.3102 - BT: 140.7174