
      ==> Arguments:
          dataset: cifar100
          model: resnet20
          workers: 8
          epochs: 250
          start_epoch: 0
          batch_size: 128
          lr: 0.0001
          momentum: 0.9
          weight_decay: 0.0001
          tag: qfp_i8b7f_w8b7f2
          milestones: [80, 140, 200]
          gamma: 0.2
          input_size: None
          print_freq: 200
          resume: ../pretrained_models/ideal/resnet20qfp_cifar100_half_qfp_i8b7f_w8b7f_best.pth.tar
          evaluate: False
          pretrained: None
          half: True
          savedir: ../pretrained_models/ideal/
          save_every: 10
          gpus: 1
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
=> loading checkpoint '../pretrained_models/ideal/resnet20qfp_cifar100_half_qfp_i8b7f_w8b7f_best.pth.tar'
Resumed model accuracy: 63.1099967956543
=> loaded checkpoint from ../pretrained_models/ideal/resnet20qfp_cifar100_half_qfp_i8b7f_w8b7f_best.pth.tar
Files already downloaded and verified
Files already downloaded and verified
Test: [0/79]	Loss 1.4805 (1.4805)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 63.110 Prec@5 86.510
Pretrained model accuracy: 63.1099967956543
Epoch: [0][0/391]	Loss 0.5303 (0.5303)	Prec@1 85.156 (85.156)	Prec@5 96.094 (96.094)	LR: 0.0001
Epoch: [0][200/391]	Loss 0.6631 (0.5928)	Prec@1 78.906 (83.699)	Prec@5 96.875 (98.107)	LR: 0.0001
 * Prec@1 83.602 Prec@5 98.130
Best Train Accuracy: 83.60%

Test: [0/79]	Loss 1.4697 (1.4697)	Prec@1 64.844 (64.844)	Prec@5 85.938 (85.938)
 * Prec@1 62.740 Prec@5 86.320
Best accuracy: 63.11%

Epoch: [1][0/391]	Loss 0.6729 (0.6729)	Prec@1 82.031 (82.031)	Prec@5 96.875 (96.875)	LR: 0.0001
Epoch: [1][200/391]	Loss 0.5752 (0.5957)	Prec@1 85.156 (83.567)	Prec@5 97.656 (98.181)	LR: 0.0001
 * Prec@1 83.686 Prec@5 98.158
Best Train Accuracy: 83.69%

Test: [0/79]	Loss 1.4932 (1.4932)	Prec@1 64.844 (64.844)	Prec@5 85.156 (85.156)
 * Prec@1 62.680 Prec@5 86.410
Best accuracy: 63.11%

Epoch: [2][0/391]	Loss 0.6958 (0.6958)	Prec@1 82.812 (82.812)	Prec@5 96.875 (96.875)	LR: 0.0001
Epoch: [2][200/391]	Loss 0.4968 (0.6011)	Prec@1 84.375 (83.193)	Prec@5 98.438 (98.033)	LR: 0.0001
 * Prec@1 83.260 Prec@5 98.128
Best Train Accuracy: 83.69%

Test: [0/79]	Loss 1.4639 (1.4639)	Prec@1 66.406 (66.406)	Prec@5 85.156 (85.156)
 * Prec@1 62.900 Prec@5 86.450
Best accuracy: 63.11%

Epoch: [3][0/391]	Loss 0.5645 (0.5645)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)	LR: 0.0001
Epoch: [3][200/391]	Loss 0.7080 (0.5986)	Prec@1 78.125 (83.454)	Prec@5 95.312 (98.053)	LR: 0.0001
 * Prec@1 83.482 Prec@5 98.150
Best Train Accuracy: 83.69%

Test: [0/79]	Loss 1.4814 (1.4814)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.850 Prec@5 86.400
Best accuracy: 63.11%

Epoch: [4][0/391]	Loss 0.5952 (0.5952)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [4][200/391]	Loss 0.6055 (0.5957)	Prec@1 80.469 (83.438)	Prec@5 99.219 (98.107)	LR: 0.0001
 * Prec@1 83.490 Prec@5 98.022
Best Train Accuracy: 83.69%

Test: [0/79]	Loss 1.4941 (1.4941)	Prec@1 65.625 (65.625)	Prec@5 85.938 (85.938)
 * Prec@1 62.830 Prec@5 86.470
Best accuracy: 63.11%

Epoch: [5][0/391]	Loss 0.4456 (0.4456)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)	LR: 0.0001
Epoch: [5][200/391]	Loss 0.5386 (0.5918)	Prec@1 87.500 (83.462)	Prec@5 99.219 (98.095)	LR: 0.0001
 * Prec@1 83.522 Prec@5 98.104
Best Train Accuracy: 83.69%

Test: [0/79]	Loss 1.4795 (1.4795)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.660 Prec@5 86.280
Best accuracy: 63.11%

Epoch: [6][0/391]	Loss 0.6094 (0.6094)	Prec@1 85.938 (85.938)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [6][200/391]	Loss 0.5762 (0.5933)	Prec@1 82.031 (83.396)	Prec@5 97.656 (98.169)	LR: 0.0001
 * Prec@1 83.260 Prec@5 98.094
Best Train Accuracy: 83.69%

Test: [0/79]	Loss 1.4805 (1.4805)	Prec@1 64.844 (64.844)	Prec@5 85.938 (85.938)
 * Prec@1 62.780 Prec@5 86.380
Best accuracy: 63.11%

Epoch: [7][0/391]	Loss 0.6372 (0.6372)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [7][200/391]	Loss 0.4871 (0.5898)	Prec@1 85.156 (83.703)	Prec@5 98.438 (98.127)	LR: 0.0001
 * Prec@1 83.586 Prec@5 98.152
Best Train Accuracy: 83.69%

Test: [0/79]	Loss 1.4717 (1.4717)	Prec@1 64.062 (64.062)	Prec@5 86.719 (86.719)
 * Prec@1 62.680 Prec@5 86.520
Best accuracy: 63.11%

Epoch: [8][0/391]	Loss 0.5498 (0.5498)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [8][200/391]	Loss 0.6968 (0.5947)	Prec@1 77.344 (83.512)	Prec@5 95.312 (98.185)	LR: 0.0001
 * Prec@1 83.378 Prec@5 98.138
Best Train Accuracy: 83.69%

Test: [0/79]	Loss 1.4951 (1.4951)	Prec@1 65.625 (65.625)	Prec@5 85.156 (85.156)
 * Prec@1 62.780 Prec@5 86.040
Best accuracy: 63.11%

Epoch: [9][0/391]	Loss 0.6143 (0.6143)	Prec@1 82.812 (82.812)	Prec@5 96.875 (96.875)	LR: 0.0001
Epoch: [9][200/391]	Loss 0.5718 (0.5894)	Prec@1 84.375 (83.551)	Prec@5 100.000 (98.119)	LR: 0.0001
 * Prec@1 83.670 Prec@5 98.130
Best Train Accuracy: 83.69%

Test: [0/79]	Loss 1.4727 (1.4727)	Prec@1 65.625 (65.625)	Prec@5 85.156 (85.156)
 * Prec@1 62.880 Prec@5 86.340
Best accuracy: 63.11%

Epoch: [10][0/391]	Loss 0.5244 (0.5244)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)	LR: 0.0001
Epoch: [10][200/391]	Loss 0.5688 (0.5918)	Prec@1 79.688 (83.734)	Prec@5 99.219 (98.228)	LR: 0.0001
 * Prec@1 83.680 Prec@5 98.154
Best Train Accuracy: 83.69%

Test: [0/79]	Loss 1.4922 (1.4922)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.870 Prec@5 86.110
Best accuracy: 63.11%

Epoch: [11][0/391]	Loss 0.5571 (0.5571)	Prec@1 85.938 (85.938)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [11][200/391]	Loss 0.5176 (0.5938)	Prec@1 86.719 (83.539)	Prec@5 97.656 (98.165)	LR: 0.0001
 * Prec@1 83.666 Prec@5 98.126
Best Train Accuracy: 83.69%

Test: [0/79]	Loss 1.4746 (1.4746)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.820 Prec@5 86.480
Best accuracy: 63.11%

Epoch: [12][0/391]	Loss 0.6523 (0.6523)	Prec@1 81.250 (81.250)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [12][200/391]	Loss 0.5576 (0.5879)	Prec@1 85.938 (83.652)	Prec@5 98.438 (98.208)	LR: 0.0001
 * Prec@1 83.694 Prec@5 98.102
Best Train Accuracy: 83.69%

Test: [0/79]	Loss 1.4756 (1.4756)	Prec@1 65.625 (65.625)	Prec@5 85.156 (85.156)
 * Prec@1 62.830 Prec@5 86.250
Best accuracy: 63.11%

Epoch: [13][0/391]	Loss 0.6880 (0.6880)	Prec@1 83.594 (83.594)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [13][200/391]	Loss 0.6025 (0.5903)	Prec@1 82.812 (83.804)	Prec@5 99.219 (98.119)	LR: 0.0001
 * Prec@1 83.802 Prec@5 98.126
Best Train Accuracy: 83.80%

Test: [0/79]	Loss 1.4805 (1.4805)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.910 Prec@5 86.500
Best accuracy: 63.11%

Epoch: [14][0/391]	Loss 0.6260 (0.6260)	Prec@1 83.594 (83.594)	Prec@5 96.875 (96.875)	LR: 0.0001
Epoch: [14][200/391]	Loss 0.5928 (0.5947)	Prec@1 85.156 (83.749)	Prec@5 96.875 (98.068)	LR: 0.0001
 * Prec@1 83.714 Prec@5 98.064
Best Train Accuracy: 83.80%

Test: [0/79]	Loss 1.4570 (1.4570)	Prec@1 64.062 (64.062)	Prec@5 86.719 (86.719)
 * Prec@1 62.980 Prec@5 86.540
Best accuracy: 63.11%

Epoch: [15][0/391]	Loss 0.6709 (0.6709)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [15][200/391]	Loss 0.6157 (0.5908)	Prec@1 82.812 (83.590)	Prec@5 98.438 (98.290)	LR: 0.0001
 * Prec@1 83.650 Prec@5 98.206
Best Train Accuracy: 83.80%

Test: [0/79]	Loss 1.4707 (1.4707)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.970 Prec@5 86.280
Best accuracy: 63.11%

Epoch: [16][0/391]	Loss 0.5601 (0.5601)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)	LR: 0.0001
Epoch: [16][200/391]	Loss 0.6050 (0.5952)	Prec@1 80.469 (83.353)	Prec@5 97.656 (98.103)	LR: 0.0001
 * Prec@1 83.582 Prec@5 98.118
Best Train Accuracy: 83.80%

Test: [0/79]	Loss 1.4863 (1.4863)	Prec@1 65.625 (65.625)	Prec@5 84.375 (84.375)
 * Prec@1 62.910 Prec@5 86.280
Best accuracy: 63.11%

Epoch: [17][0/391]	Loss 0.4504 (0.4504)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)	LR: 0.0001
Epoch: [17][200/391]	Loss 0.5869 (0.5859)	Prec@1 82.812 (83.928)	Prec@5 98.438 (98.169)	LR: 0.0001
 * Prec@1 83.648 Prec@5 98.140
Best Train Accuracy: 83.80%

Test: [0/79]	Loss 1.4717 (1.4717)	Prec@1 64.062 (64.062)	Prec@5 84.375 (84.375)
 * Prec@1 62.800 Prec@5 86.420
Best accuracy: 63.11%

Epoch: [18][0/391]	Loss 0.6113 (0.6113)	Prec@1 84.375 (84.375)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [18][200/391]	Loss 0.7261 (0.5903)	Prec@1 75.781 (83.570)	Prec@5 98.438 (98.099)	LR: 0.0001
 * Prec@1 83.596 Prec@5 98.146
Best Train Accuracy: 83.80%

Test: [0/79]	Loss 1.4756 (1.4756)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.740 Prec@5 86.330
Best accuracy: 63.11%

Epoch: [19][0/391]	Loss 0.6196 (0.6196)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [19][200/391]	Loss 0.6533 (0.5938)	Prec@1 86.719 (83.827)	Prec@5 96.875 (98.099)	LR: 0.0001
 * Prec@1 83.836 Prec@5 98.188
Best Train Accuracy: 83.84%

Test: [0/79]	Loss 1.4678 (1.4678)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.640 Prec@5 86.410
Best accuracy: 63.11%

Epoch: [20][0/391]	Loss 0.7256 (0.7256)	Prec@1 77.344 (77.344)	Prec@5 96.094 (96.094)	LR: 0.0001
Epoch: [20][200/391]	Loss 0.6201 (0.5859)	Prec@1 82.031 (83.757)	Prec@5 95.312 (98.208)	LR: 0.0001
 * Prec@1 83.542 Prec@5 98.218
Best Train Accuracy: 83.84%

Test: [0/79]	Loss 1.4658 (1.4658)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.830 Prec@5 86.410
Best accuracy: 63.11%

Epoch: [21][0/391]	Loss 0.5889 (0.5889)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [21][200/391]	Loss 0.6094 (0.5820)	Prec@1 85.156 (84.068)	Prec@5 96.875 (98.263)	LR: 0.0001
 * Prec@1 83.682 Prec@5 98.188
Best Train Accuracy: 83.84%

Test: [0/79]	Loss 1.4297 (1.4297)	Prec@1 64.062 (64.062)	Prec@5 85.938 (85.938)
 * Prec@1 62.820 Prec@5 86.320
Best accuracy: 63.11%

Epoch: [22][0/391]	Loss 0.6123 (0.6123)	Prec@1 83.594 (83.594)	Prec@5 96.875 (96.875)	LR: 0.0001
Epoch: [22][200/391]	Loss 0.6880 (0.5859)	Prec@1 84.375 (83.870)	Prec@5 96.094 (98.146)	LR: 0.0001
 * Prec@1 83.870 Prec@5 98.170
Best Train Accuracy: 83.87%

Test: [0/79]	Loss 1.4785 (1.4785)	Prec@1 66.406 (66.406)	Prec@5 85.156 (85.156)
 * Prec@1 62.840 Prec@5 86.310
Best accuracy: 63.11%

Epoch: [23][0/391]	Loss 0.6133 (0.6133)	Prec@1 85.938 (85.938)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [23][200/391]	Loss 0.6523 (0.5869)	Prec@1 81.250 (84.037)	Prec@5 98.438 (98.154)	LR: 0.0001
 * Prec@1 83.926 Prec@5 98.236
Best Train Accuracy: 83.93%

Test: [0/79]	Loss 1.4521 (1.4521)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 63.000 Prec@5 86.550
Best accuracy: 63.11%

Epoch: [24][0/391]	Loss 0.5947 (0.5947)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)	LR: 0.0001
Epoch: [24][200/391]	Loss 0.6074 (0.5913)	Prec@1 81.250 (83.780)	Prec@5 96.094 (98.173)	LR: 0.0001
 * Prec@1 84.078 Prec@5 98.218
Best Train Accuracy: 84.08%

Test: [0/79]	Loss 1.4600 (1.4600)	Prec@1 67.188 (67.188)	Prec@5 84.375 (84.375)
 * Prec@1 62.970 Prec@5 86.230
Best accuracy: 63.11%

Epoch: [25][0/391]	Loss 0.6079 (0.6079)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [25][200/391]	Loss 0.6631 (0.5894)	Prec@1 79.688 (83.718)	Prec@5 100.000 (98.177)	LR: 0.0001
 * Prec@1 83.770 Prec@5 98.202
Best Train Accuracy: 84.08%

Test: [0/79]	Loss 1.4805 (1.4805)	Prec@1 62.500 (62.500)	Prec@5 85.938 (85.938)
 * Prec@1 62.830 Prec@5 86.440
Best accuracy: 63.11%

Epoch: [26][0/391]	Loss 0.5688 (0.5688)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [26][200/391]	Loss 0.6904 (0.5859)	Prec@1 78.125 (83.870)	Prec@5 97.656 (98.185)	LR: 0.0001
 * Prec@1 83.792 Prec@5 98.108
Best Train Accuracy: 84.08%

Test: [0/79]	Loss 1.4824 (1.4824)	Prec@1 64.844 (64.844)	Prec@5 85.938 (85.938)
 * Prec@1 62.710 Prec@5 86.150
Best accuracy: 63.11%

Epoch: [27][0/391]	Loss 0.5322 (0.5322)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)	LR: 0.0001
Epoch: [27][200/391]	Loss 0.5986 (0.5884)	Prec@1 82.812 (83.765)	Prec@5 98.438 (98.298)	LR: 0.0001
 * Prec@1 83.906 Prec@5 98.266
Best Train Accuracy: 84.08%

Test: [0/79]	Loss 1.4707 (1.4707)	Prec@1 64.062 (64.062)	Prec@5 85.938 (85.938)
 * Prec@1 62.740 Prec@5 86.380
Best accuracy: 63.11%

Epoch: [28][0/391]	Loss 0.7588 (0.7588)	Prec@1 75.781 (75.781)	Prec@5 96.094 (96.094)	LR: 0.0001
Epoch: [28][200/391]	Loss 0.6377 (0.5879)	Prec@1 82.031 (83.652)	Prec@5 96.875 (98.208)	LR: 0.0001
 * Prec@1 84.094 Prec@5 98.252
Best Train Accuracy: 84.09%

Test: [0/79]	Loss 1.4883 (1.4883)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.880 Prec@5 86.430
Best accuracy: 63.11%

Epoch: [29][0/391]	Loss 0.6655 (0.6655)	Prec@1 87.500 (87.500)	Prec@5 95.312 (95.312)	LR: 0.0001
Epoch: [29][200/391]	Loss 0.5815 (0.5840)	Prec@1 81.250 (84.052)	Prec@5 99.219 (98.340)	LR: 0.0001
 * Prec@1 83.982 Prec@5 98.266
Best Train Accuracy: 84.09%

Test: [0/79]	Loss 1.4668 (1.4668)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.630 Prec@5 86.520
Best accuracy: 63.11%

Epoch: [30][0/391]	Loss 0.5522 (0.5522)	Prec@1 85.938 (85.938)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [30][200/391]	Loss 0.6138 (0.5850)	Prec@1 83.594 (84.014)	Prec@5 98.438 (98.263)	LR: 0.0001
 * Prec@1 83.876 Prec@5 98.234
Best Train Accuracy: 84.09%

Test: [0/79]	Loss 1.4541 (1.4541)	Prec@1 64.062 (64.062)	Prec@5 85.938 (85.938)
 * Prec@1 63.010 Prec@5 86.470
Best accuracy: 63.11%

Epoch: [31][0/391]	Loss 0.6948 (0.6948)	Prec@1 84.375 (84.375)	Prec@5 95.312 (95.312)	LR: 0.0001
Epoch: [31][200/391]	Loss 0.4309 (0.5815)	Prec@1 90.625 (83.955)	Prec@5 100.000 (98.286)	LR: 0.0001
 * Prec@1 83.824 Prec@5 98.248
Best Train Accuracy: 84.09%

Test: [0/79]	Loss 1.4824 (1.4824)	Prec@1 64.844 (64.844)	Prec@5 84.375 (84.375)
 * Prec@1 62.800 Prec@5 86.420
Best accuracy: 63.11%

Epoch: [32][0/391]	Loss 0.5654 (0.5654)	Prec@1 85.156 (85.156)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [32][200/391]	Loss 0.6196 (0.5845)	Prec@1 83.594 (83.862)	Prec@5 98.438 (98.197)	LR: 0.0001
 * Prec@1 84.058 Prec@5 98.172
Best Train Accuracy: 84.09%

Test: [0/79]	Loss 1.4453 (1.4453)	Prec@1 64.844 (64.844)	Prec@5 85.156 (85.156)
 * Prec@1 62.550 Prec@5 86.240
Best accuracy: 63.11%

Epoch: [33][0/391]	Loss 0.4490 (0.4490)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [33][200/391]	Loss 0.4897 (0.5776)	Prec@1 89.062 (84.227)	Prec@5 96.875 (98.177)	LR: 0.0001
 * Prec@1 84.280 Prec@5 98.256
Best Train Accuracy: 84.28%

Test: [0/79]	Loss 1.4902 (1.4902)	Prec@1 61.719 (61.719)	Prec@5 85.938 (85.938)
 * Prec@1 62.950 Prec@5 86.380
Best accuracy: 63.11%

Epoch: [34][0/391]	Loss 0.5376 (0.5376)	Prec@1 85.938 (85.938)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [34][200/391]	Loss 0.6191 (0.5762)	Prec@1 83.594 (84.499)	Prec@5 98.438 (98.286)	LR: 0.0001
 * Prec@1 84.446 Prec@5 98.306
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4756 (1.4756)	Prec@1 63.281 (63.281)	Prec@5 84.375 (84.375)
 * Prec@1 62.640 Prec@5 86.350
Best accuracy: 63.11%

Epoch: [35][0/391]	Loss 0.6421 (0.6421)	Prec@1 82.031 (82.031)	Prec@5 96.875 (96.875)	LR: 0.0001
Epoch: [35][200/391]	Loss 0.6113 (0.5708)	Prec@1 84.375 (84.340)	Prec@5 98.438 (98.371)	LR: 0.0001
 * Prec@1 84.262 Prec@5 98.332
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4746 (1.4746)	Prec@1 63.281 (63.281)	Prec@5 84.375 (84.375)
 * Prec@1 62.710 Prec@5 86.420
Best accuracy: 63.11%

Epoch: [36][0/391]	Loss 0.6074 (0.6074)	Prec@1 84.375 (84.375)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [36][200/391]	Loss 0.5977 (0.5791)	Prec@1 86.719 (83.982)	Prec@5 96.875 (98.352)	LR: 0.0001
 * Prec@1 84.074 Prec@5 98.250
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4658 (1.4658)	Prec@1 64.062 (64.062)	Prec@5 85.938 (85.938)
 * Prec@1 62.710 Prec@5 86.470
Best accuracy: 63.11%

Epoch: [37][0/391]	Loss 0.5669 (0.5669)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [37][200/391]	Loss 0.4133 (0.5669)	Prec@1 89.062 (84.659)	Prec@5 99.219 (98.212)	LR: 0.0001
 * Prec@1 84.426 Prec@5 98.210
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4551 (1.4551)	Prec@1 64.844 (64.844)	Prec@5 85.938 (85.938)
 * Prec@1 62.810 Prec@5 86.300
Best accuracy: 63.11%

Epoch: [38][0/391]	Loss 0.7476 (0.7476)	Prec@1 78.125 (78.125)	Prec@5 96.875 (96.875)	LR: 0.0001
Epoch: [38][200/391]	Loss 0.5415 (0.5732)	Prec@1 85.938 (84.507)	Prec@5 100.000 (98.278)	LR: 0.0001
 * Prec@1 84.450 Prec@5 98.284
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4785 (1.4785)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.850 Prec@5 86.300
Best accuracy: 63.11%

Epoch: [39][0/391]	Loss 0.5176 (0.5176)	Prec@1 86.719 (86.719)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [39][200/391]	Loss 0.5273 (0.5688)	Prec@1 87.500 (84.565)	Prec@5 99.219 (98.278)	LR: 0.0001
 * Prec@1 84.382 Prec@5 98.224
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4658 (1.4658)	Prec@1 63.281 (63.281)	Prec@5 84.375 (84.375)
 * Prec@1 62.590 Prec@5 86.260
Best accuracy: 63.11%

Epoch: [40][0/391]	Loss 0.5898 (0.5898)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)	LR: 0.0001
Epoch: [40][200/391]	Loss 0.6367 (0.5884)	Prec@1 82.031 (83.881)	Prec@5 96.094 (98.231)	LR: 0.0001
 * Prec@1 83.778 Prec@5 98.224
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4688 (1.4688)	Prec@1 64.844 (64.844)	Prec@5 85.938 (85.938)
 * Prec@1 62.560 Prec@5 86.230
Best accuracy: 63.11%

Epoch: [41][0/391]	Loss 0.5942 (0.5942)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [41][200/391]	Loss 0.5977 (0.5879)	Prec@1 82.031 (83.761)	Prec@5 98.438 (98.220)	LR: 0.0001
 * Prec@1 83.660 Prec@5 98.170
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4688 (1.4688)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.900 Prec@5 86.390
Best accuracy: 63.11%

Epoch: [42][0/391]	Loss 0.5010 (0.5010)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [42][200/391]	Loss 0.5186 (0.5884)	Prec@1 89.844 (83.407)	Prec@5 99.219 (98.259)	LR: 0.0001
 * Prec@1 83.504 Prec@5 98.230
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4990 (1.4990)	Prec@1 60.938 (60.938)	Prec@5 85.156 (85.156)
 * Prec@1 62.610 Prec@5 86.250
Best accuracy: 63.11%

Epoch: [43][0/391]	Loss 0.5630 (0.5630)	Prec@1 86.719 (86.719)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [43][200/391]	Loss 0.6499 (0.5815)	Prec@1 82.812 (83.815)	Prec@5 97.656 (98.274)	LR: 0.0001
 * Prec@1 83.804 Prec@5 98.272
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.5000 (1.5000)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.980 Prec@5 86.130
Best accuracy: 63.11%

Epoch: [44][0/391]	Loss 0.4949 (0.4949)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [44][200/391]	Loss 0.5122 (0.5894)	Prec@1 87.500 (83.668)	Prec@5 97.656 (98.197)	LR: 0.0001
 * Prec@1 83.742 Prec@5 98.242
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4756 (1.4756)	Prec@1 62.500 (62.500)	Prec@5 85.156 (85.156)
 * Prec@1 62.950 Prec@5 86.340
Best accuracy: 63.11%

Epoch: [45][0/391]	Loss 0.5830 (0.5830)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)	LR: 0.0001
Epoch: [45][200/391]	Loss 0.5459 (0.5830)	Prec@1 86.719 (83.967)	Prec@5 97.656 (98.103)	LR: 0.0001
 * Prec@1 83.788 Prec@5 98.152
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4844 (1.4844)	Prec@1 59.375 (59.375)	Prec@5 86.719 (86.719)
 * Prec@1 62.790 Prec@5 86.060
Best accuracy: 63.11%

Epoch: [46][0/391]	Loss 0.5830 (0.5830)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [46][200/391]	Loss 0.4929 (0.5825)	Prec@1 86.719 (84.138)	Prec@5 97.656 (98.142)	LR: 0.0001
 * Prec@1 84.108 Prec@5 98.254
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4932 (1.4932)	Prec@1 60.938 (60.938)	Prec@5 85.938 (85.938)
 * Prec@1 62.560 Prec@5 86.350
Best accuracy: 63.11%

Epoch: [47][0/391]	Loss 0.6445 (0.6445)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [47][200/391]	Loss 0.6250 (0.5884)	Prec@1 81.250 (83.722)	Prec@5 99.219 (98.231)	LR: 0.0001
 * Prec@1 83.770 Prec@5 98.196
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4590 (1.4590)	Prec@1 62.500 (62.500)	Prec@5 86.719 (86.719)
 * Prec@1 62.980 Prec@5 86.200
Best accuracy: 63.11%

Epoch: [48][0/391]	Loss 0.6958 (0.6958)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [48][200/391]	Loss 0.5654 (0.5767)	Prec@1 84.375 (84.332)	Prec@5 98.438 (98.418)	LR: 0.0001
 * Prec@1 84.260 Prec@5 98.374
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4941 (1.4941)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.690 Prec@5 86.560
Best accuracy: 63.11%

Epoch: [49][0/391]	Loss 0.6021 (0.6021)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)	LR: 0.0001
Epoch: [49][200/391]	Loss 0.4949 (0.5820)	Prec@1 87.500 (84.037)	Prec@5 99.219 (98.142)	LR: 0.0001
 * Prec@1 83.848 Prec@5 98.202
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4688 (1.4688)	Prec@1 62.500 (62.500)	Prec@5 86.719 (86.719)
 * Prec@1 62.810 Prec@5 86.390
Best accuracy: 63.11%

Epoch: [50][0/391]	Loss 0.5386 (0.5386)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)	LR: 0.0001
Epoch: [50][200/391]	Loss 0.6196 (0.5864)	Prec@1 84.375 (83.877)	Prec@5 98.438 (98.165)	LR: 0.0001
 * Prec@1 83.930 Prec@5 98.236
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4746 (1.4746)	Prec@1 65.625 (65.625)	Prec@5 85.938 (85.938)
 * Prec@1 62.970 Prec@5 86.410
Best accuracy: 63.11%

Epoch: [51][0/391]	Loss 0.5532 (0.5532)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)	LR: 0.0001
Epoch: [51][200/391]	Loss 0.5449 (0.5835)	Prec@1 86.719 (84.083)	Prec@5 98.438 (98.115)	LR: 0.0001
 * Prec@1 84.044 Prec@5 98.188
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4658 (1.4658)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.920 Prec@5 86.330
Best accuracy: 63.11%

Epoch: [52][0/391]	Loss 0.5493 (0.5493)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)	LR: 0.0001
Epoch: [52][200/391]	Loss 0.7368 (0.5830)	Prec@1 77.344 (83.982)	Prec@5 97.656 (98.278)	LR: 0.0001
 * Prec@1 83.926 Prec@5 98.246
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4766 (1.4766)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.860 Prec@5 86.470
Best accuracy: 63.11%

Epoch: [53][0/391]	Loss 0.5635 (0.5635)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)	LR: 0.0001
Epoch: [53][200/391]	Loss 0.4714 (0.5811)	Prec@1 89.844 (84.185)	Prec@5 100.000 (98.270)	LR: 0.0001
 * Prec@1 84.090 Prec@5 98.240
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4561 (1.4561)	Prec@1 64.062 (64.062)	Prec@5 86.719 (86.719)
 * Prec@1 63.040 Prec@5 86.460
Best accuracy: 63.11%

Epoch: [54][0/391]	Loss 0.7588 (0.7588)	Prec@1 78.125 (78.125)	Prec@5 95.312 (95.312)	LR: 0.0001
Epoch: [54][200/391]	Loss 0.6914 (0.5801)	Prec@1 82.031 (84.270)	Prec@5 98.438 (98.298)	LR: 0.0001
 * Prec@1 84.152 Prec@5 98.240
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.5010 (1.5010)	Prec@1 60.938 (60.938)	Prec@5 85.938 (85.938)
 * Prec@1 62.780 Prec@5 86.320
Best accuracy: 63.11%

Epoch: [55][0/391]	Loss 0.6528 (0.6528)	Prec@1 78.906 (78.906)	Prec@5 96.875 (96.875)	LR: 0.0001
Epoch: [55][200/391]	Loss 0.6099 (0.5845)	Prec@1 79.688 (83.947)	Prec@5 99.219 (98.228)	LR: 0.0001
 * Prec@1 84.144 Prec@5 98.252
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4990 (1.4990)	Prec@1 60.156 (60.156)	Prec@5 85.938 (85.938)
 * Prec@1 62.840 Prec@5 86.240
Best accuracy: 63.11%

Epoch: [56][0/391]	Loss 0.5049 (0.5049)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)	LR: 0.0001
Epoch: [56][200/391]	Loss 0.4585 (0.5884)	Prec@1 88.281 (83.703)	Prec@5 98.438 (98.123)	LR: 0.0001
 * Prec@1 83.814 Prec@5 98.176
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4707 (1.4707)	Prec@1 64.844 (64.844)	Prec@5 85.156 (85.156)
 * Prec@1 62.750 Prec@5 86.410
Best accuracy: 63.11%

Epoch: [57][0/391]	Loss 0.5762 (0.5762)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)	LR: 0.0001
Epoch: [57][200/391]	Loss 0.5649 (0.5811)	Prec@1 85.156 (84.309)	Prec@5 97.656 (98.313)	LR: 0.0001
 * Prec@1 84.128 Prec@5 98.256
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4688 (1.4688)	Prec@1 63.281 (63.281)	Prec@5 86.719 (86.719)
 * Prec@1 62.740 Prec@5 86.210
Best accuracy: 63.11%

Epoch: [58][0/391]	Loss 0.7412 (0.7412)	Prec@1 79.688 (79.688)	Prec@5 96.875 (96.875)	LR: 0.0001
Epoch: [58][200/391]	Loss 0.6431 (0.5732)	Prec@1 78.906 (84.289)	Prec@5 99.219 (98.379)	LR: 0.0001
 * Prec@1 84.376 Prec@5 98.298
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.4961 (1.4961)	Prec@1 60.938 (60.938)	Prec@5 86.719 (86.719)
 * Prec@1 62.890 Prec@5 86.190
Best accuracy: 63.11%

Epoch: [59][0/391]	Loss 0.6382 (0.6382)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)	LR: 0.0001
Epoch: [59][200/391]	Loss 0.5122 (0.5815)	Prec@1 88.281 (83.889)	Prec@5 99.219 (98.263)	LR: 0.0001
 * Prec@1 83.972 Prec@5 98.282
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.5107 (1.5107)	Prec@1 61.719 (61.719)	Prec@5 85.156 (85.156)
 * Prec@1 62.730 Prec@5 86.390
Best accuracy: 63.11%

Epoch: [60][0/391]	Loss 0.5322 (0.5322)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [60][200/391]	Loss 0.6323 (0.5757)	Prec@1 76.562 (84.200)	Prec@5 98.438 (98.352)	LR: 0.0001
 * Prec@1 84.142 Prec@5 98.284
Best Train Accuracy: 84.45%

Test: [0/79]	Loss 1.5000 (1.5000)	Prec@1 62.500 (62.500)	Prec@5 85.938 (85.938)
 * Prec@1 62.650 Prec@5 86.320
Best accuracy: 63.11%

Epoch: [61][0/391]	Loss 0.4753 (0.4753)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [61][200/391]	Loss 0.5640 (0.5757)	Prec@1 81.250 (84.838)	Prec@5 96.875 (98.204)	LR: 0.0001
 * Prec@1 84.496 Prec@5 98.190
Best Train Accuracy: 84.50%

Test: [0/79]	Loss 1.4824 (1.4824)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.840 Prec@5 86.330
Best accuracy: 63.11%

Epoch: [62][0/391]	Loss 0.6250 (0.6250)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [62][200/391]	Loss 0.5474 (0.5786)	Prec@1 85.938 (84.235)	Prec@5 99.219 (98.379)	LR: 0.0001
 * Prec@1 84.228 Prec@5 98.284
Best Train Accuracy: 84.50%

Test: [0/79]	Loss 1.4941 (1.4941)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.760 Prec@5 86.410
Best accuracy: 63.11%

Epoch: [63][0/391]	Loss 0.5806 (0.5806)	Prec@1 81.250 (81.250)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [63][200/391]	Loss 0.5762 (0.5703)	Prec@1 86.719 (84.426)	Prec@5 98.438 (98.371)	LR: 0.0001
 * Prec@1 84.214 Prec@5 98.336
Best Train Accuracy: 84.50%

Test: [0/79]	Loss 1.4678 (1.4678)	Prec@1 62.500 (62.500)	Prec@5 86.719 (86.719)
 * Prec@1 62.810 Prec@5 86.490
Best accuracy: 63.11%

Epoch: [64][0/391]	Loss 0.6753 (0.6753)	Prec@1 80.469 (80.469)	Prec@5 96.094 (96.094)	LR: 0.0001
Epoch: [64][200/391]	Loss 0.5264 (0.5747)	Prec@1 87.500 (84.247)	Prec@5 97.656 (98.294)	LR: 0.0001
 * Prec@1 84.400 Prec@5 98.318
Best Train Accuracy: 84.50%

Test: [0/79]	Loss 1.5039 (1.5039)	Prec@1 62.500 (62.500)	Prec@5 85.938 (85.938)
 * Prec@1 62.480 Prec@5 86.140
Best accuracy: 63.11%

Epoch: [65][0/391]	Loss 0.6646 (0.6646)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)	LR: 0.0001
Epoch: [65][200/391]	Loss 0.7246 (0.5786)	Prec@1 79.688 (84.398)	Prec@5 96.094 (98.344)	LR: 0.0001
 * Prec@1 84.400 Prec@5 98.314
Best Train Accuracy: 84.50%

Test: [0/79]	Loss 1.5166 (1.5166)	Prec@1 64.062 (64.062)	Prec@5 84.375 (84.375)
 * Prec@1 62.930 Prec@5 86.150
Best accuracy: 63.11%

Epoch: [66][0/391]	Loss 0.5786 (0.5786)	Prec@1 85.938 (85.938)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [66][200/391]	Loss 0.5054 (0.5747)	Prec@1 84.375 (84.309)	Prec@5 100.000 (98.301)	LR: 0.0001
 * Prec@1 84.342 Prec@5 98.338
Best Train Accuracy: 84.50%

Test: [0/79]	Loss 1.5049 (1.5049)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.940 Prec@5 86.330
Best accuracy: 63.11%

Epoch: [67][0/391]	Loss 0.8193 (0.8193)	Prec@1 74.219 (74.219)	Prec@5 96.094 (96.094)	LR: 0.0001
Epoch: [67][200/391]	Loss 0.4517 (0.5796)	Prec@1 87.500 (84.293)	Prec@5 99.219 (98.165)	LR: 0.0001
 * Prec@1 84.200 Prec@5 98.254
Best Train Accuracy: 84.50%

Test: [0/79]	Loss 1.4873 (1.4873)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.600 Prec@5 86.320
Best accuracy: 63.11%

Epoch: [68][0/391]	Loss 0.7280 (0.7280)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [68][200/391]	Loss 0.6294 (0.5698)	Prec@1 82.812 (84.686)	Prec@5 97.656 (98.333)	LR: 0.0001
 * Prec@1 84.660 Prec@5 98.304
Best Train Accuracy: 84.66%

Test: [0/79]	Loss 1.5039 (1.5039)	Prec@1 64.062 (64.062)	Prec@5 85.938 (85.938)
 * Prec@1 63.020 Prec@5 86.370
Best accuracy: 63.11%

Epoch: [69][0/391]	Loss 0.5293 (0.5293)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [69][200/391]	Loss 0.4587 (0.5698)	Prec@1 88.281 (84.612)	Prec@5 99.219 (98.360)	LR: 0.0001
 * Prec@1 84.646 Prec@5 98.344
Best Train Accuracy: 84.66%

Test: [0/79]	Loss 1.4932 (1.4932)	Prec@1 62.500 (62.500)	Prec@5 85.938 (85.938)
 * Prec@1 62.760 Prec@5 86.450
Best accuracy: 63.11%

Epoch: [70][0/391]	Loss 0.4617 (0.4617)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)	LR: 0.0001
Epoch: [70][200/391]	Loss 0.4875 (0.5703)	Prec@1 89.844 (84.694)	Prec@5 99.219 (98.321)	LR: 0.0001
 * Prec@1 84.608 Prec@5 98.296
Best Train Accuracy: 84.66%

Test: [0/79]	Loss 1.4951 (1.4951)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.690 Prec@5 86.260
Best accuracy: 63.11%

Epoch: [71][0/391]	Loss 0.5063 (0.5063)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)	LR: 0.0001
Epoch: [71][200/391]	Loss 0.7075 (0.5728)	Prec@1 81.250 (84.729)	Prec@5 96.875 (98.270)	LR: 0.0001
 * Prec@1 84.578 Prec@5 98.316
Best Train Accuracy: 84.66%

Test: [0/79]	Loss 1.5010 (1.5010)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.890 Prec@5 86.470
Best accuracy: 63.11%

Epoch: [72][0/391]	Loss 0.6235 (0.6235)	Prec@1 80.469 (80.469)	Prec@5 96.875 (96.875)	LR: 0.0001
Epoch: [72][200/391]	Loss 0.7207 (0.5698)	Prec@1 76.562 (84.717)	Prec@5 96.875 (98.251)	LR: 0.0001
 * Prec@1 84.782 Prec@5 98.336
Best Train Accuracy: 84.78%

Test: [0/79]	Loss 1.4980 (1.4980)	Prec@1 64.062 (64.062)	Prec@5 86.719 (86.719)
 * Prec@1 62.840 Prec@5 86.470
Best accuracy: 63.11%

Epoch: [73][0/391]	Loss 0.5928 (0.5928)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)	LR: 0.0001
Epoch: [73][200/391]	Loss 0.6719 (0.5698)	Prec@1 78.906 (84.764)	Prec@5 97.656 (98.286)	LR: 0.0001
 * Prec@1 84.644 Prec@5 98.336
Best Train Accuracy: 84.78%

Test: [0/79]	Loss 1.4736 (1.4736)	Prec@1 61.719 (61.719)	Prec@5 85.938 (85.938)
 * Prec@1 63.010 Prec@5 86.440
Best accuracy: 63.11%

Epoch: [74][0/391]	Loss 0.6343 (0.6343)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)	LR: 0.0001
Epoch: [74][200/391]	Loss 0.6201 (0.5596)	Prec@1 82.812 (84.974)	Prec@5 98.438 (98.348)	LR: 0.0001
 * Prec@1 84.998 Prec@5 98.326
Best Train Accuracy: 85.00%

Test: [0/79]	Loss 1.4893 (1.4893)	Prec@1 64.062 (64.062)	Prec@5 85.938 (85.938)
 * Prec@1 62.990 Prec@5 86.430
Best accuracy: 63.11%

Epoch: [75][0/391]	Loss 0.6997 (0.6997)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [75][200/391]	Loss 0.5874 (0.5630)	Prec@1 82.031 (84.519)	Prec@5 98.438 (98.383)	LR: 0.0001
 * Prec@1 84.678 Prec@5 98.372
Best Train Accuracy: 85.00%

Test: [0/79]	Loss 1.4932 (1.4932)	Prec@1 64.844 (64.844)	Prec@5 84.375 (84.375)
 * Prec@1 63.010 Prec@5 86.440
Best accuracy: 63.11%

Epoch: [76][0/391]	Loss 0.4851 (0.4851)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)	LR: 0.0001
Epoch: [76][200/391]	Loss 0.4961 (0.5664)	Prec@1 88.281 (85.001)	Prec@5 98.438 (98.360)	LR: 0.0001
 * Prec@1 85.112 Prec@5 98.408
Best Train Accuracy: 85.11%

Test: [0/79]	Loss 1.4697 (1.4697)	Prec@1 64.062 (64.062)	Prec@5 83.594 (83.594)
 * Prec@1 63.040 Prec@5 86.450
Best accuracy: 63.11%

Epoch: [77][0/391]	Loss 0.6333 (0.6333)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)	LR: 0.0001
Epoch: [77][200/391]	Loss 0.5356 (0.5586)	Prec@1 85.938 (85.133)	Prec@5 97.656 (98.403)	LR: 0.0001
 * Prec@1 85.182 Prec@5 98.382
Best Train Accuracy: 85.18%

Test: [0/79]	Loss 1.4707 (1.4707)	Prec@1 64.844 (64.844)	Prec@5 85.156 (85.156)
 * Prec@1 62.760 Prec@5 86.440
Best accuracy: 63.11%

Epoch: [78][0/391]	Loss 0.6777 (0.6777)	Prec@1 81.250 (81.250)	Prec@5 96.094 (96.094)	LR: 0.0001
Epoch: [78][200/391]	Loss 0.5884 (0.5562)	Prec@1 83.594 (85.452)	Prec@5 97.656 (98.438)	LR: 0.0001
 * Prec@1 85.392 Prec@5 98.404
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4990 (1.4990)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.800 Prec@5 86.290
Best accuracy: 63.11%

Epoch: [79][0/391]	Loss 0.5400 (0.5400)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)	LR: 0.0001
Epoch: [79][200/391]	Loss 0.5967 (0.5586)	Prec@1 84.375 (85.187)	Prec@5 99.219 (98.403)	LR: 0.0001
 * Prec@1 85.384 Prec@5 98.476
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5000 (1.5000)	Prec@1 60.938 (60.938)	Prec@5 84.375 (84.375)
 * Prec@1 62.700 Prec@5 86.320
Best accuracy: 63.11%

Epoch: [80][0/391]	Loss 0.6167 (0.6167)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)	LR: 2e-05
Epoch: [80][200/391]	Loss 0.5459 (0.5913)	Prec@1 85.938 (83.947)	Prec@5 99.219 (98.158)	LR: 2e-05
 * Prec@1 83.666 Prec@5 98.136
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5107 (1.5107)	Prec@1 61.719 (61.719)	Prec@5 85.156 (85.156)
 * Prec@1 62.920 Prec@5 86.160
Best accuracy: 63.11%

Epoch: [81][0/391]	Loss 0.6479 (0.6479)	Prec@1 83.594 (83.594)	Prec@5 96.875 (96.875)	LR: 2e-05
Epoch: [81][200/391]	Loss 0.6172 (0.5942)	Prec@1 84.375 (83.431)	Prec@5 98.438 (98.130)	LR: 2e-05
 * Prec@1 83.416 Prec@5 98.102
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5137 (1.5137)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.660 Prec@5 86.260
Best accuracy: 63.11%

Epoch: [82][0/391]	Loss 0.5420 (0.5420)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [82][200/391]	Loss 0.7388 (0.5898)	Prec@1 82.031 (83.792)	Prec@5 98.438 (98.103)	LR: 2e-05
 * Prec@1 83.932 Prec@5 98.162
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5068 (1.5068)	Prec@1 64.844 (64.844)	Prec@5 84.375 (84.375)
 * Prec@1 62.760 Prec@5 86.250
Best accuracy: 63.11%

Epoch: [83][0/391]	Loss 0.6626 (0.6626)	Prec@1 82.812 (82.812)	Prec@5 96.875 (96.875)	LR: 2e-05
Epoch: [83][200/391]	Loss 0.5879 (0.5942)	Prec@1 82.031 (83.687)	Prec@5 100.000 (98.173)	LR: 2e-05
 * Prec@1 83.512 Prec@5 98.162
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4795 (1.4795)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 63.050 Prec@5 86.290
Best accuracy: 63.11%

Epoch: [84][0/391]	Loss 0.5269 (0.5269)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [84][200/391]	Loss 0.6831 (0.5913)	Prec@1 82.031 (83.668)	Prec@5 96.094 (98.263)	LR: 2e-05
 * Prec@1 83.734 Prec@5 98.248
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4941 (1.4941)	Prec@1 64.062 (64.062)	Prec@5 84.375 (84.375)
 * Prec@1 62.850 Prec@5 86.360
Best accuracy: 63.11%

Epoch: [85][0/391]	Loss 0.5708 (0.5708)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [85][200/391]	Loss 0.6553 (0.5801)	Prec@1 81.250 (83.998)	Prec@5 97.656 (98.266)	LR: 2e-05
 * Prec@1 83.920 Prec@5 98.200
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4980 (1.4980)	Prec@1 64.844 (64.844)	Prec@5 85.156 (85.156)
 * Prec@1 62.760 Prec@5 86.360
Best accuracy: 63.11%

Epoch: [86][0/391]	Loss 0.5146 (0.5146)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)	LR: 2e-05
Epoch: [86][200/391]	Loss 0.6123 (0.5938)	Prec@1 82.031 (83.804)	Prec@5 98.438 (98.189)	LR: 2e-05
 * Prec@1 83.810 Prec@5 98.174
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4814 (1.4814)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.800 Prec@5 86.460
Best accuracy: 63.11%

Epoch: [87][0/391]	Loss 0.5850 (0.5850)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)	LR: 2e-05
Epoch: [87][200/391]	Loss 0.5859 (0.5884)	Prec@1 83.594 (83.726)	Prec@5 99.219 (98.068)	LR: 2e-05
 * Prec@1 83.854 Prec@5 98.112
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5059 (1.5059)	Prec@1 62.500 (62.500)	Prec@5 85.156 (85.156)
 * Prec@1 62.940 Prec@5 86.320
Best accuracy: 63.11%

Epoch: [88][0/391]	Loss 0.6006 (0.6006)	Prec@1 82.031 (82.031)	Prec@5 96.875 (96.875)	LR: 2e-05
Epoch: [88][200/391]	Loss 0.6763 (0.5918)	Prec@1 81.250 (83.831)	Prec@5 96.875 (98.216)	LR: 2e-05
 * Prec@1 83.776 Prec@5 98.138
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5029 (1.5029)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.680 Prec@5 86.290
Best accuracy: 63.11%

Epoch: [89][0/391]	Loss 0.5991 (0.5991)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [89][200/391]	Loss 0.4612 (0.5869)	Prec@1 90.625 (83.718)	Prec@5 98.438 (98.158)	LR: 2e-05
 * Prec@1 83.568 Prec@5 98.222
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4854 (1.4854)	Prec@1 67.188 (67.188)	Prec@5 85.156 (85.156)
 * Prec@1 62.690 Prec@5 86.340
Best accuracy: 63.11%

Epoch: [90][0/391]	Loss 0.6719 (0.6719)	Prec@1 79.688 (79.688)	Prec@5 95.312 (95.312)	LR: 2e-05
Epoch: [90][200/391]	Loss 0.5010 (0.5864)	Prec@1 85.156 (84.130)	Prec@5 98.438 (98.208)	LR: 2e-05
 * Prec@1 84.062 Prec@5 98.212
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4873 (1.4873)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.730 Prec@5 86.340
Best accuracy: 63.11%

Epoch: [91][0/391]	Loss 0.6108 (0.6108)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)	LR: 2e-05
Epoch: [91][200/391]	Loss 0.5645 (0.5947)	Prec@1 82.031 (83.691)	Prec@5 98.438 (98.064)	LR: 2e-05
 * Prec@1 83.890 Prec@5 98.166
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5078 (1.5078)	Prec@1 64.062 (64.062)	Prec@5 84.375 (84.375)
 * Prec@1 62.740 Prec@5 86.300
Best accuracy: 63.11%

Epoch: [92][0/391]	Loss 0.4983 (0.4983)	Prec@1 88.281 (88.281)	Prec@5 97.656 (97.656)	LR: 2e-05
Epoch: [92][200/391]	Loss 0.6011 (0.5908)	Prec@1 85.156 (83.629)	Prec@5 99.219 (98.317)	LR: 2e-05
 * Prec@1 83.680 Prec@5 98.220
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4883 (1.4883)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.880 Prec@5 86.430
Best accuracy: 63.11%

Epoch: [93][0/391]	Loss 0.6489 (0.6489)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)	LR: 2e-05
Epoch: [93][200/391]	Loss 0.7148 (0.5776)	Prec@1 80.469 (84.208)	Prec@5 95.312 (98.356)	LR: 2e-05
 * Prec@1 83.974 Prec@5 98.270
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4932 (1.4932)	Prec@1 65.625 (65.625)	Prec@5 84.375 (84.375)
 * Prec@1 62.950 Prec@5 86.280
Best accuracy: 63.11%

Epoch: [94][0/391]	Loss 0.5879 (0.5879)	Prec@1 84.375 (84.375)	Prec@5 97.656 (97.656)	LR: 2e-05
Epoch: [94][200/391]	Loss 0.5640 (0.5864)	Prec@1 86.719 (83.881)	Prec@5 99.219 (98.193)	LR: 2e-05
 * Prec@1 83.834 Prec@5 98.180
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4932 (1.4932)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.660 Prec@5 86.360
Best accuracy: 63.11%

Epoch: [95][0/391]	Loss 0.6206 (0.6206)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [95][200/391]	Loss 0.5024 (0.5884)	Prec@1 85.938 (83.885)	Prec@5 100.000 (98.169)	LR: 2e-05
 * Prec@1 83.638 Prec@5 98.150
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4922 (1.4922)	Prec@1 64.062 (64.062)	Prec@5 84.375 (84.375)
 * Prec@1 62.660 Prec@5 86.360
Best accuracy: 63.11%

Epoch: [96][0/391]	Loss 0.5513 (0.5513)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [96][200/391]	Loss 0.7310 (0.5845)	Prec@1 76.562 (83.745)	Prec@5 97.656 (98.235)	LR: 2e-05
 * Prec@1 84.082 Prec@5 98.216
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4785 (1.4785)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.860 Prec@5 86.410
Best accuracy: 63.11%

Epoch: [97][0/391]	Loss 0.6060 (0.6060)	Prec@1 85.156 (85.156)	Prec@5 97.656 (97.656)	LR: 2e-05
Epoch: [97][200/391]	Loss 0.5884 (0.5903)	Prec@1 83.594 (83.543)	Prec@5 98.438 (98.150)	LR: 2e-05
 * Prec@1 83.630 Prec@5 98.104
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5078 (1.5078)	Prec@1 61.719 (61.719)	Prec@5 84.375 (84.375)
 * Prec@1 62.630 Prec@5 86.360
Best accuracy: 63.11%

Epoch: [98][0/391]	Loss 0.5195 (0.5195)	Prec@1 90.625 (90.625)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [98][200/391]	Loss 0.6836 (0.5850)	Prec@1 78.125 (83.843)	Prec@5 98.438 (98.317)	LR: 2e-05
 * Prec@1 83.736 Prec@5 98.236
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4824 (1.4824)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 63.030 Prec@5 86.190
Best accuracy: 63.11%

Epoch: [99][0/391]	Loss 0.4817 (0.4817)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)	LR: 2e-05
Epoch: [99][200/391]	Loss 0.5845 (0.5840)	Prec@1 84.375 (84.025)	Prec@5 98.438 (98.208)	LR: 2e-05
 * Prec@1 83.960 Prec@5 98.172
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4980 (1.4980)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.880 Prec@5 86.150
Best accuracy: 63.11%

Epoch: [100][0/391]	Loss 0.7451 (0.7451)	Prec@1 77.344 (77.344)	Prec@5 96.875 (96.875)	LR: 2e-05
Epoch: [100][200/391]	Loss 0.5732 (0.5884)	Prec@1 82.031 (83.990)	Prec@5 99.219 (98.162)	LR: 2e-05
 * Prec@1 83.888 Prec@5 98.142
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5049 (1.5049)	Prec@1 60.156 (60.156)	Prec@5 84.375 (84.375)
 * Prec@1 62.670 Prec@5 86.260
Best accuracy: 63.11%

Epoch: [101][0/391]	Loss 0.6133 (0.6133)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [101][200/391]	Loss 0.5923 (0.5918)	Prec@1 82.812 (83.539)	Prec@5 97.656 (98.134)	LR: 2e-05
 * Prec@1 83.678 Prec@5 98.138
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5039 (1.5039)	Prec@1 61.719 (61.719)	Prec@5 85.938 (85.938)
 * Prec@1 62.920 Prec@5 86.290
Best accuracy: 63.11%

Epoch: [102][0/391]	Loss 0.4854 (0.4854)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)	LR: 2e-05
Epoch: [102][200/391]	Loss 0.5044 (0.5752)	Prec@1 81.250 (84.433)	Prec@5 99.219 (98.309)	LR: 2e-05
 * Prec@1 84.228 Prec@5 98.178
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4990 (1.4990)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.560 Prec@5 86.350
Best accuracy: 63.11%

Epoch: [103][0/391]	Loss 0.5283 (0.5283)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [103][200/391]	Loss 0.6099 (0.5825)	Prec@1 85.938 (84.014)	Prec@5 97.656 (98.197)	LR: 2e-05
 * Prec@1 84.050 Prec@5 98.162
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4785 (1.4785)	Prec@1 64.844 (64.844)	Prec@5 85.156 (85.156)
 * Prec@1 62.550 Prec@5 86.560
Best accuracy: 63.11%

Epoch: [104][0/391]	Loss 0.6597 (0.6597)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)	LR: 2e-05
Epoch: [104][200/391]	Loss 0.6260 (0.5864)	Prec@1 85.156 (83.893)	Prec@5 96.875 (98.243)	LR: 2e-05
 * Prec@1 83.850 Prec@5 98.222
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4893 (1.4893)	Prec@1 64.062 (64.062)	Prec@5 84.375 (84.375)
 * Prec@1 62.760 Prec@5 86.430
Best accuracy: 63.11%

Epoch: [105][0/391]	Loss 0.6016 (0.6016)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)	LR: 2e-05
Epoch: [105][200/391]	Loss 0.6611 (0.5850)	Prec@1 80.469 (84.033)	Prec@5 98.438 (98.212)	LR: 2e-05
 * Prec@1 83.916 Prec@5 98.238
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4941 (1.4941)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.790 Prec@5 86.390
Best accuracy: 63.11%

Epoch: [106][0/391]	Loss 0.7090 (0.7090)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)	LR: 2e-05
Epoch: [106][200/391]	Loss 0.5684 (0.5850)	Prec@1 84.375 (84.083)	Prec@5 97.656 (98.177)	LR: 2e-05
 * Prec@1 84.000 Prec@5 98.170
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4922 (1.4922)	Prec@1 62.500 (62.500)	Prec@5 85.938 (85.938)
 * Prec@1 62.990 Prec@5 86.440
Best accuracy: 63.11%

Epoch: [107][0/391]	Loss 0.5220 (0.5220)	Prec@1 85.938 (85.938)	Prec@5 97.656 (97.656)	LR: 2e-05
Epoch: [107][200/391]	Loss 0.5498 (0.5894)	Prec@1 86.719 (83.947)	Prec@5 98.438 (98.068)	LR: 2e-05
 * Prec@1 83.926 Prec@5 98.092
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5166 (1.5166)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.660 Prec@5 86.200
Best accuracy: 63.11%

Epoch: [108][0/391]	Loss 0.7266 (0.7266)	Prec@1 78.906 (78.906)	Prec@5 96.875 (96.875)	LR: 2e-05
Epoch: [108][200/391]	Loss 0.5176 (0.5854)	Prec@1 85.938 (83.936)	Prec@5 98.438 (98.317)	LR: 2e-05
 * Prec@1 83.856 Prec@5 98.258
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5088 (1.5088)	Prec@1 61.719 (61.719)	Prec@5 84.375 (84.375)
 * Prec@1 62.720 Prec@5 86.470
Best accuracy: 63.11%

Epoch: [109][0/391]	Loss 0.5933 (0.5933)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)	LR: 2e-05
Epoch: [109][200/391]	Loss 0.6318 (0.5903)	Prec@1 82.031 (83.846)	Prec@5 97.656 (98.162)	LR: 2e-05
 * Prec@1 84.058 Prec@5 98.150
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4834 (1.4834)	Prec@1 64.844 (64.844)	Prec@5 85.938 (85.938)
 * Prec@1 62.760 Prec@5 86.280
Best accuracy: 63.11%

Epoch: [110][0/391]	Loss 0.6929 (0.6929)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [110][200/391]	Loss 0.5791 (0.5894)	Prec@1 80.469 (83.843)	Prec@5 100.000 (98.080)	LR: 2e-05
 * Prec@1 84.046 Prec@5 98.170
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4990 (1.4990)	Prec@1 63.281 (63.281)	Prec@5 84.375 (84.375)
 * Prec@1 62.940 Prec@5 86.290
Best accuracy: 63.11%

Epoch: [111][0/391]	Loss 0.6836 (0.6836)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)	LR: 2e-05
Epoch: [111][200/391]	Loss 0.7012 (0.5806)	Prec@1 80.469 (83.854)	Prec@5 99.219 (98.247)	LR: 2e-05
 * Prec@1 83.866 Prec@5 98.250
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5088 (1.5088)	Prec@1 62.500 (62.500)	Prec@5 85.156 (85.156)
 * Prec@1 62.780 Prec@5 86.320
Best accuracy: 63.11%

Epoch: [112][0/391]	Loss 0.6455 (0.6455)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [112][200/391]	Loss 0.6016 (0.5830)	Prec@1 84.375 (84.115)	Prec@5 96.094 (98.298)	LR: 2e-05
 * Prec@1 84.160 Prec@5 98.204
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4980 (1.4980)	Prec@1 62.500 (62.500)	Prec@5 84.375 (84.375)
 * Prec@1 62.790 Prec@5 86.270
Best accuracy: 63.11%

Epoch: [113][0/391]	Loss 0.5991 (0.5991)	Prec@1 85.938 (85.938)	Prec@5 97.656 (97.656)	LR: 2e-05
Epoch: [113][200/391]	Loss 0.6055 (0.5811)	Prec@1 84.375 (84.255)	Prec@5 97.656 (98.204)	LR: 2e-05
 * Prec@1 84.198 Prec@5 98.204
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4795 (1.4795)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.930 Prec@5 86.420
Best accuracy: 63.11%

Epoch: [114][0/391]	Loss 0.6074 (0.6074)	Prec@1 86.719 (86.719)	Prec@5 96.094 (96.094)	LR: 2e-05
Epoch: [114][200/391]	Loss 0.5269 (0.5845)	Prec@1 85.156 (84.157)	Prec@5 99.219 (98.298)	LR: 2e-05
 * Prec@1 84.246 Prec@5 98.306
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4922 (1.4922)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.800 Prec@5 86.390
Best accuracy: 63.11%

Epoch: [115][0/391]	Loss 0.6826 (0.6826)	Prec@1 77.344 (77.344)	Prec@5 96.875 (96.875)	LR: 2e-05
Epoch: [115][200/391]	Loss 0.6675 (0.5835)	Prec@1 83.594 (83.963)	Prec@5 96.875 (98.263)	LR: 2e-05
 * Prec@1 84.068 Prec@5 98.200
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4727 (1.4727)	Prec@1 65.625 (65.625)	Prec@5 85.938 (85.938)
 * Prec@1 62.880 Prec@5 86.420
Best accuracy: 63.11%

Epoch: [116][0/391]	Loss 0.5342 (0.5342)	Prec@1 87.500 (87.500)	Prec@5 96.875 (96.875)	LR: 2e-05
Epoch: [116][200/391]	Loss 0.7358 (0.5879)	Prec@1 77.344 (83.959)	Prec@5 96.875 (98.142)	LR: 2e-05
 * Prec@1 84.086 Prec@5 98.218
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4717 (1.4717)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.780 Prec@5 86.350
Best accuracy: 63.11%

Epoch: [117][0/391]	Loss 0.4915 (0.4915)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)	LR: 2e-05
Epoch: [117][200/391]	Loss 0.4597 (0.5815)	Prec@1 86.719 (84.049)	Prec@5 99.219 (98.301)	LR: 2e-05
 * Prec@1 83.964 Prec@5 98.320
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4912 (1.4912)	Prec@1 63.281 (63.281)	Prec@5 83.594 (83.594)
 * Prec@1 62.460 Prec@5 86.450
Best accuracy: 63.11%

Epoch: [118][0/391]	Loss 0.6606 (0.6606)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [118][200/391]	Loss 0.5605 (0.5845)	Prec@1 85.156 (83.971)	Prec@5 97.656 (98.290)	LR: 2e-05
 * Prec@1 84.028 Prec@5 98.294
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5000 (1.5000)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.790 Prec@5 86.470
Best accuracy: 63.11%

Epoch: [119][0/391]	Loss 0.5513 (0.5513)	Prec@1 85.938 (85.938)	Prec@5 97.656 (97.656)	LR: 2e-05
Epoch: [119][200/391]	Loss 0.5552 (0.5747)	Prec@1 87.500 (84.402)	Prec@5 97.656 (98.278)	LR: 2e-05
 * Prec@1 84.388 Prec@5 98.330
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5020 (1.5020)	Prec@1 64.844 (64.844)	Prec@5 85.156 (85.156)
 * Prec@1 62.840 Prec@5 86.350
Best accuracy: 63.11%

Epoch: [120][0/391]	Loss 0.7686 (0.7686)	Prec@1 78.125 (78.125)	Prec@5 96.094 (96.094)	LR: 2e-05
Epoch: [120][200/391]	Loss 0.6006 (0.5918)	Prec@1 82.031 (83.516)	Prec@5 98.438 (98.228)	LR: 2e-05
 * Prec@1 83.450 Prec@5 98.194
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5137 (1.5137)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.840 Prec@5 86.450
Best accuracy: 63.11%

Epoch: [121][0/391]	Loss 0.6680 (0.6680)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)	LR: 2e-05
Epoch: [121][200/391]	Loss 0.5977 (0.6025)	Prec@1 83.594 (83.310)	Prec@5 96.875 (98.115)	LR: 2e-05
 * Prec@1 83.476 Prec@5 98.084
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4854 (1.4854)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.920 Prec@5 86.410
Best accuracy: 63.11%

Epoch: [122][0/391]	Loss 0.5356 (0.5356)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [122][200/391]	Loss 0.6802 (0.5923)	Prec@1 82.031 (83.516)	Prec@5 96.875 (98.371)	LR: 2e-05
 * Prec@1 83.630 Prec@5 98.286
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4775 (1.4775)	Prec@1 65.625 (65.625)	Prec@5 85.938 (85.938)
 * Prec@1 62.850 Prec@5 86.380
Best accuracy: 63.11%

Epoch: [123][0/391]	Loss 0.6475 (0.6475)	Prec@1 83.594 (83.594)	Prec@5 96.094 (96.094)	LR: 2e-05
Epoch: [123][200/391]	Loss 0.6431 (0.5933)	Prec@1 80.469 (83.524)	Prec@5 97.656 (98.154)	LR: 2e-05
 * Prec@1 83.488 Prec@5 98.128
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5176 (1.5176)	Prec@1 64.844 (64.844)	Prec@5 84.375 (84.375)
 * Prec@1 62.800 Prec@5 86.210
Best accuracy: 63.11%

Epoch: [124][0/391]	Loss 0.5957 (0.5957)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)	LR: 2e-05
Epoch: [124][200/391]	Loss 0.6489 (0.5913)	Prec@1 81.250 (83.652)	Prec@5 96.875 (98.181)	LR: 2e-05
 * Prec@1 83.554 Prec@5 98.166
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4980 (1.4980)	Prec@1 64.062 (64.062)	Prec@5 84.375 (84.375)
 * Prec@1 62.670 Prec@5 86.390
Best accuracy: 63.11%

Epoch: [125][0/391]	Loss 0.5840 (0.5840)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)	LR: 2e-05
Epoch: [125][200/391]	Loss 0.6743 (0.5898)	Prec@1 82.812 (83.765)	Prec@5 97.656 (98.134)	LR: 2e-05
 * Prec@1 83.560 Prec@5 98.126
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4912 (1.4912)	Prec@1 64.844 (64.844)	Prec@5 84.375 (84.375)
 * Prec@1 62.700 Prec@5 86.350
Best accuracy: 63.11%

Epoch: [126][0/391]	Loss 0.5840 (0.5840)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)	LR: 2e-05
Epoch: [126][200/391]	Loss 0.6147 (0.5903)	Prec@1 78.906 (83.469)	Prec@5 97.656 (98.204)	LR: 2e-05
 * Prec@1 83.378 Prec@5 98.182
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4766 (1.4766)	Prec@1 64.062 (64.062)	Prec@5 85.938 (85.938)
 * Prec@1 62.890 Prec@5 86.380
Best accuracy: 63.11%

Epoch: [127][0/391]	Loss 0.5874 (0.5874)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)	LR: 2e-05
Epoch: [127][200/391]	Loss 0.5649 (0.5972)	Prec@1 83.594 (83.718)	Prec@5 98.438 (98.103)	LR: 2e-05
 * Prec@1 83.774 Prec@5 98.184
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4980 (1.4980)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.810 Prec@5 86.390
Best accuracy: 63.11%

Epoch: [128][0/391]	Loss 0.5781 (0.5781)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [128][200/391]	Loss 0.5205 (0.5869)	Prec@1 82.031 (83.889)	Prec@5 98.438 (98.130)	LR: 2e-05
 * Prec@1 83.504 Prec@5 98.086
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5020 (1.5020)	Prec@1 61.719 (61.719)	Prec@5 85.156 (85.156)
 * Prec@1 62.700 Prec@5 86.480
Best accuracy: 63.11%

Epoch: [129][0/391]	Loss 0.7446 (0.7446)	Prec@1 83.594 (83.594)	Prec@5 95.312 (95.312)	LR: 2e-05
Epoch: [129][200/391]	Loss 0.6323 (0.5957)	Prec@1 85.938 (83.598)	Prec@5 96.094 (98.200)	LR: 2e-05
 * Prec@1 83.668 Prec@5 98.220
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5088 (1.5088)	Prec@1 62.500 (62.500)	Prec@5 84.375 (84.375)
 * Prec@1 62.570 Prec@5 86.360
Best accuracy: 63.11%

Epoch: [130][0/391]	Loss 0.4709 (0.4709)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [130][200/391]	Loss 0.5620 (0.5957)	Prec@1 84.375 (83.500)	Prec@5 96.875 (98.099)	LR: 2e-05
 * Prec@1 83.470 Prec@5 98.118
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4980 (1.4980)	Prec@1 64.844 (64.844)	Prec@5 85.156 (85.156)
 * Prec@1 63.050 Prec@5 86.420
Best accuracy: 63.11%

Epoch: [131][0/391]	Loss 0.5010 (0.5010)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)	LR: 2e-05
Epoch: [131][200/391]	Loss 0.6543 (0.6016)	Prec@1 83.594 (83.217)	Prec@5 96.875 (98.076)	LR: 2e-05
 * Prec@1 83.410 Prec@5 98.142
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4824 (1.4824)	Prec@1 64.062 (64.062)	Prec@5 84.375 (84.375)
 * Prec@1 62.850 Prec@5 86.390
Best accuracy: 63.11%

Epoch: [132][0/391]	Loss 0.6172 (0.6172)	Prec@1 82.812 (82.812)	Prec@5 97.656 (97.656)	LR: 2e-05
Epoch: [132][200/391]	Loss 0.5723 (0.5938)	Prec@1 82.031 (83.396)	Prec@5 99.219 (98.235)	LR: 2e-05
 * Prec@1 83.562 Prec@5 98.174
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4756 (1.4756)	Prec@1 61.719 (61.719)	Prec@5 84.375 (84.375)
 * Prec@1 63.000 Prec@5 86.420
Best accuracy: 63.11%

Epoch: [133][0/391]	Loss 0.5630 (0.5630)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [133][200/391]	Loss 0.5518 (0.5884)	Prec@1 86.719 (83.815)	Prec@5 97.656 (98.193)	LR: 2e-05
 * Prec@1 83.752 Prec@5 98.172
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4766 (1.4766)	Prec@1 61.719 (61.719)	Prec@5 85.156 (85.156)
 * Prec@1 62.780 Prec@5 86.430
Best accuracy: 63.11%

Epoch: [134][0/391]	Loss 0.6582 (0.6582)	Prec@1 83.594 (83.594)	Prec@5 96.875 (96.875)	LR: 2e-05
Epoch: [134][200/391]	Loss 0.4983 (0.5938)	Prec@1 86.719 (83.644)	Prec@5 97.656 (98.224)	LR: 2e-05
 * Prec@1 83.502 Prec@5 98.178
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4854 (1.4854)	Prec@1 64.844 (64.844)	Prec@5 85.156 (85.156)
 * Prec@1 63.030 Prec@5 86.390
Best accuracy: 63.11%

Epoch: [135][0/391]	Loss 0.5166 (0.5166)	Prec@1 86.719 (86.719)	Prec@5 97.656 (97.656)	LR: 2e-05
Epoch: [135][200/391]	Loss 0.4854 (0.5928)	Prec@1 89.062 (83.586)	Prec@5 98.438 (98.127)	LR: 2e-05
 * Prec@1 83.654 Prec@5 98.142
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4980 (1.4980)	Prec@1 61.719 (61.719)	Prec@5 84.375 (84.375)
 * Prec@1 62.570 Prec@5 86.140
Best accuracy: 63.11%

Epoch: [136][0/391]	Loss 0.6592 (0.6592)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)	LR: 2e-05
Epoch: [136][200/391]	Loss 0.6460 (0.5942)	Prec@1 81.250 (83.617)	Prec@5 97.656 (98.088)	LR: 2e-05
 * Prec@1 83.504 Prec@5 98.120
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5088 (1.5088)	Prec@1 61.719 (61.719)	Prec@5 84.375 (84.375)
 * Prec@1 62.780 Prec@5 86.250
Best accuracy: 63.11%

Epoch: [137][0/391]	Loss 0.5625 (0.5625)	Prec@1 84.375 (84.375)	Prec@5 97.656 (97.656)	LR: 2e-05
Epoch: [137][200/391]	Loss 0.6538 (0.5991)	Prec@1 83.594 (83.613)	Prec@5 96.094 (98.154)	LR: 2e-05
 * Prec@1 83.720 Prec@5 98.188
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4717 (1.4717)	Prec@1 65.625 (65.625)	Prec@5 83.594 (83.594)
 * Prec@1 62.870 Prec@5 86.250
Best accuracy: 63.11%

Epoch: [138][0/391]	Loss 0.6597 (0.6597)	Prec@1 82.812 (82.812)	Prec@5 96.875 (96.875)	LR: 2e-05
Epoch: [138][200/391]	Loss 0.5889 (0.5981)	Prec@1 81.250 (83.275)	Prec@5 98.438 (98.212)	LR: 2e-05
 * Prec@1 83.408 Prec@5 98.190
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4834 (1.4834)	Prec@1 64.062 (64.062)	Prec@5 84.375 (84.375)
 * Prec@1 62.960 Prec@5 86.370
Best accuracy: 63.11%

Epoch: [139][0/391]	Loss 0.5322 (0.5322)	Prec@1 81.250 (81.250)	Prec@5 97.656 (97.656)	LR: 2e-05
Epoch: [139][200/391]	Loss 0.5757 (0.5967)	Prec@1 82.812 (83.388)	Prec@5 98.438 (98.165)	LR: 2e-05
 * Prec@1 83.500 Prec@5 98.156
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4951 (1.4951)	Prec@1 60.156 (60.156)	Prec@5 85.156 (85.156)
 * Prec@1 62.830 Prec@5 86.430
Best accuracy: 63.11%

Epoch: [140][0/391]	Loss 0.6309 (0.6309)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)	LR: 4.000000000000001e-06
Epoch: [140][200/391]	Loss 0.6631 (0.5962)	Prec@1 79.688 (83.563)	Prec@5 99.219 (98.053)	LR: 4.000000000000001e-06
 * Prec@1 83.406 Prec@5 98.088
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4756 (1.4756)	Prec@1 62.500 (62.500)	Prec@5 85.938 (85.938)
 * Prec@1 62.660 Prec@5 86.250
Best accuracy: 63.11%

Epoch: [141][0/391]	Loss 0.6714 (0.6714)	Prec@1 81.250 (81.250)	Prec@5 96.875 (96.875)	LR: 4.000000000000001e-06
Epoch: [141][200/391]	Loss 0.6670 (0.5991)	Prec@1 81.250 (83.361)	Prec@5 96.094 (98.076)	LR: 4.000000000000001e-06
 * Prec@1 83.376 Prec@5 98.090
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4951 (1.4951)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.690 Prec@5 86.290
Best accuracy: 63.11%

Epoch: [142][0/391]	Loss 0.5728 (0.5728)	Prec@1 85.938 (85.938)	Prec@5 96.875 (96.875)	LR: 4.000000000000001e-06
Epoch: [142][200/391]	Loss 0.5737 (0.5884)	Prec@1 84.375 (83.761)	Prec@5 97.656 (98.220)	LR: 4.000000000000001e-06
 * Prec@1 83.434 Prec@5 98.176
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4922 (1.4922)	Prec@1 60.938 (60.938)	Prec@5 85.938 (85.938)
 * Prec@1 62.750 Prec@5 86.290
Best accuracy: 63.11%

Epoch: [143][0/391]	Loss 0.6060 (0.6060)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [143][200/391]	Loss 0.4939 (0.5977)	Prec@1 87.500 (83.477)	Prec@5 99.219 (98.146)	LR: 4.000000000000001e-06
 * Prec@1 83.494 Prec@5 98.136
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4961 (1.4961)	Prec@1 62.500 (62.500)	Prec@5 85.156 (85.156)
 * Prec@1 62.980 Prec@5 86.500
Best accuracy: 63.11%

Epoch: [144][0/391]	Loss 0.6084 (0.6084)	Prec@1 82.812 (82.812)	Prec@5 96.875 (96.875)	LR: 4.000000000000001e-06
Epoch: [144][200/391]	Loss 0.6865 (0.6050)	Prec@1 78.906 (83.240)	Prec@5 98.438 (98.107)	LR: 4.000000000000001e-06
 * Prec@1 83.478 Prec@5 98.160
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4600 (1.4600)	Prec@1 64.062 (64.062)	Prec@5 85.938 (85.938)
 * Prec@1 62.900 Prec@5 86.320
Best accuracy: 63.11%

Epoch: [145][0/391]	Loss 0.4451 (0.4451)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [145][200/391]	Loss 0.5981 (0.5981)	Prec@1 83.594 (83.166)	Prec@5 98.438 (98.006)	LR: 4.000000000000001e-06
 * Prec@1 83.410 Prec@5 98.094
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4844 (1.4844)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.920 Prec@5 86.200
Best accuracy: 63.11%

Epoch: [146][0/391]	Loss 0.5366 (0.5366)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)	LR: 4.000000000000001e-06
Epoch: [146][200/391]	Loss 0.5083 (0.5908)	Prec@1 86.719 (83.664)	Prec@5 97.656 (98.060)	LR: 4.000000000000001e-06
 * Prec@1 83.588 Prec@5 98.142
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4736 (1.4736)	Prec@1 65.625 (65.625)	Prec@5 85.938 (85.938)
 * Prec@1 62.850 Prec@5 86.370
Best accuracy: 63.11%

Epoch: [147][0/391]	Loss 0.4749 (0.4749)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [147][200/391]	Loss 0.6030 (0.5972)	Prec@1 85.938 (83.734)	Prec@5 97.656 (98.103)	LR: 4.000000000000001e-06
 * Prec@1 83.754 Prec@5 98.132
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4756 (1.4756)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.880 Prec@5 86.310
Best accuracy: 63.11%

Epoch: [148][0/391]	Loss 0.6279 (0.6279)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)	LR: 4.000000000000001e-06
Epoch: [148][200/391]	Loss 0.5879 (0.5972)	Prec@1 85.938 (83.462)	Prec@5 97.656 (98.204)	LR: 4.000000000000001e-06
 * Prec@1 83.562 Prec@5 98.190
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4609 (1.4609)	Prec@1 66.406 (66.406)	Prec@5 85.938 (85.938)
 * Prec@1 62.870 Prec@5 86.570
Best accuracy: 63.11%

Epoch: [149][0/391]	Loss 0.4773 (0.4773)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [149][200/391]	Loss 0.7529 (0.6040)	Prec@1 79.688 (83.326)	Prec@5 97.656 (98.053)	LR: 4.000000000000001e-06
 * Prec@1 83.432 Prec@5 98.086
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4795 (1.4795)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.700 Prec@5 86.150
Best accuracy: 63.11%

Epoch: [150][0/391]	Loss 0.5342 (0.5342)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)	LR: 4.000000000000001e-06
Epoch: [150][200/391]	Loss 0.4873 (0.5967)	Prec@1 84.375 (83.485)	Prec@5 100.000 (98.111)	LR: 4.000000000000001e-06
 * Prec@1 83.570 Prec@5 98.144
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4648 (1.4648)	Prec@1 64.062 (64.062)	Prec@5 85.938 (85.938)
 * Prec@1 62.990 Prec@5 86.420
Best accuracy: 63.11%

Epoch: [151][0/391]	Loss 0.6343 (0.6343)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)	LR: 4.000000000000001e-06
Epoch: [151][200/391]	Loss 0.5430 (0.6016)	Prec@1 86.719 (83.143)	Prec@5 98.438 (98.142)	LR: 4.000000000000001e-06
 * Prec@1 83.276 Prec@5 98.084
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4629 (1.4629)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 63.040 Prec@5 86.420
Best accuracy: 63.11%

Epoch: [152][0/391]	Loss 0.6240 (0.6240)	Prec@1 88.281 (88.281)	Prec@5 97.656 (97.656)	LR: 4.000000000000001e-06
Epoch: [152][200/391]	Loss 0.5747 (0.5918)	Prec@1 82.812 (83.796)	Prec@5 98.438 (98.154)	LR: 4.000000000000001e-06
 * Prec@1 83.480 Prec@5 98.082
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4990 (1.4990)	Prec@1 64.062 (64.062)	Prec@5 85.938 (85.938)
 * Prec@1 62.770 Prec@5 86.330
Best accuracy: 63.11%

Epoch: [153][0/391]	Loss 0.5869 (0.5869)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [153][200/391]	Loss 0.4832 (0.5981)	Prec@1 89.844 (83.399)	Prec@5 96.875 (98.115)	LR: 4.000000000000001e-06
 * Prec@1 83.570 Prec@5 98.152
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5146 (1.5146)	Prec@1 63.281 (63.281)	Prec@5 84.375 (84.375)
 * Prec@1 62.790 Prec@5 86.150
Best accuracy: 63.11%

Epoch: [154][0/391]	Loss 0.6416 (0.6416)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [154][200/391]	Loss 0.4873 (0.5952)	Prec@1 90.625 (83.660)	Prec@5 98.438 (98.150)	LR: 4.000000000000001e-06
 * Prec@1 83.488 Prec@5 98.154
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4912 (1.4912)	Prec@1 67.188 (67.188)	Prec@5 84.375 (84.375)
 * Prec@1 62.970 Prec@5 86.240
Best accuracy: 63.11%

Epoch: [155][0/391]	Loss 0.6753 (0.6753)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)	LR: 4.000000000000001e-06
Epoch: [155][200/391]	Loss 0.6230 (0.5938)	Prec@1 80.469 (83.427)	Prec@5 97.656 (98.193)	LR: 4.000000000000001e-06
 * Prec@1 83.628 Prec@5 98.154
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4814 (1.4814)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.770 Prec@5 86.340
Best accuracy: 63.11%

Epoch: [156][0/391]	Loss 0.5913 (0.5913)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [156][200/391]	Loss 0.6250 (0.5972)	Prec@1 85.156 (83.399)	Prec@5 96.094 (98.162)	LR: 4.000000000000001e-06
 * Prec@1 83.376 Prec@5 98.120
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4912 (1.4912)	Prec@1 63.281 (63.281)	Prec@5 86.719 (86.719)
 * Prec@1 62.890 Prec@5 86.380
Best accuracy: 63.11%

Epoch: [157][0/391]	Loss 0.6230 (0.6230)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)	LR: 4.000000000000001e-06
Epoch: [157][200/391]	Loss 0.6357 (0.5938)	Prec@1 81.250 (83.462)	Prec@5 97.656 (98.111)	LR: 4.000000000000001e-06
 * Prec@1 83.574 Prec@5 98.048
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4834 (1.4834)	Prec@1 64.844 (64.844)	Prec@5 85.156 (85.156)
 * Prec@1 62.840 Prec@5 86.320
Best accuracy: 63.11%

Epoch: [158][0/391]	Loss 0.5127 (0.5127)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)	LR: 4.000000000000001e-06
Epoch: [158][200/391]	Loss 0.7070 (0.5947)	Prec@1 78.125 (83.384)	Prec@5 96.094 (98.189)	LR: 4.000000000000001e-06
 * Prec@1 83.622 Prec@5 98.206
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4824 (1.4824)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.910 Prec@5 86.210
Best accuracy: 63.11%

Epoch: [159][0/391]	Loss 0.6812 (0.6812)	Prec@1 82.812 (82.812)	Prec@5 96.875 (96.875)	LR: 4.000000000000001e-06
Epoch: [159][200/391]	Loss 0.6016 (0.5928)	Prec@1 85.156 (83.547)	Prec@5 98.438 (98.197)	LR: 4.000000000000001e-06
 * Prec@1 83.570 Prec@5 98.158
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4805 (1.4805)	Prec@1 64.062 (64.062)	Prec@5 86.719 (86.719)
 * Prec@1 62.980 Prec@5 86.350
Best accuracy: 63.11%

Epoch: [160][0/391]	Loss 0.5376 (0.5376)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)	LR: 4.000000000000001e-06
Epoch: [160][200/391]	Loss 0.5142 (0.5859)	Prec@1 85.938 (84.087)	Prec@5 99.219 (98.130)	LR: 4.000000000000001e-06
 * Prec@1 83.770 Prec@5 98.146
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4844 (1.4844)	Prec@1 64.062 (64.062)	Prec@5 85.938 (85.938)
 * Prec@1 62.820 Prec@5 86.460
Best accuracy: 63.11%

Epoch: [161][0/391]	Loss 0.6484 (0.6484)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)	LR: 4.000000000000001e-06
Epoch: [161][200/391]	Loss 0.6553 (0.6040)	Prec@1 83.594 (83.139)	Prec@5 97.656 (98.111)	LR: 4.000000000000001e-06
 * Prec@1 83.514 Prec@5 98.068
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5166 (1.5166)	Prec@1 60.938 (60.938)	Prec@5 86.719 (86.719)
 * Prec@1 62.590 Prec@5 86.470
Best accuracy: 63.11%

Epoch: [162][0/391]	Loss 0.5098 (0.5098)	Prec@1 88.281 (88.281)	Prec@5 96.094 (96.094)	LR: 4.000000000000001e-06
Epoch: [162][200/391]	Loss 0.5957 (0.5991)	Prec@1 82.812 (83.263)	Prec@5 98.438 (98.053)	LR: 4.000000000000001e-06
 * Prec@1 83.446 Prec@5 98.104
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4951 (1.4951)	Prec@1 61.719 (61.719)	Prec@5 85.938 (85.938)
 * Prec@1 62.750 Prec@5 86.450
Best accuracy: 63.11%

Epoch: [163][0/391]	Loss 0.4697 (0.4697)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)	LR: 4.000000000000001e-06
Epoch: [163][200/391]	Loss 0.6235 (0.6006)	Prec@1 78.906 (83.353)	Prec@5 97.656 (98.158)	LR: 4.000000000000001e-06
 * Prec@1 83.572 Prec@5 98.202
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5117 (1.5117)	Prec@1 61.719 (61.719)	Prec@5 85.938 (85.938)
 * Prec@1 62.920 Prec@5 86.440
Best accuracy: 63.11%

Epoch: [164][0/391]	Loss 0.5117 (0.5117)	Prec@1 87.500 (87.500)	Prec@5 97.656 (97.656)	LR: 4.000000000000001e-06
Epoch: [164][200/391]	Loss 0.5581 (0.5918)	Prec@1 85.156 (83.843)	Prec@5 98.438 (98.084)	LR: 4.000000000000001e-06
 * Prec@1 83.690 Prec@5 98.092
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5000 (1.5000)	Prec@1 66.406 (66.406)	Prec@5 85.938 (85.938)
 * Prec@1 62.850 Prec@5 86.370
Best accuracy: 63.11%

Epoch: [165][0/391]	Loss 0.6113 (0.6113)	Prec@1 84.375 (84.375)	Prec@5 97.656 (97.656)	LR: 4.000000000000001e-06
Epoch: [165][200/391]	Loss 0.5596 (0.5957)	Prec@1 85.938 (83.364)	Prec@5 98.438 (98.189)	LR: 4.000000000000001e-06
 * Prec@1 83.478 Prec@5 98.104
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4863 (1.4863)	Prec@1 65.625 (65.625)	Prec@5 85.156 (85.156)
 * Prec@1 62.800 Prec@5 86.420
Best accuracy: 63.11%

Epoch: [166][0/391]	Loss 0.5513 (0.5513)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [166][200/391]	Loss 0.5693 (0.5947)	Prec@1 85.156 (83.380)	Prec@5 99.219 (98.045)	LR: 4.000000000000001e-06
 * Prec@1 83.408 Prec@5 98.092
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4746 (1.4746)	Prec@1 64.844 (64.844)	Prec@5 85.156 (85.156)
 * Prec@1 62.780 Prec@5 86.290
Best accuracy: 63.11%

Epoch: [167][0/391]	Loss 0.5522 (0.5522)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)	LR: 4.000000000000001e-06
Epoch: [167][200/391]	Loss 0.4756 (0.5952)	Prec@1 87.500 (83.368)	Prec@5 98.438 (98.154)	LR: 4.000000000000001e-06
 * Prec@1 83.448 Prec@5 98.150
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4668 (1.4668)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.790 Prec@5 86.200
Best accuracy: 63.11%

Epoch: [168][0/391]	Loss 0.6738 (0.6738)	Prec@1 81.250 (81.250)	Prec@5 97.656 (97.656)	LR: 4.000000000000001e-06
Epoch: [168][200/391]	Loss 0.5083 (0.5996)	Prec@1 86.719 (83.271)	Prec@5 98.438 (98.142)	LR: 4.000000000000001e-06
 * Prec@1 83.438 Prec@5 98.140
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4971 (1.4971)	Prec@1 65.625 (65.625)	Prec@5 85.938 (85.938)
 * Prec@1 62.870 Prec@5 86.300
Best accuracy: 63.11%

Epoch: [169][0/391]	Loss 0.5869 (0.5869)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [169][200/391]	Loss 0.6948 (0.5977)	Prec@1 79.688 (83.259)	Prec@5 98.438 (98.235)	LR: 4.000000000000001e-06
 * Prec@1 83.342 Prec@5 98.198
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4941 (1.4941)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.660 Prec@5 86.330
Best accuracy: 63.11%

Epoch: [170][0/391]	Loss 0.7134 (0.7134)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)	LR: 4.000000000000001e-06
Epoch: [170][200/391]	Loss 0.4771 (0.6001)	Prec@1 87.500 (83.170)	Prec@5 98.438 (98.150)	LR: 4.000000000000001e-06
 * Prec@1 83.404 Prec@5 98.120
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5049 (1.5049)	Prec@1 60.938 (60.938)	Prec@5 84.375 (84.375)
 * Prec@1 62.980 Prec@5 86.350
Best accuracy: 63.11%

Epoch: [171][0/391]	Loss 0.6919 (0.6919)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)	LR: 4.000000000000001e-06
Epoch: [171][200/391]	Loss 0.5771 (0.5962)	Prec@1 82.812 (83.458)	Prec@5 97.656 (98.134)	LR: 4.000000000000001e-06
 * Prec@1 83.406 Prec@5 98.192
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4883 (1.4883)	Prec@1 64.844 (64.844)	Prec@5 85.938 (85.938)
 * Prec@1 62.790 Prec@5 86.530
Best accuracy: 63.11%

Epoch: [172][0/391]	Loss 0.5981 (0.5981)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)	LR: 4.000000000000001e-06
Epoch: [172][200/391]	Loss 0.6758 (0.5928)	Prec@1 80.469 (83.535)	Prec@5 96.094 (98.053)	LR: 4.000000000000001e-06
 * Prec@1 83.464 Prec@5 98.064
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5000 (1.5000)	Prec@1 62.500 (62.500)	Prec@5 85.938 (85.938)
 * Prec@1 62.740 Prec@5 86.270
Best accuracy: 63.11%

Epoch: [173][0/391]	Loss 0.4207 (0.4207)	Prec@1 92.188 (92.188)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [173][200/391]	Loss 0.5410 (0.5972)	Prec@1 85.156 (83.314)	Prec@5 99.219 (97.998)	LR: 4.000000000000001e-06
 * Prec@1 83.544 Prec@5 98.130
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4922 (1.4922)	Prec@1 63.281 (63.281)	Prec@5 84.375 (84.375)
 * Prec@1 62.820 Prec@5 86.420
Best accuracy: 63.11%

Epoch: [174][0/391]	Loss 0.6021 (0.6021)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)	LR: 4.000000000000001e-06
Epoch: [174][200/391]	Loss 0.6260 (0.5923)	Prec@1 82.031 (83.411)	Prec@5 98.438 (98.099)	LR: 4.000000000000001e-06
 * Prec@1 83.500 Prec@5 98.166
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5020 (1.5020)	Prec@1 64.062 (64.062)	Prec@5 84.375 (84.375)
 * Prec@1 62.700 Prec@5 86.330
Best accuracy: 63.11%

Epoch: [175][0/391]	Loss 0.6533 (0.6533)	Prec@1 82.812 (82.812)	Prec@5 97.656 (97.656)	LR: 4.000000000000001e-06
Epoch: [175][200/391]	Loss 0.4465 (0.6016)	Prec@1 88.281 (83.528)	Prec@5 98.438 (98.029)	LR: 4.000000000000001e-06
 * Prec@1 83.622 Prec@5 98.070
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4707 (1.4707)	Prec@1 61.719 (61.719)	Prec@5 85.938 (85.938)
 * Prec@1 62.730 Prec@5 86.270
Best accuracy: 63.11%

Epoch: [176][0/391]	Loss 0.6953 (0.6953)	Prec@1 84.375 (84.375)	Prec@5 97.656 (97.656)	LR: 4.000000000000001e-06
Epoch: [176][200/391]	Loss 0.6650 (0.5972)	Prec@1 77.344 (83.446)	Prec@5 97.656 (98.197)	LR: 4.000000000000001e-06
 * Prec@1 83.454 Prec@5 98.180
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4912 (1.4912)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.800 Prec@5 86.200
Best accuracy: 63.11%

Epoch: [177][0/391]	Loss 0.5508 (0.5508)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [177][200/391]	Loss 0.6230 (0.5957)	Prec@1 84.375 (83.714)	Prec@5 96.875 (98.119)	LR: 4.000000000000001e-06
 * Prec@1 83.654 Prec@5 98.118
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4775 (1.4775)	Prec@1 63.281 (63.281)	Prec@5 84.375 (84.375)
 * Prec@1 63.110 Prec@5 86.320
Best accuracy: 63.11%

Epoch: [178][0/391]	Loss 0.5718 (0.5718)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [178][200/391]	Loss 0.5503 (0.5894)	Prec@1 85.938 (83.738)	Prec@5 100.000 (98.294)	LR: 4.000000000000001e-06
 * Prec@1 83.740 Prec@5 98.272
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4736 (1.4736)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.870 Prec@5 86.300
Best accuracy: 63.11%

Epoch: [179][0/391]	Loss 0.5483 (0.5483)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)	LR: 4.000000000000001e-06
Epoch: [179][200/391]	Loss 0.7705 (0.6035)	Prec@1 75.000 (83.248)	Prec@5 97.656 (97.998)	LR: 4.000000000000001e-06
 * Prec@1 83.436 Prec@5 98.084
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4824 (1.4824)	Prec@1 61.719 (61.719)	Prec@5 85.156 (85.156)
 * Prec@1 62.610 Prec@5 86.310
Best accuracy: 63.11%

Epoch: [180][0/391]	Loss 0.4458 (0.4458)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)	LR: 4.000000000000001e-06
Epoch: [180][200/391]	Loss 0.5845 (0.5957)	Prec@1 83.594 (83.489)	Prec@5 98.438 (98.150)	LR: 4.000000000000001e-06
 * Prec@1 83.472 Prec@5 98.198
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5010 (1.5010)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.750 Prec@5 86.370
Best accuracy: 63.11%

Epoch: [181][0/391]	Loss 0.6323 (0.6323)	Prec@1 82.812 (82.812)	Prec@5 96.875 (96.875)	LR: 4.000000000000001e-06
Epoch: [181][200/391]	Loss 0.7363 (0.5918)	Prec@1 78.125 (83.687)	Prec@5 96.875 (98.251)	LR: 4.000000000000001e-06
 * Prec@1 83.606 Prec@5 98.134
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4785 (1.4785)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.850 Prec@5 86.290
Best accuracy: 63.11%

Epoch: [182][0/391]	Loss 0.6958 (0.6958)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)	LR: 4.000000000000001e-06
Epoch: [182][200/391]	Loss 0.6748 (0.5913)	Prec@1 79.688 (83.543)	Prec@5 96.094 (98.189)	LR: 4.000000000000001e-06
 * Prec@1 83.588 Prec@5 98.154
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4678 (1.4678)	Prec@1 64.062 (64.062)	Prec@5 85.938 (85.938)
 * Prec@1 63.010 Prec@5 86.450
Best accuracy: 63.11%

Epoch: [183][0/391]	Loss 0.6909 (0.6909)	Prec@1 82.812 (82.812)	Prec@5 96.875 (96.875)	LR: 4.000000000000001e-06
Epoch: [183][200/391]	Loss 0.4988 (0.5986)	Prec@1 87.500 (83.368)	Prec@5 99.219 (98.119)	LR: 4.000000000000001e-06
 * Prec@1 83.430 Prec@5 98.104
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4590 (1.4590)	Prec@1 63.281 (63.281)	Prec@5 84.375 (84.375)
 * Prec@1 62.710 Prec@5 86.250
Best accuracy: 63.11%

Epoch: [184][0/391]	Loss 0.6572 (0.6572)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [184][200/391]	Loss 0.6172 (0.5903)	Prec@1 82.031 (83.738)	Prec@5 96.875 (98.251)	LR: 4.000000000000001e-06
 * Prec@1 83.596 Prec@5 98.182
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4912 (1.4912)	Prec@1 64.062 (64.062)	Prec@5 85.938 (85.938)
 * Prec@1 62.740 Prec@5 86.480
Best accuracy: 63.11%

Epoch: [185][0/391]	Loss 0.6270 (0.6270)	Prec@1 84.375 (84.375)	Prec@5 97.656 (97.656)	LR: 4.000000000000001e-06
Epoch: [185][200/391]	Loss 0.6396 (0.5874)	Prec@1 82.031 (83.691)	Prec@5 97.656 (98.235)	LR: 4.000000000000001e-06
 * Prec@1 83.522 Prec@5 98.150
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4541 (1.4541)	Prec@1 65.625 (65.625)	Prec@5 85.938 (85.938)
 * Prec@1 63.040 Prec@5 86.320
Best accuracy: 63.11%

Epoch: [186][0/391]	Loss 0.7070 (0.7070)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)	LR: 4.000000000000001e-06
Epoch: [186][200/391]	Loss 0.6011 (0.6060)	Prec@1 79.688 (83.205)	Prec@5 98.438 (98.064)	LR: 4.000000000000001e-06
 * Prec@1 83.588 Prec@5 98.130
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4775 (1.4775)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.570 Prec@5 86.390
Best accuracy: 63.11%

Epoch: [187][0/391]	Loss 0.6201 (0.6201)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [187][200/391]	Loss 0.4617 (0.6016)	Prec@1 89.844 (83.190)	Prec@5 98.438 (98.068)	LR: 4.000000000000001e-06
 * Prec@1 83.402 Prec@5 98.176
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4883 (1.4883)	Prec@1 65.625 (65.625)	Prec@5 85.156 (85.156)
 * Prec@1 62.710 Prec@5 86.280
Best accuracy: 63.11%

Epoch: [188][0/391]	Loss 0.6567 (0.6567)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [188][200/391]	Loss 0.5977 (0.6016)	Prec@1 85.156 (83.384)	Prec@5 97.656 (98.060)	LR: 4.000000000000001e-06
 * Prec@1 83.544 Prec@5 98.118
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4805 (1.4805)	Prec@1 65.625 (65.625)	Prec@5 85.938 (85.938)
 * Prec@1 62.720 Prec@5 86.340
Best accuracy: 63.11%

Epoch: [189][0/391]	Loss 0.5928 (0.5928)	Prec@1 85.938 (85.938)	Prec@5 96.875 (96.875)	LR: 4.000000000000001e-06
Epoch: [189][200/391]	Loss 0.5020 (0.5850)	Prec@1 85.938 (83.695)	Prec@5 99.219 (98.165)	LR: 4.000000000000001e-06
 * Prec@1 83.256 Prec@5 98.114
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5049 (1.5049)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.680 Prec@5 86.180
Best accuracy: 63.11%

Epoch: [190][0/391]	Loss 0.4761 (0.4761)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)	LR: 4.000000000000001e-06
Epoch: [190][200/391]	Loss 0.5386 (0.5977)	Prec@1 82.812 (83.551)	Prec@5 99.219 (98.103)	LR: 4.000000000000001e-06
 * Prec@1 83.624 Prec@5 98.112
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4697 (1.4697)	Prec@1 64.062 (64.062)	Prec@5 84.375 (84.375)
 * Prec@1 62.630 Prec@5 86.200
Best accuracy: 63.11%

Epoch: [191][0/391]	Loss 0.6323 (0.6323)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [191][200/391]	Loss 0.4746 (0.5962)	Prec@1 89.844 (83.477)	Prec@5 99.219 (98.185)	LR: 4.000000000000001e-06
 * Prec@1 83.440 Prec@5 98.190
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4912 (1.4912)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.950 Prec@5 86.550
Best accuracy: 63.11%

Epoch: [192][0/391]	Loss 0.5762 (0.5762)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)	LR: 4.000000000000001e-06
Epoch: [192][200/391]	Loss 0.6289 (0.5986)	Prec@1 84.375 (83.551)	Prec@5 97.656 (98.150)	LR: 4.000000000000001e-06
 * Prec@1 83.374 Prec@5 98.186
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4893 (1.4893)	Prec@1 60.938 (60.938)	Prec@5 85.938 (85.938)
 * Prec@1 62.800 Prec@5 86.430
Best accuracy: 63.11%

Epoch: [193][0/391]	Loss 0.6392 (0.6392)	Prec@1 81.250 (81.250)	Prec@5 96.875 (96.875)	LR: 4.000000000000001e-06
Epoch: [193][200/391]	Loss 0.5898 (0.5972)	Prec@1 85.938 (83.465)	Prec@5 99.219 (98.006)	LR: 4.000000000000001e-06
 * Prec@1 83.388 Prec@5 98.136
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4980 (1.4980)	Prec@1 63.281 (63.281)	Prec@5 83.594 (83.594)
 * Prec@1 62.820 Prec@5 86.400
Best accuracy: 63.11%

Epoch: [194][0/391]	Loss 0.5190 (0.5190)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [194][200/391]	Loss 0.6299 (0.5962)	Prec@1 82.031 (83.166)	Prec@5 96.875 (98.142)	LR: 4.000000000000001e-06
 * Prec@1 83.336 Prec@5 98.144
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4795 (1.4795)	Prec@1 64.844 (64.844)	Prec@5 84.375 (84.375)
 * Prec@1 62.740 Prec@5 86.320
Best accuracy: 63.11%

Epoch: [195][0/391]	Loss 0.4719 (0.4719)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)	LR: 4.000000000000001e-06
Epoch: [195][200/391]	Loss 0.6147 (0.5938)	Prec@1 82.031 (83.726)	Prec@5 98.438 (98.290)	LR: 4.000000000000001e-06
 * Prec@1 83.654 Prec@5 98.202
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4863 (1.4863)	Prec@1 64.062 (64.062)	Prec@5 83.594 (83.594)
 * Prec@1 62.990 Prec@5 86.510
Best accuracy: 63.11%

Epoch: [196][0/391]	Loss 0.7852 (0.7852)	Prec@1 76.562 (76.562)	Prec@5 95.312 (95.312)	LR: 4.000000000000001e-06
Epoch: [196][200/391]	Loss 0.5269 (0.5991)	Prec@1 88.281 (83.337)	Prec@5 98.438 (98.103)	LR: 4.000000000000001e-06
 * Prec@1 83.534 Prec@5 98.136
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5039 (1.5039)	Prec@1 62.500 (62.500)	Prec@5 85.156 (85.156)
 * Prec@1 62.670 Prec@5 86.350
Best accuracy: 63.11%

Epoch: [197][0/391]	Loss 0.6338 (0.6338)	Prec@1 82.812 (82.812)	Prec@5 96.094 (96.094)	LR: 4.000000000000001e-06
Epoch: [197][200/391]	Loss 0.4932 (0.5938)	Prec@1 88.281 (83.477)	Prec@5 100.000 (98.177)	LR: 4.000000000000001e-06
 * Prec@1 83.480 Prec@5 98.146
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4814 (1.4814)	Prec@1 64.062 (64.062)	Prec@5 85.938 (85.938)
 * Prec@1 62.830 Prec@5 86.390
Best accuracy: 63.11%

Epoch: [198][0/391]	Loss 0.7017 (0.7017)	Prec@1 78.125 (78.125)	Prec@5 96.094 (96.094)	LR: 4.000000000000001e-06
Epoch: [198][200/391]	Loss 0.5640 (0.5923)	Prec@1 82.812 (83.392)	Prec@5 99.219 (98.231)	LR: 4.000000000000001e-06
 * Prec@1 83.414 Prec@5 98.218
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5088 (1.5088)	Prec@1 62.500 (62.500)	Prec@5 85.156 (85.156)
 * Prec@1 62.790 Prec@5 86.330
Best accuracy: 63.11%

Epoch: [199][0/391]	Loss 0.6396 (0.6396)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)	LR: 4.000000000000001e-06
Epoch: [199][200/391]	Loss 0.5161 (0.5898)	Prec@1 84.375 (83.535)	Prec@5 99.219 (98.084)	LR: 4.000000000000001e-06
 * Prec@1 83.516 Prec@5 98.128
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4854 (1.4854)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.810 Prec@5 86.380
Best accuracy: 63.11%

Epoch: [200][0/391]	Loss 0.4832 (0.4832)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)	LR: 8.000000000000002e-07
Epoch: [200][200/391]	Loss 0.6333 (0.5894)	Prec@1 84.375 (83.905)	Prec@5 96.094 (98.247)	LR: 8.000000000000002e-07
 * Prec@1 83.646 Prec@5 98.138
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4775 (1.4775)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 63.050 Prec@5 86.340
Best accuracy: 63.11%

Epoch: [201][0/391]	Loss 0.5747 (0.5747)	Prec@1 85.156 (85.156)	Prec@5 97.656 (97.656)	LR: 8.000000000000002e-07
Epoch: [201][200/391]	Loss 0.4878 (0.5991)	Prec@1 88.281 (83.326)	Prec@5 99.219 (98.165)	LR: 8.000000000000002e-07
 * Prec@1 83.346 Prec@5 98.172
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4883 (1.4883)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.960 Prec@5 86.390
Best accuracy: 63.11%

Epoch: [202][0/391]	Loss 0.5991 (0.5991)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)	LR: 8.000000000000002e-07
Epoch: [202][200/391]	Loss 0.5947 (0.5962)	Prec@1 79.688 (83.582)	Prec@5 98.438 (98.150)	LR: 8.000000000000002e-07
 * Prec@1 83.618 Prec@5 98.116
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4961 (1.4961)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.740 Prec@5 86.430
Best accuracy: 63.11%

Epoch: [203][0/391]	Loss 0.5767 (0.5767)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)	LR: 8.000000000000002e-07
Epoch: [203][200/391]	Loss 0.5010 (0.5957)	Prec@1 86.719 (83.368)	Prec@5 100.000 (98.224)	LR: 8.000000000000002e-07
 * Prec@1 83.570 Prec@5 98.180
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5020 (1.5020)	Prec@1 60.156 (60.156)	Prec@5 83.594 (83.594)
 * Prec@1 62.870 Prec@5 86.280
Best accuracy: 63.11%

Epoch: [204][0/391]	Loss 0.5938 (0.5938)	Prec@1 82.812 (82.812)	Prec@5 96.875 (96.875)	LR: 8.000000000000002e-07
Epoch: [204][200/391]	Loss 0.5898 (0.6001)	Prec@1 85.938 (83.500)	Prec@5 99.219 (98.025)	LR: 8.000000000000002e-07
 * Prec@1 83.536 Prec@5 98.140
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4951 (1.4951)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.590 Prec@5 86.330
Best accuracy: 63.11%

Epoch: [205][0/391]	Loss 0.6089 (0.6089)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)	LR: 8.000000000000002e-07
Epoch: [205][200/391]	Loss 0.5757 (0.5835)	Prec@1 85.156 (83.889)	Prec@5 99.219 (98.204)	LR: 8.000000000000002e-07
 * Prec@1 83.736 Prec@5 98.220
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4961 (1.4961)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.710 Prec@5 86.350
Best accuracy: 63.11%

Epoch: [206][0/391]	Loss 0.7422 (0.7422)	Prec@1 78.906 (78.906)	Prec@5 95.312 (95.312)	LR: 8.000000000000002e-07
Epoch: [206][200/391]	Loss 0.4553 (0.5928)	Prec@1 92.188 (83.532)	Prec@5 99.219 (98.181)	LR: 8.000000000000002e-07
 * Prec@1 83.568 Prec@5 98.174
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5195 (1.5195)	Prec@1 62.500 (62.500)	Prec@5 85.156 (85.156)
 * Prec@1 62.900 Prec@5 86.290
Best accuracy: 63.11%

Epoch: [207][0/391]	Loss 0.6426 (0.6426)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)	LR: 8.000000000000002e-07
Epoch: [207][200/391]	Loss 0.5610 (0.5918)	Prec@1 86.719 (83.314)	Prec@5 97.656 (98.146)	LR: 8.000000000000002e-07
 * Prec@1 83.536 Prec@5 98.112
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4814 (1.4814)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.970 Prec@5 86.310
Best accuracy: 63.11%

Epoch: [208][0/391]	Loss 0.6479 (0.6479)	Prec@1 82.031 (82.031)	Prec@5 96.094 (96.094)	LR: 8.000000000000002e-07
Epoch: [208][200/391]	Loss 0.5020 (0.5918)	Prec@1 87.500 (83.644)	Prec@5 99.219 (98.138)	LR: 8.000000000000002e-07
 * Prec@1 83.650 Prec@5 98.148
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5029 (1.5029)	Prec@1 64.844 (64.844)	Prec@5 86.719 (86.719)
 * Prec@1 62.950 Prec@5 86.350
Best accuracy: 63.11%

Epoch: [209][0/391]	Loss 0.4514 (0.4514)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)	LR: 8.000000000000002e-07
Epoch: [209][200/391]	Loss 0.6641 (0.5981)	Prec@1 82.031 (83.524)	Prec@5 95.312 (98.057)	LR: 8.000000000000002e-07
 * Prec@1 83.426 Prec@5 98.096
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4727 (1.4727)	Prec@1 64.062 (64.062)	Prec@5 85.938 (85.938)
 * Prec@1 62.760 Prec@5 86.340
Best accuracy: 63.11%

Epoch: [210][0/391]	Loss 0.5605 (0.5605)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)	LR: 8.000000000000002e-07
Epoch: [210][200/391]	Loss 0.8242 (0.5918)	Prec@1 71.875 (83.629)	Prec@5 95.312 (98.169)	LR: 8.000000000000002e-07
 * Prec@1 83.578 Prec@5 98.202
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4980 (1.4980)	Prec@1 64.062 (64.062)	Prec@5 84.375 (84.375)
 * Prec@1 62.880 Prec@5 86.340
Best accuracy: 63.11%

Epoch: [211][0/391]	Loss 0.5527 (0.5527)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)	LR: 8.000000000000002e-07
Epoch: [211][200/391]	Loss 0.6099 (0.5967)	Prec@1 82.031 (83.388)	Prec@5 97.656 (98.072)	LR: 8.000000000000002e-07
 * Prec@1 83.504 Prec@5 98.094
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4600 (1.4600)	Prec@1 65.625 (65.625)	Prec@5 85.938 (85.938)
 * Prec@1 62.870 Prec@5 86.050
Best accuracy: 63.11%

Epoch: [212][0/391]	Loss 0.6260 (0.6260)	Prec@1 82.812 (82.812)	Prec@5 97.656 (97.656)	LR: 8.000000000000002e-07
Epoch: [212][200/391]	Loss 0.5962 (0.6074)	Prec@1 82.031 (83.104)	Prec@5 98.438 (98.045)	LR: 8.000000000000002e-07
 * Prec@1 83.244 Prec@5 98.104
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4941 (1.4941)	Prec@1 62.500 (62.500)	Prec@5 85.938 (85.938)
 * Prec@1 62.840 Prec@5 86.490
Best accuracy: 63.11%

Epoch: [213][0/391]	Loss 0.6113 (0.6113)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)	LR: 8.000000000000002e-07
Epoch: [213][200/391]	Loss 0.5552 (0.5981)	Prec@1 83.594 (83.454)	Prec@5 99.219 (98.224)	LR: 8.000000000000002e-07
 * Prec@1 83.502 Prec@5 98.226
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4961 (1.4961)	Prec@1 61.719 (61.719)	Prec@5 86.719 (86.719)
 * Prec@1 62.760 Prec@5 86.310
Best accuracy: 63.11%

Epoch: [214][0/391]	Loss 0.5859 (0.5859)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)	LR: 8.000000000000002e-07
Epoch: [214][200/391]	Loss 0.5488 (0.5840)	Prec@1 84.375 (84.021)	Prec@5 98.438 (98.243)	LR: 8.000000000000002e-07
 * Prec@1 83.916 Prec@5 98.112
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4971 (1.4971)	Prec@1 63.281 (63.281)	Prec@5 86.719 (86.719)
 * Prec@1 62.780 Prec@5 86.530
Best accuracy: 63.11%

Epoch: [215][0/391]	Loss 0.5034 (0.5034)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)	LR: 8.000000000000002e-07
Epoch: [215][200/391]	Loss 0.7129 (0.6006)	Prec@1 79.688 (83.259)	Prec@5 96.094 (98.064)	LR: 8.000000000000002e-07
 * Prec@1 83.460 Prec@5 98.048
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4854 (1.4854)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.930 Prec@5 86.320
Best accuracy: 63.11%

Epoch: [216][0/391]	Loss 0.5342 (0.5342)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)	LR: 8.000000000000002e-07
Epoch: [216][200/391]	Loss 0.6372 (0.6025)	Prec@1 85.938 (83.252)	Prec@5 97.656 (98.022)	LR: 8.000000000000002e-07
 * Prec@1 83.506 Prec@5 98.056
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5098 (1.5098)	Prec@1 64.062 (64.062)	Prec@5 83.594 (83.594)
 * Prec@1 62.790 Prec@5 86.230
Best accuracy: 63.11%

Epoch: [217][0/391]	Loss 0.4985 (0.4985)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)	LR: 8.000000000000002e-07
Epoch: [217][200/391]	Loss 0.5806 (0.5898)	Prec@1 86.719 (83.671)	Prec@5 99.219 (98.142)	LR: 8.000000000000002e-07
 * Prec@1 83.708 Prec@5 98.214
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4990 (1.4990)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.760 Prec@5 86.300
Best accuracy: 63.11%

Epoch: [218][0/391]	Loss 0.6216 (0.6216)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)	LR: 8.000000000000002e-07
Epoch: [218][200/391]	Loss 0.5713 (0.5928)	Prec@1 82.812 (83.625)	Prec@5 99.219 (98.150)	LR: 8.000000000000002e-07
 * Prec@1 83.544 Prec@5 98.136
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4893 (1.4893)	Prec@1 60.156 (60.156)	Prec@5 85.156 (85.156)
 * Prec@1 62.720 Prec@5 86.310
Best accuracy: 63.11%

Epoch: [219][0/391]	Loss 0.5942 (0.5942)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)	LR: 8.000000000000002e-07
Epoch: [219][200/391]	Loss 0.6367 (0.5957)	Prec@1 80.469 (83.030)	Prec@5 98.438 (98.270)	LR: 8.000000000000002e-07
 * Prec@1 83.136 Prec@5 98.184
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4980 (1.4980)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.640 Prec@5 86.140
Best accuracy: 63.11%

Epoch: [220][0/391]	Loss 0.6841 (0.6841)	Prec@1 79.688 (79.688)	Prec@5 96.094 (96.094)	LR: 8.000000000000002e-07
Epoch: [220][200/391]	Loss 0.5942 (0.5957)	Prec@1 83.594 (83.570)	Prec@5 98.438 (98.084)	LR: 8.000000000000002e-07
 * Prec@1 83.582 Prec@5 98.090
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5156 (1.5156)	Prec@1 61.719 (61.719)	Prec@5 84.375 (84.375)
 * Prec@1 62.780 Prec@5 86.180
Best accuracy: 63.11%

Epoch: [221][0/391]	Loss 0.4609 (0.4609)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)	LR: 8.000000000000002e-07
Epoch: [221][200/391]	Loss 0.5137 (0.5884)	Prec@1 86.719 (83.679)	Prec@5 100.000 (98.395)	LR: 8.000000000000002e-07
 * Prec@1 83.492 Prec@5 98.210
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4941 (1.4941)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.640 Prec@5 86.270
Best accuracy: 63.11%

Epoch: [222][0/391]	Loss 0.6890 (0.6890)	Prec@1 82.031 (82.031)	Prec@5 95.312 (95.312)	LR: 8.000000000000002e-07
Epoch: [222][200/391]	Loss 0.6338 (0.5981)	Prec@1 78.906 (83.326)	Prec@5 96.875 (98.099)	LR: 8.000000000000002e-07
 * Prec@1 83.282 Prec@5 98.150
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5098 (1.5098)	Prec@1 61.719 (61.719)	Prec@5 84.375 (84.375)
 * Prec@1 62.440 Prec@5 86.470
Best accuracy: 63.11%

Epoch: [223][0/391]	Loss 0.4944 (0.4944)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)	LR: 8.000000000000002e-07
Epoch: [223][200/391]	Loss 0.6055 (0.5918)	Prec@1 83.594 (83.598)	Prec@5 97.656 (98.068)	LR: 8.000000000000002e-07
 * Prec@1 83.540 Prec@5 98.076
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4580 (1.4580)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.810 Prec@5 86.330
Best accuracy: 63.11%

Epoch: [224][0/391]	Loss 0.6362 (0.6362)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)	LR: 8.000000000000002e-07
Epoch: [224][200/391]	Loss 0.6094 (0.6050)	Prec@1 83.594 (83.337)	Prec@5 96.094 (97.932)	LR: 8.000000000000002e-07
 * Prec@1 83.592 Prec@5 98.108
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4971 (1.4971)	Prec@1 63.281 (63.281)	Prec@5 84.375 (84.375)
 * Prec@1 62.560 Prec@5 86.370
Best accuracy: 63.11%

Epoch: [225][0/391]	Loss 0.6338 (0.6338)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)	LR: 8.000000000000002e-07
Epoch: [225][200/391]	Loss 0.5376 (0.5859)	Prec@1 85.156 (83.901)	Prec@5 98.438 (98.076)	LR: 8.000000000000002e-07
 * Prec@1 83.856 Prec@5 98.104
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4707 (1.4707)	Prec@1 65.625 (65.625)	Prec@5 86.719 (86.719)
 * Prec@1 62.920 Prec@5 86.370
Best accuracy: 63.11%

Epoch: [226][0/391]	Loss 0.5796 (0.5796)	Prec@1 83.594 (83.594)	Prec@5 96.094 (96.094)	LR: 8.000000000000002e-07
Epoch: [226][200/391]	Loss 0.6885 (0.5996)	Prec@1 80.469 (83.563)	Prec@5 98.438 (98.092)	LR: 8.000000000000002e-07
 * Prec@1 83.470 Prec@5 98.138
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4766 (1.4766)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.710 Prec@5 86.290
Best accuracy: 63.11%

Epoch: [227][0/391]	Loss 0.5347 (0.5347)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)	LR: 8.000000000000002e-07
Epoch: [227][200/391]	Loss 0.7271 (0.5908)	Prec@1 75.781 (83.753)	Prec@5 96.875 (98.216)	LR: 8.000000000000002e-07
 * Prec@1 83.676 Prec@5 98.194
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4961 (1.4961)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.630 Prec@5 86.250
Best accuracy: 63.11%

Epoch: [228][0/391]	Loss 0.6294 (0.6294)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)	LR: 8.000000000000002e-07
Epoch: [228][200/391]	Loss 0.5469 (0.5903)	Prec@1 86.719 (83.574)	Prec@5 97.656 (98.123)	LR: 8.000000000000002e-07
 * Prec@1 83.636 Prec@5 98.106
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4902 (1.4902)	Prec@1 62.500 (62.500)	Prec@5 85.156 (85.156)
 * Prec@1 62.740 Prec@5 86.330
Best accuracy: 63.11%

Epoch: [229][0/391]	Loss 0.6440 (0.6440)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)	LR: 8.000000000000002e-07
Epoch: [229][200/391]	Loss 0.4338 (0.5972)	Prec@1 89.844 (83.446)	Prec@5 100.000 (98.235)	LR: 8.000000000000002e-07
 * Prec@1 83.392 Prec@5 98.184
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4922 (1.4922)	Prec@1 63.281 (63.281)	Prec@5 85.156 (85.156)
 * Prec@1 62.570 Prec@5 86.360
Best accuracy: 63.11%

Epoch: [230][0/391]	Loss 0.6172 (0.6172)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)	LR: 8.000000000000002e-07
Epoch: [230][200/391]	Loss 0.7051 (0.5928)	Prec@1 78.125 (83.454)	Prec@5 95.312 (98.185)	LR: 8.000000000000002e-07
 * Prec@1 83.620 Prec@5 98.196
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4795 (1.4795)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.810 Prec@5 86.520
Best accuracy: 63.11%

Epoch: [231][0/391]	Loss 0.6357 (0.6357)	Prec@1 81.250 (81.250)	Prec@5 97.656 (97.656)	LR: 8.000000000000002e-07
Epoch: [231][200/391]	Loss 0.5684 (0.5957)	Prec@1 85.938 (83.372)	Prec@5 98.438 (98.049)	LR: 8.000000000000002e-07
 * Prec@1 83.474 Prec@5 98.018
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5010 (1.5010)	Prec@1 64.062 (64.062)	Prec@5 86.719 (86.719)
 * Prec@1 62.950 Prec@5 86.390
Best accuracy: 63.11%

Epoch: [232][0/391]	Loss 0.5498 (0.5498)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)	LR: 8.000000000000002e-07
Epoch: [232][200/391]	Loss 0.5361 (0.5933)	Prec@1 85.156 (83.648)	Prec@5 98.438 (98.224)	LR: 8.000000000000002e-07
 * Prec@1 83.554 Prec@5 98.168
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4951 (1.4951)	Prec@1 61.719 (61.719)	Prec@5 85.156 (85.156)
 * Prec@1 62.870 Prec@5 86.340
Best accuracy: 63.11%

Epoch: [233][0/391]	Loss 0.6499 (0.6499)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)	LR: 8.000000000000002e-07
Epoch: [233][200/391]	Loss 0.5122 (0.5879)	Prec@1 87.500 (83.722)	Prec@5 98.438 (98.216)	LR: 8.000000000000002e-07
 * Prec@1 83.618 Prec@5 98.232
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5039 (1.5039)	Prec@1 60.938 (60.938)	Prec@5 85.938 (85.938)
 * Prec@1 62.980 Prec@5 86.310
Best accuracy: 63.11%

Epoch: [234][0/391]	Loss 0.5659 (0.5659)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)	LR: 8.000000000000002e-07
Epoch: [234][200/391]	Loss 0.5303 (0.5918)	Prec@1 83.594 (83.563)	Prec@5 99.219 (98.301)	LR: 8.000000000000002e-07
 * Prec@1 83.512 Prec@5 98.202
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4990 (1.4990)	Prec@1 64.844 (64.844)	Prec@5 85.156 (85.156)
 * Prec@1 62.820 Prec@5 86.340
Best accuracy: 63.11%

Epoch: [235][0/391]	Loss 0.6108 (0.6108)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)	LR: 8.000000000000002e-07
Epoch: [235][200/391]	Loss 0.7461 (0.5972)	Prec@1 77.344 (83.306)	Prec@5 95.312 (98.243)	LR: 8.000000000000002e-07
 * Prec@1 83.358 Prec@5 98.232
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4834 (1.4834)	Prec@1 64.844 (64.844)	Prec@5 85.938 (85.938)
 * Prec@1 63.060 Prec@5 86.260
Best accuracy: 63.11%

Epoch: [236][0/391]	Loss 0.5537 (0.5537)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)	LR: 8.000000000000002e-07
Epoch: [236][200/391]	Loss 0.7090 (0.5938)	Prec@1 79.688 (83.434)	Prec@5 96.875 (98.224)	LR: 8.000000000000002e-07
 * Prec@1 83.348 Prec@5 98.214
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5078 (1.5078)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.700 Prec@5 86.410
Best accuracy: 63.11%

Epoch: [237][0/391]	Loss 0.5952 (0.5952)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)	LR: 8.000000000000002e-07
Epoch: [237][200/391]	Loss 0.5225 (0.6016)	Prec@1 86.719 (83.275)	Prec@5 98.438 (98.088)	LR: 8.000000000000002e-07
 * Prec@1 83.458 Prec@5 98.124
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4688 (1.4688)	Prec@1 64.844 (64.844)	Prec@5 83.594 (83.594)
 * Prec@1 63.000 Prec@5 86.320
Best accuracy: 63.11%

Epoch: [238][0/391]	Loss 0.6030 (0.6030)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)	LR: 8.000000000000002e-07
Epoch: [238][200/391]	Loss 0.6113 (0.5947)	Prec@1 84.375 (83.438)	Prec@5 98.438 (98.301)	LR: 8.000000000000002e-07
 * Prec@1 83.526 Prec@5 98.154
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4688 (1.4688)	Prec@1 64.844 (64.844)	Prec@5 85.938 (85.938)
 * Prec@1 62.980 Prec@5 86.400
Best accuracy: 63.11%

Epoch: [239][0/391]	Loss 0.5542 (0.5542)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)	LR: 8.000000000000002e-07
Epoch: [239][200/391]	Loss 0.5854 (0.5986)	Prec@1 83.594 (83.637)	Prec@5 99.219 (98.095)	LR: 8.000000000000002e-07
 * Prec@1 83.534 Prec@5 98.100
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4717 (1.4717)	Prec@1 66.406 (66.406)	Prec@5 85.938 (85.938)
 * Prec@1 62.880 Prec@5 86.340
Best accuracy: 63.11%

Epoch: [240][0/391]	Loss 0.6353 (0.6353)	Prec@1 83.594 (83.594)	Prec@5 97.656 (97.656)	LR: 8.000000000000002e-07
Epoch: [240][200/391]	Loss 0.5698 (0.5986)	Prec@1 86.719 (83.481)	Prec@5 96.875 (98.115)	LR: 8.000000000000002e-07
 * Prec@1 83.592 Prec@5 98.216
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4834 (1.4834)	Prec@1 65.625 (65.625)	Prec@5 85.156 (85.156)
 * Prec@1 62.820 Prec@5 86.350
Best accuracy: 63.11%

Epoch: [241][0/391]	Loss 0.5293 (0.5293)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)	LR: 8.000000000000002e-07
Epoch: [241][200/391]	Loss 0.6909 (0.5962)	Prec@1 80.469 (83.341)	Prec@5 98.438 (98.014)	LR: 8.000000000000002e-07
 * Prec@1 83.508 Prec@5 98.072
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5068 (1.5068)	Prec@1 64.844 (64.844)	Prec@5 83.594 (83.594)
 * Prec@1 62.590 Prec@5 86.340
Best accuracy: 63.11%

Epoch: [242][0/391]	Loss 0.5713 (0.5713)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)	LR: 8.000000000000002e-07
Epoch: [242][200/391]	Loss 0.6499 (0.5918)	Prec@1 77.344 (83.796)	Prec@5 97.656 (98.158)	LR: 8.000000000000002e-07
 * Prec@1 83.698 Prec@5 98.174
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4639 (1.4639)	Prec@1 62.500 (62.500)	Prec@5 84.375 (84.375)
 * Prec@1 62.840 Prec@5 86.270
Best accuracy: 63.11%

Epoch: [243][0/391]	Loss 0.5894 (0.5894)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)	LR: 8.000000000000002e-07
Epoch: [243][200/391]	Loss 0.6011 (0.5894)	Prec@1 84.375 (83.815)	Prec@5 98.438 (98.115)	LR: 8.000000000000002e-07
 * Prec@1 83.668 Prec@5 98.152
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4629 (1.4629)	Prec@1 64.062 (64.062)	Prec@5 85.938 (85.938)
 * Prec@1 62.630 Prec@5 86.190
Best accuracy: 63.11%

Epoch: [244][0/391]	Loss 0.4719 (0.4719)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)	LR: 8.000000000000002e-07
Epoch: [244][200/391]	Loss 0.6553 (0.6021)	Prec@1 81.250 (83.306)	Prec@5 98.438 (98.072)	LR: 8.000000000000002e-07
 * Prec@1 83.426 Prec@5 98.090
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4893 (1.4893)	Prec@1 62.500 (62.500)	Prec@5 85.938 (85.938)
 * Prec@1 62.780 Prec@5 86.400
Best accuracy: 63.11%

Epoch: [245][0/391]	Loss 0.5762 (0.5762)	Prec@1 84.375 (84.375)	Prec@5 97.656 (97.656)	LR: 8.000000000000002e-07
Epoch: [245][200/391]	Loss 0.6406 (0.5918)	Prec@1 77.344 (83.504)	Prec@5 99.219 (98.150)	LR: 8.000000000000002e-07
 * Prec@1 83.478 Prec@5 98.168
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4795 (1.4795)	Prec@1 65.625 (65.625)	Prec@5 85.156 (85.156)
 * Prec@1 62.640 Prec@5 86.340
Best accuracy: 63.11%

Epoch: [246][0/391]	Loss 0.5693 (0.5693)	Prec@1 82.812 (82.812)	Prec@5 96.875 (96.875)	LR: 8.000000000000002e-07
Epoch: [246][200/391]	Loss 0.5542 (0.5981)	Prec@1 84.375 (83.559)	Prec@5 98.438 (98.103)	LR: 8.000000000000002e-07
 * Prec@1 83.590 Prec@5 98.130
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5068 (1.5068)	Prec@1 64.062 (64.062)	Prec@5 85.156 (85.156)
 * Prec@1 62.580 Prec@5 86.350
Best accuracy: 63.11%

Epoch: [247][0/391]	Loss 0.4434 (0.4434)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)	LR: 8.000000000000002e-07
Epoch: [247][200/391]	Loss 0.5679 (0.5967)	Prec@1 84.375 (83.368)	Prec@5 97.656 (98.158)	LR: 8.000000000000002e-07
 * Prec@1 83.398 Prec@5 98.122
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5146 (1.5146)	Prec@1 63.281 (63.281)	Prec@5 84.375 (84.375)
 * Prec@1 62.620 Prec@5 86.230
Best accuracy: 63.11%

Epoch: [248][0/391]	Loss 0.5811 (0.5811)	Prec@1 87.500 (87.500)	Prec@5 97.656 (97.656)	LR: 8.000000000000002e-07
Epoch: [248][200/391]	Loss 0.7368 (0.5894)	Prec@1 78.906 (83.637)	Prec@5 96.875 (98.317)	LR: 8.000000000000002e-07
 * Prec@1 83.444 Prec@5 98.146
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.4541 (1.4541)	Prec@1 63.281 (63.281)	Prec@5 85.938 (85.938)
 * Prec@1 62.960 Prec@5 86.330
Best accuracy: 63.11%

Epoch: [249][0/391]	Loss 0.6567 (0.6567)	Prec@1 80.469 (80.469)	Prec@5 94.531 (94.531)	LR: 8.000000000000002e-07
Epoch: [249][200/391]	Loss 0.6982 (0.5981)	Prec@1 78.125 (83.403)	Prec@5 97.656 (98.138)	LR: 8.000000000000002e-07
 * Prec@1 83.568 Prec@5 98.088
Best Train Accuracy: 85.39%

Test: [0/79]	Loss 1.5127 (1.5127)	Prec@1 62.500 (62.500)	Prec@5 85.938 (85.938)
 * Prec@1 62.690 Prec@5 86.400
Best accuracy: 63.11%

