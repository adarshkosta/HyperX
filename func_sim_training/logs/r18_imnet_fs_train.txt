WARNING: crossbar sizes with different row annd column dimension not supported.

      ==> Arguments:
          dataset: imnet
          model: resnet18
          workers: 4
          epochs: 30
          start_epoch: 0
          train_batch_size: 320
          test_batch_size: 320
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          mvm: True
          nideal: None
          tag: i8b6f_w8b6f
          milestones: [5, 10, 15, 20]
          gamma: 0.2
          input_size: None
          print_freq: 100
          resume: 
          evaluate: False
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          half: False
          savedir: ../pretrained_models/ideal/
          save_every: 10
          gpus: 0,1,2,3

      ==> Functional simulator configurations:
          weight_bits=8
          weight_bit_frac=6
          input_bits=8
          input_bit_frac=6
          xbar_row_size=64
          xbar_col_size=64
          tile_row=2
          tile_col=2
          bit_stream=1
          bit_slice=2
          adc_bit=14
          acm_bits=32
          acm_bit_frac=24
          mvm=True
          non-ideality=False
          
xbmodel=NN_model(
  (fc1): Linear(in_features=4160, out_features=500, bias=True)
  (relu1): ReLU(inplace=True)
  (do2): Dropout(p=0.5, inplace=False)
  (fc3): Linear(in_features=500, out_features=64, bias=True)
)
          
xbmodel_weight_path=../xb_models/XB_64_stream1slice207dropout50epochs.pth.tar
          inmax_test=1.2
          inmin_test=0.857


DEVICE: cuda
GPU Id(s) being used: 0,1,2,3
==> Building model and model_mvm for resnet18 ...
WARNING: crossbar sizes with different row annd column dimension not supported.
==> Initializing model parameters ...
==> Load pretrained model from ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Pretrained model accuracy: 69.93189239501953
Validating...
Test: [0/157]	Loss 2.3369 (2.3369)	Prec@1 43.750 (43.750)
Test: [1/157]	Loss 1.7060 (2.0214)	Prec@1 60.000 (51.875)
Test: [2/157]	Loss 1.6027 (1.8819)	Prec@1 65.000 (56.250)
Test: [3/157]	Loss 2.2705 (1.9790)	Prec@1 51.250 (55.000)
Test: [4/157]	Loss 3.8142 (2.3461)	Prec@1 28.750 (49.750)
Test: [5/157]	Loss 3.7917 (2.5870)	Prec@1 25.938 (45.781)
Test: [6/157]	Loss 3.3682 (2.6986)	Prec@1 31.250 (43.705)
Test: [7/157]	Loss 3.5870 (2.8097)	Prec@1 27.812 (41.719)
Test: [8/157]	Loss 3.9012 (2.9309)	Prec@1 19.688 (39.271)
Test: [9/157]	Loss 2.8007 (2.9179)	Prec@1 36.562 (39.000)
Test: [10/157]	Loss 2.0539 (2.8394)	Prec@1 48.125 (39.830)
Test: [11/157]	Loss 2.3210 (2.7962)	Prec@1 45.312 (40.286)
Test: [12/157]	Loss 2.5009 (2.7735)	Prec@1 48.438 (40.913)
Test: [13/157]	Loss 1.2391 (2.6639)	Prec@1 72.500 (43.170)
Test: [14/157]	Loss 1.6831 (2.5985)	Prec@1 64.062 (44.562)
Test: [15/157]	Loss 1.9772 (2.5597)	Prec@1 57.812 (45.391)
Test: [16/157]	Loss 3.1153 (2.5923)	Prec@1 33.750 (44.706)
Test: [17/157]	Loss 4.4826 (2.6974)	Prec@1 16.875 (43.160)
Test: [18/157]	Loss 2.6542 (2.6951)	Prec@1 38.125 (42.895)
Test: [19/157]	Loss 2.9953 (2.7101)	Prec@1 36.562 (42.578)
Test: [20/157]	Loss 1.8304 (2.6682)	Prec@1 58.750 (43.348)
Test: [21/157]	Loss 1.8143 (2.6294)	Prec@1 59.062 (44.062)
Test: [22/157]	Loss 2.1192 (2.6072)	Prec@1 55.312 (44.552)
Test: [23/157]	Loss 4.5713 (2.6890)	Prec@1 21.250 (43.581)
Test: [24/157]	Loss 3.9643 (2.7400)	Prec@1 24.688 (42.825)
Test: [25/157]	Loss 2.7540 (2.7406)	Prec@1 37.188 (42.608)
Test: [26/157]	Loss 2.9362 (2.7478)	Prec@1 35.938 (42.361)
Test: [27/157]	Loss 2.9938 (2.7566)	Prec@1 31.562 (41.975)
Test: [28/157]	Loss 2.4352 (2.7455)	Prec@1 42.188 (41.983)
Test: [29/157]	Loss 2.9694 (2.7530)	Prec@1 34.375 (41.729)
Test: [30/157]	Loss 2.6993 (2.7513)	Prec@1 38.438 (41.623)
Test: [31/157]	Loss 2.8019 (2.7528)	Prec@1 36.250 (41.455)
Test: [32/157]	Loss 2.9917 (2.7601)	Prec@1 35.000 (41.259)
Test: [33/157]	Loss 2.5952 (2.7552)	Prec@1 40.312 (41.232)
Test: [34/157]	Loss 2.6023 (2.7509)	Prec@1 45.000 (41.339)
Test: [35/157]	Loss 3.4052 (2.7690)	Prec@1 32.812 (41.102)
Test: [36/157]	Loss 3.1917 (2.7805)	Prec@1 29.688 (40.794)
Test: [37/157]	Loss 4.0830 (2.8147)	Prec@1 14.688 (40.107)
Test: [38/157]	Loss 3.9314 (2.8434)	Prec@1 22.188 (39.647)
Test: [39/157]	Loss 3.6935 (2.8646)	Prec@1 31.250 (39.438)
Test: [40/157]	Loss 3.7011 (2.8850)	Prec@1 28.750 (39.177)
Test: [41/157]	Loss 3.6058 (2.9022)	Prec@1 24.062 (38.817)
Test: [42/157]	Loss 2.2462 (2.8869)	Prec@1 44.375 (38.946)
Test: [43/157]	Loss 2.5990 (2.8804)	Prec@1 43.125 (39.041)
Test: [44/157]	Loss 3.4232 (2.8925)	Prec@1 37.500 (39.007)
Test: [45/157]	Loss 2.0843 (2.8749)	Prec@1 51.875 (39.287)
Test: [46/157]	Loss 2.4833 (2.8666)	Prec@1 45.312 (39.415)
Test: [47/157]	Loss 3.4689 (2.8791)	Prec@1 31.562 (39.251)
Test: [48/157]	Loss 4.0874 (2.9038)	Prec@1 21.250 (38.884)
Test: [49/157]	Loss 4.0962 (2.9276)	Prec@1 24.688 (38.600)
Test: [50/157]	Loss 1.5256 (2.9001)	Prec@1 67.500 (39.167)
Test: [51/157]	Loss 1.9248 (2.8814)	Prec@1 52.812 (39.429)
Test: [52/157]	Loss 2.3316 (2.8710)	Prec@1 53.125 (39.688)
Test: [53/157]	Loss 2.4632 (2.8634)	Prec@1 49.062 (39.861)
Test: [54/157]	Loss 1.7182 (2.8426)	Prec@1 56.562 (40.165)
Test: [55/157]	Loss 2.7858 (2.8416)	Prec@1 40.000 (40.162)
Test: [56/157]	Loss 2.7441 (2.8399)	Prec@1 47.188 (40.285)
Test: [57/157]	Loss 3.8668 (2.8576)	Prec@1 25.625 (40.032)
Test: [58/157]	Loss 3.6128 (2.8704)	Prec@1 36.562 (39.974)
Test: [59/157]	Loss 3.7719 (2.8854)	Prec@1 27.188 (39.760)
Test: [60/157]	Loss 2.1068 (2.8727)	Prec@1 51.562 (39.954)
Test: [61/157]	Loss 2.3759 (2.8646)	Prec@1 46.250 (40.055)
Test: [62/157]	Loss 4.3048 (2.8875)	Prec@1 26.875 (39.846)
Test: [63/157]	Loss 3.4298 (2.8960)	Prec@1 33.438 (39.746)
Test: [64/157]	Loss 4.2655 (2.9170)	Prec@1 20.312 (39.447)
Test: [65/157]	Loss 4.5976 (2.9425)	Prec@1 26.562 (39.252)
Test: [66/157]	Loss 3.2121 (2.9465)	Prec@1 36.562 (39.212)
Test: [67/157]	Loss 4.6539 (2.9716)	Prec@1 19.062 (38.915)
Test: [68/157]	Loss 3.8271 (2.9840)	Prec@1 28.438 (38.764)
Test: [69/157]	Loss 5.1138 (3.0145)	Prec@1 14.375 (38.415)
Test: [70/157]	Loss 3.5201 (3.0216)	Prec@1 28.750 (38.279)
Test: [71/157]	Loss 4.3783 (3.0404)	Prec@1 25.000 (38.095)
Test: [72/157]	Loss 4.9133 (3.0661)	Prec@1 18.438 (37.825)
Test: [73/157]	Loss 3.7962 (3.0760)	Prec@1 31.562 (37.741)
Test: [74/157]	Loss 4.7415 (3.0982)	Prec@1 19.375 (37.496)
Test: [75/157]	Loss 4.6596 (3.1187)	Prec@1 18.750 (37.249)
Test: [76/157]	Loss 4.0086 (3.1303)	Prec@1 29.062 (37.143)
Test: [77/157]	Loss 4.3325 (3.1457)	Prec@1 26.250 (37.003)
Test: [78/157]	Loss 4.6734 (3.1650)	Prec@1 26.875 (36.875)
Test: [79/157]	Loss 4.3105 (3.1793)	Prec@1 21.250 (36.680)
Test: [80/157]	Loss 5.4416 (3.2073)	Prec@1 14.688 (36.408)
Test: [81/157]	Loss 4.7303 (3.2258)	Prec@1 18.438 (36.189)
Test: [82/157]	Loss 4.6639 (3.2432)	Prec@1 17.500 (35.964)
Test: [83/157]	Loss 4.2350 (3.2550)	Prec@1 24.688 (35.830)
Test: [84/157]	Loss 5.1315 (3.2771)	Prec@1 20.938 (35.654)
Test: [85/157]	Loss 3.2837 (3.2771)	Prec@1 33.125 (35.625)
Test: [86/157]	Loss 3.8276 (3.2835)	Prec@1 30.312 (35.564)
Test: [87/157]	Loss 4.6582 (3.2991)	Prec@1 24.688 (35.440)
Test: [88/157]	Loss 3.4939 (3.3013)	Prec@1 39.375 (35.485)
Test: [89/157]	Loss 3.7583 (3.3063)	Prec@1 33.438 (35.462)
Test: [90/157]	Loss 3.4749 (3.3082)	Prec@1 34.375 (35.450)
Test: [91/157]	Loss 5.0313 (3.3269)	Prec@1 19.688 (35.279)
Test: [92/157]	Loss 5.5307 (3.3506)	Prec@1 16.250 (35.074)
Test: [93/157]	Loss 5.2695 (3.3710)	Prec@1 15.625 (34.867)
Test: [94/157]	Loss 4.0562 (3.3782)	Prec@1 31.875 (34.836)
Test: [95/157]	Loss 3.3597 (3.3781)	Prec@1 42.188 (34.912)
Test: [96/157]	Loss 4.5977 (3.3906)	Prec@1 21.875 (34.778)
Test: [97/157]	Loss 5.9001 (3.4162)	Prec@1 15.000 (34.576)
Test: [98/157]	Loss 5.4418 (3.4367)	Prec@1 18.125 (34.410)
Test: [99/157]	Loss 4.7465 (3.4498)	Prec@1 11.875 (34.184)
Test: [100/157]	Loss 4.2663 (3.4579)	Prec@1 31.875 (34.162)
Test: [101/157]	Loss 3.9717 (3.4629)	Prec@1 33.125 (34.151)
Test: [102/157]	Loss 4.1337 (3.4694)	Prec@1 25.625 (34.069)
Test: [103/157]	Loss 3.8627 (3.4732)	Prec@1 22.500 (33.957)
Test: [104/157]	Loss 3.2115 (3.4707)	Prec@1 39.062 (34.006)
Test: [105/157]	Loss 5.6982 (3.4917)	Prec@1 15.000 (33.827)
Test: [106/157]	Loss 4.6304 (3.5024)	Prec@1 25.000 (33.744)
Test: [107/157]	Loss 3.1352 (3.4990)	Prec@1 38.125 (33.785)
Test: [108/157]	Loss 4.6517 (3.5095)	Prec@1 18.125 (33.641)
Test: [109/157]	Loss 3.5187 (3.5096)	Prec@1 34.688 (33.651)
Test: [110/157]	Loss 5.2372 (3.5252)	Prec@1 15.000 (33.483)
Test: [111/157]	Loss 4.1738 (3.5310)	Prec@1 29.688 (33.449)
Test: [112/157]	Loss 4.6941 (3.5413)	Prec@1 20.625 (33.335)
Test: [113/157]	Loss 3.8890 (3.5443)	Prec@1 30.625 (33.311)
Test: [114/157]	Loss 4.5666 (3.5532)	Prec@1 19.062 (33.188)
Test: [115/157]	Loss 4.1488 (3.5584)	Prec@1 30.938 (33.168)
Test: [116/157]	Loss 4.8804 (3.5697)	Prec@1 15.625 (33.018)
Test: [117/157]	Loss 5.1861 (3.5834)	Prec@1 15.938 (32.873)
Test: [118/157]	Loss 4.7594 (3.5932)	Prec@1 22.812 (32.789)
Test: [119/157]	Loss 5.1274 (3.6060)	Prec@1 18.125 (32.667)
Test: [120/157]	Loss 5.3564 (3.6205)	Prec@1 20.312 (32.565)
Test: [121/157]	Loss 4.7293 (3.6296)	Prec@1 23.125 (32.487)
Test: [122/157]	Loss 4.8302 (3.6393)	Prec@1 20.000 (32.386)
Test: [123/157]	Loss 4.6262 (3.6473)	Prec@1 18.750 (32.276)
Test: [124/157]	Loss 3.8092 (3.6486)	Prec@1 32.812 (32.280)
Test: [125/157]	Loss 3.5333 (3.6477)	Prec@1 34.375 (32.297)
Test: [126/157]	Loss 4.3753 (3.6534)	Prec@1 22.500 (32.219)
Test: [127/157]	Loss 5.4706 (3.6676)	Prec@1 15.000 (32.085)
Test: [128/157]	Loss 4.5830 (3.6747)	Prec@1 23.125 (32.016)
Test: [129/157]	Loss 4.4028 (3.6803)	Prec@1 24.062 (31.954)
Test: [130/157]	Loss 5.0845 (3.6910)	Prec@1 21.562 (31.875)
Test: [131/157]	Loss 4.4240 (3.6966)	Prec@1 26.250 (31.832)
Test: [132/157]	Loss 3.8782 (3.6979)	Prec@1 30.625 (31.823)
Test: [133/157]	Loss 3.9193 (3.6996)	Prec@1 32.188 (31.826)
Test: [134/157]	Loss 3.9589 (3.7015)	Prec@1 28.438 (31.801)
Test: [135/157]	Loss 4.0061 (3.7037)	Prec@1 24.062 (31.744)
Test: [136/157]	Loss 3.8134 (3.7045)	Prec@1 25.625 (31.699)
Test: [137/157]	Loss 4.6412 (3.7113)	Prec@1 18.438 (31.603)
Test: [138/157]	Loss 3.8321 (3.7122)	Prec@1 31.562 (31.603)
Test: [139/157]	Loss 4.3495 (3.7168)	Prec@1 23.438 (31.545)
Test: [140/157]	Loss 4.2073 (3.7202)	Prec@1 26.875 (31.512)
Test: [141/157]	Loss 4.9483 (3.7289)	Prec@1 20.312 (31.433)
Test: [142/157]	Loss 4.0552 (3.7312)	Prec@1 26.250 (31.396)
Test: [143/157]	Loss 3.4311 (3.7291)	Prec@1 30.312 (31.389)
Test: [144/157]	Loss 2.6820 (3.7219)	Prec@1 44.375 (31.478)
Test: [145/157]	Loss 4.2786 (3.7257)	Prec@1 22.188 (31.415)
Test: [146/157]	Loss 2.8819 (3.7199)	Prec@1 39.062 (31.467)
Test: [147/157]	Loss 3.2092 (3.7165)	Prec@1 36.562 (31.501)
Test: [148/157]	Loss 4.1027 (3.7191)	Prec@1 24.062 (31.451)
Test: [149/157]	Loss 3.1761 (3.7155)	Prec@1 42.188 (31.523)
Test: [150/157]	Loss 4.0882 (3.7179)	Prec@1 23.750 (31.471)
Test: [151/157]	Loss 4.3597 (3.7221)	Prec@1 20.312 (31.398)
Test: [152/157]	Loss 2.5002 (3.7142)	Prec@1 43.750 (31.479)
Test: [153/157]	Loss 2.5877 (3.7068)	Prec@1 46.250 (31.575)
Test: [154/157]	Loss 2.2330 (3.6973)	Prec@1 55.938 (31.732)
Test: [155/157]	Loss 1.8888 (3.6857)	Prec@1 57.500 (31.897)
Test: [156/157]	Loss 3.7700 (3.6859)	Prec@1 21.250 (31.880)
 * Prec@1 31.880
Pretrained model accuracy: 31.88
