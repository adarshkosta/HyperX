
      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 0
          frozen_layers: 1
Savedir:  ../pretrained_models/frozen/x64-8b/rram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 0
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/train/relu1
Test path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/test/relu1
ResNet18(
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (conv2): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu2): ReLU(inplace=True)
  (conv3): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu3): ReLU(inplace=True)
  (conv4): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu4): ReLU(inplace=True)
  (conv5): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu5): ReLU(inplace=True)
  (conv6): QConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv1): Sequential(
    (0): QConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu6): ReLU(inplace=True)
  (conv7): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu7): ReLU(inplace=True)
  (conv8): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): QConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): QConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): QConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): QConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 13.000 Prec@5 57.850 Loss 2.2754
Avg Loading time: 8.7975 seconds
Avg Batch time: 8.8865 seconds

Pre-trained Prec@1 with 1 layers frozen: 13.0 	 Loss: 2.275390625

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.01	DT: 0.000 (13.602)	BT: 0.228 (13.847)	Loss 0.7397 (1.0783)	Prec@1 83.594 (69.702)	
Epoch: [0][155/391]	LR: 0.01	DT: 3.961 (13.187)	BT: 4.239 (13.439)	Loss 0.5728 (0.8433)	Prec@1 82.812 (76.623)	
Epoch: [0][233/391]	LR: 0.01	DT: 8.780 (12.596)	BT: 9.027 (12.849)	Loss 0.4954 (0.7279)	Prec@1 85.938 (79.661)	
Epoch: [0][311/391]	LR: 0.01	DT: 0.000 (11.522)	BT: 0.252 (11.776)	Loss 0.3755 (0.6581)	Prec@1 90.625 (81.440)	
Epoch: [0][389/391]	LR: 0.01	DT: 0.000 (10.737)	BT: 0.241 (10.993)	Loss 0.4187 (0.6082)	Prec@1 85.938 (82.728)	
Total train loss: 0.6077
Avg Loading time: 10.7094 seconds
Avg Batch time: 10.9649 seconds

Train time: 4287.318275928497
 * Prec@1 78.060 Prec@5 98.260 Loss 0.7109
Avg Loading time: 6.3041 seconds
Avg Batch time: 6.3975 seconds

Best acc: 78.060
--------------------------------------------------------------------------------
Test time: 506.43817830085754

Epoch: [1][77/391]	LR: 0.01	DT: 0.814 (8.863)	BT: 1.087 (9.139)	Loss 0.3115 (0.3676)	Prec@1 92.188 (88.852)	
Epoch: [1][155/391]	LR: 0.01	DT: 0.000 (9.081)	BT: 0.258 (9.356)	Loss 0.4041 (0.3734)	Prec@1 89.062 (88.627)	
Epoch: [1][233/391]	LR: 0.01	DT: 0.000 (9.004)	BT: 0.265 (9.280)	Loss 0.3574 (0.3675)	Prec@1 87.500 (88.712)	
Epoch: [1][311/391]	LR: 0.01	DT: 0.000 (8.667)	BT: 0.284 (8.944)	Loss 0.3037 (0.3609)	Prec@1 91.406 (88.792)	
Epoch: [1][389/391]	LR: 0.01	DT: 1.941 (8.603)	BT: 2.226 (8.882)	Loss 0.4839 (0.3556)	Prec@1 84.375 (88.928)	
Total train loss: 0.3556
Avg Loading time: 8.5815 seconds
Avg Batch time: 8.8602 seconds

Train time: 3464.4102075099945
 * Prec@1 88.480 Prec@5 99.590 Loss 0.4001
Avg Loading time: 7.0256 seconds
Avg Batch time: 7.1283 seconds

Best acc: 88.480
--------------------------------------------------------------------------------
Test time: 564.142689704895

Epoch: [2][77/391]	LR: 0.01	DT: 0.000 (9.016)	BT: 0.260 (9.292)	Loss 0.2954 (0.3157)	Prec@1 93.750 (89.904)	
Epoch: [2][155/391]	LR: 0.01	DT: 0.000 (8.875)	BT: 0.275 (9.151)	Loss 0.3142 (0.3157)	Prec@1 89.844 (89.894)	
Epoch: [2][233/391]	LR: 0.01	DT: 0.000 (8.738)	BT: 0.276 (9.014)	Loss 0.3723 (0.3121)	Prec@1 91.406 (89.957)	
Epoch: [2][311/391]	LR: 0.01	DT: 0.000 (8.627)	BT: 0.261 (8.904)	Loss 0.2430 (0.3117)	Prec@1 91.406 (89.956)	
Epoch: [2][389/391]	LR: 0.01	DT: 0.000 (8.749)	BT: 0.258 (9.026)	Loss 0.3181 (0.3099)	Prec@1 89.844 (90.006)	
Total train loss: 0.3097
Avg Loading time: 8.7268 seconds
Avg Batch time: 9.0031 seconds

Train time: 3520.271494626999
 * Prec@1 90.110 Prec@5 99.770 Loss 0.3032
Avg Loading time: 8.0877 seconds
Avg Batch time: 8.1959 seconds

Best acc: 90.110
--------------------------------------------------------------------------------
Test time: 650.0762190818787

Epoch: [3][77/391]	LR: 0.01	DT: 0.000 (9.445)	BT: 0.283 (9.737)	Loss 0.2690 (0.2802)	Prec@1 90.625 (90.825)	
Epoch: [3][155/391]	LR: 0.01	DT: 1.638 (9.643)	BT: 1.938 (9.936)	Loss 0.2380 (0.2859)	Prec@1 92.969 (90.620)	
Epoch: [3][233/391]	LR: 0.01	DT: 0.000 (9.652)	BT: 0.298 (9.944)	Loss 0.2715 (0.2872)	Prec@1 90.625 (90.568)	
Epoch: [3][311/391]	LR: 0.01	DT: 0.000 (9.474)	BT: 0.270 (9.765)	Loss 0.2874 (0.2924)	Prec@1 89.062 (90.355)	
Epoch: [3][389/391]	LR: 0.01	DT: 0.000 (9.292)	BT: 0.254 (9.582)	Loss 0.2983 (0.2966)	Prec@1 92.188 (90.252)	
Total train loss: 0.2966
Avg Loading time: 9.2684 seconds
Avg Batch time: 9.5576 seconds

Train time: 3737.0553567409515
 * Prec@1 89.770 Prec@5 99.750 Loss 0.3184
Avg Loading time: 7.0860 seconds
Avg Batch time: 7.1926 seconds

Best acc: 90.110
--------------------------------------------------------------------------------
Test time: 568.762699842453

Epoch: [4][77/391]	LR: 0.01	DT: 0.000 (9.050)	BT: 0.280 (9.336)	Loss 0.2173 (0.2830)	Prec@1 91.406 (90.935)	
Epoch: [4][155/391]	LR: 0.01	DT: 0.000 (9.500)	BT: 0.257 (9.787)	Loss 0.3003 (0.3094)	Prec@1 89.062 (89.914)	
Epoch: [4][233/391]	LR: 0.01	DT: 0.000 (9.636)	BT: 0.270 (9.920)	Loss 0.3325 (0.3153)	Prec@1 86.719 (89.687)	
Epoch: [4][311/391]	LR: 0.01	DT: 0.000 (9.341)	BT: 0.253 (9.623)	Loss 0.2290 (0.3137)	Prec@1 93.750 (89.759)	
Epoch: [4][389/391]	LR: 0.01	DT: 0.000 (9.080)	BT: 0.279 (9.361)	Loss 0.3452 (0.3126)	Prec@1 88.281 (89.688)	
Total train loss: 0.3128
Avg Loading time: 9.0572 seconds
Avg Batch time: 9.3375 seconds

Train time: 3651.000467777252
 * Prec@1 89.070 Prec@5 99.720 Loss 0.3372
Avg Loading time: 7.3110 seconds
Avg Batch time: 7.4177 seconds

Best acc: 90.110
--------------------------------------------------------------------------------
Test time: 586.5916411876678

Epoch: [5][77/391]	LR: 0.01	DT: 0.420 (9.699)	BT: 0.732 (9.991)	Loss 0.3242 (0.2771)	Prec@1 90.625 (90.735)	
Epoch: [5][155/391]	LR: 0.01	DT: 0.000 (9.811)	BT: 0.264 (10.104)	Loss 0.1989 (0.2805)	Prec@1 94.531 (90.830)	
Epoch: [5][233/391]	LR: 0.01	DT: 0.000 (9.600)	BT: 0.276 (9.888)	Loss 0.3066 (0.2817)	Prec@1 88.281 (90.852)	
Epoch: [5][311/391]	LR: 0.01	DT: 0.000 (9.294)	BT: 0.259 (9.581)	Loss 0.3191 (0.2890)	Prec@1 86.719 (90.577)	
Epoch: [5][389/391]	LR: 0.01	DT: 0.000 (9.139)	BT: 0.258 (9.423)	Loss 0.2681 (0.2900)	Prec@1 92.969 (90.435)	
Total train loss: 0.2899
Avg Loading time: 9.1153 seconds
Avg Batch time: 9.3992 seconds

Train time: 3675.1934971809387
 * Prec@1 87.960 Prec@5 99.730 Loss 0.3523
Avg Loading time: 8.8595 seconds
Avg Batch time: 8.9709 seconds

Best acc: 90.110
--------------------------------------------------------------------------------
Test time: 709.6888084411621

Epoch: [6][77/391]	LR: 0.01	DT: 0.000 (8.891)	BT: 0.266 (9.174)	Loss 0.3535 (0.2739)	Prec@1 89.844 (91.056)	
Epoch: [6][155/391]	LR: 0.01	DT: 0.000 (8.520)	BT: 0.277 (8.803)	Loss 0.2268 (0.2749)	Prec@1 93.750 (90.925)	
Epoch: [6][233/391]	LR: 0.01	DT: 0.000 (8.654)	BT: 0.300 (8.934)	Loss 0.2532 (0.2847)	Prec@1 89.844 (90.458)	
Epoch: [6][311/391]	LR: 0.01	DT: 0.000 (8.576)	BT: 0.259 (8.856)	Loss 0.1797 (0.2882)	Prec@1 94.531 (90.330)	
Epoch: [6][389/391]	LR: 0.01	DT: 0.000 (8.439)	BT: 0.283 (8.720)	Loss 0.3220 (0.2902)	Prec@1 89.062 (90.250)	
Total train loss: 0.2903
Avg Loading time: 8.4175 seconds
Avg Batch time: 8.6982 seconds

Train time: 3401.0640845298767
 * Prec@1 75.700 Prec@5 99.030 Loss 0.6851
Avg Loading time: 7.8991 seconds
Avg Batch time: 8.0085 seconds

Best acc: 90.110
--------------------------------------------------------------------------------
Test time: 634.9534296989441

Epoch: [7][77/391]	LR: 0.01	DT: 0.000 (8.188)	BT: 0.278 (8.476)	Loss 0.4097 (0.2987)	Prec@1 85.938 (89.974)	
Epoch: [7][155/391]	LR: 0.01	DT: 0.000 (8.616)	BT: 0.270 (8.901)	Loss 0.2581 (0.3016)	Prec@1 91.406 (89.704)	
Epoch: [7][233/391]	LR: 0.01	DT: 0.000 (8.822)	BT: 0.270 (9.108)	Loss 0.2817 (0.3004)	Prec@1 90.625 (89.914)	
Epoch: [7][311/391]	LR: 0.01	DT: 0.000 (8.713)	BT: 0.268 (8.999)	Loss 0.3550 (0.3014)	Prec@1 90.625 (89.976)	
Epoch: [7][389/391]	LR: 0.01	DT: 0.000 (8.421)	BT: 0.283 (8.706)	Loss 0.3955 (0.3045)	Prec@1 89.062 (89.890)	
Total train loss: 0.3047
Avg Loading time: 8.3990 seconds
Avg Batch time: 8.6840 seconds

Train time: 3395.4896960258484
 * Prec@1 69.350 Prec@5 96.640 Loss 0.9150
Avg Loading time: 7.6537 seconds
Avg Batch time: 7.7600 seconds

Best acc: 90.110
--------------------------------------------------------------------------------
Test time: 613.7847325801849

Epoch: [8][77/391]	LR: 0.01	DT: 0.000 (8.698)	BT: 0.281 (8.988)	Loss 0.2274 (0.3118)	Prec@1 91.406 (89.834)	
Epoch: [8][155/391]	LR: 0.01	DT: 2.639 (8.968)	BT: 2.984 (9.259)	Loss 0.2595 (0.3187)	Prec@1 92.188 (89.313)	
Epoch: [8][233/391]	LR: 0.01	DT: 0.000 (9.036)	BT: 0.280 (9.328)	Loss 0.2410 (0.3340)	Prec@1 92.969 (88.732)	
Epoch: [8][311/391]	LR: 0.01	DT: 0.375 (8.620)	BT: 0.687 (8.910)	Loss 0.4822 (0.3343)	Prec@1 79.688 (88.667)	
Epoch: [8][389/391]	LR: 0.01	DT: 1.673 (8.424)	BT: 1.962 (8.713)	Loss 0.2075 (0.3358)	Prec@1 92.969 (88.610)	
Total train loss: 0.3356
Avg Loading time: 8.4025 seconds
Avg Batch time: 8.6915 seconds

Train time: 3398.4521589279175
 * Prec@1 71.580 Prec@5 97.230 Loss 0.8511
Avg Loading time: 8.0075 seconds
Avg Batch time: 8.1169 seconds

Best acc: 90.110
--------------------------------------------------------------------------------
Test time: 641.8093218803406

Epoch: [9][77/391]	LR: 0.01	DT: 0.000 (9.126)	BT: 0.259 (9.418)	Loss 0.3311 (0.3137)	Prec@1 89.844 (89.373)	
Epoch: [9][155/391]	LR: 0.01	DT: 0.000 (9.322)	BT: 0.278 (9.615)	Loss 0.4197 (0.3235)	Prec@1 89.844 (88.942)	
Epoch: [9][233/391]	LR: 0.01	DT: 8.554 (9.134)	BT: 8.881 (9.425)	Loss 0.2681 (0.3259)	Prec@1 89.844 (88.839)	
Epoch: [9][311/391]	LR: 0.01	DT: 3.535 (8.918)	BT: 3.834 (9.209)	Loss 0.3215 (0.3215)	Prec@1 87.500 (89.093)	
Epoch: [9][389/391]	LR: 0.01	DT: 0.000 (8.738)	BT: 0.259 (9.028)	Loss 0.2742 (0.3191)	Prec@1 90.625 (89.169)	
Total train loss: 0.3191
Avg Loading time: 8.7154 seconds
Avg Batch time: 9.0057 seconds

Train time: 3521.348555088043
 * Prec@1 80.230 Prec@5 98.670 Loss 0.5835
Avg Loading time: 8.5222 seconds
Avg Batch time: 8.6325 seconds

Best acc: 90.110
--------------------------------------------------------------------------------
Test time: 684.2106585502625

Epoch: [10][77/391]	LR: 0.002	DT: 0.000 (8.182)	BT: 0.264 (8.471)	Loss 0.3105 (0.2843)	Prec@1 89.844 (90.905)	
Epoch: [10][155/391]	LR: 0.002	DT: 0.000 (8.308)	BT: 0.269 (8.596)	Loss 0.2952 (0.2857)	Prec@1 88.281 (90.810)	
Epoch: [10][233/391]	LR: 0.002	DT: 0.000 (8.558)	BT: 0.300 (8.846)	Loss 0.3291 (0.2824)	Prec@1 88.281 (90.852)	
Epoch: [10][311/391]	LR: 0.002	DT: 0.000 (8.443)	BT: 0.262 (8.730)	Loss 0.3320 (0.2830)	Prec@1 93.750 (90.773)	
Epoch: [10][389/391]	LR: 0.002	DT: 0.000 (8.315)	BT: 0.265 (8.601)	Loss 0.2693 (0.2815)	Prec@1 92.969 (90.887)	
Total train loss: 0.2814
Avg Loading time: 8.2935 seconds
Avg Batch time: 8.5793 seconds

Train time: 3354.569299221039
 * Prec@1 89.920 Prec@5 99.800 Loss 0.3059
Avg Loading time: 7.4256 seconds
Avg Batch time: 7.5325 seconds

Best acc: 90.110
--------------------------------------------------------------------------------
Test time: 595.6322174072266

Epoch: [11][77/391]	LR: 0.002	DT: 0.000 (8.427)	BT: 0.271 (8.718)	Loss 0.3213 (0.2773)	Prec@1 85.938 (90.665)	
Epoch: [11][155/391]	LR: 0.002	DT: 0.000 (8.690)	BT: 0.262 (8.983)	Loss 0.3303 (0.2758)	Prec@1 86.719 (90.946)	
Epoch: [11][233/391]	LR: 0.002	DT: 0.000 (8.821)	BT: 0.345 (9.115)	Loss 0.3523 (0.2726)	Prec@1 89.062 (91.153)	
Epoch: [11][311/391]	LR: 0.002	DT: 0.000 (8.643)	BT: 0.273 (8.936)	Loss 0.1897 (0.2731)	Prec@1 94.531 (91.116)	
Epoch: [11][389/391]	LR: 0.002	DT: 0.000 (8.365)	BT: 0.266 (8.657)	Loss 0.2927 (0.2721)	Prec@1 92.188 (91.168)	
Total train loss: 0.2719
Avg Loading time: 8.3436 seconds
Avg Batch time: 8.6353 seconds

Train time: 3376.4151406288147
 * Prec@1 89.950 Prec@5 99.820 Loss 0.3025
Avg Loading time: 7.5865 seconds
Avg Batch time: 7.6980 seconds

Best acc: 90.110
--------------------------------------------------------------------------------
Test time: 608.7913897037506

Epoch: [12][77/391]	LR: 0.002	DT: 0.000 (8.759)	BT: 0.263 (9.044)	Loss 0.2795 (0.2616)	Prec@1 91.406 (91.647)	
Epoch: [12][155/391]	LR: 0.002	DT: 0.000 (8.982)	BT: 0.272 (9.270)	Loss 0.3140 (0.2656)	Prec@1 87.500 (91.451)	
Epoch: [12][233/391]	LR: 0.002	DT: 9.397 (8.920)	BT: 9.682 (9.207)	Loss 0.2764 (0.2649)	Prec@1 93.750 (91.436)	
Epoch: [12][311/391]	LR: 0.002	DT: 0.000 (8.466)	BT: 0.278 (8.752)	Loss 0.2102 (0.2666)	Prec@1 92.188 (91.361)	
Epoch: [12][389/391]	LR: 0.002	DT: 0.000 (8.363)	BT: 0.278 (8.647)	Loss 0.3052 (0.2680)	Prec@1 90.625 (91.326)	
Total train loss: 0.2680
Avg Loading time: 8.3411 seconds
Avg Batch time: 8.6258 seconds

Train time: 3372.78470659256
 * Prec@1 90.110 Prec@5 99.790 Loss 0.3003
Avg Loading time: 8.4387 seconds
Avg Batch time: 8.5467 seconds

Best acc: 90.110
--------------------------------------------------------------------------------
Test time: 676.9471848011017

Epoch: [13][77/391]	LR: 0.002	DT: 0.000 (8.807)	BT: 0.279 (9.098)	Loss 0.1868 (0.2565)	Prec@1 96.875 (91.777)	
Epoch: [13][155/391]	LR: 0.002	DT: 1.289 (8.630)	BT: 1.579 (8.924)	Loss 0.3765 (0.2613)	Prec@1 88.281 (91.587)	
Epoch: [13][233/391]	LR: 0.002	DT: 16.302 (8.597)	BT: 16.600 (8.891)	Loss 0.2585 (0.2633)	Prec@1 92.969 (91.490)	
Epoch: [13][311/391]	LR: 0.002	DT: 0.440 (8.317)	BT: 0.733 (8.610)	Loss 0.2377 (0.2646)	Prec@1 90.625 (91.451)	
Epoch: [13][389/391]	LR: 0.002	DT: 0.000 (8.333)	BT: 0.261 (8.624)	Loss 0.2025 (0.2655)	Prec@1 94.531 (91.426)	
Total train loss: 0.2656
Avg Loading time: 8.3113 seconds
Avg Batch time: 8.6026 seconds

Train time: 3363.7422568798065
 * Prec@1 90.100 Prec@5 99.790 Loss 0.2981
Avg Loading time: 8.1648 seconds
Avg Batch time: 8.2744 seconds

Best acc: 90.110
--------------------------------------------------------------------------------
Test time: 655.784019947052

Epoch: [14][77/391]	LR: 0.002	DT: 0.000 (8.234)	BT: 0.278 (8.517)	Loss 0.2284 (0.2551)	Prec@1 92.969 (91.536)	
Epoch: [14][155/391]	LR: 0.002	DT: 0.000 (8.441)	BT: 0.259 (8.723)	Loss 0.2849 (0.2636)	Prec@1 89.844 (91.281)	
Epoch: [14][233/391]	LR: 0.002	DT: 0.000 (8.668)	BT: 0.280 (8.950)	Loss 0.2264 (0.2585)	Prec@1 92.969 (91.533)	
Epoch: [14][311/391]	LR: 0.002	DT: 0.000 (8.351)	BT: 0.275 (8.632)	Loss 0.3015 (0.2598)	Prec@1 90.625 (91.567)	
Epoch: [14][389/391]	LR: 0.002	DT: 0.000 (8.346)	BT: 0.271 (8.627)	Loss 0.2258 (0.2604)	Prec@1 92.969 (91.581)	
Total train loss: 0.2605
Avg Loading time: 8.3248 seconds
Avg Batch time: 8.6050 seconds

Train time: 3364.5974791049957
 * Prec@1 90.090 Prec@5 99.780 Loss 0.2971
Avg Loading time: 8.0769 seconds
Avg Batch time: 8.1841 seconds

Best acc: 90.110
--------------------------------------------------------------------------------
Test time: 647.0944938659668

Epoch: [15][77/391]	LR: 0.002	DT: 0.000 (8.659)	BT: 0.270 (8.946)	Loss 0.1907 (0.2698)	Prec@1 92.969 (91.056)	
Epoch: [15][155/391]	LR: 0.002	DT: 0.000 (8.885)	BT: 0.263 (9.173)	Loss 0.2347 (0.2575)	Prec@1 94.531 (91.551)	
Epoch: [15][233/391]	LR: 0.002	DT: 8.845 (8.956)	BT: 9.106 (9.244)	Loss 0.2483 (0.2590)	Prec@1 90.625 (91.627)	
Epoch: [15][311/391]	LR: 0.002	DT: 0.000 (8.577)	BT: 0.261 (8.864)	Loss 0.3135 (0.2608)	Prec@1 90.625 (91.536)	
Epoch: [15][389/391]	LR: 0.002	DT: 0.000 (8.466)	BT: 0.262 (8.755)	Loss 0.2367 (0.2602)	Prec@1 92.188 (91.524)	
Total train loss: 0.2603
Avg Loading time: 8.4448 seconds
Avg Batch time: 8.7326 seconds

Train time: 3414.5144176483154
 * Prec@1 90.060 Prec@5 99.790 Loss 0.2957
Avg Loading time: 7.9580 seconds
Avg Batch time: 8.0650 seconds

Best acc: 90.110
--------------------------------------------------------------------------------
Test time: 637.7746953964233

Epoch: [16][77/391]	LR: 0.002	DT: 0.000 (8.927)	BT: 0.261 (9.217)	Loss 0.2222 (0.2556)	Prec@1 93.750 (92.047)	
Epoch: [16][155/391]	LR: 0.002	DT: 2.850 (9.016)	BT: 3.163 (9.305)	Loss 0.2147 (0.2485)	Prec@1 94.531 (92.198)	
Epoch: [16][233/391]	LR: 0.002	DT: 3.607 (8.884)	BT: 3.908 (9.174)	Loss 0.2661 (0.2549)	Prec@1 92.188 (91.867)	
Epoch: [16][311/391]	LR: 0.002	DT: 0.000 (8.405)	BT: 0.259 (8.692)	Loss 0.2527 (0.2568)	Prec@1 91.406 (91.809)	
Epoch: [16][389/391]	LR: 0.002	DT: 0.000 (8.498)	BT: 0.260 (8.786)	Loss 0.1648 (0.2585)	Prec@1 96.094 (91.723)	
Total train loss: 0.2584
Avg Loading time: 8.4761 seconds
Avg Batch time: 8.7637 seconds

Train time: 3426.675055503845
 * Prec@1 90.130 Prec@5 99.820 Loss 0.2947
Avg Loading time: 9.6936 seconds
Avg Batch time: 9.8046 seconds

Best acc: 90.130
--------------------------------------------------------------------------------
Test time: 777.239426612854

Epoch: [17][77/391]	LR: 0.002	DT: 0.000 (9.490)	BT: 0.267 (9.783)	Loss 0.2703 (0.2452)	Prec@1 89.844 (92.037)	
Epoch: [17][155/391]	LR: 0.002	DT: 0.000 (9.623)	BT: 0.277 (9.910)	Loss 0.3130 (0.2510)	Prec@1 89.844 (91.897)	
Epoch: [17][233/391]	LR: 0.002	DT: 0.000 (9.579)	BT: 0.285 (9.866)	Loss 0.3494 (0.2556)	Prec@1 89.062 (91.797)	
Epoch: [17][311/391]	LR: 0.002	DT: 0.000 (8.950)	BT: 0.265 (9.235)	Loss 0.3250 (0.2547)	Prec@1 90.625 (91.819)	
Epoch: [17][389/391]	LR: 0.002	DT: 0.000 (8.947)	BT: 0.257 (9.232)	Loss 0.1969 (0.2548)	Prec@1 92.969 (91.879)	
Total train loss: 0.2549
Avg Loading time: 8.9245 seconds
Avg Batch time: 9.2092 seconds

Train time: 3600.887566804886
 * Prec@1 90.200 Prec@5 99.770 Loss 0.2954
Avg Loading time: 8.5184 seconds
Avg Batch time: 8.6285 seconds

Best acc: 90.200
--------------------------------------------------------------------------------
Test time: 684.3631489276886

Epoch: [18][77/391]	LR: 0.002	DT: 0.000 (9.854)	BT: 0.282 (10.145)	Loss 0.2068 (0.2445)	Prec@1 92.969 (92.047)	
Epoch: [18][155/391]	LR: 0.002	DT: 0.000 (10.183)	BT: 0.258 (10.473)	Loss 0.1935 (0.2460)	Prec@1 94.531 (92.067)	
Epoch: [18][233/391]	LR: 0.002	DT: 0.000 (10.260)	BT: 0.258 (10.548)	Loss 0.1580 (0.2491)	Prec@1 94.531 (91.844)	
Epoch: [18][311/391]	LR: 0.002	DT: 6.159 (9.479)	BT: 6.479 (9.766)	Loss 0.2106 (0.2514)	Prec@1 92.969 (91.827)	
Epoch: [18][389/391]	LR: 0.002	DT: 0.000 (9.331)	BT: 0.277 (9.621)	Loss 0.2146 (0.2520)	Prec@1 93.750 (91.801)	
Total train loss: 0.2520
Avg Loading time: 9.3075 seconds
Avg Batch time: 9.5973 seconds

Train time: 3752.609786748886
 * Prec@1 90.200 Prec@5 99.740 Loss 0.2937
Avg Loading time: 8.4136 seconds
Avg Batch time: 8.5212 seconds

Best acc: 90.200
--------------------------------------------------------------------------------
Test time: 673.7799422740936

Epoch: [19][77/391]	LR: 0.002	DT: 0.000 (8.722)	BT: 0.273 (9.014)	Loss 0.3069 (0.2429)	Prec@1 86.719 (92.258)	
Epoch: [19][155/391]	LR: 0.002	DT: 9.531 (8.934)	BT: 9.828 (9.224)	Loss 0.2864 (0.2494)	Prec@1 92.188 (92.032)	
Epoch: [19][233/391]	LR: 0.002	DT: 2.644 (8.930)	BT: 2.947 (9.220)	Loss 0.2935 (0.2495)	Prec@1 89.062 (92.064)	
Epoch: [19][311/391]	LR: 0.002	DT: 0.000 (8.470)	BT: 0.263 (8.760)	Loss 0.2465 (0.2487)	Prec@1 89.844 (92.040)	
Epoch: [19][389/391]	LR: 0.002	DT: 0.000 (8.462)	BT: 0.269 (8.752)	Loss 0.2283 (0.2514)	Prec@1 91.406 (91.923)	
Total train loss: 0.2514
Avg Loading time: 8.4406 seconds
Avg Batch time: 8.7302 seconds

Train time: 3413.6379034519196
 * Prec@1 90.080 Prec@5 99.790 Loss 0.2925
Avg Loading time: 8.0859 seconds
Avg Batch time: 8.1945 seconds

Best acc: 90.200
--------------------------------------------------------------------------------
Test time: 648.0117402076721

Epoch: [20][77/391]	LR: 0.0004	DT: 0.000 (8.977)	BT: 0.288 (9.271)	Loss 0.1979 (0.2488)	Prec@1 92.969 (92.017)	
Epoch: [20][155/391]	LR: 0.0004	DT: 0.000 (9.030)	BT: 0.278 (9.325)	Loss 0.2913 (0.2463)	Prec@1 89.062 (92.017)	
Epoch: [20][233/391]	LR: 0.0004	DT: 7.597 (8.909)	BT: 7.899 (9.203)	Loss 0.2290 (0.2486)	Prec@1 93.750 (91.887)	
Epoch: [20][311/391]	LR: 0.0004	DT: 0.461 (8.398)	BT: 0.725 (8.691)	Loss 0.1763 (0.2473)	Prec@1 95.312 (92.000)	
Epoch: [20][389/391]	LR: 0.0004	DT: 0.000 (8.554)	BT: 0.283 (8.848)	Loss 0.1892 (0.2487)	Prec@1 92.969 (91.985)	
Total train loss: 0.2486
Avg Loading time: 8.5321 seconds
Avg Batch time: 8.8259 seconds

Train time: 3451.0134744644165
 * Prec@1 90.070 Prec@5 99.760 Loss 0.2944
Avg Loading time: 9.0422 seconds
Avg Batch time: 9.1520 seconds

Best acc: 90.200
--------------------------------------------------------------------------------
Test time: 724.8858280181885

Epoch: [21][77/391]	LR: 0.0004	DT: 0.000 (9.587)	BT: 0.271 (9.876)	Loss 0.2695 (0.2538)	Prec@1 90.625 (91.697)	
Epoch: [21][155/391]	LR: 0.0004	DT: 0.000 (9.787)	BT: 0.278 (10.077)	Loss 0.2571 (0.2513)	Prec@1 90.625 (91.892)	
Epoch: [21][233/391]	LR: 0.0004	DT: 3.456 (9.862)	BT: 3.791 (10.152)	Loss 0.2152 (0.2503)	Prec@1 93.750 (91.947)	
Epoch: [21][311/391]	LR: 0.0004	DT: 0.000 (9.263)	BT: 0.280 (9.553)	Loss 0.2466 (0.2492)	Prec@1 92.969 (91.935)	
Epoch: [21][389/391]	LR: 0.0004	DT: 0.000 (9.194)	BT: 0.261 (9.484)	Loss 0.1691 (0.2503)	Prec@1 97.656 (91.933)	
Total train loss: 0.2504
Avg Loading time: 9.1704 seconds
Avg Batch time: 9.4603 seconds

Train time: 3699.0392773151398
 * Prec@1 90.170 Prec@5 99.780 Loss 0.2915
Avg Loading time: 7.1415 seconds
Avg Batch time: 7.2491 seconds

Best acc: 90.200
--------------------------------------------------------------------------------
Test time: 573.2357323169708

Epoch: [22][77/391]	LR: 0.0004	DT: 4.046 (8.541)	BT: 4.317 (8.835)	Loss 0.2700 (0.2478)	Prec@1 92.969 (92.057)	
Epoch: [22][155/391]	LR: 0.0004	DT: 0.314 (8.735)	BT: 0.617 (9.028)	Loss 0.2815 (0.2489)	Prec@1 89.062 (91.912)	
Epoch: [22][233/391]	LR: 0.0004	DT: 0.528 (8.871)	BT: 0.816 (9.164)	Loss 0.2773 (0.2496)	Prec@1 92.188 (91.994)	
Epoch: [22][311/391]	LR: 0.0004	DT: 0.000 (8.424)	BT: 0.259 (8.717)	Loss 0.1956 (0.2478)	Prec@1 93.750 (92.065)	
Epoch: [22][389/391]	LR: 0.0004	DT: 0.000 (8.518)	BT: 0.260 (8.811)	Loss 0.3374 (0.2485)	Prec@1 87.500 (92.113)	
Total train loss: 0.2485
Avg Loading time: 8.4964 seconds
Avg Batch time: 8.7894 seconds

Train time: 3436.7105910778046
 * Prec@1 90.270 Prec@5 99.760 Loss 0.2915
Avg Loading time: 8.4575 seconds
Avg Batch time: 8.5667 seconds

Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 678.3702719211578

Epoch: [23][77/391]	LR: 0.0004	DT: 0.000 (8.646)	BT: 0.271 (8.941)	Loss 0.2081 (0.2494)	Prec@1 89.844 (92.258)	
Epoch: [23][155/391]	LR: 0.0004	DT: 0.000 (8.945)	BT: 0.260 (9.239)	Loss 0.2952 (0.2476)	Prec@1 91.406 (92.177)	
Epoch: [23][233/391]	LR: 0.0004	DT: 0.000 (9.036)	BT: 0.291 (9.330)	Loss 0.3513 (0.2504)	Prec@1 89.844 (91.984)	
Epoch: [23][311/391]	LR: 0.0004	DT: 0.408 (8.756)	BT: 0.687 (9.048)	Loss 0.2554 (0.2507)	Prec@1 90.625 (92.015)	
Epoch: [23][389/391]	LR: 0.0004	DT: 0.000 (8.869)	BT: 0.262 (9.161)	Loss 0.2693 (0.2506)	Prec@1 90.625 (91.985)	
Total train loss: 0.2504
Avg Loading time: 8.8464 seconds
Avg Batch time: 9.1381 seconds

Train time: 3573.023758649826
 * Prec@1 90.110 Prec@5 99.790 Loss 0.2976
Avg Loading time: 11.6520 seconds
Avg Batch time: 11.7619 seconds

Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 931.78475689888

Epoch: [24][77/391]	LR: 0.0004	DT: 0.000 (9.974)	BT: 0.279 (10.262)	Loss 0.1897 (0.2488)	Prec@1 94.531 (91.957)	
Epoch: [24][155/391]	LR: 0.0004	DT: 0.000 (9.771)	BT: 0.257 (10.059)	Loss 0.3298 (0.2508)	Prec@1 89.844 (91.892)	
Epoch: [24][233/391]	LR: 0.0004	DT: 4.460 (9.600)	BT: 4.751 (9.886)	Loss 0.3987 (0.2529)	Prec@1 86.719 (91.884)	
Epoch: [24][311/391]	LR: 0.0004	DT: 0.000 (8.947)	BT: 0.258 (9.232)	Loss 0.1670 (0.2535)	Prec@1 95.312 (91.890)	
Epoch: [24][389/391]	LR: 0.0004	DT: 0.000 (9.001)	BT: 0.269 (9.286)	Loss 0.2455 (0.2505)	Prec@1 92.969 (91.969)	
Total train loss: 0.2504
Avg Loading time: 8.9784 seconds
Avg Batch time: 9.2631 seconds

Train time: 3621.953331232071
 * Prec@1 90.200 Prec@5 99.770 Loss 0.2913
Avg Loading time: 9.0687 seconds
Avg Batch time: 9.1790 seconds

Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 727.2444226741791

Epoch: [25][77/391]	LR: 0.0004	DT: 0.000 (9.214)	BT: 0.276 (9.508)	Loss 0.1565 (0.2458)	Prec@1 96.875 (92.087)	
Epoch: [25][155/391]	LR: 0.0004	DT: 0.000 (9.300)	BT: 0.271 (9.589)	Loss 0.2498 (0.2471)	Prec@1 92.969 (92.047)	
Epoch: [25][233/391]	LR: 0.0004	DT: 17.978 (9.328)	BT: 18.281 (9.616)	Loss 0.1255 (0.2473)	Prec@1 96.094 (92.114)	
Epoch: [25][311/391]	LR: 0.0004	DT: 0.000 (8.910)	BT: 0.264 (9.198)	Loss 0.2233 (0.2488)	Prec@1 91.406 (92.127)	
Epoch: [25][389/391]	LR: 0.0004	DT: 0.000 (9.059)	BT: 0.279 (9.348)	Loss 0.3040 (0.2489)	Prec@1 90.625 (92.167)	
Total train loss: 0.2490
Avg Loading time: 9.0360 seconds
Avg Batch time: 9.3248 seconds

Train time: 3646.066748857498
 * Prec@1 90.100 Prec@5 99.800 Loss 0.2937
Avg Loading time: 7.6764 seconds
Avg Batch time: 7.7836 seconds

Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 615.4483737945557

Epoch: [26][77/391]	LR: 0.0004	DT: 4.045 (9.177)	BT: 4.341 (9.471)	Loss 0.2184 (0.2428)	Prec@1 95.312 (92.157)	
Epoch: [26][155/391]	LR: 0.0004	DT: 0.000 (9.471)	BT: 0.315 (9.763)	Loss 0.1880 (0.2462)	Prec@1 93.750 (92.137)	
Epoch: [26][233/391]	LR: 0.0004	DT: 9.259 (9.589)	BT: 9.576 (9.879)	Loss 0.2406 (0.2498)	Prec@1 91.406 (92.087)	
Epoch: [26][311/391]	LR: 0.0004	DT: 0.000 (9.110)	BT: 0.271 (9.398)	Loss 0.2284 (0.2483)	Prec@1 92.969 (92.087)	
Epoch: [26][389/391]	LR: 0.0004	DT: 0.000 (9.179)	BT: 0.305 (9.466)	Loss 0.2468 (0.2485)	Prec@1 92.969 (92.065)	
Total train loss: 0.2485
Avg Loading time: 9.1552 seconds
Avg Batch time: 9.4427 seconds

Train time: 3692.1437854766846
 * Prec@1 90.260 Prec@5 99.760 Loss 0.2917
Avg Loading time: 8.8652 seconds
Avg Batch time: 8.9731 seconds

Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 709.5016603469849

Epoch: [27][77/391]	LR: 0.0004	DT: 0.000 (8.681)	BT: 0.287 (8.977)	Loss 0.2671 (0.2610)	Prec@1 92.188 (91.466)	
Epoch: [27][155/391]	LR: 0.0004	DT: 4.461 (8.913)	BT: 4.763 (9.209)	Loss 0.2673 (0.2527)	Prec@1 90.625 (91.777)	
Epoch: [27][233/391]	LR: 0.0004	DT: 0.000 (8.856)	BT: 0.369 (9.152)	Loss 0.1489 (0.2532)	Prec@1 96.094 (91.874)	
Epoch: [27][311/391]	LR: 0.0004	DT: 0.000 (8.466)	BT: 0.281 (8.761)	Loss 0.2317 (0.2509)	Prec@1 92.188 (91.957)	
Epoch: [27][389/391]	LR: 0.0004	DT: 2.615 (8.492)	BT: 2.928 (8.787)	Loss 0.2225 (0.2508)	Prec@1 92.188 (92.007)	
Total train loss: 0.2507
Avg Loading time: 8.4699 seconds
Avg Batch time: 8.7646 seconds

Train time: 3427.005487203598
 * Prec@1 90.250 Prec@5 99.810 Loss 0.2944
Avg Loading time: 8.4239 seconds
Avg Batch time: 8.5325 seconds

Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 676.3046309947968

Epoch: [28][77/391]	LR: 0.0004	DT: 0.000 (8.787)	BT: 0.260 (9.068)	Loss 0.2012 (0.2510)	Prec@1 94.531 (91.817)	
Epoch: [28][155/391]	LR: 0.0004	DT: 0.000 (8.923)	BT: 0.261 (9.203)	Loss 0.2925 (0.2496)	Prec@1 91.406 (92.022)	
Epoch: [28][233/391]	LR: 0.0004	DT: 0.000 (8.828)	BT: 0.274 (9.109)	Loss 0.3179 (0.2485)	Prec@1 89.062 (92.097)	
Epoch: [28][311/391]	LR: 0.0004	DT: 0.000 (8.383)	BT: 0.261 (8.664)	Loss 0.2693 (0.2468)	Prec@1 92.188 (92.182)	
Epoch: [28][389/391]	LR: 0.0004	DT: 0.000 (8.498)	BT: 0.256 (8.779)	Loss 0.2917 (0.2486)	Prec@1 92.188 (92.091)	
Total train loss: 0.2487
Avg Loading time: 8.4759 seconds
Avg Batch time: 8.7568 seconds

Train time: 3423.9443423748016
 * Prec@1 90.210 Prec@5 99.770 Loss 0.2930
Avg Loading time: 7.9063 seconds
Avg Batch time: 8.0192 seconds

Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 635.8153254985809

Epoch: [29][77/391]	LR: 0.0004	DT: 1.785 (8.776)	BT: 2.084 (9.067)	Loss 0.1937 (0.2538)	Prec@1 95.312 (91.607)	
Epoch: [29][155/391]	LR: 0.0004	DT: 0.000 (8.889)	BT: 0.282 (9.182)	Loss 0.2357 (0.2528)	Prec@1 92.969 (91.597)	
Epoch: [29][233/391]	LR: 0.0004	DT: 0.000 (8.729)	BT: 0.287 (9.022)	Loss 0.2223 (0.2522)	Prec@1 91.406 (91.683)	
Epoch: [29][311/391]	LR: 0.0004	DT: 0.000 (8.451)	BT: 0.272 (8.743)	Loss 0.2830 (0.2521)	Prec@1 91.406 (91.732)	
Epoch: [29][389/391]	LR: 0.0004	DT: 3.068 (8.514)	BT: 3.363 (8.806)	Loss 0.2405 (0.2506)	Prec@1 92.188 (91.819)	
Total train loss: 0.2505
Avg Loading time: 8.4923 seconds
Avg Batch time: 8.7837 seconds

Train time: 3434.48482298851
 * Prec@1 90.220 Prec@5 99.790 Loss 0.2922
Avg Loading time: 7.9164 seconds
Avg Batch time: 8.0232 seconds

Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 634.4840841293335

Epoch: [30][77/391]	LR: 8e-05	DT: 0.000 (8.997)	BT: 0.280 (9.289)	Loss 0.2808 (0.2491)	Prec@1 90.625 (92.097)	
Epoch: [30][155/391]	LR: 8e-05	DT: 0.000 (9.224)	BT: 0.263 (9.515)	Loss 0.1776 (0.2474)	Prec@1 95.312 (92.052)	
Epoch: [30][233/391]	LR: 8e-05	DT: 5.127 (9.143)	BT: 5.437 (9.435)	Loss 0.2698 (0.2483)	Prec@1 90.625 (92.027)	
Epoch: [30][311/391]	LR: 8e-05	DT: 5.384 (8.769)	BT: 5.672 (9.059)	Loss 0.2308 (0.2473)	Prec@1 92.188 (92.057)	
Epoch: [30][389/391]	LR: 8e-05	DT: 0.000 (8.810)	BT: 0.278 (9.102)	Loss 0.3462 (0.2472)	Prec@1 88.281 (92.033)	
Total train loss: 0.2473
Avg Loading time: 8.7873 seconds
Avg Batch time: 9.0788 seconds

Train time: 3549.858677625656
 * Prec@1 90.040 Prec@5 99.720 Loss 0.2957
Avg Loading time: 8.9299 seconds
Avg Batch time: 9.0406 seconds

Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 714.9001061916351

Epoch: [31][77/391]	LR: 8e-05	DT: 0.000 (8.616)	BT: 0.282 (8.909)	Loss 0.2092 (0.2414)	Prec@1 96.875 (92.608)	
Epoch: [31][155/391]	LR: 8e-05	DT: 0.000 (8.768)	BT: 0.275 (9.060)	Loss 0.2183 (0.2471)	Prec@1 96.875 (92.248)	
Epoch: [31][233/391]	LR: 8e-05	DT: 0.000 (8.691)	BT: 0.274 (8.982)	Loss 0.3013 (0.2463)	Prec@1 88.281 (92.204)	
Epoch: [31][311/391]	LR: 8e-05	DT: 0.000 (8.405)	BT: 0.269 (8.694)	Loss 0.2546 (0.2472)	Prec@1 89.062 (92.110)	
Epoch: [31][389/391]	LR: 8e-05	DT: 0.000 (8.462)	BT: 0.264 (8.751)	Loss 0.2656 (0.2482)	Prec@1 89.062 (92.061)	
Total train loss: 0.2481
Avg Loading time: 8.4407 seconds
Avg Batch time: 8.7291 seconds

Train time: 3413.1767814159393
 * Prec@1 90.120 Prec@5 99.780 Loss 0.2925
Avg Loading time: 8.4936 seconds
Avg Batch time: 8.6082 seconds

Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 682.4611456394196

Epoch: [32][77/391]	LR: 8e-05	DT: 0.000 (8.709)	BT: 0.277 (8.999)	Loss 0.1810 (0.2486)	Prec@1 96.094 (92.137)	
Epoch: [32][155/391]	LR: 8e-05	DT: 0.000 (8.960)	BT: 0.271 (9.249)	Loss 0.2952 (0.2502)	Prec@1 88.281 (92.147)	
Epoch: [32][233/391]	LR: 8e-05	DT: 0.000 (8.746)	BT: 0.262 (9.033)	Loss 0.2175 (0.2465)	Prec@1 90.625 (92.248)	
Epoch: [32][311/391]	LR: 8e-05	DT: 0.000 (8.392)	BT: 0.260 (8.679)	Loss 0.3132 (0.2476)	Prec@1 89.844 (92.225)	
Epoch: [32][389/391]	LR: 8e-05	DT: 0.000 (8.446)	BT: 0.262 (8.734)	Loss 0.2277 (0.2480)	Prec@1 92.969 (92.173)	
Total train loss: 0.2480
Avg Loading time: 8.4242 seconds
Avg Batch time: 8.7122 seconds

Train time: 3406.536251783371
 * Prec@1 89.990 Prec@5 99.850 Loss 0.2947
Avg Loading time: 7.1274 seconds
Avg Batch time: 7.2372 seconds

Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 572.2876214981079

Epoch: [33][77/391]	LR: 8e-05	DT: 0.000 (8.813)	BT: 0.261 (9.103)	Loss 0.1853 (0.2530)	Prec@1 96.094 (91.817)	
Epoch: [33][155/391]	LR: 8e-05	DT: 0.000 (8.986)	BT: 0.286 (9.276)	Loss 0.2021 (0.2527)	Prec@1 94.531 (91.797)	
Epoch: [33][233/391]	LR: 8e-05	DT: 15.103 (8.753)	BT: 15.403 (9.042)	Loss 0.2954 (0.2503)	Prec@1 92.188 (91.917)	
Epoch: [33][311/391]	LR: 8e-05	DT: 0.000 (8.428)	BT: 0.264 (8.717)	Loss 0.1942 (0.2490)	Prec@1 94.531 (92.042)	
Epoch: [33][389/391]	LR: 8e-05	DT: 0.000 (8.520)	BT: 0.274 (8.809)	Loss 0.2325 (0.2489)	Prec@1 94.531 (92.087)	
Total train loss: 0.2489
Avg Loading time: 8.4981 seconds
Avg Batch time: 8.7867 seconds

Train time: 3435.6486513614655
 * Prec@1 90.190 Prec@5 99.790 Loss 0.2925
Avg Loading time: 7.9239 seconds
Avg Batch time: 8.0314 seconds

Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 635.1031861305237

Epoch: [34][77/391]	LR: 8e-05	DT: 0.000 (8.556)	BT: 0.260 (8.841)	Loss 0.2515 (0.2535)	Prec@1 93.750 (92.017)	
Epoch: [34][155/391]	LR: 8e-05	DT: 0.000 (8.759)	BT: 0.273 (9.043)	Loss 0.2598 (0.2523)	Prec@1 94.531 (91.857)	
Epoch: [34][233/391]	LR: 8e-05	DT: 12.878 (8.697)	BT: 13.159 (8.982)	Loss 0.2450 (0.2493)	Prec@1 92.188 (91.960)	
Epoch: [34][311/391]	LR: 8e-05	DT: 0.000 (8.420)	BT: 0.262 (8.705)	Loss 0.2612 (0.2486)	Prec@1 92.969 (91.980)	
Epoch: [34][389/391]	LR: 8e-05	DT: 0.000 (8.603)	BT: 0.277 (8.889)	Loss 0.2166 (0.2491)	Prec@1 92.969 (91.985)	
Total train loss: 0.2494
Avg Loading time: 8.5812 seconds
Avg Batch time: 8.8669 seconds

Train time: 3467.055278301239
 * Prec@1 90.230 Prec@5 99.770 Loss 0.2920
Avg Loading time: 9.4770 seconds
Avg Batch time: 9.5888 seconds

Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 759.728556394577

Epoch: [35][77/391]	LR: 8e-05	DT: 0.000 (8.937)	BT: 0.261 (9.231)	Loss 0.1826 (0.2367)	Prec@1 91.406 (92.468)	
Epoch: [35][155/391]	LR: 8e-05	DT: 6.886 (9.148)	BT: 7.203 (9.440)	Loss 0.2837 (0.2456)	Prec@1 89.062 (92.162)	
Epoch: [35][233/391]	LR: 8e-05	DT: 6.201 (8.886)	BT: 6.536 (9.177)	Loss 0.2732 (0.2471)	Prec@1 91.406 (92.144)	
Epoch: [35][311/391]	LR: 8e-05	DT: 0.000 (8.615)	BT: 0.263 (8.905)	Loss 0.1842 (0.2475)	Prec@1 96.094 (92.097)	
Epoch: [35][389/391]	LR: 8e-05	DT: 0.000 (8.634)	BT: 0.260 (8.924)	Loss 0.2194 (0.2473)	Prec@1 93.750 (92.141)	
Total train loss: 0.2473
Avg Loading time: 8.6120 seconds
Avg Batch time: 8.9012 seconds

Train time: 3480.4114339351654
 * Prec@1 90.260 Prec@5 99.810 Loss 0.2915
Avg Loading time: 8.3050 seconds
Avg Batch time: 8.4198 seconds

Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 667.5186049938202

Epoch: [36][77/391]	LR: 8e-05	DT: 0.000 (9.089)	BT: 0.271 (9.380)	Loss 0.1931 (0.2513)	Prec@1 95.312 (91.536)	
Epoch: [36][155/391]	LR: 8e-05	DT: 0.000 (9.310)	BT: 0.264 (9.601)	Loss 0.2286 (0.2462)	Prec@1 92.188 (92.037)	
Epoch: [36][233/391]	LR: 8e-05	DT: 11.538 (9.056)	BT: 11.848 (9.346)	Loss 0.3196 (0.2483)	Prec@1 90.625 (92.001)	
Epoch: [36][311/391]	LR: 8e-05	DT: 0.000 (8.704)	BT: 0.272 (8.994)	Loss 0.2600 (0.2495)	Prec@1 89.844 (91.905)	
Epoch: [36][389/391]	LR: 8e-05	DT: 0.000 (8.838)	BT: 0.265 (9.128)	Loss 0.2629 (0.2507)	Prec@1 91.406 (91.865)	
Total train loss: 0.2507
Avg Loading time: 8.8156 seconds
Avg Batch time: 9.1050 seconds

Train time: 3560.088935613632
 * Prec@1 90.270 Prec@5 99.770 Loss 0.2932
Avg Loading time: 8.7268 seconds
Avg Batch time: 8.8384 seconds

Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 698.8647336959839

Epoch: [37][77/391]	LR: 8e-05	DT: 0.000 (9.789)	BT: 0.269 (10.079)	Loss 0.2561 (0.2436)	Prec@1 90.625 (92.017)	
Epoch: [37][155/391]	LR: 8e-05	DT: 0.000 (9.658)	BT: 0.315 (9.949)	Loss 0.2050 (0.2479)	Prec@1 96.094 (91.947)	
Epoch: [37][233/391]	LR: 8e-05	DT: 0.000 (9.172)	BT: 0.292 (9.463)	Loss 0.2111 (0.2487)	Prec@1 93.750 (91.894)	
Epoch: [37][311/391]	LR: 8e-05	DT: 0.000 (8.791)	BT: 0.261 (9.080)	Loss 0.3701 (0.2483)	Prec@1 86.719 (91.982)	
Epoch: [37][389/391]	LR: 8e-05	DT: 0.000 (8.834)	BT: 0.271 (9.124)	Loss 0.1824 (0.2496)	Prec@1 95.312 (91.947)	
Total train loss: 0.2497
Avg Loading time: 8.8115 seconds
Avg Batch time: 9.1009 seconds

Train time: 3558.515483379364
 * Prec@1 90.170 Prec@5 99.770 Loss 0.2927
Avg Loading time: 8.1396 seconds
Avg Batch time: 8.2465 seconds

Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 652.0969750881195

Epoch: [38][77/391]	LR: 8e-05	DT: 0.206 (8.501)	BT: 0.513 (8.799)	Loss 0.2358 (0.2522)	Prec@1 90.625 (91.597)	
Epoch: [38][155/391]	LR: 8e-05	DT: 0.000 (8.624)	BT: 0.268 (8.917)	Loss 0.3193 (0.2512)	Prec@1 88.281 (91.787)	
Epoch: [38][233/391]	LR: 8e-05	DT: 0.000 (8.510)	BT: 0.385 (8.803)	Loss 0.2332 (0.2515)	Prec@1 92.969 (91.804)	
Epoch: [38][311/391]	LR: 8e-05	DT: 1.698 (8.333)	BT: 2.004 (8.626)	Loss 0.2448 (0.2505)	Prec@1 91.406 (91.940)	
Epoch: [38][389/391]	LR: 8e-05	DT: 0.659 (8.488)	BT: 0.965 (8.780)	Loss 0.2908 (0.2488)	Prec@1 90.625 (92.035)	
Total train loss: 0.2488
Avg Loading time: 8.4661 seconds
Avg Batch time: 8.7584 seconds

Train time: 3424.598312139511
 * Prec@1 90.350 Prec@5 99.770 Loss 0.2930
Avg Loading time: 9.4601 seconds
Avg Batch time: 9.5697 seconds

Best acc: 90.350
--------------------------------------------------------------------------------
Test time: 758.8999283313751

Epoch: [39][77/391]	LR: 8e-05	DT: 0.000 (8.235)	BT: 0.273 (8.521)	Loss 0.2164 (0.2534)	Prec@1 92.188 (92.177)	
Epoch: [39][155/391]	LR: 8e-05	DT: 0.000 (7.587)	BT: 0.241 (7.866)	Loss 0.2163 (0.2484)	Prec@1 92.188 (92.323)	
Epoch: [39][233/391]	LR: 8e-05	DT: 4.467 (7.139)	BT: 4.766 (7.418)	Loss 0.2067 (0.2473)	Prec@1 92.969 (92.371)	
Epoch: [39][311/391]	LR: 8e-05	DT: 0.000 (6.704)	BT: 0.263 (6.984)	Loss 0.2245 (0.2463)	Prec@1 92.969 (92.400)	
Epoch: [39][389/391]	LR: 8e-05	DT: 0.000 (6.588)	BT: 0.269 (6.868)	Loss 0.2209 (0.2482)	Prec@1 96.094 (92.220)	
Total train loss: 0.2485
Avg Loading time: 6.5707 seconds
Avg Batch time: 6.8512 seconds

Train time: 2678.8941299915314
 * Prec@1 90.140 Prec@5 99.780 Loss 0.2915
Avg Loading time: 5.7890 seconds
Avg Batch time: 5.9008 seconds

Best acc: 90.350
--------------------------------------------------------------------------------
Test time: 466.75535225868225

Epoch: [40][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (4.788)	BT: 0.269 (5.076)	Loss 0.1870 (0.2489)	Prec@1 93.750 (92.278)	
Epoch: [40][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (4.986)	BT: 0.281 (5.278)	Loss 0.2075 (0.2521)	Prec@1 92.969 (91.952)	
Epoch: [40][233/391]	LR: 1.6000000000000003e-05	DT: 9.928 (5.185)	BT: 10.249 (5.477)	Loss 0.2886 (0.2465)	Prec@1 91.406 (92.181)	
Epoch: [40][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.236)	BT: 0.262 (5.528)	Loss 0.3245 (0.2492)	Prec@1 92.188 (92.110)	
Epoch: [40][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.206)	BT: 0.278 (5.497)	Loss 0.1815 (0.2478)	Prec@1 92.188 (92.119)	
Total train loss: 0.2478
Avg Loading time: 5.1924 seconds
Avg Batch time: 5.4836 seconds

Train time: 2144.1890511512756
 * Prec@1 90.180 Prec@5 99.760 Loss 0.2920
Avg Loading time: 5.9996 seconds
Avg Batch time: 6.1137 seconds

Best acc: 90.350
--------------------------------------------------------------------------------
Test time: 484.62182807922363

Epoch: [41][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (4.884)	BT: 0.281 (5.175)	Loss 0.3213 (0.2426)	Prec@1 90.625 (92.218)	
Epoch: [41][155/391]	LR: 1.6000000000000003e-05	DT: 1.747 (5.023)	BT: 2.044 (5.314)	Loss 0.3579 (0.2517)	Prec@1 86.719 (91.787)	
Epoch: [41][233/391]	LR: 1.6000000000000003e-05	DT: 0.372 (5.200)	BT: 0.681 (5.492)	Loss 0.2178 (0.2521)	Prec@1 92.969 (91.814)	
Epoch: [41][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.268)	BT: 0.283 (5.559)	Loss 0.2769 (0.2520)	Prec@1 88.281 (91.774)	
Epoch: [41][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.233)	BT: 0.279 (5.522)	Loss 0.2001 (0.2530)	Prec@1 94.531 (91.813)	
Total train loss: 0.2530
Avg Loading time: 5.2194 seconds
Avg Batch time: 5.5084 seconds

Train time: 2153.884129524231
 * Prec@1 90.170 Prec@5 99.810 Loss 0.2913
Avg Loading time: 6.0203 seconds
Avg Batch time: 6.1279 seconds

Best acc: 90.350
--------------------------------------------------------------------------------
Test time: 484.67173504829407

Epoch: [42][77/391]	LR: 1.6000000000000003e-05	DT: 5.763 (4.995)	BT: 6.065 (5.283)	Loss 0.2644 (0.2567)	Prec@1 88.281 (91.667)	
Epoch: [42][155/391]	LR: 1.6000000000000003e-05	DT: 0.606 (5.049)	BT: 0.926 (5.338)	Loss 0.1892 (0.2546)	Prec@1 96.094 (91.637)	
Epoch: [42][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.226)	BT: 0.265 (5.515)	Loss 0.1964 (0.2501)	Prec@1 93.750 (91.940)	
Epoch: [42][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.315)	BT: 0.263 (5.605)	Loss 0.2345 (0.2498)	Prec@1 91.406 (91.982)	
Epoch: [42][389/391]	LR: 1.6000000000000003e-05	DT: 4.633 (5.249)	BT: 4.938 (5.539)	Loss 0.2439 (0.2493)	Prec@1 93.750 (92.025)	
Total train loss: 0.2491
Avg Loading time: 5.2353 seconds
Avg Batch time: 5.5248 seconds

Train time: 2160.2787387371063
 * Prec@1 90.290 Prec@5 99.780 Loss 0.2917
Avg Loading time: 6.0732 seconds
Avg Batch time: 6.1841 seconds

Best acc: 90.350
--------------------------------------------------------------------------------
Test time: 489.10348677635193

Epoch: [43][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (4.912)	BT: 0.273 (5.200)	Loss 0.2231 (0.2467)	Prec@1 90.625 (92.037)	
Epoch: [43][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.067)	BT: 0.271 (5.356)	Loss 0.2825 (0.2463)	Prec@1 93.750 (91.962)	
Epoch: [43][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.229)	BT: 0.275 (5.517)	Loss 0.2206 (0.2483)	Prec@1 94.531 (91.834)	
Epoch: [43][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.349)	BT: 0.260 (5.637)	Loss 0.1519 (0.2468)	Prec@1 97.656 (91.927)	
Epoch: [43][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.277)	BT: 0.285 (5.565)	Loss 0.2242 (0.2475)	Prec@1 93.750 (91.943)	
Total train loss: 0.2476
Avg Loading time: 5.2635 seconds
Avg Batch time: 5.5514 seconds

Train time: 2170.676380634308
 * Prec@1 90.150 Prec@5 99.790 Loss 0.2915
Avg Loading time: 6.1438 seconds
Avg Batch time: 6.2555 seconds

Best acc: 90.350
--------------------------------------------------------------------------------
Test time: 495.8382017612457

Epoch: [44][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (4.978)	BT: 0.281 (5.262)	Loss 0.2559 (0.2518)	Prec@1 92.188 (92.107)	
Epoch: [44][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.285)	BT: 0.274 (5.570)	Loss 0.2434 (0.2492)	Prec@1 92.188 (92.047)	
Epoch: [44][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.383)	BT: 0.280 (5.668)	Loss 0.1997 (0.2514)	Prec@1 93.750 (91.930)	
Epoch: [44][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.383)	BT: 0.259 (5.668)	Loss 0.2185 (0.2513)	Prec@1 93.750 (91.915)	
Epoch: [44][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.289)	BT: 0.281 (5.573)	Loss 0.2573 (0.2492)	Prec@1 89.844 (91.957)	
Total train loss: 0.2495
Avg Loading time: 5.2759 seconds
Avg Batch time: 5.5597 seconds

Train time: 2173.9328162670135
 * Prec@1 90.180 Prec@5 99.790 Loss 0.2925
Avg Loading time: 6.0747 seconds
Avg Batch time: 6.1867 seconds

Best acc: 90.350
--------------------------------------------------------------------------------
Test time: 489.28566789627075

Epoch: [45][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (4.764)	BT: 0.269 (5.056)	Loss 0.2705 (0.2505)	Prec@1 92.188 (91.987)	
Epoch: [45][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (4.957)	BT: 0.261 (5.248)	Loss 0.2898 (0.2508)	Prec@1 90.625 (91.937)	
Epoch: [45][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.105)	BT: 0.270 (5.394)	Loss 0.2386 (0.2478)	Prec@1 93.750 (92.007)	
Epoch: [45][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.176)	BT: 0.261 (5.466)	Loss 0.2198 (0.2503)	Prec@1 92.969 (91.915)	
Epoch: [45][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.135)	BT: 0.280 (5.424)	Loss 0.3052 (0.2504)	Prec@1 91.406 (91.949)	
Total train loss: 0.2504
Avg Loading time: 5.1219 seconds
Avg Batch time: 5.4106 seconds

Train time: 2115.5884294509888
 * Prec@1 90.200 Prec@5 99.800 Loss 0.2920
Avg Loading time: 6.1349 seconds
Avg Batch time: 6.2448 seconds

Best acc: 90.350
--------------------------------------------------------------------------------
Test time: 493.90961956977844

