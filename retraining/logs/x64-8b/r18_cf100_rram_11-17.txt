
      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 0
          frozen_layers: 11
Savedir:  ../pretrained_models/frozen/x64-8b/rram/cifar100/resnet18
DEVICE: cuda
GPU Id(s) being used: 0
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar100/resnet18/train/relu11
Test path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar100/resnet18/test/relu11
ResNet18(
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=100, bias=False)
  (bn19): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 0.960 Prec@5 5.160 Loss 4.5898
Avg Loading time: 1.9258 seconds
Avg Batch time: 1.9436 seconds

Pre-trained Prec@1 with 11 layers frozen: 0.9599999785423279 	 Loss: 4.58984375

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (2.750)	BT: 0.027 (2.780)	Loss 1.8213 (2.3830)	Prec@1 50.000 (41.577)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (2.863)	BT: 0.024 (2.892)	Loss 1.6064 (2.0434)	Prec@1 60.156 (47.671)	
Epoch: [0][233/391]	LR: 0.1	DT: 3.334 (3.069)	BT: 3.368 (3.097)	Loss 1.5303 (1.8802)	Prec@1 57.812 (50.765)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (3.063)	BT: 0.024 (3.091)	Loss 1.2617 (1.7632)	Prec@1 67.969 (53.295)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (3.120)	BT: 0.025 (3.148)	Loss 1.3086 (1.6879)	Prec@1 63.281 (54.860)	
Total train loss: 1.6875
Avg Loading time: 3.1120 seconds
Avg Batch time: 3.1399 seconds

Train time: 1227.805294752121
 * Prec@1 61.960 Prec@5 89.210 Loss 1.3379
Avg Loading time: 1.4965 seconds
Avg Batch time: 1.5053 seconds

Best acc: 61.960
--------------------------------------------------------------------------------
Test time: 119.89859509468079

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (1.372)	BT: 0.024 (1.399)	Loss 1.0605 (1.0038)	Prec@1 71.094 (71.234)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.760)	BT: 0.026 (0.786)	Loss 0.9502 (1.0135)	Prec@1 71.875 (70.668)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.535)	BT: 0.025 (0.561)	Loss 0.9097 (1.0254)	Prec@1 75.781 (70.262)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.426)	BT: 0.023 (0.452)	Loss 1.1553 (1.0346)	Prec@1 67.188 (69.937)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.733 (0.362)	BT: 0.755 (0.388)	Loss 1.0146 (1.0351)	Prec@1 67.969 (69.848)	
Total train loss: 1.0356
Avg Loading time: 0.3610 seconds
Avg Batch time: 0.3871 seconds

Train time: 151.44807887077332
 * Prec@1 65.650 Prec@5 90.110 Loss 1.2236
Avg Loading time: 0.1286 seconds
Avg Batch time: 0.1385 seconds

Best acc: 65.650
--------------------------------------------------------------------------------
Test time: 12.024914979934692

Epoch: [2][77/391]	LR: 0.1	DT: 0.044 (0.121)	BT: 0.065 (0.148)	Loss 0.7051 (0.6742)	Prec@1 80.469 (80.288)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.109)	BT: 0.021 (0.136)	Loss 0.6826 (0.6810)	Prec@1 80.469 (79.818)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.003 (0.107)	BT: 0.030 (0.135)	Loss 0.7666 (0.6988)	Prec@1 77.344 (79.110)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.111)	BT: 0.026 (0.139)	Loss 0.8447 (0.7156)	Prec@1 71.875 (78.606)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.106)	BT: 0.030 (0.133)	Loss 0.8232 (0.7364)	Prec@1 71.094 (77.977)	
Total train loss: 0.7366
Avg Loading time: 0.1054 seconds
Avg Batch time: 0.1328 seconds

Train time: 52.08683395385742
 * Prec@1 66.310 Prec@5 90.380 Loss 1.2197
Avg Loading time: 0.1203 seconds
Avg Batch time: 0.1299 seconds

Best acc: 66.310
--------------------------------------------------------------------------------
Test time: 11.252119541168213

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.124)	BT: 0.026 (0.151)	Loss 0.3579 (0.4275)	Prec@1 89.844 (87.660)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.358 (0.115)	BT: 0.385 (0.141)	Loss 0.4539 (0.4572)	Prec@1 85.156 (86.503)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.112)	BT: 0.022 (0.139)	Loss 0.3647 (0.4754)	Prec@1 89.062 (85.841)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.110)	BT: 0.041 (0.137)	Loss 0.6279 (0.5024)	Prec@1 81.250 (84.806)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.110)	BT: 0.022 (0.137)	Loss 0.5391 (0.5208)	Prec@1 83.594 (84.201)	
Total train loss: 0.5211
Avg Loading time: 0.1096 seconds
Avg Batch time: 0.1363 seconds

Train time: 53.4696569442749
 * Prec@1 65.300 Prec@5 89.520 Loss 1.3174
Avg Loading time: 0.1463 seconds
Avg Batch time: 0.1561 seconds

Best acc: 66.310
--------------------------------------------------------------------------------
Test time: 12.959051609039307

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.105)	BT: 0.055 (0.132)	Loss 0.4062 (0.3189)	Prec@1 87.500 (90.515)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.105)	BT: 0.022 (0.131)	Loss 0.3291 (0.3232)	Prec@1 90.625 (90.315)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.096)	BT: 0.040 (0.122)	Loss 0.2629 (0.3351)	Prec@1 89.844 (89.884)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.101)	BT: 0.022 (0.126)	Loss 0.4729 (0.3519)	Prec@1 85.156 (89.320)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.104)	BT: 0.025 (0.129)	Loss 0.5337 (0.3735)	Prec@1 85.156 (88.586)	
Total train loss: 0.3738
Avg Loading time: 0.1033 seconds
Avg Batch time: 0.1285 seconds

Train time: 50.427475929260254
 * Prec@1 62.780 Prec@5 87.590 Loss 1.5195
Avg Loading time: 0.1296 seconds
Avg Batch time: 0.1404 seconds

Best acc: 66.310
--------------------------------------------------------------------------------
Test time: 11.666574478149414

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.088)	BT: 0.028 (0.115)	Loss 0.2079 (0.2400)	Prec@1 92.188 (93.109)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.085)	BT: 0.021 (0.112)	Loss 0.3364 (0.2411)	Prec@1 90.625 (92.959)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.000 (0.084)	BT: 0.036 (0.112)	Loss 0.2720 (0.2480)	Prec@1 90.625 (92.688)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.091)	BT: 0.022 (0.119)	Loss 0.3425 (0.2582)	Prec@1 89.062 (92.288)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.091)	BT: 0.021 (0.118)	Loss 0.3025 (0.2711)	Prec@1 89.844 (91.781)	
Total train loss: 0.2711
Avg Loading time: 0.0905 seconds
Avg Batch time: 0.1175 seconds

Train time: 46.0578498840332
 * Prec@1 65.570 Prec@5 88.580 Loss 1.4385
Avg Loading time: 0.0839 seconds
Avg Batch time: 0.0937 seconds

Best acc: 66.310
--------------------------------------------------------------------------------
Test time: 8.035387516021729

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.098)	BT: 0.021 (0.123)	Loss 0.2086 (0.2013)	Prec@1 92.969 (94.081)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.095)	BT: 0.052 (0.120)	Loss 0.2659 (0.1958)	Prec@1 89.062 (94.276)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.095)	BT: 0.026 (0.121)	Loss 0.1768 (0.1961)	Prec@1 95.312 (94.191)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.021 (0.094)	BT: 0.044 (0.119)	Loss 0.2440 (0.2040)	Prec@1 91.406 (93.890)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.099)	BT: 0.026 (0.125)	Loss 0.1995 (0.2135)	Prec@1 93.750 (93.578)	
Total train loss: 0.2138
Avg Loading time: 0.0986 seconds
Avg Batch time: 0.1245 seconds

Train time: 48.80154585838318
 * Prec@1 66.050 Prec@5 88.130 Loss 1.4648
Avg Loading time: 0.1152 seconds
Avg Batch time: 0.1255 seconds

Best acc: 66.310
--------------------------------------------------------------------------------
Test time: 10.52269172668457

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.093)	BT: 0.021 (0.119)	Loss 0.1545 (0.1530)	Prec@1 95.312 (95.623)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.090)	BT: 0.026 (0.116)	Loss 0.2009 (0.1480)	Prec@1 92.188 (95.703)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.080)	BT: 0.024 (0.106)	Loss 0.1611 (0.1540)	Prec@1 95.312 (95.489)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.080)	BT: 0.021 (0.106)	Loss 0.1682 (0.1619)	Prec@1 94.531 (95.235)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.083)	BT: 0.028 (0.109)	Loss 0.1444 (0.1694)	Prec@1 95.312 (94.960)	
Total train loss: 0.1695
Avg Loading time: 0.0826 seconds
Avg Batch time: 0.1086 seconds

Train time: 42.64938426017761
 * Prec@1 66.690 Prec@5 88.360 Loss 1.4238
Avg Loading time: 0.1286 seconds
Avg Batch time: 0.1395 seconds

Best acc: 66.690
--------------------------------------------------------------------------------
Test time: 12.015244960784912

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.113)	BT: 0.026 (0.140)	Loss 0.1536 (0.1092)	Prec@1 94.531 (97.035)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.111)	BT: 0.027 (0.137)	Loss 0.1054 (0.1126)	Prec@1 97.656 (97.030)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.099)	BT: 0.021 (0.126)	Loss 0.1582 (0.1156)	Prec@1 94.531 (96.895)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.108)	BT: 0.036 (0.134)	Loss 0.1472 (0.1200)	Prec@1 95.312 (96.750)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.063 (0.119)	BT: 0.092 (0.145)	Loss 0.1316 (0.1255)	Prec@1 94.531 (96.565)	
Total train loss: 0.1258
Avg Loading time: 0.1183 seconds
Avg Batch time: 0.1446 seconds

Train time: 56.641088008880615
 * Prec@1 66.940 Prec@5 87.610 Loss 1.4766
Avg Loading time: 0.1615 seconds
Avg Batch time: 0.1722 seconds

Best acc: 66.940
--------------------------------------------------------------------------------
Test time: 14.692118883132935

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.148)	BT: 0.024 (0.174)	Loss 0.0486 (0.0993)	Prec@1 99.219 (97.296)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.159)	BT: 0.024 (0.185)	Loss 0.0563 (0.0992)	Prec@1 97.656 (97.316)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.107 (0.162)	BT: 0.146 (0.189)	Loss 0.1082 (0.1016)	Prec@1 96.875 (97.232)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.157)	BT: 0.022 (0.184)	Loss 0.0916 (0.1055)	Prec@1 98.438 (97.090)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.165)	BT: 0.025 (0.192)	Loss 0.1566 (0.1088)	Prec@1 96.875 (97.013)	
Total train loss: 0.1089
Avg Loading time: 0.1649 seconds
Avg Batch time: 0.1916 seconds

Train time: 75.09487318992615
 * Prec@1 66.150 Prec@5 88.110 Loss 1.5049
Avg Loading time: 0.2324 seconds
Avg Batch time: 0.2434 seconds

Best acc: 66.940
--------------------------------------------------------------------------------
Test time: 19.84775948524475

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.214)	BT: 0.022 (0.242)	Loss 0.0196 (0.0698)	Prec@1 100.000 (98.227)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.184)	BT: 0.022 (0.210)	Loss 0.0321 (0.0617)	Prec@1 99.219 (98.493)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.163)	BT: 0.028 (0.189)	Loss 0.0275 (0.0555)	Prec@1 100.000 (98.721)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.149)	BT: 0.023 (0.174)	Loss 0.0192 (0.0510)	Prec@1 100.000 (98.876)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.147)	BT: 0.022 (0.173)	Loss 0.0266 (0.0485)	Prec@1 100.000 (98.940)	
Total train loss: 0.0485
Avg Loading time: 0.1462 seconds
Avg Batch time: 0.1722 seconds

Train time: 67.4975368976593
 * Prec@1 71.530 Prec@5 90.230 Loss 1.2393
Avg Loading time: 0.1162 seconds
Avg Batch time: 0.1273 seconds

Best acc: 71.530
--------------------------------------------------------------------------------
Test time: 11.102558612823486

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.070)	BT: 0.023 (0.098)	Loss 0.0171 (0.0231)	Prec@1 100.000 (99.730)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.051)	BT: 0.035 (0.082)	Loss 0.0251 (0.0225)	Prec@1 99.219 (99.735)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.045)	BT: 0.021 (0.076)	Loss 0.0127 (0.0222)	Prec@1 100.000 (99.716)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.038)	BT: 0.039 (0.069)	Loss 0.0191 (0.0219)	Prec@1 99.219 (99.725)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.032)	BT: 0.020 (0.063)	Loss 0.0447 (0.0219)	Prec@1 98.438 (99.718)	
Total train loss: 0.0219
Avg Loading time: 0.0323 seconds
Avg Batch time: 0.0632 seconds

Train time: 24.921898126602173
 * Prec@1 72.280 Prec@5 90.570 Loss 1.2266
Avg Loading time: 0.0812 seconds
Avg Batch time: 0.0931 seconds

Best acc: 72.280
--------------------------------------------------------------------------------
Test time: 8.384633779525757

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.087)	BT: 0.022 (0.114)	Loss 0.0359 (0.0163)	Prec@1 99.219 (99.810)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.072)	BT: 0.022 (0.097)	Loss 0.0088 (0.0165)	Prec@1 100.000 (99.835)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.339 (0.067)	BT: 0.364 (0.093)	Loss 0.0206 (0.0166)	Prec@1 99.219 (99.830)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.072)	BT: 0.032 (0.099)	Loss 0.0160 (0.0165)	Prec@1 100.000 (99.835)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.070)	BT: 0.029 (0.097)	Loss 0.0117 (0.0166)	Prec@1 100.000 (99.824)	
Total train loss: 0.0166
Avg Loading time: 0.0702 seconds
Avg Batch time: 0.0969 seconds

Train time: 38.07675790786743
 * Prec@1 72.160 Prec@5 90.330 Loss 1.2119
Avg Loading time: 0.1326 seconds
Avg Batch time: 0.1434 seconds

Best acc: 72.280
--------------------------------------------------------------------------------
Test time: 11.916112899780273

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.097)	BT: 0.022 (0.124)	Loss 0.0121 (0.0149)	Prec@1 100.000 (99.880)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.274 (0.085)	BT: 0.308 (0.112)	Loss 0.0110 (0.0144)	Prec@1 100.000 (99.885)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.093 (0.079)	BT: 0.120 (0.106)	Loss 0.0139 (0.0144)	Prec@1 100.000 (99.876)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.265 (0.078)	BT: 0.286 (0.105)	Loss 0.0071 (0.0145)	Prec@1 100.000 (99.872)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.080)	BT: 0.037 (0.107)	Loss 0.0233 (0.0143)	Prec@1 99.219 (99.868)	
Total train loss: 0.0143
Avg Loading time: 0.0800 seconds
Avg Batch time: 0.1070 seconds

Train time: 42.00973916053772
 * Prec@1 72.380 Prec@5 90.590 Loss 1.2236
Avg Loading time: 0.0841 seconds
Avg Batch time: 0.0947 seconds

Best acc: 72.380
--------------------------------------------------------------------------------
Test time: 8.594850063323975

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.068)	BT: 0.022 (0.097)	Loss 0.0076 (0.0136)	Prec@1 100.000 (99.870)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.058)	BT: 0.025 (0.087)	Loss 0.0118 (0.0131)	Prec@1 100.000 (99.885)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.062)	BT: 0.028 (0.090)	Loss 0.0094 (0.0132)	Prec@1 100.000 (99.863)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.064)	BT: 0.034 (0.092)	Loss 0.0085 (0.0131)	Prec@1 100.000 (99.880)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.070)	BT: 0.021 (0.097)	Loss 0.0167 (0.0128)	Prec@1 100.000 (99.896)	
Total train loss: 0.0128
Avg Loading time: 0.0696 seconds
Avg Batch time: 0.0967 seconds

Train time: 37.9333393573761
 * Prec@1 72.330 Prec@5 90.450 Loss 1.2266
Avg Loading time: 0.0979 seconds
Avg Batch time: 0.1091 seconds

Best acc: 72.380
--------------------------------------------------------------------------------
Test time: 9.300978183746338

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.063)	BT: 0.021 (0.091)	Loss 0.0070 (0.0108)	Prec@1 100.000 (99.940)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.073)	BT: 0.021 (0.099)	Loss 0.0122 (0.0108)	Prec@1 100.000 (99.940)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.070)	BT: 0.031 (0.096)	Loss 0.0056 (0.0109)	Prec@1 100.000 (99.923)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.059)	BT: 0.021 (0.086)	Loss 0.0109 (0.0107)	Prec@1 100.000 (99.930)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.079 (0.062)	BT: 0.105 (0.089)	Loss 0.0049 (0.0108)	Prec@1 100.000 (99.928)	
Total train loss: 0.0108
Avg Loading time: 0.0618 seconds
Avg Batch time: 0.0891 seconds

Train time: 35.06736874580383
 * Prec@1 72.230 Prec@5 90.500 Loss 1.2217
Avg Loading time: 0.0772 seconds
Avg Batch time: 0.0898 seconds

Best acc: 72.380
--------------------------------------------------------------------------------
Test time: 7.773950576782227

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.056)	BT: 0.037 (0.086)	Loss 0.0136 (0.0098)	Prec@1 100.000 (99.980)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.059)	BT: 0.026 (0.087)	Loss 0.0087 (0.0104)	Prec@1 100.000 (99.945)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.059)	BT: 0.040 (0.087)	Loss 0.0058 (0.0105)	Prec@1 100.000 (99.917)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.003 (0.056)	BT: 0.031 (0.084)	Loss 0.0135 (0.0108)	Prec@1 100.000 (99.905)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.051)	BT: 0.021 (0.080)	Loss 0.0107 (0.0107)	Prec@1 100.000 (99.910)	
Total train loss: 0.0107
Avg Loading time: 0.0513 seconds
Avg Batch time: 0.0797 seconds

Train time: 31.337472677230835
 * Prec@1 72.330 Prec@5 90.490 Loss 1.2227
Avg Loading time: 0.0471 seconds
Avg Batch time: 0.0593 seconds

Best acc: 72.380
--------------------------------------------------------------------------------
Test time: 5.356050491333008

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.036)	BT: 0.027 (0.066)	Loss 0.0117 (0.0102)	Prec@1 100.000 (99.940)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.024)	BT: 0.030 (0.054)	Loss 0.0107 (0.0103)	Prec@1 100.000 (99.945)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.043 (0.051)	Loss 0.0092 (0.0100)	Prec@1 100.000 (99.953)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.033)	BT: 0.024 (0.062)	Loss 0.0052 (0.0102)	Prec@1 100.000 (99.945)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.039)	BT: 0.026 (0.068)	Loss 0.0054 (0.0102)	Prec@1 100.000 (99.950)	
Total train loss: 0.0102
Avg Loading time: 0.0393 seconds
Avg Batch time: 0.0682 seconds

Train time: 26.861854553222656
 * Prec@1 72.280 Prec@5 90.410 Loss 1.2227
Avg Loading time: 0.0627 seconds
Avg Batch time: 0.0759 seconds

Best acc: 72.380
--------------------------------------------------------------------------------
Test time: 6.648494243621826

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.072)	BT: 0.041 (0.099)	Loss 0.0102 (0.0103)	Prec@1 100.000 (99.920)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.075)	BT: 0.021 (0.104)	Loss 0.0126 (0.0094)	Prec@1 100.000 (99.955)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.068)	BT: 0.022 (0.096)	Loss 0.0048 (0.0094)	Prec@1 100.000 (99.947)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.064)	BT: 0.029 (0.092)	Loss 0.0066 (0.0095)	Prec@1 100.000 (99.942)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.063)	BT: 0.021 (0.091)	Loss 0.0075 (0.0093)	Prec@1 100.000 (99.948)	
Total train loss: 0.0093
Avg Loading time: 0.0633 seconds
Avg Batch time: 0.0907 seconds

Train time: 35.613733768463135
 * Prec@1 72.380 Prec@5 90.600 Loss 1.2217
Avg Loading time: 0.0871 seconds
Avg Batch time: 0.0984 seconds

Best acc: 72.380
--------------------------------------------------------------------------------
Test time: 8.336324691772461

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.063)	BT: 0.024 (0.088)	Loss 0.0042 (0.0084)	Prec@1 100.000 (99.950)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.075)	BT: 0.022 (0.101)	Loss 0.0040 (0.0090)	Prec@1 100.000 (99.940)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.598 (0.072)	BT: 0.621 (0.099)	Loss 0.0067 (0.0092)	Prec@1 100.000 (99.933)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.072)	BT: 0.020 (0.099)	Loss 0.0053 (0.0092)	Prec@1 100.000 (99.930)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.070)	BT: 0.021 (0.097)	Loss 0.0110 (0.0089)	Prec@1 100.000 (99.940)	
Total train loss: 0.0089
Avg Loading time: 0.0698 seconds
Avg Batch time: 0.0968 seconds

Train time: 38.007739782333374
 * Prec@1 72.420 Prec@5 90.620 Loss 1.2236
Avg Loading time: 0.0707 seconds
Avg Batch time: 0.0816 seconds

Best acc: 72.420
--------------------------------------------------------------------------------
Test time: 7.881339073181152

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.086)	BT: 0.026 (0.113)	Loss 0.0044 (0.0078)	Prec@1 100.000 (99.970)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.075)	BT: 0.027 (0.102)	Loss 0.0049 (0.0080)	Prec@1 100.000 (99.965)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.073)	BT: 0.022 (0.100)	Loss 0.0049 (0.0078)	Prec@1 100.000 (99.960)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.072)	BT: 0.022 (0.099)	Loss 0.0047 (0.0080)	Prec@1 100.000 (99.952)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.070)	BT: 0.021 (0.097)	Loss 0.0040 (0.0080)	Prec@1 100.000 (99.948)	
Total train loss: 0.0080
Avg Loading time: 0.0706 seconds
Avg Batch time: 0.0972 seconds

Train time: 38.218183517456055
 * Prec@1 72.510 Prec@5 90.460 Loss 1.2236
Avg Loading time: 0.0970 seconds
Avg Batch time: 0.1078 seconds

Best acc: 72.510
--------------------------------------------------------------------------------
Test time: 9.558346033096313

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.089)	BT: 0.023 (0.116)	Loss 0.0059 (0.0077)	Prec@1 100.000 (99.960)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.081)	BT: 0.035 (0.108)	Loss 0.0034 (0.0076)	Prec@1 100.000 (99.970)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.079)	BT: 0.023 (0.105)	Loss 0.0050 (0.0077)	Prec@1 100.000 (99.963)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.079)	BT: 0.022 (0.105)	Loss 0.0078 (0.0077)	Prec@1 100.000 (99.962)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.076)	BT: 0.025 (0.103)	Loss 0.0097 (0.0078)	Prec@1 99.219 (99.956)	
Total train loss: 0.0078
Avg Loading time: 0.0755 seconds
Avg Batch time: 0.1028 seconds

Train time: 40.38038897514343
 * Prec@1 72.470 Prec@5 90.400 Loss 1.2246
Avg Loading time: 0.0949 seconds
Avg Batch time: 0.1045 seconds

Best acc: 72.510
--------------------------------------------------------------------------------
Test time: 8.88236951828003

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.084)	BT: 0.030 (0.111)	Loss 0.0138 (0.0080)	Prec@1 100.000 (99.950)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.538 (0.072)	BT: 0.567 (0.099)	Loss 0.0040 (0.0082)	Prec@1 100.000 (99.955)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.072)	BT: 0.023 (0.099)	Loss 0.0043 (0.0080)	Prec@1 100.000 (99.957)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.078)	BT: 0.021 (0.104)	Loss 0.0133 (0.0079)	Prec@1 100.000 (99.960)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.078)	BT: 0.032 (0.105)	Loss 0.0088 (0.0079)	Prec@1 100.000 (99.964)	
Total train loss: 0.0079
Avg Loading time: 0.0781 seconds
Avg Batch time: 0.1046 seconds

Train time: 41.039135217666626
 * Prec@1 72.370 Prec@5 90.420 Loss 1.2344
Avg Loading time: 0.1054 seconds
Avg Batch time: 0.1156 seconds

Best acc: 72.510
--------------------------------------------------------------------------------
Test time: 9.776204586029053

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.100)	BT: 0.021 (0.123)	Loss 0.0121 (0.0075)	Prec@1 100.000 (99.980)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.097)	BT: 0.026 (0.121)	Loss 0.0062 (0.0074)	Prec@1 100.000 (99.980)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.158 (0.087)	BT: 0.183 (0.112)	Loss 0.0117 (0.0076)	Prec@1 100.000 (99.973)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.086)	BT: 0.025 (0.111)	Loss 0.0144 (0.0077)	Prec@1 100.000 (99.962)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.084)	BT: 0.020 (0.109)	Loss 0.0043 (0.0077)	Prec@1 100.000 (99.960)	
Total train loss: 0.0077
Avg Loading time: 0.0838 seconds
Avg Batch time: 0.1085 seconds

Train time: 42.56086468696594
 * Prec@1 72.350 Prec@5 90.590 Loss 1.2275
Avg Loading time: 0.0870 seconds
Avg Batch time: 0.0973 seconds

Best acc: 72.510
--------------------------------------------------------------------------------
Test time: 8.307459115982056

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.092)	BT: 0.024 (0.117)	Loss 0.0066 (0.0088)	Prec@1 100.000 (99.910)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.086)	BT: 0.023 (0.112)	Loss 0.0089 (0.0083)	Prec@1 100.000 (99.950)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.081)	BT: 0.034 (0.108)	Loss 0.0035 (0.0082)	Prec@1 100.000 (99.947)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.083)	BT: 0.021 (0.109)	Loss 0.0045 (0.0080)	Prec@1 100.000 (99.952)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.082)	BT: 0.022 (0.109)	Loss 0.0060 (0.0081)	Prec@1 100.000 (99.952)	
Total train loss: 0.0081
Avg Loading time: 0.0822 seconds
Avg Batch time: 0.1087 seconds

Train time: 42.66872262954712
 * Prec@1 72.500 Prec@5 90.420 Loss 1.2256
Avg Loading time: 0.1258 seconds
Avg Batch time: 0.1369 seconds

Best acc: 72.510
--------------------------------------------------------------------------------
Test time: 11.453721523284912

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.082)	BT: 0.031 (0.108)	Loss 0.0061 (0.0087)	Prec@1 100.000 (99.950)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.078)	BT: 0.024 (0.104)	Loss 0.0109 (0.0083)	Prec@1 100.000 (99.960)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.079)	BT: 0.036 (0.106)	Loss 0.0103 (0.0083)	Prec@1 100.000 (99.970)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.081)	BT: 0.021 (0.108)	Loss 0.0060 (0.0082)	Prec@1 100.000 (99.962)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.084)	BT: 0.022 (0.110)	Loss 0.0044 (0.0082)	Prec@1 100.000 (99.962)	
Total train loss: 0.0082
Avg Loading time: 0.0833 seconds
Avg Batch time: 0.1096 seconds

Train time: 42.94301676750183
 * Prec@1 72.480 Prec@5 90.550 Loss 1.2256
Avg Loading time: 0.0849 seconds
Avg Batch time: 0.0941 seconds

Best acc: 72.510
--------------------------------------------------------------------------------
Test time: 8.017805576324463

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.094)	BT: 0.022 (0.120)	Loss 0.0024 (0.0085)	Prec@1 100.000 (99.970)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.090)	BT: 0.021 (0.115)	Loss 0.0053 (0.0078)	Prec@1 100.000 (99.965)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.008 (0.089)	BT: 0.030 (0.115)	Loss 0.0071 (0.0080)	Prec@1 100.000 (99.960)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.086)	BT: 0.024 (0.111)	Loss 0.0065 (0.0082)	Prec@1 100.000 (99.952)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.086)	BT: 0.023 (0.111)	Loss 0.0096 (0.0082)	Prec@1 100.000 (99.956)	
Total train loss: 0.0082
Avg Loading time: 0.0857 seconds
Avg Batch time: 0.1105 seconds

Train time: 43.35432720184326
 * Prec@1 72.320 Prec@5 90.700 Loss 1.2285
Avg Loading time: 0.1078 seconds
Avg Batch time: 0.1182 seconds

Best acc: 72.510
--------------------------------------------------------------------------------
Test time: 9.920708179473877

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.106)	BT: 0.027 (0.132)	Loss 0.0096 (0.0077)	Prec@1 100.000 (99.970)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.103)	BT: 0.021 (0.129)	Loss 0.0050 (0.0076)	Prec@1 100.000 (99.955)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.101)	BT: 0.022 (0.127)	Loss 0.0070 (0.0077)	Prec@1 100.000 (99.960)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.106)	BT: 0.022 (0.132)	Loss 0.0104 (0.0077)	Prec@1 100.000 (99.957)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.105)	BT: 0.028 (0.131)	Loss 0.0049 (0.0077)	Prec@1 100.000 (99.962)	
Total train loss: 0.0078
Avg Loading time: 0.1049 seconds
Avg Batch time: 0.1311 seconds

Train time: 51.46307587623596
 * Prec@1 72.370 Prec@5 90.570 Loss 1.2266
Avg Loading time: 0.1319 seconds
Avg Batch time: 0.1424 seconds

Best acc: 72.510
--------------------------------------------------------------------------------
Test time: 11.816104173660278

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.088)	BT: 0.029 (0.116)	Loss 0.0097 (0.0072)	Prec@1 100.000 (99.980)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.086)	BT: 0.032 (0.111)	Loss 0.0080 (0.0078)	Prec@1 100.000 (99.955)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.702 (0.083)	BT: 0.732 (0.109)	Loss 0.0045 (0.0081)	Prec@1 100.000 (99.957)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.085)	BT: 0.025 (0.110)	Loss 0.0110 (0.0084)	Prec@1 100.000 (99.952)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.092)	BT: 0.022 (0.117)	Loss 0.0052 (0.0083)	Prec@1 100.000 (99.950)	
Total train loss: 0.0083
Avg Loading time: 0.0913 seconds
Avg Batch time: 0.1171 seconds

Train time: 45.93640756607056
 * Prec@1 72.410 Prec@5 90.550 Loss 1.2275
Avg Loading time: 0.0901 seconds
Avg Batch time: 0.1007 seconds

Best acc: 72.510
--------------------------------------------------------------------------------
Test time: 8.578667402267456

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.108)	BT: 0.022 (0.133)	Loss 0.0060 (0.0074)	Prec@1 100.000 (99.950)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.523 (0.100)	BT: 0.563 (0.126)	Loss 0.0070 (0.0074)	Prec@1 100.000 (99.960)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.095)	BT: 0.022 (0.122)	Loss 0.0043 (0.0072)	Prec@1 100.000 (99.970)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.097)	BT: 0.045 (0.123)	Loss 0.0083 (0.0074)	Prec@1 100.000 (99.960)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.090)	BT: 0.021 (0.117)	Loss 0.0079 (0.0073)	Prec@1 100.000 (99.968)	
Total train loss: 0.0074
Avg Loading time: 0.0902 seconds
Avg Batch time: 0.1166 seconds

Train time: 45.74282240867615
 * Prec@1 72.620 Prec@5 90.420 Loss 1.2334
Avg Loading time: 0.1338 seconds
Avg Batch time: 0.1442 seconds

Best acc: 72.620
--------------------------------------------------------------------------------
Test time: 12.396406888961792

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.097)	BT: 0.032 (0.124)	Loss 0.0040 (0.0077)	Prec@1 100.000 (99.960)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.093)	BT: 0.027 (0.121)	Loss 0.0065 (0.0079)	Prec@1 100.000 (99.960)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.092)	BT: 0.024 (0.119)	Loss 0.0124 (0.0078)	Prec@1 100.000 (99.957)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.043 (0.094)	BT: 0.078 (0.121)	Loss 0.0106 (0.0079)	Prec@1 100.000 (99.950)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.095)	BT: 0.023 (0.122)	Loss 0.0086 (0.0079)	Prec@1 100.000 (99.950)	
Total train loss: 0.0080
Avg Loading time: 0.0947 seconds
Avg Batch time: 0.1223 seconds

Train time: 47.9566011428833
 * Prec@1 72.370 Prec@5 90.300 Loss 1.2344
Avg Loading time: 0.1418 seconds
Avg Batch time: 0.1523 seconds

Best acc: 72.620
--------------------------------------------------------------------------------
Test time: 12.632601737976074

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.293 (0.105)	BT: 0.325 (0.135)	Loss 0.0081 (0.0076)	Prec@1 100.000 (99.980)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.086)	BT: 0.026 (0.114)	Loss 0.0103 (0.0077)	Prec@1 100.000 (99.975)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.090)	BT: 0.026 (0.119)	Loss 0.0046 (0.0080)	Prec@1 100.000 (99.957)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.085)	BT: 0.023 (0.113)	Loss 0.0028 (0.0081)	Prec@1 100.000 (99.952)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.088)	BT: 0.032 (0.116)	Loss 0.0175 (0.0081)	Prec@1 100.000 (99.952)	
Total train loss: 0.0081
Avg Loading time: 0.0880 seconds
Avg Batch time: 0.1162 seconds

Train time: 45.62829875946045
 * Prec@1 72.330 Prec@5 90.560 Loss 1.2256
Avg Loading time: 0.0801 seconds
Avg Batch time: 0.0910 seconds

Best acc: 72.620
--------------------------------------------------------------------------------
Test time: 7.851597309112549

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.089)	BT: 0.029 (0.117)	Loss 0.0050 (0.0080)	Prec@1 100.000 (99.960)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.090)	BT: 0.031 (0.118)	Loss 0.0056 (0.0080)	Prec@1 100.000 (99.940)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.223 (0.085)	BT: 0.246 (0.112)	Loss 0.0060 (0.0081)	Prec@1 100.000 (99.933)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.086)	BT: 0.029 (0.112)	Loss 0.0110 (0.0080)	Prec@1 100.000 (99.947)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.090)	BT: 0.027 (0.116)	Loss 0.0100 (0.0079)	Prec@1 100.000 (99.952)	
Total train loss: 0.0079
Avg Loading time: 0.0900 seconds
Avg Batch time: 0.1162 seconds

Train time: 45.60878825187683
 * Prec@1 72.400 Prec@5 90.490 Loss 1.2285
Avg Loading time: 0.1186 seconds
Avg Batch time: 0.1284 seconds

Best acc: 72.620
--------------------------------------------------------------------------------
Test time: 10.73950743675232

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.158 (0.089)	BT: 0.184 (0.115)	Loss 0.0037 (0.0071)	Prec@1 100.000 (99.980)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.095)	BT: 0.021 (0.121)	Loss 0.0068 (0.0076)	Prec@1 100.000 (99.965)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.090)	BT: 0.022 (0.116)	Loss 0.0049 (0.0077)	Prec@1 100.000 (99.957)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.092)	BT: 0.041 (0.118)	Loss 0.0029 (0.0079)	Prec@1 100.000 (99.952)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.012 (0.093)	BT: 0.034 (0.120)	Loss 0.0068 (0.0079)	Prec@1 100.000 (99.948)	
Total train loss: 0.0079
Avg Loading time: 0.0926 seconds
Avg Batch time: 0.1194 seconds

Train time: 46.802526235580444
 * Prec@1 72.650 Prec@5 90.540 Loss 1.2246
Avg Loading time: 0.1074 seconds
Avg Batch time: 0.1184 seconds

Best acc: 72.650
--------------------------------------------------------------------------------
Test time: 10.375646591186523

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.098)	BT: 0.033 (0.124)	Loss 0.0096 (0.0070)	Prec@1 100.000 (99.970)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.102)	BT: 0.026 (0.128)	Loss 0.0058 (0.0071)	Prec@1 100.000 (99.970)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.180 (0.094)	BT: 0.207 (0.120)	Loss 0.0102 (0.0072)	Prec@1 100.000 (99.967)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.093)	BT: 0.020 (0.118)	Loss 0.0046 (0.0075)	Prec@1 100.000 (99.965)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.001 (0.091)	BT: 0.027 (0.117)	Loss 0.0061 (0.0074)	Prec@1 100.000 (99.970)	
Total train loss: 0.0074
Avg Loading time: 0.0911 seconds
Avg Batch time: 0.1164 seconds

Train time: 45.63283586502075
 * Prec@1 72.700 Prec@5 90.460 Loss 1.2256
Avg Loading time: 0.1341 seconds
Avg Batch time: 0.1434 seconds

Best acc: 72.700
--------------------------------------------------------------------------------
Test time: 12.400992393493652

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.108)	BT: 0.021 (0.135)	Loss 0.0167 (0.0086)	Prec@1 100.000 (99.920)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.091)	BT: 0.021 (0.118)	Loss 0.0287 (0.0078)	Prec@1 99.219 (99.950)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.093)	BT: 0.026 (0.119)	Loss 0.0038 (0.0077)	Prec@1 100.000 (99.963)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.092)	BT: 0.032 (0.119)	Loss 0.0081 (0.0076)	Prec@1 100.000 (99.960)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.093)	BT: 0.020 (0.120)	Loss 0.0176 (0.0076)	Prec@1 100.000 (99.966)	
Total train loss: 0.0076
Avg Loading time: 0.0925 seconds
Avg Batch time: 0.1193 seconds

Train time: 46.75150680541992
 * Prec@1 72.590 Prec@5 90.560 Loss 1.2285
Avg Loading time: 0.1116 seconds
Avg Batch time: 0.1231 seconds

Best acc: 72.700
--------------------------------------------------------------------------------
Test time: 10.315590620040894

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.104)	BT: 0.038 (0.130)	Loss 0.0068 (0.0069)	Prec@1 100.000 (99.960)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.134 (0.082)	BT: 0.157 (0.108)	Loss 0.0058 (0.0071)	Prec@1 100.000 (99.975)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.081)	BT: 0.028 (0.107)	Loss 0.0049 (0.0073)	Prec@1 100.000 (99.970)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.082)	BT: 0.028 (0.109)	Loss 0.0047 (0.0072)	Prec@1 100.000 (99.970)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.085)	BT: 0.022 (0.112)	Loss 0.0066 (0.0076)	Prec@1 100.000 (99.964)	
Total train loss: 0.0076
Avg Loading time: 0.0849 seconds
Avg Batch time: 0.1116 seconds

Train time: 43.83633017539978
 * Prec@1 72.790 Prec@5 90.470 Loss 1.2275
Avg Loading time: 0.1065 seconds
Avg Batch time: 0.1167 seconds

Best acc: 72.790
--------------------------------------------------------------------------------
Test time: 10.266024827957153

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.087)	BT: 0.021 (0.114)	Loss 0.0119 (0.0082)	Prec@1 100.000 (99.940)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.082)	BT: 0.024 (0.108)	Loss 0.0043 (0.0078)	Prec@1 100.000 (99.945)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.083)	BT: 0.032 (0.109)	Loss 0.0053 (0.0077)	Prec@1 100.000 (99.943)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.085)	BT: 0.028 (0.111)	Loss 0.0046 (0.0078)	Prec@1 100.000 (99.955)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.084)	BT: 0.027 (0.110)	Loss 0.0052 (0.0078)	Prec@1 100.000 (99.950)	
Total train loss: 0.0078
Avg Loading time: 0.0833 seconds
Avg Batch time: 0.1098 seconds

Train time: 43.11293268203735
 * Prec@1 72.540 Prec@5 90.610 Loss 1.2256
Avg Loading time: 0.0636 seconds
Avg Batch time: 0.0732 seconds

Best acc: 72.790
--------------------------------------------------------------------------------
Test time: 6.417187690734863

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.101)	BT: 0.023 (0.126)	Loss 0.0079 (0.0075)	Prec@1 100.000 (99.960)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.293 (0.090)	BT: 0.325 (0.115)	Loss 0.0175 (0.0075)	Prec@1 100.000 (99.945)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.084)	BT: 0.028 (0.111)	Loss 0.0054 (0.0075)	Prec@1 100.000 (99.950)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.088)	BT: 0.025 (0.114)	Loss 0.0061 (0.0074)	Prec@1 100.000 (99.955)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.085)	BT: 0.021 (0.112)	Loss 0.0042 (0.0073)	Prec@1 100.000 (99.958)	
Total train loss: 0.0074
Avg Loading time: 0.0853 seconds
Avg Batch time: 0.1114 seconds

Train time: 43.70002627372742
 * Prec@1 72.420 Prec@5 90.690 Loss 1.2305
Avg Loading time: 0.1179 seconds
Avg Batch time: 0.1290 seconds

Best acc: 72.790
--------------------------------------------------------------------------------
Test time: 10.802079916000366

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.086)	BT: 0.022 (0.113)	Loss 0.0077 (0.0075)	Prec@1 100.000 (99.980)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.087)	BT: 0.022 (0.113)	Loss 0.0101 (0.0075)	Prec@1 100.000 (99.975)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.082)	BT: 0.042 (0.108)	Loss 0.0027 (0.0074)	Prec@1 100.000 (99.977)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.076)	BT: 0.024 (0.102)	Loss 0.0135 (0.0074)	Prec@1 100.000 (99.980)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.079)	BT: 0.022 (0.105)	Loss 0.0030 (0.0074)	Prec@1 100.000 (99.980)	
Total train loss: 0.0075
Avg Loading time: 0.0787 seconds
Avg Batch time: 0.1047 seconds

Train time: 41.10444688796997
 * Prec@1 72.440 Prec@5 90.590 Loss 1.2227
Avg Loading time: 0.1172 seconds
Avg Batch time: 0.1291 seconds

Best acc: 72.790
--------------------------------------------------------------------------------
Test time: 10.822703838348389

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.118)	BT: 0.022 (0.145)	Loss 0.0051 (0.0094)	Prec@1 100.000 (99.890)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.111)	BT: 0.038 (0.138)	Loss 0.0040 (0.0082)	Prec@1 100.000 (99.930)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.108)	BT: 0.022 (0.135)	Loss 0.0097 (0.0080)	Prec@1 100.000 (99.953)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.013 (0.116)	BT: 0.034 (0.143)	Loss 0.0058 (0.0080)	Prec@1 100.000 (99.950)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.117)	BT: 0.031 (0.144)	Loss 0.0187 (0.0079)	Prec@1 100.000 (99.956)	
Total train loss: 0.0079
Avg Loading time: 0.1168 seconds
Avg Batch time: 0.1437 seconds

Train time: 56.324028730392456
 * Prec@1 72.540 Prec@5 90.390 Loss 1.2275
Avg Loading time: 0.1636 seconds
Avg Batch time: 0.1743 seconds

Best acc: 72.790
--------------------------------------------------------------------------------
Test time: 14.415281772613525

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.132)	BT: 0.023 (0.158)	Loss 0.0055 (0.0082)	Prec@1 100.000 (99.950)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.125)	BT: 0.023 (0.151)	Loss 0.0153 (0.0081)	Prec@1 99.219 (99.935)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.120)	BT: 0.022 (0.146)	Loss 0.0050 (0.0079)	Prec@1 100.000 (99.943)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.121)	BT: 0.028 (0.147)	Loss 0.0160 (0.0078)	Prec@1 100.000 (99.952)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.122)	BT: 0.022 (0.147)	Loss 0.0150 (0.0079)	Prec@1 100.000 (99.952)	
Total train loss: 0.0079
Avg Loading time: 0.1215 seconds
Avg Batch time: 0.1471 seconds

Train time: 57.634448289871216
 * Prec@1 72.340 Prec@5 90.470 Loss 1.2324
Avg Loading time: 0.1782 seconds
Avg Batch time: 0.1893 seconds

Best acc: 72.790
--------------------------------------------------------------------------------
Test time: 15.571066856384277

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.140)	BT: 0.025 (0.167)	Loss 0.0038 (0.0084)	Prec@1 100.000 (99.960)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.305 (0.117)	BT: 0.340 (0.144)	Loss 0.0043 (0.0080)	Prec@1 100.000 (99.960)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.117)	BT: 0.023 (0.144)	Loss 0.0071 (0.0077)	Prec@1 100.000 (99.957)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.003 (0.118)	BT: 0.033 (0.145)	Loss 0.0054 (0.0077)	Prec@1 100.000 (99.960)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.116)	BT: 0.020 (0.143)	Loss 0.0131 (0.0078)	Prec@1 100.000 (99.960)	
Total train loss: 0.0078
Avg Loading time: 0.1158 seconds
Avg Batch time: 0.1423 seconds

Train time: 55.7472140789032
 * Prec@1 72.480 Prec@5 90.620 Loss 1.2314
Avg Loading time: 0.1542 seconds
Avg Batch time: 0.1658 seconds

Best acc: 72.790
--------------------------------------------------------------------------------
Test time: 13.733935117721558

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.098)	BT: 0.037 (0.125)	Loss 0.0073 (0.0081)	Prec@1 100.000 (99.940)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.078)	BT: 0.027 (0.106)	Loss 0.0060 (0.0082)	Prec@1 100.000 (99.940)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.065)	BT: 0.023 (0.093)	Loss 0.0305 (0.0082)	Prec@1 99.219 (99.947)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.054)	BT: 0.033 (0.084)	Loss 0.0054 (0.0084)	Prec@1 100.000 (99.942)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.047)	BT: 0.025 (0.077)	Loss 0.0264 (0.0084)	Prec@1 99.219 (99.946)	
Total train loss: 0.0084
Avg Loading time: 0.0470 seconds
Avg Batch time: 0.0772 seconds

Train time: 30.367228507995605
 * Prec@1 72.380 Prec@5 90.520 Loss 1.2314
Avg Loading time: 0.0319 seconds
Avg Batch time: 0.0485 seconds

Best acc: 72.790
--------------------------------------------------------------------------------
Test time: 4.4305174350738525

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.110)	BT: 0.021 (0.136)	Loss 0.0076 (0.0072)	Prec@1 99.219 (99.960)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.100)	BT: 0.021 (0.126)	Loss 0.0053 (0.0077)	Prec@1 100.000 (99.965)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.094)	BT: 0.022 (0.121)	Loss 0.0091 (0.0080)	Prec@1 100.000 (99.960)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.094)	BT: 0.022 (0.120)	Loss 0.0044 (0.0080)	Prec@1 100.000 (99.955)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.093)	BT: 0.028 (0.120)	Loss 0.0038 (0.0079)	Prec@1 100.000 (99.960)	
Total train loss: 0.0079
Avg Loading time: 0.0927 seconds
Avg Batch time: 0.1194 seconds

Train time: 46.79079270362854
 * Prec@1 72.550 Prec@5 90.520 Loss 1.2275
Avg Loading time: 0.1561 seconds
Avg Batch time: 0.1668 seconds

Best acc: 72.790
--------------------------------------------------------------------------------
Test time: 13.816916704177856

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.089)	BT: 0.022 (0.116)	Loss 0.0031 (0.0073)	Prec@1 100.000 (99.970)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.102)	BT: 0.031 (0.127)	Loss 0.0037 (0.0073)	Prec@1 100.000 (99.970)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.819 (0.100)	BT: 0.844 (0.125)	Loss 0.0144 (0.0073)	Prec@1 99.219 (99.970)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.100)	BT: 0.022 (0.126)	Loss 0.0041 (0.0074)	Prec@1 100.000 (99.967)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.096)	BT: 0.025 (0.122)	Loss 0.0061 (0.0075)	Prec@1 100.000 (99.962)	
Total train loss: 0.0075
Avg Loading time: 0.0961 seconds
Avg Batch time: 0.1222 seconds

Train time: 47.9518256187439
 * Prec@1 72.460 Prec@5 90.570 Loss 1.2275
Avg Loading time: 0.1322 seconds
Avg Batch time: 0.1426 seconds

Best acc: 72.790
--------------------------------------------------------------------------------
Test time: 11.85271692276001

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.095)	BT: 0.022 (0.120)	Loss 0.0051 (0.0080)	Prec@1 100.000 (99.980)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.079 (0.104)	BT: 0.103 (0.130)	Loss 0.0035 (0.0077)	Prec@1 100.000 (99.975)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.100)	BT: 0.029 (0.127)	Loss 0.0077 (0.0077)	Prec@1 100.000 (99.967)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.102)	BT: 0.030 (0.128)	Loss 0.0099 (0.0079)	Prec@1 100.000 (99.960)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.106)	BT: 0.023 (0.132)	Loss 0.0045 (0.0080)	Prec@1 100.000 (99.956)	
Total train loss: 0.0080
Avg Loading time: 0.1053 seconds
Avg Batch time: 0.1313 seconds

Train time: 51.54003930091858
 * Prec@1 72.470 Prec@5 90.600 Loss 1.2275
Avg Loading time: 0.1331 seconds
Avg Batch time: 0.1441 seconds

Best acc: 72.790
--------------------------------------------------------------------------------
Test time: 12.03715991973877

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.087)	BT: 0.038 (0.116)	Loss 0.0107 (0.0081)	Prec@1 100.000 (99.950)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.550 (0.084)	BT: 0.581 (0.112)	Loss 0.0126 (0.0079)	Prec@1 100.000 (99.965)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.073)	BT: 0.031 (0.101)	Loss 0.0040 (0.0078)	Prec@1 100.000 (99.963)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.058)	BT: 0.063 (0.086)	Loss 0.0150 (0.0079)	Prec@1 99.219 (99.962)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.058)	BT: 0.020 (0.086)	Loss 0.0039 (0.0080)	Prec@1 100.000 (99.962)	
Total train loss: 0.0081
Avg Loading time: 0.0577 seconds
Avg Batch time: 0.0860 seconds

Train time: 33.82971692085266
 * Prec@1 72.410 Prec@5 90.520 Loss 1.2314
Avg Loading time: 0.0773 seconds
Avg Batch time: 0.0904 seconds

Best acc: 72.790
--------------------------------------------------------------------------------
Test time: 7.763564825057983

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.106 (0.071)	BT: 0.138 (0.101)	Loss 0.0062 (0.0078)	Prec@1 100.000 (99.940)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.070)	BT: 0.022 (0.100)	Loss 0.0029 (0.0077)	Prec@1 100.000 (99.955)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.065)	BT: 0.025 (0.095)	Loss 0.0049 (0.0076)	Prec@1 100.000 (99.957)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.064)	BT: 0.034 (0.093)	Loss 0.0064 (0.0074)	Prec@1 100.000 (99.960)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.063)	BT: 0.021 (0.092)	Loss 0.0109 (0.0074)	Prec@1 100.000 (99.954)	
Total train loss: 0.0074
Avg Loading time: 0.0629 seconds
Avg Batch time: 0.0914 seconds

Train time: 35.92532706260681
 * Prec@1 72.430 Prec@5 90.550 Loss 1.2275
Avg Loading time: 0.0874 seconds
Avg Batch time: 0.0978 seconds

Best acc: 72.790
--------------------------------------------------------------------------------
Test time: 8.392383337020874

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.078)	BT: 0.021 (0.104)	Loss 0.0176 (0.0082)	Prec@1 99.219 (99.920)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.068)	BT: 0.029 (0.094)	Loss 0.0072 (0.0080)	Prec@1 100.000 (99.935)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.042 (0.066)	BT: 0.074 (0.094)	Loss 0.0070 (0.0081)	Prec@1 100.000 (99.943)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.001 (0.069)	BT: 0.034 (0.098)	Loss 0.0074 (0.0079)	Prec@1 100.000 (99.950)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.069)	BT: 0.028 (0.097)	Loss 0.0046 (0.0081)	Prec@1 100.000 (99.942)	
Total train loss: 0.0081
Avg Loading time: 0.0686 seconds
Avg Batch time: 0.0968 seconds

Train time: 38.02448296546936
 * Prec@1 72.790 Prec@5 90.580 Loss 1.2275
Avg Loading time: 0.0817 seconds
Avg Batch time: 0.0938 seconds

Best acc: 72.790
--------------------------------------------------------------------------------
Test time: 8.060717582702637


      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 0
          frozen_layers: 13
Savedir:  ../pretrained_models/frozen/x64-8b/rram/cifar100/resnet18
DEVICE: cuda
GPU Id(s) being used: 0
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar100/resnet18/train/relu13
Test path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar100/resnet18/test/relu13
ResNet18(
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=100, bias=False)
  (bn19): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 0.990 Prec@5 4.560 Loss 4.6289
Avg Loading time: 0.5969 seconds
Avg Batch time: 0.6129 seconds

Pre-trained Prec@1 with 13 layers frozen: 0.9899999499320984 	 Loss: 4.62890625

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (1.467)	BT: 0.019 (1.489)	Loss 1.9004 (2.4187)	Prec@1 47.656 (41.536)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (1.352)	BT: 0.019 (1.374)	Loss 1.6377 (2.0458)	Prec@1 56.250 (48.167)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (1.312)	BT: 0.020 (1.333)	Loss 1.4023 (1.8750)	Prec@1 64.062 (51.382)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (1.256)	BT: 0.019 (1.277)	Loss 1.3711 (1.7675)	Prec@1 62.500 (53.511)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (1.241)	BT: 0.018 (1.261)	Loss 1.2725 (1.6847)	Prec@1 61.719 (55.192)	
Total train loss: 1.6847
Avg Loading time: 1.2375 seconds
Avg Batch time: 1.2581 seconds

Train time: 491.9849181175232
 * Prec@1 62.750 Prec@5 89.180 Loss 1.3203
Avg Loading time: 0.1164 seconds
Avg Batch time: 0.1257 seconds

Best acc: 62.750
--------------------------------------------------------------------------------
Test time: 10.828517198562622

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.100)	BT: 0.019 (0.121)	Loss 1.0830 (0.9921)	Prec@1 65.625 (71.544)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.102)	BT: 0.017 (0.123)	Loss 1.0078 (1.0134)	Prec@1 71.094 (70.658)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.943 (0.103)	BT: 0.960 (0.124)	Loss 0.8965 (1.0160)	Prec@1 72.656 (70.489)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.103)	BT: 0.039 (0.124)	Loss 0.8809 (1.0227)	Prec@1 74.219 (70.302)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.104)	BT: 0.015 (0.125)	Loss 1.1719 (1.0245)	Prec@1 67.188 (70.357)	
Total train loss: 1.0247
Avg Loading time: 0.1036 seconds
Avg Batch time: 0.1249 seconds

Train time: 48.95331048965454
 * Prec@1 65.050 Prec@5 89.750 Loss 1.2500
Avg Loading time: 0.1348 seconds
Avg Batch time: 0.1437 seconds

Best acc: 65.050
--------------------------------------------------------------------------------
Test time: 12.338871955871582

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.122)	BT: 0.019 (0.141)	Loss 0.5615 (0.6368)	Prec@1 82.812 (81.210)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.083 (0.105)	BT: 0.102 (0.126)	Loss 0.7021 (0.6560)	Prec@1 75.781 (80.308)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.172 (0.104)	BT: 0.195 (0.125)	Loss 0.7832 (0.6827)	Prec@1 78.125 (79.654)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.001 (0.101)	BT: 0.022 (0.122)	Loss 0.8135 (0.6986)	Prec@1 74.219 (79.074)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.101)	BT: 0.016 (0.123)	Loss 0.7358 (0.7207)	Prec@1 77.344 (78.259)	
Total train loss: 0.7209
Avg Loading time: 0.1005 seconds
Avg Batch time: 0.1224 seconds

Train time: 48.023154497146606
 * Prec@1 66.420 Prec@5 89.870 Loss 1.2266
Avg Loading time: 0.1203 seconds
Avg Batch time: 0.1295 seconds

Best acc: 66.420
--------------------------------------------------------------------------------
Test time: 11.160580158233643

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.121)	BT: 0.019 (0.143)	Loss 0.3259 (0.4327)	Prec@1 89.844 (87.270)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.115)	BT: 0.024 (0.137)	Loss 0.4570 (0.4389)	Prec@1 82.812 (86.814)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.109)	BT: 0.015 (0.131)	Loss 0.4761 (0.4553)	Prec@1 85.156 (86.278)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.109)	BT: 0.035 (0.131)	Loss 0.6377 (0.4770)	Prec@1 78.906 (85.462)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.106)	BT: 0.019 (0.128)	Loss 0.7266 (0.4939)	Prec@1 77.344 (84.888)	
Total train loss: 0.4942
Avg Loading time: 0.1059 seconds
Avg Batch time: 0.1277 seconds

Train time: 50.112447023391724
 * Prec@1 65.230 Prec@5 89.210 Loss 1.3662
Avg Loading time: 0.1239 seconds
Avg Batch time: 0.1340 seconds

Best acc: 66.420
--------------------------------------------------------------------------------
Test time: 11.110105037689209

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.095)	BT: 0.023 (0.118)	Loss 0.2651 (0.2982)	Prec@1 92.188 (91.066)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.096)	BT: 0.017 (0.118)	Loss 0.2477 (0.2979)	Prec@1 94.531 (91.036)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.096)	BT: 0.025 (0.119)	Loss 0.2778 (0.3128)	Prec@1 92.969 (90.445)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.097)	BT: 0.045 (0.120)	Loss 0.3716 (0.3286)	Prec@1 88.281 (89.964)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.100)	BT: 0.020 (0.123)	Loss 0.3823 (0.3458)	Prec@1 85.156 (89.345)	
Total train loss: 0.3461
Avg Loading time: 0.0998 seconds
Avg Batch time: 0.1227 seconds

Train time: 48.16078519821167
 * Prec@1 64.920 Prec@5 88.140 Loss 1.4365
Avg Loading time: 0.0964 seconds
Avg Batch time: 0.1062 seconds

Best acc: 66.420
--------------------------------------------------------------------------------
Test time: 8.925783157348633

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.097)	BT: 0.023 (0.117)	Loss 0.2900 (0.2223)	Prec@1 89.844 (93.450)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.086)	BT: 0.019 (0.106)	Loss 0.1786 (0.2199)	Prec@1 94.531 (93.580)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.000 (0.084)	BT: 0.020 (0.105)	Loss 0.2690 (0.2223)	Prec@1 92.188 (93.496)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.082)	BT: 0.020 (0.103)	Loss 0.2615 (0.2319)	Prec@1 91.406 (93.106)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.088)	BT: 0.017 (0.109)	Loss 0.4060 (0.2443)	Prec@1 83.594 (92.632)	
Total train loss: 0.2448
Avg Loading time: 0.0874 seconds
Avg Batch time: 0.1084 seconds

Train time: 42.527503490448
 * Prec@1 65.710 Prec@5 88.290 Loss 1.4512
Avg Loading time: 0.0986 seconds
Avg Batch time: 0.1079 seconds

Best acc: 66.420
--------------------------------------------------------------------------------
Test time: 9.084106922149658

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.095)	BT: 0.018 (0.114)	Loss 0.2229 (0.1797)	Prec@1 92.969 (94.982)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.089)	BT: 0.018 (0.109)	Loss 0.1251 (0.1701)	Prec@1 96.875 (95.292)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.089)	BT: 0.023 (0.109)	Loss 0.0931 (0.1738)	Prec@1 96.875 (95.059)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.090)	BT: 0.018 (0.111)	Loss 0.1931 (0.1788)	Prec@1 92.969 (94.844)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.090)	BT: 0.020 (0.111)	Loss 0.2277 (0.1880)	Prec@1 92.188 (94.515)	
Total train loss: 0.1882
Avg Loading time: 0.0899 seconds
Avg Batch time: 0.1110 seconds

Train time: 43.51076412200928
 * Prec@1 65.320 Prec@5 87.640 Loss 1.5508
Avg Loading time: 0.0997 seconds
Avg Batch time: 0.1090 seconds

Best acc: 66.420
--------------------------------------------------------------------------------
Test time: 9.164870262145996

Epoch: [7][77/391]	LR: 0.1	DT: 0.301 (0.097)	BT: 0.335 (0.118)	Loss 0.1650 (0.1369)	Prec@1 95.312 (96.094)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.083)	BT: 0.020 (0.106)	Loss 0.0927 (0.1285)	Prec@1 96.094 (96.374)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.088)	BT: 0.019 (0.110)	Loss 0.1224 (0.1356)	Prec@1 97.656 (96.097)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.090)	BT: 0.019 (0.112)	Loss 0.1672 (0.1421)	Prec@1 92.969 (95.856)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.205 (0.091)	BT: 0.231 (0.114)	Loss 0.2124 (0.1483)	Prec@1 92.969 (95.639)	
Total train loss: 0.1485
Avg Loading time: 0.0907 seconds
Avg Batch time: 0.1133 seconds

Train time: 44.48200082778931
 * Prec@1 67.360 Prec@5 88.800 Loss 1.4463
Avg Loading time: 0.1259 seconds
Avg Batch time: 0.1341 seconds

Best acc: 67.360
--------------------------------------------------------------------------------
Test time: 11.476834774017334

Epoch: [8][77/391]	LR: 0.1	DT: 0.356 (0.095)	BT: 0.380 (0.117)	Loss 0.1124 (0.1019)	Prec@1 97.656 (97.396)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.091)	BT: 0.024 (0.113)	Loss 0.1064 (0.1087)	Prec@1 97.656 (97.150)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.090)	BT: 0.024 (0.112)	Loss 0.1306 (0.1123)	Prec@1 96.094 (97.005)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.091)	BT: 0.022 (0.113)	Loss 0.0726 (0.1164)	Prec@1 98.438 (96.883)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.091)	BT: 0.027 (0.112)	Loss 0.1661 (0.1228)	Prec@1 96.094 (96.651)	
Total train loss: 0.1229
Avg Loading time: 0.0907 seconds
Avg Batch time: 0.1122 seconds

Train time: 44.01240038871765
 * Prec@1 66.000 Prec@5 88.440 Loss 1.4971
Avg Loading time: 0.0823 seconds
Avg Batch time: 0.0926 seconds

Best acc: 67.360
--------------------------------------------------------------------------------
Test time: 7.905435800552368

Epoch: [9][77/391]	LR: 0.1	DT: 0.044 (0.093)	BT: 0.073 (0.115)	Loss 0.0929 (0.1048)	Prec@1 96.875 (97.316)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.086)	BT: 0.016 (0.108)	Loss 0.1471 (0.1040)	Prec@1 94.531 (97.256)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.311 (0.086)	BT: 0.331 (0.107)	Loss 0.1197 (0.1024)	Prec@1 96.094 (97.246)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.091)	BT: 0.020 (0.112)	Loss 0.1113 (0.1042)	Prec@1 96.094 (97.160)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.089)	BT: 0.028 (0.111)	Loss 0.1414 (0.1059)	Prec@1 94.531 (97.093)	
Total train loss: 0.1059
Avg Loading time: 0.0892 seconds
Avg Batch time: 0.1106 seconds

Train time: 43.39430570602417
 * Prec@1 67.300 Prec@5 88.200 Loss 1.5068
Avg Loading time: 0.0965 seconds
Avg Batch time: 0.1058 seconds

Best acc: 67.360
--------------------------------------------------------------------------------
Test time: 8.948373556137085

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.086)	BT: 0.019 (0.106)	Loss 0.0827 (0.0631)	Prec@1 96.875 (98.498)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.086)	BT: 0.022 (0.106)	Loss 0.0412 (0.0558)	Prec@1 100.000 (98.678)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.087)	BT: 0.024 (0.108)	Loss 0.0208 (0.0525)	Prec@1 100.000 (98.808)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.085)	BT: 0.017 (0.106)	Loss 0.0229 (0.0490)	Prec@1 99.219 (98.936)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.031 (0.084)	BT: 0.050 (0.105)	Loss 0.0293 (0.0469)	Prec@1 100.000 (98.992)	
Total train loss: 0.0470
Avg Loading time: 0.0835 seconds
Avg Batch time: 0.1044 seconds

Train time: 40.930667877197266
 * Prec@1 71.030 Prec@5 90.050 Loss 1.2812
Avg Loading time: 0.0939 seconds
Avg Batch time: 0.1035 seconds

Best acc: 71.030
--------------------------------------------------------------------------------
Test time: 9.185929536819458

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.097)	BT: 0.025 (0.119)	Loss 0.0300 (0.0234)	Prec@1 99.219 (99.730)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.086)	BT: 0.018 (0.109)	Loss 0.0127 (0.0237)	Prec@1 100.000 (99.705)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.083)	BT: 0.021 (0.106)	Loss 0.0210 (0.0233)	Prec@1 100.000 (99.723)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.079)	BT: 0.019 (0.102)	Loss 0.0120 (0.0228)	Prec@1 100.000 (99.720)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.191 (0.078)	BT: 0.216 (0.100)	Loss 0.0123 (0.0225)	Prec@1 100.000 (99.726)	
Total train loss: 0.0225
Avg Loading time: 0.0780 seconds
Avg Batch time: 0.0998 seconds

Train time: 39.23392176628113
 * Prec@1 71.410 Prec@5 90.100 Loss 1.2793
Avg Loading time: 0.0993 seconds
Avg Batch time: 0.1085 seconds

Best acc: 71.410
--------------------------------------------------------------------------------
Test time: 9.500510454177856

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.192 (0.087)	BT: 0.211 (0.109)	Loss 0.0241 (0.0170)	Prec@1 99.219 (99.860)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.063 (0.084)	BT: 0.078 (0.106)	Loss 0.0159 (0.0166)	Prec@1 100.000 (99.845)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.083)	BT: 0.017 (0.104)	Loss 0.0106 (0.0173)	Prec@1 100.000 (99.826)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.079)	BT: 0.026 (0.101)	Loss 0.0237 (0.0171)	Prec@1 99.219 (99.822)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.085 (0.080)	BT: 0.105 (0.101)	Loss 0.0235 (0.0168)	Prec@1 99.219 (99.824)	
Total train loss: 0.0168
Avg Loading time: 0.0797 seconds
Avg Batch time: 0.1011 seconds

Train time: 39.63666367530823
 * Prec@1 71.390 Prec@5 90.160 Loss 1.2852
Avg Loading time: 0.0995 seconds
Avg Batch time: 0.1092 seconds

Best acc: 71.410
--------------------------------------------------------------------------------
Test time: 9.237568140029907

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.080)	BT: 0.019 (0.101)	Loss 0.0127 (0.0139)	Prec@1 100.000 (99.900)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.076)	BT: 0.023 (0.098)	Loss 0.0117 (0.0147)	Prec@1 100.000 (99.875)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.071)	BT: 0.021 (0.093)	Loss 0.0129 (0.0145)	Prec@1 100.000 (99.876)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.074)	BT: 0.016 (0.096)	Loss 0.0257 (0.0148)	Prec@1 99.219 (99.860)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.076)	BT: 0.021 (0.098)	Loss 0.0225 (0.0149)	Prec@1 99.219 (99.864)	
Total train loss: 0.0149
Avg Loading time: 0.0754 seconds
Avg Batch time: 0.0975 seconds

Train time: 38.31064987182617
 * Prec@1 71.560 Prec@5 89.970 Loss 1.2881
Avg Loading time: 0.0922 seconds
Avg Batch time: 0.1012 seconds

Best acc: 71.560
--------------------------------------------------------------------------------
Test time: 8.941327095031738

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.080)	BT: 0.019 (0.102)	Loss 0.0125 (0.0121)	Prec@1 100.000 (99.950)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.069)	BT: 0.031 (0.092)	Loss 0.0055 (0.0123)	Prec@1 100.000 (99.930)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.441 (0.062)	BT: 0.460 (0.085)	Loss 0.0086 (0.0122)	Prec@1 100.000 (99.913)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.057)	BT: 0.019 (0.081)	Loss 0.0118 (0.0127)	Prec@1 100.000 (99.905)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.016 (0.050)	BT: 0.031 (0.074)	Loss 0.0130 (0.0125)	Prec@1 100.000 (99.902)	
Total train loss: 0.0126
Avg Loading time: 0.0497 seconds
Avg Batch time: 0.0736 seconds

Train time: 28.957274913787842
 * Prec@1 71.600 Prec@5 89.920 Loss 1.2881
Avg Loading time: 0.0331 seconds
Avg Batch time: 0.0428 seconds

Best acc: 71.600
--------------------------------------------------------------------------------
Test time: 4.352744102478027

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.108)	BT: 0.017 (0.129)	Loss 0.0045 (0.0110)	Prec@1 100.000 (99.910)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.224 (0.101)	BT: 0.242 (0.122)	Loss 0.0135 (0.0110)	Prec@1 99.219 (99.925)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.096)	BT: 0.019 (0.118)	Loss 0.0080 (0.0109)	Prec@1 100.000 (99.940)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.099)	BT: 0.019 (0.121)	Loss 0.0516 (0.0111)	Prec@1 99.219 (99.935)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.098)	BT: 0.017 (0.120)	Loss 0.0140 (0.0112)	Prec@1 100.000 (99.922)	
Total train loss: 0.0113
Avg Loading time: 0.0974 seconds
Avg Batch time: 0.1199 seconds

Train time: 46.982216596603394
 * Prec@1 71.760 Prec@5 89.830 Loss 1.2900
Avg Loading time: 0.1319 seconds
Avg Batch time: 0.1405 seconds

Best acc: 71.760
--------------------------------------------------------------------------------
Test time: 12.00027847290039

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.114)	BT: 0.019 (0.135)	Loss 0.0073 (0.0111)	Prec@1 100.000 (99.880)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.130)	BT: 0.020 (0.151)	Loss 0.0067 (0.0117)	Prec@1 100.000 (99.880)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.119)	BT: 0.019 (0.140)	Loss 0.0086 (0.0113)	Prec@1 100.000 (99.897)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.116)	BT: 0.019 (0.137)	Loss 0.0088 (0.0112)	Prec@1 100.000 (99.902)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.280 (0.113)	BT: 0.299 (0.134)	Loss 0.0113 (0.0109)	Prec@1 100.000 (99.914)	
Total train loss: 0.0109
Avg Loading time: 0.1124 seconds
Avg Batch time: 0.1334 seconds

Train time: 52.34395980834961
 * Prec@1 71.730 Prec@5 89.990 Loss 1.2939
Avg Loading time: 0.1444 seconds
Avg Batch time: 0.1529 seconds

Best acc: 71.760
--------------------------------------------------------------------------------
Test time: 12.627837896347046

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.117)	BT: 0.018 (0.140)	Loss 0.0114 (0.0099)	Prec@1 100.000 (99.930)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.117)	BT: 0.016 (0.139)	Loss 0.0093 (0.0098)	Prec@1 100.000 (99.940)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.057 (0.103)	BT: 0.073 (0.125)	Loss 0.0106 (0.0094)	Prec@1 99.219 (99.953)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.096)	BT: 0.017 (0.118)	Loss 0.0124 (0.0093)	Prec@1 100.000 (99.957)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.101)	BT: 0.019 (0.122)	Loss 0.0148 (0.0098)	Prec@1 100.000 (99.946)	
Total train loss: 0.0098
Avg Loading time: 0.1008 seconds
Avg Batch time: 0.1219 seconds

Train time: 47.822457790374756
 * Prec@1 71.840 Prec@5 89.890 Loss 1.3027
Avg Loading time: 0.0791 seconds
Avg Batch time: 0.0888 seconds

Best acc: 71.840
--------------------------------------------------------------------------------
Test time: 8.027830123901367

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.076)	BT: 0.017 (0.098)	Loss 0.0039 (0.0082)	Prec@1 100.000 (99.990)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.259 (0.066)	BT: 0.281 (0.089)	Loss 0.0067 (0.0088)	Prec@1 100.000 (99.965)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.060)	BT: 0.040 (0.082)	Loss 0.0059 (0.0088)	Prec@1 100.000 (99.967)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.058)	BT: 0.028 (0.082)	Loss 0.0069 (0.0090)	Prec@1 100.000 (99.960)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.058)	BT: 0.017 (0.082)	Loss 0.0066 (0.0092)	Prec@1 100.000 (99.954)	
Total train loss: 0.0092
Avg Loading time: 0.0583 seconds
Avg Batch time: 0.0817 seconds

Train time: 32.06506133079529
 * Prec@1 71.820 Prec@5 89.840 Loss 1.2959
Avg Loading time: 0.0602 seconds
Avg Batch time: 0.0701 seconds

Best acc: 71.840
--------------------------------------------------------------------------------
Test time: 6.121814727783203

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.072)	BT: 0.018 (0.097)	Loss 0.0079 (0.0085)	Prec@1 100.000 (99.980)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.071)	BT: 0.019 (0.095)	Loss 0.0039 (0.0087)	Prec@1 100.000 (99.950)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.068)	BT: 0.038 (0.091)	Loss 0.0136 (0.0090)	Prec@1 100.000 (99.947)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.068)	BT: 0.028 (0.091)	Loss 0.0089 (0.0086)	Prec@1 100.000 (99.952)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.063)	BT: 0.016 (0.086)	Loss 0.0305 (0.0088)	Prec@1 99.219 (99.944)	
Total train loss: 0.0088
Avg Loading time: 0.0627 seconds
Avg Batch time: 0.0863 seconds

Train time: 33.88421607017517
 * Prec@1 71.900 Prec@5 89.930 Loss 1.2998
Avg Loading time: 0.0812 seconds
Avg Batch time: 0.0905 seconds

Best acc: 71.900
--------------------------------------------------------------------------------
Test time: 8.049692392349243

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.075)	BT: 0.022 (0.098)	Loss 0.0049 (0.0086)	Prec@1 100.000 (99.960)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.075)	BT: 0.029 (0.098)	Loss 0.0094 (0.0084)	Prec@1 100.000 (99.950)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.072)	BT: 0.016 (0.094)	Loss 0.0121 (0.0085)	Prec@1 100.000 (99.943)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.073)	BT: 0.019 (0.095)	Loss 0.0058 (0.0081)	Prec@1 100.000 (99.955)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.072)	BT: 0.020 (0.095)	Loss 0.0056 (0.0080)	Prec@1 100.000 (99.958)	
Total train loss: 0.0080
Avg Loading time: 0.0723 seconds
Avg Batch time: 0.0946 seconds

Train time: 37.1164984703064
 * Prec@1 71.690 Prec@5 89.810 Loss 1.3047
Avg Loading time: 0.0996 seconds
Avg Batch time: 0.1096 seconds

Best acc: 71.900
--------------------------------------------------------------------------------
Test time: 9.215547323226929

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.072)	BT: 0.028 (0.094)	Loss 0.0060 (0.0090)	Prec@1 100.000 (99.930)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.067)	BT: 0.035 (0.089)	Loss 0.0071 (0.0083)	Prec@1 100.000 (99.955)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.064)	BT: 0.017 (0.084)	Loss 0.0096 (0.0082)	Prec@1 100.000 (99.960)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.063)	BT: 0.026 (0.084)	Loss 0.0085 (0.0082)	Prec@1 100.000 (99.965)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.060)	BT: 0.019 (0.081)	Loss 0.0080 (0.0083)	Prec@1 100.000 (99.962)	
Total train loss: 0.0083
Avg Loading time: 0.0598 seconds
Avg Batch time: 0.0808 seconds

Train time: 31.776291370391846
 * Prec@1 71.830 Prec@5 89.890 Loss 1.2998
Avg Loading time: 0.0716 seconds
Avg Batch time: 0.0808 seconds

Best acc: 71.900
--------------------------------------------------------------------------------
Test time: 6.940634489059448

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.078)	BT: 0.020 (0.102)	Loss 0.0158 (0.0088)	Prec@1 99.219 (99.930)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.077)	BT: 0.018 (0.099)	Loss 0.0103 (0.0083)	Prec@1 100.000 (99.940)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.565 (0.075)	BT: 0.581 (0.097)	Loss 0.0041 (0.0083)	Prec@1 100.000 (99.937)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.072)	BT: 0.027 (0.095)	Loss 0.0032 (0.0081)	Prec@1 100.000 (99.942)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.072)	BT: 0.014 (0.095)	Loss 0.0076 (0.0082)	Prec@1 100.000 (99.942)	
Total train loss: 0.0082
Avg Loading time: 0.0716 seconds
Avg Batch time: 0.0944 seconds

Train time: 37.051488637924194
 * Prec@1 71.900 Prec@5 89.870 Loss 1.2949
Avg Loading time: 0.1068 seconds
Avg Batch time: 0.1161 seconds

Best acc: 71.900
--------------------------------------------------------------------------------
Test time: 9.732419490814209

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.082)	BT: 0.018 (0.102)	Loss 0.0070 (0.0071)	Prec@1 100.000 (99.980)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.073)	BT: 0.017 (0.094)	Loss 0.0078 (0.0079)	Prec@1 100.000 (99.960)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.073)	BT: 0.032 (0.095)	Loss 0.0033 (0.0080)	Prec@1 100.000 (99.963)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.075)	BT: 0.026 (0.097)	Loss 0.0168 (0.0081)	Prec@1 100.000 (99.960)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.075)	BT: 0.024 (0.098)	Loss 0.0039 (0.0081)	Prec@1 100.000 (99.958)	
Total train loss: 0.0081
Avg Loading time: 0.0750 seconds
Avg Batch time: 0.0975 seconds

Train time: 38.32917833328247
 * Prec@1 71.860 Prec@5 89.980 Loss 1.2969
Avg Loading time: 0.0825 seconds
Avg Batch time: 0.0930 seconds

Best acc: 71.900
--------------------------------------------------------------------------------
Test time: 8.04926061630249

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.089)	BT: 0.016 (0.109)	Loss 0.0075 (0.0080)	Prec@1 100.000 (99.960)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.086)	BT: 0.031 (0.106)	Loss 0.0090 (0.0081)	Prec@1 100.000 (99.955)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.360 (0.085)	BT: 0.385 (0.106)	Loss 0.0052 (0.0081)	Prec@1 100.000 (99.957)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.081)	BT: 0.019 (0.103)	Loss 0.0081 (0.0083)	Prec@1 100.000 (99.945)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.078)	BT: 0.019 (0.100)	Loss 0.0072 (0.0083)	Prec@1 100.000 (99.944)	
Total train loss: 0.0084
Avg Loading time: 0.0774 seconds
Avg Batch time: 0.0994 seconds

Train time: 39.00216889381409
 * Prec@1 71.840 Prec@5 89.940 Loss 1.3037
Avg Loading time: 0.0883 seconds
Avg Batch time: 0.0973 seconds

Best acc: 71.900
--------------------------------------------------------------------------------
Test time: 8.234517097473145

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.086)	BT: 0.016 (0.107)	Loss 0.0087 (0.0094)	Prec@1 100.000 (99.950)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.125 (0.082)	BT: 0.152 (0.103)	Loss 0.0096 (0.0088)	Prec@1 100.000 (99.940)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.049 (0.083)	BT: 0.091 (0.104)	Loss 0.0064 (0.0083)	Prec@1 100.000 (99.953)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.082)	BT: 0.017 (0.104)	Loss 0.0041 (0.0081)	Prec@1 100.000 (99.962)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.080)	BT: 0.015 (0.102)	Loss 0.0031 (0.0081)	Prec@1 100.000 (99.964)	
Total train loss: 0.0081
Avg Loading time: 0.0803 seconds
Avg Batch time: 0.1016 seconds

Train time: 39.8935866355896
 * Prec@1 71.860 Prec@5 89.930 Loss 1.2949
Avg Loading time: 0.0753 seconds
Avg Batch time: 0.0846 seconds

Best acc: 71.900
--------------------------------------------------------------------------------
Test time: 7.266840219497681

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.095)	BT: 0.023 (0.117)	Loss 0.0084 (0.0086)	Prec@1 100.000 (99.950)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.078)	BT: 0.036 (0.100)	Loss 0.0155 (0.0087)	Prec@1 100.000 (99.955)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.079)	BT: 0.019 (0.101)	Loss 0.0084 (0.0082)	Prec@1 100.000 (99.960)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.077)	BT: 0.016 (0.098)	Loss 0.0030 (0.0081)	Prec@1 100.000 (99.962)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.073)	BT: 0.016 (0.094)	Loss 0.0041 (0.0081)	Prec@1 100.000 (99.962)	
Total train loss: 0.0081
Avg Loading time: 0.0729 seconds
Avg Batch time: 0.0937 seconds

Train time: 36.75200271606445
 * Prec@1 71.910 Prec@5 89.900 Loss 1.2998
Avg Loading time: 0.3979 seconds
Avg Batch time: 0.4080 seconds

Best acc: 71.910
--------------------------------------------------------------------------------
Test time: 33.135772466659546

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.544)	BT: 0.021 (0.565)	Loss 0.0029 (0.0089)	Prec@1 100.000 (99.940)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.425)	BT: 0.020 (0.445)	Loss 0.0200 (0.0086)	Prec@1 99.219 (99.945)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 3.237 (0.499)	BT: 3.263 (0.519)	Loss 0.0134 (0.0085)	Prec@1 100.000 (99.950)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.542)	BT: 0.020 (0.563)	Loss 0.0069 (0.0084)	Prec@1 100.000 (99.952)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.552)	BT: 0.023 (0.573)	Loss 0.0073 (0.0082)	Prec@1 100.000 (99.952)	
Total train loss: 0.0083
Avg Loading time: 0.5505 seconds
Avg Batch time: 0.5711 seconds

Train time: 223.4400565624237
 * Prec@1 71.790 Prec@5 89.890 Loss 1.3047
Avg Loading time: 0.6243 seconds
Avg Batch time: 0.6329 seconds

Best acc: 71.910
--------------------------------------------------------------------------------
Test time: 50.53004050254822

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.001 (0.626)	BT: 0.025 (0.646)	Loss 0.0068 (0.0083)	Prec@1 100.000 (99.950)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.613)	BT: 0.018 (0.633)	Loss 0.0071 (0.0078)	Prec@1 100.000 (99.965)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.615)	BT: 0.020 (0.635)	Loss 0.0076 (0.0082)	Prec@1 100.000 (99.960)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.601)	BT: 0.018 (0.620)	Loss 0.0080 (0.0079)	Prec@1 100.000 (99.965)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.602)	BT: 0.019 (0.622)	Loss 0.0050 (0.0081)	Prec@1 100.000 (99.960)	
Total train loss: 0.0081
Avg Loading time: 0.6007 seconds
Avg Batch time: 0.6205 seconds

Train time: 242.73025584220886
 * Prec@1 71.810 Prec@5 89.890 Loss 1.3027
Avg Loading time: 0.6897 seconds
Avg Batch time: 0.6980 seconds

Best acc: 71.910
--------------------------------------------------------------------------------
Test time: 55.691380739212036

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.298)	BT: 0.018 (0.319)	Loss 0.0059 (0.0088)	Prec@1 100.000 (99.960)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.207)	BT: 0.016 (0.226)	Loss 0.0119 (0.0082)	Prec@1 100.000 (99.975)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.181)	BT: 0.018 (0.200)	Loss 0.0022 (0.0084)	Prec@1 100.000 (99.963)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.161)	BT: 0.020 (0.181)	Loss 0.0070 (0.0082)	Prec@1 100.000 (99.965)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.150)	BT: 0.019 (0.170)	Loss 0.0075 (0.0081)	Prec@1 100.000 (99.964)	
Total train loss: 0.0081
Avg Loading time: 0.1493 seconds
Avg Batch time: 0.1699 seconds

Train time: 66.53432655334473
 * Prec@1 71.970 Prec@5 89.850 Loss 1.3066
Avg Loading time: 0.1237 seconds
Avg Batch time: 0.1326 seconds

Best acc: 71.970
--------------------------------------------------------------------------------
Test time: 11.425071001052856

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.077)	BT: 0.017 (0.098)	Loss 0.0029 (0.0070)	Prec@1 100.000 (99.980)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.093)	BT: 0.016 (0.113)	Loss 0.0073 (0.0077)	Prec@1 100.000 (99.980)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.097)	BT: 0.022 (0.117)	Loss 0.0042 (0.0079)	Prec@1 100.000 (99.973)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.107)	BT: 0.019 (0.127)	Loss 0.0065 (0.0078)	Prec@1 100.000 (99.967)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.116)	BT: 0.024 (0.136)	Loss 0.0074 (0.0079)	Prec@1 100.000 (99.962)	
Total train loss: 0.0079
Avg Loading time: 0.1159 seconds
Avg Batch time: 0.1356 seconds

Train time: 53.20794415473938
 * Prec@1 71.830 Prec@5 89.930 Loss 1.2969
Avg Loading time: 0.1627 seconds
Avg Batch time: 0.1724 seconds

Best acc: 71.970
--------------------------------------------------------------------------------
Test time: 14.202094316482544

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.011 (0.133)	BT: 0.030 (0.153)	Loss 0.0059 (0.0078)	Prec@1 100.000 (99.980)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.135)	BT: 0.019 (0.156)	Loss 0.0071 (0.0079)	Prec@1 100.000 (99.960)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.130)	BT: 0.022 (0.151)	Loss 0.0109 (0.0078)	Prec@1 100.000 (99.963)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.132)	BT: 0.020 (0.153)	Loss 0.0027 (0.0080)	Prec@1 100.000 (99.960)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.133)	BT: 0.018 (0.154)	Loss 0.0051 (0.0079)	Prec@1 100.000 (99.960)	
Total train loss: 0.0079
Avg Loading time: 0.1331 seconds
Avg Batch time: 0.1540 seconds

Train time: 60.3936402797699
 * Prec@1 71.770 Prec@5 89.860 Loss 1.3057
Avg Loading time: 0.1580 seconds
Avg Batch time: 0.1663 seconds

Best acc: 71.970
--------------------------------------------------------------------------------
Test time: 13.719222068786621

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.131)	BT: 0.019 (0.153)	Loss 0.0075 (0.0078)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.133)	BT: 0.020 (0.153)	Loss 0.0253 (0.0079)	Prec@1 99.219 (99.985)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.143)	BT: 0.030 (0.163)	Loss 0.0117 (0.0078)	Prec@1 100.000 (99.977)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.140)	BT: 0.031 (0.161)	Loss 0.0103 (0.0078)	Prec@1 100.000 (99.975)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.137)	BT: 0.015 (0.157)	Loss 0.0112 (0.0078)	Prec@1 100.000 (99.970)	
Total train loss: 0.0078
Avg Loading time: 0.1364 seconds
Avg Batch time: 0.1568 seconds

Train time: 61.4849591255188
 * Prec@1 71.700 Prec@5 89.890 Loss 1.2998
Avg Loading time: 0.1620 seconds
Avg Batch time: 0.1706 seconds

Best acc: 71.970
--------------------------------------------------------------------------------
Test time: 14.064353704452515

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.121)	BT: 0.019 (0.143)	Loss 0.0032 (0.0081)	Prec@1 100.000 (99.980)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.106)	BT: 0.019 (0.129)	Loss 0.0072 (0.0080)	Prec@1 100.000 (99.970)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.426 (0.105)	BT: 0.450 (0.127)	Loss 0.0170 (0.0082)	Prec@1 99.219 (99.960)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.105)	BT: 0.020 (0.126)	Loss 0.0043 (0.0079)	Prec@1 100.000 (99.970)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.101)	BT: 0.018 (0.122)	Loss 0.0061 (0.0078)	Prec@1 100.000 (99.968)	
Total train loss: 0.0079
Avg Loading time: 0.1008 seconds
Avg Batch time: 0.1221 seconds

Train time: 47.936848163604736
 * Prec@1 71.810 Prec@5 89.790 Loss 1.2979
Avg Loading time: 0.0955 seconds
Avg Batch time: 0.1045 seconds

Best acc: 71.970
--------------------------------------------------------------------------------
Test time: 8.803014755249023

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.095)	BT: 0.018 (0.115)	Loss 0.0040 (0.0075)	Prec@1 100.000 (99.940)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.089)	BT: 0.017 (0.110)	Loss 0.0054 (0.0076)	Prec@1 100.000 (99.950)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.089)	BT: 0.018 (0.111)	Loss 0.0134 (0.0076)	Prec@1 100.000 (99.943)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.088)	BT: 0.020 (0.110)	Loss 0.0059 (0.0076)	Prec@1 100.000 (99.955)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.088)	BT: 0.015 (0.109)	Loss 0.0049 (0.0077)	Prec@1 100.000 (99.948)	
Total train loss: 0.0077
Avg Loading time: 0.0874 seconds
Avg Batch time: 0.1087 seconds

Train time: 42.61179852485657
 * Prec@1 71.950 Prec@5 89.980 Loss 1.2939
Avg Loading time: 0.1053 seconds
Avg Batch time: 0.1147 seconds

Best acc: 71.970
--------------------------------------------------------------------------------
Test time: 9.721295356750488

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.059)	BT: 0.047 (0.082)	Loss 0.0063 (0.0078)	Prec@1 100.000 (99.960)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.049 (0.048)	BT: 0.069 (0.073)	Loss 0.0041 (0.0084)	Prec@1 100.000 (99.950)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.045)	BT: 0.041 (0.070)	Loss 0.0075 (0.0080)	Prec@1 100.000 (99.960)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.042)	BT: 0.016 (0.068)	Loss 0.0047 (0.0079)	Prec@1 100.000 (99.965)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.052)	BT: 0.017 (0.077)	Loss 0.0060 (0.0080)	Prec@1 100.000 (99.964)	
Total train loss: 0.0080
Avg Loading time: 0.0523 seconds
Avg Batch time: 0.0773 seconds

Train time: 30.349959135055542
 * Prec@1 71.840 Prec@5 89.860 Loss 1.3027
Avg Loading time: 0.1182 seconds
Avg Batch time: 0.1268 seconds

Best acc: 71.970
--------------------------------------------------------------------------------
Test time: 10.589317321777344

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.080)	BT: 0.019 (0.102)	Loss 0.0129 (0.0092)	Prec@1 99.219 (99.900)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.092)	BT: 0.020 (0.114)	Loss 0.0031 (0.0085)	Prec@1 100.000 (99.935)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.099)	BT: 0.015 (0.119)	Loss 0.0068 (0.0083)	Prec@1 100.000 (99.937)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.111)	BT: 0.019 (0.132)	Loss 0.0112 (0.0082)	Prec@1 100.000 (99.940)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.309 (0.111)	BT: 0.331 (0.132)	Loss 0.0084 (0.0082)	Prec@1 100.000 (99.940)	
Total train loss: 0.0082
Avg Loading time: 0.1109 seconds
Avg Batch time: 0.1319 seconds

Train time: 51.69707775115967
 * Prec@1 71.960 Prec@5 89.940 Loss 1.3027
Avg Loading time: 0.1867 seconds
Avg Batch time: 0.1954 seconds

Best acc: 71.970
--------------------------------------------------------------------------------
Test time: 15.983739614486694

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.127)	BT: 0.019 (0.148)	Loss 0.0062 (0.0084)	Prec@1 100.000 (99.960)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.119)	BT: 0.021 (0.140)	Loss 0.0181 (0.0085)	Prec@1 99.219 (99.935)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.119)	BT: 0.017 (0.141)	Loss 0.0067 (0.0083)	Prec@1 100.000 (99.950)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.128)	BT: 0.019 (0.150)	Loss 0.0141 (0.0083)	Prec@1 100.000 (99.947)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.129)	BT: 0.024 (0.150)	Loss 0.0070 (0.0081)	Prec@1 100.000 (99.948)	
Total train loss: 0.0081
Avg Loading time: 0.1300 seconds
Avg Batch time: 0.1516 seconds

Train time: 59.43672060966492
 * Prec@1 71.700 Prec@5 89.900 Loss 1.3037
Avg Loading time: 0.1934 seconds
Avg Batch time: 0.2031 seconds

Best acc: 71.970
--------------------------------------------------------------------------------
Test time: 16.63487958908081

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.106)	BT: 0.016 (0.128)	Loss 0.0138 (0.0078)	Prec@1 100.000 (99.950)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.122)	BT: 0.019 (0.143)	Loss 0.0053 (0.0079)	Prec@1 100.000 (99.940)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.128)	BT: 0.021 (0.149)	Loss 0.0056 (0.0082)	Prec@1 100.000 (99.937)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.122)	BT: 0.030 (0.142)	Loss 0.0054 (0.0081)	Prec@1 100.000 (99.940)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.222 (0.110)	BT: 0.245 (0.131)	Loss 0.0074 (0.0080)	Prec@1 100.000 (99.950)	
Total train loss: 0.0080
Avg Loading time: 0.1096 seconds
Avg Batch time: 0.1309 seconds

Train time: 51.35745668411255
 * Prec@1 71.840 Prec@5 90.040 Loss 1.3057
Avg Loading time: 0.0970 seconds
Avg Batch time: 0.1070 seconds

Best acc: 71.970
--------------------------------------------------------------------------------
Test time: 8.977774858474731

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.076)	BT: 0.025 (0.097)	Loss 0.0121 (0.0076)	Prec@1 100.000 (99.960)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.063)	BT: 0.017 (0.085)	Loss 0.0069 (0.0079)	Prec@1 100.000 (99.970)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.358 (0.067)	BT: 0.377 (0.088)	Loss 0.0076 (0.0082)	Prec@1 100.000 (99.953)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.070)	BT: 0.019 (0.091)	Loss 0.0063 (0.0079)	Prec@1 100.000 (99.962)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.016 (0.071)	BT: 0.034 (0.093)	Loss 0.0132 (0.0079)	Prec@1 100.000 (99.964)	
Total train loss: 0.0079
Avg Loading time: 0.0708 seconds
Avg Batch time: 0.0927 seconds

Train time: 36.377591371536255
 * Prec@1 71.750 Prec@5 89.880 Loss 1.3018
Avg Loading time: 0.0690 seconds
Avg Batch time: 0.0804 seconds

Best acc: 71.970
--------------------------------------------------------------------------------
Test time: 6.898053884506226

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.001 (0.084)	BT: 0.032 (0.106)	Loss 0.0082 (0.0088)	Prec@1 100.000 (99.930)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.075)	BT: 0.016 (0.097)	Loss 0.0045 (0.0086)	Prec@1 100.000 (99.940)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.077)	BT: 0.025 (0.098)	Loss 0.0072 (0.0083)	Prec@1 100.000 (99.943)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.080)	BT: 0.022 (0.102)	Loss 0.0074 (0.0080)	Prec@1 100.000 (99.950)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.080)	BT: 0.024 (0.101)	Loss 0.0124 (0.0078)	Prec@1 99.219 (99.954)	
Total train loss: 0.0078
Avg Loading time: 0.0794 seconds
Avg Batch time: 0.1010 seconds

Train time: 39.64767408370972
 * Prec@1 71.890 Prec@5 89.920 Loss 1.2959
Avg Loading time: 0.1102 seconds
Avg Batch time: 0.1195 seconds

Best acc: 71.970
--------------------------------------------------------------------------------
Test time: 10.041483879089355

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.084)	BT: 0.027 (0.104)	Loss 0.0262 (0.0089)	Prec@1 99.219 (99.940)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.079)	BT: 0.039 (0.100)	Loss 0.0305 (0.0083)	Prec@1 99.219 (99.955)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.070)	BT: 0.016 (0.092)	Loss 0.0049 (0.0082)	Prec@1 100.000 (99.950)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.076)	BT: 0.019 (0.098)	Loss 0.0046 (0.0083)	Prec@1 100.000 (99.945)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.078)	BT: 0.019 (0.099)	Loss 0.0082 (0.0080)	Prec@1 100.000 (99.952)	
Total train loss: 0.0080
Avg Loading time: 0.0773 seconds
Avg Batch time: 0.0991 seconds

Train time: 38.86540627479553
 * Prec@1 72.030 Prec@5 89.800 Loss 1.2988
Avg Loading time: 0.1140 seconds
Avg Batch time: 0.1232 seconds

Best acc: 72.030
--------------------------------------------------------------------------------
Test time: 10.67887544631958

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.066 (0.091)	BT: 0.086 (0.112)	Loss 0.0059 (0.0082)	Prec@1 100.000 (99.950)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.088)	BT: 0.018 (0.109)	Loss 0.0059 (0.0077)	Prec@1 100.000 (99.960)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.081)	BT: 0.025 (0.102)	Loss 0.0094 (0.0080)	Prec@1 100.000 (99.947)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.081)	BT: 0.019 (0.102)	Loss 0.0076 (0.0079)	Prec@1 100.000 (99.947)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.084)	BT: 0.018 (0.105)	Loss 0.0052 (0.0078)	Prec@1 100.000 (99.952)	
Total train loss: 0.0079
Avg Loading time: 0.0837 seconds
Avg Batch time: 0.1048 seconds

Train time: 41.090222120285034
 * Prec@1 71.750 Prec@5 89.880 Loss 1.2998
Avg Loading time: 0.0990 seconds
Avg Batch time: 0.1084 seconds

Best acc: 72.030
--------------------------------------------------------------------------------
Test time: 9.151646137237549

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.100)	BT: 0.021 (0.122)	Loss 0.0124 (0.0081)	Prec@1 100.000 (99.940)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.090)	BT: 0.018 (0.112)	Loss 0.0098 (0.0078)	Prec@1 100.000 (99.945)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.087)	BT: 0.019 (0.109)	Loss 0.0102 (0.0078)	Prec@1 100.000 (99.950)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.083)	BT: 0.019 (0.105)	Loss 0.0085 (0.0076)	Prec@1 100.000 (99.957)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.085)	BT: 0.019 (0.106)	Loss 0.0077 (0.0077)	Prec@1 100.000 (99.954)	
Total train loss: 0.0077
Avg Loading time: 0.0844 seconds
Avg Batch time: 0.1060 seconds

Train time: 41.62514615058899
 * Prec@1 71.940 Prec@5 89.990 Loss 1.2988
Avg Loading time: 0.0760 seconds
Avg Batch time: 0.0845 seconds

Best acc: 72.030
--------------------------------------------------------------------------------
Test time: 7.274551153182983

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.096)	BT: 0.016 (0.117)	Loss 0.0062 (0.0085)	Prec@1 100.000 (99.970)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.094)	BT: 0.027 (0.115)	Loss 0.0110 (0.0083)	Prec@1 100.000 (99.960)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.093)	BT: 0.023 (0.115)	Loss 0.0067 (0.0082)	Prec@1 100.000 (99.953)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.095)	BT: 0.029 (0.116)	Loss 0.0064 (0.0080)	Prec@1 100.000 (99.960)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.179 (0.093)	BT: 0.200 (0.115)	Loss 0.0108 (0.0081)	Prec@1 100.000 (99.954)	
Total train loss: 0.0081
Avg Loading time: 0.0929 seconds
Avg Batch time: 0.1151 seconds

Train time: 45.15539884567261
 * Prec@1 71.870 Prec@5 89.860 Loss 1.2988
Avg Loading time: 0.0964 seconds
Avg Batch time: 0.1074 seconds

Best acc: 72.030
--------------------------------------------------------------------------------
Test time: 9.103578805923462

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.098)	BT: 0.017 (0.119)	Loss 0.0063 (0.0085)	Prec@1 100.000 (99.960)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.091)	BT: 0.019 (0.112)	Loss 0.0110 (0.0081)	Prec@1 100.000 (99.960)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.091)	BT: 0.019 (0.112)	Loss 0.0064 (0.0082)	Prec@1 100.000 (99.960)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.089)	BT: 0.017 (0.110)	Loss 0.0154 (0.0080)	Prec@1 100.000 (99.952)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.089)	BT: 0.015 (0.110)	Loss 0.0131 (0.0081)	Prec@1 100.000 (99.954)	
Total train loss: 0.0081
Avg Loading time: 0.0889 seconds
Avg Batch time: 0.1102 seconds

Train time: 43.180964946746826
 * Prec@1 71.910 Prec@5 90.030 Loss 1.2988
Avg Loading time: 0.0877 seconds
Avg Batch time: 0.0984 seconds

Best acc: 72.030
--------------------------------------------------------------------------------
Test time: 8.35261869430542

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.094)	BT: 0.019 (0.115)	Loss 0.0053 (0.0076)	Prec@1 100.000 (99.960)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.089)	BT: 0.026 (0.110)	Loss 0.0067 (0.0083)	Prec@1 100.000 (99.935)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.424 (0.090)	BT: 0.448 (0.111)	Loss 0.0090 (0.0081)	Prec@1 100.000 (99.950)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.446 (0.088)	BT: 0.471 (0.110)	Loss 0.0054 (0.0079)	Prec@1 100.000 (99.950)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.088)	BT: 0.016 (0.110)	Loss 0.0088 (0.0080)	Prec@1 100.000 (99.952)	
Total train loss: 0.0080
Avg Loading time: 0.0879 seconds
Avg Batch time: 0.1093 seconds

Train time: 42.92244482040405
 * Prec@1 71.690 Prec@5 89.920 Loss 1.3076
Avg Loading time: 0.1238 seconds
Avg Batch time: 0.1329 seconds

Best acc: 72.030
--------------------------------------------------------------------------------
Test time: 11.0186607837677

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.093)	BT: 0.015 (0.112)	Loss 0.0049 (0.0084)	Prec@1 100.000 (99.920)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.077)	BT: 0.018 (0.096)	Loss 0.0091 (0.0079)	Prec@1 100.000 (99.945)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.147 (0.079)	BT: 0.165 (0.099)	Loss 0.0115 (0.0080)	Prec@1 100.000 (99.937)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.273 (0.083)	BT: 0.297 (0.104)	Loss 0.0066 (0.0080)	Prec@1 100.000 (99.942)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.086)	BT: 0.015 (0.107)	Loss 0.0046 (0.0082)	Prec@1 100.000 (99.936)	
Total train loss: 0.0082
Avg Loading time: 0.0853 seconds
Avg Batch time: 0.1070 seconds

Train time: 42.006208181381226
 * Prec@1 71.910 Prec@5 89.890 Loss 1.3057
Avg Loading time: 0.0953 seconds
Avg Batch time: 0.1043 seconds

Best acc: 72.030
--------------------------------------------------------------------------------
Test time: 8.785488605499268

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.085)	BT: 0.016 (0.107)	Loss 0.0037 (0.0083)	Prec@1 100.000 (99.960)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.086)	BT: 0.020 (0.107)	Loss 0.0045 (0.0083)	Prec@1 100.000 (99.970)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.291 (0.087)	BT: 0.315 (0.108)	Loss 0.0138 (0.0083)	Prec@1 100.000 (99.967)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.088)	BT: 0.022 (0.109)	Loss 0.0059 (0.0083)	Prec@1 100.000 (99.962)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.090)	BT: 0.024 (0.112)	Loss 0.0049 (0.0081)	Prec@1 100.000 (99.970)	
Total train loss: 0.0081
Avg Loading time: 0.0901 seconds
Avg Batch time: 0.1115 seconds

Train time: 43.75199508666992
 * Prec@1 71.790 Prec@5 90.040 Loss 1.2939
Avg Loading time: 0.1171 seconds
Avg Batch time: 0.1265 seconds

Best acc: 72.030
--------------------------------------------------------------------------------
Test time: 10.568417072296143

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.075 (0.113)	BT: 0.094 (0.133)	Loss 0.0071 (0.0085)	Prec@1 100.000 (99.950)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.096)	BT: 0.018 (0.117)	Loss 0.0257 (0.0079)	Prec@1 99.219 (99.955)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.101)	BT: 0.020 (0.121)	Loss 0.0069 (0.0080)	Prec@1 100.000 (99.947)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.094)	BT: 0.021 (0.114)	Loss 0.0051 (0.0079)	Prec@1 100.000 (99.960)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.096)	BT: 0.016 (0.116)	Loss 0.0045 (0.0080)	Prec@1 100.000 (99.966)	
Total train loss: 0.0080
Avg Loading time: 0.0960 seconds
Avg Batch time: 0.1159 seconds

Train time: 45.424724102020264
 * Prec@1 72.000 Prec@5 89.860 Loss 1.2959
Avg Loading time: 0.0984 seconds
Avg Batch time: 0.1087 seconds

Best acc: 72.030
--------------------------------------------------------------------------------
Test time: 9.19315481185913


      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 0
          frozen_layers: 15
Savedir:  ../pretrained_models/frozen/x64-8b/rram/cifar100/resnet18
DEVICE: cuda
GPU Id(s) being used: 0
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar100/resnet18/train/relu15
Test path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar100/resnet18/test/relu15
ResNet18(
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=100, bias=False)
  (bn19): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 0.980 Prec@5 5.100 Loss 4.6094
Avg Loading time: 0.4750 seconds
Avg Batch time: 0.4869 seconds

Pre-trained Prec@1 with 15 layers frozen: 0.9799999594688416 	 Loss: 4.609375

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (1.276)	BT: 0.009 (1.288)	Loss 1.7480 (2.5229)	Prec@1 54.688 (39.673)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (1.209)	BT: 0.012 (1.221)	Loss 1.6309 (2.1535)	Prec@1 58.594 (46.124)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.539 (1.140)	BT: 0.556 (1.152)	Loss 1.9854 (1.9796)	Prec@1 53.125 (49.182)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (1.087)	BT: 0.009 (1.099)	Loss 1.6836 (1.8672)	Prec@1 55.469 (51.332)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (1.068)	BT: 0.009 (1.080)	Loss 1.4492 (1.7928)	Prec@1 57.031 (52.827)	
Total train loss: 1.7924
Avg Loading time: 1.0652 seconds
Avg Batch time: 1.0772 seconds

Train time: 421.2796823978424
 * Prec@1 60.230 Prec@5 87.610 Loss 1.4277
Avg Loading time: 0.1432 seconds
Avg Batch time: 0.1504 seconds

Best acc: 60.230
--------------------------------------------------------------------------------
Test time: 12.496932744979858

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.144)	BT: 0.017 (0.156)	Loss 0.9121 (1.1071)	Prec@1 75.000 (68.570)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.128)	BT: 0.017 (0.140)	Loss 1.0508 (1.1260)	Prec@1 68.750 (67.904)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.125)	BT: 0.019 (0.138)	Loss 1.3682 (1.1363)	Prec@1 64.844 (67.491)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.122)	BT: 0.010 (0.134)	Loss 1.3359 (1.1508)	Prec@1 60.938 (67.107)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.118)	BT: 0.011 (0.131)	Loss 1.1826 (1.1570)	Prec@1 64.844 (66.965)	
Total train loss: 1.1571
Avg Loading time: 0.1182 seconds
Avg Batch time: 0.1303 seconds

Train time: 51.096370697021484
 * Prec@1 63.470 Prec@5 89.240 Loss 1.3184
Avg Loading time: 0.1097 seconds
Avg Batch time: 0.1160 seconds

Best acc: 63.470
--------------------------------------------------------------------------------
Test time: 9.755614757537842

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.082)	BT: 0.009 (0.093)	Loss 0.6860 (0.8005)	Prec@1 76.562 (76.583)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.108)	BT: 0.009 (0.120)	Loss 0.7466 (0.8230)	Prec@1 78.125 (75.781)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (0.107)	BT: 0.019 (0.118)	Loss 0.6816 (0.8377)	Prec@1 78.125 (75.421)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.104)	BT: 0.009 (0.115)	Loss 1.1289 (0.8582)	Prec@1 67.188 (74.850)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.105)	BT: 0.009 (0.116)	Loss 1.0459 (0.8780)	Prec@1 74.219 (74.231)	
Total train loss: 0.8787
Avg Loading time: 0.1047 seconds
Avg Batch time: 0.1162 seconds

Train time: 45.55681753158569
 * Prec@1 63.410 Prec@5 88.480 Loss 1.3711
Avg Loading time: 0.1051 seconds
Avg Batch time: 0.1103 seconds

Best acc: 63.470
--------------------------------------------------------------------------------
Test time: 9.066983699798584

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.090)	BT: 0.010 (0.102)	Loss 0.6348 (0.5696)	Prec@1 84.375 (83.544)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.102)	BT: 0.009 (0.114)	Loss 0.6807 (0.5890)	Prec@1 78.125 (82.682)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.102)	BT: 0.010 (0.113)	Loss 0.7056 (0.6074)	Prec@1 78.906 (82.045)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.096)	BT: 0.013 (0.108)	Loss 0.7236 (0.6363)	Prec@1 78.125 (81.105)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.102)	BT: 0.011 (0.114)	Loss 0.5879 (0.6555)	Prec@1 85.156 (80.457)	
Total train loss: 0.6560
Avg Loading time: 0.1014 seconds
Avg Batch time: 0.1133 seconds

Train time: 44.456297159194946
 * Prec@1 63.120 Prec@5 88.400 Loss 1.3877
Avg Loading time: 0.0986 seconds
Avg Batch time: 0.1038 seconds

Best acc: 63.470
--------------------------------------------------------------------------------
Test time: 8.555655002593994

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.084)	BT: 0.009 (0.096)	Loss 0.3494 (0.3863)	Prec@1 91.406 (88.932)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.087)	BT: 0.019 (0.099)	Loss 0.3665 (0.3918)	Prec@1 86.719 (88.552)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.099 (0.089)	BT: 0.114 (0.101)	Loss 0.4167 (0.4067)	Prec@1 87.500 (87.834)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.087)	BT: 0.018 (0.098)	Loss 0.6294 (0.4322)	Prec@1 78.125 (86.999)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.093)	BT: 0.009 (0.105)	Loss 0.4810 (0.4591)	Prec@1 85.156 (85.960)	
Total train loss: 0.4597
Avg Loading time: 0.0925 seconds
Avg Batch time: 0.1043 seconds

Train time: 40.87963652610779
 * Prec@1 62.660 Prec@5 87.300 Loss 1.4873
Avg Loading time: 0.1027 seconds
Avg Batch time: 0.1089 seconds

Best acc: 63.470
--------------------------------------------------------------------------------
Test time: 9.037208080291748

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.121)	BT: 0.022 (0.133)	Loss 0.2551 (0.2770)	Prec@1 93.750 (91.827)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.119)	BT: 0.010 (0.132)	Loss 0.3115 (0.2830)	Prec@1 89.062 (91.712)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.000 (0.118)	BT: 0.010 (0.130)	Loss 0.3003 (0.2871)	Prec@1 92.969 (91.490)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.113)	BT: 0.013 (0.125)	Loss 0.3823 (0.3059)	Prec@1 90.625 (90.883)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.057 (0.113)	BT: 0.067 (0.125)	Loss 0.3159 (0.3254)	Prec@1 92.188 (90.234)	
Total train loss: 0.3256
Avg Loading time: 0.1127 seconds
Avg Batch time: 0.1250 seconds

Train time: 48.98972249031067
 * Prec@1 63.160 Prec@5 86.960 Loss 1.5938
Avg Loading time: 0.1106 seconds
Avg Batch time: 0.1163 seconds

Best acc: 63.470
--------------------------------------------------------------------------------
Test time: 9.577304601669312

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.131)	BT: 0.009 (0.143)	Loss 0.2494 (0.2268)	Prec@1 92.188 (93.440)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.131)	BT: 0.010 (0.143)	Loss 0.2054 (0.2201)	Prec@1 93.750 (93.650)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.120)	BT: 0.013 (0.131)	Loss 0.2886 (0.2227)	Prec@1 91.406 (93.483)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.114)	BT: 0.009 (0.126)	Loss 0.3020 (0.2280)	Prec@1 92.969 (93.292)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.117)	BT: 0.009 (0.129)	Loss 0.1805 (0.2348)	Prec@1 97.656 (93.119)	
Total train loss: 0.2350
Avg Loading time: 0.1169 seconds
Avg Batch time: 0.1283 seconds

Train time: 50.3072292804718
 * Prec@1 62.760 Prec@5 86.190 Loss 1.6660
Avg Loading time: 0.1159 seconds
Avg Batch time: 0.1204 seconds

Best acc: 63.470
--------------------------------------------------------------------------------
Test time: 9.930365562438965

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.090)	BT: 0.012 (0.101)	Loss 0.1558 (0.1535)	Prec@1 96.094 (95.813)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.087)	BT: 0.017 (0.099)	Loss 0.1683 (0.1526)	Prec@1 95.312 (95.818)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.086)	BT: 0.012 (0.098)	Loss 0.1678 (0.1590)	Prec@1 95.312 (95.593)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.089)	BT: 0.017 (0.101)	Loss 0.1858 (0.1662)	Prec@1 93.750 (95.290)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.083)	BT: 0.011 (0.096)	Loss 0.1909 (0.1745)	Prec@1 96.094 (95.028)	
Total train loss: 0.1745
Avg Loading time: 0.0829 seconds
Avg Batch time: 0.0953 seconds

Train time: 37.45856237411499
 * Prec@1 63.280 Prec@5 86.990 Loss 1.6348
Avg Loading time: 0.0559 seconds
Avg Batch time: 0.0629 seconds

Best acc: 63.470
--------------------------------------------------------------------------------
Test time: 5.381760358810425

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.051)	BT: 0.010 (0.064)	Loss 0.2201 (0.1329)	Prec@1 92.188 (96.364)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.081)	BT: 0.010 (0.093)	Loss 0.1285 (0.1281)	Prec@1 96.094 (96.630)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.374 (0.082)	BT: 0.390 (0.095)	Loss 0.1259 (0.1340)	Prec@1 97.656 (96.411)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.071 (0.084)	BT: 0.080 (0.096)	Loss 0.1777 (0.1409)	Prec@1 94.531 (96.169)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.089)	BT: 0.014 (0.101)	Loss 0.2272 (0.1485)	Prec@1 94.531 (95.909)	
Total train loss: 0.1488
Avg Loading time: 0.0891 seconds
Avg Batch time: 0.1012 seconds

Train time: 39.6655490398407
 * Prec@1 63.600 Prec@5 86.580 Loss 1.6699
Avg Loading time: 0.1290 seconds
Avg Batch time: 0.1351 seconds

Best acc: 63.600
--------------------------------------------------------------------------------
Test time: 11.295358657836914

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.095)	BT: 0.010 (0.107)	Loss 0.1106 (0.1256)	Prec@1 96.875 (96.554)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.096)	BT: 0.011 (0.108)	Loss 0.0487 (0.1210)	Prec@1 99.219 (96.725)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.099)	BT: 0.010 (0.111)	Loss 0.0721 (0.1190)	Prec@1 100.000 (96.782)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.105)	BT: 0.018 (0.117)	Loss 0.1573 (0.1201)	Prec@1 96.094 (96.750)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.106)	BT: 0.017 (0.118)	Loss 0.2010 (0.1236)	Prec@1 92.969 (96.649)	
Total train loss: 0.1236
Avg Loading time: 0.1059 seconds
Avg Batch time: 0.1182 seconds

Train time: 46.37751364707947
 * Prec@1 63.730 Prec@5 86.590 Loss 1.6768
Avg Loading time: 0.1073 seconds
Avg Batch time: 0.1131 seconds

Best acc: 63.730
--------------------------------------------------------------------------------
Test time: 9.488458156585693

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.091)	BT: 0.009 (0.104)	Loss 0.0559 (0.0756)	Prec@1 100.000 (98.187)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.305 (0.103)	BT: 0.321 (0.115)	Loss 0.0703 (0.0645)	Prec@1 98.438 (98.538)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.105)	BT: 0.016 (0.117)	Loss 0.0565 (0.0597)	Prec@1 98.438 (98.688)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.104)	BT: 0.009 (0.115)	Loss 0.0374 (0.0561)	Prec@1 99.219 (98.786)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.109)	BT: 0.009 (0.121)	Loss 0.0470 (0.0537)	Prec@1 98.438 (98.862)	
Total train loss: 0.0537
Avg Loading time: 0.1092 seconds
Avg Batch time: 0.1209 seconds

Train time: 47.43364405632019
 * Prec@1 67.040 Prec@5 87.950 Loss 1.4932
Avg Loading time: 0.1070 seconds
Avg Batch time: 0.1134 seconds

Best acc: 67.040
--------------------------------------------------------------------------------
Test time: 9.580454349517822

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.121)	BT: 0.010 (0.133)	Loss 0.0159 (0.0279)	Prec@1 100.000 (99.629)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.106)	BT: 0.012 (0.118)	Loss 0.0348 (0.0269)	Prec@1 99.219 (99.679)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.104)	BT: 0.011 (0.117)	Loss 0.0568 (0.0268)	Prec@1 99.219 (99.676)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.001 (0.106)	BT: 0.013 (0.119)	Loss 0.0146 (0.0271)	Prec@1 100.000 (99.659)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.107)	BT: 0.010 (0.119)	Loss 0.0221 (0.0270)	Prec@1 100.000 (99.651)	
Total train loss: 0.0270
Avg Loading time: 0.1065 seconds
Avg Batch time: 0.1190 seconds

Train time: 46.697803258895874
 * Prec@1 67.320 Prec@5 87.960 Loss 1.4980
Avg Loading time: 0.0560 seconds
Avg Batch time: 0.0616 seconds

Best acc: 67.320
--------------------------------------------------------------------------------
Test time: 5.471601963043213

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.050)	BT: 0.013 (0.066)	Loss 0.0188 (0.0198)	Prec@1 100.000 (99.870)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.057)	BT: 0.016 (0.072)	Loss 0.0168 (0.0201)	Prec@1 100.000 (99.865)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.073 (0.060)	BT: 0.085 (0.075)	Loss 0.0125 (0.0199)	Prec@1 100.000 (99.846)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.538 (0.064)	BT: 0.548 (0.079)	Loss 0.0348 (0.0196)	Prec@1 99.219 (99.857)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.066)	BT: 0.009 (0.080)	Loss 0.0345 (0.0202)	Prec@1 99.219 (99.840)	
Total train loss: 0.0202
Avg Loading time: 0.0654 seconds
Avg Batch time: 0.0795 seconds

Train time: 31.23699450492859
 * Prec@1 67.280 Prec@5 88.060 Loss 1.5098
Avg Loading time: 0.0680 seconds
Avg Batch time: 0.0750 seconds

Best acc: 67.320
--------------------------------------------------------------------------------
Test time: 6.321940660476685

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.069)	BT: 0.010 (0.082)	Loss 0.0157 (0.0175)	Prec@1 100.000 (99.900)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.124 (0.071)	BT: 0.140 (0.084)	Loss 0.0218 (0.0175)	Prec@1 100.000 (99.880)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.070)	BT: 0.014 (0.083)	Loss 0.0147 (0.0175)	Prec@1 100.000 (99.880)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.071)	BT: 0.013 (0.084)	Loss 0.0226 (0.0177)	Prec@1 99.219 (99.860)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.073)	BT: 0.030 (0.086)	Loss 0.0296 (0.0177)	Prec@1 99.219 (99.842)	
Total train loss: 0.0178
Avg Loading time: 0.0730 seconds
Avg Batch time: 0.0860 seconds

Train time: 33.81773233413696
 * Prec@1 67.500 Prec@5 87.830 Loss 1.4941
Avg Loading time: 0.1013 seconds
Avg Batch time: 0.1075 seconds

Best acc: 67.500
--------------------------------------------------------------------------------
Test time: 9.115076541900635

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.057)	BT: 0.010 (0.069)	Loss 0.0125 (0.0151)	Prec@1 100.000 (99.900)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.067)	BT: 0.013 (0.079)	Loss 0.0099 (0.0149)	Prec@1 100.000 (99.910)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.068)	BT: 0.014 (0.080)	Loss 0.0162 (0.0150)	Prec@1 100.000 (99.913)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.068)	BT: 0.009 (0.080)	Loss 0.0215 (0.0152)	Prec@1 100.000 (99.912)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.067)	BT: 0.009 (0.080)	Loss 0.0138 (0.0151)	Prec@1 100.000 (99.906)	
Total train loss: 0.0151
Avg Loading time: 0.0664 seconds
Avg Batch time: 0.0794 seconds

Train time: 31.203640699386597
 * Prec@1 67.640 Prec@5 87.810 Loss 1.5020
Avg Loading time: 0.0873 seconds
Avg Batch time: 0.0933 seconds

Best acc: 67.640
--------------------------------------------------------------------------------
Test time: 7.976791620254517

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.094)	BT: 0.010 (0.107)	Loss 0.0087 (0.0142)	Prec@1 100.000 (99.900)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.082)	BT: 0.013 (0.095)	Loss 0.0121 (0.0146)	Prec@1 100.000 (99.890)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.075)	BT: 0.013 (0.088)	Loss 0.0112 (0.0142)	Prec@1 100.000 (99.903)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.074)	BT: 0.009 (0.086)	Loss 0.0215 (0.0141)	Prec@1 99.219 (99.905)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.075)	BT: 0.012 (0.087)	Loss 0.0076 (0.0141)	Prec@1 100.000 (99.910)	
Total train loss: 0.0142
Avg Loading time: 0.0744 seconds
Avg Batch time: 0.0868 seconds

Train time: 34.09949541091919
 * Prec@1 67.850 Prec@5 87.980 Loss 1.5107
Avg Loading time: 0.0926 seconds
Avg Batch time: 0.0986 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 8.379776239395142

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.088)	BT: 0.009 (0.100)	Loss 0.0078 (0.0135)	Prec@1 100.000 (99.910)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.085)	BT: 0.012 (0.097)	Loss 0.0094 (0.0133)	Prec@1 100.000 (99.930)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.082)	BT: 0.012 (0.094)	Loss 0.0193 (0.0128)	Prec@1 100.000 (99.940)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.077)	BT: 0.011 (0.089)	Loss 0.0172 (0.0131)	Prec@1 100.000 (99.940)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.080)	BT: 0.009 (0.092)	Loss 0.0164 (0.0131)	Prec@1 99.219 (99.924)	
Total train loss: 0.0132
Avg Loading time: 0.0795 seconds
Avg Batch time: 0.0914 seconds

Train time: 35.891523122787476
 * Prec@1 67.550 Prec@5 87.820 Loss 1.5068
Avg Loading time: 0.1016 seconds
Avg Batch time: 0.1073 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 8.911163806915283

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.104)	BT: 0.018 (0.118)	Loss 0.0043 (0.0120)	Prec@1 100.000 (99.910)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.225 (0.099)	BT: 0.236 (0.112)	Loss 0.0062 (0.0124)	Prec@1 100.000 (99.910)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.095)	BT: 0.010 (0.107)	Loss 0.0130 (0.0123)	Prec@1 100.000 (99.910)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.092)	BT: 0.009 (0.104)	Loss 0.0114 (0.0125)	Prec@1 100.000 (99.912)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.058 (0.092)	BT: 0.068 (0.104)	Loss 0.0185 (0.0127)	Prec@1 100.000 (99.912)	
Total train loss: 0.0128
Avg Loading time: 0.0918 seconds
Avg Batch time: 0.1040 seconds

Train time: 40.76537251472473
 * Prec@1 67.660 Prec@5 87.800 Loss 1.5107
Avg Loading time: 0.0765 seconds
Avg Batch time: 0.0827 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 6.905411720275879

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.084)	BT: 0.010 (0.095)	Loss 0.0134 (0.0123)	Prec@1 100.000 (99.900)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.091)	BT: 0.009 (0.103)	Loss 0.0139 (0.0125)	Prec@1 100.000 (99.905)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.671 (0.092)	BT: 0.681 (0.104)	Loss 0.0149 (0.0125)	Prec@1 100.000 (99.907)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.093)	BT: 0.009 (0.105)	Loss 0.0057 (0.0123)	Prec@1 100.000 (99.910)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.092)	BT: 0.011 (0.104)	Loss 0.0102 (0.0123)	Prec@1 100.000 (99.910)	
Total train loss: 0.0123
Avg Loading time: 0.0915 seconds
Avg Batch time: 0.1034 seconds

Train time: 40.622807025909424
 * Prec@1 67.740 Prec@5 87.920 Loss 1.5176
Avg Loading time: 0.1134 seconds
Avg Batch time: 0.1198 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 9.80732536315918

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.101)	BT: 0.009 (0.112)	Loss 0.0111 (0.0124)	Prec@1 100.000 (99.900)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.088)	BT: 0.013 (0.099)	Loss 0.0190 (0.0121)	Prec@1 100.000 (99.925)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.089)	BT: 0.014 (0.101)	Loss 0.0067 (0.0125)	Prec@1 100.000 (99.910)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.090)	BT: 0.012 (0.102)	Loss 0.0123 (0.0121)	Prec@1 100.000 (99.932)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.091)	BT: 0.010 (0.103)	Loss 0.0112 (0.0119)	Prec@1 100.000 (99.934)	
Total train loss: 0.0119
Avg Loading time: 0.0911 seconds
Avg Batch time: 0.1027 seconds

Train time: 40.32738375663757
 * Prec@1 67.810 Prec@5 87.890 Loss 1.5156
Avg Loading time: 0.0907 seconds
Avg Batch time: 0.0977 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 8.101499080657959

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.094)	BT: 0.009 (0.106)	Loss 0.0084 (0.0101)	Prec@1 100.000 (99.980)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.091)	BT: 0.010 (0.103)	Loss 0.0056 (0.0102)	Prec@1 100.000 (99.965)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.093)	BT: 0.012 (0.105)	Loss 0.0120 (0.0104)	Prec@1 100.000 (99.957)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.090)	BT: 0.010 (0.101)	Loss 0.0084 (0.0109)	Prec@1 100.000 (99.940)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.090)	BT: 0.009 (0.102)	Loss 0.0084 (0.0107)	Prec@1 100.000 (99.946)	
Total train loss: 0.0107
Avg Loading time: 0.0898 seconds
Avg Batch time: 0.1017 seconds

Train time: 39.89307713508606
 * Prec@1 67.590 Prec@5 87.910 Loss 1.5195
Avg Loading time: 0.0977 seconds
Avg Batch time: 0.1034 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 8.564330577850342

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.108)	BT: 0.009 (0.120)	Loss 0.0087 (0.0099)	Prec@1 100.000 (99.990)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.101)	BT: 0.010 (0.113)	Loss 0.0070 (0.0103)	Prec@1 100.000 (99.965)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.099)	BT: 0.010 (0.112)	Loss 0.0041 (0.0104)	Prec@1 100.000 (99.950)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.095)	BT: 0.009 (0.107)	Loss 0.0060 (0.0103)	Prec@1 100.000 (99.950)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.093)	BT: 0.009 (0.105)	Loss 0.0144 (0.0104)	Prec@1 100.000 (99.952)	
Total train loss: 0.0104
Avg Loading time: 0.0929 seconds
Avg Batch time: 0.1050 seconds

Train time: 41.17806601524353
 * Prec@1 67.700 Prec@5 87.850 Loss 1.5127
Avg Loading time: 0.0864 seconds
Avg Batch time: 0.0925 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 7.712575912475586

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.106)	BT: 0.009 (0.118)	Loss 0.0074 (0.0101)	Prec@1 100.000 (99.950)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.105)	BT: 0.010 (0.117)	Loss 0.0060 (0.0102)	Prec@1 100.000 (99.940)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.097)	BT: 0.010 (0.109)	Loss 0.0032 (0.0104)	Prec@1 100.000 (99.933)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.097)	BT: 0.013 (0.109)	Loss 0.0093 (0.0103)	Prec@1 100.000 (99.942)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.097)	BT: 0.009 (0.109)	Loss 0.0246 (0.0104)	Prec@1 99.219 (99.940)	
Total train loss: 0.0104
Avg Loading time: 0.0968 seconds
Avg Batch time: 0.1083 seconds

Train time: 42.52606201171875
 * Prec@1 67.670 Prec@5 87.920 Loss 1.5156
Avg Loading time: 0.1224 seconds
Avg Batch time: 0.1281 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 10.490370750427246

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.173 (0.096)	BT: 0.184 (0.108)	Loss 0.0070 (0.0102)	Prec@1 100.000 (99.950)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.419 (0.100)	BT: 0.430 (0.112)	Loss 0.0119 (0.0106)	Prec@1 100.000 (99.940)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.099)	BT: 0.016 (0.111)	Loss 0.0058 (0.0106)	Prec@1 100.000 (99.940)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.104)	BT: 0.010 (0.116)	Loss 0.0084 (0.0103)	Prec@1 100.000 (99.950)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.104)	BT: 0.013 (0.117)	Loss 0.0132 (0.0102)	Prec@1 100.000 (99.956)	
Total train loss: 0.0102
Avg Loading time: 0.1041 seconds
Avg Batch time: 0.1167 seconds

Train time: 45.8263475894928
 * Prec@1 67.600 Prec@5 87.920 Loss 1.5107
Avg Loading time: 0.1031 seconds
Avg Batch time: 0.1091 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 8.963777542114258

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.104)	BT: 0.009 (0.116)	Loss 0.0104 (0.0105)	Prec@1 100.000 (99.970)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.095)	BT: 0.010 (0.107)	Loss 0.0083 (0.0106)	Prec@1 100.000 (99.960)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.179 (0.099)	BT: 0.189 (0.111)	Loss 0.0142 (0.0107)	Prec@1 100.000 (99.957)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.099)	BT: 0.010 (0.111)	Loss 0.0104 (0.0106)	Prec@1 100.000 (99.945)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.101)	BT: 0.012 (0.113)	Loss 0.0069 (0.0107)	Prec@1 100.000 (99.942)	
Total train loss: 0.0107
Avg Loading time: 0.1007 seconds
Avg Batch time: 0.1124 seconds

Train time: 44.08768057823181
 * Prec@1 67.740 Prec@5 87.730 Loss 1.5166
Avg Loading time: 0.1168 seconds
Avg Batch time: 0.1220 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 9.987599611282349

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.101)	BT: 0.010 (0.114)	Loss 0.0153 (0.0105)	Prec@1 100.000 (99.930)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.096)	BT: 0.011 (0.108)	Loss 0.0112 (0.0104)	Prec@1 100.000 (99.940)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.340 (0.096)	BT: 0.350 (0.108)	Loss 0.0119 (0.0103)	Prec@1 100.000 (99.943)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.097)	BT: 0.009 (0.108)	Loss 0.0062 (0.0104)	Prec@1 100.000 (99.942)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.097)	BT: 0.009 (0.108)	Loss 0.0142 (0.0104)	Prec@1 100.000 (99.942)	
Total train loss: 0.0105
Avg Loading time: 0.0964 seconds
Avg Batch time: 0.1080 seconds

Train time: 42.359362840652466
 * Prec@1 67.690 Prec@5 87.830 Loss 1.5098
Avg Loading time: 0.0900 seconds
Avg Batch time: 0.0970 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 8.04320216178894

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.098)	BT: 0.010 (0.110)	Loss 0.0259 (0.0101)	Prec@1 100.000 (99.950)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.789 (0.107)	BT: 0.804 (0.119)	Loss 0.0079 (0.0104)	Prec@1 100.000 (99.945)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.127 (0.105)	BT: 0.137 (0.117)	Loss 0.0131 (0.0104)	Prec@1 100.000 (99.947)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.102)	BT: 0.009 (0.114)	Loss 0.0122 (0.0102)	Prec@1 100.000 (99.955)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.103)	BT: 0.013 (0.115)	Loss 0.0081 (0.0102)	Prec@1 100.000 (99.956)	
Total train loss: 0.0103
Avg Loading time: 0.1025 seconds
Avg Batch time: 0.1145 seconds

Train time: 44.8845956325531
 * Prec@1 67.790 Prec@5 87.840 Loss 1.5117
Avg Loading time: 0.0984 seconds
Avg Batch time: 0.1042 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 8.645760536193848

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.104)	BT: 0.009 (0.117)	Loss 0.0070 (0.0102)	Prec@1 100.000 (99.970)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.096)	BT: 0.009 (0.108)	Loss 0.0101 (0.0098)	Prec@1 100.000 (99.975)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.094 (0.096)	BT: 0.112 (0.108)	Loss 0.0071 (0.0101)	Prec@1 100.000 (99.973)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.096)	BT: 0.010 (0.108)	Loss 0.0084 (0.0103)	Prec@1 100.000 (99.955)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.094)	BT: 0.009 (0.106)	Loss 0.0067 (0.0103)	Prec@1 100.000 (99.948)	
Total train loss: 0.0103
Avg Loading time: 0.0934 seconds
Avg Batch time: 0.1057 seconds

Train time: 41.43103289604187
 * Prec@1 67.690 Prec@5 87.690 Loss 1.5146
Avg Loading time: 0.1221 seconds
Avg Batch time: 0.1280 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 10.544563293457031

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.097)	BT: 0.010 (0.109)	Loss 0.0054 (0.0098)	Prec@1 100.000 (99.960)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.093)	BT: 0.012 (0.106)	Loss 0.0131 (0.0098)	Prec@1 100.000 (99.970)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.092)	BT: 0.009 (0.105)	Loss 0.0060 (0.0101)	Prec@1 100.000 (99.963)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.095)	BT: 0.009 (0.107)	Loss 0.0108 (0.0099)	Prec@1 100.000 (99.965)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.096)	BT: 0.011 (0.108)	Loss 0.0117 (0.0098)	Prec@1 100.000 (99.966)	
Total train loss: 0.0099
Avg Loading time: 0.0958 seconds
Avg Batch time: 0.1081 seconds

Train time: 42.441930294036865
 * Prec@1 67.520 Prec@5 87.800 Loss 1.5254
Avg Loading time: 0.0978 seconds
Avg Batch time: 0.1038 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 8.519538402557373

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.111)	BT: 0.009 (0.123)	Loss 0.0075 (0.0099)	Prec@1 100.000 (99.980)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.096)	BT: 0.011 (0.108)	Loss 0.0094 (0.0104)	Prec@1 100.000 (99.960)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 1.336 (0.095)	BT: 1.354 (0.107)	Loss 0.0069 (0.0101)	Prec@1 100.000 (99.953)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.096)	BT: 0.009 (0.108)	Loss 0.0201 (0.0099)	Prec@1 99.219 (99.950)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.097)	BT: 0.013 (0.109)	Loss 0.0072 (0.0101)	Prec@1 100.000 (99.942)	
Total train loss: 0.0101
Avg Loading time: 0.0965 seconds
Avg Batch time: 0.1083 seconds

Train time: 42.48447370529175
 * Prec@1 67.660 Prec@5 87.810 Loss 1.5195
Avg Loading time: 0.0908 seconds
Avg Batch time: 0.0959 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 7.969422340393066

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.093)	BT: 0.009 (0.105)	Loss 0.0071 (0.0109)	Prec@1 100.000 (99.930)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.091)	BT: 0.010 (0.103)	Loss 0.0042 (0.0105)	Prec@1 100.000 (99.945)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.094)	BT: 0.011 (0.105)	Loss 0.0094 (0.0107)	Prec@1 100.000 (99.940)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.089)	BT: 0.011 (0.102)	Loss 0.0108 (0.0104)	Prec@1 100.000 (99.945)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.090)	BT: 0.010 (0.102)	Loss 0.0085 (0.0103)	Prec@1 100.000 (99.948)	
Total train loss: 0.0103
Avg Loading time: 0.0902 seconds
Avg Batch time: 0.1021 seconds

Train time: 40.04744601249695
 * Prec@1 67.750 Prec@5 87.900 Loss 1.5059
Avg Loading time: 0.0968 seconds
Avg Batch time: 0.1031 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 8.550064325332642

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.103)	BT: 0.011 (0.115)	Loss 0.0121 (0.0099)	Prec@1 100.000 (99.940)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.095)	BT: 0.014 (0.107)	Loss 0.0045 (0.0095)	Prec@1 100.000 (99.965)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.341 (0.095)	BT: 0.361 (0.108)	Loss 0.0049 (0.0100)	Prec@1 100.000 (99.960)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.089)	BT: 0.009 (0.101)	Loss 0.0070 (0.0100)	Prec@1 100.000 (99.950)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.090)	BT: 0.009 (0.102)	Loss 0.0117 (0.0101)	Prec@1 100.000 (99.952)	
Total train loss: 0.0101
Avg Loading time: 0.0902 seconds
Avg Batch time: 0.1022 seconds

Train time: 40.074955701828
 * Prec@1 67.690 Prec@5 87.840 Loss 1.5215
Avg Loading time: 0.0877 seconds
Avg Batch time: 0.0938 seconds

Best acc: 67.850
--------------------------------------------------------------------------------
Test time: 7.821907043457031

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.114)	BT: 0.009 (0.126)	Loss 0.0083 (0.0100)	Prec@1 100.000 (99.960)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.109)	BT: 0.018 (0.121)	Loss 0.0115 (0.0096)	Prec@1 100.000 (99.970)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.124 (0.099)	BT: 0.134 (0.111)	Loss 0.0049 (0.0096)	Prec@1 100.000 (99.963)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.184 (0.097)	BT: 0.195 (0.109)	Loss 0.0172 (0.0098)	Prec@1 100.000 (99.960)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.101)	BT: 0.009 (0.113)	Loss 0.0104 (0.0097)	Prec@1 100.000 (99.964)	
Total train loss: 0.0098
Avg Loading time: 0.1003 seconds
Avg Batch time: 0.1125 seconds

Train time: 44.08707070350647
 * Prec@1 67.940 Prec@5 87.720 Loss 1.5137
Avg Loading time: 0.1269 seconds
Avg Batch time: 0.1328 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 11.120993614196777

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.104)	BT: 0.011 (0.115)	Loss 0.0089 (0.0114)	Prec@1 100.000 (99.920)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.102)	BT: 0.009 (0.114)	Loss 0.0064 (0.0108)	Prec@1 100.000 (99.925)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.100)	BT: 0.010 (0.112)	Loss 0.0099 (0.0106)	Prec@1 100.000 (99.927)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.099)	BT: 0.011 (0.111)	Loss 0.0087 (0.0106)	Prec@1 100.000 (99.930)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.101)	BT: 0.009 (0.112)	Loss 0.0153 (0.0105)	Prec@1 100.000 (99.938)	
Total train loss: 0.0105
Avg Loading time: 0.1012 seconds
Avg Batch time: 0.1132 seconds

Train time: 44.38819694519043
 * Prec@1 67.510 Prec@5 87.970 Loss 1.5146
Avg Loading time: 0.1033 seconds
Avg Batch time: 0.1089 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 8.986586332321167

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.102)	BT: 0.009 (0.113)	Loss 0.0084 (0.0089)	Prec@1 100.000 (99.970)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.085)	BT: 0.015 (0.097)	Loss 0.0119 (0.0093)	Prec@1 100.000 (99.970)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.088)	BT: 0.011 (0.100)	Loss 0.0050 (0.0095)	Prec@1 100.000 (99.963)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.085)	BT: 0.009 (0.097)	Loss 0.0104 (0.0097)	Prec@1 100.000 (99.955)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.089)	BT: 0.015 (0.101)	Loss 0.0083 (0.0097)	Prec@1 100.000 (99.956)	
Total train loss: 0.0097
Avg Loading time: 0.0885 seconds
Avg Batch time: 0.1007 seconds

Train time: 39.5437126159668
 * Prec@1 67.670 Prec@5 87.840 Loss 1.5117
Avg Loading time: 0.1046 seconds
Avg Batch time: 0.1100 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 9.100106477737427

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.099)	BT: 0.011 (0.111)	Loss 0.0088 (0.0100)	Prec@1 100.000 (99.960)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.097)	BT: 0.010 (0.109)	Loss 0.0114 (0.0102)	Prec@1 100.000 (99.950)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.212 (0.100)	BT: 0.223 (0.112)	Loss 0.0084 (0.0104)	Prec@1 100.000 (99.947)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.090)	BT: 0.012 (0.102)	Loss 0.0080 (0.0103)	Prec@1 100.000 (99.945)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.095)	BT: 0.012 (0.107)	Loss 0.0048 (0.0101)	Prec@1 100.000 (99.948)	
Total train loss: 0.0101
Avg Loading time: 0.0950 seconds
Avg Batch time: 0.1067 seconds

Train time: 41.84443140029907
 * Prec@1 67.720 Prec@5 87.930 Loss 1.5127
Avg Loading time: 0.4802 seconds
Avg Batch time: 0.4869 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 38.8158757686615

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.556)	BT: 0.010 (0.568)	Loss 0.0069 (0.0101)	Prec@1 100.000 (99.940)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.435)	BT: 0.012 (0.447)	Loss 0.0067 (0.0097)	Prec@1 100.000 (99.945)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.557)	BT: 0.015 (0.568)	Loss 0.0104 (0.0101)	Prec@1 100.000 (99.950)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.584)	BT: 0.009 (0.595)	Loss 0.0280 (0.0100)	Prec@1 100.000 (99.945)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.536)	BT: 0.010 (0.547)	Loss 0.0074 (0.0099)	Prec@1 100.000 (99.950)	
Total train loss: 0.0099
Avg Loading time: 0.5347 seconds
Avg Batch time: 0.5461 seconds

Train time: 213.62855434417725
 * Prec@1 67.720 Prec@5 87.810 Loss 1.5146
Avg Loading time: 0.4644 seconds
Avg Batch time: 0.4700 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 37.47816228866577

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.407)	BT: 0.009 (0.419)	Loss 0.0062 (0.0099)	Prec@1 100.000 (99.960)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.191 (0.386)	BT: 0.206 (0.399)	Loss 0.0348 (0.0099)	Prec@1 99.219 (99.950)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.383)	BT: 0.015 (0.395)	Loss 0.0072 (0.0099)	Prec@1 100.000 (99.957)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.373)	BT: 0.009 (0.385)	Loss 0.0076 (0.0102)	Prec@1 100.000 (99.955)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.374)	BT: 0.009 (0.386)	Loss 0.0159 (0.0101)	Prec@1 100.000 (99.960)	
Total train loss: 0.0101
Avg Loading time: 0.3733 seconds
Avg Batch time: 0.3852 seconds

Train time: 150.71070194244385
 * Prec@1 67.780 Prec@5 87.670 Loss 1.5186
Avg Loading time: 0.4022 seconds
Avg Batch time: 0.4076 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 32.5757052898407

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.385)	BT: 0.011 (0.396)	Loss 0.0138 (0.0105)	Prec@1 100.000 (99.920)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.377)	BT: 0.010 (0.389)	Loss 0.0077 (0.0101)	Prec@1 100.000 (99.935)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.059 (0.274)	BT: 0.074 (0.286)	Loss 0.0054 (0.0100)	Prec@1 100.000 (99.947)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.004 (0.222)	BT: 0.016 (0.234)	Loss 0.0062 (0.0100)	Prec@1 100.000 (99.945)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.011 (0.192)	BT: 0.022 (0.203)	Loss 0.0069 (0.0101)	Prec@1 100.000 (99.940)	
Total train loss: 0.0102
Avg Loading time: 0.1913 seconds
Avg Batch time: 0.2028 seconds

Train time: 79.47147822380066
 * Prec@1 67.460 Prec@5 87.730 Loss 1.5205
Avg Loading time: 0.0748 seconds
Avg Batch time: 0.0810 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 6.807246446609497

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.069)	BT: 0.018 (0.083)	Loss 0.0051 (0.0098)	Prec@1 100.000 (99.980)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.451 (0.062)	BT: 0.461 (0.075)	Loss 0.0060 (0.0100)	Prec@1 100.000 (99.955)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.058)	BT: 0.025 (0.071)	Loss 0.0074 (0.0099)	Prec@1 100.000 (99.950)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.058)	BT: 0.013 (0.071)	Loss 0.0064 (0.0099)	Prec@1 100.000 (99.957)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.060)	BT: 0.009 (0.073)	Loss 0.0105 (0.0102)	Prec@1 100.000 (99.948)	
Total train loss: 0.0102
Avg Loading time: 0.0596 seconds
Avg Batch time: 0.0724 seconds

Train time: 28.42504572868347
 * Prec@1 67.850 Prec@5 87.790 Loss 1.5107
Avg Loading time: 0.0539 seconds
Avg Batch time: 0.0599 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 5.114916086196899

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.060)	BT: 0.009 (0.071)	Loss 0.0064 (0.0100)	Prec@1 100.000 (99.970)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.418 (0.062)	BT: 0.427 (0.073)	Loss 0.0096 (0.0103)	Prec@1 100.000 (99.940)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.063)	BT: 0.017 (0.075)	Loss 0.0130 (0.0103)	Prec@1 100.000 (99.950)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.065)	BT: 0.020 (0.077)	Loss 0.0091 (0.0102)	Prec@1 100.000 (99.952)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.067)	BT: 0.011 (0.079)	Loss 0.0071 (0.0102)	Prec@1 100.000 (99.954)	
Total train loss: 0.0103
Avg Loading time: 0.0665 seconds
Avg Batch time: 0.0786 seconds

Train time: 30.92350172996521
 * Prec@1 67.730 Prec@5 87.890 Loss 1.5166
Avg Loading time: 0.1032 seconds
Avg Batch time: 0.1080 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 8.974116563796997

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.081)	BT: 0.010 (0.093)	Loss 0.0135 (0.0105)	Prec@1 100.000 (99.950)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.077)	BT: 0.009 (0.089)	Loss 0.0190 (0.0099)	Prec@1 100.000 (99.965)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.073)	BT: 0.018 (0.085)	Loss 0.0072 (0.0097)	Prec@1 100.000 (99.963)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.066)	BT: 0.014 (0.078)	Loss 0.0110 (0.0098)	Prec@1 100.000 (99.962)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.113 (0.067)	BT: 0.125 (0.079)	Loss 0.0073 (0.0098)	Prec@1 100.000 (99.954)	
Total train loss: 0.0098
Avg Loading time: 0.0666 seconds
Avg Batch time: 0.0785 seconds

Train time: 30.844680786132812
 * Prec@1 67.760 Prec@5 87.760 Loss 1.5117
Avg Loading time: 0.0625 seconds
Avg Batch time: 0.0682 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 5.7376954555511475

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.083)	BT: 0.020 (0.097)	Loss 0.0166 (0.0096)	Prec@1 100.000 (99.970)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.074)	BT: 0.020 (0.088)	Loss 0.0148 (0.0101)	Prec@1 100.000 (99.955)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.068)	BT: 0.012 (0.081)	Loss 0.0057 (0.0098)	Prec@1 100.000 (99.957)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.068)	BT: 0.010 (0.081)	Loss 0.0113 (0.0100)	Prec@1 100.000 (99.950)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.070)	BT: 0.009 (0.083)	Loss 0.0188 (0.0099)	Prec@1 99.219 (99.952)	
Total train loss: 0.0099
Avg Loading time: 0.0699 seconds
Avg Batch time: 0.0827 seconds

Train time: 32.44161009788513
 * Prec@1 67.780 Prec@5 87.820 Loss 1.5166
Avg Loading time: 0.1033 seconds
Avg Batch time: 0.1095 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 9.063102722167969

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.068)	BT: 0.024 (0.081)	Loss 0.0038 (0.0097)	Prec@1 100.000 (99.970)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.075)	BT: 0.009 (0.088)	Loss 0.0073 (0.0099)	Prec@1 100.000 (99.950)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.076)	BT: 0.026 (0.089)	Loss 0.0129 (0.0102)	Prec@1 100.000 (99.943)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.078)	BT: 0.010 (0.090)	Loss 0.0089 (0.0100)	Prec@1 100.000 (99.947)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.078)	BT: 0.010 (0.091)	Loss 0.0111 (0.0100)	Prec@1 100.000 (99.948)	
Total train loss: 0.0101
Avg Loading time: 0.0776 seconds
Avg Batch time: 0.0903 seconds

Train time: 35.500802755355835
 * Prec@1 67.830 Prec@5 87.960 Loss 1.5146
Avg Loading time: 0.0745 seconds
Avg Batch time: 0.0796 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 6.630026340484619

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.080)	BT: 0.009 (0.092)	Loss 0.0067 (0.0094)	Prec@1 100.000 (99.960)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.032 (0.071)	BT: 0.041 (0.083)	Loss 0.0049 (0.0093)	Prec@1 100.000 (99.960)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.073)	BT: 0.010 (0.084)	Loss 0.0101 (0.0096)	Prec@1 100.000 (99.957)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.075)	BT: 0.011 (0.087)	Loss 0.0144 (0.0096)	Prec@1 100.000 (99.947)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.076)	BT: 0.011 (0.087)	Loss 0.0063 (0.0100)	Prec@1 100.000 (99.936)	
Total train loss: 0.0100
Avg Loading time: 0.0754 seconds
Avg Batch time: 0.0868 seconds

Train time: 34.12294054031372
 * Prec@1 67.530 Prec@5 87.880 Loss 1.5137
Avg Loading time: 0.1038 seconds
Avg Batch time: 0.1098 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 9.071264505386353

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.086)	BT: 0.010 (0.097)	Loss 0.0128 (0.0104)	Prec@1 100.000 (99.960)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.082 (0.087)	BT: 0.099 (0.099)	Loss 0.0046 (0.0101)	Prec@1 100.000 (99.935)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.402 (0.085)	BT: 0.417 (0.097)	Loss 0.0085 (0.0101)	Prec@1 100.000 (99.930)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.082)	BT: 0.012 (0.093)	Loss 0.0049 (0.0098)	Prec@1 100.000 (99.942)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.083)	BT: 0.009 (0.095)	Loss 0.0095 (0.0098)	Prec@1 100.000 (99.948)	
Total train loss: 0.0098
Avg Loading time: 0.0831 seconds
Avg Batch time: 0.0949 seconds

Train time: 37.185426235198975
 * Prec@1 67.420 Prec@5 87.930 Loss 1.5195
Avg Loading time: 0.0778 seconds
Avg Batch time: 0.0841 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 7.054703235626221

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.092)	BT: 0.009 (0.104)	Loss 0.0078 (0.0093)	Prec@1 100.000 (99.970)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.036 (0.088)	BT: 0.050 (0.099)	Loss 0.0058 (0.0095)	Prec@1 100.000 (99.955)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.010 (0.088)	BT: 0.020 (0.100)	Loss 0.0116 (0.0096)	Prec@1 100.000 (99.953)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.088)	BT: 0.010 (0.100)	Loss 0.0096 (0.0097)	Prec@1 100.000 (99.955)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.113 (0.089)	BT: 0.124 (0.101)	Loss 0.0057 (0.0098)	Prec@1 100.000 (99.952)	
Total train loss: 0.0098
Avg Loading time: 0.0883 seconds
Avg Batch time: 0.1004 seconds

Train time: 39.39291000366211
 * Prec@1 67.750 Prec@5 87.740 Loss 1.5156
Avg Loading time: 0.1039 seconds
Avg Batch time: 0.1096 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 9.014729738235474

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.102)	BT: 0.009 (0.114)	Loss 0.0074 (0.0092)	Prec@1 100.000 (99.990)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.093)	BT: 0.009 (0.104)	Loss 0.0092 (0.0096)	Prec@1 100.000 (99.970)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.237 (0.093)	BT: 0.249 (0.104)	Loss 0.0046 (0.0099)	Prec@1 100.000 (99.970)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.093)	BT: 0.012 (0.105)	Loss 0.0157 (0.0099)	Prec@1 100.000 (99.965)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.196 (0.093)	BT: 0.207 (0.104)	Loss 0.0154 (0.0098)	Prec@1 100.000 (99.964)	
Total train loss: 0.0099
Avg Loading time: 0.0924 seconds
Avg Batch time: 0.1042 seconds

Train time: 40.84514784812927
 * Prec@1 67.730 Prec@5 87.900 Loss 1.5156
Avg Loading time: 0.0962 seconds
Avg Batch time: 0.1024 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 8.493072271347046

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.108)	BT: 0.010 (0.120)	Loss 0.0082 (0.0105)	Prec@1 100.000 (99.950)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.094)	BT: 0.009 (0.107)	Loss 0.0051 (0.0100)	Prec@1 100.000 (99.965)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.207 (0.088)	BT: 0.226 (0.100)	Loss 0.0069 (0.0099)	Prec@1 100.000 (99.963)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.091)	BT: 0.010 (0.103)	Loss 0.0170 (0.0100)	Prec@1 100.000 (99.962)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.090)	BT: 0.009 (0.101)	Loss 0.0156 (0.0101)	Prec@1 99.219 (99.958)	
Total train loss: 0.0102
Avg Loading time: 0.0893 seconds
Avg Batch time: 0.1012 seconds

Train time: 39.754443883895874
 * Prec@1 67.460 Prec@5 87.970 Loss 1.5156
Avg Loading time: 0.1139 seconds
Avg Batch time: 0.1198 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 9.845087766647339

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.111)	BT: 0.013 (0.123)	Loss 0.0112 (0.0101)	Prec@1 100.000 (99.960)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.101)	BT: 0.011 (0.112)	Loss 0.0063 (0.0102)	Prec@1 100.000 (99.950)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.006 (0.099)	BT: 0.022 (0.111)	Loss 0.0076 (0.0101)	Prec@1 100.000 (99.953)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.099)	BT: 0.009 (0.110)	Loss 0.0133 (0.0101)	Prec@1 100.000 (99.957)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.097)	BT: 0.017 (0.109)	Loss 0.0063 (0.0101)	Prec@1 100.000 (99.954)	
Total train loss: 0.0101
Avg Loading time: 0.0972 seconds
Avg Batch time: 0.1090 seconds

Train time: 42.765676498413086
 * Prec@1 67.570 Prec@5 87.940 Loss 1.5195
Avg Loading time: 0.1109 seconds
Avg Batch time: 0.1162 seconds

Best acc: 67.940
--------------------------------------------------------------------------------
Test time: 9.588229894638062


      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 0
          frozen_layers: 17
Savedir:  ../pretrained_models/frozen/x64-8b/rram/cifar100/resnet18
DEVICE: cuda
GPU Id(s) being used: 0
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar100/resnet18/train/relu17
Test path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar100/resnet18/test/relu17
ResNet18(
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=100, bias=False)
  (bn19): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 1.180 Prec@5 5.070 Loss 4.6211
Avg Loading time: 0.4648 seconds
Avg Batch time: 0.4777 seconds

Pre-trained Prec@1 with 17 layers frozen: 1.1799999475479126 	 Loss: 4.62109375

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (1.267)	BT: 0.004 (1.274)	Loss 2.1523 (2.7803)	Prec@1 47.656 (35.837)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.487 (1.178)	BT: 0.496 (1.185)	Loss 1.8506 (2.4207)	Prec@1 51.562 (42.248)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.280 (1.109)	BT: 0.289 (1.116)	Loss 1.7119 (2.2536)	Prec@1 58.594 (45.122)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (1.041)	BT: 0.004 (1.048)	Loss 1.8633 (2.1582)	Prec@1 50.000 (46.474)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (1.015)	BT: 0.004 (1.022)	Loss 1.7598 (2.0880)	Prec@1 51.562 (47.462)	
Total train loss: 2.0875
Avg Loading time: 1.0125 seconds
Avg Batch time: 1.0194 seconds

Train time: 398.66955947875977
 * Prec@1 54.260 Prec@5 82.350 Loss 1.7148
Avg Loading time: 0.1410 seconds
Avg Batch time: 0.1460 seconds

Best acc: 54.260
--------------------------------------------------------------------------------
Test time: 11.676730394363403

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.125)	BT: 0.004 (0.131)	Loss 1.7754 (1.5793)	Prec@1 59.375 (57.792)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.116)	BT: 0.012 (0.122)	Loss 1.6211 (1.5746)	Prec@1 53.906 (57.627)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.117)	BT: 0.005 (0.124)	Loss 1.5195 (1.5881)	Prec@1 56.250 (57.081)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.914 (0.109)	BT: 0.924 (0.116)	Loss 1.5352 (1.5983)	Prec@1 55.469 (56.909)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.109)	BT: 0.004 (0.115)	Loss 1.8193 (1.6094)	Prec@1 52.344 (56.506)	
Total train loss: 1.6097
Avg Loading time: 0.1085 seconds
Avg Batch time: 0.1150 seconds

Train time: 45.06430673599243
 * Prec@1 54.960 Prec@5 83.240 Loss 1.6562
Avg Loading time: 0.0923 seconds
Avg Batch time: 0.0966 seconds

Best acc: 54.960
--------------------------------------------------------------------------------
Test time: 7.764528751373291

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.104)	BT: 0.005 (0.111)	Loss 1.6943 (1.4191)	Prec@1 50.781 (61.008)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.108)	BT: 0.004 (0.115)	Loss 1.4199 (1.4483)	Prec@1 60.156 (60.131)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (0.107)	BT: 0.010 (0.114)	Loss 1.5957 (1.4727)	Prec@1 56.250 (59.502)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.104)	BT: 0.003 (0.111)	Loss 1.4678 (1.4872)	Prec@1 57.031 (59.182)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.104)	BT: 0.009 (0.111)	Loss 1.4463 (1.4966)	Prec@1 60.938 (58.910)	
Total train loss: 1.4962
Avg Loading time: 0.1036 seconds
Avg Batch time: 0.1107 seconds

Train time: 43.380088329315186
 * Prec@1 55.330 Prec@5 83.450 Loss 1.6348
Avg Loading time: 0.1214 seconds
Avg Batch time: 0.1255 seconds

Best acc: 55.330
--------------------------------------------------------------------------------
Test time: 10.077833652496338

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.097)	BT: 0.006 (0.103)	Loss 1.1973 (1.3613)	Prec@1 69.531 (62.650)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.098)	BT: 0.006 (0.105)	Loss 1.5195 (1.3799)	Prec@1 58.594 (61.604)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.100)	BT: 0.013 (0.106)	Loss 1.7773 (1.4023)	Prec@1 52.344 (61.144)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.099)	BT: 0.003 (0.106)	Loss 1.4453 (1.4130)	Prec@1 57.812 (60.700)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.014 (0.100)	BT: 0.020 (0.106)	Loss 1.4365 (1.4301)	Prec@1 63.281 (60.377)	
Total train loss: 1.4302
Avg Loading time: 0.0997 seconds
Avg Batch time: 0.1061 seconds

Train time: 41.62672686576843
 * Prec@1 55.440 Prec@5 83.650 Loss 1.6367
Avg Loading time: 0.1003 seconds
Avg Batch time: 0.1053 seconds

Best acc: 55.440
--------------------------------------------------------------------------------
Test time: 8.462907314300537

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.100)	BT: 0.003 (0.108)	Loss 1.5576 (1.3088)	Prec@1 57.031 (63.341)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.015 (0.082)	BT: 0.019 (0.089)	Loss 1.4814 (1.3340)	Prec@1 58.594 (62.585)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.091)	BT: 0.004 (0.098)	Loss 1.4199 (1.3545)	Prec@1 59.375 (62.176)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.093)	BT: 0.005 (0.100)	Loss 1.6494 (1.3752)	Prec@1 55.469 (61.616)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.093)	BT: 0.004 (0.100)	Loss 1.5469 (1.3905)	Prec@1 55.469 (61.262)	
Total train loss: 1.3905
Avg Loading time: 0.0930 seconds
Avg Batch time: 0.0998 seconds

Train time: 39.17816734313965
 * Prec@1 56.110 Prec@5 83.720 Loss 1.6260
Avg Loading time: 0.0727 seconds
Avg Batch time: 0.0770 seconds

Best acc: 56.110
--------------------------------------------------------------------------------
Test time: 6.247775554656982

Epoch: [5][77/391]	LR: 0.1	DT: 0.028 (0.105)	BT: 0.033 (0.112)	Loss 1.5059 (1.2672)	Prec@1 57.031 (64.904)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.214 (0.099)	BT: 0.220 (0.106)	Loss 1.4082 (1.3028)	Prec@1 63.281 (63.802)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.325 (0.098)	BT: 0.335 (0.105)	Loss 1.3379 (1.3216)	Prec@1 61.719 (63.315)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.096)	BT: 0.007 (0.102)	Loss 1.4551 (1.3444)	Prec@1 57.812 (62.538)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.092)	BT: 0.006 (0.099)	Loss 1.5205 (1.3605)	Prec@1 58.594 (61.925)	
Total train loss: 1.3610
Avg Loading time: 0.0921 seconds
Avg Batch time: 0.0988 seconds

Train time: 38.74285387992859
 * Prec@1 55.450 Prec@5 83.560 Loss 1.6465
Avg Loading time: 0.1142 seconds
Avg Batch time: 0.1186 seconds

Best acc: 56.110
--------------------------------------------------------------------------------
Test time: 9.53533124923706

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.091)	BT: 0.005 (0.098)	Loss 1.0449 (1.2772)	Prec@1 68.750 (64.052)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.088)	BT: 0.009 (0.095)	Loss 1.2422 (1.2989)	Prec@1 67.188 (63.416)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.087)	BT: 0.008 (0.093)	Loss 1.6133 (1.3153)	Prec@1 61.719 (62.904)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.086)	BT: 0.004 (0.093)	Loss 1.5010 (1.3285)	Prec@1 60.938 (62.643)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.059 (0.087)	BT: 0.063 (0.094)	Loss 1.2998 (1.3410)	Prec@1 62.500 (62.304)	
Total train loss: 1.3410
Avg Loading time: 0.0872 seconds
Avg Batch time: 0.0939 seconds

Train time: 36.91103434562683
 * Prec@1 55.920 Prec@5 83.600 Loss 1.6387
Avg Loading time: 0.0867 seconds
Avg Batch time: 0.0919 seconds

Best acc: 56.110
--------------------------------------------------------------------------------
Test time: 7.394529581069946

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.118)	BT: 0.005 (0.124)	Loss 1.2559 (1.2509)	Prec@1 65.625 (64.643)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.101)	BT: 0.004 (0.107)	Loss 1.2812 (1.2843)	Prec@1 57.031 (63.877)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.124 (0.100)	BT: 0.129 (0.106)	Loss 1.2900 (1.2914)	Prec@1 62.500 (63.812)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.095)	BT: 0.005 (0.101)	Loss 1.1953 (1.3058)	Prec@1 67.969 (63.246)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.091)	BT: 0.005 (0.098)	Loss 1.2783 (1.3233)	Prec@1 61.719 (62.616)	
Total train loss: 1.3233
Avg Loading time: 0.0912 seconds
Avg Batch time: 0.0977 seconds

Train time: 38.37819504737854
 * Prec@1 55.850 Prec@5 83.830 Loss 1.6338
Avg Loading time: 0.1071 seconds
Avg Batch time: 0.1109 seconds

Best acc: 56.110
--------------------------------------------------------------------------------
Test time: 8.93777871131897

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.100)	BT: 0.004 (0.107)	Loss 1.3555 (1.2285)	Prec@1 61.719 (65.425)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.096)	BT: 0.007 (0.102)	Loss 1.0771 (1.2567)	Prec@1 67.969 (64.603)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.091)	BT: 0.010 (0.097)	Loss 1.1523 (1.2769)	Prec@1 69.531 (64.143)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.085)	BT: 0.005 (0.092)	Loss 1.0049 (1.2953)	Prec@1 64.844 (63.507)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.082)	BT: 0.004 (0.088)	Loss 1.3359 (1.3138)	Prec@1 64.844 (63.129)	
Total train loss: 1.3139
Avg Loading time: 0.0817 seconds
Avg Batch time: 0.0880 seconds

Train time: 34.56980919837952
 * Prec@1 55.680 Prec@5 83.890 Loss 1.6436
Avg Loading time: 0.0694 seconds
Avg Batch time: 0.0743 seconds

Best acc: 56.110
--------------------------------------------------------------------------------
Test time: 6.042228937149048

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.092)	BT: 0.006 (0.099)	Loss 1.2666 (1.2337)	Prec@1 61.719 (65.375)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.087)	BT: 0.007 (0.094)	Loss 1.4111 (1.2550)	Prec@1 60.938 (64.724)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.085 (0.081)	BT: 0.092 (0.088)	Loss 1.4492 (1.2624)	Prec@1 60.156 (64.473)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.074)	BT: 0.017 (0.081)	Loss 1.5840 (1.2880)	Prec@1 58.594 (63.822)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.137 (0.068)	BT: 0.143 (0.076)	Loss 1.3652 (1.3024)	Prec@1 58.594 (63.371)	
Total train loss: 1.3023
Avg Loading time: 0.0679 seconds
Avg Batch time: 0.0754 seconds

Train time: 29.597662687301636
 * Prec@1 55.180 Prec@5 83.500 Loss 1.6572
Avg Loading time: 0.1046 seconds
Avg Batch time: 0.1090 seconds

Best acc: 56.110
--------------------------------------------------------------------------------
Test time: 8.77804684638977

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.202 (0.125)	BT: 0.207 (0.132)	Loss 1.2129 (1.1662)	Prec@1 65.625 (66.717)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.037 (0.113)	BT: 0.050 (0.120)	Loss 1.2812 (1.1646)	Prec@1 65.625 (66.927)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.110)	BT: 0.013 (0.117)	Loss 1.1475 (1.1626)	Prec@1 68.750 (67.064)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.116)	BT: 0.004 (0.123)	Loss 0.9316 (1.1655)	Prec@1 77.344 (67.092)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.117)	BT: 0.007 (0.124)	Loss 1.0332 (1.1679)	Prec@1 73.438 (66.991)	
Total train loss: 1.1681
Avg Loading time: 0.1171 seconds
Avg Batch time: 0.1237 seconds

Train time: 48.54519605636597
 * Prec@1 56.600 Prec@5 84.040 Loss 1.6172
Avg Loading time: 0.1336 seconds
Avg Batch time: 0.1383 seconds

Best acc: 56.600
--------------------------------------------------------------------------------
Test time: 11.049437999725342

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.112)	BT: 0.005 (0.117)	Loss 1.2217 (1.1264)	Prec@1 69.531 (68.339)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.119)	BT: 0.004 (0.125)	Loss 1.1035 (1.1343)	Prec@1 70.312 (68.244)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.068 (0.116)	BT: 0.072 (0.122)	Loss 1.2939 (1.1350)	Prec@1 61.719 (68.136)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.338 (0.112)	BT: 0.349 (0.118)	Loss 1.1553 (1.1388)	Prec@1 65.625 (68.081)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.089 (0.107)	BT: 0.096 (0.113)	Loss 0.9644 (1.1421)	Prec@1 71.094 (67.925)	
Total train loss: 1.1423
Avg Loading time: 0.1065 seconds
Avg Batch time: 0.1124 seconds

Train time: 44.110349893569946
 * Prec@1 56.720 Prec@5 83.850 Loss 1.6260
Avg Loading time: 0.1317 seconds
Avg Batch time: 0.1364 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 10.93917989730835

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.085)	BT: 0.010 (0.092)	Loss 0.9624 (1.0987)	Prec@1 71.875 (68.800)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.087)	BT: 0.004 (0.094)	Loss 1.1758 (1.1109)	Prec@1 66.406 (68.885)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.097)	BT: 0.004 (0.103)	Loss 1.3291 (1.1232)	Prec@1 65.625 (68.513)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.103)	BT: 0.004 (0.109)	Loss 1.1377 (1.1292)	Prec@1 64.844 (68.249)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.109)	BT: 0.004 (0.115)	Loss 0.9653 (1.1323)	Prec@1 74.219 (68.115)	
Total train loss: 1.1324
Avg Loading time: 0.1088 seconds
Avg Batch time: 0.1151 seconds

Train time: 45.19280791282654
 * Prec@1 56.550 Prec@5 83.840 Loss 1.6348
Avg Loading time: 0.1011 seconds
Avg Batch time: 0.1063 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 8.539304494857788

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.100)	BT: 0.007 (0.106)	Loss 1.0996 (1.0825)	Prec@1 64.844 (69.040)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.009 (0.106)	BT: 0.014 (0.112)	Loss 1.0811 (1.1110)	Prec@1 64.062 (68.545)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.111)	BT: 0.004 (0.116)	Loss 1.1113 (1.1232)	Prec@1 67.969 (68.202)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.115)	BT: 0.005 (0.121)	Loss 1.1689 (1.1267)	Prec@1 64.062 (68.109)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.113)	BT: 0.005 (0.119)	Loss 1.1211 (1.1297)	Prec@1 71.875 (68.093)	
Total train loss: 1.1298
Avg Loading time: 0.1125 seconds
Avg Batch time: 0.1188 seconds

Train time: 46.60440421104431
 * Prec@1 56.280 Prec@5 83.760 Loss 1.6387
Avg Loading time: 0.1196 seconds
Avg Batch time: 0.1242 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 9.963424682617188

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.082)	BT: 0.004 (0.088)	Loss 1.3799 (1.0957)	Prec@1 60.938 (68.870)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.078)	BT: 0.006 (0.084)	Loss 1.3232 (1.1088)	Prec@1 64.062 (68.455)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.078 (0.065)	BT: 0.091 (0.071)	Loss 1.1055 (1.1143)	Prec@1 72.656 (68.233)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.066)	BT: 0.004 (0.072)	Loss 0.9277 (1.1198)	Prec@1 71.875 (68.139)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.068)	BT: 0.004 (0.075)	Loss 1.1035 (1.1271)	Prec@1 71.875 (67.937)	
Total train loss: 1.1275
Avg Loading time: 0.0683 seconds
Avg Batch time: 0.0747 seconds

Train time: 29.392542123794556
 * Prec@1 56.030 Prec@5 83.880 Loss 1.6514
Avg Loading time: 0.0875 seconds
Avg Batch time: 0.0928 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 7.458626985549927

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.100)	BT: 0.005 (0.109)	Loss 1.2773 (1.0854)	Prec@1 64.844 (69.211)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.378 (0.102)	BT: 0.386 (0.110)	Loss 1.1260 (1.1033)	Prec@1 71.094 (68.815)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.104)	BT: 0.004 (0.111)	Loss 1.2344 (1.1070)	Prec@1 65.625 (68.463)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.101)	BT: 0.006 (0.108)	Loss 1.0117 (1.1170)	Prec@1 74.219 (68.189)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.097)	BT: 0.006 (0.104)	Loss 1.1387 (1.1241)	Prec@1 65.625 (68.097)	
Total train loss: 1.1241
Avg Loading time: 0.0968 seconds
Avg Batch time: 0.1039 seconds

Train time: 40.731945753097534
 * Prec@1 56.150 Prec@5 83.650 Loss 1.6543
Avg Loading time: 0.1152 seconds
Avg Batch time: 0.1194 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 9.607682228088379

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.105)	BT: 0.004 (0.112)	Loss 1.0879 (1.0881)	Prec@1 66.406 (69.161)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.104)	BT: 0.005 (0.111)	Loss 1.1094 (1.0970)	Prec@1 67.969 (69.030)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.099)	BT: 0.006 (0.106)	Loss 1.1758 (1.1129)	Prec@1 64.062 (68.460)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.001 (0.100)	BT: 0.018 (0.107)	Loss 1.2090 (1.1187)	Prec@1 67.188 (68.234)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.099)	BT: 0.006 (0.107)	Loss 1.1582 (1.1201)	Prec@1 67.188 (68.203)	
Total train loss: 1.1206
Avg Loading time: 0.0992 seconds
Avg Batch time: 0.1063 seconds

Train time: 41.69132375717163
 * Prec@1 56.080 Prec@5 83.420 Loss 1.6621
Avg Loading time: 0.0841 seconds
Avg Batch time: 0.0889 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 7.137429714202881

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.107)	BT: 0.012 (0.114)	Loss 1.0830 (1.0765)	Prec@1 70.312 (69.441)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.105)	BT: 0.008 (0.112)	Loss 1.0996 (1.0906)	Prec@1 70.312 (69.301)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.096)	BT: 0.005 (0.103)	Loss 1.1221 (1.0949)	Prec@1 63.281 (68.937)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.097)	BT: 0.006 (0.104)	Loss 1.3818 (1.1083)	Prec@1 57.031 (68.447)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.406 (0.095)	BT: 0.411 (0.102)	Loss 1.0996 (1.1170)	Prec@1 64.844 (68.155)	
Total train loss: 1.1173
Avg Loading time: 0.0948 seconds
Avg Batch time: 0.1016 seconds

Train time: 39.91574716567993
 * Prec@1 55.700 Prec@5 83.350 Loss 1.6748
Avg Loading time: 0.1128 seconds
Avg Batch time: 0.1183 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 9.535179138183594

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.257 (0.083)	BT: 0.268 (0.091)	Loss 1.2412 (1.1161)	Prec@1 61.719 (67.989)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.077)	BT: 0.007 (0.085)	Loss 1.1133 (1.1110)	Prec@1 71.094 (68.359)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.077)	BT: 0.007 (0.085)	Loss 1.1904 (1.1133)	Prec@1 64.844 (68.359)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.075)	BT: 0.005 (0.082)	Loss 1.3447 (1.1152)	Prec@1 61.719 (68.294)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.533 (0.077)	BT: 0.541 (0.084)	Loss 1.0176 (1.1154)	Prec@1 73.438 (68.367)	
Total train loss: 1.1156
Avg Loading time: 0.0766 seconds
Avg Batch time: 0.0842 seconds

Train time: 33.04911518096924
 * Prec@1 56.030 Prec@5 83.550 Loss 1.6641
Avg Loading time: 0.0622 seconds
Avg Batch time: 0.0671 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 5.4236650466918945

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.089)	BT: 0.005 (0.096)	Loss 1.1152 (1.0815)	Prec@1 67.188 (69.221)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.087)	BT: 0.007 (0.095)	Loss 0.9849 (1.0920)	Prec@1 72.656 (69.060)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.088)	BT: 0.005 (0.096)	Loss 1.4326 (1.1081)	Prec@1 64.062 (68.536)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.083)	BT: 0.006 (0.091)	Loss 1.0879 (1.1134)	Prec@1 67.969 (68.324)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.084)	BT: 0.008 (0.092)	Loss 1.1670 (1.1196)	Prec@1 69.531 (68.195)	
Total train loss: 1.1196
Avg Loading time: 0.0840 seconds
Avg Batch time: 0.0915 seconds

Train time: 35.94763803482056
 * Prec@1 55.760 Prec@5 83.400 Loss 1.6768
Avg Loading time: 0.0925 seconds
Avg Batch time: 0.0973 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 7.8702592849731445

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.070)	BT: 0.005 (0.077)	Loss 0.8560 (1.0685)	Prec@1 75.781 (69.521)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.071)	BT: 0.004 (0.077)	Loss 0.8989 (1.0679)	Prec@1 73.438 (69.792)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.088 (0.076)	BT: 0.092 (0.082)	Loss 0.9580 (1.0691)	Prec@1 71.875 (69.661)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.389 (0.077)	BT: 0.402 (0.083)	Loss 1.0352 (1.0701)	Prec@1 71.875 (69.589)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.076)	BT: 0.004 (0.083)	Loss 1.0762 (1.0727)	Prec@1 67.188 (69.423)	
Total train loss: 1.0728
Avg Loading time: 0.0758 seconds
Avg Batch time: 0.0826 seconds

Train time: 32.390584230422974
 * Prec@1 55.890 Prec@5 83.590 Loss 1.6738
Avg Loading time: 0.0891 seconds
Avg Batch time: 0.0938 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 7.602841854095459

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.365 (0.093)	BT: 0.371 (0.100)	Loss 1.1475 (1.0739)	Prec@1 67.969 (68.800)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.084)	BT: 0.005 (0.091)	Loss 1.0000 (1.0613)	Prec@1 73.438 (69.611)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.331 (0.081)	BT: 0.338 (0.088)	Loss 1.0049 (1.0664)	Prec@1 70.312 (69.441)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.082)	BT: 0.005 (0.089)	Loss 1.0498 (1.0664)	Prec@1 70.312 (69.689)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.268 (0.080)	BT: 0.278 (0.087)	Loss 1.0791 (1.0698)	Prec@1 68.750 (69.653)	
Total train loss: 1.0699
Avg Loading time: 0.0802 seconds
Avg Batch time: 0.0871 seconds

Train time: 34.19041895866394
 * Prec@1 55.720 Prec@5 83.510 Loss 1.6787
Avg Loading time: 0.0918 seconds
Avg Batch time: 0.0973 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 7.811884641647339

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.087)	BT: 0.005 (0.093)	Loss 1.0547 (1.0523)	Prec@1 70.312 (70.132)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.086)	BT: 0.004 (0.093)	Loss 1.1309 (1.0612)	Prec@1 70.312 (69.892)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.088)	BT: 0.005 (0.095)	Loss 1.1094 (1.0638)	Prec@1 65.625 (69.842)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.085)	BT: 0.004 (0.091)	Loss 1.0469 (1.0649)	Prec@1 69.531 (69.912)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.087)	BT: 0.005 (0.093)	Loss 0.9595 (1.0679)	Prec@1 71.094 (69.792)	
Total train loss: 1.0678
Avg Loading time: 0.0866 seconds
Avg Batch time: 0.0933 seconds

Train time: 36.6054310798645
 * Prec@1 55.960 Prec@5 83.590 Loss 1.6738
Avg Loading time: 0.1022 seconds
Avg Batch time: 0.1065 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 8.602331399917603

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.083)	BT: 0.004 (0.089)	Loss 1.0264 (1.0659)	Prec@1 67.969 (69.461)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.085)	BT: 0.006 (0.092)	Loss 1.1064 (1.0619)	Prec@1 66.406 (69.767)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.084)	BT: 0.008 (0.090)	Loss 1.1709 (1.0577)	Prec@1 68.750 (70.089)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.085)	BT: 0.007 (0.092)	Loss 1.0518 (1.0629)	Prec@1 72.656 (69.924)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.086)	BT: 0.004 (0.093)	Loss 1.0361 (1.0676)	Prec@1 68.750 (69.754)	
Total train loss: 1.0675
Avg Loading time: 0.0861 seconds
Avg Batch time: 0.0929 seconds

Train time: 36.48487854003906
 * Prec@1 55.970 Prec@5 83.500 Loss 1.6738
Avg Loading time: 0.1095 seconds
Avg Batch time: 0.1145 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 9.174479007720947

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.106)	BT: 0.013 (0.113)	Loss 1.1309 (1.0597)	Prec@1 70.312 (69.992)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.098)	BT: 0.005 (0.106)	Loss 1.2168 (1.0595)	Prec@1 68.750 (69.857)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.208 (0.102)	BT: 0.213 (0.109)	Loss 1.1924 (1.0581)	Prec@1 69.531 (70.039)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.099)	BT: 0.011 (0.106)	Loss 1.2656 (1.0615)	Prec@1 64.062 (69.917)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.098)	BT: 0.008 (0.105)	Loss 1.1562 (1.0662)	Prec@1 71.875 (69.760)	
Total train loss: 1.0667
Avg Loading time: 0.0977 seconds
Avg Batch time: 0.1046 seconds

Train time: 40.99892020225525
 * Prec@1 55.900 Prec@5 83.660 Loss 1.6787
Avg Loading time: 0.0928 seconds
Avg Batch time: 0.0975 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 7.8772292137146

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.100)	BT: 0.005 (0.107)	Loss 0.9932 (1.0622)	Prec@1 72.656 (70.012)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.096)	BT: 0.008 (0.102)	Loss 1.1221 (1.0572)	Prec@1 64.062 (70.097)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.094)	BT: 0.010 (0.101)	Loss 1.1504 (1.0573)	Prec@1 67.188 (70.189)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.095)	BT: 0.004 (0.102)	Loss 1.0098 (1.0638)	Prec@1 65.625 (69.749)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.095)	BT: 0.006 (0.102)	Loss 1.1992 (1.0681)	Prec@1 64.062 (69.649)	
Total train loss: 1.0685
Avg Loading time: 0.0949 seconds
Avg Batch time: 0.1016 seconds

Train time: 39.850998878479004
 * Prec@1 55.870 Prec@5 83.540 Loss 1.6787
Avg Loading time: 0.1037 seconds
Avg Batch time: 0.1085 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 8.75762414932251

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.110)	BT: 0.007 (0.117)	Loss 1.1963 (1.0650)	Prec@1 63.281 (69.702)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 1.106 (0.114)	BT: 1.118 (0.121)	Loss 1.2559 (1.0524)	Prec@1 62.500 (70.037)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.045 (0.107)	BT: 0.051 (0.114)	Loss 0.9507 (1.0566)	Prec@1 74.219 (69.945)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.110)	BT: 0.006 (0.117)	Loss 1.0020 (1.0567)	Prec@1 73.438 (70.035)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.108)	BT: 0.014 (0.115)	Loss 1.0820 (1.0591)	Prec@1 67.188 (69.906)	
Total train loss: 1.0594
Avg Loading time: 0.1079 seconds
Avg Batch time: 0.1149 seconds

Train time: 45.07425260543823
 * Prec@1 55.750 Prec@5 83.440 Loss 1.6787
Avg Loading time: 0.0875 seconds
Avg Batch time: 0.0920 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 7.45688796043396

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.096)	BT: 0.005 (0.102)	Loss 0.9282 (1.0712)	Prec@1 71.875 (69.571)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.097)	BT: 0.006 (0.104)	Loss 1.0410 (1.0652)	Prec@1 75.781 (69.561)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.093)	BT: 0.016 (0.099)	Loss 1.1074 (1.0624)	Prec@1 67.188 (69.815)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.092)	BT: 0.006 (0.098)	Loss 0.9512 (1.0652)	Prec@1 73.438 (69.744)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.092)	BT: 0.004 (0.099)	Loss 1.2725 (1.0668)	Prec@1 69.531 (69.796)	
Total train loss: 1.0666
Avg Loading time: 0.0920 seconds
Avg Batch time: 0.0987 seconds

Train time: 38.77332377433777
 * Prec@1 55.660 Prec@5 83.500 Loss 1.6797
Avg Loading time: 0.1179 seconds
Avg Batch time: 0.1225 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 9.799901008605957

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.111)	BT: 0.005 (0.118)	Loss 1.1426 (1.0600)	Prec@1 66.406 (69.651)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.105)	BT: 0.004 (0.112)	Loss 1.1787 (1.0695)	Prec@1 67.188 (69.361)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.468 (0.102)	BT: 0.475 (0.109)	Loss 1.1475 (1.0693)	Prec@1 66.406 (69.408)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.098)	BT: 0.007 (0.105)	Loss 1.1191 (1.0696)	Prec@1 69.531 (69.474)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.097)	BT: 0.005 (0.104)	Loss 1.0928 (1.0658)	Prec@1 67.188 (69.619)	
Total train loss: 1.0658
Avg Loading time: 0.0968 seconds
Avg Batch time: 0.1038 seconds

Train time: 40.74029278755188
 * Prec@1 55.910 Prec@5 83.450 Loss 1.6787
Avg Loading time: 0.0792 seconds
Avg Batch time: 0.0840 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 6.762325048446655

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.114)	BT: 0.005 (0.121)	Loss 1.1934 (1.0400)	Prec@1 60.938 (70.333)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.099)	BT: 0.005 (0.106)	Loss 0.9302 (1.0649)	Prec@1 70.312 (69.581)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.187 (0.100)	BT: 0.201 (0.107)	Loss 1.2334 (1.0624)	Prec@1 60.938 (69.651)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.096)	BT: 0.006 (0.103)	Loss 0.9375 (1.0607)	Prec@1 76.562 (69.812)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.097)	BT: 0.008 (0.104)	Loss 1.1201 (1.0639)	Prec@1 71.875 (69.778)	
Total train loss: 1.0639
Avg Loading time: 0.0966 seconds
Avg Batch time: 0.1033 seconds

Train time: 40.516005754470825
 * Prec@1 55.750 Prec@5 83.570 Loss 1.6787
Avg Loading time: 0.1170 seconds
Avg Batch time: 0.1223 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 9.777337551116943

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.102)	BT: 0.009 (0.109)	Loss 1.1191 (1.0657)	Prec@1 71.875 (69.762)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.093)	BT: 0.005 (0.100)	Loss 0.9956 (1.0590)	Prec@1 76.562 (70.252)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.226 (0.098)	BT: 0.243 (0.105)	Loss 0.8599 (1.0541)	Prec@1 74.219 (70.172)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.184 (0.097)	BT: 0.189 (0.104)	Loss 0.9995 (1.0525)	Prec@1 69.531 (70.175)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.101)	BT: 0.005 (0.108)	Loss 1.1719 (1.0521)	Prec@1 71.094 (70.156)	
Total train loss: 1.0525
Avg Loading time: 0.1005 seconds
Avg Batch time: 0.1076 seconds

Train time: 42.18175411224365
 * Prec@1 55.970 Prec@5 83.450 Loss 1.6768
Avg Loading time: 0.1024 seconds
Avg Batch time: 0.1073 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 8.6055006980896

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.108)	BT: 0.008 (0.114)	Loss 1.0273 (1.0356)	Prec@1 76.562 (70.653)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.087 (0.100)	BT: 0.093 (0.107)	Loss 1.1309 (1.0517)	Prec@1 66.406 (70.353)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.091)	BT: 0.007 (0.099)	Loss 1.4863 (1.0513)	Prec@1 58.594 (70.309)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.093)	BT: 0.004 (0.100)	Loss 1.0508 (1.0538)	Prec@1 67.969 (70.107)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.012 (0.093)	BT: 0.016 (0.100)	Loss 1.1465 (1.0579)	Prec@1 70.312 (69.876)	
Total train loss: 1.0578
Avg Loading time: 0.0927 seconds
Avg Batch time: 0.0997 seconds

Train time: 39.07852005958557
 * Prec@1 55.780 Prec@5 83.490 Loss 1.6768
Avg Loading time: 0.1045 seconds
Avg Batch time: 0.1086 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 8.738192081451416

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.112)	BT: 0.008 (0.118)	Loss 0.9912 (1.0426)	Prec@1 69.531 (70.483)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.100)	BT: 0.007 (0.106)	Loss 0.8267 (1.0647)	Prec@1 80.469 (69.822)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.097)	BT: 0.005 (0.103)	Loss 1.0547 (1.0586)	Prec@1 64.844 (70.089)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.093)	BT: 0.004 (0.100)	Loss 0.8613 (1.0644)	Prec@1 77.344 (69.889)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.094)	BT: 0.005 (0.101)	Loss 0.9150 (1.0601)	Prec@1 75.000 (69.938)	
Total train loss: 1.0603
Avg Loading time: 0.0943 seconds
Avg Batch time: 0.1011 seconds

Train time: 39.6559681892395
 * Prec@1 55.950 Prec@5 83.400 Loss 1.6768
Avg Loading time: 0.0990 seconds
Avg Batch time: 0.1035 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 8.325255632400513

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.098)	BT: 0.007 (0.105)	Loss 1.1094 (1.0440)	Prec@1 71.094 (70.172)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.097)	BT: 0.005 (0.103)	Loss 1.0068 (1.0558)	Prec@1 71.094 (70.097)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.098)	BT: 0.006 (0.104)	Loss 0.9482 (1.0484)	Prec@1 75.000 (70.403)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.099)	BT: 0.008 (0.106)	Loss 1.0498 (1.0487)	Prec@1 73.438 (70.423)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.098)	BT: 0.004 (0.105)	Loss 1.0967 (1.0535)	Prec@1 69.531 (70.226)	
Total train loss: 1.0536
Avg Loading time: 0.0982 seconds
Avg Batch time: 0.1049 seconds

Train time: 41.15286040306091
 * Prec@1 55.800 Prec@5 83.430 Loss 1.6797
Avg Loading time: 0.1202 seconds
Avg Batch time: 0.1240 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 9.943983316421509

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.344 (0.111)	BT: 0.353 (0.119)	Loss 1.0166 (1.0709)	Prec@1 65.625 (69.992)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.097)	BT: 0.011 (0.104)	Loss 1.0010 (1.0585)	Prec@1 71.875 (70.272)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.145 (0.094)	BT: 0.158 (0.100)	Loss 0.8833 (1.0547)	Prec@1 75.000 (70.323)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.095)	BT: 0.004 (0.101)	Loss 1.1074 (1.0550)	Prec@1 71.094 (70.262)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.095 (0.097)	BT: 0.099 (0.103)	Loss 1.1533 (1.0546)	Prec@1 69.531 (70.196)	
Total train loss: 1.0550
Avg Loading time: 0.0964 seconds
Avg Batch time: 0.1028 seconds

Train time: 40.38394284248352
 * Prec@1 55.760 Prec@5 83.490 Loss 1.6836
Avg Loading time: 0.0839 seconds
Avg Batch time: 0.0889 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 7.196544885635376

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.099)	BT: 0.007 (0.106)	Loss 1.0205 (1.0417)	Prec@1 71.875 (70.232)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.101)	BT: 0.005 (0.108)	Loss 1.2363 (1.0548)	Prec@1 62.500 (70.022)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.005 (0.098)	BT: 0.010 (0.104)	Loss 1.2178 (1.0545)	Prec@1 63.281 (70.242)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.098)	BT: 0.004 (0.105)	Loss 0.9966 (1.0551)	Prec@1 67.969 (70.202)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.098)	BT: 0.003 (0.104)	Loss 1.0117 (1.0541)	Prec@1 70.312 (70.226)	
Total train loss: 1.0541
Avg Loading time: 0.0980 seconds
Avg Batch time: 0.1040 seconds

Train time: 40.88289999961853
 * Prec@1 55.750 Prec@5 83.440 Loss 1.6797
Avg Loading time: 0.0920 seconds
Avg Batch time: 0.0963 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 7.7436699867248535

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.105)	BT: 0.006 (0.112)	Loss 0.9619 (1.0659)	Prec@1 71.094 (69.952)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.105)	BT: 0.004 (0.113)	Loss 1.1484 (1.0583)	Prec@1 68.750 (70.067)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.281 (0.100)	BT: 0.290 (0.107)	Loss 1.2100 (1.0598)	Prec@1 67.969 (70.119)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.565 (0.101)	BT: 0.572 (0.108)	Loss 1.0996 (1.0593)	Prec@1 67.188 (70.097)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.101)	BT: 0.005 (0.108)	Loss 0.9917 (1.0582)	Prec@1 66.406 (70.064)	
Total train loss: 1.0585
Avg Loading time: 0.1011 seconds
Avg Batch time: 0.1077 seconds

Train time: 42.26286959648132
 * Prec@1 55.840 Prec@5 83.490 Loss 1.6797
Avg Loading time: 0.0985 seconds
Avg Batch time: 0.1030 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 8.268639326095581

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.103)	BT: 0.004 (0.109)	Loss 1.0098 (1.0572)	Prec@1 71.094 (70.032)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.102)	BT: 0.005 (0.107)	Loss 1.1270 (1.0570)	Prec@1 70.312 (69.942)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.060 (0.096)	BT: 0.065 (0.101)	Loss 1.1914 (1.0598)	Prec@1 67.969 (69.975)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.096)	BT: 0.004 (0.102)	Loss 1.0254 (1.0564)	Prec@1 70.312 (70.070)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.094)	BT: 0.006 (0.101)	Loss 1.1553 (1.0538)	Prec@1 64.062 (70.174)	
Total train loss: 1.0534
Avg Loading time: 0.0941 seconds
Avg Batch time: 0.1003 seconds

Train time: 39.36080884933472
 * Prec@1 56.020 Prec@5 83.560 Loss 1.6787
Avg Loading time: 0.0979 seconds
Avg Batch time: 0.1027 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 8.225305557250977

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.106)	BT: 0.005 (0.112)	Loss 1.1318 (1.0589)	Prec@1 66.406 (69.702)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.102)	BT: 0.005 (0.108)	Loss 0.8188 (1.0558)	Prec@1 76.562 (69.897)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.098)	BT: 0.007 (0.104)	Loss 1.0107 (1.0535)	Prec@1 70.312 (70.142)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.093)	BT: 0.005 (0.099)	Loss 1.0889 (1.0562)	Prec@1 71.875 (70.100)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.093)	BT: 0.004 (0.100)	Loss 0.9600 (1.0541)	Prec@1 69.531 (70.098)	
Total train loss: 1.0543
Avg Loading time: 0.0931 seconds
Avg Batch time: 0.0993 seconds

Train time: 38.961724519729614
 * Prec@1 55.790 Prec@5 83.450 Loss 1.6797
Avg Loading time: 0.0908 seconds
Avg Batch time: 0.0953 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 7.663563251495361

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.098)	BT: 0.004 (0.105)	Loss 0.9292 (1.0363)	Prec@1 71.094 (70.613)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.099)	BT: 0.005 (0.106)	Loss 0.8350 (1.0414)	Prec@1 76.562 (70.653)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.098)	BT: 0.004 (0.105)	Loss 1.0596 (1.0449)	Prec@1 68.750 (70.426)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.394 (0.095)	BT: 0.400 (0.102)	Loss 0.9771 (1.0568)	Prec@1 73.438 (70.025)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.094)	BT: 0.005 (0.101)	Loss 1.2002 (1.0579)	Prec@1 64.062 (69.900)	
Total train loss: 1.0581
Avg Loading time: 0.0941 seconds
Avg Batch time: 0.1009 seconds

Train time: 39.591694831848145
 * Prec@1 55.970 Prec@5 83.330 Loss 1.6787
Avg Loading time: 0.0969 seconds
Avg Batch time: 0.1011 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 8.138373136520386

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.113)	BT: 0.005 (0.119)	Loss 0.9141 (1.0672)	Prec@1 70.312 (69.511)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.101)	BT: 0.005 (0.107)	Loss 1.0049 (1.0700)	Prec@1 71.875 (69.531)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.098)	BT: 0.006 (0.104)	Loss 1.1748 (1.0688)	Prec@1 69.531 (69.601)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.094)	BT: 0.008 (0.101)	Loss 1.1260 (1.0652)	Prec@1 65.625 (69.804)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.095)	BT: 0.004 (0.102)	Loss 1.0156 (1.0587)	Prec@1 70.312 (69.966)	
Total train loss: 1.0586
Avg Loading time: 0.0949 seconds
Avg Batch time: 0.1015 seconds

Train time: 39.853304386138916
 * Prec@1 55.870 Prec@5 83.420 Loss 1.6787
Avg Loading time: 0.0820 seconds
Avg Batch time: 0.0868 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 7.024433374404907

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.093)	BT: 0.004 (0.099)	Loss 1.1416 (1.0272)	Prec@1 68.750 (70.743)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.089)	BT: 0.005 (0.095)	Loss 1.1670 (1.0479)	Prec@1 66.406 (70.267)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.005 (0.083)	BT: 0.016 (0.090)	Loss 0.9448 (1.0468)	Prec@1 75.781 (70.306)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.084)	BT: 0.004 (0.090)	Loss 1.0449 (1.0519)	Prec@1 71.875 (70.265)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.087)	BT: 0.004 (0.093)	Loss 1.1006 (1.0543)	Prec@1 68.750 (70.112)	
Total train loss: 1.0541
Avg Loading time: 0.0864 seconds
Avg Batch time: 0.0928 seconds

Train time: 36.44215440750122
 * Prec@1 55.780 Prec@5 83.310 Loss 1.6768
Avg Loading time: 0.0880 seconds
Avg Batch time: 0.0919 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 7.3887693881988525

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.096)	BT: 0.005 (0.103)	Loss 0.9712 (1.0734)	Prec@1 71.875 (69.641)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.098)	BT: 0.004 (0.105)	Loss 0.9072 (1.0678)	Prec@1 75.781 (69.686)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.264 (0.094)	BT: 0.270 (0.100)	Loss 0.9370 (1.0598)	Prec@1 74.219 (69.905)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.090)	BT: 0.007 (0.096)	Loss 1.0811 (1.0578)	Prec@1 72.656 (70.120)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.091)	BT: 0.004 (0.097)	Loss 0.9707 (1.0559)	Prec@1 73.438 (70.090)	
Total train loss: 1.0558
Avg Loading time: 0.0904 seconds
Avg Batch time: 0.0968 seconds

Train time: 38.027984619140625
 * Prec@1 55.620 Prec@5 83.450 Loss 1.6768
Avg Loading time: 0.0827 seconds
Avg Batch time: 0.0870 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 7.030376434326172

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.102)	BT: 0.004 (0.108)	Loss 1.0762 (1.0670)	Prec@1 70.312 (69.321)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.096)	BT: 0.006 (0.102)	Loss 1.3086 (1.0640)	Prec@1 64.062 (69.626)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.734 (0.090)	BT: 0.743 (0.096)	Loss 1.0889 (1.0569)	Prec@1 69.531 (69.815)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.088)	BT: 0.008 (0.094)	Loss 1.0791 (1.0534)	Prec@1 71.094 (69.969)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.086)	BT: 0.011 (0.092)	Loss 1.1650 (1.0537)	Prec@1 69.531 (70.016)	
Total train loss: 1.0534
Avg Loading time: 0.0853 seconds
Avg Batch time: 0.0914 seconds

Train time: 35.916831254959106
 * Prec@1 55.850 Prec@5 83.480 Loss 1.6787
Avg Loading time: 0.0735 seconds
Avg Batch time: 0.0788 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 6.414334297180176

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.056)	BT: 0.007 (0.064)	Loss 1.1445 (1.0759)	Prec@1 63.281 (69.882)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.103 (0.048)	BT: 0.108 (0.056)	Loss 1.1533 (1.0630)	Prec@1 71.094 (69.962)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.064)	BT: 0.003 (0.072)	Loss 1.0996 (1.0529)	Prec@1 69.531 (70.109)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.075)	BT: 0.004 (0.082)	Loss 1.1855 (1.0579)	Prec@1 67.969 (69.889)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.078)	BT: 0.005 (0.086)	Loss 1.0293 (1.0542)	Prec@1 71.094 (69.986)	
Total train loss: 1.0545
Avg Loading time: 0.0781 seconds
Avg Batch time: 0.0854 seconds

Train time: 33.53363561630249
 * Prec@1 55.670 Prec@5 83.350 Loss 1.6797
Avg Loading time: 0.1120 seconds
Avg Batch time: 0.1163 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 9.358458518981934

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.108)	BT: 0.005 (0.114)	Loss 1.1211 (1.0725)	Prec@1 63.281 (69.371)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.097)	BT: 0.005 (0.104)	Loss 0.9819 (1.0631)	Prec@1 75.000 (69.782)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.105)	BT: 0.006 (0.112)	Loss 1.1699 (1.0555)	Prec@1 69.531 (69.982)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.067 (0.106)	BT: 0.077 (0.113)	Loss 1.0967 (1.0570)	Prec@1 71.875 (70.012)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.102)	BT: 0.004 (0.109)	Loss 1.1318 (1.0557)	Prec@1 68.750 (69.978)	
Total train loss: 1.0562
Avg Loading time: 0.1019 seconds
Avg Batch time: 0.1085 seconds

Train time: 42.53474164009094
 * Prec@1 55.810 Prec@5 83.510 Loss 1.6787
Avg Loading time: 0.0946 seconds
Avg Batch time: 0.0990 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 7.946130275726318

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.110)	BT: 0.011 (0.117)	Loss 0.8540 (1.0169)	Prec@1 75.781 (70.673)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.098)	BT: 0.004 (0.105)	Loss 0.8867 (1.0350)	Prec@1 72.656 (70.498)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.076 (0.091)	BT: 0.080 (0.098)	Loss 1.2275 (1.0442)	Prec@1 63.281 (70.473)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.233 (0.099)	BT: 0.240 (0.106)	Loss 1.1914 (1.0486)	Prec@1 62.500 (70.200)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.100)	BT: 0.005 (0.107)	Loss 0.9795 (1.0532)	Prec@1 75.000 (70.128)	
Total train loss: 1.0537
Avg Loading time: 0.0998 seconds
Avg Batch time: 0.1072 seconds

Train time: 42.07916617393494
 * Prec@1 55.670 Prec@5 83.610 Loss 1.6865
Avg Loading time: 0.1249 seconds
Avg Batch time: 0.1300 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 10.40851354598999

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.099)	BT: 0.004 (0.105)	Loss 0.9941 (1.0598)	Prec@1 75.781 (69.792)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.093)	BT: 0.008 (0.099)	Loss 1.2129 (1.0602)	Prec@1 67.188 (70.022)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.021 (0.097)	BT: 0.027 (0.104)	Loss 0.9556 (1.0626)	Prec@1 70.312 (69.919)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.096)	BT: 0.004 (0.103)	Loss 0.8618 (1.0589)	Prec@1 74.219 (69.879)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.103)	BT: 0.004 (0.110)	Loss 1.0166 (1.0563)	Prec@1 67.969 (70.008)	
Total train loss: 1.0564
Avg Loading time: 0.1031 seconds
Avg Batch time: 0.1097 seconds

Train time: 43.06342315673828
 * Prec@1 55.990 Prec@5 83.450 Loss 1.6748
Avg Loading time: 0.1311 seconds
Avg Batch time: 0.1361 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 10.853513479232788

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.118)	BT: 0.004 (0.125)	Loss 0.9971 (1.0523)	Prec@1 72.656 (70.062)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.165 (0.108)	BT: 0.170 (0.115)	Loss 0.9268 (1.0492)	Prec@1 75.000 (70.433)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.109)	BT: 0.008 (0.116)	Loss 0.9932 (1.0494)	Prec@1 71.875 (70.219)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.105)	BT: 0.005 (0.112)	Loss 0.7788 (1.0567)	Prec@1 80.469 (70.040)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.101)	BT: 0.005 (0.108)	Loss 0.9893 (1.0534)	Prec@1 67.188 (70.188)	
Total train loss: 1.0538
Avg Loading time: 0.1007 seconds
Avg Batch time: 0.1075 seconds

Train time: 42.19849634170532
 * Prec@1 55.960 Prec@5 83.550 Loss 1.6797
Avg Loading time: 0.0542 seconds
Avg Batch time: 0.0609 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 5.014673948287964

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.086)	BT: 0.004 (0.092)	Loss 1.2100 (1.0587)	Prec@1 69.531 (70.312)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.082)	BT: 0.013 (0.088)	Loss 1.1699 (1.0612)	Prec@1 69.531 (70.092)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.019 (0.080)	BT: 0.031 (0.087)	Loss 1.0303 (1.0534)	Prec@1 75.781 (70.142)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.079)	BT: 0.004 (0.085)	Loss 1.1904 (1.0550)	Prec@1 69.531 (70.145)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.081)	BT: 0.005 (0.088)	Loss 1.0518 (1.0580)	Prec@1 72.656 (70.044)	
Total train loss: 1.0578
Avg Loading time: 0.0810 seconds
Avg Batch time: 0.0875 seconds

Train time: 34.3642418384552
 * Prec@1 55.740 Prec@5 83.470 Loss 1.6787
Avg Loading time: 0.0839 seconds
Avg Batch time: 0.0880 seconds

Best acc: 56.720
--------------------------------------------------------------------------------
Test time: 7.06184720993042

