
      ==> Arguments:
          dataset: cifar100
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20fp_cifar100.pth.tar
          mode: rram
          workers: 8
          epochs: 40
          start_epoch: 0
          batch_size: 256
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          milestones: [8, 16, 24, 32]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 11
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20fp_cifar100.pth.tar ...
Original model accuracy: 69.5999984741211
ResNet_cifar(
  (conv12): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): QConv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu14): ReLU(inplace=True)
  (conv15): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): QConv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (relu15): ReLU(inplace=True)
  (conv16): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (conv18): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu18): ReLU(inplace=True)
  (conv19): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu19): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (bn20): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=64, out_features=100, bias=False)
  (bn21): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 49.430 Prec@5 76.960 Loss 2.1836
Pre-trained Prec@1 with 11 layers frozen: 49.43000030517578 	 Loss: 2.18359375

Starting training on SRAM layers...
Epoch: [0][38/196]	LR: 0.01	Loss 0.7090 (0.7516)	Prec@1 81.641 (77.875)	
Epoch: [0][77/196]	LR: 0.01	Loss 0.9565 (0.7920)	Prec@1 74.219 (76.993)	
Epoch: [0][116/196]	LR: 0.01	Loss 0.9194 (0.8441)	Prec@1 72.656 (75.594)	
Epoch: [0][155/196]	LR: 0.01	Loss 0.9209 (0.8520)	Prec@1 78.125 (75.601)	
Epoch: [0][194/196]	LR: 0.01	Loss 0.7476 (0.8437)	Prec@1 79.688 (75.986)	
Total train loss: 0.8437

Train time: 361.6139192581177
 * Prec@1 61.680 Prec@5 87.180 Loss 1.4199
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 389.76994585990906

Epoch: [1][38/196]	LR: 0.01	Loss 0.8643 (0.8921)	Prec@1 73.828 (75.571)	
Epoch: [1][77/196]	LR: 0.01	Loss 0.8408 (0.8877)	Prec@1 77.734 (75.356)	
Epoch: [1][116/196]	LR: 0.01	Loss 0.7842 (0.8692)	Prec@1 78.125 (75.711)	
Epoch: [1][155/196]	LR: 0.01	Loss 0.7910 (0.8542)	Prec@1 79.297 (76.037)	
Epoch: [1][194/196]	LR: 0.01	Loss 0.9614 (0.8407)	Prec@1 72.266 (76.322)	
Total train loss: 0.8410

Train time: 72.91116619110107
 * Prec@1 46.760 Prec@5 73.510 Loss 2.2441
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 78.25066423416138

Epoch: [2][38/196]	LR: 0.01	Loss 0.8823 (0.8501)	Prec@1 72.266 (76.042)	
Epoch: [2][77/196]	LR: 0.01	Loss 0.8589 (0.8727)	Prec@1 78.125 (75.441)	
Epoch: [2][116/196]	LR: 0.01	Loss 0.8906 (0.8981)	Prec@1 74.219 (74.790)	
Epoch: [2][155/196]	LR: 0.01	Loss 1.0801 (0.9043)	Prec@1 68.359 (74.457)	
Epoch: [2][194/196]	LR: 0.01	Loss 1.1865 (0.9345)	Prec@1 68.359 (73.594)	
Total train loss: 0.9347

Train time: 26.12156105041504
 * Prec@1 51.030 Prec@5 79.780 Loss 2.1133
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 31.385474920272827

Epoch: [3][38/196]	LR: 0.01	Loss 1.0059 (1.1006)	Prec@1 69.922 (68.620)	
Epoch: [3][77/196]	LR: 0.01	Loss 1.3848 (1.1131)	Prec@1 58.203 (68.409)	
Epoch: [3][116/196]	LR: 0.01	Loss 1.3301 (1.2029)	Prec@1 61.328 (66.490)	
Epoch: [3][155/196]	LR: 0.01	Loss 1.4033 (1.2431)	Prec@1 60.156 (65.653)	
Epoch: [3][194/196]	LR: 0.01	Loss 1.4258 (1.2720)	Prec@1 61.328 (65.046)	
Total train loss: 1.2725

Train time: 25.912625312805176
 * Prec@1 45.370 Prec@5 73.490 Loss 2.2188
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 29.21038317680359

Epoch: [4][38/196]	LR: 0.01	Loss 1.2461 (1.3549)	Prec@1 66.406 (63.652)	
Epoch: [4][77/196]	LR: 0.01	Loss 1.5020 (1.3642)	Prec@1 63.281 (63.436)	
Epoch: [4][116/196]	LR: 0.01	Loss 1.3818 (1.3735)	Prec@1 61.719 (63.004)	
Epoch: [4][155/196]	LR: 0.01	Loss 1.3135 (1.3697)	Prec@1 64.453 (63.083)	
Epoch: [4][194/196]	LR: 0.01	Loss 1.3535 (1.3595)	Prec@1 66.406 (63.275)	
Total train loss: 1.3598

Train time: 21.360671043395996
 * Prec@1 56.900 Prec@5 83.710 Loss 1.6465
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 27.035958528518677

Epoch: [5][38/196]	LR: 0.01	Loss 1.3096 (1.3263)	Prec@1 64.453 (64.113)	
Epoch: [5][77/196]	LR: 0.01	Loss 1.4971 (1.3856)	Prec@1 63.672 (62.735)	
Epoch: [5][116/196]	LR: 0.01	Loss 1.4531 (1.3948)	Prec@1 59.766 (62.280)	
Epoch: [5][155/196]	LR: 0.01	Loss 1.7627 (1.4372)	Prec@1 51.562 (61.356)	
Epoch: [5][194/196]	LR: 0.01	Loss 1.6143 (1.4756)	Prec@1 58.203 (60.501)	
Total train loss: 1.4761

Train time: 23.97989010810852
 * Prec@1 47.370 Prec@5 74.680 Loss 2.1562
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 27.480777740478516

Epoch: [6][38/196]	LR: 0.01	Loss 1.7480 (1.7487)	Prec@1 53.516 (53.496)	
Epoch: [6][77/196]	LR: 0.01	Loss 1.9346 (1.7649)	Prec@1 50.391 (53.385)	
Epoch: [6][116/196]	LR: 0.01	Loss 1.8018 (1.8063)	Prec@1 57.031 (52.274)	
Epoch: [6][155/196]	LR: 0.01	Loss 1.8721 (1.7952)	Prec@1 47.656 (52.404)	
Epoch: [6][194/196]	LR: 0.01	Loss 1.5693 (1.7793)	Prec@1 53.125 (52.825)	
Total train loss: 1.7797

Train time: 18.564873218536377
 * Prec@1 29.890 Prec@5 58.090 Loss 3.5078
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 25.301690578460693

Epoch: [7][38/196]	LR: 0.01	Loss 1.6426 (1.6880)	Prec@1 55.469 (54.507)	
Epoch: [7][77/196]	LR: 0.01	Loss 1.6992 (1.6969)	Prec@1 50.781 (54.152)	
Epoch: [7][116/196]	LR: 0.01	Loss 1.7617 (1.7073)	Prec@1 52.734 (53.886)	
Epoch: [7][155/196]	LR: 0.01	Loss 1.8398 (1.7561)	Prec@1 54.297 (52.767)	
Epoch: [7][194/196]	LR: 0.01	Loss 1.6357 (1.7848)	Prec@1 52.344 (52.027)	
Total train loss: 1.7853

Train time: 20.329559087753296
 * Prec@1 35.430 Prec@5 67.820 Loss 3.3320
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 24.289518356323242

Epoch: [8][38/196]	LR: 0.001	Loss 1.6787 (1.7862)	Prec@1 52.734 (51.873)	
Epoch: [8][77/196]	LR: 0.001	Loss 1.6299 (1.7816)	Prec@1 56.250 (51.913)	
Epoch: [8][116/196]	LR: 0.001	Loss 1.8398 (1.7801)	Prec@1 50.391 (51.916)	
Epoch: [8][155/196]	LR: 0.001	Loss 1.6680 (1.7698)	Prec@1 57.031 (52.111)	
Epoch: [8][194/196]	LR: 0.001	Loss 1.5674 (1.7625)	Prec@1 54.297 (52.268)	
Total train loss: 1.7624

Train time: 19.555927515029907
 * Prec@1 51.180 Prec@5 80.420 Loss 1.8750
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 24.71257448196411

Epoch: [9][38/196]	LR: 0.001	Loss 1.8555 (1.7265)	Prec@1 50.781 (52.784)	
Epoch: [9][77/196]	LR: 0.001	Loss 1.7832 (1.7220)	Prec@1 51.172 (53.170)	
Epoch: [9][116/196]	LR: 0.001	Loss 1.6973 (1.7184)	Prec@1 52.734 (53.195)	
Epoch: [9][155/196]	LR: 0.001	Loss 1.6299 (1.7179)	Prec@1 57.031 (53.345)	
Epoch: [9][194/196]	LR: 0.001	Loss 1.9277 (1.7222)	Prec@1 49.219 (53.219)	
Total train loss: 1.7222

Train time: 18.8397696018219
 * Prec@1 51.700 Prec@5 80.580 Loss 1.8643
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 22.86847233772278

Epoch: [10][38/196]	LR: 0.001	Loss 1.8193 (1.7058)	Prec@1 49.219 (53.335)	
Epoch: [10][77/196]	LR: 0.001	Loss 1.8408 (1.7042)	Prec@1 53.906 (53.415)	
Epoch: [10][116/196]	LR: 0.001	Loss 1.5703 (1.7068)	Prec@1 55.859 (53.456)	
Epoch: [10][155/196]	LR: 0.001	Loss 1.7676 (1.7070)	Prec@1 53.906 (53.563)	
Epoch: [10][194/196]	LR: 0.001	Loss 1.8564 (1.7118)	Prec@1 47.266 (53.433)	
Total train loss: 1.7120

Train time: 20.178566455841064
 * Prec@1 51.820 Prec@5 80.480 Loss 1.8574
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 25.33980393409729

Epoch: [11][38/196]	LR: 0.001	Loss 1.5029 (1.6865)	Prec@1 55.078 (53.786)	
Epoch: [11][77/196]	LR: 0.001	Loss 1.8672 (1.6998)	Prec@1 54.297 (53.806)	
Epoch: [11][116/196]	LR: 0.001	Loss 1.5830 (1.6982)	Prec@1 55.078 (53.786)	
Epoch: [11][155/196]	LR: 0.001	Loss 1.6367 (1.6996)	Prec@1 59.375 (53.696)	
Epoch: [11][194/196]	LR: 0.001	Loss 1.7305 (1.6988)	Prec@1 53.125 (53.764)	
Total train loss: 1.6995

Train time: 18.76775574684143
 * Prec@1 52.280 Prec@5 80.630 Loss 1.8418
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 22.711177349090576

Epoch: [12][38/196]	LR: 0.001	Loss 1.7881 (1.7078)	Prec@1 55.078 (53.816)	
Epoch: [12][77/196]	LR: 0.001	Loss 1.7676 (1.6967)	Prec@1 51.562 (54.107)	
Epoch: [12][116/196]	LR: 0.001	Loss 1.7549 (1.6949)	Prec@1 51.172 (53.963)	
Epoch: [12][155/196]	LR: 0.001	Loss 1.6279 (1.6993)	Prec@1 55.469 (53.819)	
Epoch: [12][194/196]	LR: 0.001	Loss 1.8115 (1.6918)	Prec@1 51.172 (53.986)	
Total train loss: 1.6920

Train time: 19.749568939208984
 * Prec@1 52.030 Prec@5 80.770 Loss 1.8467
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 24.078357219696045

Epoch: [13][38/196]	LR: 0.001	Loss 1.5908 (1.7001)	Prec@1 57.422 (53.576)	
Epoch: [13][77/196]	LR: 0.001	Loss 1.6035 (1.6875)	Prec@1 53.516 (54.127)	
Epoch: [13][116/196]	LR: 0.001	Loss 1.6855 (1.6906)	Prec@1 56.250 (54.026)	
Epoch: [13][155/196]	LR: 0.001	Loss 1.6602 (1.6882)	Prec@1 53.516 (54.014)	
Epoch: [13][194/196]	LR: 0.001	Loss 1.8057 (1.6860)	Prec@1 52.734 (54.143)	
Total train loss: 1.6861

Train time: 18.980588674545288
 * Prec@1 52.210 Prec@5 80.760 Loss 1.8428
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 23.719311475753784

Epoch: [14][38/196]	LR: 0.001	Loss 1.6709 (1.6829)	Prec@1 53.906 (54.237)	
Epoch: [14][77/196]	LR: 0.001	Loss 1.6836 (1.6833)	Prec@1 52.734 (54.077)	
Epoch: [14][116/196]	LR: 0.001	Loss 1.7578 (1.6887)	Prec@1 50.781 (53.933)	
Epoch: [14][155/196]	LR: 0.001	Loss 1.7412 (1.6835)	Prec@1 50.781 (54.164)	
Epoch: [14][194/196]	LR: 0.001	Loss 1.4980 (1.6774)	Prec@1 57.812 (54.289)	
Total train loss: 1.6773

Train time: 19.548999309539795
 * Prec@1 52.150 Prec@5 80.700 Loss 1.8320
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 24.422892570495605

Epoch: [15][38/196]	LR: 0.001	Loss 1.9717 (1.6907)	Prec@1 49.219 (54.567)	
Epoch: [15][77/196]	LR: 0.001	Loss 1.8604 (1.6919)	Prec@1 50.000 (54.307)	
Epoch: [15][116/196]	LR: 0.001	Loss 1.5049 (1.6770)	Prec@1 58.594 (54.544)	
Epoch: [15][155/196]	LR: 0.001	Loss 1.6416 (1.6722)	Prec@1 54.297 (54.617)	
Epoch: [15][194/196]	LR: 0.001	Loss 1.5869 (1.6693)	Prec@1 57.812 (54.601)	
Total train loss: 1.6692

Train time: 22.033058881759644
 * Prec@1 52.890 Prec@5 81.360 Loss 1.8145
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 26.748270750045776

Epoch: [16][38/196]	LR: 0.0001	Loss 1.7119 (1.6573)	Prec@1 53.125 (55.118)	
Epoch: [16][77/196]	LR: 0.0001	Loss 1.6309 (1.6442)	Prec@1 55.469 (55.003)	
Epoch: [16][116/196]	LR: 0.0001	Loss 1.6377 (1.6493)	Prec@1 56.641 (54.955)	
Epoch: [16][155/196]	LR: 0.0001	Loss 1.9248 (1.6553)	Prec@1 46.094 (54.718)	
Epoch: [16][194/196]	LR: 0.0001	Loss 1.8086 (1.6588)	Prec@1 51.172 (54.601)	
Total train loss: 1.6590

Train time: 19.730626106262207
 * Prec@1 52.650 Prec@5 81.340 Loss 1.8164
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 23.817491054534912

Epoch: [17][38/196]	LR: 0.0001	Loss 1.5928 (1.6643)	Prec@1 55.078 (54.437)	
Epoch: [17][77/196]	LR: 0.0001	Loss 1.6963 (1.6608)	Prec@1 53.906 (54.467)	
Epoch: [17][116/196]	LR: 0.0001	Loss 1.6562 (1.6609)	Prec@1 53.906 (54.501)	
Epoch: [17][155/196]	LR: 0.0001	Loss 1.6465 (1.6574)	Prec@1 53.125 (54.675)	
Epoch: [17][194/196]	LR: 0.0001	Loss 1.7070 (1.6592)	Prec@1 53.906 (54.679)	
Total train loss: 1.6590

Train time: 17.769985675811768
 * Prec@1 52.770 Prec@5 81.340 Loss 1.8125
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 24.32343578338623

Epoch: [18][38/196]	LR: 0.0001	Loss 1.4766 (1.6680)	Prec@1 60.547 (54.387)	
Epoch: [18][77/196]	LR: 0.0001	Loss 1.6318 (1.6576)	Prec@1 52.734 (54.743)	
Epoch: [18][116/196]	LR: 0.0001	Loss 1.8291 (1.6590)	Prec@1 49.609 (54.597)	
Epoch: [18][155/196]	LR: 0.0001	Loss 1.6250 (1.6594)	Prec@1 57.031 (54.567)	
Epoch: [18][194/196]	LR: 0.0001	Loss 1.7832 (1.6585)	Prec@1 52.344 (54.619)	
Total train loss: 1.6586

Train time: 17.936689138412476
 * Prec@1 52.730 Prec@5 81.160 Loss 1.8164
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 21.82933735847473

Epoch: [19][38/196]	LR: 0.0001	Loss 1.6650 (1.6546)	Prec@1 55.078 (54.557)	
Epoch: [19][77/196]	LR: 0.0001	Loss 1.5615 (1.6499)	Prec@1 58.594 (54.768)	
Epoch: [19][116/196]	LR: 0.0001	Loss 1.7676 (1.6516)	Prec@1 54.297 (54.955)	
Epoch: [19][155/196]	LR: 0.0001	Loss 1.4590 (1.6542)	Prec@1 58.984 (54.715)	
Epoch: [19][194/196]	LR: 0.0001	Loss 1.7158 (1.6561)	Prec@1 55.078 (54.718)	
Total train loss: 1.6559

Train time: 19.06462836265564
 * Prec@1 52.810 Prec@5 81.120 Loss 1.8125
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 23.186697244644165

Epoch: [20][38/196]	LR: 0.0001	Loss 1.6855 (1.6496)	Prec@1 49.219 (54.848)	
Epoch: [20][77/196]	LR: 0.0001	Loss 1.7568 (1.6447)	Prec@1 53.516 (54.943)	
Epoch: [20][116/196]	LR: 0.0001	Loss 1.6943 (1.6588)	Prec@1 50.000 (54.667)	
Epoch: [20][155/196]	LR: 0.0001	Loss 1.5791 (1.6564)	Prec@1 53.516 (54.580)	
Epoch: [20][194/196]	LR: 0.0001	Loss 1.7266 (1.6582)	Prec@1 51.172 (54.581)	
Total train loss: 1.6586

Train time: 19.17974615097046
 * Prec@1 52.630 Prec@5 81.150 Loss 1.8164
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 25.212489128112793

Epoch: [21][38/196]	LR: 0.0001	Loss 1.6758 (1.6875)	Prec@1 55.859 (54.257)	
Epoch: [21][77/196]	LR: 0.0001	Loss 1.8662 (1.6680)	Prec@1 48.438 (54.783)	
Epoch: [21][116/196]	LR: 0.0001	Loss 1.6475 (1.6605)	Prec@1 54.688 (54.784)	
Epoch: [21][155/196]	LR: 0.0001	Loss 1.7295 (1.6632)	Prec@1 53.906 (54.605)	
Epoch: [21][194/196]	LR: 0.0001	Loss 1.5635 (1.6601)	Prec@1 57.031 (54.734)	
Total train loss: 1.6603

Train time: 19.81541085243225
 * Prec@1 52.750 Prec@5 81.150 Loss 1.8164
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 25.14521837234497

Epoch: [22][38/196]	LR: 0.0001	Loss 1.8379 (1.6477)	Prec@1 50.781 (55.028)	
Epoch: [22][77/196]	LR: 0.0001	Loss 1.8242 (1.6575)	Prec@1 53.125 (54.407)	
Epoch: [22][116/196]	LR: 0.0001	Loss 1.6670 (1.6527)	Prec@1 51.172 (54.667)	
Epoch: [22][155/196]	LR: 0.0001	Loss 1.7529 (1.6542)	Prec@1 50.781 (54.655)	
Epoch: [22][194/196]	LR: 0.0001	Loss 1.6885 (1.6576)	Prec@1 52.344 (54.629)	
Total train loss: 1.6575

Train time: 19.245835781097412
 * Prec@1 52.520 Prec@5 81.130 Loss 1.8164
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 23.505423069000244

Epoch: [23][38/196]	LR: 0.0001	Loss 1.5996 (1.6326)	Prec@1 55.469 (55.879)	
Epoch: [23][77/196]	LR: 0.0001	Loss 1.6465 (1.6527)	Prec@1 56.250 (55.263)	
Epoch: [23][116/196]	LR: 0.0001	Loss 1.5332 (1.6608)	Prec@1 56.641 (54.828)	
Epoch: [23][155/196]	LR: 0.0001	Loss 1.5957 (1.6618)	Prec@1 56.250 (54.868)	
Epoch: [23][194/196]	LR: 0.0001	Loss 1.5127 (1.6576)	Prec@1 55.859 (54.842)	
Total train loss: 1.6574

Train time: 19.44329285621643
 * Prec@1 52.680 Prec@5 81.180 Loss 1.8125
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 25.48637104034424

Epoch: [24][38/196]	LR: 1e-05	Loss 1.6035 (1.6391)	Prec@1 59.766 (55.369)	
Epoch: [24][77/196]	LR: 1e-05	Loss 1.7324 (1.6514)	Prec@1 52.344 (55.013)	
Epoch: [24][116/196]	LR: 1e-05	Loss 1.7490 (1.6533)	Prec@1 50.391 (54.894)	
Epoch: [24][155/196]	LR: 1e-05	Loss 1.6807 (1.6559)	Prec@1 51.562 (54.738)	
Epoch: [24][194/196]	LR: 1e-05	Loss 1.6182 (1.6573)	Prec@1 53.125 (54.643)	
Total train loss: 1.6573

Train time: 18.962154626846313
 * Prec@1 52.270 Prec@5 81.060 Loss 1.8223
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 22.75191855430603

Epoch: [25][38/196]	LR: 1e-05	Loss 1.4844 (1.6534)	Prec@1 59.766 (55.008)	
Epoch: [25][77/196]	LR: 1e-05	Loss 1.7656 (1.6591)	Prec@1 48.828 (54.848)	
Epoch: [25][116/196]	LR: 1e-05	Loss 1.6182 (1.6554)	Prec@1 51.953 (54.818)	
Epoch: [25][155/196]	LR: 1e-05	Loss 1.8789 (1.6546)	Prec@1 51.562 (54.758)	
Epoch: [25][194/196]	LR: 1e-05	Loss 1.6709 (1.6589)	Prec@1 57.422 (54.669)	
Total train loss: 1.6591

Train time: 19.46920680999756
 * Prec@1 52.430 Prec@5 81.000 Loss 1.8174
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 22.6145441532135

Epoch: [26][38/196]	LR: 1e-05	Loss 1.8730 (1.6587)	Prec@1 48.047 (54.908)	
Epoch: [26][77/196]	LR: 1e-05	Loss 1.7334 (1.6505)	Prec@1 52.734 (54.928)	
Epoch: [26][116/196]	LR: 1e-05	Loss 1.5400 (1.6543)	Prec@1 57.031 (54.711)	
Epoch: [26][155/196]	LR: 1e-05	Loss 1.6816 (1.6534)	Prec@1 52.344 (54.793)	
Epoch: [26][194/196]	LR: 1e-05	Loss 1.4971 (1.6565)	Prec@1 58.203 (54.685)	
Total train loss: 1.6569

Train time: 20.45533537864685
 * Prec@1 52.550 Prec@5 81.300 Loss 1.8193
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 26.827243089675903

Epoch: [27][38/196]	LR: 1e-05	Loss 1.5469 (1.6345)	Prec@1 59.766 (55.929)	
Epoch: [27][77/196]	LR: 1e-05	Loss 1.5645 (1.6381)	Prec@1 57.812 (55.324)	
Epoch: [27][116/196]	LR: 1e-05	Loss 1.7920 (1.6427)	Prec@1 52.344 (55.075)	
Epoch: [27][155/196]	LR: 1e-05	Loss 1.6475 (1.6504)	Prec@1 56.641 (55.028)	
Epoch: [27][194/196]	LR: 1e-05	Loss 1.5723 (1.6570)	Prec@1 56.250 (54.692)	
Total train loss: 1.6573

Train time: 19.492883920669556
 * Prec@1 52.530 Prec@5 81.060 Loss 1.8164
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 23.441109895706177

Epoch: [28][38/196]	LR: 1e-05	Loss 1.7871 (1.6639)	Prec@1 52.344 (54.918)	
Epoch: [28][77/196]	LR: 1e-05	Loss 1.6396 (1.6619)	Prec@1 51.953 (54.652)	
Epoch: [28][116/196]	LR: 1e-05	Loss 1.6240 (1.6559)	Prec@1 54.297 (54.791)	
Epoch: [28][155/196]	LR: 1e-05	Loss 1.7656 (1.6571)	Prec@1 49.219 (54.718)	
Epoch: [28][194/196]	LR: 1e-05	Loss 1.7900 (1.6568)	Prec@1 49.219 (54.722)	
Total train loss: 1.6572

Train time: 19.826237440109253
 * Prec@1 52.720 Prec@5 81.280 Loss 1.8145
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 24.264437198638916

Epoch: [29][38/196]	LR: 1e-05	Loss 1.6270 (1.6691)	Prec@1 54.688 (54.437)	
Epoch: [29][77/196]	LR: 1e-05	Loss 1.7568 (1.6720)	Prec@1 50.391 (54.667)	
Epoch: [29][116/196]	LR: 1e-05	Loss 1.7002 (1.6672)	Prec@1 55.078 (54.654)	
Epoch: [29][155/196]	LR: 1e-05	Loss 1.5684 (1.6577)	Prec@1 56.250 (54.898)	
Epoch: [29][194/196]	LR: 1e-05	Loss 1.7051 (1.6601)	Prec@1 55.078 (54.786)	
Total train loss: 1.6597

Train time: 19.66720938682556
 * Prec@1 52.500 Prec@5 81.220 Loss 1.8164
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 23.71659803390503

Epoch: [30][38/196]	LR: 1e-05	Loss 1.5703 (1.6728)	Prec@1 56.641 (54.046)	
Epoch: [30][77/196]	LR: 1e-05	Loss 1.6670 (1.6609)	Prec@1 56.250 (54.607)	
Epoch: [30][116/196]	LR: 1e-05	Loss 1.7021 (1.6523)	Prec@1 52.734 (54.624)	
Epoch: [30][155/196]	LR: 1e-05	Loss 1.6133 (1.6508)	Prec@1 58.594 (54.773)	
Epoch: [30][194/196]	LR: 1e-05	Loss 1.5840 (1.6561)	Prec@1 55.469 (54.677)	
Total train loss: 1.6558

Train time: 19.68579936027527
 * Prec@1 52.600 Prec@5 81.000 Loss 1.8193
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 24.204877376556396

Epoch: [31][38/196]	LR: 1e-05	Loss 1.5312 (1.6190)	Prec@1 60.156 (55.709)	
Epoch: [31][77/196]	LR: 1e-05	Loss 1.6133 (1.6359)	Prec@1 54.297 (55.173)	
Epoch: [31][116/196]	LR: 1e-05	Loss 1.7949 (1.6461)	Prec@1 52.734 (55.162)	
Epoch: [31][155/196]	LR: 1e-05	Loss 1.6562 (1.6453)	Prec@1 52.344 (55.126)	
Epoch: [31][194/196]	LR: 1e-05	Loss 1.5674 (1.6553)	Prec@1 55.859 (54.912)	
Total train loss: 1.6556

Train time: 19.340487718582153
 * Prec@1 52.390 Prec@5 81.110 Loss 1.8203
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 24.54088854789734

Epoch: [32][38/196]	LR: 1.0000000000000002e-06	Loss 1.7305 (1.6446)	Prec@1 51.172 (55.188)	
Epoch: [32][77/196]	LR: 1.0000000000000002e-06	Loss 1.5537 (1.6605)	Prec@1 56.250 (54.572)	
Epoch: [32][116/196]	LR: 1.0000000000000002e-06	Loss 1.6172 (1.6563)	Prec@1 57.031 (54.587)	
Epoch: [32][155/196]	LR: 1.0000000000000002e-06	Loss 1.7881 (1.6600)	Prec@1 48.828 (54.547)	
Epoch: [32][194/196]	LR: 1.0000000000000002e-06	Loss 1.6689 (1.6584)	Prec@1 52.344 (54.716)	
Total train loss: 1.6583

Train time: 20.317472219467163
 * Prec@1 52.600 Prec@5 81.210 Loss 1.8145
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 23.954752206802368

Epoch: [33][38/196]	LR: 1.0000000000000002e-06	Loss 1.5029 (1.6594)	Prec@1 57.812 (55.018)	
Epoch: [33][77/196]	LR: 1.0000000000000002e-06	Loss 1.6582 (1.6571)	Prec@1 55.859 (55.003)	
Epoch: [33][116/196]	LR: 1.0000000000000002e-06	Loss 1.6787 (1.6636)	Prec@1 53.516 (54.848)	
Epoch: [33][155/196]	LR: 1.0000000000000002e-06	Loss 1.6074 (1.6550)	Prec@1 55.078 (54.920)	
Epoch: [33][194/196]	LR: 1.0000000000000002e-06	Loss 1.5176 (1.6592)	Prec@1 59.375 (54.748)	
Total train loss: 1.6593

Train time: 19.414851665496826
 * Prec@1 52.600 Prec@5 81.210 Loss 1.8174
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 24.558833837509155

Epoch: [34][38/196]	LR: 1.0000000000000002e-06	Loss 1.5576 (1.6568)	Prec@1 57.422 (54.417)	
Epoch: [34][77/196]	LR: 1.0000000000000002e-06	Loss 1.5312 (1.6547)	Prec@1 57.812 (54.527)	
Epoch: [34][116/196]	LR: 1.0000000000000002e-06	Loss 1.7559 (1.6564)	Prec@1 50.781 (54.647)	
Epoch: [34][155/196]	LR: 1.0000000000000002e-06	Loss 1.8193 (1.6618)	Prec@1 48.438 (54.585)	
Epoch: [34][194/196]	LR: 1.0000000000000002e-06	Loss 1.6631 (1.6580)	Prec@1 52.344 (54.619)	
Total train loss: 1.6577

Train time: 20.63360333442688
 * Prec@1 52.980 Prec@5 81.110 Loss 1.8125
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 23.772326469421387

Epoch: [35][38/196]	LR: 1.0000000000000002e-06	Loss 1.7041 (1.6522)	Prec@1 55.469 (54.627)	
Epoch: [35][77/196]	LR: 1.0000000000000002e-06	Loss 1.8047 (1.6712)	Prec@1 46.875 (54.402)	
Epoch: [35][116/196]	LR: 1.0000000000000002e-06	Loss 1.7480 (1.6663)	Prec@1 51.953 (54.577)	
Epoch: [35][155/196]	LR: 1.0000000000000002e-06	Loss 1.7461 (1.6573)	Prec@1 51.172 (54.768)	
Epoch: [35][194/196]	LR: 1.0000000000000002e-06	Loss 1.5312 (1.6580)	Prec@1 55.469 (54.758)	
Total train loss: 1.6577

Train time: 18.36167812347412
 * Prec@1 52.650 Prec@5 81.070 Loss 1.8174
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 22.55618929862976

Epoch: [36][38/196]	LR: 1.0000000000000002e-06	Loss 1.7891 (1.6825)	Prec@1 53.516 (54.367)	
Epoch: [36][77/196]	LR: 1.0000000000000002e-06	Loss 1.7803 (1.6670)	Prec@1 53.516 (54.512)	
Epoch: [36][116/196]	LR: 1.0000000000000002e-06	Loss 1.6719 (1.6536)	Prec@1 54.688 (54.774)	
Epoch: [36][155/196]	LR: 1.0000000000000002e-06	Loss 1.5400 (1.6580)	Prec@1 60.938 (54.690)	
Epoch: [36][194/196]	LR: 1.0000000000000002e-06	Loss 1.6348 (1.6590)	Prec@1 56.641 (54.679)	
Total train loss: 1.6588

Train time: 19.454256534576416
 * Prec@1 52.610 Prec@5 81.020 Loss 1.8174
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 24.960897207260132

Epoch: [37][38/196]	LR: 1.0000000000000002e-06	Loss 1.7471 (1.6563)	Prec@1 55.078 (54.988)	
Epoch: [37][77/196]	LR: 1.0000000000000002e-06	Loss 1.6230 (1.6537)	Prec@1 54.688 (55.028)	
Epoch: [37][116/196]	LR: 1.0000000000000002e-06	Loss 1.6221 (1.6565)	Prec@1 55.078 (54.851)	
Epoch: [37][155/196]	LR: 1.0000000000000002e-06	Loss 1.4814 (1.6545)	Prec@1 60.156 (54.920)	
Epoch: [37][194/196]	LR: 1.0000000000000002e-06	Loss 1.8428 (1.6581)	Prec@1 51.953 (54.722)	
Total train loss: 1.6584

Train time: 19.96468734741211
 * Prec@1 52.860 Prec@5 81.200 Loss 1.8203
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 23.358027696609497

Epoch: [38][38/196]	LR: 1.0000000000000002e-06	Loss 1.6816 (1.6544)	Prec@1 53.125 (55.449)	
Epoch: [38][77/196]	LR: 1.0000000000000002e-06	Loss 1.7471 (1.6500)	Prec@1 51.172 (55.243)	
Epoch: [38][116/196]	LR: 1.0000000000000002e-06	Loss 1.6953 (1.6564)	Prec@1 53.516 (54.821)	
Epoch: [38][155/196]	LR: 1.0000000000000002e-06	Loss 1.7139 (1.6539)	Prec@1 52.344 (54.758)	
Epoch: [38][194/196]	LR: 1.0000000000000002e-06	Loss 1.8105 (1.6557)	Prec@1 51.562 (54.685)	
Total train loss: 1.6565

Train time: 18.556156158447266
 * Prec@1 52.720 Prec@5 81.220 Loss 1.8164
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 23.859399795532227

Epoch: [39][38/196]	LR: 1.0000000000000002e-06	Loss 1.4844 (1.6451)	Prec@1 57.422 (54.968)	
Epoch: [39][77/196]	LR: 1.0000000000000002e-06	Loss 1.7031 (1.6592)	Prec@1 51.953 (54.723)	
Epoch: [39][116/196]	LR: 1.0000000000000002e-06	Loss 1.6709 (1.6608)	Prec@1 57.422 (54.771)	
Epoch: [39][155/196]	LR: 1.0000000000000002e-06	Loss 1.6416 (1.6624)	Prec@1 53.906 (54.723)	
Epoch: [39][194/196]	LR: 1.0000000000000002e-06	Loss 1.3652 (1.6588)	Prec@1 65.234 (54.766)	
Total train loss: 1.6585

Train time: 19.824156999588013
 * Prec@1 52.790 Prec@5 81.100 Loss 1.8145
Best acc: 61.680
--------------------------------------------------------------------------------
Test time: 24.211462020874023


      ==> Arguments:
          dataset: cifar100
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20fp_cifar100.pth.tar
          mode: rram
          workers: 8
          epochs: 40
          start_epoch: 0
          batch_size: 256
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          milestones: [8, 16, 24, 32]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 13
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20fp_cifar100.pth.tar ...
Original model accuracy: 69.5999984741211
ResNet_cifar(
  (conv14): QConv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu14): ReLU(inplace=True)
  (conv15): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): QConv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (relu15): ReLU(inplace=True)
  (conv16): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (conv18): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu18): ReLU(inplace=True)
  (conv19): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu19): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (bn20): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=64, out_features=100, bias=False)
  (bn21): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 41.080 Prec@5 68.330 Loss 2.7656
Pre-trained Prec@1 with 13 layers frozen: 41.07999801635742 	 Loss: 2.765625

Starting training on SRAM layers...
Epoch: [0][38/196]	LR: 0.01	Loss 1.0146 (0.8957)	Prec@1 68.750 (74.189)	
Epoch: [0][77/196]	LR: 0.01	Loss 1.3379 (1.0217)	Prec@1 64.844 (70.918)	
Epoch: [0][116/196]	LR: 0.01	Loss 1.6523 (1.1699)	Prec@1 55.469 (67.304)	
Epoch: [0][155/196]	LR: 0.01	Loss 1.4404 (1.2548)	Prec@1 58.594 (65.052)	
Epoch: [0][194/196]	LR: 0.01	Loss 1.3125 (1.2751)	Prec@1 66.797 (64.529)	
Total train loss: 1.2755

Train time: 161.03962230682373
 * Prec@1 47.810 Prec@5 76.160 Loss 2.1406
Best acc: 47.810
--------------------------------------------------------------------------------
Test time: 165.65062737464905

Epoch: [1][38/196]	LR: 0.01	Loss 1.2432 (1.3747)	Prec@1 67.188 (62.851)	
Epoch: [1][77/196]	LR: 0.01	Loss 1.2891 (1.3529)	Prec@1 65.625 (63.457)	
Epoch: [1][116/196]	LR: 0.01	Loss 1.3379 (1.3271)	Prec@1 61.328 (63.966)	
Epoch: [1][155/196]	LR: 0.01	Loss 1.1748 (1.3116)	Prec@1 68.750 (64.553)	
Epoch: [1][194/196]	LR: 0.01	Loss 1.3555 (1.3005)	Prec@1 66.016 (64.926)	
Total train loss: 1.3006

Train time: 18.90382218360901
 * Prec@1 50.990 Prec@5 79.010 Loss 2.0879
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 23.324363231658936

Epoch: [2][38/196]	LR: 0.01	Loss 1.3193 (1.2714)	Prec@1 63.281 (65.805)	
Epoch: [2][77/196]	LR: 0.01	Loss 1.4756 (1.3129)	Prec@1 61.719 (64.533)	
Epoch: [2][116/196]	LR: 0.01	Loss 1.3809 (1.3469)	Prec@1 62.500 (63.866)	
Epoch: [2][155/196]	LR: 0.01	Loss 1.3906 (1.3782)	Prec@1 60.938 (63.071)	
Epoch: [2][194/196]	LR: 0.01	Loss 1.3818 (1.3971)	Prec@1 64.453 (62.694)	
Total train loss: 1.3975

Train time: 19.87862777709961
 * Prec@1 45.150 Prec@5 74.720 Loss 2.1855
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 24.290013313293457

Epoch: [3][38/196]	LR: 0.01	Loss 1.4629 (1.4951)	Prec@1 60.547 (60.527)	
Epoch: [3][77/196]	LR: 0.01	Loss 1.4443 (1.5293)	Prec@1 61.719 (59.345)	
Epoch: [3][116/196]	LR: 0.01	Loss 1.6201 (1.5425)	Prec@1 58.203 (59.418)	
Epoch: [3][155/196]	LR: 0.01	Loss 1.6396 (1.5654)	Prec@1 57.422 (59.107)	
Epoch: [3][194/196]	LR: 0.01	Loss 1.7988 (1.5926)	Prec@1 50.000 (58.592)	
Total train loss: 1.5930

Train time: 19.29057240486145
 * Prec@1 42.060 Prec@5 72.500 Loss 2.3105
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 24.48688244819641

Epoch: [4][38/196]	LR: 0.01	Loss 1.9551 (1.7761)	Prec@1 51.562 (53.936)	
Epoch: [4][77/196]	LR: 0.01	Loss 1.7373 (1.7576)	Prec@1 58.984 (54.502)	
Epoch: [4][116/196]	LR: 0.01	Loss 1.6875 (1.7678)	Prec@1 55.469 (54.467)	
Epoch: [4][155/196]	LR: 0.01	Loss 1.9248 (1.7714)	Prec@1 51.172 (54.412)	
Epoch: [4][194/196]	LR: 0.01	Loss 1.8574 (1.7860)	Prec@1 50.781 (54.048)	
Total train loss: 1.7857

Train time: 20.522554636001587
 * Prec@1 50.020 Prec@5 80.060 Loss 1.9004
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 24.61089015007019

Epoch: [5][38/196]	LR: 0.01	Loss 1.8848 (1.8469)	Prec@1 51.562 (52.554)	
Epoch: [5][77/196]	LR: 0.01	Loss 1.8594 (1.8758)	Prec@1 51.562 (51.788)	
Epoch: [5][116/196]	LR: 0.01	Loss 1.9297 (1.8817)	Prec@1 51.172 (51.539)	
Epoch: [5][155/196]	LR: 0.01	Loss 1.8271 (1.8872)	Prec@1 51.953 (51.547)	
Epoch: [5][194/196]	LR: 0.01	Loss 2.0117 (1.8954)	Prec@1 44.531 (51.370)	
Total train loss: 1.8956

Train time: 20.840696573257446
 * Prec@1 41.920 Prec@5 72.300 Loss 2.2832
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 24.21691632270813

Epoch: [6][38/196]	LR: 0.01	Loss 2.0977 (1.9988)	Prec@1 47.656 (49.119)	
Epoch: [6][77/196]	LR: 0.01	Loss 2.0859 (2.0440)	Prec@1 45.312 (47.927)	
Epoch: [6][116/196]	LR: 0.01	Loss 2.3457 (2.1131)	Prec@1 36.719 (46.538)	
Epoch: [6][155/196]	LR: 0.01	Loss 2.1777 (2.1408)	Prec@1 43.359 (45.460)	
Epoch: [6][194/196]	LR: 0.01	Loss 2.0781 (2.1247)	Prec@1 45.703 (45.605)	
Total train loss: 2.1246

Train time: 20.480297803878784
 * Prec@1 44.350 Prec@5 75.140 Loss 2.1543
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 25.42671275138855

Epoch: [7][38/196]	LR: 0.01	Loss 2.0000 (2.0734)	Prec@1 48.828 (46.224)	
Epoch: [7][77/196]	LR: 0.01	Loss 2.2695 (2.1402)	Prec@1 37.500 (44.656)	
Epoch: [7][116/196]	LR: 0.01	Loss 2.1602 (2.1725)	Prec@1 44.141 (43.957)	
Epoch: [7][155/196]	LR: 0.01	Loss 2.3711 (2.2036)	Prec@1 32.812 (43.152)	
Epoch: [7][194/196]	LR: 0.01	Loss 2.2207 (2.2195)	Prec@1 40.625 (42.867)	
Total train loss: 2.2199

Train time: 21.111027717590332
 * Prec@1 36.720 Prec@5 68.570 Loss 2.5000
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 24.460925817489624

Epoch: [8][38/196]	LR: 0.001	Loss 2.2793 (2.2593)	Prec@1 44.141 (42.137)	
Epoch: [8][77/196]	LR: 0.001	Loss 2.2578 (2.2633)	Prec@1 44.141 (42.127)	
Epoch: [8][116/196]	LR: 0.001	Loss 2.2715 (2.2667)	Prec@1 45.703 (42.067)	
Epoch: [8][155/196]	LR: 0.001	Loss 2.2559 (2.2716)	Prec@1 44.531 (41.847)	
Epoch: [8][194/196]	LR: 0.001	Loss 2.2969 (2.2691)	Prec@1 40.625 (41.863)	
Total train loss: 2.2692

Train time: 19.804842710494995
 * Prec@1 41.120 Prec@5 72.930 Loss 2.2891
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 23.61612057685852

Epoch: [9][38/196]	LR: 0.001	Loss 2.2012 (2.2600)	Prec@1 42.969 (41.587)	
Epoch: [9][77/196]	LR: 0.001	Loss 2.1641 (2.2595)	Prec@1 47.656 (41.827)	
Epoch: [9][116/196]	LR: 0.001	Loss 2.0938 (2.2585)	Prec@1 48.828 (41.954)	
Epoch: [9][155/196]	LR: 0.001	Loss 2.1699 (2.2568)	Prec@1 42.969 (42.077)	
Epoch: [9][194/196]	LR: 0.001	Loss 2.1406 (2.2556)	Prec@1 44.922 (42.183)	
Total train loss: 2.2559

Train time: 19.383682012557983
 * Prec@1 41.410 Prec@5 73.020 Loss 2.2871
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 23.484636545181274

Epoch: [10][38/196]	LR: 0.001	Loss 2.3359 (2.2519)	Prec@1 42.578 (42.428)	
Epoch: [10][77/196]	LR: 0.001	Loss 2.3848 (2.2580)	Prec@1 37.891 (42.478)	
Epoch: [10][116/196]	LR: 0.001	Loss 2.0977 (2.2503)	Prec@1 44.531 (42.551)	
Epoch: [10][155/196]	LR: 0.001	Loss 2.1172 (2.2500)	Prec@1 45.703 (42.435)	
Epoch: [10][194/196]	LR: 0.001	Loss 2.2852 (2.2512)	Prec@1 41.016 (42.362)	
Total train loss: 2.2515

Train time: 18.753679513931274
 * Prec@1 41.760 Prec@5 73.360 Loss 2.2754
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 22.361958742141724

Epoch: [11][38/196]	LR: 0.001	Loss 2.2285 (2.2319)	Prec@1 43.359 (42.989)	
Epoch: [11][77/196]	LR: 0.001	Loss 2.1621 (2.2468)	Prec@1 45.312 (42.538)	
Epoch: [11][116/196]	LR: 0.001	Loss 2.4102 (2.2526)	Prec@1 44.531 (42.274)	
Epoch: [11][155/196]	LR: 0.001	Loss 2.4004 (2.2454)	Prec@1 39.062 (42.488)	
Epoch: [11][194/196]	LR: 0.001	Loss 2.2148 (2.2490)	Prec@1 44.922 (42.384)	
Total train loss: 2.2492

Train time: 18.35605502128601
 * Prec@1 41.470 Prec@5 73.250 Loss 2.2852
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 22.51786518096924

Epoch: [12][38/196]	LR: 0.001	Loss 2.1289 (2.2467)	Prec@1 46.094 (42.268)	
Epoch: [12][77/196]	LR: 0.001	Loss 2.1641 (2.2429)	Prec@1 44.141 (42.333)	
Epoch: [12][116/196]	LR: 0.001	Loss 2.2148 (2.2428)	Prec@1 42.578 (42.278)	
Epoch: [12][155/196]	LR: 0.001	Loss 2.3184 (2.2438)	Prec@1 43.750 (42.403)	
Epoch: [12][194/196]	LR: 0.001	Loss 2.2129 (2.2469)	Prec@1 43.750 (42.488)	
Total train loss: 2.2470

Train time: 16.75377869606018
 * Prec@1 41.580 Prec@5 73.480 Loss 2.2695
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 21.05982494354248

Epoch: [13][38/196]	LR: 0.001	Loss 2.1934 (2.2575)	Prec@1 42.969 (41.496)	
Epoch: [13][77/196]	LR: 0.001	Loss 2.2539 (2.2465)	Prec@1 44.531 (42.092)	
Epoch: [13][116/196]	LR: 0.001	Loss 2.2266 (2.2476)	Prec@1 43.359 (42.301)	
Epoch: [13][155/196]	LR: 0.001	Loss 2.3027 (2.2438)	Prec@1 39.844 (42.305)	
Epoch: [13][194/196]	LR: 0.001	Loss 2.1367 (2.2420)	Prec@1 45.703 (42.482)	
Total train loss: 2.2425

Train time: 20.084665060043335
 * Prec@1 41.580 Prec@5 73.520 Loss 2.2637
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 24.37587881088257

Epoch: [14][38/196]	LR: 0.001	Loss 2.0684 (2.2630)	Prec@1 47.656 (41.907)	
Epoch: [14][77/196]	LR: 0.001	Loss 2.2324 (2.2601)	Prec@1 45.703 (42.218)	
Epoch: [14][116/196]	LR: 0.001	Loss 2.1406 (2.2484)	Prec@1 42.969 (42.411)	
Epoch: [14][155/196]	LR: 0.001	Loss 2.3887 (2.2408)	Prec@1 37.891 (42.668)	
Epoch: [14][194/196]	LR: 0.001	Loss 2.0996 (2.2384)	Prec@1 46.094 (42.700)	
Total train loss: 2.2389

Train time: 19.81497597694397
 * Prec@1 41.430 Prec@5 73.490 Loss 2.2676
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 24.423696041107178

Epoch: [15][38/196]	LR: 0.001	Loss 2.3477 (2.2398)	Prec@1 40.234 (42.949)	
Epoch: [15][77/196]	LR: 0.001	Loss 2.1621 (2.2429)	Prec@1 45.703 (42.758)	
Epoch: [15][116/196]	LR: 0.001	Loss 2.2441 (2.2465)	Prec@1 42.578 (42.625)	
Epoch: [15][155/196]	LR: 0.001	Loss 2.1035 (2.2410)	Prec@1 42.188 (42.636)	
Epoch: [15][194/196]	LR: 0.001	Loss 2.2129 (2.2389)	Prec@1 43.750 (42.632)	
Total train loss: 2.2391

Train time: 19.01063632965088
 * Prec@1 41.720 Prec@5 73.400 Loss 2.2695
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 25.232028484344482

Epoch: [16][38/196]	LR: 0.0001	Loss 2.3398 (2.2354)	Prec@1 39.844 (42.608)	
Epoch: [16][77/196]	LR: 0.0001	Loss 2.3613 (2.2397)	Prec@1 41.016 (42.638)	
Epoch: [16][116/196]	LR: 0.0001	Loss 2.1816 (2.2297)	Prec@1 41.406 (42.842)	
Epoch: [16][155/196]	LR: 0.0001	Loss 2.2715 (2.2292)	Prec@1 37.891 (42.841)	
Epoch: [16][194/196]	LR: 0.0001	Loss 2.1523 (2.2351)	Prec@1 41.406 (42.660)	
Total train loss: 2.2349

Train time: 18.601107120513916
 * Prec@1 41.650 Prec@5 73.570 Loss 2.2598
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 23.21915626525879

Epoch: [17][38/196]	LR: 0.0001	Loss 2.2480 (2.2552)	Prec@1 44.531 (42.358)	
Epoch: [17][77/196]	LR: 0.0001	Loss 2.0879 (2.2427)	Prec@1 45.703 (42.438)	
Epoch: [17][116/196]	LR: 0.0001	Loss 2.4570 (2.2434)	Prec@1 32.812 (42.394)	
Epoch: [17][155/196]	LR: 0.0001	Loss 2.3379 (2.2377)	Prec@1 39.844 (42.576)	
Epoch: [17][194/196]	LR: 0.0001	Loss 2.2227 (2.2375)	Prec@1 39.453 (42.568)	
Total train loss: 2.2376

Train time: 18.40069007873535
 * Prec@1 41.870 Prec@5 73.570 Loss 2.2598
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 22.493703842163086

Epoch: [18][38/196]	LR: 0.0001	Loss 2.2598 (2.2363)	Prec@1 42.188 (42.658)	
Epoch: [18][77/196]	LR: 0.0001	Loss 2.2773 (2.2437)	Prec@1 35.938 (42.548)	
Epoch: [18][116/196]	LR: 0.0001	Loss 2.2051 (2.2424)	Prec@1 41.797 (42.394)	
Epoch: [18][155/196]	LR: 0.0001	Loss 2.3086 (2.2408)	Prec@1 42.188 (42.713)	
Epoch: [18][194/196]	LR: 0.0001	Loss 2.2148 (2.2364)	Prec@1 42.188 (42.792)	
Total train loss: 2.2370

Train time: 19.318919897079468
 * Prec@1 41.600 Prec@5 73.440 Loss 2.2676
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 24.336588621139526

Epoch: [19][38/196]	LR: 0.0001	Loss 1.9512 (2.2273)	Prec@1 52.344 (43.069)	
Epoch: [19][77/196]	LR: 0.0001	Loss 2.2930 (2.2383)	Prec@1 44.531 (42.538)	
Epoch: [19][116/196]	LR: 0.0001	Loss 2.1465 (2.2445)	Prec@1 45.703 (42.314)	
Epoch: [19][155/196]	LR: 0.0001	Loss 2.1426 (2.2408)	Prec@1 44.531 (42.330)	
Epoch: [19][194/196]	LR: 0.0001	Loss 2.1895 (2.2370)	Prec@1 42.188 (42.556)	
Total train loss: 2.2369

Train time: 18.1011905670166
 * Prec@1 41.370 Prec@5 73.460 Loss 2.2773
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 22.734570026397705

Epoch: [20][38/196]	LR: 0.0001	Loss 2.1035 (2.2228)	Prec@1 46.484 (43.309)	
Epoch: [20][77/196]	LR: 0.0001	Loss 2.2324 (2.2330)	Prec@1 42.578 (43.244)	
Epoch: [20][116/196]	LR: 0.0001	Loss 2.2832 (2.2374)	Prec@1 45.312 (43.189)	
Epoch: [20][155/196]	LR: 0.0001	Loss 2.2051 (2.2434)	Prec@1 42.188 (42.901)	
Epoch: [20][194/196]	LR: 0.0001	Loss 2.2012 (2.2362)	Prec@1 44.141 (42.871)	
Total train loss: 2.2363

Train time: 19.468141078948975
 * Prec@1 41.470 Prec@5 73.430 Loss 2.2695
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 23.882187128067017

Epoch: [21][38/196]	LR: 0.0001	Loss 2.3945 (2.2265)	Prec@1 39.453 (43.309)	
Epoch: [21][77/196]	LR: 0.0001	Loss 2.2344 (2.2316)	Prec@1 41.406 (42.678)	
Epoch: [21][116/196]	LR: 0.0001	Loss 2.3184 (2.2360)	Prec@1 35.938 (42.628)	
Epoch: [21][155/196]	LR: 0.0001	Loss 2.3184 (2.2368)	Prec@1 39.062 (42.586)	
Epoch: [21][194/196]	LR: 0.0001	Loss 2.1543 (2.2357)	Prec@1 41.797 (42.648)	
Total train loss: 2.2357

Train time: 19.338157653808594
 * Prec@1 41.540 Prec@5 73.340 Loss 2.2656
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 24.070060968399048

Epoch: [22][38/196]	LR: 0.0001	Loss 2.2910 (2.2430)	Prec@1 41.406 (42.268)	
Epoch: [22][77/196]	LR: 0.0001	Loss 2.1836 (2.2324)	Prec@1 45.703 (42.964)	
Epoch: [22][116/196]	LR: 0.0001	Loss 2.2441 (2.2292)	Prec@1 41.797 (42.935)	
Epoch: [22][155/196]	LR: 0.0001	Loss 2.1328 (2.2319)	Prec@1 47.266 (42.856)	
Epoch: [22][194/196]	LR: 0.0001	Loss 2.1875 (2.2373)	Prec@1 41.797 (42.688)	
Total train loss: 2.2372

Train time: 19.458994150161743
 * Prec@1 41.690 Prec@5 73.520 Loss 2.2637
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 23.722068548202515

Epoch: [23][38/196]	LR: 0.0001	Loss 2.2207 (2.2615)	Prec@1 42.578 (42.017)	
Epoch: [23][77/196]	LR: 0.0001	Loss 2.1758 (2.2502)	Prec@1 46.094 (42.082)	
Epoch: [23][116/196]	LR: 0.0001	Loss 2.4238 (2.2452)	Prec@1 35.547 (42.314)	
Epoch: [23][155/196]	LR: 0.0001	Loss 2.2676 (2.2392)	Prec@1 42.969 (42.495)	
Epoch: [23][194/196]	LR: 0.0001	Loss 2.1895 (2.2359)	Prec@1 45.703 (42.598)	
Total train loss: 2.2360

Train time: 18.773362398147583
 * Prec@1 41.410 Prec@5 73.460 Loss 2.2695
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 22.105526447296143

Epoch: [24][38/196]	LR: 1e-05	Loss 2.3613 (2.2332)	Prec@1 41.406 (42.578)	
Epoch: [24][77/196]	LR: 1e-05	Loss 2.2051 (2.2212)	Prec@1 42.578 (42.914)	
Epoch: [24][116/196]	LR: 1e-05	Loss 2.2754 (2.2286)	Prec@1 41.016 (42.849)	
Epoch: [24][155/196]	LR: 1e-05	Loss 2.2695 (2.2330)	Prec@1 42.188 (42.713)	
Epoch: [24][194/196]	LR: 1e-05	Loss 2.1426 (2.2340)	Prec@1 46.875 (42.768)	
Total train loss: 2.2342

Train time: 19.178399801254272
 * Prec@1 41.520 Prec@5 73.500 Loss 2.2656
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 24.270092725753784

Epoch: [25][38/196]	LR: 1e-05	Loss 2.1484 (2.2305)	Prec@1 46.484 (42.468)	
Epoch: [25][77/196]	LR: 1e-05	Loss 2.2969 (2.2352)	Prec@1 42.578 (42.613)	
Epoch: [25][116/196]	LR: 1e-05	Loss 2.2695 (2.2372)	Prec@1 44.141 (42.455)	
Epoch: [25][155/196]	LR: 1e-05	Loss 2.1133 (2.2322)	Prec@1 45.312 (42.593)	
Epoch: [25][194/196]	LR: 1e-05	Loss 2.1855 (2.2355)	Prec@1 41.797 (42.676)	
Total train loss: 2.2357

Train time: 18.99717664718628
 * Prec@1 41.540 Prec@5 73.310 Loss 2.2695
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 23.584000825881958

Epoch: [26][38/196]	LR: 1e-05	Loss 2.2441 (2.2333)	Prec@1 41.016 (42.368)	
Epoch: [26][77/196]	LR: 1e-05	Loss 2.3711 (2.2363)	Prec@1 39.062 (42.949)	
Epoch: [26][116/196]	LR: 1e-05	Loss 2.1074 (2.2363)	Prec@1 46.094 (42.829)	
Epoch: [26][155/196]	LR: 1e-05	Loss 2.3867 (2.2382)	Prec@1 38.281 (42.763)	
Epoch: [26][194/196]	LR: 1e-05	Loss 2.3359 (2.2356)	Prec@1 40.625 (42.774)	
Total train loss: 2.2354

Train time: 20.305999040603638
 * Prec@1 41.920 Prec@5 73.540 Loss 2.2617
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 24.413268089294434

Epoch: [27][38/196]	LR: 1e-05	Loss 2.2930 (2.2593)	Prec@1 38.672 (41.757)	
Epoch: [27][77/196]	LR: 1e-05	Loss 2.2109 (2.2520)	Prec@1 46.094 (42.027)	
Epoch: [27][116/196]	LR: 1e-05	Loss 2.2461 (2.2461)	Prec@1 44.531 (42.284)	
Epoch: [27][155/196]	LR: 1e-05	Loss 2.1289 (2.2376)	Prec@1 47.266 (42.591)	
Epoch: [27][194/196]	LR: 1e-05	Loss 2.3047 (2.2348)	Prec@1 40.625 (42.686)	
Total train loss: 2.2352

Train time: 19.17584753036499
 * Prec@1 41.590 Prec@5 73.350 Loss 2.2734
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 26.825971126556396

Epoch: [28][38/196]	LR: 1e-05	Loss 2.2188 (2.2178)	Prec@1 41.797 (42.808)	
Epoch: [28][77/196]	LR: 1e-05	Loss 2.2012 (2.2200)	Prec@1 43.750 (42.994)	
Epoch: [28][116/196]	LR: 1e-05	Loss 2.3027 (2.2348)	Prec@1 39.844 (42.581)	
Epoch: [28][155/196]	LR: 1e-05	Loss 2.1719 (2.2373)	Prec@1 45.703 (42.641)	
Epoch: [28][194/196]	LR: 1e-05	Loss 2.2012 (2.2381)	Prec@1 42.578 (42.690)	
Total train loss: 2.2379

Train time: 19.264744997024536
 * Prec@1 41.890 Prec@5 73.460 Loss 2.2617
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 23.344782829284668

Epoch: [29][38/196]	LR: 1e-05	Loss 2.1816 (2.2125)	Prec@1 46.484 (43.009)	
Epoch: [29][77/196]	LR: 1e-05	Loss 2.0703 (2.2286)	Prec@1 48.047 (43.089)	
Epoch: [29][116/196]	LR: 1e-05	Loss 2.1426 (2.2279)	Prec@1 44.141 (42.895)	
Epoch: [29][155/196]	LR: 1e-05	Loss 2.1309 (2.2347)	Prec@1 44.531 (42.641)	
Epoch: [29][194/196]	LR: 1e-05	Loss 2.1426 (2.2352)	Prec@1 44.531 (42.762)	
Total train loss: 2.2352

Train time: 18.168142557144165
 * Prec@1 41.620 Prec@5 73.380 Loss 2.2676
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 21.317081689834595

Epoch: [30][38/196]	LR: 1e-05	Loss 2.2227 (2.2383)	Prec@1 42.969 (42.308)	
Epoch: [30][77/196]	LR: 1e-05	Loss 2.3027 (2.2316)	Prec@1 41.797 (42.854)	
Epoch: [30][116/196]	LR: 1e-05	Loss 2.1016 (2.2292)	Prec@1 46.484 (43.019)	
Epoch: [30][155/196]	LR: 1e-05	Loss 2.2656 (2.2283)	Prec@1 43.359 (42.796)	
Epoch: [30][194/196]	LR: 1e-05	Loss 2.0957 (2.2338)	Prec@1 51.172 (42.648)	
Total train loss: 2.2341

Train time: 19.10824942588806
 * Prec@1 41.830 Prec@5 73.470 Loss 2.2656
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 23.306880474090576

Epoch: [31][38/196]	LR: 1e-05	Loss 2.2070 (2.2321)	Prec@1 44.141 (42.819)	
Epoch: [31][77/196]	LR: 1e-05	Loss 2.3164 (2.2345)	Prec@1 41.406 (42.598)	
Epoch: [31][116/196]	LR: 1e-05	Loss 2.4023 (2.2402)	Prec@1 36.719 (42.625)	
Epoch: [31][155/196]	LR: 1e-05	Loss 2.2129 (2.2389)	Prec@1 42.578 (42.586)	
Epoch: [31][194/196]	LR: 1e-05	Loss 2.2676 (2.2358)	Prec@1 42.578 (42.660)	
Total train loss: 2.2359

Train time: 17.837799310684204
 * Prec@1 41.560 Prec@5 73.520 Loss 2.2676
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 21.66329264640808

Epoch: [32][38/196]	LR: 1.0000000000000002e-06	Loss 2.2188 (2.2499)	Prec@1 42.188 (42.318)	
Epoch: [32][77/196]	LR: 1.0000000000000002e-06	Loss 2.1621 (2.2379)	Prec@1 46.484 (42.783)	
Epoch: [32][116/196]	LR: 1.0000000000000002e-06	Loss 2.2578 (2.2377)	Prec@1 44.141 (42.708)	
Epoch: [32][155/196]	LR: 1.0000000000000002e-06	Loss 2.3477 (2.2355)	Prec@1 42.578 (42.691)	
Epoch: [32][194/196]	LR: 1.0000000000000002e-06	Loss 2.2715 (2.2373)	Prec@1 42.578 (42.708)	
Total train loss: 2.2373

Train time: 19.291309595108032
 * Prec@1 41.440 Prec@5 73.380 Loss 2.2676
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 22.645676136016846

Epoch: [33][38/196]	LR: 1.0000000000000002e-06	Loss 2.2793 (2.2325)	Prec@1 41.797 (42.628)	
Epoch: [33][77/196]	LR: 1.0000000000000002e-06	Loss 2.1719 (2.2226)	Prec@1 45.703 (43.019)	
Epoch: [33][116/196]	LR: 1.0000000000000002e-06	Loss 2.1738 (2.2362)	Prec@1 42.969 (42.712)	
Epoch: [33][155/196]	LR: 1.0000000000000002e-06	Loss 2.2441 (2.2358)	Prec@1 39.453 (42.748)	
Epoch: [33][194/196]	LR: 1.0000000000000002e-06	Loss 2.3613 (2.2368)	Prec@1 40.234 (42.738)	
Total train loss: 2.2367

Train time: 19.292827367782593
 * Prec@1 41.540 Prec@5 73.340 Loss 2.2656
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 26.4757022857666

Epoch: [34][38/196]	LR: 1.0000000000000002e-06	Loss 2.1914 (2.2230)	Prec@1 43.750 (42.698)	
Epoch: [34][77/196]	LR: 1.0000000000000002e-06	Loss 2.3926 (2.2293)	Prec@1 35.938 (42.834)	
Epoch: [34][116/196]	LR: 1.0000000000000002e-06	Loss 2.2383 (2.2318)	Prec@1 46.484 (42.872)	
Epoch: [34][155/196]	LR: 1.0000000000000002e-06	Loss 2.4258 (2.2355)	Prec@1 41.406 (42.703)	
Epoch: [34][194/196]	LR: 1.0000000000000002e-06	Loss 2.1113 (2.2356)	Prec@1 45.703 (42.732)	
Total train loss: 2.2357

Train time: 19.89948058128357
 * Prec@1 41.570 Prec@5 73.430 Loss 2.2617
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 24.184930562973022

Epoch: [35][38/196]	LR: 1.0000000000000002e-06	Loss 2.1367 (2.2228)	Prec@1 41.406 (43.189)	
Epoch: [35][77/196]	LR: 1.0000000000000002e-06	Loss 2.2773 (2.2283)	Prec@1 41.016 (43.124)	
Epoch: [35][116/196]	LR: 1.0000000000000002e-06	Loss 2.3027 (2.2329)	Prec@1 40.625 (42.788)	
Epoch: [35][155/196]	LR: 1.0000000000000002e-06	Loss 2.1016 (2.2387)	Prec@1 48.438 (42.666)	
Epoch: [35][194/196]	LR: 1.0000000000000002e-06	Loss 2.4258 (2.2373)	Prec@1 38.281 (42.660)	
Total train loss: 2.2373

Train time: 18.730804920196533
 * Prec@1 41.560 Prec@5 73.460 Loss 2.2695
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 23.461008071899414

Epoch: [36][38/196]	LR: 1.0000000000000002e-06	Loss 2.2520 (2.2565)	Prec@1 44.922 (42.288)	
Epoch: [36][77/196]	LR: 1.0000000000000002e-06	Loss 2.2812 (2.2401)	Prec@1 36.328 (42.588)	
Epoch: [36][116/196]	LR: 1.0000000000000002e-06	Loss 2.2852 (2.2391)	Prec@1 41.016 (42.702)	
Epoch: [36][155/196]	LR: 1.0000000000000002e-06	Loss 2.1191 (2.2359)	Prec@1 46.094 (42.678)	
Epoch: [36][194/196]	LR: 1.0000000000000002e-06	Loss 2.2695 (2.2362)	Prec@1 41.016 (42.678)	
Total train loss: 2.2362

Train time: 18.879342794418335
 * Prec@1 41.710 Prec@5 73.510 Loss 2.2637
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 23.017727613449097

Epoch: [37][38/196]	LR: 1.0000000000000002e-06	Loss 2.3301 (2.2412)	Prec@1 38.672 (42.969)	
Epoch: [37][77/196]	LR: 1.0000000000000002e-06	Loss 2.3457 (2.2519)	Prec@1 42.188 (42.213)	
Epoch: [37][116/196]	LR: 1.0000000000000002e-06	Loss 2.2695 (2.2489)	Prec@1 36.719 (42.304)	
Epoch: [37][155/196]	LR: 1.0000000000000002e-06	Loss 2.1934 (2.2411)	Prec@1 40.625 (42.450)	
Epoch: [37][194/196]	LR: 1.0000000000000002e-06	Loss 2.1914 (2.2357)	Prec@1 43.750 (42.704)	
Total train loss: 2.2358

Train time: 20.507548332214355
 * Prec@1 41.390 Prec@5 73.360 Loss 2.2695
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 24.751590967178345

Epoch: [38][38/196]	LR: 1.0000000000000002e-06	Loss 2.2832 (2.2370)	Prec@1 41.016 (42.598)	
Epoch: [38][77/196]	LR: 1.0000000000000002e-06	Loss 2.1270 (2.2303)	Prec@1 46.875 (42.698)	
Epoch: [38][116/196]	LR: 1.0000000000000002e-06	Loss 2.1895 (2.2317)	Prec@1 45.703 (42.712)	
Epoch: [38][155/196]	LR: 1.0000000000000002e-06	Loss 2.1367 (2.2325)	Prec@1 43.750 (42.711)	
Epoch: [38][194/196]	LR: 1.0000000000000002e-06	Loss 2.2949 (2.2340)	Prec@1 40.625 (42.776)	
Total train loss: 2.2339

Train time: 18.88356328010559
 * Prec@1 41.650 Prec@5 73.490 Loss 2.2637
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 22.747620105743408

Epoch: [39][38/196]	LR: 1.0000000000000002e-06	Loss 2.2324 (2.2377)	Prec@1 43.750 (42.348)	
Epoch: [39][77/196]	LR: 1.0000000000000002e-06	Loss 2.2480 (2.2491)	Prec@1 42.188 (42.017)	
Epoch: [39][116/196]	LR: 1.0000000000000002e-06	Loss 2.1641 (2.2377)	Prec@1 45.312 (42.344)	
Epoch: [39][155/196]	LR: 1.0000000000000002e-06	Loss 2.2051 (2.2343)	Prec@1 42.188 (42.488)	
Epoch: [39][194/196]	LR: 1.0000000000000002e-06	Loss 2.4414 (2.2367)	Prec@1 41.797 (42.556)	
Total train loss: 2.2370

Train time: 18.43866229057312
 * Prec@1 41.400 Prec@5 73.550 Loss 2.2656
Best acc: 50.990
--------------------------------------------------------------------------------
Test time: 23.535958290100098


      ==> Arguments:
          dataset: cifar100
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20fp_cifar100.pth.tar
          mode: rram
          workers: 8
          epochs: 40
          start_epoch: 0
          batch_size: 256
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          milestones: [8, 16, 24, 32]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 15
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20fp_cifar100.pth.tar ...
Original model accuracy: 69.5999984741211
ResNet_cifar(
  (conv16): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (conv18): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu18): ReLU(inplace=True)
  (conv19): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu19): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (bn20): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=64, out_features=100, bias=False)
  (bn21): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 38.420 Prec@5 66.870 Loss 2.9238
Pre-trained Prec@1 with 15 layers frozen: 38.41999816894531 	 Loss: 2.923828125

Starting training on SRAM layers...
Epoch: [0][38/196]	LR: 0.01	Loss 1.1523 (1.2700)	Prec@1 66.016 (64.824)	
Epoch: [0][77/196]	LR: 0.01	Loss 1.2373 (1.2515)	Prec@1 66.797 (65.009)	
Epoch: [0][116/196]	LR: 0.01	Loss 1.1191 (1.2216)	Prec@1 67.188 (65.779)	
Epoch: [0][155/196]	LR: 0.01	Loss 1.1143 (1.2084)	Prec@1 68.750 (66.051)	
Epoch: [0][194/196]	LR: 0.01	Loss 1.1475 (1.2024)	Prec@1 69.531 (66.128)	
Total train loss: 1.2019

Train time: 105.50891613960266
 * Prec@1 59.010 Prec@5 84.270 Loss 1.6123
Best acc: 59.010
--------------------------------------------------------------------------------
Test time: 109.66104626655579

Epoch: [1][38/196]	LR: 0.01	Loss 1.0830 (1.1345)	Prec@1 72.266 (68.169)	
Epoch: [1][77/196]	LR: 0.01	Loss 1.1377 (1.1553)	Prec@1 70.703 (67.583)	
Epoch: [1][116/196]	LR: 0.01	Loss 1.0977 (1.1512)	Prec@1 73.438 (67.745)	
Epoch: [1][155/196]	LR: 0.01	Loss 1.4355 (1.1647)	Prec@1 57.422 (67.463)	
Epoch: [1][194/196]	LR: 0.01	Loss 1.4521 (1.1991)	Prec@1 62.109 (66.655)	
Total train loss: 1.1988

Train time: 18.645552158355713
 * Prec@1 55.550 Prec@5 82.710 Loss 1.7549
Best acc: 59.010
--------------------------------------------------------------------------------
Test time: 23.0974383354187

Epoch: [2][38/196]	LR: 0.01	Loss 1.0713 (1.2093)	Prec@1 69.531 (65.825)	
Epoch: [2][77/196]	LR: 0.01	Loss 1.1299 (1.1713)	Prec@1 71.875 (67.188)	
Epoch: [2][116/196]	LR: 0.01	Loss 1.1338 (1.1571)	Prec@1 66.797 (67.638)	
Epoch: [2][155/196]	LR: 0.01	Loss 1.2588 (1.1638)	Prec@1 67.578 (67.360)	
Epoch: [2][194/196]	LR: 0.01	Loss 1.0586 (1.1616)	Prec@1 67.969 (67.428)	
Total train loss: 1.1619

Train time: 18.36754322052002
 * Prec@1 60.500 Prec@5 85.670 Loss 1.5303
Best acc: 60.500
--------------------------------------------------------------------------------
Test time: 21.861404418945312

Epoch: [3][38/196]	LR: 0.01	Loss 1.0889 (1.0981)	Prec@1 69.922 (69.131)	
Epoch: [3][77/196]	LR: 0.01	Loss 1.3154 (1.1097)	Prec@1 66.797 (68.720)	
Epoch: [3][116/196]	LR: 0.01	Loss 1.0303 (1.0949)	Prec@1 66.406 (68.904)	
Epoch: [3][155/196]	LR: 0.01	Loss 1.2500 (1.1007)	Prec@1 64.453 (68.635)	
Epoch: [3][194/196]	LR: 0.01	Loss 1.0713 (1.0977)	Prec@1 64.844 (68.658)	
Total train loss: 1.0974

Train time: 16.983956336975098
 * Prec@1 60.560 Prec@5 86.370 Loss 1.4883
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 21.98513102531433

Epoch: [4][38/196]	LR: 0.01	Loss 1.1396 (1.0594)	Prec@1 69.531 (69.351)	
Epoch: [4][77/196]	LR: 0.01	Loss 1.2129 (1.0749)	Prec@1 67.578 (68.820)	
Epoch: [4][116/196]	LR: 0.01	Loss 1.0459 (1.0774)	Prec@1 73.828 (68.817)	
Epoch: [4][155/196]	LR: 0.01	Loss 1.0332 (1.0747)	Prec@1 69.531 (69.038)	
Epoch: [4][194/196]	LR: 0.01	Loss 1.0166 (1.0739)	Prec@1 69.922 (69.141)	
Total train loss: 1.0739

Train time: 18.322960376739502
 * Prec@1 57.230 Prec@5 84.210 Loss 1.6299
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 22.438361883163452

Epoch: [5][38/196]	LR: 0.01	Loss 1.2021 (1.1253)	Prec@1 66.797 (68.049)	
Epoch: [5][77/196]	LR: 0.01	Loss 1.2158 (1.1487)	Prec@1 68.359 (67.523)	
Epoch: [5][116/196]	LR: 0.01	Loss 1.0430 (1.1442)	Prec@1 66.797 (67.625)	
Epoch: [5][155/196]	LR: 0.01	Loss 1.1855 (1.1515)	Prec@1 68.359 (67.428)	
Epoch: [5][194/196]	LR: 0.01	Loss 1.3633 (1.1700)	Prec@1 67.188 (67.204)	
Total train loss: 1.1704

Train time: 18.01032257080078
 * Prec@1 57.040 Prec@5 84.580 Loss 1.6611
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 22.569736003875732

Epoch: [6][38/196]	LR: 0.01	Loss 1.4189 (1.3482)	Prec@1 60.547 (64.403)	
Epoch: [6][77/196]	LR: 0.01	Loss 1.3447 (1.3516)	Prec@1 65.234 (64.253)	
Epoch: [6][116/196]	LR: 0.01	Loss 1.5039 (1.3483)	Prec@1 63.672 (64.473)	
Epoch: [6][155/196]	LR: 0.01	Loss 1.3457 (1.3524)	Prec@1 68.359 (64.383)	
Epoch: [6][194/196]	LR: 0.01	Loss 1.4707 (1.3726)	Prec@1 60.547 (63.952)	
Total train loss: 1.3729

Train time: 17.134337186813354
 * Prec@1 55.030 Prec@5 82.700 Loss 1.7246
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 20.58133053779602

Epoch: [7][38/196]	LR: 0.01	Loss 1.4277 (1.4709)	Prec@1 63.672 (62.280)	
Epoch: [7][77/196]	LR: 0.01	Loss 1.5625 (1.5004)	Prec@1 56.641 (61.468)	
Epoch: [7][116/196]	LR: 0.01	Loss 1.3604 (1.4846)	Prec@1 64.062 (61.839)	
Epoch: [7][155/196]	LR: 0.01	Loss 1.4736 (1.4800)	Prec@1 60.547 (61.754)	
Epoch: [7][194/196]	LR: 0.01	Loss 1.5029 (1.4754)	Prec@1 60.938 (61.729)	
Total train loss: 1.4755

Train time: 17.79273271560669
 * Prec@1 56.460 Prec@5 83.920 Loss 1.6523
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 21.72641158103943

Epoch: [8][38/196]	LR: 0.001	Loss 1.3799 (1.4587)	Prec@1 63.281 (62.460)	
Epoch: [8][77/196]	LR: 0.001	Loss 1.4180 (1.4687)	Prec@1 65.625 (62.385)	
Epoch: [8][116/196]	LR: 0.001	Loss 1.4648 (1.4618)	Prec@1 63.281 (62.450)	
Epoch: [8][155/196]	LR: 0.001	Loss 1.4014 (1.4625)	Prec@1 63.281 (62.485)	
Epoch: [8][194/196]	LR: 0.001	Loss 1.5078 (1.4639)	Prec@1 62.500 (62.432)	
Total train loss: 1.4641

Train time: 19.56921648979187
 * Prec@1 56.700 Prec@5 84.170 Loss 1.6436
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 23.329832315444946

Epoch: [9][38/196]	LR: 0.001	Loss 1.5840 (1.4568)	Prec@1 58.594 (62.460)	
Epoch: [9][77/196]	LR: 0.001	Loss 1.4258 (1.4544)	Prec@1 65.234 (62.330)	
Epoch: [9][116/196]	LR: 0.001	Loss 1.4492 (1.4520)	Prec@1 60.938 (62.350)	
Epoch: [9][155/196]	LR: 0.001	Loss 1.4590 (1.4523)	Prec@1 58.594 (62.455)	
Epoch: [9][194/196]	LR: 0.001	Loss 1.5273 (1.4574)	Prec@1 62.109 (62.312)	
Total train loss: 1.4573

Train time: 17.134320974349976
 * Prec@1 56.780 Prec@5 84.320 Loss 1.6436
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 21.432376861572266

Epoch: [10][38/196]	LR: 0.001	Loss 1.3682 (1.4438)	Prec@1 65.234 (62.400)	
Epoch: [10][77/196]	LR: 0.001	Loss 1.4600 (1.4514)	Prec@1 61.328 (62.405)	
Epoch: [10][116/196]	LR: 0.001	Loss 1.2695 (1.4582)	Prec@1 67.969 (62.276)	
Epoch: [10][155/196]	LR: 0.001	Loss 1.3564 (1.4568)	Prec@1 66.016 (62.327)	
Epoch: [10][194/196]	LR: 0.001	Loss 1.4043 (1.4574)	Prec@1 64.844 (62.382)	
Total train loss: 1.4575

Train time: 19.293346166610718
 * Prec@1 56.890 Prec@5 84.220 Loss 1.6357
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 22.956098079681396

Epoch: [11][38/196]	LR: 0.001	Loss 1.4248 (1.4478)	Prec@1 60.156 (62.300)	
Epoch: [11][77/196]	LR: 0.001	Loss 1.4775 (1.4513)	Prec@1 64.062 (62.540)	
Epoch: [11][116/196]	LR: 0.001	Loss 1.3994 (1.4585)	Prec@1 63.672 (62.430)	
Epoch: [11][155/196]	LR: 0.001	Loss 1.4746 (1.4558)	Prec@1 60.547 (62.407)	
Epoch: [11][194/196]	LR: 0.001	Loss 1.4551 (1.4551)	Prec@1 62.891 (62.456)	
Total train loss: 1.4556

Train time: 19.262237787246704
 * Prec@1 57.000 Prec@5 84.160 Loss 1.6357
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 23.631261348724365

Epoch: [12][38/196]	LR: 0.001	Loss 1.3252 (1.4648)	Prec@1 69.922 (62.460)	
Epoch: [12][77/196]	LR: 0.001	Loss 1.4131 (1.4594)	Prec@1 61.328 (62.435)	
Epoch: [12][116/196]	LR: 0.001	Loss 1.3955 (1.4592)	Prec@1 60.547 (62.407)	
Epoch: [12][155/196]	LR: 0.001	Loss 1.4141 (1.4475)	Prec@1 62.109 (62.685)	
Epoch: [12][194/196]	LR: 0.001	Loss 1.3457 (1.4527)	Prec@1 64.844 (62.572)	
Total train loss: 1.4531

Train time: 18.343945503234863
 * Prec@1 56.740 Prec@5 84.100 Loss 1.6465
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 24.352364540100098

Epoch: [13][38/196]	LR: 0.001	Loss 1.5107 (1.4517)	Prec@1 60.938 (62.250)	
Epoch: [13][77/196]	LR: 0.001	Loss 1.3887 (1.4543)	Prec@1 64.062 (62.280)	
Epoch: [13][116/196]	LR: 0.001	Loss 1.4375 (1.4569)	Prec@1 62.891 (62.143)	
Epoch: [13][155/196]	LR: 0.001	Loss 1.4541 (1.4544)	Prec@1 63.672 (62.235)	
Epoch: [13][194/196]	LR: 0.001	Loss 1.5391 (1.4558)	Prec@1 58.594 (62.242)	
Total train loss: 1.4558

Train time: 17.571245670318604
 * Prec@1 57.000 Prec@5 84.150 Loss 1.6348
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 22.107978582382202

Epoch: [14][38/196]	LR: 0.001	Loss 1.5098 (1.4713)	Prec@1 63.281 (61.999)	
Epoch: [14][77/196]	LR: 0.001	Loss 1.4668 (1.4683)	Prec@1 61.719 (62.084)	
Epoch: [14][116/196]	LR: 0.001	Loss 1.3965 (1.4597)	Prec@1 62.500 (62.133)	
Epoch: [14][155/196]	LR: 0.001	Loss 1.5195 (1.4572)	Prec@1 59.766 (62.200)	
Epoch: [14][194/196]	LR: 0.001	Loss 1.3672 (1.4554)	Prec@1 59.766 (62.326)	
Total train loss: 1.4558

Train time: 19.699528694152832
 * Prec@1 56.810 Prec@5 84.160 Loss 1.6396
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 23.989612817764282

Epoch: [15][38/196]	LR: 0.001	Loss 1.3818 (1.4548)	Prec@1 67.578 (63.211)	
Epoch: [15][77/196]	LR: 0.001	Loss 1.5088 (1.4534)	Prec@1 60.156 (62.951)	
Epoch: [15][116/196]	LR: 0.001	Loss 1.6152 (1.4552)	Prec@1 59.375 (62.603)	
Epoch: [15][155/196]	LR: 0.001	Loss 1.5439 (1.4521)	Prec@1 57.031 (62.548)	
Epoch: [15][194/196]	LR: 0.001	Loss 1.4678 (1.4520)	Prec@1 62.109 (62.546)	
Total train loss: 1.4519

Train time: 19.174771785736084
 * Prec@1 56.900 Prec@5 84.200 Loss 1.6396
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 24.164933919906616

Epoch: [16][38/196]	LR: 0.0001	Loss 1.3535 (1.4685)	Prec@1 64.453 (61.739)	
Epoch: [16][77/196]	LR: 0.0001	Loss 1.4795 (1.4516)	Prec@1 64.844 (62.295)	
Epoch: [16][116/196]	LR: 0.0001	Loss 1.4639 (1.4555)	Prec@1 60.938 (62.323)	
Epoch: [16][155/196]	LR: 0.0001	Loss 1.3457 (1.4535)	Prec@1 65.625 (62.225)	
Epoch: [16][194/196]	LR: 0.0001	Loss 1.5605 (1.4525)	Prec@1 55.859 (62.262)	
Total train loss: 1.4524

Train time: 18.628883600234985
 * Prec@1 56.820 Prec@5 84.220 Loss 1.6416
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 22.2154700756073

Epoch: [17][38/196]	LR: 0.0001	Loss 1.4121 (1.4327)	Prec@1 62.891 (63.011)	
Epoch: [17][77/196]	LR: 0.0001	Loss 1.4834 (1.4349)	Prec@1 60.938 (62.715)	
Epoch: [17][116/196]	LR: 0.0001	Loss 1.5127 (1.4507)	Prec@1 59.375 (62.386)	
Epoch: [17][155/196]	LR: 0.0001	Loss 1.4844 (1.4556)	Prec@1 62.500 (62.245)	
Epoch: [17][194/196]	LR: 0.0001	Loss 1.5146 (1.4514)	Prec@1 59.375 (62.274)	
Total train loss: 1.4511

Train time: 17.783934593200684
 * Prec@1 56.820 Prec@5 84.120 Loss 1.6387
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 21.44260048866272

Epoch: [18][38/196]	LR: 0.0001	Loss 1.3525 (1.4485)	Prec@1 66.016 (62.159)	
Epoch: [18][77/196]	LR: 0.0001	Loss 1.3984 (1.4474)	Prec@1 62.109 (62.570)	
Epoch: [18][116/196]	LR: 0.0001	Loss 1.5000 (1.4469)	Prec@1 60.938 (62.654)	
Epoch: [18][155/196]	LR: 0.0001	Loss 1.5742 (1.4485)	Prec@1 58.203 (62.583)	
Epoch: [18][194/196]	LR: 0.0001	Loss 1.5908 (1.4513)	Prec@1 57.812 (62.430)	
Total train loss: 1.4516

Train time: 18.423206090927124
 * Prec@1 57.000 Prec@5 84.230 Loss 1.6348
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 26.7583429813385

Epoch: [19][38/196]	LR: 0.0001	Loss 1.3994 (1.4586)	Prec@1 67.578 (62.400)	
Epoch: [19][77/196]	LR: 0.0001	Loss 1.4580 (1.4662)	Prec@1 64.062 (62.355)	
Epoch: [19][116/196]	LR: 0.0001	Loss 1.4834 (1.4554)	Prec@1 61.719 (62.490)	
Epoch: [19][155/196]	LR: 0.0001	Loss 1.4688 (1.4504)	Prec@1 56.250 (62.462)	
Epoch: [19][194/196]	LR: 0.0001	Loss 1.4600 (1.4512)	Prec@1 64.844 (62.408)	
Total train loss: 1.4510

Train time: 19.314900159835815
 * Prec@1 56.750 Prec@5 84.170 Loss 1.6396
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 22.965736627578735

Epoch: [20][38/196]	LR: 0.0001	Loss 1.4014 (1.4433)	Prec@1 64.453 (62.059)	
Epoch: [20][77/196]	LR: 0.0001	Loss 1.4346 (1.4508)	Prec@1 60.938 (62.220)	
Epoch: [20][116/196]	LR: 0.0001	Loss 1.4297 (1.4559)	Prec@1 63.672 (62.310)	
Epoch: [20][155/196]	LR: 0.0001	Loss 1.3691 (1.4540)	Prec@1 67.969 (62.397)	
Epoch: [20][194/196]	LR: 0.0001	Loss 1.3203 (1.4518)	Prec@1 67.188 (62.472)	
Total train loss: 1.4519

Train time: 18.965156316757202
 * Prec@1 56.860 Prec@5 84.060 Loss 1.6396
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 23.05685305595398

Epoch: [21][38/196]	LR: 0.0001	Loss 1.4268 (1.4368)	Prec@1 63.281 (62.841)	
Epoch: [21][77/196]	LR: 0.0001	Loss 1.3867 (1.4484)	Prec@1 61.719 (62.295)	
Epoch: [21][116/196]	LR: 0.0001	Loss 1.4883 (1.4491)	Prec@1 62.891 (62.400)	
Epoch: [21][155/196]	LR: 0.0001	Loss 1.4365 (1.4492)	Prec@1 61.328 (62.412)	
Epoch: [21][194/196]	LR: 0.0001	Loss 1.3945 (1.4516)	Prec@1 61.328 (62.372)	
Total train loss: 1.4514

Train time: 17.912379503250122
 * Prec@1 56.670 Prec@5 84.220 Loss 1.6416
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 23.0914888381958

Epoch: [22][38/196]	LR: 0.0001	Loss 1.4844 (1.4459)	Prec@1 59.766 (63.011)	
Epoch: [22][77/196]	LR: 0.0001	Loss 1.3877 (1.4525)	Prec@1 64.062 (62.816)	
Epoch: [22][116/196]	LR: 0.0001	Loss 1.3018 (1.4489)	Prec@1 67.969 (62.770)	
Epoch: [22][155/196]	LR: 0.0001	Loss 1.6387 (1.4499)	Prec@1 58.594 (62.543)	
Epoch: [22][194/196]	LR: 0.0001	Loss 1.3193 (1.4508)	Prec@1 64.453 (62.504)	
Total train loss: 1.4510

Train time: 19.314438104629517
 * Prec@1 56.700 Prec@5 83.960 Loss 1.6445
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 23.646458387374878

Epoch: [23][38/196]	LR: 0.0001	Loss 1.4746 (1.4652)	Prec@1 60.547 (62.230)	
Epoch: [23][77/196]	LR: 0.0001	Loss 1.4531 (1.4594)	Prec@1 61.719 (62.655)	
Epoch: [23][116/196]	LR: 0.0001	Loss 1.3906 (1.4599)	Prec@1 60.156 (62.306)	
Epoch: [23][155/196]	LR: 0.0001	Loss 1.5371 (1.4539)	Prec@1 59.375 (62.427)	
Epoch: [23][194/196]	LR: 0.0001	Loss 1.3545 (1.4501)	Prec@1 59.766 (62.498)	
Total train loss: 1.4502

Train time: 18.05397057533264
 * Prec@1 56.850 Prec@5 84.260 Loss 1.6377
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 21.231202840805054

Epoch: [24][38/196]	LR: 1e-05	Loss 1.5547 (1.4586)	Prec@1 55.078 (62.590)	
Epoch: [24][77/196]	LR: 1e-05	Loss 1.4248 (1.4604)	Prec@1 62.891 (62.210)	
Epoch: [24][116/196]	LR: 1e-05	Loss 1.3594 (1.4543)	Prec@1 67.969 (62.203)	
Epoch: [24][155/196]	LR: 1e-05	Loss 1.3867 (1.4504)	Prec@1 64.844 (62.247)	
Epoch: [24][194/196]	LR: 1e-05	Loss 1.4805 (1.4525)	Prec@1 65.625 (62.238)	
Total train loss: 1.4526

Train time: 17.507269620895386
 * Prec@1 56.800 Prec@5 84.200 Loss 1.6396
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 21.285791635513306

Epoch: [25][38/196]	LR: 1e-05	Loss 1.4492 (1.4462)	Prec@1 62.109 (62.490)	
Epoch: [25][77/196]	LR: 1e-05	Loss 1.5127 (1.4507)	Prec@1 60.156 (62.320)	
Epoch: [25][116/196]	LR: 1e-05	Loss 1.4229 (1.4560)	Prec@1 61.719 (62.333)	
Epoch: [25][155/196]	LR: 1e-05	Loss 1.3682 (1.4565)	Prec@1 64.844 (62.330)	
Epoch: [25][194/196]	LR: 1e-05	Loss 1.3877 (1.4501)	Prec@1 64.062 (62.506)	
Total train loss: 1.4505

Train time: 18.417974948883057
 * Prec@1 57.020 Prec@5 84.220 Loss 1.6396
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 22.20354461669922

Epoch: [26][38/196]	LR: 1e-05	Loss 1.6533 (1.4599)	Prec@1 57.812 (62.430)	
Epoch: [26][77/196]	LR: 1e-05	Loss 1.4717 (1.4494)	Prec@1 64.062 (62.735)	
Epoch: [26][116/196]	LR: 1e-05	Loss 1.4629 (1.4504)	Prec@1 63.672 (62.400)	
Epoch: [26][155/196]	LR: 1e-05	Loss 1.4385 (1.4488)	Prec@1 62.891 (62.352)	
Epoch: [26][194/196]	LR: 1e-05	Loss 1.4336 (1.4493)	Prec@1 63.672 (62.322)	
Total train loss: 1.4498

Train time: 18.36487913131714
 * Prec@1 56.800 Prec@5 84.010 Loss 1.6465
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 21.577068090438843

Epoch: [27][38/196]	LR: 1e-05	Loss 1.4932 (1.4478)	Prec@1 58.594 (62.490)	
Epoch: [27][77/196]	LR: 1e-05	Loss 1.5820 (1.4534)	Prec@1 58.203 (62.380)	
Epoch: [27][116/196]	LR: 1e-05	Loss 1.2188 (1.4546)	Prec@1 70.703 (62.286)	
Epoch: [27][155/196]	LR: 1e-05	Loss 1.5039 (1.4521)	Prec@1 59.375 (62.375)	
Epoch: [27][194/196]	LR: 1e-05	Loss 1.3467 (1.4513)	Prec@1 66.016 (62.368)	
Total train loss: 1.4516

Train time: 17.624664545059204
 * Prec@1 57.010 Prec@5 84.170 Loss 1.6396
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 21.314430475234985

Epoch: [28][38/196]	LR: 1e-05	Loss 1.3975 (1.4442)	Prec@1 68.359 (62.260)	
Epoch: [28][77/196]	LR: 1e-05	Loss 1.4355 (1.4490)	Prec@1 62.109 (62.320)	
Epoch: [28][116/196]	LR: 1e-05	Loss 1.4443 (1.4509)	Prec@1 64.062 (62.253)	
Epoch: [28][155/196]	LR: 1e-05	Loss 1.3105 (1.4512)	Prec@1 66.406 (62.360)	
Epoch: [28][194/196]	LR: 1e-05	Loss 1.3535 (1.4507)	Prec@1 67.188 (62.426)	
Total train loss: 1.4506

Train time: 18.380832195281982
 * Prec@1 56.950 Prec@5 84.370 Loss 1.6396
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 22.004087686538696

Epoch: [29][38/196]	LR: 1e-05	Loss 1.3379 (1.4575)	Prec@1 65.234 (62.400)	
Epoch: [29][77/196]	LR: 1e-05	Loss 1.5020 (1.4521)	Prec@1 59.766 (62.500)	
Epoch: [29][116/196]	LR: 1e-05	Loss 1.3867 (1.4499)	Prec@1 64.062 (62.463)	
Epoch: [29][155/196]	LR: 1e-05	Loss 1.3643 (1.4498)	Prec@1 65.234 (62.317)	
Epoch: [29][194/196]	LR: 1e-05	Loss 1.4619 (1.4526)	Prec@1 61.328 (62.141)	
Total train loss: 1.4527

Train time: 17.672906398773193
 * Prec@1 56.720 Prec@5 84.310 Loss 1.6416
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 20.584814071655273

Epoch: [30][38/196]	LR: 1e-05	Loss 1.4814 (1.4526)	Prec@1 62.891 (62.400)	
Epoch: [30][77/196]	LR: 1e-05	Loss 1.3965 (1.4389)	Prec@1 63.672 (62.675)	
Epoch: [30][116/196]	LR: 1e-05	Loss 1.3408 (1.4450)	Prec@1 63.672 (62.510)	
Epoch: [30][155/196]	LR: 1e-05	Loss 1.4150 (1.4503)	Prec@1 63.281 (62.425)	
Epoch: [30][194/196]	LR: 1e-05	Loss 1.4873 (1.4522)	Prec@1 60.156 (62.374)	
Total train loss: 1.4525

Train time: 18.119234561920166
 * Prec@1 56.860 Prec@5 84.310 Loss 1.6436
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 21.838946104049683

Epoch: [31][38/196]	LR: 1e-05	Loss 1.4062 (1.4513)	Prec@1 64.844 (62.350)	
Epoch: [31][77/196]	LR: 1e-05	Loss 1.6748 (1.4435)	Prec@1 57.812 (62.470)	
Epoch: [31][116/196]	LR: 1e-05	Loss 1.3213 (1.4422)	Prec@1 67.188 (62.654)	
Epoch: [31][155/196]	LR: 1e-05	Loss 1.4043 (1.4509)	Prec@1 63.281 (62.365)	
Epoch: [31][194/196]	LR: 1e-05	Loss 1.5400 (1.4521)	Prec@1 59.375 (62.408)	
Total train loss: 1.4520

Train time: 18.095943212509155
 * Prec@1 57.040 Prec@5 84.270 Loss 1.6348
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 21.762384176254272

Epoch: [32][38/196]	LR: 1.0000000000000002e-06	Loss 1.4678 (1.4545)	Prec@1 64.062 (62.650)	
Epoch: [32][77/196]	LR: 1.0000000000000002e-06	Loss 1.4102 (1.4539)	Prec@1 64.844 (62.550)	
Epoch: [32][116/196]	LR: 1.0000000000000002e-06	Loss 1.4385 (1.4490)	Prec@1 60.938 (62.523)	
Epoch: [32][155/196]	LR: 1.0000000000000002e-06	Loss 1.3379 (1.4497)	Prec@1 66.016 (62.550)	
Epoch: [32][194/196]	LR: 1.0000000000000002e-06	Loss 1.4248 (1.4521)	Prec@1 64.062 (62.434)	
Total train loss: 1.4520

Train time: 18.08480405807495
 * Prec@1 56.990 Prec@5 84.280 Loss 1.6396
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 21.039812088012695

Epoch: [33][38/196]	LR: 1.0000000000000002e-06	Loss 1.5352 (1.4473)	Prec@1 59.375 (62.330)	
Epoch: [33][77/196]	LR: 1.0000000000000002e-06	Loss 1.5742 (1.4524)	Prec@1 57.422 (62.270)	
Epoch: [33][116/196]	LR: 1.0000000000000002e-06	Loss 1.3262 (1.4532)	Prec@1 65.625 (62.340)	
Epoch: [33][155/196]	LR: 1.0000000000000002e-06	Loss 1.4873 (1.4490)	Prec@1 60.547 (62.472)	
Epoch: [33][194/196]	LR: 1.0000000000000002e-06	Loss 1.5283 (1.4516)	Prec@1 57.031 (62.456)	
Total train loss: 1.4518

Train time: 17.570889472961426
 * Prec@1 56.930 Prec@5 84.070 Loss 1.6436
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 21.183917999267578

Epoch: [34][38/196]	LR: 1.0000000000000002e-06	Loss 1.4141 (1.4408)	Prec@1 62.109 (62.841)	
Epoch: [34][77/196]	LR: 1.0000000000000002e-06	Loss 1.4277 (1.4594)	Prec@1 67.188 (62.104)	
Epoch: [34][116/196]	LR: 1.0000000000000002e-06	Loss 1.4102 (1.4503)	Prec@1 66.797 (62.507)	
Epoch: [34][155/196]	LR: 1.0000000000000002e-06	Loss 1.4014 (1.4528)	Prec@1 64.844 (62.425)	
Epoch: [34][194/196]	LR: 1.0000000000000002e-06	Loss 1.5283 (1.4512)	Prec@1 58.203 (62.510)	
Total train loss: 1.4512

Train time: 19.25663948059082
 * Prec@1 56.790 Prec@5 84.190 Loss 1.6396
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 22.96049427986145

Epoch: [35][38/196]	LR: 1.0000000000000002e-06	Loss 1.4814 (1.4553)	Prec@1 61.328 (62.360)	
Epoch: [35][77/196]	LR: 1.0000000000000002e-06	Loss 1.5977 (1.4495)	Prec@1 54.297 (62.365)	
Epoch: [35][116/196]	LR: 1.0000000000000002e-06	Loss 1.4170 (1.4540)	Prec@1 60.938 (62.083)	
Epoch: [35][155/196]	LR: 1.0000000000000002e-06	Loss 1.4219 (1.4535)	Prec@1 61.328 (62.147)	
Epoch: [35][194/196]	LR: 1.0000000000000002e-06	Loss 1.3965 (1.4519)	Prec@1 63.672 (62.332)	
Total train loss: 1.4518

Train time: 19.704241275787354
 * Prec@1 57.120 Prec@5 84.060 Loss 1.6396
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 22.84249258041382

Epoch: [36][38/196]	LR: 1.0000000000000002e-06	Loss 1.4785 (1.4336)	Prec@1 60.156 (63.111)	
Epoch: [36][77/196]	LR: 1.0000000000000002e-06	Loss 1.4160 (1.4444)	Prec@1 65.625 (62.805)	
Epoch: [36][116/196]	LR: 1.0000000000000002e-06	Loss 1.4023 (1.4481)	Prec@1 64.453 (62.580)	
Epoch: [36][155/196]	LR: 1.0000000000000002e-06	Loss 1.4004 (1.4514)	Prec@1 66.016 (62.387)	
Epoch: [36][194/196]	LR: 1.0000000000000002e-06	Loss 1.3350 (1.4520)	Prec@1 64.844 (62.308)	
Total train loss: 1.4522

Train time: 17.24753499031067
 * Prec@1 56.770 Prec@5 84.070 Loss 1.6396
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 21.330588340759277

Epoch: [37][38/196]	LR: 1.0000000000000002e-06	Loss 1.3828 (1.4632)	Prec@1 64.453 (62.640)	
Epoch: [37][77/196]	LR: 1.0000000000000002e-06	Loss 1.5439 (1.4502)	Prec@1 63.672 (62.795)	
Epoch: [37][116/196]	LR: 1.0000000000000002e-06	Loss 1.4570 (1.4525)	Prec@1 60.547 (62.730)	
Epoch: [37][155/196]	LR: 1.0000000000000002e-06	Loss 1.4531 (1.4521)	Prec@1 62.500 (62.560)	
Epoch: [37][194/196]	LR: 1.0000000000000002e-06	Loss 1.4766 (1.4519)	Prec@1 61.719 (62.518)	
Total train loss: 1.4521

Train time: 16.599249362945557
 * Prec@1 57.020 Prec@5 84.090 Loss 1.6416
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 20.309122562408447

Epoch: [38][38/196]	LR: 1.0000000000000002e-06	Loss 1.5664 (1.4541)	Prec@1 59.375 (62.139)	
Epoch: [38][77/196]	LR: 1.0000000000000002e-06	Loss 1.4854 (1.4488)	Prec@1 61.719 (62.300)	
Epoch: [38][116/196]	LR: 1.0000000000000002e-06	Loss 1.4082 (1.4533)	Prec@1 64.453 (62.340)	
Epoch: [38][155/196]	LR: 1.0000000000000002e-06	Loss 1.5391 (1.4595)	Prec@1 60.938 (62.032)	
Epoch: [38][194/196]	LR: 1.0000000000000002e-06	Loss 1.3350 (1.4540)	Prec@1 67.969 (62.141)	
Total train loss: 1.4544

Train time: 18.30444359779358
 * Prec@1 56.980 Prec@5 84.170 Loss 1.6367
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 22.42205834388733

Epoch: [39][38/196]	LR: 1.0000000000000002e-06	Loss 1.6045 (1.4451)	Prec@1 60.547 (62.891)	
Epoch: [39][77/196]	LR: 1.0000000000000002e-06	Loss 1.4434 (1.4482)	Prec@1 60.938 (62.921)	
Epoch: [39][116/196]	LR: 1.0000000000000002e-06	Loss 1.5244 (1.4522)	Prec@1 64.062 (62.650)	
Epoch: [39][155/196]	LR: 1.0000000000000002e-06	Loss 1.4092 (1.4500)	Prec@1 59.375 (62.495)	
Epoch: [39][194/196]	LR: 1.0000000000000002e-06	Loss 1.3916 (1.4504)	Prec@1 63.672 (62.428)	
Total train loss: 1.4504

Train time: 19.93075728416443
 * Prec@1 56.800 Prec@5 84.030 Loss 1.6396
Best acc: 60.560
--------------------------------------------------------------------------------
Test time: 23.774031400680542


      ==> Arguments:
          dataset: cifar100
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20fp_cifar100.pth.tar
          mode: rram
          workers: 8
          epochs: 40
          start_epoch: 0
          batch_size: 256
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          milestones: [8, 16, 24, 32]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 17
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20fp_cifar100.pth.tar ...
Original model accuracy: 69.5999984741211
ResNet_cifar(
  (conv18): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu18): ReLU(inplace=True)
  (conv19): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu19): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (bn20): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=64, out_features=100, bias=False)
  (bn21): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 32.510 Prec@5 62.310 Loss 3.4785
Pre-trained Prec@1 with 17 layers frozen: 32.5099983215332 	 Loss: 3.478515625

Starting training on SRAM layers...
Epoch: [0][38/196]	LR: 0.01	Loss 1.3623 (1.5266)	Prec@1 59.766 (58.594)	
Epoch: [0][77/196]	LR: 0.01	Loss 1.4561 (1.4809)	Prec@1 64.453 (59.630)	
Epoch: [0][116/196]	LR: 0.01	Loss 1.3057 (1.4447)	Prec@1 63.281 (60.347)	
Epoch: [0][155/196]	LR: 0.01	Loss 1.2383 (1.4221)	Prec@1 66.406 (61.028)	
Epoch: [0][194/196]	LR: 0.01	Loss 1.3477 (1.4027)	Prec@1 64.453 (61.402)	
Total train loss: 1.4024

Train time: 127.8377685546875
 * Prec@1 56.260 Prec@5 83.120 Loss 1.6787
Best acc: 56.260
--------------------------------------------------------------------------------
Test time: 131.58846497535706

Epoch: [1][38/196]	LR: 0.01	Loss 1.1309 (1.3204)	Prec@1 67.188 (63.301)	
Epoch: [1][77/196]	LR: 0.01	Loss 1.3770 (1.3227)	Prec@1 65.625 (63.091)	
Epoch: [1][116/196]	LR: 0.01	Loss 1.2998 (1.3171)	Prec@1 61.719 (63.388)	
Epoch: [1][155/196]	LR: 0.01	Loss 1.4287 (1.3254)	Prec@1 61.328 (63.299)	
Epoch: [1][194/196]	LR: 0.01	Loss 1.2930 (1.3362)	Prec@1 66.406 (63.117)	
Total train loss: 1.3363

Train time: 20.706247806549072
 * Prec@1 57.260 Prec@5 83.630 Loss 1.6270
Best acc: 57.260
--------------------------------------------------------------------------------
Test time: 24.702006578445435

Epoch: [2][38/196]	LR: 0.01	Loss 1.3008 (1.3678)	Prec@1 67.188 (62.851)	
Epoch: [2][77/196]	LR: 0.01	Loss 1.6367 (1.3904)	Prec@1 55.859 (62.485)	
Epoch: [2][116/196]	LR: 0.01	Loss 1.4805 (1.3910)	Prec@1 62.891 (62.490)	
Epoch: [2][155/196]	LR: 0.01	Loss 1.2803 (1.3994)	Prec@1 63.672 (62.177)	
Epoch: [2][194/196]	LR: 0.01	Loss 1.3867 (1.3978)	Prec@1 60.547 (62.238)	
Total train loss: 1.3977

Train time: 17.64306664466858
 * Prec@1 57.510 Prec@5 83.420 Loss 1.6250
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 21.432370901107788

Epoch: [3][38/196]	LR: 0.01	Loss 1.2949 (1.3899)	Prec@1 62.109 (62.921)	
Epoch: [3][77/196]	LR: 0.01	Loss 1.3672 (1.3941)	Prec@1 64.062 (62.715)	
Epoch: [3][116/196]	LR: 0.01	Loss 1.5303 (1.4060)	Prec@1 62.109 (62.520)	
Epoch: [3][155/196]	LR: 0.01	Loss 1.5908 (1.4220)	Prec@1 60.547 (62.154)	
Epoch: [3][194/196]	LR: 0.01	Loss 1.3545 (1.4339)	Prec@1 65.234 (62.051)	
Total train loss: 1.4344

Train time: 17.497597694396973
 * Prec@1 56.240 Prec@5 82.510 Loss 1.6797
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 23.5665123462677

Epoch: [4][38/196]	LR: 0.01	Loss 1.4609 (1.5229)	Prec@1 63.672 (61.308)	
Epoch: [4][77/196]	LR: 0.01	Loss 1.6035 (1.5310)	Prec@1 60.156 (61.073)	
Epoch: [4][116/196]	LR: 0.01	Loss 1.4121 (1.5336)	Prec@1 64.453 (60.944)	
Epoch: [4][155/196]	LR: 0.01	Loss 1.4814 (1.5392)	Prec@1 63.672 (60.837)	
Epoch: [4][194/196]	LR: 0.01	Loss 1.6416 (1.5496)	Prec@1 57.812 (60.485)	
Total train loss: 1.5500

Train time: 18.227866172790527
 * Prec@1 54.850 Prec@5 81.650 Loss 1.7666
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 22.284126043319702

Epoch: [5][38/196]	LR: 0.01	Loss 1.4941 (1.5921)	Prec@1 66.016 (59.806)	
Epoch: [5][77/196]	LR: 0.01	Loss 1.7500 (1.5932)	Prec@1 58.984 (60.071)	
Epoch: [5][116/196]	LR: 0.01	Loss 1.5645 (1.6029)	Prec@1 65.234 (59.746)	
Epoch: [5][155/196]	LR: 0.01	Loss 1.5723 (1.6158)	Prec@1 62.891 (59.400)	
Epoch: [5][194/196]	LR: 0.01	Loss 1.6113 (1.6296)	Prec@1 60.156 (59.241)	
Total train loss: 1.6297

Train time: 16.348296403884888
 * Prec@1 53.960 Prec@5 81.530 Loss 1.7939
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 20.023094177246094

Epoch: [6][38/196]	LR: 0.01	Loss 1.6436 (1.6598)	Prec@1 61.719 (59.425)	
Epoch: [6][77/196]	LR: 0.01	Loss 1.5986 (1.6790)	Prec@1 63.281 (58.989)	
Epoch: [6][116/196]	LR: 0.01	Loss 1.6934 (1.6876)	Prec@1 56.250 (58.797)	
Epoch: [6][155/196]	LR: 0.01	Loss 1.7432 (1.6992)	Prec@1 52.734 (58.423)	
Epoch: [6][194/196]	LR: 0.01	Loss 1.9121 (1.7084)	Prec@1 53.125 (58.375)	
Total train loss: 1.7092

Train time: 16.467482089996338
 * Prec@1 53.370 Prec@5 80.890 Loss 1.8467
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 22.53993821144104

Epoch: [7][38/196]	LR: 0.01	Loss 1.7363 (1.7739)	Prec@1 60.938 (57.672)	
Epoch: [7][77/196]	LR: 0.01	Loss 1.8145 (1.7706)	Prec@1 55.078 (57.823)	
Epoch: [7][116/196]	LR: 0.01	Loss 1.6240 (1.7725)	Prec@1 66.406 (57.806)	
Epoch: [7][155/196]	LR: 0.01	Loss 1.8789 (1.7875)	Prec@1 57.031 (57.342)	
Epoch: [7][194/196]	LR: 0.01	Loss 1.8467 (1.7980)	Prec@1 53.906 (57.212)	
Total train loss: 1.7985

Train time: 17.239316701889038
 * Prec@1 52.330 Prec@5 80.170 Loss 1.9355
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 20.842848777770996

Epoch: [8][38/196]	LR: 0.001	Loss 1.7207 (1.8356)	Prec@1 62.109 (56.621)	
Epoch: [8][77/196]	LR: 0.001	Loss 1.7891 (1.8355)	Prec@1 57.031 (56.951)	
Epoch: [8][116/196]	LR: 0.001	Loss 1.7461 (1.8340)	Prec@1 62.891 (56.874)	
Epoch: [8][155/196]	LR: 0.001	Loss 1.6504 (1.8358)	Prec@1 58.594 (56.798)	
Epoch: [8][194/196]	LR: 0.001	Loss 1.7266 (1.8363)	Prec@1 58.203 (56.773)	
Total train loss: 1.8365

Train time: 17.403693914413452
 * Prec@1 53.150 Prec@5 80.860 Loss 1.8994
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 21.133147716522217

Epoch: [9][38/196]	LR: 0.001	Loss 1.9189 (1.8387)	Prec@1 50.000 (56.831)	
Epoch: [9][77/196]	LR: 0.001	Loss 1.9170 (1.8304)	Prec@1 55.078 (57.166)	
Epoch: [9][116/196]	LR: 0.001	Loss 1.8916 (1.8331)	Prec@1 54.297 (56.911)	
Epoch: [9][155/196]	LR: 0.001	Loss 1.9609 (1.8413)	Prec@1 51.953 (56.803)	
Epoch: [9][194/196]	LR: 0.001	Loss 1.8574 (1.8438)	Prec@1 57.031 (56.627)	
Total train loss: 1.8435

Train time: 16.293237924575806
 * Prec@1 52.930 Prec@5 80.600 Loss 1.9072
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 22.156094312667847

Epoch: [10][38/196]	LR: 0.001	Loss 1.7920 (1.8343)	Prec@1 57.812 (57.432)	
Epoch: [10][77/196]	LR: 0.001	Loss 1.8721 (1.8428)	Prec@1 54.688 (56.896)	
Epoch: [10][116/196]	LR: 0.001	Loss 1.9434 (1.8434)	Prec@1 50.000 (56.928)	
Epoch: [10][155/196]	LR: 0.001	Loss 1.9668 (1.8537)	Prec@1 54.297 (56.553)	
Epoch: [10][194/196]	LR: 0.001	Loss 2.0156 (1.8558)	Prec@1 54.297 (56.386)	
Total train loss: 1.8556

Train time: 17.86713147163391
 * Prec@1 52.930 Prec@5 80.460 Loss 1.9121
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 21.605954885482788

Epoch: [11][38/196]	LR: 0.001	Loss 1.8037 (1.8722)	Prec@1 59.766 (56.290)	
Epoch: [11][77/196]	LR: 0.001	Loss 1.9355 (1.8667)	Prec@1 55.078 (56.415)	
Epoch: [11][116/196]	LR: 0.001	Loss 1.9609 (1.8676)	Prec@1 51.172 (56.357)	
Epoch: [11][155/196]	LR: 0.001	Loss 1.9434 (1.8674)	Prec@1 51.953 (56.288)	
Epoch: [11][194/196]	LR: 0.001	Loss 1.7930 (1.8675)	Prec@1 57.422 (56.362)	
Total train loss: 1.8676

Train time: 18.01772928237915
 * Prec@1 52.670 Prec@5 80.320 Loss 1.9297
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 22.28941798210144

Epoch: [12][38/196]	LR: 0.001	Loss 1.7441 (1.8381)	Prec@1 60.547 (57.312)	
Epoch: [12][77/196]	LR: 0.001	Loss 1.9375 (1.8627)	Prec@1 53.125 (56.601)	
Epoch: [12][116/196]	LR: 0.001	Loss 1.8809 (1.8735)	Prec@1 56.641 (56.253)	
Epoch: [12][155/196]	LR: 0.001	Loss 1.9434 (1.8759)	Prec@1 56.250 (56.300)	
Epoch: [12][194/196]	LR: 0.001	Loss 2.0566 (1.8788)	Prec@1 52.734 (56.250)	
Total train loss: 1.8790

Train time: 18.443176984786987
 * Prec@1 52.520 Prec@5 80.240 Loss 1.9395
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 22.750169277191162

Epoch: [13][38/196]	LR: 0.001	Loss 1.9756 (1.8739)	Prec@1 52.734 (56.360)	
Epoch: [13][77/196]	LR: 0.001	Loss 1.8145 (1.8791)	Prec@1 58.594 (56.290)	
Epoch: [13][116/196]	LR: 0.001	Loss 1.9346 (1.8871)	Prec@1 53.125 (56.160)	
Epoch: [13][155/196]	LR: 0.001	Loss 1.9463 (1.8897)	Prec@1 56.641 (56.117)	
Epoch: [13][194/196]	LR: 0.001	Loss 1.8506 (1.8944)	Prec@1 57.812 (55.986)	
Total train loss: 1.8945

Train time: 19.17271876335144
 * Prec@1 52.700 Prec@5 80.440 Loss 1.9521
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 23.14854907989502

Epoch: [14][38/196]	LR: 0.001	Loss 1.9912 (1.9053)	Prec@1 55.859 (55.809)	
Epoch: [14][77/196]	LR: 0.001	Loss 2.0508 (1.9110)	Prec@1 51.953 (55.519)	
Epoch: [14][116/196]	LR: 0.001	Loss 1.9609 (1.9097)	Prec@1 53.125 (55.696)	
Epoch: [14][155/196]	LR: 0.001	Loss 1.8457 (1.9061)	Prec@1 54.688 (55.882)	
Epoch: [14][194/196]	LR: 0.001	Loss 1.8350 (1.9066)	Prec@1 55.859 (55.839)	
Total train loss: 1.9069

Train time: 19.367262840270996
 * Prec@1 52.400 Prec@5 80.050 Loss 1.9473
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 23.363415956497192

Epoch: [15][38/196]	LR: 0.001	Loss 1.8447 (1.9225)	Prec@1 57.812 (55.308)	
Epoch: [15][77/196]	LR: 0.001	Loss 1.8037 (1.9255)	Prec@1 60.938 (55.369)	
Epoch: [15][116/196]	LR: 0.001	Loss 1.9658 (1.9206)	Prec@1 57.031 (55.539)	
Epoch: [15][155/196]	LR: 0.001	Loss 1.9932 (1.9224)	Prec@1 54.297 (55.584)	
Epoch: [15][194/196]	LR: 0.001	Loss 1.9346 (1.9199)	Prec@1 53.906 (55.617)	
Total train loss: 1.9202

Train time: 17.974671125411987
 * Prec@1 52.280 Prec@5 79.980 Loss 1.9746
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 24.466843366622925

Epoch: [16][38/196]	LR: 0.0001	Loss 2.0117 (1.9085)	Prec@1 54.688 (55.719)	
Epoch: [16][77/196]	LR: 0.0001	Loss 2.0918 (1.9121)	Prec@1 54.688 (55.819)	
Epoch: [16][116/196]	LR: 0.0001	Loss 2.0684 (1.9178)	Prec@1 52.344 (55.606)	
Epoch: [16][155/196]	LR: 0.0001	Loss 1.9531 (1.9216)	Prec@1 53.516 (55.662)	
Epoch: [16][194/196]	LR: 0.0001	Loss 1.8076 (1.9245)	Prec@1 54.297 (55.569)	
Total train loss: 1.9250

Train time: 18.725661277770996
 * Prec@1 52.260 Prec@5 80.220 Loss 1.9697
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 22.734392404556274

Epoch: [17][38/196]	LR: 0.0001	Loss 1.8984 (1.9309)	Prec@1 58.984 (55.409)	
Epoch: [17][77/196]	LR: 0.0001	Loss 1.8027 (1.9235)	Prec@1 60.938 (55.739)	
Epoch: [17][116/196]	LR: 0.0001	Loss 1.9062 (1.9275)	Prec@1 53.125 (55.696)	
Epoch: [17][155/196]	LR: 0.0001	Loss 1.9238 (1.9276)	Prec@1 53.516 (55.601)	
Epoch: [17][194/196]	LR: 0.0001	Loss 1.9219 (1.9277)	Prec@1 57.422 (55.555)	
Total train loss: 1.9283

Train time: 16.313164710998535
 * Prec@1 52.250 Prec@5 80.040 Loss 1.9668
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 19.921526193618774

Epoch: [18][38/196]	LR: 0.0001	Loss 1.9775 (1.9313)	Prec@1 56.250 (55.469)	
Epoch: [18][77/196]	LR: 0.0001	Loss 1.9785 (1.9406)	Prec@1 53.516 (54.853)	
Epoch: [18][116/196]	LR: 0.0001	Loss 1.8975 (1.9343)	Prec@1 58.203 (55.212)	
Epoch: [18][155/196]	LR: 0.0001	Loss 1.9111 (1.9289)	Prec@1 58.203 (55.501)	
Epoch: [18][194/196]	LR: 0.0001	Loss 1.8633 (1.9286)	Prec@1 57.422 (55.483)	
Total train loss: 1.9286

Train time: 17.18541717529297
 * Prec@1 52.380 Prec@5 80.040 Loss 1.9697
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 26.253671884536743

Epoch: [19][38/196]	LR: 0.0001	Loss 2.0156 (1.9289)	Prec@1 53.516 (55.479)	
Epoch: [19][77/196]	LR: 0.0001	Loss 2.0039 (1.9255)	Prec@1 57.422 (55.504)	
Epoch: [19][116/196]	LR: 0.0001	Loss 1.9141 (1.9313)	Prec@1 55.859 (55.459)	
Epoch: [19][155/196]	LR: 0.0001	Loss 1.8711 (1.9298)	Prec@1 59.375 (55.526)	
Epoch: [19][194/196]	LR: 0.0001	Loss 1.8652 (1.9296)	Prec@1 53.516 (55.479)	
Total train loss: 1.9294

Train time: 19.08666491508484
 * Prec@1 52.110 Prec@5 80.240 Loss 1.9697
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 22.845046281814575

Epoch: [20][38/196]	LR: 0.0001	Loss 1.9854 (1.9208)	Prec@1 52.344 (55.839)	
Epoch: [20][77/196]	LR: 0.0001	Loss 1.9121 (1.9324)	Prec@1 55.469 (55.714)	
Epoch: [20][116/196]	LR: 0.0001	Loss 1.9238 (1.9316)	Prec@1 56.250 (55.622)	
Epoch: [20][155/196]	LR: 0.0001	Loss 1.9590 (1.9218)	Prec@1 53.125 (56.027)	
Epoch: [20][194/196]	LR: 0.0001	Loss 1.9863 (1.9279)	Prec@1 55.078 (55.731)	
Total train loss: 1.9276

Train time: 18.410157918930054
 * Prec@1 52.400 Prec@5 80.070 Loss 1.9678
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 22.06961154937744

Epoch: [21][38/196]	LR: 0.0001	Loss 1.8994 (1.9087)	Prec@1 57.812 (55.919)	
Epoch: [21][77/196]	LR: 0.0001	Loss 1.9385 (1.9207)	Prec@1 53.906 (55.654)	
Epoch: [21][116/196]	LR: 0.0001	Loss 1.9053 (1.9235)	Prec@1 54.297 (55.619)	
Epoch: [21][155/196]	LR: 0.0001	Loss 1.8926 (1.9289)	Prec@1 53.906 (55.554)	
Epoch: [21][194/196]	LR: 0.0001	Loss 2.0840 (1.9313)	Prec@1 50.391 (55.597)	
Total train loss: 1.9317

Train time: 17.998470067977905
 * Prec@1 52.100 Prec@5 80.080 Loss 1.9844
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 23.112035274505615

Epoch: [22][38/196]	LR: 0.0001	Loss 1.9746 (1.9408)	Prec@1 51.562 (55.950)	
Epoch: [22][77/196]	LR: 0.0001	Loss 1.8906 (1.9358)	Prec@1 55.078 (55.874)	
Epoch: [22][116/196]	LR: 0.0001	Loss 1.9668 (1.9289)	Prec@1 53.906 (55.863)	
Epoch: [22][155/196]	LR: 0.0001	Loss 1.8389 (1.9295)	Prec@1 58.203 (55.674)	
Epoch: [22][194/196]	LR: 0.0001	Loss 2.0039 (1.9331)	Prec@1 53.516 (55.639)	
Total train loss: 1.9325

Train time: 18.103175163269043
 * Prec@1 52.200 Prec@5 80.180 Loss 1.9600
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 22.173848152160645

Epoch: [23][38/196]	LR: 0.0001	Loss 1.8438 (1.9310)	Prec@1 55.859 (56.280)	
Epoch: [23][77/196]	LR: 0.0001	Loss 1.9150 (1.9403)	Prec@1 55.469 (55.504)	
Epoch: [23][116/196]	LR: 0.0001	Loss 1.8789 (1.9362)	Prec@1 55.859 (55.676)	
Epoch: [23][155/196]	LR: 0.0001	Loss 1.9287 (1.9346)	Prec@1 54.297 (55.566)	
Epoch: [23][194/196]	LR: 0.0001	Loss 1.9502 (1.9339)	Prec@1 55.469 (55.491)	
Total train loss: 1.9339

Train time: 16.75065016746521
 * Prec@1 52.190 Prec@5 80.100 Loss 1.9697
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 20.69124460220337

Epoch: [24][38/196]	LR: 1e-05	Loss 2.0801 (1.9487)	Prec@1 50.391 (55.619)	
Epoch: [24][77/196]	LR: 1e-05	Loss 1.9014 (1.9319)	Prec@1 56.250 (55.879)	
Epoch: [24][116/196]	LR: 1e-05	Loss 2.0117 (1.9335)	Prec@1 53.906 (55.662)	
Epoch: [24][155/196]	LR: 1e-05	Loss 1.9434 (1.9362)	Prec@1 57.031 (55.629)	
Epoch: [24][194/196]	LR: 1e-05	Loss 2.0137 (1.9346)	Prec@1 48.047 (55.579)	
Total train loss: 1.9346

Train time: 17.349851608276367
 * Prec@1 52.150 Prec@5 80.170 Loss 1.9600
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 23.064212322235107

Epoch: [25][38/196]	LR: 1e-05	Loss 1.9688 (1.9371)	Prec@1 51.953 (55.389)	
Epoch: [25][77/196]	LR: 1e-05	Loss 1.9902 (1.9445)	Prec@1 53.125 (55.233)	
Epoch: [25][116/196]	LR: 1e-05	Loss 1.8838 (1.9397)	Prec@1 55.078 (55.315)	
Epoch: [25][155/196]	LR: 1e-05	Loss 2.0312 (1.9358)	Prec@1 49.219 (55.356)	
Epoch: [25][194/196]	LR: 1e-05	Loss 1.9902 (1.9343)	Prec@1 55.859 (55.419)	
Total train loss: 1.9341

Train time: 17.134643077850342
 * Prec@1 52.170 Prec@5 80.190 Loss 1.9648
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 20.82111382484436

Epoch: [26][38/196]	LR: 1e-05	Loss 2.0410 (1.9641)	Prec@1 53.125 (54.778)	
Epoch: [26][77/196]	LR: 1e-05	Loss 1.8564 (1.9400)	Prec@1 59.766 (55.574)	
Epoch: [26][116/196]	LR: 1e-05	Loss 1.8809 (1.9338)	Prec@1 54.297 (55.495)	
Epoch: [26][155/196]	LR: 1e-05	Loss 1.8223 (1.9343)	Prec@1 59.766 (55.657)	
Epoch: [26][194/196]	LR: 1e-05	Loss 1.9834 (1.9334)	Prec@1 55.078 (55.661)	
Total train loss: 1.9337

Train time: 16.63284921646118
 * Prec@1 52.170 Prec@5 80.090 Loss 1.9678
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 20.279274225234985

Epoch: [27][38/196]	LR: 1e-05	Loss 1.8682 (1.9363)	Prec@1 56.641 (55.228)	
Epoch: [27][77/196]	LR: 1e-05	Loss 1.8984 (1.9381)	Prec@1 53.906 (55.153)	
Epoch: [27][116/196]	LR: 1e-05	Loss 1.8887 (1.9395)	Prec@1 57.812 (55.252)	
Epoch: [27][155/196]	LR: 1e-05	Loss 1.8145 (1.9354)	Prec@1 57.812 (55.469)	
Epoch: [27][194/196]	LR: 1e-05	Loss 1.9141 (1.9357)	Prec@1 59.375 (55.447)	
Total train loss: 1.9356

Train time: 16.954305171966553
 * Prec@1 52.160 Prec@5 79.980 Loss 1.9727
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 26.54742431640625

Epoch: [28][38/196]	LR: 1e-05	Loss 1.9326 (1.9335)	Prec@1 59.375 (55.579)	
Epoch: [28][77/196]	LR: 1e-05	Loss 1.9980 (1.9326)	Prec@1 53.125 (55.659)	
Epoch: [28][116/196]	LR: 1e-05	Loss 2.0801 (1.9328)	Prec@1 51.953 (55.739)	
Epoch: [28][155/196]	LR: 1e-05	Loss 1.7070 (1.9331)	Prec@1 64.062 (55.644)	
Epoch: [28][194/196]	LR: 1e-05	Loss 1.8223 (1.9349)	Prec@1 55.859 (55.517)	
Total train loss: 1.9350

Train time: 19.02285361289978
 * Prec@1 52.140 Prec@5 80.000 Loss 1.9746
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 23.159297227859497

Epoch: [29][38/196]	LR: 1e-05	Loss 1.8545 (1.9331)	Prec@1 57.812 (55.889)	
Epoch: [29][77/196]	LR: 1e-05	Loss 1.8359 (1.9280)	Prec@1 57.031 (55.854)	
Epoch: [29][116/196]	LR: 1e-05	Loss 1.9365 (1.9204)	Prec@1 58.594 (56.076)	
Epoch: [29][155/196]	LR: 1e-05	Loss 1.9258 (1.9291)	Prec@1 57.422 (55.792)	
Epoch: [29][194/196]	LR: 1e-05	Loss 1.8730 (1.9340)	Prec@1 55.859 (55.637)	
Total train loss: 1.9340

Train time: 17.140316009521484
 * Prec@1 52.310 Prec@5 80.200 Loss 1.9727
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 20.923331260681152

Epoch: [30][38/196]	LR: 1e-05	Loss 1.8730 (1.9561)	Prec@1 60.938 (55.319)	
Epoch: [30][77/196]	LR: 1e-05	Loss 1.8193 (1.9480)	Prec@1 57.422 (54.978)	
Epoch: [30][116/196]	LR: 1e-05	Loss 2.0645 (1.9439)	Prec@1 48.828 (55.055)	
Epoch: [30][155/196]	LR: 1e-05	Loss 1.9746 (1.9363)	Prec@1 57.031 (55.379)	
Epoch: [30][194/196]	LR: 1e-05	Loss 1.7041 (1.9320)	Prec@1 60.938 (55.633)	
Total train loss: 1.9323

Train time: 17.112706899642944
 * Prec@1 52.500 Prec@5 80.070 Loss 1.9824
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 22.128605127334595

Epoch: [31][38/196]	LR: 1e-05	Loss 1.9648 (1.9199)	Prec@1 53.516 (55.479)	
Epoch: [31][77/196]	LR: 1e-05	Loss 2.0938 (1.9267)	Prec@1 53.125 (55.574)	
Epoch: [31][116/196]	LR: 1e-05	Loss 1.9131 (1.9299)	Prec@1 57.422 (55.579)	
Epoch: [31][155/196]	LR: 1e-05	Loss 2.0527 (1.9348)	Prec@1 49.609 (55.471)	
Epoch: [31][194/196]	LR: 1e-05	Loss 2.0332 (1.9343)	Prec@1 55.859 (55.549)	
Total train loss: 1.9344

Train time: 16.975993871688843
 * Prec@1 52.030 Prec@5 79.930 Loss 1.9756
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 20.772963285446167

Epoch: [32][38/196]	LR: 1.0000000000000002e-06	Loss 1.7920 (1.9354)	Prec@1 58.594 (55.689)	
Epoch: [32][77/196]	LR: 1.0000000000000002e-06	Loss 1.9873 (1.9357)	Prec@1 53.516 (55.494)	
Epoch: [32][116/196]	LR: 1.0000000000000002e-06	Loss 1.8555 (1.9285)	Prec@1 54.688 (55.682)	
Epoch: [32][155/196]	LR: 1.0000000000000002e-06	Loss 1.8047 (1.9351)	Prec@1 57.812 (55.451)	
Epoch: [32][194/196]	LR: 1.0000000000000002e-06	Loss 2.0410 (1.9336)	Prec@1 53.125 (55.595)	
Total train loss: 1.9340

Train time: 18.607678174972534
 * Prec@1 52.330 Prec@5 80.120 Loss 1.9717
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 22.318156480789185

Epoch: [33][38/196]	LR: 1.0000000000000002e-06	Loss 2.0098 (1.9508)	Prec@1 55.469 (54.878)	
Epoch: [33][77/196]	LR: 1.0000000000000002e-06	Loss 2.0605 (1.9427)	Prec@1 54.297 (55.504)	
Epoch: [33][116/196]	LR: 1.0000000000000002e-06	Loss 2.0156 (1.9366)	Prec@1 51.562 (55.499)	
Epoch: [33][155/196]	LR: 1.0000000000000002e-06	Loss 1.9023 (1.9376)	Prec@1 62.891 (55.411)	
Epoch: [33][194/196]	LR: 1.0000000000000002e-06	Loss 2.0703 (1.9356)	Prec@1 49.609 (55.549)	
Total train loss: 1.9357

Train time: 18.43107295036316
 * Prec@1 52.220 Prec@5 80.180 Loss 1.9756
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 25.852124452590942

Epoch: [34][38/196]	LR: 1.0000000000000002e-06	Loss 2.0195 (1.9387)	Prec@1 53.516 (55.258)	
Epoch: [34][77/196]	LR: 1.0000000000000002e-06	Loss 2.0762 (1.9433)	Prec@1 55.469 (55.273)	
Epoch: [34][116/196]	LR: 1.0000000000000002e-06	Loss 1.9697 (1.9476)	Prec@1 53.906 (55.258)	
Epoch: [34][155/196]	LR: 1.0000000000000002e-06	Loss 1.8223 (1.9422)	Prec@1 58.594 (55.288)	
Epoch: [34][194/196]	LR: 1.0000000000000002e-06	Loss 1.8799 (1.9346)	Prec@1 53.516 (55.441)	
Total train loss: 1.9350

Train time: 18.995940446853638
 * Prec@1 52.310 Prec@5 80.190 Loss 1.9678
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 22.277533292770386

Epoch: [35][38/196]	LR: 1.0000000000000002e-06	Loss 2.0527 (1.9371)	Prec@1 51.562 (55.669)	
Epoch: [35][77/196]	LR: 1.0000000000000002e-06	Loss 2.0469 (1.9427)	Prec@1 48.828 (55.193)	
Epoch: [35][116/196]	LR: 1.0000000000000002e-06	Loss 1.8633 (1.9410)	Prec@1 55.859 (55.479)	
Epoch: [35][155/196]	LR: 1.0000000000000002e-06	Loss 1.8662 (1.9388)	Prec@1 58.984 (55.464)	
Epoch: [35][194/196]	LR: 1.0000000000000002e-06	Loss 1.8906 (1.9344)	Prec@1 59.375 (55.673)	
Total train loss: 1.9342

Train time: 16.57452130317688
 * Prec@1 52.260 Prec@5 80.120 Loss 1.9717
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 19.81939673423767

Epoch: [36][38/196]	LR: 1.0000000000000002e-06	Loss 1.8906 (1.9268)	Prec@1 59.375 (55.789)	
Epoch: [36][77/196]	LR: 1.0000000000000002e-06	Loss 1.8398 (1.9285)	Prec@1 56.250 (55.704)	
Epoch: [36][116/196]	LR: 1.0000000000000002e-06	Loss 1.9092 (1.9305)	Prec@1 58.203 (55.799)	
Epoch: [36][155/196]	LR: 1.0000000000000002e-06	Loss 1.8857 (1.9320)	Prec@1 56.250 (55.499)	
Epoch: [36][194/196]	LR: 1.0000000000000002e-06	Loss 1.9766 (1.9337)	Prec@1 53.906 (55.523)	
Total train loss: 1.9339

Train time: 17.384737491607666
 * Prec@1 52.240 Prec@5 80.030 Loss 1.9756
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 21.71537208557129

Epoch: [37][38/196]	LR: 1.0000000000000002e-06	Loss 1.9033 (1.9205)	Prec@1 55.078 (55.980)	
Epoch: [37][77/196]	LR: 1.0000000000000002e-06	Loss 2.0117 (1.9341)	Prec@1 54.688 (55.499)	
Epoch: [37][116/196]	LR: 1.0000000000000002e-06	Loss 1.9248 (1.9340)	Prec@1 56.641 (55.329)	
Epoch: [37][155/196]	LR: 1.0000000000000002e-06	Loss 1.9336 (1.9385)	Prec@1 54.688 (55.419)	
Epoch: [37][194/196]	LR: 1.0000000000000002e-06	Loss 2.1250 (1.9335)	Prec@1 46.875 (55.613)	
Total train loss: 1.9341

Train time: 19.273343086242676
 * Prec@1 52.280 Prec@5 80.270 Loss 1.9746
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 22.811476945877075

Epoch: [38][38/196]	LR: 1.0000000000000002e-06	Loss 2.0098 (1.9436)	Prec@1 53.125 (54.988)	
Epoch: [38][77/196]	LR: 1.0000000000000002e-06	Loss 1.9180 (1.9344)	Prec@1 57.812 (55.163)	
Epoch: [38][116/196]	LR: 1.0000000000000002e-06	Loss 2.0566 (1.9321)	Prec@1 53.125 (55.355)	
Epoch: [38][155/196]	LR: 1.0000000000000002e-06	Loss 2.0098 (1.9322)	Prec@1 55.469 (55.374)	
Epoch: [38][194/196]	LR: 1.0000000000000002e-06	Loss 1.9062 (1.9337)	Prec@1 60.156 (55.393)	
Total train loss: 1.9339

Train time: 18.448288917541504
 * Prec@1 52.190 Prec@5 80.050 Loss 1.9893
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 21.676840782165527

Epoch: [39][38/196]	LR: 1.0000000000000002e-06	Loss 1.9395 (1.9541)	Prec@1 53.906 (54.828)	
Epoch: [39][77/196]	LR: 1.0000000000000002e-06	Loss 1.8633 (1.9395)	Prec@1 55.078 (55.258)	
Epoch: [39][116/196]	LR: 1.0000000000000002e-06	Loss 1.9814 (1.9282)	Prec@1 53.906 (55.773)	
Epoch: [39][155/196]	LR: 1.0000000000000002e-06	Loss 1.9482 (1.9343)	Prec@1 53.516 (55.436)	
Epoch: [39][194/196]	LR: 1.0000000000000002e-06	Loss 1.8857 (1.9334)	Prec@1 58.203 (55.423)	
Total train loss: 1.9333

Train time: 17.327216863632202
 * Prec@1 52.140 Prec@5 80.180 Loss 1.9775
Best acc: 57.510
--------------------------------------------------------------------------------
Test time: 21.572612285614014


      ==> Arguments:
          dataset: cifar100
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20fp_cifar100.pth.tar
          mode: rram
          workers: 8
          epochs: 40
          start_epoch: 0
          batch_size: 256
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          milestones: [8, 16, 24, 32]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 19
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20fp_cifar100.pth.tar ...
Original model accuracy: 69.5999984741211
ResNet_cifar(
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (bn20): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=64, out_features=100, bias=False)
  (bn21): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 29.410 Prec@5 59.380 Loss 3.9395
Pre-trained Prec@1 with 19 layers frozen: 29.40999984741211 	 Loss: 3.939453125

Starting training on SRAM layers...
Epoch: [0][38/196]	LR: 0.01	Loss 1.7793 (1.8150)	Prec@1 51.172 (52.374)	
Epoch: [0][77/196]	LR: 0.01	Loss 1.6904 (1.7810)	Prec@1 54.297 (53.676)	
Epoch: [0][116/196]	LR: 0.01	Loss 1.7207 (1.7786)	Prec@1 56.250 (53.976)	
Epoch: [0][155/196]	LR: 0.01	Loss 1.7139 (1.7498)	Prec@1 57.031 (54.632)	
Epoch: [0][194/196]	LR: 0.01	Loss 1.6270 (1.7343)	Prec@1 55.859 (54.964)	
Total train loss: 1.7343

Train time: 162.59051299095154
 * Prec@1 52.800 Prec@5 79.830 Loss 1.8779
Best acc: 52.800
--------------------------------------------------------------------------------
Test time: 165.72122144699097

Epoch: [1][38/196]	LR: 0.01	Loss 1.6133 (1.6846)	Prec@1 51.953 (56.180)	
Epoch: [1][77/196]	LR: 0.01	Loss 1.6367 (1.6687)	Prec@1 56.250 (56.510)	
Epoch: [1][116/196]	LR: 0.01	Loss 1.5615 (1.6727)	Prec@1 57.422 (56.377)	
Epoch: [1][155/196]	LR: 0.01	Loss 1.5391 (1.6656)	Prec@1 60.156 (56.453)	
Epoch: [1][194/196]	LR: 0.01	Loss 1.6523 (1.6642)	Prec@1 56.641 (56.510)	
Total train loss: 1.6643

Train time: 14.401396989822388
 * Prec@1 52.770 Prec@5 79.940 Loss 1.8672
Best acc: 52.800
--------------------------------------------------------------------------------
Test time: 17.38666081428528

Epoch: [2][38/196]	LR: 0.01	Loss 1.7207 (1.6950)	Prec@1 53.125 (56.010)	
Epoch: [2][77/196]	LR: 0.01	Loss 1.5146 (1.6770)	Prec@1 60.938 (56.430)	
Epoch: [2][116/196]	LR: 0.01	Loss 1.6514 (1.6863)	Prec@1 57.812 (56.303)	
Epoch: [2][155/196]	LR: 0.01	Loss 1.6768 (1.6876)	Prec@1 54.297 (56.468)	
Epoch: [2][194/196]	LR: 0.01	Loss 1.6064 (1.6818)	Prec@1 59.766 (56.552)	
Total train loss: 1.6816

Train time: 13.368384838104248
 * Prec@1 52.950 Prec@5 79.960 Loss 1.8652
Best acc: 52.950
--------------------------------------------------------------------------------
Test time: 17.489514589309692

Epoch: [3][38/196]	LR: 0.01	Loss 1.5547 (1.6779)	Prec@1 60.547 (56.090)	
Epoch: [3][77/196]	LR: 0.01	Loss 1.5098 (1.6646)	Prec@1 60.547 (56.591)	
Epoch: [3][116/196]	LR: 0.01	Loss 1.5547 (1.6551)	Prec@1 60.547 (56.707)	
Epoch: [3][155/196]	LR: 0.01	Loss 1.5859 (1.6554)	Prec@1 61.328 (56.696)	
Epoch: [3][194/196]	LR: 0.01	Loss 1.6299 (1.6567)	Prec@1 52.734 (56.685)	
Total train loss: 1.6568

Train time: 12.205484628677368
 * Prec@1 53.030 Prec@5 80.070 Loss 1.8594
Best acc: 53.030
--------------------------------------------------------------------------------
Test time: 15.96279239654541

Epoch: [4][38/196]	LR: 0.01	Loss 1.6729 (1.6518)	Prec@1 57.031 (56.801)	
Epoch: [4][77/196]	LR: 0.01	Loss 1.6787 (1.6493)	Prec@1 57.031 (57.212)	
Epoch: [4][116/196]	LR: 0.01	Loss 1.6348 (1.6522)	Prec@1 53.125 (57.068)	
Epoch: [4][155/196]	LR: 0.01	Loss 1.7881 (1.6566)	Prec@1 51.172 (56.863)	
Epoch: [4][194/196]	LR: 0.01	Loss 1.6504 (1.6641)	Prec@1 59.766 (56.907)	
Total train loss: 1.6646

Train time: 12.952729225158691
 * Prec@1 52.930 Prec@5 79.790 Loss 1.8564
Best acc: 53.030
--------------------------------------------------------------------------------
Test time: 20.114463090896606

Epoch: [5][38/196]	LR: 0.01	Loss 1.5957 (1.6925)	Prec@1 58.203 (57.292)	
Epoch: [5][77/196]	LR: 0.01	Loss 1.6719 (1.6889)	Prec@1 57.812 (57.222)	
Epoch: [5][116/196]	LR: 0.01	Loss 1.8057 (1.6931)	Prec@1 55.078 (56.894)	
Epoch: [5][155/196]	LR: 0.01	Loss 1.6797 (1.6941)	Prec@1 55.469 (56.838)	
Epoch: [5][194/196]	LR: 0.01	Loss 1.6045 (1.6937)	Prec@1 57.422 (56.787)	
Total train loss: 1.6932

Train time: 13.251690864562988
 * Prec@1 53.030 Prec@5 79.980 Loss 1.8496
Best acc: 53.030
--------------------------------------------------------------------------------
Test time: 16.181959629058838

Epoch: [6][38/196]	LR: 0.01	Loss 1.7305 (1.6528)	Prec@1 54.688 (56.621)	
Epoch: [6][77/196]	LR: 0.01	Loss 1.7852 (1.6842)	Prec@1 52.344 (56.495)	
Epoch: [6][116/196]	LR: 0.01	Loss 1.6074 (1.6899)	Prec@1 58.203 (56.514)	
Epoch: [6][155/196]	LR: 0.01	Loss 1.7549 (1.6908)	Prec@1 57.422 (56.533)	
Epoch: [6][194/196]	LR: 0.01	Loss 1.5283 (1.6882)	Prec@1 61.328 (56.536)	
Total train loss: 1.6881

Train time: 12.671345233917236
 * Prec@1 53.080 Prec@5 79.860 Loss 1.8496
Best acc: 53.080
--------------------------------------------------------------------------------
Test time: 15.260278940200806

Epoch: [7][38/196]	LR: 0.01	Loss 1.6748 (1.7050)	Prec@1 56.250 (56.060)	
Epoch: [7][77/196]	LR: 0.01	Loss 1.4209 (1.6739)	Prec@1 64.844 (57.006)	
Epoch: [7][116/196]	LR: 0.01	Loss 1.6689 (1.6729)	Prec@1 59.375 (56.998)	
Epoch: [7][155/196]	LR: 0.01	Loss 1.7764 (1.6756)	Prec@1 57.812 (56.889)	
Epoch: [7][194/196]	LR: 0.01	Loss 1.7227 (1.6804)	Prec@1 53.906 (56.849)	
Total train loss: 1.6802

Train time: 12.131680727005005
 * Prec@1 53.110 Prec@5 80.020 Loss 1.8447
Best acc: 53.110
--------------------------------------------------------------------------------
Test time: 16.003634929656982

Epoch: [8][38/196]	LR: 0.001	Loss 1.4600 (1.6545)	Prec@1 60.938 (57.121)	
Epoch: [8][77/196]	LR: 0.001	Loss 1.6758 (1.6594)	Prec@1 54.297 (57.131)	
Epoch: [8][116/196]	LR: 0.001	Loss 1.6299 (1.6664)	Prec@1 58.984 (57.118)	
Epoch: [8][155/196]	LR: 0.001	Loss 1.7227 (1.6643)	Prec@1 52.734 (57.039)	
Epoch: [8][194/196]	LR: 0.001	Loss 1.7188 (1.6622)	Prec@1 50.391 (57.021)	
Total train loss: 1.6624

Train time: 12.631383419036865
 * Prec@1 52.970 Prec@5 79.980 Loss 1.8428
Best acc: 53.110
--------------------------------------------------------------------------------
Test time: 17.460704803466797

Epoch: [9][38/196]	LR: 0.001	Loss 1.7178 (1.6628)	Prec@1 54.297 (56.741)	
Epoch: [9][77/196]	LR: 0.001	Loss 1.6064 (1.6602)	Prec@1 58.594 (56.951)	
Epoch: [9][116/196]	LR: 0.001	Loss 1.5439 (1.6564)	Prec@1 59.766 (57.075)	
Epoch: [9][155/196]	LR: 0.001	Loss 1.5732 (1.6558)	Prec@1 60.547 (57.134)	
Epoch: [9][194/196]	LR: 0.001	Loss 1.7217 (1.6616)	Prec@1 57.031 (56.933)	
Total train loss: 1.6620

Train time: 13.398356914520264
 * Prec@1 53.200 Prec@5 79.970 Loss 1.8467
Best acc: 53.200
--------------------------------------------------------------------------------
Test time: 17.556302309036255

Epoch: [10][38/196]	LR: 0.001	Loss 1.7441 (1.6723)	Prec@1 54.688 (56.961)	
Epoch: [10][77/196]	LR: 0.001	Loss 1.7363 (1.6522)	Prec@1 58.203 (57.282)	
Epoch: [10][116/196]	LR: 0.001	Loss 1.5947 (1.6636)	Prec@1 59.375 (56.978)	
Epoch: [10][155/196]	LR: 0.001	Loss 1.7129 (1.6670)	Prec@1 57.812 (57.016)	
Epoch: [10][194/196]	LR: 0.001	Loss 1.5820 (1.6627)	Prec@1 57.812 (57.103)	
Total train loss: 1.6626

Train time: 12.968199968338013
 * Prec@1 53.180 Prec@5 80.060 Loss 1.8467
Best acc: 53.200
--------------------------------------------------------------------------------
Test time: 16.04610824584961

Epoch: [11][38/196]	LR: 0.001	Loss 1.6641 (1.6749)	Prec@1 51.953 (56.300)	
Epoch: [11][77/196]	LR: 0.001	Loss 1.7285 (1.6720)	Prec@1 55.469 (56.746)	
Epoch: [11][116/196]	LR: 0.001	Loss 1.6709 (1.6675)	Prec@1 56.250 (56.914)	
Epoch: [11][155/196]	LR: 0.001	Loss 1.7598 (1.6684)	Prec@1 53.125 (56.964)	
Epoch: [11][194/196]	LR: 0.001	Loss 1.5674 (1.6627)	Prec@1 59.375 (57.111)	
Total train loss: 1.6628

Train time: 12.330815315246582
 * Prec@1 53.070 Prec@5 79.980 Loss 1.8477
Best acc: 53.200
--------------------------------------------------------------------------------
Test time: 15.203120946884155

Epoch: [12][38/196]	LR: 0.001	Loss 1.7803 (1.6801)	Prec@1 54.688 (56.440)	
Epoch: [12][77/196]	LR: 0.001	Loss 1.6133 (1.6730)	Prec@1 60.547 (56.540)	
Epoch: [12][116/196]	LR: 0.001	Loss 1.7168 (1.6622)	Prec@1 56.250 (56.971)	
Epoch: [12][155/196]	LR: 0.001	Loss 1.5986 (1.6655)	Prec@1 61.328 (56.961)	
Epoch: [12][194/196]	LR: 0.001	Loss 1.8213 (1.6613)	Prec@1 51.562 (57.001)	
Total train loss: 1.6615

Train time: 12.384552001953125
 * Prec@1 53.160 Prec@5 80.110 Loss 1.8467
Best acc: 53.200
--------------------------------------------------------------------------------
Test time: 16.74265480041504

Epoch: [13][38/196]	LR: 0.001	Loss 1.8691 (1.6678)	Prec@1 52.734 (56.921)	
Epoch: [13][77/196]	LR: 0.001	Loss 1.7529 (1.6668)	Prec@1 53.906 (57.096)	
Epoch: [13][116/196]	LR: 0.001	Loss 1.7061 (1.6562)	Prec@1 50.781 (57.492)	
Epoch: [13][155/196]	LR: 0.001	Loss 1.7080 (1.6596)	Prec@1 57.812 (57.339)	
Epoch: [13][194/196]	LR: 0.001	Loss 1.6367 (1.6630)	Prec@1 60.156 (57.214)	
Total train loss: 1.6633

Train time: 12.999151229858398
 * Prec@1 53.080 Prec@5 79.900 Loss 1.8467
Best acc: 53.200
--------------------------------------------------------------------------------
Test time: 15.92311692237854

Epoch: [14][38/196]	LR: 0.001	Loss 1.6465 (1.6644)	Prec@1 59.375 (56.741)	
Epoch: [14][77/196]	LR: 0.001	Loss 1.5859 (1.6644)	Prec@1 58.984 (56.911)	
Epoch: [14][116/196]	LR: 0.001	Loss 1.7246 (1.6618)	Prec@1 56.250 (57.035)	
Epoch: [14][155/196]	LR: 0.001	Loss 1.6543 (1.6637)	Prec@1 56.250 (56.961)	
Epoch: [14][194/196]	LR: 0.001	Loss 1.5840 (1.6625)	Prec@1 62.109 (56.989)	
Total train loss: 1.6625

Train time: 12.984365224838257
 * Prec@1 53.040 Prec@5 80.150 Loss 1.8477
Best acc: 53.200
--------------------------------------------------------------------------------
Test time: 15.657067775726318

Epoch: [15][38/196]	LR: 0.001	Loss 1.6465 (1.6735)	Prec@1 58.984 (56.180)	
Epoch: [15][77/196]	LR: 0.001	Loss 1.6475 (1.6717)	Prec@1 58.203 (56.495)	
Epoch: [15][116/196]	LR: 0.001	Loss 1.7598 (1.6616)	Prec@1 56.250 (56.961)	
Epoch: [15][155/196]	LR: 0.001	Loss 1.5371 (1.6617)	Prec@1 58.594 (56.914)	
Epoch: [15][194/196]	LR: 0.001	Loss 1.5947 (1.6622)	Prec@1 59.375 (56.911)	
Total train loss: 1.6624

Train time: 12.10478162765503
 * Prec@1 53.350 Prec@5 80.030 Loss 1.8418
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 14.875126600265503

Epoch: [16][38/196]	LR: 0.0001	Loss 1.6377 (1.6529)	Prec@1 59.375 (57.562)	
Epoch: [16][77/196]	LR: 0.0001	Loss 1.5195 (1.6652)	Prec@1 62.109 (56.891)	
Epoch: [16][116/196]	LR: 0.0001	Loss 1.7734 (1.6671)	Prec@1 55.078 (56.808)	
Epoch: [16][155/196]	LR: 0.0001	Loss 1.6982 (1.6683)	Prec@1 53.516 (56.793)	
Epoch: [16][194/196]	LR: 0.0001	Loss 1.7588 (1.6634)	Prec@1 56.641 (57.003)	
Total train loss: 1.6634

Train time: 12.116699457168579
 * Prec@1 53.150 Prec@5 80.070 Loss 1.8477
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 14.89529013633728

Epoch: [17][38/196]	LR: 0.0001	Loss 1.6963 (1.6561)	Prec@1 55.859 (56.991)	
Epoch: [17][77/196]	LR: 0.0001	Loss 1.5225 (1.6455)	Prec@1 61.328 (57.577)	
Epoch: [17][116/196]	LR: 0.0001	Loss 1.6719 (1.6550)	Prec@1 57.422 (57.181)	
Epoch: [17][155/196]	LR: 0.0001	Loss 1.7188 (1.6600)	Prec@1 53.125 (57.061)	
Epoch: [17][194/196]	LR: 0.0001	Loss 1.6963 (1.6620)	Prec@1 55.859 (57.013)	
Total train loss: 1.6619

Train time: 12.44840145111084
 * Prec@1 53.040 Prec@5 80.080 Loss 1.8467
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 15.21133279800415

Epoch: [18][38/196]	LR: 0.0001	Loss 1.6377 (1.6449)	Prec@1 55.859 (57.642)	
Epoch: [18][77/196]	LR: 0.0001	Loss 1.7061 (1.6570)	Prec@1 54.297 (57.202)	
Epoch: [18][116/196]	LR: 0.0001	Loss 1.5498 (1.6611)	Prec@1 57.812 (56.771)	
Epoch: [18][155/196]	LR: 0.0001	Loss 1.7637 (1.6577)	Prec@1 56.250 (57.056)	
Epoch: [18][194/196]	LR: 0.0001	Loss 1.6562 (1.6632)	Prec@1 56.641 (56.909)	
Total train loss: 1.6629

Train time: 12.789889335632324
 * Prec@1 53.050 Prec@5 80.030 Loss 1.8516
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 15.233498334884644

Epoch: [19][38/196]	LR: 0.0001	Loss 1.5254 (1.6728)	Prec@1 59.375 (56.821)	
Epoch: [19][77/196]	LR: 0.0001	Loss 1.6211 (1.6584)	Prec@1 58.203 (57.026)	
Epoch: [19][116/196]	LR: 0.0001	Loss 1.6553 (1.6620)	Prec@1 58.203 (57.088)	
Epoch: [19][155/196]	LR: 0.0001	Loss 1.6260 (1.6656)	Prec@1 55.469 (56.959)	
Epoch: [19][194/196]	LR: 0.0001	Loss 1.6699 (1.6606)	Prec@1 59.375 (56.991)	
Total train loss: 1.6606

Train time: 12.274998903274536
 * Prec@1 53.210 Prec@5 79.960 Loss 1.8467
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 15.490240573883057

Epoch: [20][38/196]	LR: 0.0001	Loss 1.6719 (1.6684)	Prec@1 56.641 (56.380)	
Epoch: [20][77/196]	LR: 0.0001	Loss 1.7031 (1.6711)	Prec@1 57.422 (56.936)	
Epoch: [20][116/196]	LR: 0.0001	Loss 1.6162 (1.6730)	Prec@1 55.469 (56.831)	
Epoch: [20][155/196]	LR: 0.0001	Loss 1.8545 (1.6676)	Prec@1 49.609 (56.956)	
Epoch: [20][194/196]	LR: 0.0001	Loss 1.6934 (1.6625)	Prec@1 55.859 (57.057)	
Total train loss: 1.6623

Train time: 12.503855466842651
 * Prec@1 53.200 Prec@5 80.100 Loss 1.8447
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 15.360192775726318

Epoch: [21][38/196]	LR: 0.0001	Loss 1.6650 (1.6688)	Prec@1 57.422 (56.571)	
Epoch: [21][77/196]	LR: 0.0001	Loss 1.6328 (1.6755)	Prec@1 55.469 (56.440)	
Epoch: [21][116/196]	LR: 0.0001	Loss 1.6582 (1.6623)	Prec@1 55.078 (56.701)	
Epoch: [21][155/196]	LR: 0.0001	Loss 1.6260 (1.6596)	Prec@1 58.594 (56.954)	
Epoch: [21][194/196]	LR: 0.0001	Loss 1.7646 (1.6629)	Prec@1 53.906 (56.943)	
Total train loss: 1.6627

Train time: 12.506690979003906
 * Prec@1 53.220 Prec@5 80.000 Loss 1.8467
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 15.910305500030518

Epoch: [22][38/196]	LR: 0.0001	Loss 1.6436 (1.6693)	Prec@1 56.250 (56.851)	
Epoch: [22][77/196]	LR: 0.0001	Loss 1.5820 (1.6778)	Prec@1 57.031 (56.746)	
Epoch: [22][116/196]	LR: 0.0001	Loss 1.6943 (1.6746)	Prec@1 58.594 (56.828)	
Epoch: [22][155/196]	LR: 0.0001	Loss 1.6797 (1.6696)	Prec@1 57.422 (56.961)	
Epoch: [22][194/196]	LR: 0.0001	Loss 1.7754 (1.6632)	Prec@1 58.594 (57.119)	
Total train loss: 1.6633

Train time: 12.997064352035522
 * Prec@1 53.190 Prec@5 80.000 Loss 1.8496
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 16.12560248374939

Epoch: [23][38/196]	LR: 0.0001	Loss 1.6738 (1.6704)	Prec@1 57.031 (56.721)	
Epoch: [23][77/196]	LR: 0.0001	Loss 1.5654 (1.6746)	Prec@1 60.938 (56.435)	
Epoch: [23][116/196]	LR: 0.0001	Loss 1.6592 (1.6787)	Prec@1 56.641 (56.367)	
Epoch: [23][155/196]	LR: 0.0001	Loss 1.6553 (1.6677)	Prec@1 58.984 (56.833)	
Epoch: [23][194/196]	LR: 0.0001	Loss 1.6074 (1.6625)	Prec@1 58.594 (57.045)	
Total train loss: 1.6625

Train time: 12.682766437530518
 * Prec@1 53.060 Prec@5 79.960 Loss 1.8467
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 15.708867073059082

Epoch: [24][38/196]	LR: 1e-05	Loss 1.7451 (1.6693)	Prec@1 56.641 (56.681)	
Epoch: [24][77/196]	LR: 1e-05	Loss 1.6973 (1.6607)	Prec@1 56.641 (57.217)	
Epoch: [24][116/196]	LR: 1e-05	Loss 1.6953 (1.6548)	Prec@1 60.156 (57.312)	
Epoch: [24][155/196]	LR: 1e-05	Loss 1.6514 (1.6628)	Prec@1 56.641 (57.101)	
Epoch: [24][194/196]	LR: 1e-05	Loss 1.5713 (1.6612)	Prec@1 59.766 (57.019)	
Total train loss: 1.6613

Train time: 13.75292420387268
 * Prec@1 53.220 Prec@5 80.000 Loss 1.8418
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 17.21274757385254

Epoch: [25][38/196]	LR: 1e-05	Loss 1.7207 (1.6643)	Prec@1 57.031 (57.402)	
Epoch: [25][77/196]	LR: 1e-05	Loss 1.5508 (1.6567)	Prec@1 58.203 (57.242)	
Epoch: [25][116/196]	LR: 1e-05	Loss 1.7109 (1.6596)	Prec@1 55.859 (57.121)	
Epoch: [25][155/196]	LR: 1e-05	Loss 1.7852 (1.6632)	Prec@1 54.297 (56.899)	
Epoch: [25][194/196]	LR: 1e-05	Loss 1.5986 (1.6633)	Prec@1 57.422 (56.945)	
Total train loss: 1.6631

Train time: 12.423156499862671
 * Prec@1 53.260 Prec@5 80.000 Loss 1.8467
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 15.75836443901062

Epoch: [26][38/196]	LR: 1e-05	Loss 1.7275 (1.6685)	Prec@1 53.516 (56.540)	
Epoch: [26][77/196]	LR: 1e-05	Loss 1.6484 (1.6621)	Prec@1 57.031 (56.776)	
Epoch: [26][116/196]	LR: 1e-05	Loss 1.6055 (1.6708)	Prec@1 59.766 (56.681)	
Epoch: [26][155/196]	LR: 1e-05	Loss 1.7275 (1.6661)	Prec@1 52.734 (56.853)	
Epoch: [26][194/196]	LR: 1e-05	Loss 1.6572 (1.6634)	Prec@1 54.297 (56.907)	
Total train loss: 1.6637

Train time: 13.531043767929077
 * Prec@1 52.980 Prec@5 79.910 Loss 1.8467
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 16.289636373519897

Epoch: [27][38/196]	LR: 1e-05	Loss 1.6738 (1.6498)	Prec@1 58.594 (57.712)	
Epoch: [27][77/196]	LR: 1e-05	Loss 1.7402 (1.6547)	Prec@1 52.344 (57.061)	
Epoch: [27][116/196]	LR: 1e-05	Loss 1.7129 (1.6568)	Prec@1 55.859 (57.015)	
Epoch: [27][155/196]	LR: 1e-05	Loss 1.8291 (1.6599)	Prec@1 51.172 (56.956)	
Epoch: [27][194/196]	LR: 1e-05	Loss 1.5742 (1.6613)	Prec@1 58.203 (57.053)	
Total train loss: 1.6614

Train time: 13.894147872924805
 * Prec@1 53.080 Prec@5 80.040 Loss 1.8477
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 18.025177717208862

Epoch: [28][38/196]	LR: 1e-05	Loss 1.7314 (1.6619)	Prec@1 57.812 (56.721)	
Epoch: [28][77/196]	LR: 1e-05	Loss 1.8262 (1.6612)	Prec@1 55.469 (56.651)	
Epoch: [28][116/196]	LR: 1e-05	Loss 1.5420 (1.6561)	Prec@1 58.203 (56.824)	
Epoch: [28][155/196]	LR: 1e-05	Loss 1.6309 (1.6572)	Prec@1 58.984 (56.986)	
Epoch: [28][194/196]	LR: 1e-05	Loss 1.7480 (1.6633)	Prec@1 57.031 (56.925)	
Total train loss: 1.6639

Train time: 14.604182243347168
 * Prec@1 53.220 Prec@5 80.030 Loss 1.8428
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 19.188761234283447

Epoch: [29][38/196]	LR: 1e-05	Loss 1.5918 (1.6441)	Prec@1 61.328 (57.652)	
Epoch: [29][77/196]	LR: 1e-05	Loss 1.6465 (1.6528)	Prec@1 58.203 (57.176)	
Epoch: [29][116/196]	LR: 1e-05	Loss 1.7480 (1.6698)	Prec@1 55.078 (56.844)	
Epoch: [29][155/196]	LR: 1e-05	Loss 1.7715 (1.6632)	Prec@1 53.516 (56.994)	
Epoch: [29][194/196]	LR: 1e-05	Loss 1.6426 (1.6638)	Prec@1 62.891 (56.979)	
Total train loss: 1.6640

Train time: 14.421443462371826
 * Prec@1 53.120 Prec@5 79.930 Loss 1.8496
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 18.123421907424927

Epoch: [30][38/196]	LR: 1e-05	Loss 1.8281 (1.6867)	Prec@1 54.688 (56.611)	
Epoch: [30][77/196]	LR: 1e-05	Loss 1.7139 (1.6682)	Prec@1 55.859 (56.976)	
Epoch: [30][116/196]	LR: 1e-05	Loss 1.5811 (1.6597)	Prec@1 57.031 (57.342)	
Epoch: [30][155/196]	LR: 1e-05	Loss 1.7432 (1.6605)	Prec@1 56.250 (57.179)	
Epoch: [30][194/196]	LR: 1e-05	Loss 1.8008 (1.6624)	Prec@1 55.078 (57.075)	
Total train loss: 1.6626

Train time: 13.591395854949951
 * Prec@1 53.250 Prec@5 79.890 Loss 1.8418
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 16.66586184501648

Epoch: [31][38/196]	LR: 1e-05	Loss 1.7832 (1.6689)	Prec@1 53.125 (57.252)	
Epoch: [31][77/196]	LR: 1e-05	Loss 1.6631 (1.6537)	Prec@1 57.422 (57.582)	
Epoch: [31][116/196]	LR: 1e-05	Loss 1.7139 (1.6502)	Prec@1 58.594 (57.676)	
Epoch: [31][155/196]	LR: 1e-05	Loss 1.7666 (1.6537)	Prec@1 54.297 (57.479)	
Epoch: [31][194/196]	LR: 1e-05	Loss 1.7432 (1.6613)	Prec@1 54.297 (57.248)	
Total train loss: 1.6617

Train time: 12.848682641983032
 * Prec@1 53.160 Prec@5 80.060 Loss 1.8447
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 16.19265127182007

Epoch: [32][38/196]	LR: 1.0000000000000002e-06	Loss 1.7021 (1.6831)	Prec@1 56.250 (56.581)	
Epoch: [32][77/196]	LR: 1.0000000000000002e-06	Loss 1.6768 (1.6812)	Prec@1 58.203 (56.520)	
Epoch: [32][116/196]	LR: 1.0000000000000002e-06	Loss 1.6602 (1.6727)	Prec@1 55.859 (56.854)	
Epoch: [32][155/196]	LR: 1.0000000000000002e-06	Loss 1.7363 (1.6656)	Prec@1 57.031 (57.111)	
Epoch: [32][194/196]	LR: 1.0000000000000002e-06	Loss 1.7725 (1.6617)	Prec@1 48.438 (57.071)	
Total train loss: 1.6619

Train time: 12.26406979560852
 * Prec@1 53.100 Prec@5 80.020 Loss 1.8447
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 16.407216548919678

Epoch: [33][38/196]	LR: 1.0000000000000002e-06	Loss 1.5400 (1.6443)	Prec@1 53.516 (57.192)	
Epoch: [33][77/196]	LR: 1.0000000000000002e-06	Loss 1.6553 (1.6449)	Prec@1 55.859 (57.262)	
Epoch: [33][116/196]	LR: 1.0000000000000002e-06	Loss 1.7383 (1.6514)	Prec@1 60.156 (57.275)	
Epoch: [33][155/196]	LR: 1.0000000000000002e-06	Loss 1.5547 (1.6542)	Prec@1 61.719 (57.192)	
Epoch: [33][194/196]	LR: 1.0000000000000002e-06	Loss 1.8086 (1.6613)	Prec@1 53.516 (56.989)	
Total train loss: 1.6614

Train time: 12.44719672203064
 * Prec@1 53.280 Prec@5 80.030 Loss 1.8447
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 15.622122287750244

Epoch: [34][38/196]	LR: 1.0000000000000002e-06	Loss 1.6055 (1.6705)	Prec@1 54.688 (56.871)	
Epoch: [34][77/196]	LR: 1.0000000000000002e-06	Loss 1.7021 (1.6655)	Prec@1 55.859 (57.126)	
Epoch: [34][116/196]	LR: 1.0000000000000002e-06	Loss 1.6846 (1.6592)	Prec@1 57.422 (57.192)	
Epoch: [34][155/196]	LR: 1.0000000000000002e-06	Loss 1.5908 (1.6607)	Prec@1 59.375 (57.121)	
Epoch: [34][194/196]	LR: 1.0000000000000002e-06	Loss 1.7197 (1.6612)	Prec@1 56.641 (57.077)	
Total train loss: 1.6618

Train time: 12.42144513130188
 * Prec@1 53.320 Prec@5 79.990 Loss 1.8447
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 15.145807981491089

Epoch: [35][38/196]	LR: 1.0000000000000002e-06	Loss 1.6846 (1.6740)	Prec@1 54.688 (56.550)	
Epoch: [35][77/196]	LR: 1.0000000000000002e-06	Loss 1.6094 (1.6680)	Prec@1 53.516 (56.706)	
Epoch: [35][116/196]	LR: 1.0000000000000002e-06	Loss 1.6611 (1.6602)	Prec@1 57.812 (57.008)	
Epoch: [35][155/196]	LR: 1.0000000000000002e-06	Loss 1.6553 (1.6577)	Prec@1 58.984 (57.029)	
Epoch: [35][194/196]	LR: 1.0000000000000002e-06	Loss 1.6475 (1.6640)	Prec@1 58.984 (56.887)	
Total train loss: 1.6642

Train time: 12.705682516098022
 * Prec@1 53.140 Prec@5 80.000 Loss 1.8477
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 16.140113353729248

Epoch: [36][38/196]	LR: 1.0000000000000002e-06	Loss 1.6680 (1.6635)	Prec@1 58.984 (57.272)	
Epoch: [36][77/196]	LR: 1.0000000000000002e-06	Loss 1.7432 (1.6590)	Prec@1 57.031 (57.086)	
Epoch: [36][116/196]	LR: 1.0000000000000002e-06	Loss 1.7236 (1.6527)	Prec@1 56.641 (57.258)	
Epoch: [36][155/196]	LR: 1.0000000000000002e-06	Loss 1.7480 (1.6629)	Prec@1 57.812 (56.891)	
Epoch: [36][194/196]	LR: 1.0000000000000002e-06	Loss 1.6191 (1.6618)	Prec@1 57.422 (56.945)	
Total train loss: 1.6620

Train time: 12.413620710372925
 * Prec@1 53.260 Prec@5 79.910 Loss 1.8447
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 18.634886264801025

Epoch: [37][38/196]	LR: 1.0000000000000002e-06	Loss 1.7314 (1.6962)	Prec@1 55.078 (56.120)	
Epoch: [37][77/196]	LR: 1.0000000000000002e-06	Loss 1.5166 (1.6704)	Prec@1 61.328 (56.971)	
Epoch: [37][116/196]	LR: 1.0000000000000002e-06	Loss 1.5312 (1.6650)	Prec@1 61.328 (56.901)	
Epoch: [37][155/196]	LR: 1.0000000000000002e-06	Loss 1.6172 (1.6638)	Prec@1 58.203 (57.014)	
Epoch: [37][194/196]	LR: 1.0000000000000002e-06	Loss 1.5068 (1.6616)	Prec@1 62.500 (56.935)	
Total train loss: 1.6618

Train time: 12.468725681304932
 * Prec@1 53.080 Prec@5 79.910 Loss 1.8477
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 15.951423406600952

Epoch: [38][38/196]	LR: 1.0000000000000002e-06	Loss 1.6299 (1.6855)	Prec@1 57.422 (56.621)	
Epoch: [38][77/196]	LR: 1.0000000000000002e-06	Loss 1.6328 (1.6650)	Prec@1 57.422 (56.901)	
Epoch: [38][116/196]	LR: 1.0000000000000002e-06	Loss 1.7383 (1.6519)	Prec@1 54.688 (57.235)	
Epoch: [38][155/196]	LR: 1.0000000000000002e-06	Loss 1.7646 (1.6545)	Prec@1 55.078 (57.279)	
Epoch: [38][194/196]	LR: 1.0000000000000002e-06	Loss 1.7764 (1.6614)	Prec@1 53.516 (57.073)	
Total train loss: 1.6614

Train time: 12.646424770355225
 * Prec@1 53.320 Prec@5 80.020 Loss 1.8467
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 15.703887224197388

Epoch: [39][38/196]	LR: 1.0000000000000002e-06	Loss 1.6084 (1.6788)	Prec@1 57.812 (56.711)	
Epoch: [39][77/196]	LR: 1.0000000000000002e-06	Loss 1.6836 (1.6723)	Prec@1 57.031 (56.976)	
Epoch: [39][116/196]	LR: 1.0000000000000002e-06	Loss 1.7109 (1.6671)	Prec@1 54.297 (57.015)	
Epoch: [39][155/196]	LR: 1.0000000000000002e-06	Loss 1.5195 (1.6661)	Prec@1 62.500 (57.119)	
Epoch: [39][194/196]	LR: 1.0000000000000002e-06	Loss 1.6445 (1.6613)	Prec@1 61.719 (57.262)	
Total train loss: 1.6617

Train time: 13.129197835922241
 * Prec@1 53.230 Prec@5 80.110 Loss 1.8418
Best acc: 53.350
--------------------------------------------------------------------------------
Test time: 16.48608660697937

