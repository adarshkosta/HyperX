
      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.02
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 5
Savedir:  ../pretrained_models/frozen/x64-8b/rram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/train/relu5
Test path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/test/relu5
ResNet18(
  (conv6): QConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv1): Sequential(
    (0): QConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu6): ReLU(inplace=True)
  (conv7): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu7): ReLU(inplace=True)
  (conv8): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): QConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): QConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): QConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): QConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 8.500 Prec@5 42.850 Loss 2.3379
Avg Loading time: 3.4774 seconds
Avg Batch time: 3.5198 seconds

Pre-trained Prec@1 with 5 layers frozen: 8.5 	 Loss: 2.337890625

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.02	DT: 0.000 (2.504)	BT: 0.058 (2.572)	Loss 0.6270 (0.9998)	Prec@1 82.812 (71.394)	
Epoch: [0][155/391]	LR: 0.02	DT: 0.000 (2.306)	BT: 0.067 (2.372)	Loss 0.4956 (0.7859)	Prec@1 82.812 (77.194)	
Epoch: [0][233/391]	LR: 0.02	DT: 7.603 (2.604)	BT: 7.681 (2.671)	Loss 0.5171 (0.7250)	Prec@1 85.938 (78.319)	
Epoch: [0][311/391]	LR: 0.02	DT: 0.000 (2.777)	BT: 0.067 (2.844)	Loss 0.6431 (0.6826)	Prec@1 78.125 (79.272)	
Epoch: [0][389/391]	LR: 0.02	DT: 0.000 (3.007)	BT: 0.057 (3.074)	Loss 0.6489 (0.6613)	Prec@1 73.438 (79.603)	
Total train loss: 0.6612
Avg Loading time: 2.9988 seconds
Avg Batch time: 3.0664 seconds

Train time: 1199.0372111797333
 * Prec@1 25.700 Prec@5 69.240 Loss 2.1191
Avg Loading time: 4.2179 seconds
Avg Batch time: 4.2504 seconds

Best acc: 25.700
--------------------------------------------------------------------------------
Test time: 336.8573565483093

Epoch: [1][77/391]	LR: 0.02	DT: 0.290 (3.860)	BT: 0.352 (3.930)	Loss 0.6123 (0.6315)	Prec@1 78.906 (78.856)	
Epoch: [1][155/391]	LR: 0.02	DT: 1.026 (3.658)	BT: 1.085 (3.726)	Loss 0.5957 (0.5926)	Prec@1 78.125 (80.073)	
Epoch: [1][233/391]	LR: 0.02	DT: 0.000 (3.738)	BT: 0.063 (3.804)	Loss 0.4956 (0.5896)	Prec@1 80.469 (80.142)	
Epoch: [1][311/391]	LR: 0.02	DT: 0.000 (3.673)	BT: 0.053 (3.739)	Loss 0.5127 (0.5879)	Prec@1 82.812 (80.206)	
Epoch: [1][389/391]	LR: 0.02	DT: 0.000 (3.683)	BT: 0.060 (3.749)	Loss 0.6514 (0.5870)	Prec@1 77.344 (80.188)	
Total train loss: 0.5869
Avg Loading time: 3.6735 seconds
Avg Batch time: 3.7395 seconds

Train time: 1462.231493473053
 * Prec@1 50.120 Prec@5 88.500 Loss 1.5518
Avg Loading time: 3.7599 seconds
Avg Batch time: 3.7877 seconds

Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 300.29825615882874

Epoch: [2][77/391]	LR: 0.02	DT: 0.000 (3.791)	BT: 0.054 (3.856)	Loss 0.4893 (0.5890)	Prec@1 78.906 (80.038)	
Epoch: [2][155/391]	LR: 0.02	DT: 0.000 (3.803)	BT: 0.077 (3.869)	Loss 0.5542 (0.5903)	Prec@1 85.156 (79.833)	
Epoch: [2][233/391]	LR: 0.02	DT: 0.000 (3.787)	BT: 0.063 (3.852)	Loss 0.5288 (0.5832)	Prec@1 80.469 (80.212)	
Epoch: [2][311/391]	LR: 0.02	DT: 0.000 (3.471)	BT: 0.053 (3.536)	Loss 0.4285 (0.5744)	Prec@1 85.938 (80.496)	
Epoch: [2][389/391]	LR: 0.02	DT: 0.000 (3.117)	BT: 0.054 (3.182)	Loss 0.5029 (0.5674)	Prec@1 82.812 (80.683)	
Total train loss: 0.5673
Avg Loading time: 3.1092 seconds
Avg Batch time: 3.1735 seconds

Train time: 1240.9240443706512
 * Prec@1 64.770 Prec@5 96.020 Loss 1.1084
Avg Loading time: 1.6580 seconds
Avg Batch time: 1.6849 seconds

Best acc: 64.770
--------------------------------------------------------------------------------
Test time: 134.50590419769287

Epoch: [3][77/391]	LR: 0.02	DT: 0.000 (2.572)	BT: 0.053 (2.635)	Loss 0.5747 (0.5889)	Prec@1 83.594 (79.938)	
Epoch: [3][155/391]	LR: 0.02	DT: 0.000 (2.660)	BT: 0.063 (2.725)	Loss 0.5493 (0.6033)	Prec@1 80.469 (79.227)	
Epoch: [3][233/391]	LR: 0.02	DT: 2.961 (2.863)	BT: 3.028 (2.928)	Loss 0.7598 (0.5996)	Prec@1 75.781 (79.193)	
Epoch: [3][311/391]	LR: 0.02	DT: 0.000 (2.921)	BT: 0.061 (2.986)	Loss 0.4893 (0.5871)	Prec@1 85.156 (79.662)	
Epoch: [3][389/391]	LR: 0.02	DT: 0.000 (3.029)	BT: 0.052 (3.094)	Loss 0.6416 (0.5854)	Prec@1 75.781 (79.778)	
Total train loss: 0.5856
Avg Loading time: 3.0209 seconds
Avg Batch time: 3.0861 seconds

Train time: 1206.7354052066803
 * Prec@1 46.480 Prec@5 90.520 Loss 1.7588
Avg Loading time: 3.8610 seconds
Avg Batch time: 3.8878 seconds

Best acc: 64.770
--------------------------------------------------------------------------------
Test time: 307.74783968925476

Epoch: [4][77/391]	LR: 0.02	DT: 0.000 (4.047)	BT: 0.054 (4.112)	Loss 0.6577 (0.5235)	Prec@1 76.562 (81.801)	
Epoch: [4][155/391]	LR: 0.02	DT: 0.963 (3.975)	BT: 1.025 (4.040)	Loss 0.5200 (0.5429)	Prec@1 84.375 (81.195)	
Epoch: [4][233/391]	LR: 0.02	DT: 3.175 (3.932)	BT: 3.244 (3.997)	Loss 0.8013 (0.5893)	Prec@1 71.875 (79.581)	
Epoch: [4][311/391]	LR: 0.02	DT: 0.000 (3.848)	BT: 0.053 (3.913)	Loss 0.9634 (0.6245)	Prec@1 70.312 (78.353)	
Epoch: [4][389/391]	LR: 0.02	DT: 0.000 (3.858)	BT: 0.055 (3.924)	Loss 0.6899 (0.6273)	Prec@1 81.250 (78.239)	
Total train loss: 0.6276
Avg Loading time: 3.8485 seconds
Avg Batch time: 3.9141 seconds

Train time: 1530.4982750415802
 * Prec@1 9.500 Prec@5 54.460 Loss inf
Avg Loading time: 3.4900 seconds
Avg Batch time: 3.5182 seconds

Best acc: 64.770
--------------------------------------------------------------------------------
Test time: 278.630490064621

Epoch: [5][77/391]	LR: 0.02	DT: 0.000 (3.396)	BT: 0.059 (3.464)	Loss 0.8916 (0.7791)	Prec@1 71.875 (73.277)	
Epoch: [5][155/391]	LR: 0.02	DT: 0.000 (3.165)	BT: 0.062 (3.233)	Loss 0.5732 (0.7619)	Prec@1 82.812 (73.868)	
Epoch: [5][233/391]	LR: 0.02	DT: 0.023 (2.857)	BT: 0.087 (2.923)	Loss 0.7290 (0.7323)	Prec@1 76.562 (74.886)	
Epoch: [5][311/391]	LR: 0.02	DT: 0.000 (2.532)	BT: 0.063 (2.597)	Loss 0.6270 (0.7141)	Prec@1 78.125 (75.426)	
Epoch: [5][389/391]	LR: 0.02	DT: 1.181 (2.452)	BT: 1.244 (2.518)	Loss 0.5645 (0.6998)	Prec@1 82.812 (75.781)	
Total train loss: 0.6997
Avg Loading time: 2.4458 seconds
Avg Batch time: 2.5114 seconds

Train time: 982.0561337471008
 * Prec@1 64.350 Prec@5 96.390 Loss 1.0146
Avg Loading time: 3.0808 seconds
Avg Batch time: 3.1089 seconds

Best acc: 64.770
--------------------------------------------------------------------------------
Test time: 246.24055552482605

Epoch: [6][77/391]	LR: 0.02	DT: 0.000 (3.724)	BT: 0.062 (3.789)	Loss 0.5869 (0.5893)	Prec@1 79.688 (80.158)	
Epoch: [6][155/391]	LR: 0.02	DT: 0.000 (3.800)	BT: 0.054 (3.866)	Loss 0.5205 (0.5913)	Prec@1 81.250 (79.828)	
Epoch: [6][233/391]	LR: 0.02	DT: 0.000 (3.908)	BT: 0.064 (3.973)	Loss 0.6445 (0.5878)	Prec@1 81.250 (80.101)	
Epoch: [6][311/391]	LR: 0.02	DT: 0.000 (3.816)	BT: 0.053 (3.880)	Loss 0.7056 (0.5858)	Prec@1 77.344 (80.071)	
Epoch: [6][389/391]	LR: 0.02	DT: 0.000 (3.820)	BT: 0.053 (3.884)	Loss 0.5479 (0.5863)	Prec@1 78.906 (80.040)	
Total train loss: 0.5861
Avg Loading time: 3.8102 seconds
Avg Batch time: 3.8745 seconds

Train time: 1515.006413936615
 * Prec@1 57.340 Prec@5 94.430 Loss 1.2656
Avg Loading time: 3.9039 seconds
Avg Batch time: 3.9328 seconds

Best acc: 64.770
--------------------------------------------------------------------------------
Test time: 311.30627703666687

Epoch: [7][77/391]	LR: 0.02	DT: 0.000 (3.720)	BT: 0.053 (3.784)	Loss 0.3474 (0.5480)	Prec@1 88.281 (81.160)	
Epoch: [7][155/391]	LR: 0.02	DT: 0.000 (3.486)	BT: 0.062 (3.551)	Loss 0.5947 (0.5548)	Prec@1 79.688 (80.929)	
Epoch: [7][233/391]	LR: 0.02	DT: 1.915 (3.430)	BT: 1.987 (3.495)	Loss 0.4956 (0.6006)	Prec@1 84.375 (79.370)	
Epoch: [7][311/391]	LR: 0.02	DT: 0.000 (3.324)	BT: 0.057 (3.389)	Loss 0.6670 (0.6071)	Prec@1 78.906 (79.044)	
Epoch: [7][389/391]	LR: 0.02	DT: 0.000 (3.345)	BT: 0.052 (3.409)	Loss 0.7295 (0.6124)	Prec@1 72.656 (78.898)	
Total train loss: 0.6124
Avg Loading time: 3.3367 seconds
Avg Batch time: 3.4005 seconds

Train time: 1329.6737260818481
 * Prec@1 67.950 Prec@5 95.740 Loss 0.9888
Avg Loading time: 3.3194 seconds
Avg Batch time: 3.3490 seconds

Best acc: 67.950
--------------------------------------------------------------------------------
Test time: 265.6705152988434

Epoch: [8][77/391]	LR: 0.02	DT: 0.000 (2.894)	BT: 0.057 (2.961)	Loss 0.6782 (0.6044)	Prec@1 76.562 (79.147)	
Epoch: [8][155/391]	LR: 0.02	DT: 0.000 (2.579)	BT: 0.063 (2.645)	Loss 0.6953 (0.5961)	Prec@1 74.219 (79.307)	
Epoch: [8][233/391]	LR: 0.02	DT: 3.326 (2.819)	BT: 3.399 (2.885)	Loss 0.6060 (0.5944)	Prec@1 81.250 (79.427)	
Epoch: [8][311/391]	LR: 0.02	DT: 0.000 (2.905)	BT: 0.053 (2.972)	Loss 0.5981 (0.5931)	Prec@1 80.469 (79.457)	
Epoch: [8][389/391]	LR: 0.02	DT: 0.000 (2.986)	BT: 0.057 (3.054)	Loss 0.6880 (0.6046)	Prec@1 77.344 (79.050)	
Total train loss: 0.6049
Avg Loading time: 2.9784 seconds
Avg Batch time: 3.0460 seconds

Train time: 1191.0722360610962
 * Prec@1 23.480 Prec@5 72.200 Loss inf
Avg Loading time: 3.5142 seconds
Avg Batch time: 3.5461 seconds

Best acc: 67.950
--------------------------------------------------------------------------------
Test time: 280.7708008289337

Epoch: [9][77/391]	LR: 0.02	DT: 0.000 (3.604)	BT: 0.057 (3.672)	Loss 0.7676 (0.6945)	Prec@1 73.438 (75.531)	
Epoch: [9][155/391]	LR: 0.02	DT: 0.000 (3.323)	BT: 0.067 (3.392)	Loss 0.5747 (0.6890)	Prec@1 76.562 (75.706)	
Epoch: [9][233/391]	LR: 0.02	DT: 0.000 (3.187)	BT: 0.067 (3.255)	Loss 0.7686 (0.6845)	Prec@1 75.000 (75.865)	
Epoch: [9][311/391]	LR: 0.02	DT: 0.143 (3.095)	BT: 0.201 (3.163)	Loss 0.8662 (0.6788)	Prec@1 75.000 (76.107)	
Epoch: [9][389/391]	LR: 0.02	DT: 0.000 (3.036)	BT: 0.057 (3.103)	Loss 0.7842 (0.6713)	Prec@1 66.406 (76.420)	
Total train loss: 0.6713
Avg Loading time: 3.0278 seconds
Avg Batch time: 3.0952 seconds

Train time: 1210.3120515346527
 * Prec@1 29.550 Prec@5 85.220 Loss 5.3203
Avg Loading time: 3.2634 seconds
Avg Batch time: 3.2955 seconds

Best acc: 67.950
--------------------------------------------------------------------------------
Test time: 260.9700481891632

Epoch: [10][77/391]	LR: 0.004	DT: 0.000 (3.385)	BT: 0.067 (3.453)	Loss 0.6973 (0.6147)	Prec@1 75.781 (79.097)	
Epoch: [10][155/391]	LR: 0.004	DT: 0.000 (3.415)	BT: 0.068 (3.484)	Loss 0.6714 (0.5919)	Prec@1 77.344 (79.662)	
Epoch: [10][233/391]	LR: 0.004	DT: 1.559 (3.451)	BT: 1.632 (3.521)	Loss 0.6157 (0.5880)	Prec@1 75.000 (79.684)	
Epoch: [10][311/391]	LR: 0.004	DT: 0.000 (3.345)	BT: 0.057 (3.414)	Loss 0.6143 (0.5834)	Prec@1 79.688 (79.850)	
Epoch: [10][389/391]	LR: 0.004	DT: 0.000 (3.153)	BT: 0.057 (3.222)	Loss 0.5381 (0.5812)	Prec@1 82.812 (79.924)	
Total train loss: 0.5813
Avg Loading time: 3.1452 seconds
Avg Batch time: 3.2136 seconds

Train time: 1256.5985186100006
 * Prec@1 78.920 Prec@5 98.880 Loss 0.6035
Avg Loading time: 2.5878 seconds
Avg Batch time: 2.6186 seconds

Best acc: 78.920
--------------------------------------------------------------------------------
Test time: 208.01008415222168

Epoch: [11][77/391]	LR: 0.004	DT: 0.000 (1.954)	BT: 0.058 (2.020)	Loss 0.5171 (0.5543)	Prec@1 83.594 (80.960)	
Epoch: [11][155/391]	LR: 0.004	DT: 0.000 (2.588)	BT: 0.072 (2.656)	Loss 0.5474 (0.5594)	Prec@1 80.469 (80.774)	
Epoch: [11][233/391]	LR: 0.004	DT: 4.094 (2.557)	BT: 4.166 (2.624)	Loss 0.4602 (0.5577)	Prec@1 83.594 (80.769)	
Epoch: [11][311/391]	LR: 0.004	DT: 0.077 (2.509)	BT: 0.135 (2.576)	Loss 0.6719 (0.5599)	Prec@1 78.125 (80.679)	
Epoch: [11][389/391]	LR: 0.004	DT: 0.000 (2.569)	BT: 0.061 (2.637)	Loss 0.4883 (0.5623)	Prec@1 78.906 (80.461)	
Total train loss: 0.5623
Avg Loading time: 2.5629 seconds
Avg Batch time: 2.6304 seconds

Train time: 1028.5431423187256
 * Prec@1 79.020 Prec@5 98.960 Loss 0.5923
Avg Loading time: 3.0422 seconds
Avg Batch time: 3.0738 seconds

Best acc: 79.020
--------------------------------------------------------------------------------
Test time: 243.94402718544006

Epoch: [12][77/391]	LR: 0.004	DT: 0.000 (3.061)	BT: 0.057 (3.127)	Loss 0.4316 (0.5509)	Prec@1 85.156 (81.350)	
Epoch: [12][155/391]	LR: 0.004	DT: 0.161 (3.138)	BT: 0.217 (3.204)	Loss 0.6177 (0.5528)	Prec@1 79.688 (81.250)	
Epoch: [12][233/391]	LR: 0.004	DT: 0.000 (3.250)	BT: 0.070 (3.316)	Loss 0.6465 (0.5573)	Prec@1 79.688 (80.983)	
Epoch: [12][311/391]	LR: 0.004	DT: 0.000 (3.233)	BT: 0.057 (3.298)	Loss 0.5664 (0.5590)	Prec@1 83.594 (80.977)	
Epoch: [12][389/391]	LR: 0.004	DT: 0.000 (3.273)	BT: 0.056 (3.339)	Loss 0.5435 (0.5568)	Prec@1 82.031 (81.040)	
Total train loss: 0.5567
Avg Loading time: 3.2647 seconds
Avg Batch time: 3.3303 seconds

Train time: 1302.2175323963165
 * Prec@1 79.680 Prec@5 98.980 Loss 0.5806
Avg Loading time: 3.4755 seconds
Avg Batch time: 3.5065 seconds

Best acc: 79.680
--------------------------------------------------------------------------------
Test time: 278.1611611843109

Epoch: [13][77/391]	LR: 0.004	DT: 0.000 (3.489)	BT: 0.060 (3.557)	Loss 0.6880 (0.5448)	Prec@1 78.906 (81.430)	
Epoch: [13][155/391]	LR: 0.004	DT: 2.834 (3.468)	BT: 2.911 (3.537)	Loss 0.4814 (0.5480)	Prec@1 82.812 (81.265)	
Epoch: [13][233/391]	LR: 0.004	DT: 0.000 (3.338)	BT: 0.069 (3.407)	Loss 0.5229 (0.5492)	Prec@1 78.906 (81.273)	
Epoch: [13][311/391]	LR: 0.004	DT: 1.690 (3.058)	BT: 1.763 (3.127)	Loss 0.5107 (0.5501)	Prec@1 85.938 (81.197)	
Epoch: [13][389/391]	LR: 0.004	DT: 0.000 (2.800)	BT: 0.058 (2.868)	Loss 0.5112 (0.5500)	Prec@1 80.469 (81.228)	
Total train loss: 0.5499
Avg Loading time: 2.7928 seconds
Avg Batch time: 2.8609 seconds

Train time: 1118.6877391338348
 * Prec@1 79.760 Prec@5 98.940 Loss 0.5884
Avg Loading time: 2.3624 seconds
Avg Batch time: 2.3943 seconds

Best acc: 79.760
--------------------------------------------------------------------------------
Test time: 190.29197812080383

Epoch: [14][77/391]	LR: 0.004	DT: 0.000 (3.104)	BT: 0.058 (3.170)	Loss 0.7144 (0.5523)	Prec@1 77.344 (81.250)	
Epoch: [14][155/391]	LR: 0.004	DT: 0.000 (2.860)	BT: 0.058 (2.926)	Loss 0.4031 (0.5453)	Prec@1 86.719 (81.400)	
Epoch: [14][233/391]	LR: 0.004	DT: 0.000 (2.887)	BT: 0.068 (2.954)	Loss 0.5444 (0.5483)	Prec@1 82.812 (81.333)	
Epoch: [14][311/391]	LR: 0.004	DT: 1.186 (2.922)	BT: 1.251 (2.989)	Loss 0.4976 (0.5465)	Prec@1 81.250 (81.358)	
Epoch: [14][389/391]	LR: 0.004	DT: 0.000 (2.998)	BT: 0.059 (3.065)	Loss 0.3977 (0.5503)	Prec@1 86.719 (81.200)	
Total train loss: 0.5501
Avg Loading time: 2.9905 seconds
Avg Batch time: 3.0569 seconds

Train time: 1195.3360080718994
 * Prec@1 79.820 Prec@5 99.060 Loss 0.5864
Avg Loading time: 3.4717 seconds
Avg Batch time: 3.5034 seconds

Best acc: 79.820
--------------------------------------------------------------------------------
Test time: 277.92862153053284

Epoch: [15][77/391]	LR: 0.004	DT: 0.000 (3.492)	BT: 0.060 (3.561)	Loss 0.5356 (0.5499)	Prec@1 79.688 (80.609)	
Epoch: [15][155/391]	LR: 0.004	DT: 3.355 (3.485)	BT: 3.430 (3.555)	Loss 0.7393 (0.5436)	Prec@1 69.531 (81.140)	
Epoch: [15][233/391]	LR: 0.004	DT: 7.901 (3.504)	BT: 7.965 (3.574)	Loss 0.4331 (0.5443)	Prec@1 86.719 (81.147)	
Epoch: [15][311/391]	LR: 0.004	DT: 0.000 (3.423)	BT: 0.052 (3.492)	Loss 0.6582 (0.5460)	Prec@1 75.781 (81.085)	
Epoch: [15][389/391]	LR: 0.004	DT: 0.000 (3.372)	BT: 0.061 (3.440)	Loss 0.4731 (0.5460)	Prec@1 83.594 (81.104)	
Total train loss: 0.5461
Avg Loading time: 3.3638 seconds
Avg Batch time: 3.4314 seconds

Train time: 1341.751981496811
 * Prec@1 78.980 Prec@5 98.980 Loss 0.6045
Avg Loading time: 2.2043 seconds
Avg Batch time: 2.2340 seconds

Best acc: 79.820
--------------------------------------------------------------------------------
Test time: 177.11473393440247

Epoch: [16][77/391]	LR: 0.004	DT: 0.000 (2.929)	BT: 0.059 (2.997)	Loss 0.4690 (0.5262)	Prec@1 84.375 (81.991)	
Epoch: [16][155/391]	LR: 0.004	DT: 0.000 (2.746)	BT: 0.068 (2.813)	Loss 0.5610 (0.5374)	Prec@1 82.812 (81.485)	
Epoch: [16][233/391]	LR: 0.004	DT: 2.052 (2.546)	BT: 2.127 (2.612)	Loss 0.6528 (0.5430)	Prec@1 78.125 (81.320)	
Epoch: [16][311/391]	LR: 0.004	DT: 0.000 (2.384)	BT: 0.058 (2.450)	Loss 0.5298 (0.5420)	Prec@1 82.031 (81.285)	
Epoch: [16][389/391]	LR: 0.004	DT: 0.000 (2.443)	BT: 0.058 (2.510)	Loss 0.5947 (0.5409)	Prec@1 75.781 (81.294)	
Total train loss: 0.5411
Avg Loading time: 2.4371 seconds
Avg Batch time: 2.5032 seconds

Train time: 978.8297784328461
 * Prec@1 79.430 Prec@5 99.010 Loss 0.5879
Avg Loading time: 3.3087 seconds
Avg Batch time: 3.3407 seconds

Best acc: 79.820
--------------------------------------------------------------------------------
Test time: 264.5556516647339

Epoch: [17][77/391]	LR: 0.004	DT: 0.000 (3.125)	BT: 0.058 (3.194)	Loss 0.4634 (0.5377)	Prec@1 84.375 (81.220)	
Epoch: [17][155/391]	LR: 0.004	DT: 0.000 (3.201)	BT: 0.058 (3.269)	Loss 0.5908 (0.5483)	Prec@1 78.906 (80.950)	
Epoch: [17][233/391]	LR: 0.004	DT: 0.000 (3.399)	BT: 0.073 (3.466)	Loss 0.5703 (0.5501)	Prec@1 82.031 (80.916)	
Epoch: [17][311/391]	LR: 0.004	DT: 0.000 (3.410)	BT: 0.052 (3.476)	Loss 0.4390 (0.5491)	Prec@1 86.719 (81.020)	
Epoch: [17][389/391]	LR: 0.004	DT: 0.000 (3.456)	BT: 0.058 (3.522)	Loss 0.6055 (0.5514)	Prec@1 79.688 (81.024)	
Total train loss: 0.5516
Avg Loading time: 3.4475 seconds
Avg Batch time: 3.5134 seconds

Train time: 1373.8118743896484
 * Prec@1 79.600 Prec@5 99.080 Loss 0.5884
Avg Loading time: 3.7198 seconds
Avg Batch time: 3.7528 seconds

Best acc: 79.820
--------------------------------------------------------------------------------
Test time: 297.07037234306335

Epoch: [18][77/391]	LR: 0.004	DT: 0.000 (3.485)	BT: 0.058 (3.554)	Loss 0.5444 (0.5337)	Prec@1 80.469 (81.460)	
Epoch: [18][155/391]	LR: 0.004	DT: 2.204 (3.350)	BT: 2.279 (3.420)	Loss 0.5952 (0.5368)	Prec@1 78.906 (81.485)	
Epoch: [18][233/391]	LR: 0.004	DT: 7.044 (3.317)	BT: 7.120 (3.388)	Loss 0.4338 (0.5383)	Prec@1 85.156 (81.447)	
Epoch: [18][311/391]	LR: 0.004	DT: 0.000 (3.236)	BT: 0.070 (3.307)	Loss 0.6777 (0.5400)	Prec@1 75.781 (81.388)	
Epoch: [18][389/391]	LR: 0.004	DT: 0.000 (3.252)	BT: 0.067 (3.322)	Loss 0.6035 (0.5416)	Prec@1 80.469 (81.368)	
Total train loss: 0.5417
Avg Loading time: 3.2432 seconds
Avg Batch time: 3.3141 seconds

Train time: 1295.8892409801483
 * Prec@1 79.780 Prec@5 99.050 Loss 0.5806
Avg Loading time: 3.2515 seconds
Avg Batch time: 3.2834 seconds

Best acc: 79.820
--------------------------------------------------------------------------------
Test time: 260.0181887149811

Epoch: [19][77/391]	LR: 0.004	DT: 0.000 (2.627)	BT: 0.064 (2.697)	Loss 0.5864 (0.5480)	Prec@1 78.906 (81.000)	
Epoch: [19][155/391]	LR: 0.004	DT: 2.186 (2.529)	BT: 2.258 (2.599)	Loss 0.4519 (0.5501)	Prec@1 85.156 (80.894)	
Epoch: [19][233/391]	LR: 0.004	DT: 0.000 (2.698)	BT: 0.073 (2.768)	Loss 0.4629 (0.5462)	Prec@1 86.719 (81.150)	
Epoch: [19][311/391]	LR: 0.004	DT: 0.000 (2.797)	BT: 0.056 (2.867)	Loss 0.5361 (0.5422)	Prec@1 81.250 (81.333)	
Epoch: [19][389/391]	LR: 0.004	DT: 0.000 (2.847)	BT: 0.064 (2.917)	Loss 0.5420 (0.5421)	Prec@1 79.688 (81.340)	
Total train loss: 0.5425
Avg Loading time: 2.8397 seconds
Avg Batch time: 2.9097 seconds

Train time: 1137.7548413276672
 * Prec@1 79.690 Prec@5 98.950 Loss 0.5869
Avg Loading time: 3.0017 seconds
Avg Batch time: 3.0326 seconds

Best acc: 79.820
--------------------------------------------------------------------------------
Test time: 240.20994758605957

Epoch: [20][77/391]	LR: 0.0008	DT: 0.587 (3.437)	BT: 0.649 (3.508)	Loss 0.6367 (0.5360)	Prec@1 78.906 (81.430)	
Epoch: [20][155/391]	LR: 0.0008	DT: 0.302 (3.251)	BT: 0.371 (3.322)	Loss 0.5068 (0.5316)	Prec@1 82.031 (81.681)	
Epoch: [20][233/391]	LR: 0.0008	DT: 0.000 (3.105)	BT: 0.064 (3.174)	Loss 0.5488 (0.5268)	Prec@1 80.469 (81.831)	
Epoch: [20][311/391]	LR: 0.0008	DT: 0.000 (3.003)	BT: 0.054 (3.071)	Loss 0.3738 (0.5252)	Prec@1 89.844 (81.906)	
Epoch: [20][389/391]	LR: 0.0008	DT: 0.000 (2.989)	BT: 0.055 (3.057)	Loss 0.4038 (0.5275)	Prec@1 86.719 (81.837)	
Total train loss: 0.5276
Avg Loading time: 2.9810 seconds
Avg Batch time: 3.0489 seconds

Train time: 1192.2065608501434
 * Prec@1 80.330 Prec@5 99.050 Loss 0.5728
Avg Loading time: 3.1926 seconds
Avg Batch time: 3.2241 seconds

Best acc: 80.330
--------------------------------------------------------------------------------
Test time: 255.80956602096558

Epoch: [21][77/391]	LR: 0.0008	DT: 0.000 (3.382)	BT: 0.057 (3.451)	Loss 0.4583 (0.5288)	Prec@1 82.812 (81.841)	
Epoch: [21][155/391]	LR: 0.0008	DT: 1.046 (3.450)	BT: 1.111 (3.520)	Loss 0.4338 (0.5284)	Prec@1 85.156 (81.976)	
Epoch: [21][233/391]	LR: 0.0008	DT: 0.000 (3.461)	BT: 0.068 (3.531)	Loss 0.5083 (0.5276)	Prec@1 85.156 (81.888)	
Epoch: [21][311/391]	LR: 0.0008	DT: 0.000 (3.378)	BT: 0.054 (3.447)	Loss 0.5381 (0.5313)	Prec@1 83.594 (81.813)	
Epoch: [21][389/391]	LR: 0.0008	DT: 0.000 (3.185)	BT: 0.058 (3.253)	Loss 0.5093 (0.5295)	Prec@1 84.375 (81.873)	
Total train loss: 0.5295
Avg Loading time: 3.1765 seconds
Avg Batch time: 3.2447 seconds

Train time: 1268.7537651062012
 * Prec@1 80.070 Prec@5 98.980 Loss 0.5742
Avg Loading time: 2.4985 seconds
Avg Batch time: 2.5279 seconds

Best acc: 80.330
--------------------------------------------------------------------------------
Test time: 200.35228991508484

Epoch: [22][77/391]	LR: 0.0008	DT: 0.000 (2.674)	BT: 0.059 (2.740)	Loss 0.6587 (0.5222)	Prec@1 77.344 (82.382)	
Epoch: [22][155/391]	LR: 0.0008	DT: 0.000 (2.779)	BT: 0.064 (2.844)	Loss 0.4282 (0.5270)	Prec@1 82.812 (81.961)	
Epoch: [22][233/391]	LR: 0.0008	DT: 0.000 (2.807)	BT: 0.069 (2.873)	Loss 0.4873 (0.5253)	Prec@1 82.812 (81.974)	
Epoch: [22][311/391]	LR: 0.0008	DT: 0.000 (2.815)	BT: 0.058 (2.881)	Loss 0.4795 (0.5256)	Prec@1 82.812 (81.979)	
Epoch: [22][389/391]	LR: 0.0008	DT: 0.000 (2.811)	BT: 0.057 (2.878)	Loss 0.6187 (0.5255)	Prec@1 80.469 (81.989)	
Total train loss: 0.5257
Avg Loading time: 2.8043 seconds
Avg Batch time: 2.8703 seconds

Train time: 1122.3788981437683
 * Prec@1 80.410 Prec@5 99.050 Loss 0.5713
Avg Loading time: 3.0019 seconds
Avg Batch time: 3.0338 seconds

Best acc: 80.410
--------------------------------------------------------------------------------
Test time: 240.79163455963135

Epoch: [23][77/391]	LR: 0.0008	DT: 0.000 (3.047)	BT: 0.062 (3.113)	Loss 0.6245 (0.5189)	Prec@1 78.125 (81.821)	
Epoch: [23][155/391]	LR: 0.0008	DT: 0.000 (3.112)	BT: 0.068 (3.179)	Loss 0.4382 (0.5238)	Prec@1 86.719 (81.826)	
Epoch: [23][233/391]	LR: 0.0008	DT: 0.000 (3.185)	BT: 0.077 (3.253)	Loss 0.4731 (0.5265)	Prec@1 84.375 (81.824)	
Epoch: [23][311/391]	LR: 0.0008	DT: 0.000 (3.170)	BT: 0.057 (3.238)	Loss 0.6030 (0.5298)	Prec@1 77.344 (81.716)	
Epoch: [23][389/391]	LR: 0.0008	DT: 0.000 (3.216)	BT: 0.057 (3.283)	Loss 0.6152 (0.5271)	Prec@1 74.219 (81.877)	
Total train loss: 0.5269
Avg Loading time: 3.2077 seconds
Avg Batch time: 3.2748 seconds

Train time: 1280.518619775772
 * Prec@1 80.090 Prec@5 98.990 Loss 0.5703
Avg Loading time: 3.5383 seconds
Avg Batch time: 3.5706 seconds

Best acc: 80.410
--------------------------------------------------------------------------------
Test time: 282.71132373809814

Epoch: [24][77/391]	LR: 0.0008	DT: 0.000 (3.424)	BT: 0.057 (3.493)	Loss 0.5820 (0.5201)	Prec@1 81.250 (82.322)	
Epoch: [24][155/391]	LR: 0.0008	DT: 1.214 (3.437)	BT: 1.289 (3.507)	Loss 0.5122 (0.5267)	Prec@1 82.812 (81.921)	
Epoch: [24][233/391]	LR: 0.0008	DT: 0.000 (3.271)	BT: 0.064 (3.340)	Loss 0.4541 (0.5286)	Prec@1 87.500 (81.858)	
Epoch: [24][311/391]	LR: 0.0008	DT: 0.000 (3.018)	BT: 0.057 (3.088)	Loss 0.4473 (0.5268)	Prec@1 85.156 (81.816)	
Epoch: [24][389/391]	LR: 0.0008	DT: 0.000 (2.760)	BT: 0.057 (2.829)	Loss 0.4958 (0.5266)	Prec@1 85.156 (81.865)	
Total train loss: 0.5268
Avg Loading time: 2.7526 seconds
Avg Batch time: 2.8214 seconds

Train time: 1103.239014863968
 * Prec@1 80.490 Prec@5 98.990 Loss 0.5713
Avg Loading time: 2.1502 seconds
Avg Batch time: 2.1800 seconds

Best acc: 80.490
--------------------------------------------------------------------------------
Test time: 173.3609344959259

Epoch: [25][77/391]	LR: 0.0008	DT: 0.000 (2.876)	BT: 0.058 (2.945)	Loss 0.5444 (0.5284)	Prec@1 75.781 (81.921)	
Epoch: [25][155/391]	LR: 0.0008	DT: 0.323 (2.890)	BT: 0.388 (2.959)	Loss 0.5854 (0.5234)	Prec@1 78.906 (82.086)	
Epoch: [25][233/391]	LR: 0.0008	DT: 0.000 (2.837)	BT: 0.065 (2.906)	Loss 0.3564 (0.5249)	Prec@1 89.062 (81.864)	
Epoch: [25][311/391]	LR: 0.0008	DT: 0.000 (2.816)	BT: 0.058 (2.884)	Loss 0.4709 (0.5248)	Prec@1 85.156 (81.964)	
Epoch: [25][389/391]	LR: 0.0008	DT: 0.000 (2.919)	BT: 0.066 (2.988)	Loss 0.4780 (0.5247)	Prec@1 83.594 (82.017)	
Total train loss: 0.5249
Avg Loading time: 2.9114 seconds
Avg Batch time: 2.9808 seconds

Train time: 1165.558571100235
 * Prec@1 80.250 Prec@5 99.030 Loss 0.5718
Avg Loading time: 3.4295 seconds
Avg Batch time: 3.4617 seconds

Best acc: 80.490
--------------------------------------------------------------------------------
Test time: 274.09738874435425

Epoch: [26][77/391]	LR: 0.0008	DT: 0.000 (3.536)	BT: 0.058 (3.604)	Loss 0.4429 (0.5166)	Prec@1 84.375 (82.332)	
Epoch: [26][155/391]	LR: 0.0008	DT: 0.000 (3.525)	BT: 0.058 (3.591)	Loss 0.4861 (0.5195)	Prec@1 82.031 (82.131)	
Epoch: [26][233/391]	LR: 0.0008	DT: 0.000 (3.477)	BT: 0.064 (3.542)	Loss 0.4758 (0.5202)	Prec@1 85.156 (81.978)	
Epoch: [26][311/391]	LR: 0.0008	DT: 0.000 (3.390)	BT: 0.057 (3.455)	Loss 0.5264 (0.5227)	Prec@1 80.469 (81.884)	
Epoch: [26][389/391]	LR: 0.0008	DT: 0.000 (3.366)	BT: 0.057 (3.431)	Loss 0.4998 (0.5245)	Prec@1 79.688 (81.865)	
Total train loss: 0.5247
Avg Loading time: 3.3569 seconds
Avg Batch time: 3.4222 seconds

Train time: 1338.1584734916687
 * Prec@1 80.370 Prec@5 99.050 Loss 0.5693
Avg Loading time: 2.7542 seconds
Avg Batch time: 2.7853 seconds

Best acc: 80.490
--------------------------------------------------------------------------------
Test time: 220.66385674476624

Epoch: [27][77/391]	LR: 0.0008	DT: 0.000 (2.961)	BT: 0.062 (3.029)	Loss 0.5015 (0.5107)	Prec@1 83.594 (82.492)	
Epoch: [27][155/391]	LR: 0.0008	DT: 1.636 (2.651)	BT: 1.703 (2.718)	Loss 0.5742 (0.5136)	Prec@1 81.250 (82.427)	
Epoch: [27][233/391]	LR: 0.0008	DT: 0.000 (2.445)	BT: 0.069 (2.511)	Loss 0.4653 (0.5219)	Prec@1 80.469 (82.115)	
Epoch: [27][311/391]	LR: 0.0008	DT: 0.000 (2.345)	BT: 0.053 (2.410)	Loss 0.4673 (0.5218)	Prec@1 88.281 (82.131)	
Epoch: [27][389/391]	LR: 0.0008	DT: 0.000 (2.474)	BT: 0.067 (2.540)	Loss 0.5327 (0.5228)	Prec@1 82.031 (82.089)	
Total train loss: 0.5230
Avg Loading time: 2.4672 seconds
Avg Batch time: 2.5332 seconds

Train time: 990.5551064014435
 * Prec@1 80.000 Prec@5 99.010 Loss 0.5713
Avg Loading time: 3.0759 seconds
Avg Batch time: 3.1076 seconds

Best acc: 80.490
--------------------------------------------------------------------------------
Test time: 246.31352353096008

Epoch: [28][77/391]	LR: 0.0008	DT: 0.000 (3.385)	BT: 0.057 (3.453)	Loss 0.5220 (0.5208)	Prec@1 85.156 (82.171)	
Epoch: [28][155/391]	LR: 0.0008	DT: 3.797 (3.187)	BT: 3.871 (3.256)	Loss 0.5688 (0.5253)	Prec@1 85.156 (81.876)	
Epoch: [28][233/391]	LR: 0.0008	DT: 1.947 (3.169)	BT: 2.024 (3.239)	Loss 0.5718 (0.5310)	Prec@1 79.688 (81.694)	
Epoch: [28][311/391]	LR: 0.0008	DT: 0.000 (3.174)	BT: 0.059 (3.244)	Loss 0.5088 (0.5269)	Prec@1 81.250 (81.781)	
Epoch: [28][389/391]	LR: 0.0008	DT: 0.000 (3.192)	BT: 0.060 (3.261)	Loss 0.6328 (0.5267)	Prec@1 78.906 (81.819)	
Total train loss: 0.5266
Avg Loading time: 3.1835 seconds
Avg Batch time: 3.2529 seconds

Train time: 1271.971995830536
 * Prec@1 80.240 Prec@5 99.020 Loss 0.5747
Avg Loading time: 3.4306 seconds
Avg Batch time: 3.4612 seconds

Best acc: 80.490
--------------------------------------------------------------------------------
Test time: 274.05298829078674

Epoch: [29][77/391]	LR: 0.0008	DT: 0.000 (3.298)	BT: 0.068 (3.371)	Loss 0.5913 (0.5243)	Prec@1 78.906 (82.131)	
Epoch: [29][155/391]	LR: 0.0008	DT: 0.000 (3.084)	BT: 0.068 (3.155)	Loss 0.5107 (0.5227)	Prec@1 82.812 (82.046)	
Epoch: [29][233/391]	LR: 0.0008	DT: 2.196 (3.042)	BT: 2.274 (3.114)	Loss 0.5415 (0.5211)	Prec@1 81.250 (82.061)	
Epoch: [29][311/391]	LR: 0.0008	DT: 0.000 (2.972)	BT: 0.053 (3.043)	Loss 0.4768 (0.5238)	Prec@1 82.812 (81.981)	
Epoch: [29][389/391]	LR: 0.0008	DT: 0.000 (2.970)	BT: 0.067 (3.040)	Loss 0.5557 (0.5242)	Prec@1 79.688 (81.999)	
Total train loss: 0.5240
Avg Loading time: 2.9622 seconds
Avg Batch time: 3.0325 seconds

Train time: 1185.765329360962
 * Prec@1 80.270 Prec@5 99.030 Loss 0.5703
Avg Loading time: 3.2243 seconds
Avg Batch time: 3.2547 seconds

Best acc: 80.490
--------------------------------------------------------------------------------
Test time: 257.75995349884033

Epoch: [30][77/391]	LR: 0.00016	DT: 0.000 (2.437)	BT: 0.058 (2.505)	Loss 0.5381 (0.5174)	Prec@1 81.250 (82.522)	
Epoch: [30][155/391]	LR: 0.00016	DT: 0.000 (2.414)	BT: 0.064 (2.480)	Loss 0.5186 (0.5186)	Prec@1 80.469 (82.257)	
Epoch: [30][233/391]	LR: 0.00016	DT: 0.000 (2.574)	BT: 0.063 (2.641)	Loss 0.4883 (0.5198)	Prec@1 82.031 (82.181)	
Epoch: [30][311/391]	LR: 0.00016	DT: 0.000 (2.674)	BT: 0.057 (2.740)	Loss 0.4573 (0.5194)	Prec@1 85.156 (82.174)	
Epoch: [30][389/391]	LR: 0.00016	DT: 0.000 (2.808)	BT: 0.057 (2.875)	Loss 0.6001 (0.5225)	Prec@1 80.469 (82.019)	
Total train loss: 0.5226
Avg Loading time: 2.8013 seconds
Avg Batch time: 2.8679 seconds

Train time: 1121.410770893097
 * Prec@1 80.100 Prec@5 99.060 Loss 0.5693
Avg Loading time: 3.2465 seconds
Avg Batch time: 3.2769 seconds

Best acc: 80.490
--------------------------------------------------------------------------------
Test time: 259.51180505752563

Epoch: [31][77/391]	LR: 0.00016	DT: 0.140 (2.401)	BT: 0.198 (2.467)	Loss 0.4351 (0.5239)	Prec@1 83.594 (82.202)	
Epoch: [31][155/391]	LR: 0.00016	DT: 0.000 (2.695)	BT: 0.067 (2.761)	Loss 0.6118 (0.5192)	Prec@1 75.781 (82.011)	
Epoch: [31][233/391]	LR: 0.00016	DT: 0.000 (2.802)	BT: 0.069 (2.869)	Loss 0.5977 (0.5190)	Prec@1 77.344 (82.141)	
Epoch: [31][311/391]	LR: 0.00016	DT: 0.000 (2.752)	BT: 0.054 (2.820)	Loss 0.5049 (0.5210)	Prec@1 83.594 (82.034)	
Epoch: [31][389/391]	LR: 0.00016	DT: 0.000 (2.786)	BT: 0.058 (2.854)	Loss 0.4895 (0.5223)	Prec@1 85.156 (82.071)	
Total train loss: 0.5222
Avg Loading time: 2.7792 seconds
Avg Batch time: 2.8466 seconds

Train time: 1113.0963242053986
 * Prec@1 80.580 Prec@5 99.050 Loss 0.5684
Avg Loading time: 3.1018 seconds
Avg Batch time: 3.1326 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 248.61165356636047

Epoch: [32][77/391]	LR: 0.00016	DT: 0.000 (3.241)	BT: 0.057 (3.311)	Loss 0.4692 (0.5136)	Prec@1 86.719 (82.362)	
Epoch: [32][155/391]	LR: 0.00016	DT: 0.000 (3.318)	BT: 0.063 (3.389)	Loss 0.4917 (0.5152)	Prec@1 82.812 (82.282)	
Epoch: [32][233/391]	LR: 0.00016	DT: 10.773 (3.314)	BT: 10.848 (3.383)	Loss 0.4810 (0.5186)	Prec@1 85.156 (81.968)	
Epoch: [32][311/391]	LR: 0.00016	DT: 0.000 (3.256)	BT: 0.058 (3.324)	Loss 0.5762 (0.5190)	Prec@1 80.469 (81.959)	
Epoch: [32][389/391]	LR: 0.00016	DT: 0.260 (3.182)	BT: 0.325 (3.249)	Loss 0.5776 (0.5215)	Prec@1 76.562 (81.863)	
Total train loss: 0.5212
Avg Loading time: 3.1738 seconds
Avg Batch time: 3.2410 seconds

Train time: 1267.2927434444427
 * Prec@1 80.420 Prec@5 99.030 Loss 0.5674
Avg Loading time: 2.4410 seconds
Avg Batch time: 2.4713 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 195.86249423027039

Epoch: [33][77/391]	LR: 0.00016	DT: 0.000 (2.455)	BT: 0.061 (2.522)	Loss 0.5986 (0.5187)	Prec@1 76.562 (81.681)	
Epoch: [33][155/391]	LR: 0.00016	DT: 0.000 (2.680)	BT: 0.079 (2.746)	Loss 0.4993 (0.5202)	Prec@1 84.375 (81.951)	
Epoch: [33][233/391]	LR: 0.00016	DT: 7.612 (2.874)	BT: 7.683 (2.941)	Loss 0.4448 (0.5248)	Prec@1 85.938 (81.891)	
Epoch: [33][311/391]	LR: 0.00016	DT: 0.000 (2.978)	BT: 0.059 (3.045)	Loss 0.6421 (0.5248)	Prec@1 78.125 (81.901)	
Epoch: [33][389/391]	LR: 0.00016	DT: 0.000 (3.099)	BT: 0.053 (3.166)	Loss 0.4675 (0.5230)	Prec@1 85.156 (82.023)	
Total train loss: 0.5230
Avg Loading time: 3.0915 seconds
Avg Batch time: 3.1580 seconds

Train time: 1234.8883621692657
 * Prec@1 80.400 Prec@5 99.000 Loss 0.5684
Avg Loading time: 3.2669 seconds
Avg Batch time: 3.2966 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 261.11101269721985

Epoch: [34][77/391]	LR: 0.00016	DT: 0.000 (3.264)	BT: 0.062 (3.334)	Loss 0.5435 (0.5283)	Prec@1 78.906 (81.641)	
Epoch: [34][155/391]	LR: 0.00016	DT: 2.122 (3.195)	BT: 2.198 (3.264)	Loss 0.5625 (0.5246)	Prec@1 79.688 (81.896)	
Epoch: [34][233/391]	LR: 0.00016	DT: 0.000 (3.252)	BT: 0.064 (3.321)	Loss 0.4702 (0.5211)	Prec@1 86.719 (82.061)	
Epoch: [34][311/391]	LR: 0.00016	DT: 0.000 (3.239)	BT: 0.055 (3.307)	Loss 0.4207 (0.5223)	Prec@1 87.500 (82.056)	
Epoch: [34][389/391]	LR: 0.00016	DT: 0.000 (3.279)	BT: 0.052 (3.346)	Loss 0.5840 (0.5216)	Prec@1 78.906 (82.085)	
Total train loss: 0.5217
Avg Loading time: 3.2704 seconds
Avg Batch time: 3.3376 seconds

Train time: 1305.0583047866821
 * Prec@1 80.300 Prec@5 99.030 Loss 0.5674
Avg Loading time: 3.4362 seconds
Avg Batch time: 3.4679 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 274.6104278564453

Epoch: [35][77/391]	LR: 0.00016	DT: 0.000 (3.372)	BT: 0.067 (3.441)	Loss 0.5479 (0.5208)	Prec@1 82.031 (82.212)	
Epoch: [35][155/391]	LR: 0.00016	DT: 1.360 (3.305)	BT: 1.429 (3.375)	Loss 0.4219 (0.5231)	Prec@1 85.156 (81.866)	
Epoch: [35][233/391]	LR: 0.00016	DT: 0.000 (3.235)	BT: 0.068 (3.305)	Loss 0.6694 (0.5205)	Prec@1 75.000 (82.091)	
Epoch: [35][311/391]	LR: 0.00016	DT: 0.000 (3.046)	BT: 0.061 (3.115)	Loss 0.5425 (0.5225)	Prec@1 85.156 (81.986)	
Epoch: [35][389/391]	LR: 0.00016	DT: 0.000 (2.854)	BT: 0.057 (2.923)	Loss 0.4756 (0.5233)	Prec@1 85.156 (81.921)	
Total train loss: 0.5233
Avg Loading time: 2.8465 seconds
Avg Batch time: 2.9159 seconds

Train time: 1140.176936864853
 * Prec@1 80.470 Prec@5 99.050 Loss 0.5698
Avg Loading time: 2.1193 seconds
Avg Batch time: 2.1488 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 170.39610052108765

Epoch: [36][77/391]	LR: 0.00016	DT: 0.000 (3.104)	BT: 0.057 (3.170)	Loss 0.6885 (0.5261)	Prec@1 73.438 (82.041)	
Epoch: [36][155/391]	LR: 0.00016	DT: 0.000 (3.045)	BT: 0.068 (3.112)	Loss 0.5439 (0.5233)	Prec@1 82.812 (82.217)	
Epoch: [36][233/391]	LR: 0.00016	DT: 0.000 (3.091)	BT: 0.083 (3.158)	Loss 0.5615 (0.5233)	Prec@1 81.250 (82.161)	
Epoch: [36][311/391]	LR: 0.00016	DT: 0.000 (3.010)	BT: 0.057 (3.077)	Loss 0.4619 (0.5216)	Prec@1 82.812 (82.252)	
Epoch: [36][389/391]	LR: 0.00016	DT: 0.000 (3.033)	BT: 0.057 (3.100)	Loss 0.4985 (0.5222)	Prec@1 82.031 (82.202)	
Total train loss: 0.5222
Avg Loading time: 3.0252 seconds
Avg Batch time: 3.0925 seconds

Train time: 1209.2395434379578
 * Prec@1 80.320 Prec@5 99.000 Loss 0.5679
Avg Loading time: 3.4404 seconds
Avg Batch time: 3.4716 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 274.90272188186646

Epoch: [37][77/391]	LR: 0.00016	DT: 0.000 (3.487)	BT: 0.057 (3.556)	Loss 0.5024 (0.5205)	Prec@1 83.594 (82.181)	
Epoch: [37][155/391]	LR: 0.00016	DT: 2.919 (3.502)	BT: 2.990 (3.571)	Loss 0.5459 (0.5204)	Prec@1 82.031 (82.076)	
Epoch: [37][233/391]	LR: 0.00016	DT: 0.000 (3.488)	BT: 0.068 (3.557)	Loss 0.6313 (0.5250)	Prec@1 76.562 (81.944)	
Epoch: [37][311/391]	LR: 0.00016	DT: 0.000 (3.397)	BT: 0.059 (3.466)	Loss 0.4756 (0.5195)	Prec@1 83.594 (82.189)	
Epoch: [37][389/391]	LR: 0.00016	DT: 0.000 (3.370)	BT: 0.057 (3.440)	Loss 0.4678 (0.5219)	Prec@1 82.812 (82.065)	
Total train loss: 0.5218
Avg Loading time: 3.3617 seconds
Avg Batch time: 3.4308 seconds

Train time: 1341.526981830597
 * Prec@1 80.330 Prec@5 99.060 Loss 0.5679
Avg Loading time: 3.1847 seconds
Avg Batch time: 3.2153 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 254.65533351898193

Epoch: [38][77/391]	LR: 0.00016	DT: 0.000 (2.980)	BT: 0.058 (3.046)	Loss 0.5078 (0.5238)	Prec@1 88.281 (82.111)	
Epoch: [38][155/391]	LR: 0.00016	DT: 0.000 (2.484)	BT: 0.061 (2.550)	Loss 0.5059 (0.5220)	Prec@1 80.469 (82.161)	
Epoch: [38][233/391]	LR: 0.00016	DT: 0.000 (2.353)	BT: 0.084 (2.420)	Loss 0.4888 (0.5221)	Prec@1 82.812 (82.145)	
Epoch: [38][311/391]	LR: 0.00016	DT: 0.000 (2.267)	BT: 0.058 (2.334)	Loss 0.4448 (0.5191)	Prec@1 82.031 (82.181)	
Epoch: [38][389/391]	LR: 0.00016	DT: 2.879 (2.407)	BT: 2.952 (2.475)	Loss 0.4634 (0.5210)	Prec@1 85.156 (82.073)	
Total train loss: 0.5211
Avg Loading time: 2.4010 seconds
Avg Batch time: 2.4691 seconds

Train time: 965.5234141349792
 * Prec@1 80.230 Prec@5 99.050 Loss 0.5679
Avg Loading time: 3.8747 seconds
Avg Batch time: 3.9068 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 309.273645401001

Epoch: [39][77/391]	LR: 0.00016	DT: 0.000 (3.813)	BT: 0.058 (3.882)	Loss 0.4341 (0.5334)	Prec@1 82.031 (80.909)	
Epoch: [39][155/391]	LR: 0.00016	DT: 0.000 (3.713)	BT: 0.062 (3.781)	Loss 0.5425 (0.5270)	Prec@1 82.031 (81.390)	
Epoch: [39][233/391]	LR: 0.00016	DT: 1.438 (3.592)	BT: 1.512 (3.660)	Loss 0.4895 (0.5270)	Prec@1 83.594 (81.577)	
Epoch: [39][311/391]	LR: 0.00016	DT: 0.000 (3.518)	BT: 0.057 (3.586)	Loss 0.4731 (0.5201)	Prec@1 82.031 (81.989)	
Epoch: [39][389/391]	LR: 0.00016	DT: 0.000 (3.546)	BT: 0.058 (3.614)	Loss 0.5518 (0.5226)	Prec@1 83.594 (81.895)	
Total train loss: 0.5225
Avg Loading time: 3.5373 seconds
Avg Batch time: 3.6047 seconds

Train time: 1409.5155711174011
 * Prec@1 80.390 Prec@5 99.080 Loss 0.5679
Avg Loading time: 3.6519 seconds
Avg Batch time: 3.6823 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 291.524893283844

Epoch: [40][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.616)	BT: 0.058 (3.682)	Loss 0.5093 (0.5251)	Prec@1 80.469 (82.121)	
Epoch: [40][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.532)	BT: 0.054 (3.598)	Loss 0.4451 (0.5210)	Prec@1 83.594 (82.001)	
Epoch: [40][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.460)	BT: 0.068 (3.527)	Loss 0.4653 (0.5216)	Prec@1 86.719 (82.178)	
Epoch: [40][311/391]	LR: 3.2000000000000005e-05	DT: 0.101 (3.354)	BT: 0.174 (3.422)	Loss 0.4380 (0.5227)	Prec@1 82.812 (82.084)	
Epoch: [40][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.347)	BT: 0.061 (3.415)	Loss 0.3333 (0.5215)	Prec@1 92.969 (82.135)	
Total train loss: 0.5216
Avg Loading time: 3.3384 seconds
Avg Batch time: 3.4065 seconds

Train time: 1332.0409951210022
 * Prec@1 80.260 Prec@5 99.070 Loss 0.5684
Avg Loading time: 3.2192 seconds
Avg Batch time: 3.2500 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 257.3898878097534

Epoch: [41][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.413)	BT: 0.057 (2.480)	Loss 0.4707 (0.5329)	Prec@1 86.719 (81.721)	
Epoch: [41][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.365)	BT: 0.067 (2.434)	Loss 0.4443 (0.5299)	Prec@1 85.938 (81.916)	
Epoch: [41][233/391]	LR: 3.2000000000000005e-05	DT: 14.393 (2.514)	BT: 14.464 (2.582)	Loss 0.5547 (0.5256)	Prec@1 81.250 (82.005)	
Epoch: [41][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.668)	BT: 0.057 (2.735)	Loss 0.5698 (0.5232)	Prec@1 81.250 (82.104)	
Epoch: [41][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.827)	BT: 0.058 (2.894)	Loss 0.5366 (0.5231)	Prec@1 81.250 (82.021)	
Total train loss: 0.5232
Avg Loading time: 2.8199 seconds
Avg Batch time: 2.8871 seconds

Train time: 1128.9362659454346
 * Prec@1 80.230 Prec@5 99.000 Loss 0.5698
Avg Loading time: 3.4359 seconds
Avg Batch time: 3.4662 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 274.45433282852173

Epoch: [42][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.192)	BT: 0.057 (3.263)	Loss 0.5293 (0.5228)	Prec@1 82.031 (81.991)	
Epoch: [42][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.598)	BT: 0.067 (3.668)	Loss 0.5298 (0.5212)	Prec@1 81.250 (81.896)	
Epoch: [42][233/391]	LR: 3.2000000000000005e-05	DT: 1.801 (3.940)	BT: 1.876 (4.010)	Loss 0.5098 (0.5246)	Prec@1 84.375 (81.951)	
Epoch: [42][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.999)	BT: 0.057 (4.068)	Loss 0.4756 (0.5231)	Prec@1 82.031 (81.896)	
Epoch: [42][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.120)	BT: 0.064 (4.189)	Loss 0.6006 (0.5219)	Prec@1 73.438 (81.941)	
Total train loss: 0.5218
Avg Loading time: 4.1095 seconds
Avg Batch time: 4.1786 seconds

Train time: 1633.919112920761
 * Prec@1 80.400 Prec@5 99.000 Loss 0.5674
Avg Loading time: 4.6879 seconds
Avg Batch time: 4.7208 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 373.58021998405457

Epoch: [43][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.919)	BT: 0.057 (4.986)	Loss 0.5161 (0.5294)	Prec@1 81.250 (81.601)	
Epoch: [43][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.901)	BT: 0.067 (4.967)	Loss 0.4736 (0.5262)	Prec@1 81.250 (81.666)	
Epoch: [43][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.450)	BT: 0.069 (4.516)	Loss 0.4705 (0.5222)	Prec@1 82.031 (81.801)	
Epoch: [43][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.899)	BT: 0.057 (3.965)	Loss 0.4333 (0.5250)	Prec@1 85.938 (81.666)	
Epoch: [43][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.593)	BT: 0.058 (3.659)	Loss 0.5479 (0.5233)	Prec@1 82.812 (81.823)	
Total train loss: 0.5235
Avg Loading time: 3.5838 seconds
Avg Batch time: 3.6494 seconds

Train time: 1427.0073623657227
 * Prec@1 80.370 Prec@5 99.050 Loss 0.5679
Avg Loading time: 3.1006 seconds
Avg Batch time: 3.1317 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 248.04385495185852

Epoch: [44][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.425)	BT: 0.058 (3.495)	Loss 0.5503 (0.5273)	Prec@1 83.594 (81.931)	
Epoch: [44][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.405)	BT: 0.066 (3.474)	Loss 0.4492 (0.5280)	Prec@1 85.938 (81.976)	
Epoch: [44][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.536)	BT: 0.086 (3.605)	Loss 0.5566 (0.5299)	Prec@1 82.812 (81.931)	
Epoch: [44][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.489)	BT: 0.052 (3.557)	Loss 0.6338 (0.5279)	Prec@1 80.469 (82.009)	
Epoch: [44][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.360)	BT: 0.057 (3.427)	Loss 0.4397 (0.5233)	Prec@1 84.375 (82.093)	
Total train loss: 0.5233
Avg Loading time: 3.3510 seconds
Avg Batch time: 3.4188 seconds

Train time: 1336.8357379436493
 * Prec@1 80.210 Prec@5 99.030 Loss 0.5698
Avg Loading time: 2.9217 seconds
Avg Batch time: 2.9526 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 234.26285481452942

Epoch: [45][77/391]	LR: 3.2000000000000005e-05	DT: 0.257 (3.481)	BT: 0.329 (3.550)	Loss 0.4978 (0.5131)	Prec@1 81.250 (82.462)	
Epoch: [45][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.446)	BT: 0.089 (3.516)	Loss 0.5171 (0.5171)	Prec@1 83.594 (82.287)	
Epoch: [45][233/391]	LR: 3.2000000000000005e-05	DT: 9.980 (3.458)	BT: 10.048 (3.526)	Loss 0.3862 (0.5204)	Prec@1 85.938 (82.178)	
Epoch: [45][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.375)	BT: 0.053 (3.442)	Loss 0.6582 (0.5217)	Prec@1 77.344 (82.174)	
Epoch: [45][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.347)	BT: 0.053 (3.413)	Loss 0.5474 (0.5221)	Prec@1 79.688 (82.139)	
Total train loss: 0.5223
Avg Loading time: 3.3382 seconds
Avg Batch time: 3.4047 seconds

Train time: 1331.304913520813
 * Prec@1 80.410 Prec@5 99.030 Loss 0.5664
Avg Loading time: 3.4753 seconds
Avg Batch time: 3.5050 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 277.5522925853729

Epoch: [46][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.436)	BT: 0.058 (3.500)	Loss 0.5361 (0.5127)	Prec@1 80.469 (82.302)	
Epoch: [46][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.058)	BT: 0.063 (3.124)	Loss 0.5356 (0.5226)	Prec@1 82.812 (82.146)	
Epoch: [46][233/391]	LR: 3.2000000000000005e-05	DT: 1.559 (2.840)	BT: 1.636 (2.907)	Loss 0.5068 (0.5221)	Prec@1 80.469 (81.948)	
Epoch: [46][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.550)	BT: 0.057 (2.617)	Loss 0.4561 (0.5223)	Prec@1 84.375 (81.926)	
Epoch: [46][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.588)	BT: 0.066 (2.656)	Loss 0.5059 (0.5214)	Prec@1 83.594 (81.963)	
Total train loss: 0.5214
Avg Loading time: 2.5817 seconds
Avg Batch time: 2.6491 seconds

Train time: 1035.9026699066162
 * Prec@1 80.160 Prec@5 99.010 Loss 0.5693
Avg Loading time: 3.2703 seconds
Avg Batch time: 3.3031 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 261.8828387260437

Epoch: [47][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.316)	BT: 0.059 (3.383)	Loss 0.6133 (0.5253)	Prec@1 76.562 (82.041)	
Epoch: [47][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.395)	BT: 0.068 (3.463)	Loss 0.4250 (0.5206)	Prec@1 84.375 (82.192)	
Epoch: [47][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.280)	BT: 0.063 (3.348)	Loss 0.5093 (0.5200)	Prec@1 84.375 (82.165)	
Epoch: [47][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.232)	BT: 0.057 (3.300)	Loss 0.5269 (0.5218)	Prec@1 85.938 (82.036)	
Epoch: [47][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.258)	BT: 0.060 (3.326)	Loss 0.4856 (0.5227)	Prec@1 82.031 (81.995)	
Total train loss: 0.5231
Avg Loading time: 3.2492 seconds
Avg Batch time: 3.3174 seconds

Train time: 1297.168743610382
 * Prec@1 80.080 Prec@5 99.020 Loss 0.5679
Avg Loading time: 3.5101 seconds
Avg Batch time: 3.5423 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 280.4789264202118

Epoch: [48][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.613)	BT: 0.067 (3.685)	Loss 0.4617 (0.5221)	Prec@1 81.250 (82.151)	
Epoch: [48][155/391]	LR: 3.2000000000000005e-05	DT: 0.126 (3.548)	BT: 0.189 (3.621)	Loss 0.5854 (0.5218)	Prec@1 78.125 (81.986)	
Epoch: [48][233/391]	LR: 3.2000000000000005e-05	DT: 2.451 (3.521)	BT: 2.521 (3.592)	Loss 0.5273 (0.5204)	Prec@1 79.688 (82.051)	
Epoch: [48][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.405)	BT: 0.053 (3.474)	Loss 0.5269 (0.5210)	Prec@1 79.688 (82.111)	
Epoch: [48][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.324)	BT: 0.063 (3.392)	Loss 0.5747 (0.5219)	Prec@1 81.250 (82.109)	
Total train loss: 0.5217
Avg Loading time: 3.3151 seconds
Avg Batch time: 3.3835 seconds

Train time: 1323.020497560501
 * Prec@1 80.380 Prec@5 99.040 Loss 0.5679
Avg Loading time: 2.6904 seconds
Avg Batch time: 2.7196 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 215.48418354988098

Epoch: [49][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.946)	BT: 0.058 (2.010)	Loss 0.5063 (0.5217)	Prec@1 86.719 (81.871)	
Epoch: [49][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.091)	BT: 0.058 (2.155)	Loss 0.5718 (0.5231)	Prec@1 81.250 (81.906)	
Epoch: [49][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.310)	BT: 0.069 (2.374)	Loss 0.6445 (0.5196)	Prec@1 78.906 (82.091)	
Epoch: [49][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.525)	BT: 0.059 (2.589)	Loss 0.4924 (0.5215)	Prec@1 85.938 (81.924)	
Epoch: [49][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.765)	BT: 0.057 (2.830)	Loss 0.5576 (0.5234)	Prec@1 81.250 (81.897)	
Total train loss: 0.5236
Avg Loading time: 2.7582 seconds
Avg Batch time: 2.8230 seconds

Train time: 1103.8626990318298
 * Prec@1 80.230 Prec@5 99.050 Loss 0.5684
Avg Loading time: 3.5791 seconds
Avg Batch time: 3.6100 seconds

Best acc: 80.580
--------------------------------------------------------------------------------
Test time: 285.8135416507721


      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode: rram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.02
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 7
Savedir:  ../pretrained_models/frozen/x64-8b/rram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/train/relu7
Test path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/test/relu7
ResNet18(
  (conv8): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): QConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): QConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): QConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): QConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 10.260 Prec@5 51.820 Loss 2.2930
Avg Loading time: 5.9308 seconds
Avg Batch time: 5.9630 seconds

Pre-trained Prec@1 with 7 layers frozen: 10.25999927520752 	 Loss: 2.29296875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.02	DT: 0.000 (7.523)	BT: 0.046 (7.573)	Loss 0.5474 (0.8897)	Prec@1 85.938 (75.531)	
Epoch: [0][155/391]	LR: 0.02	DT: 0.000 (7.260)	BT: 0.047 (7.311)	Loss 0.5063 (0.7041)	Prec@1 83.594 (79.908)	
Epoch: [0][233/391]	LR: 0.02	DT: 0.000 (7.179)	BT: 0.049 (7.229)	Loss 0.6113 (0.6878)	Prec@1 82.031 (79.734)	
Epoch: [0][311/391]	LR: 0.02	DT: 0.000 (6.949)	BT: 0.040 (6.999)	Loss 0.5645 (0.6652)	Prec@1 80.469 (79.930)	
Epoch: [0][389/391]	LR: 0.02	DT: 0.000 (6.744)	BT: 0.041 (6.795)	Loss 0.5830 (0.6524)	Prec@1 78.125 (79.956)	
Total train loss: 0.6526
Avg Loading time: 6.7270 seconds
Avg Batch time: 6.7773 seconds

Train time: 2650.010840177536
 * Prec@1 64.940 Prec@5 97.010 Loss 1.0508
Avg Loading time: 2.5055 seconds
Avg Batch time: 2.5260 seconds

Best acc: 64.940
--------------------------------------------------------------------------------
Test time: 200.5953233242035

Epoch: [1][77/391]	LR: 0.02	DT: 0.000 (3.060)	BT: 0.048 (3.113)	Loss 0.6035 (0.7001)	Prec@1 77.344 (76.202)	
Epoch: [1][155/391]	LR: 0.02	DT: 0.000 (3.212)	BT: 0.047 (3.264)	Loss 0.6714 (0.7043)	Prec@1 76.562 (76.102)	
Epoch: [1][233/391]	LR: 0.02	DT: 13.745 (3.309)	BT: 13.800 (3.359)	Loss 0.7290 (0.7101)	Prec@1 75.000 (75.871)	
Epoch: [1][311/391]	LR: 0.02	DT: 0.000 (3.165)	BT: 0.044 (3.215)	Loss 0.6821 (0.7025)	Prec@1 77.344 (76.137)	
Epoch: [1][389/391]	LR: 0.02	DT: 0.000 (3.057)	BT: 0.047 (3.106)	Loss 0.7222 (0.6940)	Prec@1 76.562 (76.340)	
Total train loss: 0.6939
Avg Loading time: 3.0487 seconds
Avg Batch time: 3.0983 seconds

Train time: 1211.5090103149414
 * Prec@1 72.330 Prec@5 98.070 Loss 0.8145
Avg Loading time: 2.4853 seconds
Avg Batch time: 2.5054 seconds

Best acc: 72.330
--------------------------------------------------------------------------------
Test time: 199.02951335906982

Epoch: [2][77/391]	LR: 0.02	DT: 0.106 (3.022)	BT: 0.152 (3.072)	Loss 0.6768 (0.6491)	Prec@1 74.219 (78.045)	
Epoch: [2][155/391]	LR: 0.02	DT: 0.000 (2.992)	BT: 0.046 (3.044)	Loss 0.6323 (0.6443)	Prec@1 80.469 (78.180)	
Epoch: [2][233/391]	LR: 0.02	DT: 0.806 (2.990)	BT: 0.860 (3.042)	Loss 0.4897 (0.6405)	Prec@1 84.375 (78.092)	
Epoch: [2][311/391]	LR: 0.02	DT: 0.000 (2.966)	BT: 0.047 (3.017)	Loss 0.6396 (0.6492)	Prec@1 78.906 (77.895)	
Epoch: [2][389/391]	LR: 0.02	DT: 1.547 (3.002)	BT: 1.601 (3.053)	Loss 0.6826 (0.6494)	Prec@1 80.469 (77.845)	
Total train loss: 0.6494
Avg Loading time: 2.9938 seconds
Avg Batch time: 3.0455 seconds

Train time: 1190.8797144889832
 * Prec@1 53.370 Prec@5 88.510 Loss 1.4580
Avg Loading time: 3.3447 seconds
Avg Batch time: 3.3671 seconds

Best acc: 72.330
--------------------------------------------------------------------------------
Test time: 266.62692975997925

Epoch: [3][77/391]	LR: 0.02	DT: 0.000 (3.401)	BT: 0.041 (3.452)	Loss 0.5664 (0.5989)	Prec@1 77.344 (79.718)	
Epoch: [3][155/391]	LR: 0.02	DT: 0.000 (3.442)	BT: 0.048 (3.494)	Loss 0.6064 (0.6131)	Prec@1 79.688 (79.217)	
Epoch: [3][233/391]	LR: 0.02	DT: 4.503 (3.355)	BT: 4.556 (3.406)	Loss 0.6401 (0.6088)	Prec@1 73.438 (79.320)	
Epoch: [3][311/391]	LR: 0.02	DT: 0.000 (3.077)	BT: 0.040 (3.127)	Loss 0.3882 (0.5975)	Prec@1 86.719 (79.535)	
Epoch: [3][389/391]	LR: 0.02	DT: 0.000 (2.925)	BT: 0.047 (2.974)	Loss 0.5386 (0.5995)	Prec@1 78.125 (79.461)	
Total train loss: 0.5995
Avg Loading time: 2.9172 seconds
Avg Batch time: 2.9664 seconds

Train time: 1159.9713959693909
 * Prec@1 55.750 Prec@5 94.430 Loss 1.2803
Avg Loading time: 2.8567 seconds
Avg Batch time: 2.8786 seconds

Best acc: 72.330
--------------------------------------------------------------------------------
Test time: 228.03821110725403

Epoch: [4][77/391]	LR: 0.02	DT: 0.000 (3.469)	BT: 0.044 (3.518)	Loss 0.9458 (0.5891)	Prec@1 68.750 (80.098)	
Epoch: [4][155/391]	LR: 0.02	DT: 0.000 (3.383)	BT: 0.047 (3.432)	Loss 0.6523 (0.6047)	Prec@1 79.688 (79.502)	
Epoch: [4][233/391]	LR: 0.02	DT: 0.040 (3.301)	BT: 0.091 (3.351)	Loss 0.5767 (0.5832)	Prec@1 76.562 (80.108)	
Epoch: [4][311/391]	LR: 0.02	DT: 0.000 (3.329)	BT: 0.048 (3.379)	Loss 0.6016 (0.5784)	Prec@1 79.688 (80.253)	
Epoch: [4][389/391]	LR: 0.02	DT: 0.000 (3.337)	BT: 0.040 (3.387)	Loss 0.6372 (0.5738)	Prec@1 76.562 (80.379)	
Total train loss: 0.5738
Avg Loading time: 3.3281 seconds
Avg Batch time: 3.3782 seconds

Train time: 1320.9546525478363
 * Prec@1 71.610 Prec@5 97.830 Loss 0.8110
Avg Loading time: 3.2511 seconds
Avg Batch time: 3.2735 seconds

Best acc: 72.330
--------------------------------------------------------------------------------
Test time: 259.27341890335083

Epoch: [5][77/391]	LR: 0.02	DT: 0.000 (3.201)	BT: 0.046 (3.251)	Loss 0.8076 (0.5372)	Prec@1 75.781 (81.370)	
Epoch: [5][155/391]	LR: 0.02	DT: 0.000 (3.254)	BT: 0.047 (3.303)	Loss 0.5415 (0.5438)	Prec@1 82.812 (81.230)	
Epoch: [5][233/391]	LR: 0.02	DT: 0.000 (3.317)	BT: 0.048 (3.366)	Loss 0.5640 (0.5517)	Prec@1 78.906 (81.120)	
Epoch: [5][311/391]	LR: 0.02	DT: 0.000 (3.286)	BT: 0.039 (3.335)	Loss 0.7085 (0.6361)	Prec@1 71.875 (77.995)	
Epoch: [5][389/391]	LR: 0.02	DT: 0.000 (3.307)	BT: 0.047 (3.356)	Loss 0.6724 (0.6527)	Prec@1 74.219 (77.408)	
Total train loss: 0.6527
Avg Loading time: 3.2985 seconds
Avg Batch time: 3.3477 seconds

Train time: 1309.031131029129
 * Prec@1 12.840 Prec@5 53.390 Loss inf
Avg Loading time: 3.6388 seconds
Avg Batch time: 3.6604 seconds

Best acc: 72.330
--------------------------------------------------------------------------------
Test time: 292.6427080631256

Epoch: [6][77/391]	LR: 0.02	DT: 0.000 (3.992)	BT: 0.041 (4.041)	Loss 0.6426 (0.6871)	Prec@1 78.906 (76.142)	
Epoch: [6][155/391]	LR: 0.02	DT: 0.000 (3.768)	BT: 0.047 (3.819)	Loss 0.6836 (0.6927)	Prec@1 74.219 (76.092)	
Epoch: [6][233/391]	LR: 0.02	DT: 0.000 (3.492)	BT: 0.048 (3.542)	Loss 0.6450 (0.6864)	Prec@1 77.344 (76.265)	
Epoch: [6][311/391]	LR: 0.02	DT: 0.000 (3.319)	BT: 0.039 (3.369)	Loss 0.7490 (0.6896)	Prec@1 74.219 (76.097)	
Epoch: [6][389/391]	LR: 0.02	DT: 0.000 (3.328)	BT: 0.039 (3.378)	Loss 0.8071 (0.6884)	Prec@1 71.094 (76.052)	
Total train loss: 0.6886
Avg Loading time: 3.3190 seconds
Avg Batch time: 3.3691 seconds

Train time: 1317.419049501419
 * Prec@1 71.530 Prec@5 98.500 Loss 0.8433
Avg Loading time: 3.7256 seconds
Avg Batch time: 3.7475 seconds

Best acc: 72.330
--------------------------------------------------------------------------------
Test time: 301.61159229278564

Epoch: [7][77/391]	LR: 0.02	DT: 0.000 (4.648)	BT: 0.039 (4.699)	Loss 0.7988 (0.6587)	Prec@1 71.094 (77.153)	
Epoch: [7][155/391]	LR: 0.02	DT: 0.000 (4.813)	BT: 0.040 (4.864)	Loss 0.6382 (0.6827)	Prec@1 78.906 (76.197)	
Epoch: [7][233/391]	LR: 0.02	DT: 0.000 (4.954)	BT: 0.049 (5.004)	Loss 0.6284 (0.6815)	Prec@1 75.000 (76.222)	
Epoch: [7][311/391]	LR: 0.02	DT: 0.000 (4.656)	BT: 0.039 (4.706)	Loss 0.5947 (0.6778)	Prec@1 79.688 (76.362)	
Epoch: [7][389/391]	LR: 0.02	DT: 0.372 (4.465)	BT: 0.419 (4.515)	Loss 0.6851 (0.6716)	Prec@1 72.656 (76.579)	
Total train loss: 0.6716
Avg Loading time: 4.4540 seconds
Avg Batch time: 4.5037 seconds

Train time: 1761.0486447811127
 * Prec@1 71.540 Prec@5 97.930 Loss 0.8311
Avg Loading time: 3.9027 seconds
Avg Batch time: 3.9246 seconds

Best acc: 72.330
--------------------------------------------------------------------------------
Test time: 310.6555416584015

Epoch: [8][77/391]	LR: 0.02	DT: 0.000 (3.686)	BT: 0.047 (3.737)	Loss 0.5264 (0.6368)	Prec@1 83.594 (77.704)	
Epoch: [8][155/391]	LR: 0.02	DT: 0.000 (3.633)	BT: 0.047 (3.683)	Loss 0.5664 (0.6351)	Prec@1 79.688 (77.850)	
Epoch: [8][233/391]	LR: 0.02	DT: 0.000 (3.562)	BT: 0.049 (3.612)	Loss 0.5713 (0.6345)	Prec@1 82.031 (77.748)	
Epoch: [8][311/391]	LR: 0.02	DT: 0.000 (3.399)	BT: 0.043 (3.449)	Loss 0.5645 (0.6333)	Prec@1 77.344 (77.782)	
Epoch: [8][389/391]	LR: 0.02	DT: 0.000 (3.263)	BT: 0.039 (3.314)	Loss 0.6426 (0.6379)	Prec@1 79.688 (77.618)	
Total train loss: 0.6379
Avg Loading time: 3.2549 seconds
Avg Batch time: 3.3052 seconds

Train time: 1292.425145149231
 * Prec@1 42.760 Prec@5 87.570 Loss 1.8418
Avg Loading time: 2.1640 seconds
Avg Batch time: 2.1856 seconds

Best acc: 72.330
--------------------------------------------------------------------------------
Test time: 173.28775072097778

Epoch: [9][77/391]	LR: 0.02	DT: 0.000 (2.220)	BT: 0.037 (2.268)	Loss 0.5356 (0.7264)	Prec@1 81.250 (74.509)	
Epoch: [9][155/391]	LR: 0.02	DT: 0.000 (2.572)	BT: 0.048 (2.621)	Loss 0.6748 (0.6818)	Prec@1 75.781 (76.087)	
Epoch: [9][233/391]	LR: 0.02	DT: 0.000 (2.842)	BT: 0.049 (2.892)	Loss 0.6616 (0.6771)	Prec@1 78.906 (76.479)	
Epoch: [9][311/391]	LR: 0.02	DT: 0.000 (2.924)	BT: 0.045 (2.974)	Loss 0.5737 (0.6679)	Prec@1 81.250 (76.755)	
Epoch: [9][389/391]	LR: 0.02	DT: 0.000 (3.018)	BT: 0.041 (3.068)	Loss 0.6382 (0.6618)	Prec@1 78.125 (76.917)	
Total train loss: 0.6617
Avg Loading time: 3.0105 seconds
Avg Batch time: 3.0604 seconds

Train time: 1196.7034595012665
 * Prec@1 27.390 Prec@5 80.260 Loss 2.2773
Avg Loading time: 3.7211 seconds
Avg Batch time: 3.7425 seconds

Best acc: 72.330
--------------------------------------------------------------------------------
Test time: 296.2650020122528

Epoch: [10][77/391]	LR: 0.004	DT: 0.000 (3.388)	BT: 0.054 (3.440)	Loss 0.5415 (0.5868)	Prec@1 81.250 (79.477)	
Epoch: [10][155/391]	LR: 0.004	DT: 0.491 (3.225)	BT: 0.540 (3.278)	Loss 0.5488 (0.5876)	Prec@1 82.031 (79.377)	
Epoch: [10][233/391]	LR: 0.004	DT: 2.698 (3.331)	BT: 2.754 (3.384)	Loss 0.5420 (0.5832)	Prec@1 79.688 (79.654)	
Epoch: [10][311/391]	LR: 0.004	DT: 0.000 (3.266)	BT: 0.041 (3.319)	Loss 0.4822 (0.5803)	Prec@1 85.938 (79.765)	
Epoch: [10][389/391]	LR: 0.004	DT: 0.055 (3.263)	BT: 0.106 (3.315)	Loss 0.5420 (0.5765)	Prec@1 83.594 (79.912)	
Total train loss: 0.5766
Avg Loading time: 3.2549 seconds
Avg Batch time: 3.3068 seconds

Train time: 1293.0502853393555
 * Prec@1 71.480 Prec@5 98.180 Loss 0.8169
Avg Loading time: 3.6039 seconds
Avg Batch time: 3.6262 seconds

Best acc: 72.330
--------------------------------------------------------------------------------
Test time: 287.13400769233704

Epoch: [11][77/391]	LR: 0.004	DT: 0.000 (3.521)	BT: 0.039 (3.571)	Loss 0.6504 (0.5532)	Prec@1 81.250 (80.699)	
Epoch: [11][155/391]	LR: 0.004	DT: 0.000 (3.671)	BT: 0.043 (3.720)	Loss 0.6030 (0.5553)	Prec@1 78.125 (80.584)	
Epoch: [11][233/391]	LR: 0.004	DT: 0.000 (3.727)	BT: 0.046 (3.775)	Loss 0.6084 (0.5577)	Prec@1 77.344 (80.569)	
Epoch: [11][311/391]	LR: 0.004	DT: 0.000 (3.396)	BT: 0.037 (3.444)	Loss 0.5776 (0.5581)	Prec@1 82.812 (80.531)	
Epoch: [11][389/391]	LR: 0.004	DT: 1.328 (3.213)	BT: 1.375 (3.260)	Loss 0.5630 (0.5567)	Prec@1 82.812 (80.611)	
Total train loss: 0.5569
Avg Loading time: 3.2046 seconds
Avg Batch time: 3.2518 seconds

Train time: 1271.5437815189362
 * Prec@1 75.180 Prec@5 98.560 Loss 0.7144
Avg Loading time: 3.1627 seconds
Avg Batch time: 3.1824 seconds

Best acc: 75.180
--------------------------------------------------------------------------------
Test time: 252.47533798217773

Epoch: [12][77/391]	LR: 0.004	DT: 0.803 (3.883)	BT: 0.851 (3.932)	Loss 0.4985 (0.5510)	Prec@1 82.031 (80.599)	
Epoch: [12][155/391]	LR: 0.004	DT: 0.000 (3.969)	BT: 0.045 (4.019)	Loss 0.5356 (0.5521)	Prec@1 81.250 (80.724)	
Epoch: [12][233/391]	LR: 0.004	DT: 2.955 (3.766)	BT: 3.001 (3.816)	Loss 0.6069 (0.5499)	Prec@1 78.906 (80.763)	
Epoch: [12][311/391]	LR: 0.004	DT: 0.000 (3.549)	BT: 0.037 (3.599)	Loss 0.7100 (0.5518)	Prec@1 75.781 (80.669)	
Epoch: [12][389/391]	LR: 0.004	DT: 0.000 (3.464)	BT: 0.042 (3.513)	Loss 0.5259 (0.5518)	Prec@1 83.594 (80.735)	
Total train loss: 0.5522
Avg Loading time: 3.4549 seconds
Avg Batch time: 3.5037 seconds

Train time: 1370.0423996448517
 * Prec@1 78.670 Prec@5 98.970 Loss 0.6118
Avg Loading time: 3.2378 seconds
Avg Batch time: 3.2582 seconds

Best acc: 78.670
--------------------------------------------------------------------------------
Test time: 258.53205966949463

Epoch: [13][77/391]	LR: 0.004	DT: 1.189 (3.574)	BT: 1.235 (3.621)	Loss 0.5107 (0.5469)	Prec@1 80.469 (80.909)	
Epoch: [13][155/391]	LR: 0.004	DT: 0.000 (3.616)	BT: 0.042 (3.663)	Loss 0.4636 (0.5586)	Prec@1 85.156 (80.594)	
Epoch: [13][233/391]	LR: 0.004	DT: 0.000 (3.615)	BT: 0.046 (3.662)	Loss 0.3801 (0.5563)	Prec@1 89.844 (80.652)	
Epoch: [13][311/391]	LR: 0.004	DT: 1.040 (3.525)	BT: 1.087 (3.573)	Loss 0.5928 (0.5542)	Prec@1 78.125 (80.754)	
Epoch: [13][389/391]	LR: 0.004	DT: 0.000 (3.575)	BT: 0.037 (3.623)	Loss 0.5190 (0.5550)	Prec@1 85.938 (80.755)	
Total train loss: 0.5552
Avg Loading time: 3.5660 seconds
Avg Batch time: 3.6136 seconds

Train time: 1412.9990799427032
 * Prec@1 68.510 Prec@5 97.410 Loss 0.8975
Avg Loading time: 3.7000 seconds
Avg Batch time: 3.7197 seconds

Best acc: 78.670
--------------------------------------------------------------------------------
Test time: 294.47633695602417

Epoch: [14][77/391]	LR: 0.004	DT: 0.000 (4.054)	BT: 0.037 (4.103)	Loss 0.6870 (0.5458)	Prec@1 75.000 (80.980)	
Epoch: [14][155/391]	LR: 0.004	DT: 0.141 (3.539)	BT: 0.190 (3.588)	Loss 0.4238 (0.5394)	Prec@1 84.375 (81.265)	
Epoch: [14][233/391]	LR: 0.004	DT: 0.000 (3.315)	BT: 0.046 (3.364)	Loss 0.4282 (0.5417)	Prec@1 83.594 (81.080)	
Epoch: [14][311/391]	LR: 0.004	DT: 0.000 (3.130)	BT: 0.040 (3.180)	Loss 0.6343 (0.5405)	Prec@1 80.469 (81.127)	
Epoch: [14][389/391]	LR: 0.004	DT: 0.000 (3.227)	BT: 0.040 (3.278)	Loss 0.5444 (0.5458)	Prec@1 82.031 (80.992)	
Total train loss: 0.5458
Avg Loading time: 3.2191 seconds
Avg Batch time: 3.2692 seconds

Train time: 1278.366478919983
 * Prec@1 79.440 Prec@5 98.950 Loss 0.5938
Avg Loading time: 3.3749 seconds
Avg Batch time: 3.3961 seconds

Best acc: 79.440
--------------------------------------------------------------------------------
Test time: 269.4085931777954

Epoch: [15][77/391]	LR: 0.004	DT: 0.220 (3.685)	BT: 0.288 (3.736)	Loss 0.5386 (0.5474)	Prec@1 78.125 (80.929)	
Epoch: [15][155/391]	LR: 0.004	DT: 0.000 (3.746)	BT: 0.047 (3.797)	Loss 0.6240 (0.5548)	Prec@1 81.250 (80.669)	
Epoch: [15][233/391]	LR: 0.004	DT: 0.000 (3.734)	BT: 0.048 (3.785)	Loss 0.4338 (0.5502)	Prec@1 85.938 (81.010)	
Epoch: [15][311/391]	LR: 0.004	DT: 0.000 (3.563)	BT: 0.047 (3.614)	Loss 0.6626 (0.5453)	Prec@1 76.562 (81.150)	
Epoch: [15][389/391]	LR: 0.004	DT: 0.000 (3.436)	BT: 0.047 (3.488)	Loss 0.5381 (0.5479)	Prec@1 81.250 (81.056)	
Total train loss: 0.5478
Avg Loading time: 3.4276 seconds
Avg Batch time: 3.4787 seconds

Train time: 1360.2633996009827
 * Prec@1 79.910 Prec@5 99.100 Loss 0.5874
Avg Loading time: 3.1948 seconds
Avg Batch time: 3.2165 seconds

Best acc: 79.910
--------------------------------------------------------------------------------
Test time: 255.21857357025146

Epoch: [16][77/391]	LR: 0.004	DT: 0.000 (3.416)	BT: 0.047 (3.469)	Loss 0.6621 (0.5414)	Prec@1 74.219 (81.070)	
Epoch: [16][155/391]	LR: 0.004	DT: 2.182 (3.404)	BT: 2.234 (3.457)	Loss 0.5288 (0.5437)	Prec@1 78.906 (81.275)	
Epoch: [16][233/391]	LR: 0.004	DT: 0.131 (3.359)	BT: 0.179 (3.412)	Loss 0.5381 (0.5456)	Prec@1 78.906 (81.143)	
Epoch: [16][311/391]	LR: 0.004	DT: 0.000 (3.270)	BT: 0.043 (3.323)	Loss 0.5459 (0.5437)	Prec@1 78.906 (81.105)	
Epoch: [16][389/391]	LR: 0.004	DT: 0.000 (3.238)	BT: 0.043 (3.290)	Loss 0.5996 (0.5432)	Prec@1 84.375 (81.116)	
Total train loss: 0.5433
Avg Loading time: 3.2295 seconds
Avg Batch time: 3.2817 seconds

Train time: 1283.2086305618286
 * Prec@1 76.210 Prec@5 98.770 Loss 0.6890
Avg Loading time: 2.8578 seconds
Avg Batch time: 2.8784 seconds

Best acc: 79.910
--------------------------------------------------------------------------------
Test time: 228.04610872268677

Epoch: [17][77/391]	LR: 0.004	DT: 0.000 (2.374)	BT: 0.046 (2.425)	Loss 0.6235 (0.5273)	Prec@1 81.250 (81.901)	
Epoch: [17][155/391]	LR: 0.004	DT: 0.000 (2.318)	BT: 0.048 (2.368)	Loss 0.5938 (0.5356)	Prec@1 78.125 (81.485)	
Epoch: [17][233/391]	LR: 0.004	DT: 0.000 (2.466)	BT: 0.048 (2.515)	Loss 0.5278 (0.5357)	Prec@1 82.812 (81.470)	
Epoch: [17][311/391]	LR: 0.004	DT: 0.000 (2.572)	BT: 0.050 (2.620)	Loss 0.3782 (0.5367)	Prec@1 89.844 (81.360)	
Epoch: [17][389/391]	LR: 0.004	DT: 0.000 (2.681)	BT: 0.037 (2.729)	Loss 0.5229 (0.5389)	Prec@1 82.812 (81.272)	
Total train loss: 0.5390
Avg Loading time: 2.6738 seconds
Avg Batch time: 2.7222 seconds

Train time: 1064.465726852417
 * Prec@1 80.140 Prec@5 99.140 Loss 0.5762
Avg Loading time: 3.1729 seconds
Avg Batch time: 3.1933 seconds

Best acc: 80.140
--------------------------------------------------------------------------------
Test time: 253.54323840141296

Epoch: [18][77/391]	LR: 0.004	DT: 0.000 (3.194)	BT: 0.040 (3.242)	Loss 0.5332 (0.5397)	Prec@1 81.250 (81.310)	
Epoch: [18][155/391]	LR: 0.004	DT: 0.000 (3.085)	BT: 0.039 (3.132)	Loss 0.5459 (0.5347)	Prec@1 78.906 (81.190)	
Epoch: [18][233/391]	LR: 0.004	DT: 0.000 (3.019)	BT: 0.047 (3.066)	Loss 0.6108 (0.5411)	Prec@1 78.125 (81.147)	
Epoch: [18][311/391]	LR: 0.004	DT: 0.000 (2.993)	BT: 0.039 (3.040)	Loss 0.6206 (0.5441)	Prec@1 75.000 (81.085)	
Epoch: [18][389/391]	LR: 0.004	DT: 0.000 (3.048)	BT: 0.039 (3.095)	Loss 0.4453 (0.5394)	Prec@1 86.719 (81.302)	
Total train loss: 0.5392
Avg Loading time: 3.0403 seconds
Avg Batch time: 3.0871 seconds

Train time: 1207.1479179859161
 * Prec@1 75.960 Prec@5 98.680 Loss 0.6958
Avg Loading time: 2.8291 seconds
Avg Batch time: 2.8494 seconds

Best acc: 80.140
--------------------------------------------------------------------------------
Test time: 225.9173128604889

Epoch: [19][77/391]	LR: 0.004	DT: 0.000 (3.540)	BT: 0.039 (3.588)	Loss 0.5312 (0.5172)	Prec@1 81.250 (81.821)	
Epoch: [19][155/391]	LR: 0.004	DT: 0.000 (3.353)	BT: 0.045 (3.400)	Loss 0.5493 (0.5312)	Prec@1 82.812 (81.365)	
Epoch: [19][233/391]	LR: 0.004	DT: 0.000 (3.301)	BT: 0.045 (3.348)	Loss 0.4900 (0.5419)	Prec@1 84.375 (81.110)	
Epoch: [19][311/391]	LR: 0.004	DT: 0.000 (3.214)	BT: 0.038 (3.261)	Loss 0.6172 (0.5410)	Prec@1 77.344 (81.167)	
Epoch: [19][389/391]	LR: 0.004	DT: 0.000 (3.148)	BT: 0.037 (3.195)	Loss 0.5825 (0.5382)	Prec@1 84.375 (81.260)	
Total train loss: 0.5388
Avg Loading time: 3.1402 seconds
Avg Batch time: 3.1866 seconds

Train time: 1246.0713238716125
 * Prec@1 56.200 Prec@5 92.960 Loss 1.9297
Avg Loading time: 1.7331 seconds
Avg Batch time: 1.7516 seconds

Best acc: 80.140
--------------------------------------------------------------------------------
Test time: 139.1699993610382

Epoch: [20][77/391]	LR: 0.0008	DT: 0.000 (1.912)	BT: 0.039 (1.957)	Loss 0.5483 (0.5355)	Prec@1 80.469 (81.300)	
Epoch: [20][155/391]	LR: 0.0008	DT: 0.000 (1.913)	BT: 0.046 (1.957)	Loss 0.5464 (0.5281)	Prec@1 82.031 (81.631)	
Epoch: [20][233/391]	LR: 0.0008	DT: 0.000 (2.328)	BT: 0.048 (2.373)	Loss 0.4331 (0.5286)	Prec@1 87.500 (81.677)	
Epoch: [20][311/391]	LR: 0.0008	DT: 0.000 (2.458)	BT: 0.038 (2.503)	Loss 0.4878 (0.5299)	Prec@1 85.156 (81.606)	
Epoch: [20][389/391]	LR: 0.0008	DT: 0.000 (2.572)	BT: 0.043 (2.618)	Loss 0.5195 (0.5276)	Prec@1 83.594 (81.767)	
Total train loss: 0.5275
Avg Loading time: 2.5652 seconds
Avg Batch time: 2.6109 seconds

Train time: 1020.9640209674835
 * Prec@1 79.910 Prec@5 99.100 Loss 0.5713
Avg Loading time: 2.8414 seconds
Avg Batch time: 2.8618 seconds

Best acc: 80.140
--------------------------------------------------------------------------------
Test time: 226.92327880859375

Epoch: [21][77/391]	LR: 0.0008	DT: 0.000 (3.310)	BT: 0.045 (3.360)	Loss 0.5664 (0.5212)	Prec@1 77.344 (81.951)	
Epoch: [21][155/391]	LR: 0.0008	DT: 0.000 (2.889)	BT: 0.044 (2.938)	Loss 0.4685 (0.5216)	Prec@1 83.594 (81.796)	
Epoch: [21][233/391]	LR: 0.0008	DT: 0.000 (2.666)	BT: 0.047 (2.713)	Loss 0.5078 (0.5253)	Prec@1 81.250 (81.757)	
Epoch: [21][311/391]	LR: 0.0008	DT: 0.587 (2.618)	BT: 0.634 (2.666)	Loss 0.5449 (0.5273)	Prec@1 82.031 (81.716)	
Epoch: [21][389/391]	LR: 0.0008	DT: 0.000 (2.668)	BT: 0.044 (2.715)	Loss 0.6504 (0.5280)	Prec@1 77.344 (81.713)	
Total train loss: 0.5281
Avg Loading time: 2.6607 seconds
Avg Batch time: 2.7081 seconds

Train time: 1058.967349767685
