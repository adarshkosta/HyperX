
      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 5
Savedir:  ../pretrained_models/frozen/x64-8b/rram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/train/relu5
Test path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/test/relu5
ResNet18(
  (conv6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv1): Sequential(
    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu6): ReLU(inplace=True)
  (conv7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu7): ReLU(inplace=True)
  (conv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 8.110 Prec@5 42.280 Loss 2.3379
Avg Loading time: 0.1617 seconds
Avg Batch time: 0.2224 seconds

Pre-trained Prec@1 with 5 layers frozen: 8.109999656677246 	 Loss: 2.337890625

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (1.495)	BT: 0.130 (1.627)	Loss 0.3154 (0.7474)	Prec@1 89.844 (76.282)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (1.441)	BT: 0.069 (1.558)	Loss 0.4333 (0.6002)	Prec@1 82.812 (80.459)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (1.379)	BT: 0.124 (1.494)	Loss 0.3228 (0.5304)	Prec@1 90.625 (82.646)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (1.300)	BT: 0.123 (1.418)	Loss 0.3162 (0.4891)	Prec@1 89.844 (83.829)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (1.269)	BT: 0.141 (1.391)	Loss 0.2720 (0.4592)	Prec@1 89.062 (84.798)	
Total train loss: 0.4588
Avg Loading time: 1.2654 seconds
Avg Batch time: 1.3881 seconds

Train time: 542.9462718963623
 * Prec@1 85.920 Prec@5 99.490 Loss 0.4265
Avg Loading time: 0.1152 seconds
Avg Batch time: 0.1705 seconds

Best acc: 85.920
--------------------------------------------------------------------------------
Test time: 14.748206853866577

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.048)	BT: 0.149 (0.188)	Loss 0.2175 (0.2375)	Prec@1 93.750 (92.087)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.025)	BT: 0.142 (0.179)	Loss 0.2286 (0.2333)	Prec@1 90.625 (92.248)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.017)	BT: 0.164 (0.174)	Loss 0.1877 (0.2385)	Prec@1 93.750 (92.014)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.015)	BT: 0.146 (0.175)	Loss 0.2390 (0.2388)	Prec@1 93.750 (91.965)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.012)	BT: 0.133 (0.172)	Loss 0.2795 (0.2368)	Prec@1 89.844 (92.021)	
Total train loss: 0.2368
Avg Loading time: 0.0124 seconds
Avg Batch time: 0.1718 seconds

Train time: 67.33514189720154
 * Prec@1 87.530 Prec@5 99.480 Loss 0.3752
Avg Loading time: 0.1142 seconds
Avg Batch time: 0.1699 seconds

Best acc: 87.530
--------------------------------------------------------------------------------
Test time: 14.726200580596924

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.030)	BT: 0.153 (0.191)	Loss 0.0976 (0.1428)	Prec@1 96.094 (95.403)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.016)	BT: 0.186 (0.182)	Loss 0.1733 (0.1498)	Prec@1 94.531 (95.022)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (0.011)	BT: 0.128 (0.180)	Loss 0.2076 (0.1524)	Prec@1 93.750 (94.929)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.194 (0.174)	Loss 0.1367 (0.1571)	Prec@1 96.094 (94.712)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.138 (0.173)	Loss 0.1689 (0.1626)	Prec@1 92.969 (94.443)	
Total train loss: 0.1625
Avg Loading time: 0.0080 seconds
Avg Batch time: 0.1731 seconds

Train time: 67.86223983764648
 * Prec@1 89.750 Prec@5 99.600 Loss 0.3159
Avg Loading time: 0.1168 seconds
Avg Batch time: 0.1666 seconds

Best acc: 89.750
--------------------------------------------------------------------------------
Test time: 14.427904605865479

Epoch: [3][77/391]	LR: 0.1	DT: 0.001 (0.026)	BT: 0.180 (0.197)	Loss 0.0875 (0.0981)	Prec@1 98.438 (96.805)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.013)	BT: 0.181 (0.180)	Loss 0.0560 (0.0993)	Prec@1 98.438 (96.690)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.009)	BT: 0.155 (0.175)	Loss 0.2590 (0.1065)	Prec@1 92.969 (96.468)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.163 (0.175)	Loss 0.1061 (0.1133)	Prec@1 94.531 (96.216)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.150 (0.171)	Loss 0.1121 (0.1155)	Prec@1 97.656 (96.142)	
Total train loss: 0.1155
Avg Loading time: 0.0070 seconds
Avg Batch time: 0.1713 seconds

Train time: 67.17347884178162
 * Prec@1 88.190 Prec@5 99.490 Loss 0.3792
Avg Loading time: 0.1116 seconds
Avg Batch time: 0.1695 seconds

Best acc: 89.750
--------------------------------------------------------------------------------
Test time: 14.19195294380188

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.033)	BT: 0.143 (0.193)	Loss 0.0466 (0.0756)	Prec@1 99.219 (97.556)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.017)	BT: 0.139 (0.182)	Loss 0.1440 (0.0852)	Prec@1 94.531 (97.180)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.072 (0.018)	BT: 0.168 (0.174)	Loss 0.1181 (0.0889)	Prec@1 94.531 (97.042)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.030)	BT: 0.137 (0.169)	Loss 0.1820 (0.0898)	Prec@1 91.406 (96.963)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.038)	BT: 0.073 (0.168)	Loss 0.0458 (0.0926)	Prec@1 99.219 (96.867)	
Total train loss: 0.0926
Avg Loading time: 0.0375 seconds
Avg Batch time: 0.1681 seconds

Train time: 65.9649305343628
 * Prec@1 88.710 Prec@5 99.540 Loss 0.3711
Avg Loading time: 0.1104 seconds
Avg Batch time: 0.1566 seconds

Best acc: 89.750
--------------------------------------------------------------------------------
Test time: 13.264823198318481

Epoch: [5][77/391]	LR: 0.1	DT: 0.580 (0.104)	BT: 0.661 (0.192)	Loss 0.0531 (0.0674)	Prec@1 97.656 (97.847)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.082)	BT: 0.129 (0.179)	Loss 0.0701 (0.0662)	Prec@1 96.875 (97.907)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.000 (0.056)	BT: 0.136 (0.172)	Loss 0.1287 (0.0699)	Prec@1 96.875 (97.780)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.044)	BT: 0.208 (0.175)	Loss 0.1022 (0.0729)	Prec@1 96.875 (97.671)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.036 (0.039)	BT: 0.170 (0.171)	Loss 0.0562 (0.0754)	Prec@1 98.438 (97.556)	
Total train loss: 0.0754
Avg Loading time: 0.0392 seconds
Avg Batch time: 0.1710 seconds

Train time: 67.01524567604065
 * Prec@1 90.980 Prec@5 99.630 Loss 0.3147
Avg Loading time: 0.1196 seconds
Avg Batch time: 0.1714 seconds

Best acc: 90.980
--------------------------------------------------------------------------------
Test time: 14.846091508865356

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.170 (0.182)	Loss 0.0662 (0.0521)	Prec@1 96.875 (98.317)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.142 (0.178)	Loss 0.0323 (0.0516)	Prec@1 99.219 (98.322)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.066 (0.015)	BT: 0.159 (0.172)	Loss 0.0423 (0.0533)	Prec@1 98.438 (98.277)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.013)	BT: 0.199 (0.171)	Loss 0.0898 (0.0570)	Prec@1 96.094 (98.170)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.011)	BT: 0.141 (0.172)	Loss 0.0850 (0.0623)	Prec@1 97.656 (98.005)	
Total train loss: 0.0625
Avg Loading time: 0.0111 seconds
Avg Batch time: 0.1716 seconds

Train time: 67.2822060585022
 * Prec@1 87.690 Prec@5 99.490 Loss 0.4075
Avg Loading time: 0.1070 seconds
Avg Batch time: 0.1576 seconds

Best acc: 90.980
--------------------------------------------------------------------------------
Test time: 13.26008415222168

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.030)	BT: 0.152 (0.191)	Loss 0.0351 (0.0501)	Prec@1 99.219 (98.508)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.017)	BT: 0.163 (0.178)	Loss 0.0169 (0.0449)	Prec@1 100.000 (98.678)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.019)	BT: 0.150 (0.175)	Loss 0.0479 (0.0499)	Prec@1 97.656 (98.441)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.204 (0.173)	Loss 0.0360 (0.0515)	Prec@1 98.438 (98.402)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.012)	BT: 0.141 (0.172)	Loss 0.0990 (0.0558)	Prec@1 96.875 (98.235)	
Total train loss: 0.0559
Avg Loading time: 0.0117 seconds
Avg Batch time: 0.1714 seconds

Train time: 67.21223258972168
 * Prec@1 90.350 Prec@5 99.430 Loss 0.3535
Avg Loading time: 0.1126 seconds
Avg Batch time: 0.1678 seconds

Best acc: 90.980
--------------------------------------------------------------------------------
Test time: 14.078110933303833

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.140 (0.176)	Loss 0.0390 (0.0483)	Prec@1 99.219 (98.548)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.020)	BT: 0.165 (0.175)	Loss 0.0974 (0.0499)	Prec@1 96.094 (98.422)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.013)	BT: 0.138 (0.174)	Loss 0.0533 (0.0481)	Prec@1 96.875 (98.438)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.010)	BT: 0.159 (0.172)	Loss 0.0633 (0.0484)	Prec@1 98.438 (98.468)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.010)	BT: 0.141 (0.171)	Loss 0.0363 (0.0516)	Prec@1 99.219 (98.321)	
Total train loss: 0.0517
Avg Loading time: 0.0101 seconds
Avg Batch time: 0.1706 seconds

Train time: 66.8656919002533
 * Prec@1 90.560 Prec@5 99.590 Loss 0.3171
Avg Loading time: 0.1015 seconds
Avg Batch time: 0.1556 seconds

Best acc: 90.980
--------------------------------------------------------------------------------
Test time: 13.169277667999268

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.025)	BT: 0.147 (0.195)	Loss 0.0399 (0.0377)	Prec@1 98.438 (98.878)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.015)	BT: 0.209 (0.182)	Loss 0.0930 (0.0363)	Prec@1 96.094 (98.913)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.010)	BT: 0.147 (0.178)	Loss 0.0307 (0.0388)	Prec@1 99.219 (98.808)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.193 (0.177)	Loss 0.0855 (0.0393)	Prec@1 96.094 (98.771)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.001 (0.007)	BT: 0.185 (0.173)	Loss 0.0642 (0.0404)	Prec@1 97.656 (98.720)	
Total train loss: 0.0404
Avg Loading time: 0.0075 seconds
Avg Batch time: 0.1729 seconds

Train time: 67.80160665512085
 * Prec@1 89.520 Prec@5 99.570 Loss 0.3550
Avg Loading time: 0.1139 seconds
Avg Batch time: 0.1704 seconds

Best acc: 90.980
--------------------------------------------------------------------------------
Test time: 14.242152690887451

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.001 (0.031)	BT: 0.146 (0.183)	Loss 0.0044 (0.0204)	Prec@1 100.000 (99.419)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.016)	BT: 0.181 (0.180)	Loss 0.0080 (0.0166)	Prec@1 100.000 (99.589)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.011)	BT: 0.169 (0.178)	Loss 0.0047 (0.0149)	Prec@1 100.000 (99.643)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.140 (0.177)	Loss 0.0022 (0.0134)	Prec@1 100.000 (99.692)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.134 (0.175)	Loss 0.0044 (0.0124)	Prec@1 100.000 (99.726)	
Total train loss: 0.0124
Avg Loading time: 0.0065 seconds
Avg Batch time: 0.1752 seconds

Train time: 68.66137981414795
 * Prec@1 93.890 Prec@5 99.750 Loss 0.2202
Avg Loading time: 0.1092 seconds
Avg Batch time: 0.1718 seconds

Best acc: 93.890
--------------------------------------------------------------------------------
Test time: 14.871273040771484

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.134 (0.188)	Loss 0.0040 (0.0049)	Prec@1 100.000 (99.950)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.182 (0.181)	Loss 0.0024 (0.0046)	Prec@1 100.000 (99.965)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.147 (0.180)	Loss 0.0017 (0.0045)	Prec@1 100.000 (99.967)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.139 (0.176)	Loss 0.0028 (0.0043)	Prec@1 100.000 (99.975)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.134 (0.175)	Loss 0.0030 (0.0043)	Prec@1 100.000 (99.970)	
Total train loss: 0.0043
Avg Loading time: 0.0054 seconds
Avg Batch time: 0.1753 seconds

Train time: 68.69741940498352
 * Prec@1 93.940 Prec@5 99.730 Loss 0.2214
Avg Loading time: 0.1026 seconds
Avg Batch time: 0.1618 seconds

Best acc: 93.940
--------------------------------------------------------------------------------
Test time: 14.051775693893433

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.026)	BT: 0.181 (0.196)	Loss 0.0048 (0.0034)	Prec@1 100.000 (99.980)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.206 (0.182)	Loss 0.0040 (0.0033)	Prec@1 100.000 (99.980)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.211 (0.179)	Loss 0.0021 (0.0034)	Prec@1 100.000 (99.980)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.140 (0.176)	Loss 0.0017 (0.0034)	Prec@1 100.000 (99.985)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.154 (0.173)	Loss 0.0027 (0.0033)	Prec@1 100.000 (99.988)	
Total train loss: 0.0033
Avg Loading time: 0.0053 seconds
Avg Batch time: 0.1727 seconds

Train time: 67.73828959465027
 * Prec@1 93.870 Prec@5 99.730 Loss 0.2186
Avg Loading time: 0.1002 seconds
Avg Batch time: 0.1653 seconds

Best acc: 93.940
--------------------------------------------------------------------------------
Test time: 13.87018895149231

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.027)	BT: 0.197 (0.187)	Loss 0.0014 (0.0029)	Prec@1 100.000 (99.990)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.181 (0.181)	Loss 0.0016 (0.0029)	Prec@1 100.000 (99.995)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.050 (0.020)	BT: 0.121 (0.170)	Loss 0.0020 (0.0030)	Prec@1 100.000 (99.990)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.060 (0.034)	BT: 0.152 (0.170)	Loss 0.0020 (0.0031)	Prec@1 100.000 (99.987)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.082 (0.043)	BT: 0.152 (0.169)	Loss 0.0039 (0.0031)	Prec@1 100.000 (99.986)	
Total train loss: 0.0031
Avg Loading time: 0.0428 seconds
Avg Batch time: 0.1691 seconds

Train time: 66.29319143295288
 * Prec@1 94.020 Prec@5 99.680 Loss 0.2172
Avg Loading time: 0.1143 seconds
Avg Batch time: 0.1651 seconds

Best acc: 94.020
--------------------------------------------------------------------------------
Test time: 15.082127332687378

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.094)	BT: 0.148 (0.229)	Loss 0.0035 (0.0027)	Prec@1 100.000 (99.980)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.048)	BT: 0.171 (0.195)	Loss 0.0026 (0.0026)	Prec@1 100.000 (99.990)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.033)	BT: 0.144 (0.188)	Loss 0.0018 (0.0026)	Prec@1 100.000 (99.993)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.036)	BT: 0.163 (0.181)	Loss 0.0009 (0.0026)	Prec@1 100.000 (99.995)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.152 (0.035)	BT: 0.222 (0.178)	Loss 0.0103 (0.0026)	Prec@1 100.000 (99.992)	
Total train loss: 0.0026
Avg Loading time: 0.0353 seconds
Avg Batch time: 0.1777 seconds

Train time: 69.6812858581543
 * Prec@1 93.930 Prec@5 99.680 Loss 0.2168
Avg Loading time: 0.1068 seconds
Avg Batch time: 0.1583 seconds

Best acc: 94.020
--------------------------------------------------------------------------------
Test time: 13.241787910461426

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.029)	BT: 0.150 (0.198)	Loss 0.0011 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.065 (0.017)	BT: 0.159 (0.184)	Loss 0.0035 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.015)	BT: 0.149 (0.178)	Loss 0.0023 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.179 (0.180)	Loss 0.0061 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.093 (0.012)	BT: 0.168 (0.175)	Loss 0.0020 (0.0023)	Prec@1 100.000 (100.000)	
Total train loss: 0.0023
Avg Loading time: 0.0124 seconds
Avg Batch time: 0.1749 seconds

Train time: 68.58115816116333
 * Prec@1 94.120 Prec@5 99.690 Loss 0.2152
Avg Loading time: 0.1058 seconds
Avg Batch time: 0.1682 seconds

Best acc: 94.120
--------------------------------------------------------------------------------
Test time: 14.546875

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.027)	BT: 0.147 (0.193)	Loss 0.0012 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.142 (0.180)	Loss 0.0060 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.190 (0.176)	Loss 0.0022 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.011)	BT: 0.229 (0.175)	Loss 0.0010 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.148 (0.175)	Loss 0.0032 (0.0024)	Prec@1 100.000 (99.996)	
Total train loss: 0.0024
Avg Loading time: 0.0128 seconds
Avg Batch time: 0.1746 seconds

Train time: 68.46924352645874
 * Prec@1 94.020 Prec@5 99.710 Loss 0.2172
Avg Loading time: 0.1014 seconds
Avg Batch time: 0.1512 seconds

Best acc: 94.120
--------------------------------------------------------------------------------
Test time: 12.764320850372314

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.028)	BT: 0.163 (0.201)	Loss 0.0012 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.015)	BT: 0.186 (0.187)	Loss 0.0020 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.010)	BT: 0.166 (0.181)	Loss 0.0015 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.151 (0.178)	Loss 0.0015 (0.0023)	Prec@1 100.000 (99.992)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.130 (0.176)	Loss 0.0021 (0.0022)	Prec@1 100.000 (99.992)	
Total train loss: 0.0022
Avg Loading time: 0.0082 seconds
Avg Batch time: 0.1756 seconds

Train time: 68.83493065834045
 * Prec@1 94.050 Prec@5 99.720 Loss 0.2159
Avg Loading time: 0.1194 seconds
Avg Batch time: 0.1737 seconds

Best acc: 94.120
--------------------------------------------------------------------------------
Test time: 14.48655366897583

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.028)	BT: 0.183 (0.199)	Loss 0.0017 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.168 (0.185)	Loss 0.0033 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.011)	BT: 0.154 (0.174)	Loss 0.0008 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.173 (0.175)	Loss 0.0040 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.127 (0.172)	Loss 0.0077 (0.0022)	Prec@1 100.000 (99.996)	
Total train loss: 0.0022
Avg Loading time: 0.0134 seconds
Avg Batch time: 0.1714 seconds

Train time: 67.13642430305481
 * Prec@1 94.200 Prec@5 99.740 Loss 0.2137
Avg Loading time: 0.0944 seconds
Avg Batch time: 0.1324 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 11.665759563446045

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.017)	BT: 0.143 (0.163)	Loss 0.0009 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.134 (0.151)	Loss 0.0016 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.134 (0.147)	Loss 0.0015 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.146 (0.144)	Loss 0.0022 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.132 (0.144)	Loss 0.0009 (0.0021)	Prec@1 100.000 (99.998)	
Total train loss: 0.0021
Avg Loading time: 0.0054 seconds
Avg Batch time: 0.1441 seconds

Train time: 56.47963070869446
 * Prec@1 94.180 Prec@5 99.710 Loss 0.2130
Avg Loading time: 0.1264 seconds
Avg Batch time: 0.1751 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 14.572915077209473

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.048)	BT: 0.078 (0.175)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.132 (0.158)	Loss 0.0020 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.016)	BT: 0.185 (0.152)	Loss 0.0006 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.088 (0.013)	BT: 0.222 (0.148)	Loss 0.0011 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.012)	BT: 0.081 (0.148)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0122 seconds
Avg Batch time: 0.1479 seconds

Train time: 57.96472668647766
 * Prec@1 94.200 Prec@5 99.740 Loss 0.2134
Avg Loading time: 0.1188 seconds
Avg Batch time: 0.1674 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 13.984847784042358

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.029)	BT: 0.128 (0.169)	Loss 0.0017 (0.0023)	Prec@1 100.000 (99.970)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.160 (0.162)	Loss 0.0015 (0.0022)	Prec@1 100.000 (99.970)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.010)	BT: 0.179 (0.165)	Loss 0.0023 (0.0022)	Prec@1 100.000 (99.980)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.156 (0.166)	Loss 0.0014 (0.0022)	Prec@1 100.000 (99.985)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.165 (0.166)	Loss 0.0014 (0.0021)	Prec@1 100.000 (99.988)	
Total train loss: 0.0021
Avg Loading time: 0.0061 seconds
Avg Batch time: 0.1654 seconds

Train time: 64.89730548858643
 * Prec@1 94.140 Prec@5 99.740 Loss 0.2137
Avg Loading time: 0.1069 seconds
Avg Batch time: 0.1684 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 14.071419954299927

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.028)	BT: 0.149 (0.193)	Loss 0.0033 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.014)	BT: 0.174 (0.180)	Loss 0.0010 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.010)	BT: 0.190 (0.176)	Loss 0.0020 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.140 (0.025)	BT: 0.212 (0.179)	Loss 0.0038 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.133 (0.178)	Loss 0.0034 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0257 seconds
Avg Batch time: 0.1780 seconds

Train time: 69.79216051101685
 * Prec@1 94.030 Prec@5 99.720 Loss 0.2144
Avg Loading time: 0.1074 seconds
Avg Batch time: 0.1719 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 14.361727476119995

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.032)	BT: 0.167 (0.180)	Loss 0.0020 (0.0025)	Prec@1 100.000 (99.990)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.038)	BT: 0.120 (0.174)	Loss 0.0045 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.037)	BT: 0.161 (0.172)	Loss 0.0011 (0.0023)	Prec@1 100.000 (99.993)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.001 (0.029)	BT: 0.171 (0.173)	Loss 0.0013 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.143 (0.173)	Loss 0.0013 (0.0022)	Prec@1 100.000 (99.996)	
Total train loss: 0.0022
Avg Loading time: 0.0237 seconds
Avg Batch time: 0.1726 seconds

Train time: 67.68823003768921
 * Prec@1 94.150 Prec@5 99.710 Loss 0.2170
Avg Loading time: 0.1079 seconds
Avg Batch time: 0.1650 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 13.809106588363647

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.033)	BT: 0.166 (0.200)	Loss 0.0015 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.180 (0.024)	BT: 0.252 (0.181)	Loss 0.0023 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.019)	BT: 0.159 (0.178)	Loss 0.0019 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.160 (0.177)	Loss 0.0006 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.016)	BT: 0.136 (0.176)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.992)	
Total train loss: 0.0021
Avg Loading time: 0.0156 seconds
Avg Batch time: 0.1754 seconds

Train time: 68.74086904525757
 * Prec@1 94.190 Prec@5 99.720 Loss 0.2128
Avg Loading time: 0.1095 seconds
Avg Batch time: 0.1631 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 13.681695938110352

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.029)	BT: 0.157 (0.201)	Loss 0.0016 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.025)	BT: 0.182 (0.182)	Loss 0.0026 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.021)	BT: 0.129 (0.184)	Loss 0.0017 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.018)	BT: 0.234 (0.180)	Loss 0.0014 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.014)	BT: 0.136 (0.181)	Loss 0.0031 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0142 seconds
Avg Batch time: 0.1812 seconds

Train time: 71.00461101531982
 * Prec@1 93.990 Prec@5 99.700 Loss 0.2158
Avg Loading time: 0.1152 seconds
Avg Batch time: 0.1701 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 14.260641098022461

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.028)	BT: 0.142 (0.198)	Loss 0.0014 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.014)	BT: 0.136 (0.183)	Loss 0.0009 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.013)	BT: 0.158 (0.177)	Loss 0.0016 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.010)	BT: 0.185 (0.175)	Loss 0.0018 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.009)	BT: 0.178 (0.176)	Loss 0.0021 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.0089 seconds
Avg Batch time: 0.1762 seconds

Train time: 69.1029326915741
 * Prec@1 94.170 Prec@5 99.740 Loss 0.2122
Avg Loading time: 0.1070 seconds
Avg Batch time: 0.1596 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 13.411052465438843

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.031)	BT: 0.157 (0.196)	Loss 0.0007 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.001 (0.030)	BT: 0.096 (0.173)	Loss 0.0021 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.126 (0.022)	BT: 0.261 (0.174)	Loss 0.0033 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.017)	BT: 0.135 (0.172)	Loss 0.0010 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.014)	BT: 0.152 (0.173)	Loss 0.0004 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0138 seconds
Avg Batch time: 0.1726 seconds

Train time: 67.67661261558533
 * Prec@1 94.180 Prec@5 99.720 Loss 0.2136
Avg Loading time: 0.1117 seconds
Avg Batch time: 0.1669 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 13.988336324691772

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.165 (0.194)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.012)	BT: 0.256 (0.182)	Loss 0.0015 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.009)	BT: 0.197 (0.174)	Loss 0.0029 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.140 (0.176)	Loss 0.0015 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.140 (0.175)	Loss 0.0034 (0.0021)	Prec@1 100.000 (100.000)	
Total train loss: 0.0021
Avg Loading time: 0.0057 seconds
Avg Batch time: 0.1743 seconds

Train time: 68.3395836353302
 * Prec@1 94.190 Prec@5 99.720 Loss 0.2148
Avg Loading time: 0.1113 seconds
Avg Batch time: 0.1738 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 14.554056406021118

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.029)	BT: 0.167 (0.199)	Loss 0.0018 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.149 (0.184)	Loss 0.0019 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.010)	BT: 0.150 (0.180)	Loss 0.0008 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.140 (0.179)	Loss 0.0027 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.186 (0.174)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0060 seconds
Avg Batch time: 0.1739 seconds

Train time: 68.18999886512756
 * Prec@1 93.920 Prec@5 99.720 Loss 0.2164
Avg Loading time: 0.1061 seconds
Avg Batch time: 0.1700 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 14.244939088821411

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.023)	BT: 0.197 (0.184)	Loss 0.0015 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.139 (0.180)	Loss 0.0014 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.128 (0.172)	Loss 0.0026 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.035 (0.009)	BT: 0.253 (0.172)	Loss 0.0011 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.025)	BT: 0.151 (0.174)	Loss 0.0011 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0252 seconds
Avg Batch time: 0.1737 seconds

Train time: 68.12115907669067
 * Prec@1 94.200 Prec@5 99.730 Loss 0.2150
Avg Loading time: 0.1046 seconds
Avg Batch time: 0.1655 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 13.877272129058838

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.028)	BT: 0.187 (0.196)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.018)	BT: 0.146 (0.179)	Loss 0.0049 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.066 (0.029)	BT: 0.147 (0.170)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.028)	BT: 0.148 (0.170)	Loss 0.0030 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.023)	BT: 0.141 (0.170)	Loss 0.0026 (0.0021)	Prec@1 100.000 (99.998)	
Total train loss: 0.0021
Avg Loading time: 0.0227 seconds
Avg Batch time: 0.1702 seconds

Train time: 66.7414722442627
 * Prec@1 94.070 Prec@5 99.730 Loss 0.2134
Avg Loading time: 0.1146 seconds
Avg Batch time: 0.1671 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 13.990168571472168

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.029)	BT: 0.193 (0.193)	Loss 0.0011 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.170 (0.180)	Loss 0.0022 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.018)	BT: 0.170 (0.177)	Loss 0.0005 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.203 (0.177)	Loss 0.0028 (0.0021)	Prec@1 100.000 (99.992)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.013)	BT: 0.137 (0.177)	Loss 0.0018 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.0129 seconds
Avg Batch time: 0.1764 seconds

Train time: 69.1581563949585
 * Prec@1 94.020 Prec@5 99.700 Loss 0.2142
Avg Loading time: 0.1159 seconds
Avg Batch time: 0.1739 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 14.545109272003174

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.025)	BT: 0.188 (0.192)	Loss 0.0020 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.001 (0.013)	BT: 0.203 (0.181)	Loss 0.0026 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.168 (0.178)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.031 (0.016)	BT: 0.163 (0.176)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.130 (0.175)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0158 seconds
Avg Batch time: 0.1750 seconds

Train time: 68.5477364063263
 * Prec@1 94.090 Prec@5 99.700 Loss 0.2126
Avg Loading time: 0.1118 seconds
Avg Batch time: 0.1633 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 13.737412214279175

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.040)	BT: 0.148 (0.194)	Loss 0.0037 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.022)	BT: 0.226 (0.183)	Loss 0.0019 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.176 (0.181)	Loss 0.0034 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.115 (0.015)	BT: 0.287 (0.176)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.036 (0.014)	BT: 0.173 (0.177)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0138 seconds
Avg Batch time: 0.1768 seconds

Train time: 69.34446740150452
 * Prec@1 94.110 Prec@5 99.740 Loss 0.2128
Avg Loading time: 0.1024 seconds
Avg Batch time: 0.1571 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 13.166768312454224

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.012 (0.046)	BT: 0.178 (0.191)	Loss 0.0023 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.025)	BT: 0.161 (0.176)	Loss 0.0009 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.001 (0.029)	BT: 0.147 (0.174)	Loss 0.0036 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.026)	BT: 0.201 (0.172)	Loss 0.0025 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.022)	BT: 0.137 (0.170)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0217 seconds
Avg Batch time: 0.1702 seconds

Train time: 66.73185515403748
 * Prec@1 94.040 Prec@5 99.740 Loss 0.2150
Avg Loading time: 0.1048 seconds
Avg Batch time: 0.1675 seconds

Best acc: 94.200
--------------------------------------------------------------------------------
Test time: 13.953962326049805

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.042 (0.026)	BT: 0.196 (0.195)	Loss 0.0034 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.152 (0.181)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.149 (0.179)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.205 (0.176)	Loss 0.0020 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.161 (0.175)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0074 seconds
Avg Batch time: 0.1743 seconds

Train time: 68.3673415184021
 * Prec@1 94.220 Prec@5 99.690 Loss 0.2134
Avg Loading time: 0.1140 seconds
Avg Batch time: 0.1695 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 14.676836729049683

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.002 (0.028)	BT: 0.198 (0.192)	Loss 0.0010 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.150 (0.181)	Loss 0.0028 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.164 (0.177)	Loss 0.0014 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.154 (0.176)	Loss 0.0008 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.138 (0.172)	Loss 0.0052 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.0072 seconds
Avg Batch time: 0.1720 seconds

Train time: 67.47070503234863
 * Prec@1 94.150 Prec@5 99.720 Loss 0.2140
Avg Loading time: 0.1110 seconds
Avg Batch time: 0.1711 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 14.243316888809204

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.026)	BT: 0.142 (0.194)	Loss 0.0015 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.013)	BT: 0.195 (0.184)	Loss 0.0011 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.136 (0.169)	Loss 0.0018 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.209 (0.163)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.992)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.129 (0.159)	Loss 0.0024 (0.0019)	Prec@1 100.000 (99.994)	
Total train loss: 0.0019
Avg Loading time: 0.0054 seconds
Avg Batch time: 0.1587 seconds

Train time: 62.20095872879028
 * Prec@1 94.110 Prec@5 99.700 Loss 0.2155
Avg Loading time: 0.0951 seconds
Avg Batch time: 0.1396 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 12.113292217254639

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.111)	BT: 0.124 (0.229)	Loss 0.0017 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.056)	BT: 0.142 (0.185)	Loss 0.0021 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.037)	BT: 0.138 (0.171)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.993)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.028)	BT: 0.159 (0.160)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.029)	BT: 0.125 (0.153)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0292 seconds
Avg Batch time: 0.1529 seconds

Train time: 59.90838575363159
 * Prec@1 94.110 Prec@5 99.710 Loss 0.2136
Avg Loading time: 0.0961 seconds
Avg Batch time: 0.1429 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 11.995852947235107

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.003 (0.026)	BT: 0.138 (0.168)	Loss 0.0015 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.013)	BT: 0.174 (0.162)	Loss 0.0008 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.139 (0.162)	Loss 0.0016 (0.0021)	Prec@1 100.000 (99.993)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.149 (0.159)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.131 (0.161)	Loss 0.0014 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0093 seconds
Avg Batch time: 0.1606 seconds

Train time: 62.948843002319336
 * Prec@1 94.110 Prec@5 99.730 Loss 0.2148
Avg Loading time: 0.1108 seconds
Avg Batch time: 0.1648 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 13.80264949798584

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.034)	BT: 0.140 (0.195)	Loss 0.0011 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.017)	BT: 0.156 (0.182)	Loss 0.0012 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.162 (0.172)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.156 (0.170)	Loss 0.0033 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.145 (0.169)	Loss 0.0048 (0.0021)	Prec@1 100.000 (99.992)	
Total train loss: 0.0021
Avg Loading time: 0.0077 seconds
Avg Batch time: 0.1683 seconds

Train time: 66.03192806243896
 * Prec@1 93.990 Prec@5 99.690 Loss 0.2148
Avg Loading time: 0.1089 seconds
Avg Batch time: 0.1682 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 13.982689142227173

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.027)	BT: 0.221 (0.192)	Loss 0.0023 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.020)	BT: 0.130 (0.175)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.240 (0.174)	Loss 0.0030 (0.0021)	Prec@1 100.000 (99.993)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.146 (0.172)	Loss 0.0021 (0.0021)	Prec@1 100.000 (99.992)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.169 (0.171)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.992)	
Total train loss: 0.0021
Avg Loading time: 0.0098 seconds
Avg Batch time: 0.1711 seconds

Train time: 67.0927038192749
 * Prec@1 93.960 Prec@5 99.700 Loss 0.2158
Avg Loading time: 0.1061 seconds
Avg Batch time: 0.1636 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 14.19132375717163

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.031)	BT: 0.078 (0.196)	Loss 0.0026 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.016)	BT: 0.139 (0.178)	Loss 0.0011 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.136 (0.175)	Loss 0.0007 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.144 (0.172)	Loss 0.0017 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.135 (0.168)	Loss 0.0014 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0069 seconds
Avg Batch time: 0.1679 seconds

Train time: 65.86294603347778
 * Prec@1 94.100 Prec@5 99.730 Loss 0.2126
Avg Loading time: 0.1113 seconds
Avg Batch time: 0.1712 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 14.31374740600586

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.031)	BT: 0.155 (0.184)	Loss 0.0007 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.016)	BT: 0.176 (0.181)	Loss 0.0026 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.182 (0.177)	Loss 0.0025 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.193 (0.175)	Loss 0.0009 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.136 (0.172)	Loss 0.0009 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0064 seconds
Avg Batch time: 0.1718 seconds

Train time: 67.351571559906
 * Prec@1 94.040 Prec@5 99.710 Loss 0.2140
Avg Loading time: 0.1088 seconds
Avg Batch time: 0.1666 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 13.880658864974976

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.028)	BT: 0.175 (0.193)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.226 (0.178)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.001 (0.009)	BT: 0.190 (0.176)	Loss 0.0017 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.092 (0.173)	Loss 0.0027 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.035 (0.006)	BT: 0.178 (0.172)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0059 seconds
Avg Batch time: 0.1717 seconds

Train time: 67.2661063671112
 * Prec@1 94.070 Prec@5 99.700 Loss 0.2148
Avg Loading time: 0.1130 seconds
Avg Batch time: 0.1666 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 13.958651781082153

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.028)	BT: 0.150 (0.196)	Loss 0.0025 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.145 (0.183)	Loss 0.0016 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.001 (0.010)	BT: 0.206 (0.176)	Loss 0.0010 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.002 (0.007)	BT: 0.156 (0.172)	Loss 0.0014 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.135 (0.169)	Loss 0.0023 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0059 seconds
Avg Batch time: 0.1692 seconds

Train time: 66.35983657836914
 * Prec@1 93.990 Prec@5 99.700 Loss 0.2122
Avg Loading time: 0.1097 seconds
Avg Batch time: 0.1648 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 13.797383785247803

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.029)	BT: 0.151 (0.189)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.001 (0.015)	BT: 0.197 (0.176)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.005 (0.011)	BT: 0.104 (0.168)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.034)	BT: 0.167 (0.178)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.992)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.027)	BT: 0.128 (0.176)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.0271 seconds
Avg Batch time: 0.1756 seconds

Train time: 68.79771447181702
 * Prec@1 94.110 Prec@5 99.720 Loss 0.2146
Avg Loading time: 0.1156 seconds
Avg Batch time: 0.1709 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 14.308376550674438

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.035)	BT: 0.144 (0.172)	Loss 0.0033 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.046 (0.042)	BT: 0.150 (0.162)	Loss 0.0017 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.034)	BT: 0.141 (0.165)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.026)	BT: 0.140 (0.167)	Loss 0.0009 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.022)	BT: 0.096 (0.167)	Loss 0.0025 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0223 seconds
Avg Batch time: 0.1663 seconds

Train time: 65.20941376686096
 * Prec@1 94.130 Prec@5 99.740 Loss 0.2140
Avg Loading time: 0.1071 seconds
Avg Batch time: 0.1625 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 13.656537532806396

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.031)	BT: 0.203 (0.199)	Loss 0.0022 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.020)	BT: 0.175 (0.181)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.183 (0.178)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.150 (0.175)	Loss 0.0022 (0.0020)	Prec@1 100.000 (99.992)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.128 (0.170)	Loss 0.0027 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.0097 seconds
Avg Batch time: 0.1700 seconds

Train time: 66.6619336605072
 * Prec@1 94.200 Prec@5 99.740 Loss 0.2130
Avg Loading time: 0.1097 seconds
Avg Batch time: 0.1762 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 14.714539766311646


      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 7
Savedir:  ../pretrained_models/frozen/x64-8b/rram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/train/relu7
Test path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/test/relu7
ResNet18(
  (conv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 9.980 Prec@5 51.410 Loss 2.2930
Avg Loading time: 0.1004 seconds
Avg Batch time: 0.1459 seconds

Pre-trained Prec@1 with 7 layers frozen: 9.979999542236328 	 Loss: 2.29296875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.112 (0.675)	BT: 0.209 (0.765)	Loss 0.4207 (0.6679)	Prec@1 87.500 (79.237)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (0.630)	BT: 0.074 (0.722)	Loss 0.3684 (0.5515)	Prec@1 89.844 (82.207)	
Epoch: [0][233/391]	LR: 0.1	DT: 2.921 (0.631)	BT: 3.019 (0.724)	Loss 0.3352 (0.4942)	Prec@1 87.500 (84.068)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (0.600)	BT: 0.048 (0.692)	Loss 0.3264 (0.4586)	Prec@1 89.844 (85.239)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (0.591)	BT: 0.097 (0.684)	Loss 0.2593 (0.4338)	Prec@1 90.625 (85.881)	
Total train loss: 0.4336
Avg Loading time: 0.5896 seconds
Avg Batch time: 0.6823 seconds

Train time: 266.94079995155334
 * Prec@1 88.700 Prec@5 99.710 Loss 0.3423
Avg Loading time: 0.0759 seconds
Avg Batch time: 0.1038 seconds

Best acc: 88.700
--------------------------------------------------------------------------------
Test time: 9.375182867050171

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.101 (0.131)	Loss 0.1849 (0.2182)	Prec@1 94.531 (92.698)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.011)	BT: 0.093 (0.116)	Loss 0.2083 (0.2193)	Prec@1 93.750 (92.588)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.147 (0.113)	Loss 0.2554 (0.2212)	Prec@1 92.188 (92.498)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.092 (0.110)	Loss 0.2064 (0.2234)	Prec@1 93.750 (92.428)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.087 (0.108)	Loss 0.2123 (0.2267)	Prec@1 92.969 (92.332)	
Total train loss: 0.2266
Avg Loading time: 0.0047 seconds
Avg Batch time: 0.1080 seconds

Train time: 42.375295877456665
 * Prec@1 91.150 Prec@5 99.700 Loss 0.2749
Avg Loading time: 0.0563 seconds
Avg Batch time: 0.0903 seconds

Best acc: 91.150
--------------------------------------------------------------------------------
Test time: 8.382067441940308

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.092 (0.133)	Loss 0.1104 (0.1308)	Prec@1 96.875 (95.753)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.012)	BT: 0.090 (0.119)	Loss 0.1500 (0.1320)	Prec@1 93.750 (95.603)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.055 (0.122)	Loss 0.1222 (0.1384)	Prec@1 93.750 (95.296)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.035)	BT: 0.112 (0.127)	Loss 0.1411 (0.1451)	Prec@1 96.094 (95.037)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.089 (0.121)	Loss 0.1527 (0.1507)	Prec@1 94.531 (94.828)	
Total train loss: 0.1508
Avg Loading time: 0.0281 seconds
Avg Batch time: 0.1212 seconds

Train time: 47.63258075714111
 * Prec@1 87.780 Prec@5 99.450 Loss 0.3889
Avg Loading time: 0.0664 seconds
Avg Batch time: 0.1009 seconds

Best acc: 91.150
--------------------------------------------------------------------------------
Test time: 8.766931533813477

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.091 (0.122)	Loss 0.0782 (0.0802)	Prec@1 97.656 (97.646)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.011)	BT: 0.142 (0.113)	Loss 0.0993 (0.0872)	Prec@1 96.875 (97.216)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.011)	BT: 0.092 (0.106)	Loss 0.1626 (0.0918)	Prec@1 94.531 (97.075)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.002 (0.008)	BT: 0.072 (0.102)	Loss 0.0600 (0.0970)	Prec@1 98.438 (96.845)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.009)	BT: 0.047 (0.096)	Loss 0.1392 (0.1015)	Prec@1 94.531 (96.679)	
Total train loss: 0.1016
Avg Loading time: 0.0094 seconds
Avg Batch time: 0.0956 seconds

Train time: 37.60056400299072
 * Prec@1 87.430 Prec@5 99.260 Loss 0.4441
Avg Loading time: 0.0632 seconds
Avg Batch time: 0.0901 seconds

Best acc: 91.150
--------------------------------------------------------------------------------
Test time: 7.887146711349487

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.020)	BT: 0.087 (0.123)	Loss 0.0726 (0.0819)	Prec@1 98.438 (97.556)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.010)	BT: 0.099 (0.114)	Loss 0.0283 (0.0770)	Prec@1 99.219 (97.571)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.101 (0.111)	Loss 0.0582 (0.0759)	Prec@1 98.438 (97.529)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.103 (0.109)	Loss 0.0520 (0.0769)	Prec@1 98.438 (97.451)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.092 (0.104)	Loss 0.1117 (0.0807)	Prec@1 96.875 (97.324)	
Total train loss: 0.0808
Avg Loading time: 0.0063 seconds
Avg Batch time: 0.1044 seconds

Train time: 41.02240204811096
 * Prec@1 88.920 Prec@5 99.610 Loss 0.3611
Avg Loading time: 0.0657 seconds
Avg Batch time: 0.0945 seconds

Best acc: 91.150
--------------------------------------------------------------------------------
Test time: 8.210849285125732

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.016)	BT: 0.093 (0.121)	Loss 0.1250 (0.0623)	Prec@1 96.875 (97.927)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.088 (0.110)	Loss 0.0229 (0.0566)	Prec@1 99.219 (98.162)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.088 (0.105)	Loss 0.0384 (0.0552)	Prec@1 99.219 (98.214)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.093 (0.096)	Loss 0.0571 (0.0602)	Prec@1 99.219 (98.057)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.003)	BT: 0.090 (0.096)	Loss 0.0671 (0.0633)	Prec@1 97.656 (97.949)	
Total train loss: 0.0633
Avg Loading time: 0.0033 seconds
Avg Batch time: 0.0961 seconds

Train time: 37.7206768989563
 * Prec@1 90.280 Prec@5 99.570 Loss 0.3210
Avg Loading time: 0.0440 seconds
Avg Batch time: 0.0643 seconds

Best acc: 91.150
--------------------------------------------------------------------------------
Test time: 5.751348495483398

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.017)	BT: 0.089 (0.112)	Loss 0.0688 (0.0550)	Prec@1 98.438 (98.157)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.009)	BT: 0.099 (0.104)	Loss 0.0447 (0.0535)	Prec@1 98.438 (98.262)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.089 (0.101)	Loss 0.0741 (0.0547)	Prec@1 96.094 (98.244)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.119 (0.006)	BT: 0.176 (0.096)	Loss 0.0656 (0.0531)	Prec@1 96.875 (98.307)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.102 (0.096)	Loss 0.0909 (0.0547)	Prec@1 95.312 (98.243)	
Total train loss: 0.0547
Avg Loading time: 0.0054 seconds
Avg Batch time: 0.0957 seconds

Train time: 37.60889387130737
 * Prec@1 90.340 Prec@5 99.500 Loss 0.3391
Avg Loading time: 0.0732 seconds
Avg Batch time: 0.1008 seconds

Best acc: 91.150
--------------------------------------------------------------------------------
Test time: 8.685240268707275

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.021)	BT: 0.092 (0.117)	Loss 0.0741 (0.0436)	Prec@1 96.875 (98.758)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.011)	BT: 0.089 (0.107)	Loss 0.0584 (0.0420)	Prec@1 97.656 (98.758)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.044 (0.101)	Loss 0.0402 (0.0455)	Prec@1 98.438 (98.554)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.012)	BT: 0.047 (0.099)	Loss 0.0295 (0.0467)	Prec@1 99.219 (98.505)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.010)	BT: 0.088 (0.097)	Loss 0.0682 (0.0498)	Prec@1 96.875 (98.399)	
Total train loss: 0.0498
Avg Loading time: 0.0102 seconds
Avg Batch time: 0.0969 seconds

Train time: 38.04794239997864
 * Prec@1 90.870 Prec@5 99.490 Loss 0.3203
Avg Loading time: 0.0458 seconds
Avg Batch time: 0.0739 seconds

Best acc: 91.150
--------------------------------------------------------------------------------
Test time: 6.637788534164429

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.095 (0.112)	Loss 0.0162 (0.0361)	Prec@1 99.219 (98.898)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.012)	BT: 0.092 (0.107)	Loss 0.0052 (0.0312)	Prec@1 100.000 (99.064)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.091 (0.106)	Loss 0.0153 (0.0302)	Prec@1 100.000 (99.089)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.110 (0.105)	Loss 0.0371 (0.0319)	Prec@1 98.438 (99.008)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.093 (0.104)	Loss 0.0452 (0.0348)	Prec@1 98.438 (98.900)	
Total train loss: 0.0349
Avg Loading time: 0.0051 seconds
Avg Batch time: 0.1043 seconds

Train time: 40.994829416275024
 * Prec@1 91.010 Prec@5 99.730 Loss 0.2969
Avg Loading time: 0.0646 seconds
Avg Batch time: 0.0920 seconds

Best acc: 91.150
--------------------------------------------------------------------------------
Test time: 7.9443652629852295

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.095 (0.125)	Loss 0.0349 (0.0347)	Prec@1 98.438 (98.938)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.011)	BT: 0.124 (0.114)	Loss 0.0478 (0.0330)	Prec@1 98.438 (98.988)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.093 (0.111)	Loss 0.0276 (0.0335)	Prec@1 99.219 (98.975)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.100 (0.108)	Loss 0.0581 (0.0331)	Prec@1 98.438 (98.998)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.088 (0.107)	Loss 0.0367 (0.0349)	Prec@1 99.219 (98.930)	
Total train loss: 0.0349
Avg Loading time: 0.0046 seconds
Avg Batch time: 0.1072 seconds

Train time: 42.15296506881714
 * Prec@1 89.960 Prec@5 99.500 Loss 0.3767
Avg Loading time: 0.0553 seconds
Avg Batch time: 0.0810 seconds

Best acc: 91.150
--------------------------------------------------------------------------------
Test time: 7.157309532165527

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.017)	BT: 0.157 (0.123)	Loss 0.0067 (0.0228)	Prec@1 100.000 (99.419)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.110 (0.113)	Loss 0.0156 (0.0178)	Prec@1 100.000 (99.534)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.088 (0.109)	Loss 0.0082 (0.0147)	Prec@1 100.000 (99.639)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.094 (0.108)	Loss 0.0024 (0.0132)	Prec@1 100.000 (99.695)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.090 (0.105)	Loss 0.0131 (0.0120)	Prec@1 99.219 (99.722)	
Total train loss: 0.0120
Avg Loading time: 0.0038 seconds
Avg Batch time: 0.1047 seconds

Train time: 41.152090549468994
 * Prec@1 93.730 Prec@5 99.710 Loss 0.2262
Avg Loading time: 0.0562 seconds
Avg Batch time: 0.0846 seconds

Best acc: 93.730
--------------------------------------------------------------------------------
Test time: 7.9042885303497314

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.017)	BT: 0.092 (0.120)	Loss 0.0118 (0.0037)	Prec@1 100.000 (99.980)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.010)	BT: 0.079 (0.106)	Loss 0.0031 (0.0041)	Prec@1 100.000 (99.970)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.012)	BT: 0.060 (0.098)	Loss 0.0090 (0.0041)	Prec@1 100.000 (99.977)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.010)	BT: 0.103 (0.099)	Loss 0.0024 (0.0041)	Prec@1 100.000 (99.970)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.091 (0.100)	Loss 0.0018 (0.0039)	Prec@1 100.000 (99.976)	
Total train loss: 0.0039
Avg Loading time: 0.0077 seconds
Avg Batch time: 0.0997 seconds

Train time: 39.212509632110596
 * Prec@1 94.040 Prec@5 99.730 Loss 0.2209
Avg Loading time: 0.0574 seconds
Avg Batch time: 0.0868 seconds

Best acc: 94.040
--------------------------------------------------------------------------------
Test time: 8.047532558441162

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.021)	BT: 0.101 (0.127)	Loss 0.0022 (0.0035)	Prec@1 100.000 (99.970)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.011)	BT: 0.127 (0.117)	Loss 0.0015 (0.0033)	Prec@1 100.000 (99.985)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.100 (0.107)	Loss 0.0017 (0.0031)	Prec@1 100.000 (99.990)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.093 (0.105)	Loss 0.0019 (0.0031)	Prec@1 100.000 (99.990)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.105 (0.105)	Loss 0.0018 (0.0031)	Prec@1 100.000 (99.990)	
Total train loss: 0.0031
Avg Loading time: 0.0048 seconds
Avg Batch time: 0.1049 seconds

Train time: 41.20614790916443
 * Prec@1 93.950 Prec@5 99.740 Loss 0.2220
Avg Loading time: 0.0705 seconds
Avg Batch time: 0.0966 seconds

Best acc: 94.040
--------------------------------------------------------------------------------
Test time: 8.425459384918213

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.021)	BT: 0.100 (0.124)	Loss 0.0026 (0.0030)	Prec@1 100.000 (100.000)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.011)	BT: 0.103 (0.113)	Loss 0.0011 (0.0029)	Prec@1 100.000 (100.000)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.121 (0.107)	Loss 0.0009 (0.0028)	Prec@1 100.000 (100.000)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.099 (0.106)	Loss 0.0015 (0.0028)	Prec@1 100.000 (100.000)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.104 (0.106)	Loss 0.0027 (0.0028)	Prec@1 100.000 (99.998)	
Total train loss: 0.0028
Avg Loading time: 0.0045 seconds
Avg Batch time: 0.1055 seconds

Train time: 41.437096118927
 * Prec@1 94.030 Prec@5 99.720 Loss 0.2209
Avg Loading time: 0.0583 seconds
Avg Batch time: 0.0860 seconds

Best acc: 94.040
--------------------------------------------------------------------------------
Test time: 7.463633298873901

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.019)	BT: 0.087 (0.124)	Loss 0.0061 (0.0030)	Prec@1 100.000 (99.990)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.010)	BT: 0.127 (0.112)	Loss 0.0019 (0.0028)	Prec@1 100.000 (99.990)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.107 (0.108)	Loss 0.0016 (0.0028)	Prec@1 100.000 (99.990)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.094 (0.107)	Loss 0.0014 (0.0027)	Prec@1 100.000 (99.990)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.101 (0.105)	Loss 0.0006 (0.0027)	Prec@1 100.000 (99.988)	
Total train loss: 0.0027
Avg Loading time: 0.0041 seconds
Avg Batch time: 0.1048 seconds

Train time: 41.183741331100464
 * Prec@1 94.050 Prec@5 99.720 Loss 0.2200
Avg Loading time: 0.0516 seconds
Avg Batch time: 0.0827 seconds

Best acc: 94.050
--------------------------------------------------------------------------------
Test time: 7.784405708312988

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.019)	BT: 0.094 (0.120)	Loss 0.0013 (0.0025)	Prec@1 100.000 (100.000)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.010)	BT: 0.092 (0.112)	Loss 0.0019 (0.0026)	Prec@1 100.000 (100.000)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.087 (0.108)	Loss 0.0013 (0.0025)	Prec@1 100.000 (100.000)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.001 (0.005)	BT: 0.093 (0.106)	Loss 0.0021 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.088 (0.104)	Loss 0.0033 (0.0025)	Prec@1 100.000 (100.000)	
Total train loss: 0.0025
Avg Loading time: 0.0041 seconds
Avg Batch time: 0.1042 seconds

Train time: 40.9280309677124
 * Prec@1 94.040 Prec@5 99.760 Loss 0.2209
Avg Loading time: 0.0550 seconds
Avg Batch time: 0.0840 seconds

Best acc: 94.050
--------------------------------------------------------------------------------
Test time: 7.373277425765991

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.021)	BT: 0.094 (0.119)	Loss 0.0029 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.011)	BT: 0.131 (0.112)	Loss 0.0008 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.087 (0.108)	Loss 0.0013 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.001 (0.006)	BT: 0.149 (0.106)	Loss 0.0010 (0.0023)	Prec@1 100.000 (99.997)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.001 (0.005)	BT: 0.086 (0.105)	Loss 0.0018 (0.0023)	Prec@1 100.000 (99.998)	
Total train loss: 0.0023
Avg Loading time: 0.0045 seconds
Avg Batch time: 0.1047 seconds

Train time: 41.17573952674866
 * Prec@1 94.100 Prec@5 99.710 Loss 0.2177
Avg Loading time: 0.0536 seconds
Avg Batch time: 0.0835 seconds

Best acc: 94.100
--------------------------------------------------------------------------------
Test time: 7.880093336105347

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.091 (0.121)	Loss 0.0016 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.005 (0.009)	BT: 0.105 (0.112)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.104 (0.107)	Loss 0.0045 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.100 (0.107)	Loss 0.0023 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.040 (0.114)	Loss 0.0016 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0216 seconds
Avg Batch time: 0.1141 seconds

Train time: 44.79900050163269
 * Prec@1 94.080 Prec@5 99.720 Loss 0.2196
Avg Loading time: 0.0598 seconds
Avg Batch time: 0.0875 seconds

Best acc: 94.100
--------------------------------------------------------------------------------
Test time: 7.657072305679321

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.017)	BT: 0.101 (0.123)	Loss 0.0015 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.086 (0.113)	Loss 0.0025 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.105 (0.109)	Loss 0.0022 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.029 (0.005)	BT: 0.119 (0.104)	Loss 0.0031 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.057 (0.102)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0087 seconds
Avg Batch time: 0.1015 seconds

Train time: 39.88911414146423
 * Prec@1 94.120 Prec@5 99.740 Loss 0.2190
Avg Loading time: 0.0568 seconds
Avg Batch time: 0.0866 seconds

Best acc: 94.120
--------------------------------------------------------------------------------
Test time: 8.084062576293945

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.043)	BT: 0.086 (0.101)	Loss 0.0016 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.099 (0.104)	Loss 0.0019 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.094 (0.101)	Loss 0.0017 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.011)	BT: 0.090 (0.101)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.106 (0.101)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.998)	
Total train loss: 0.0021
Avg Loading time: 0.0088 seconds
Avg Batch time: 0.1012 seconds

Train time: 39.77353835105896
 * Prec@1 94.130 Prec@5 99.710 Loss 0.2177
Avg Loading time: 0.0568 seconds
Avg Batch time: 0.0857 seconds

Best acc: 94.130
--------------------------------------------------------------------------------
Test time: 7.976895809173584

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.098 (0.118)	Loss 0.0026 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.001 (0.011)	BT: 0.093 (0.109)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.087 (0.106)	Loss 0.0018 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.092 (0.105)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.091 (0.105)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0048 seconds
Avg Batch time: 0.1048 seconds

Train time: 41.20417356491089
 * Prec@1 94.060 Prec@5 99.720 Loss 0.2180
Avg Loading time: 0.0630 seconds
Avg Batch time: 0.0889 seconds

Best acc: 94.130
--------------------------------------------------------------------------------
Test time: 7.756330251693726

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.103 (0.124)	Loss 0.0015 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.011)	BT: 0.091 (0.115)	Loss 0.0022 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.105 (0.110)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.094 (0.109)	Loss 0.0010 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.101 (0.105)	Loss 0.0017 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.0051 seconds
Avg Batch time: 0.1045 seconds

Train time: 41.07999110221863
 * Prec@1 94.160 Prec@5 99.700 Loss 0.2174
Avg Loading time: 0.0467 seconds
Avg Batch time: 0.0763 seconds

Best acc: 94.160
--------------------------------------------------------------------------------
Test time: 7.182963848114014

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.021)	BT: 0.095 (0.122)	Loss 0.0013 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.011)	BT: 0.093 (0.114)	Loss 0.0109 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.101 (0.109)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.090 (0.105)	Loss 0.0024 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.093 (0.104)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0064 seconds
Avg Batch time: 0.1043 seconds

Train time: 40.98449087142944
 * Prec@1 94.120 Prec@5 99.670 Loss 0.2192
Avg Loading time: 0.0604 seconds
Avg Batch time: 0.0848 seconds

Best acc: 94.160
--------------------------------------------------------------------------------
Test time: 7.374980926513672

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.021)	BT: 0.097 (0.114)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.011)	BT: 0.110 (0.110)	Loss 0.0035 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.091 (0.109)	Loss 0.0008 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.117 (0.108)	Loss 0.0099 (0.0018)	Prec@1 99.219 (99.997)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.090 (0.107)	Loss 0.0008 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0045 seconds
Avg Batch time: 0.1073 seconds

Train time: 42.08579444885254
 * Prec@1 94.180 Prec@5 99.720 Loss 0.2168
Avg Loading time: 0.0474 seconds
Avg Batch time: 0.0761 seconds

Best acc: 94.180
--------------------------------------------------------------------------------
Test time: 7.281585693359375

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.095 (0.127)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.980)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.011)	BT: 0.095 (0.117)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.092 (0.112)	Loss 0.0015 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.114 (0.110)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.046 (0.108)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0048 seconds
Avg Batch time: 0.1075 seconds

Train time: 42.2390251159668
 * Prec@1 94.180 Prec@5 99.730 Loss 0.2180
Avg Loading time: 0.0597 seconds
Avg Batch time: 0.0916 seconds

Best acc: 94.180
--------------------------------------------------------------------------------
Test time: 8.001926898956299

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.091 (0.127)	Loss 0.0066 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.012)	BT: 0.111 (0.115)	Loss 0.0036 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.114 (0.113)	Loss 0.0014 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.049 (0.110)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.075 (0.105)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0055 seconds
Avg Batch time: 0.1048 seconds

Train time: 41.15046763420105
 * Prec@1 94.180 Prec@5 99.750 Loss 0.2178
Avg Loading time: 0.0530 seconds
Avg Batch time: 0.0864 seconds

Best acc: 94.180
--------------------------------------------------------------------------------
Test time: 7.62125825881958

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.021)	BT: 0.079 (0.120)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.041 (0.014)	BT: 0.123 (0.097)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.985)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.011)	BT: 0.136 (0.094)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.983)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.094 (0.096)	Loss 0.0025 (0.0021)	Prec@1 100.000 (99.987)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.050 (0.098)	Loss 0.0008 (0.0021)	Prec@1 100.000 (99.986)	
Total train loss: 0.0021
Avg Loading time: 0.0065 seconds
Avg Batch time: 0.0978 seconds

Train time: 38.375648736953735
 * Prec@1 94.140 Prec@5 99.750 Loss 0.2170
Avg Loading time: 0.0537 seconds
Avg Batch time: 0.0823 seconds

Best acc: 94.180
--------------------------------------------------------------------------------
Test time: 7.3057005405426025

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.146 (0.130)	Loss 0.0114 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.012)	BT: 0.136 (0.115)	Loss 0.0020 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.092 (0.107)	Loss 0.0024 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.095 (0.105)	Loss 0.0013 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.093 (0.106)	Loss 0.0018 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0049 seconds
Avg Batch time: 0.1055 seconds

Train time: 41.422118186950684
 * Prec@1 94.110 Prec@5 99.710 Loss 0.2186
Avg Loading time: 0.0461 seconds
Avg Batch time: 0.0791 seconds

Best acc: 94.180
--------------------------------------------------------------------------------
Test time: 6.966097593307495

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.021)	BT: 0.101 (0.126)	Loss 0.0017 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.011)	BT: 0.129 (0.114)	Loss 0.0032 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.105 (0.108)	Loss 0.0009 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.093 (0.107)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.094 (0.106)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0045 seconds
Avg Batch time: 0.1058 seconds

Train time: 41.60489821434021
 * Prec@1 94.220 Prec@5 99.740 Loss 0.2158
Avg Loading time: 0.0566 seconds
Avg Batch time: 0.0813 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 7.724320411682129

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.116 (0.132)	Loss 0.0009 (0.0024)	Prec@1 100.000 (99.990)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.012)	BT: 0.108 (0.119)	Loss 0.0022 (0.0027)	Prec@1 100.000 (99.975)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.106 (0.112)	Loss 0.0027 (0.0025)	Prec@1 100.000 (99.983)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.122 (0.110)	Loss 0.0013 (0.0024)	Prec@1 100.000 (99.987)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.093 (0.108)	Loss 0.0014 (0.0023)	Prec@1 100.000 (99.990)	
Total train loss: 0.0023
Avg Loading time: 0.0050 seconds
Avg Batch time: 0.1079 seconds

Train time: 42.4169545173645
 * Prec@1 94.200 Prec@5 99.690 Loss 0.2188
Avg Loading time: 0.0555 seconds
Avg Batch time: 0.0842 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 7.4139440059661865

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.115 (0.121)	Loss 0.0023 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.010)	BT: 0.105 (0.113)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.100 (0.109)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.001 (0.005)	BT: 0.104 (0.107)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.111 (0.106)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0043 seconds
Avg Batch time: 0.1061 seconds

Train time: 41.68528389930725
 * Prec@1 94.030 Prec@5 99.750 Loss 0.2186
Avg Loading time: 0.0555 seconds
Avg Batch time: 0.0878 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 7.695603370666504

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.018)	BT: 0.106 (0.121)	Loss 0.0019 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.118 (0.112)	Loss 0.0028 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.115 (0.109)	Loss 0.0021 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.088 (0.105)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.089 (0.101)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.0039 seconds
Avg Batch time: 0.1009 seconds

Train time: 39.60131788253784
 * Prec@1 94.130 Prec@5 99.710 Loss 0.2192
Avg Loading time: 0.0497 seconds
Avg Batch time: 0.0669 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 5.9982991218566895

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.013)	BT: 0.086 (0.103)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.085 (0.095)	Loss 0.0023 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.085 (0.093)	Loss 0.0018 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.106 (0.093)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.090 (0.092)	Loss 0.0016 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0029 seconds
Avg Batch time: 0.0920 seconds

Train time: 36.096349239349365
 * Prec@1 94.200 Prec@5 99.750 Loss 0.2168
Avg Loading time: 0.1120 seconds
Avg Batch time: 0.1289 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 11.116889238357544

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.026)	BT: 0.090 (0.111)	Loss 0.0015 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.013)	BT: 0.086 (0.100)	Loss 0.0006 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.110 (0.096)	Loss 0.0015 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.087 (0.095)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.076 (0.092)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0054 seconds
Avg Batch time: 0.0917 seconds

Train time: 36.016658782958984
 * Prec@1 94.150 Prec@5 99.750 Loss 0.2180
Avg Loading time: 0.0512 seconds
Avg Batch time: 0.0671 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 5.973496675491333

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.086 (0.091)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.042 (0.074)	Loss 0.0007 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.092 (0.078)	Loss 0.0025 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.091 (0.081)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.041 (0.082)	Loss 0.0010 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0033 seconds
Avg Batch time: 0.0822 seconds

Train time: 32.301172494888306
 * Prec@1 94.170 Prec@5 99.730 Loss 0.2177
Avg Loading time: 0.0562 seconds
Avg Batch time: 0.0709 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 6.2793543338775635

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.085 (0.093)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.098 (0.090)	Loss 0.0023 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.092 (0.090)	Loss 0.0015 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.092 (0.091)	Loss 0.0009 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.092 (0.090)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.0035 seconds
Avg Batch time: 0.0897 seconds

Train time: 35.23566031455994
 * Prec@1 94.110 Prec@5 99.710 Loss 0.2168
Avg Loading time: 0.0387 seconds
Avg Batch time: 0.0652 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 5.843710422515869

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.094 (0.087)	Loss 0.0008 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.087 (0.089)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.088 (0.089)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.087 (0.089)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.091 (0.089)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0025 seconds
Avg Batch time: 0.0887 seconds

Train time: 34.83166027069092
 * Prec@1 94.130 Prec@5 99.710 Loss 0.2168
Avg Loading time: 0.0434 seconds
Avg Batch time: 0.0684 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 6.088176965713501

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.060 (0.099)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.090 (0.088)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.090 (0.090)	Loss 0.0010 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.093 (0.090)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.992)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.092 (0.091)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.994)	
Total train loss: 0.0019
Avg Loading time: 0.0031 seconds
Avg Batch time: 0.0905 seconds

Train time: 35.51816272735596
 * Prec@1 94.130 Prec@5 99.710 Loss 0.2184
Avg Loading time: 0.0466 seconds
Avg Batch time: 0.0672 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 6.020498514175415

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.010)	BT: 0.089 (0.105)	Loss 0.0020 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.090 (0.091)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.093 (0.093)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.092 (0.093)	Loss 0.0010 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.002)	BT: 0.091 (0.093)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0023 seconds
Avg Batch time: 0.0930 seconds

Train time: 36.49446129798889
 * Prec@1 94.090 Prec@5 99.700 Loss 0.2177
Avg Loading time: 0.0441 seconds
Avg Batch time: 0.0682 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 6.079296112060547

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.093 (0.109)	Loss 0.0011 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.105 (0.094)	Loss 0.0015 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.095 (0.094)	Loss 0.0024 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.091 (0.092)	Loss 0.0031 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.091 (0.091)	Loss 0.0009 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.0034 seconds
Avg Batch time: 0.0907 seconds

Train time: 35.6316499710083
 * Prec@1 94.180 Prec@5 99.730 Loss 0.2178
Avg Loading time: 0.0451 seconds
Avg Batch time: 0.0676 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 6.033583164215088

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.012)	BT: 0.090 (0.106)	Loss 0.0026 (0.0017)	Prec@1 100.000 (99.990)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.096 (0.100)	Loss 0.0012 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.094 (0.098)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.094 (0.097)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.090 (0.096)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.994)	
Total train loss: 0.0019
Avg Loading time: 0.0026 seconds
Avg Batch time: 0.0958 seconds

Train time: 37.62541222572327
 * Prec@1 94.090 Prec@5 99.720 Loss 0.2159
Avg Loading time: 0.0458 seconds
Avg Batch time: 0.0668 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 5.948347806930542

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.013)	BT: 0.090 (0.104)	Loss 0.0032 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.093 (0.099)	Loss 0.0028 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.090 (0.097)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.093 (0.096)	Loss 0.0026 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.091 (0.095)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0028 seconds
Avg Batch time: 0.0952 seconds

Train time: 37.381940603256226
 * Prec@1 94.100 Prec@5 99.710 Loss 0.2196
Avg Loading time: 0.0435 seconds
Avg Batch time: 0.0662 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 5.900753021240234

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.091 (0.097)	Loss 0.0018 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.093 (0.095)	Loss 0.0012 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.094 (0.095)	Loss 0.0017 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.093 (0.094)	Loss 0.0024 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.090 (0.094)	Loss 0.0021 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0031 seconds
Avg Batch time: 0.0940 seconds

Train time: 36.93501687049866
 * Prec@1 94.120 Prec@5 99.710 Loss 0.2196
Avg Loading time: 0.0435 seconds
Avg Batch time: 0.0671 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 5.99575138092041

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.090 (0.099)	Loss 0.0060 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.096 (0.096)	Loss 0.0010 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.090 (0.093)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.091 (0.092)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.087 (0.092)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0030 seconds
Avg Batch time: 0.0916 seconds

Train time: 35.98926568031311
 * Prec@1 94.080 Prec@5 99.720 Loss 0.2181
Avg Loading time: 0.0460 seconds
Avg Batch time: 0.0639 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 5.722878694534302

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.090 (0.105)	Loss 0.0009 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.090 (0.097)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.095 (0.096)	Loss 0.0028 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.095 (0.094)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.091 (0.093)	Loss 0.0014 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0029 seconds
Avg Batch time: 0.0925 seconds

Train time: 36.31882166862488
 * Prec@1 94.040 Prec@5 99.740 Loss 0.2216
Avg Loading time: 0.0432 seconds
Avg Batch time: 0.0666 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 5.940793514251709

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.015)	BT: 0.105 (0.109)	Loss 0.0040 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.102 (0.096)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.057 (0.093)	Loss 0.0023 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.098 (0.093)	Loss 0.0007 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.091 (0.093)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0031 seconds
Avg Batch time: 0.0932 seconds

Train time: 36.5903205871582
 * Prec@1 94.200 Prec@5 99.720 Loss 0.2156
Avg Loading time: 0.0466 seconds
Avg Batch time: 0.0684 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 6.0890491008758545

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.093 (0.106)	Loss 0.0013 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.093 (0.097)	Loss 0.0015 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.092 (0.094)	Loss 0.0010 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.091 (0.093)	Loss 0.0010 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.090 (0.093)	Loss 0.0071 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0029 seconds
Avg Batch time: 0.0928 seconds

Train time: 36.43360686302185
 * Prec@1 94.110 Prec@5 99.700 Loss 0.2192
Avg Loading time: 0.0425 seconds
Avg Batch time: 0.0665 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 5.982141733169556

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.015)	BT: 0.091 (0.106)	Loss 0.0016 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.093 (0.099)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.093 (0.096)	Loss 0.0020 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.074 (0.094)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.090 (0.093)	Loss 0.0017 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0032 seconds
Avg Batch time: 0.0930 seconds

Train time: 36.52480173110962
 * Prec@1 94.090 Prec@5 99.710 Loss 0.2200
Avg Loading time: 0.0413 seconds
Avg Batch time: 0.0639 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 5.710340976715088

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.015)	BT: 0.092 (0.109)	Loss 0.0032 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.092 (0.098)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.092 (0.095)	Loss 0.0017 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.092 (0.094)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.085 (0.093)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0033 seconds
Avg Batch time: 0.0931 seconds

Train time: 36.53895807266235
 * Prec@1 94.050 Prec@5 99.750 Loss 0.2196
Avg Loading time: 0.0484 seconds
Avg Batch time: 0.0672 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 6.327482223510742

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.016)	BT: 0.085 (0.106)	Loss 0.0042 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.088 (0.097)	Loss 0.0018 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.089 (0.094)	Loss 0.0026 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.092 (0.093)	Loss 0.0014 (0.0020)	Prec@1 100.000 (99.992)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.085 (0.092)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.0033 seconds
Avg Batch time: 0.0922 seconds

Train time: 36.20521950721741
 * Prec@1 94.230 Prec@5 99.730 Loss 0.2172
Avg Loading time: 0.0364 seconds
Avg Batch time: 0.0627 seconds

Best acc: 94.230
--------------------------------------------------------------------------------
Test time: 6.115745544433594


      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 9
Savedir:  ../pretrained_models/frozen/x64-8b/rram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/train/relu9
Test path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/test/relu9
ResNet18(
  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 11.010 Prec@5 54.480 Loss 2.2930
Avg Loading time: 0.4453 seconds
Avg Batch time: 0.4764 seconds

Pre-trained Prec@1 with 9 layers frozen: 11.00999927520752 	 Loss: 2.29296875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (0.728)	BT: 0.068 (0.781)	Loss 0.4568 (0.6350)	Prec@1 87.500 (80.319)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (0.667)	BT: 0.069 (0.724)	Loss 0.3931 (0.5342)	Prec@1 86.719 (82.928)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (0.646)	BT: 0.070 (0.706)	Loss 0.3884 (0.4816)	Prec@1 88.281 (84.318)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (0.623)	BT: 0.073 (0.686)	Loss 0.2661 (0.4479)	Prec@1 93.750 (85.314)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (0.619)	BT: 0.039 (0.683)	Loss 0.2057 (0.4221)	Prec@1 92.969 (86.134)	
Total train loss: 0.4217
Avg Loading time: 0.6175 seconds
Avg Batch time: 0.6810 seconds

Train time: 266.4269971847534
 * Prec@1 88.720 Prec@5 99.650 Loss 0.3357
Avg Loading time: 0.0474 seconds
Avg Batch time: 0.0670 seconds

Best acc: 88.720
--------------------------------------------------------------------------------
Test time: 6.4099225997924805

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.016)	BT: 0.074 (0.097)	Loss 0.2367 (0.1866)	Prec@1 89.844 (93.860)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.072 (0.087)	Loss 0.3311 (0.1985)	Prec@1 89.062 (93.374)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.077 (0.081)	Loss 0.1217 (0.2021)	Prec@1 97.656 (93.146)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.047 (0.080)	Loss 0.1677 (0.2040)	Prec@1 96.094 (93.089)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.003)	BT: 0.072 (0.077)	Loss 0.2866 (0.2057)	Prec@1 88.281 (92.993)	
Total train loss: 0.2058
Avg Loading time: 0.0034 seconds
Avg Batch time: 0.0767 seconds

Train time: 30.14570116996765
 * Prec@1 88.690 Prec@5 99.640 Loss 0.3391
Avg Loading time: 0.0473 seconds
Avg Batch time: 0.0653 seconds

Best acc: 88.720
--------------------------------------------------------------------------------
Test time: 5.851022720336914

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.065 (0.086)	Loss 0.1748 (0.1238)	Prec@1 94.531 (95.823)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.088 (0.074)	Loss 0.0868 (0.1210)	Prec@1 96.875 (95.863)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.082 (0.074)	Loss 0.1780 (0.1253)	Prec@1 93.750 (95.706)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.103 (0.074)	Loss 0.1514 (0.1271)	Prec@1 92.188 (95.678)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.003)	BT: 0.069 (0.074)	Loss 0.1267 (0.1323)	Prec@1 96.094 (95.549)	
Total train loss: 0.1325
Avg Loading time: 0.0029 seconds
Avg Batch time: 0.0740 seconds

Train time: 29.085668087005615
 * Prec@1 90.450 Prec@5 99.800 Loss 0.2891
Avg Loading time: 0.0505 seconds
Avg Batch time: 0.0667 seconds

Best acc: 90.450
--------------------------------------------------------------------------------
Test time: 6.42815375328064

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.079 (0.092)	Loss 0.0492 (0.0788)	Prec@1 99.219 (97.506)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.073 (0.083)	Loss 0.1090 (0.0818)	Prec@1 97.656 (97.361)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.074 (0.079)	Loss 0.0857 (0.0844)	Prec@1 96.094 (97.246)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.057 (0.077)	Loss 0.0688 (0.0875)	Prec@1 98.438 (97.128)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.003)	BT: 0.072 (0.077)	Loss 0.0298 (0.0924)	Prec@1 100.000 (96.919)	
Total train loss: 0.0924
Avg Loading time: 0.0030 seconds
Avg Batch time: 0.0773 seconds

Train time: 30.394994258880615
 * Prec@1 90.130 Prec@5 99.680 Loss 0.3247
Avg Loading time: 0.0461 seconds
Avg Batch time: 0.0651 seconds

Best acc: 90.450
--------------------------------------------------------------------------------
Test time: 5.810043811798096

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.015)	BT: 0.075 (0.092)	Loss 0.0781 (0.0595)	Prec@1 97.656 (98.067)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.039 (0.082)	Loss 0.0568 (0.0619)	Prec@1 98.438 (98.077)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.033 (0.079)	Loss 0.0438 (0.0646)	Prec@1 98.438 (97.947)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.080 (0.078)	Loss 0.1569 (0.0673)	Prec@1 94.531 (97.839)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.003)	BT: 0.072 (0.078)	Loss 0.0690 (0.0709)	Prec@1 98.438 (97.710)	
Total train loss: 0.0709
Avg Loading time: 0.0032 seconds
Avg Batch time: 0.0775 seconds

Train time: 30.471140146255493
 * Prec@1 87.590 Prec@5 99.230 Loss 0.4304
Avg Loading time: 0.0484 seconds
Avg Batch time: 0.0656 seconds

Best acc: 90.450
--------------------------------------------------------------------------------
Test time: 5.843037843704224

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.015)	BT: 0.085 (0.093)	Loss 0.0451 (0.0499)	Prec@1 96.875 (98.407)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.082 (0.085)	Loss 0.0636 (0.0465)	Prec@1 97.656 (98.563)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.088 (0.080)	Loss 0.0491 (0.0470)	Prec@1 98.438 (98.521)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.077 (0.080)	Loss 0.0422 (0.0491)	Prec@1 98.438 (98.412)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.003)	BT: 0.072 (0.078)	Loss 0.0222 (0.0531)	Prec@1 99.219 (98.279)	
Total train loss: 0.0532
Avg Loading time: 0.0032 seconds
Avg Batch time: 0.0780 seconds

Train time: 30.665550470352173
 * Prec@1 89.400 Prec@5 99.450 Loss 0.3755
Avg Loading time: 0.0488 seconds
Avg Batch time: 0.0649 seconds

Best acc: 90.450
--------------------------------------------------------------------------------
Test time: 5.798092842102051

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.013)	BT: 0.093 (0.090)	Loss 0.0230 (0.0462)	Prec@1 99.219 (98.468)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.073 (0.078)	Loss 0.0108 (0.0437)	Prec@1 100.000 (98.638)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.073 (0.078)	Loss 0.0475 (0.0437)	Prec@1 98.438 (98.618)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.003)	BT: 0.085 (0.077)	Loss 0.0662 (0.0454)	Prec@1 96.875 (98.533)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.003)	BT: 0.071 (0.076)	Loss 0.0779 (0.0465)	Prec@1 96.875 (98.500)	
Total train loss: 0.0466
Avg Loading time: 0.0028 seconds
Avg Batch time: 0.0759 seconds

Train time: 29.87732195854187
 * Prec@1 90.750 Prec@5 99.560 Loss 0.3291
Avg Loading time: 0.0455 seconds
Avg Batch time: 0.0665 seconds

Best acc: 90.750
--------------------------------------------------------------------------------
Test time: 6.396649360656738

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.015)	BT: 0.077 (0.087)	Loss 0.0452 (0.0493)	Prec@1 97.656 (98.468)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.070 (0.082)	Loss 0.0164 (0.0435)	Prec@1 100.000 (98.683)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.072 (0.079)	Loss 0.0384 (0.0432)	Prec@1 98.438 (98.668)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.079 (0.079)	Loss 0.0432 (0.0440)	Prec@1 98.438 (98.613)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.003)	BT: 0.073 (0.078)	Loss 0.0185 (0.0435)	Prec@1 100.000 (98.666)	
Total train loss: 0.0435
Avg Loading time: 0.0032 seconds
Avg Batch time: 0.0781 seconds

Train time: 30.69734477996826
 * Prec@1 90.420 Prec@5 99.600 Loss 0.3467
Avg Loading time: 0.0474 seconds
Avg Batch time: 0.0660 seconds

Best acc: 90.750
--------------------------------------------------------------------------------
Test time: 5.8954479694366455

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.072 (0.088)	Loss 0.0364 (0.0337)	Prec@1 98.438 (98.988)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.070 (0.079)	Loss 0.0198 (0.0325)	Prec@1 100.000 (99.003)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.072 (0.078)	Loss 0.0592 (0.0349)	Prec@1 98.438 (98.955)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.071 (0.077)	Loss 0.0690 (0.0357)	Prec@1 97.656 (98.928)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.003)	BT: 0.069 (0.077)	Loss 0.0245 (0.0385)	Prec@1 100.000 (98.798)	
Total train loss: 0.0385
Avg Loading time: 0.0031 seconds
Avg Batch time: 0.0765 seconds

Train time: 30.03070569038391
 * Prec@1 89.940 Prec@5 99.350 Loss 0.3713
Avg Loading time: 0.0495 seconds
Avg Batch time: 0.0695 seconds

Best acc: 90.750
--------------------------------------------------------------------------------
Test time: 6.181694507598877

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.013)	BT: 0.075 (0.088)	Loss 0.0239 (0.0303)	Prec@1 98.438 (99.079)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.070 (0.082)	Loss 0.0286 (0.0300)	Prec@1 99.219 (99.074)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.033 (0.079)	Loss 0.0159 (0.0309)	Prec@1 99.219 (99.012)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.069 (0.077)	Loss 0.0435 (0.0336)	Prec@1 98.438 (98.938)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.003)	BT: 0.067 (0.076)	Loss 0.0332 (0.0342)	Prec@1 98.438 (98.934)	
Total train loss: 0.0343
Avg Loading time: 0.0028 seconds
Avg Batch time: 0.0762 seconds

Train time: 29.907855987548828
 * Prec@1 90.770 Prec@5 99.420 Loss 0.3203
Avg Loading time: 0.0477 seconds
Avg Batch time: 0.0631 seconds

Best acc: 90.770
--------------------------------------------------------------------------------
Test time: 6.086419582366943

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.010)	BT: 0.086 (0.084)	Loss 0.0121 (0.0187)	Prec@1 100.000 (99.489)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.072 (0.079)	Loss 0.0049 (0.0151)	Prec@1 100.000 (99.629)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.068 (0.077)	Loss 0.0048 (0.0132)	Prec@1 100.000 (99.693)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.003)	BT: 0.072 (0.076)	Loss 0.0108 (0.0120)	Prec@1 100.000 (99.722)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.002)	BT: 0.034 (0.074)	Loss 0.0025 (0.0113)	Prec@1 100.000 (99.750)	
Total train loss: 0.0113
Avg Loading time: 0.0022 seconds
Avg Batch time: 0.0736 seconds

Train time: 28.931753873825073
 * Prec@1 93.300 Prec@5 99.810 Loss 0.2294
Avg Loading time: 0.1273 seconds
Avg Batch time: 0.1427 seconds

Best acc: 93.300
--------------------------------------------------------------------------------
Test time: 12.447693347930908

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.012)	BT: 0.068 (0.083)	Loss 0.0020 (0.0050)	Prec@1 100.000 (99.960)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.077 (0.078)	Loss 0.0078 (0.0046)	Prec@1 100.000 (99.965)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.073 (0.076)	Loss 0.0023 (0.0045)	Prec@1 100.000 (99.960)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.003)	BT: 0.086 (0.075)	Loss 0.0013 (0.0044)	Prec@1 100.000 (99.960)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.002)	BT: 0.070 (0.074)	Loss 0.0012 (0.0044)	Prec@1 100.000 (99.960)	
Total train loss: 0.0044
Avg Loading time: 0.0025 seconds
Avg Batch time: 0.0744 seconds

Train time: 29.255234718322754
 * Prec@1 93.520 Prec@5 99.780 Loss 0.2271
Avg Loading time: 0.0502 seconds
Avg Batch time: 0.0626 seconds

Best acc: 93.520
--------------------------------------------------------------------------------
Test time: 6.112859725952148

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.013 (0.022)	BT: 0.048 (0.066)	Loss 0.0068 (0.0034)	Prec@1 100.000 (99.990)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.068 (0.066)	Loss 0.0060 (0.0035)	Prec@1 100.000 (99.990)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.014 (0.010)	BT: 0.045 (0.061)	Loss 0.0015 (0.0034)	Prec@1 100.000 (99.993)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.067 (0.062)	Loss 0.0034 (0.0033)	Prec@1 100.000 (99.990)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.067 (0.065)	Loss 0.0011 (0.0033)	Prec@1 100.000 (99.990)	
Total train loss: 0.0033
Avg Loading time: 0.0071 seconds
Avg Batch time: 0.0646 seconds

Train time: 25.419102668762207
 * Prec@1 93.620 Prec@5 99.750 Loss 0.2250
Avg Loading time: 0.0504 seconds
Avg Batch time: 0.0666 seconds

Best acc: 93.620
--------------------------------------------------------------------------------
Test time: 6.414897680282593

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.078 (0.086)	Loss 0.0013 (0.0031)	Prec@1 100.000 (99.980)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.068 (0.073)	Loss 0.0049 (0.0031)	Prec@1 100.000 (99.990)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.070 (0.073)	Loss 0.0025 (0.0030)	Prec@1 100.000 (99.987)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.069 (0.072)	Loss 0.0020 (0.0030)	Prec@1 100.000 (99.985)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.003)	BT: 0.067 (0.072)	Loss 0.0105 (0.0031)	Prec@1 100.000 (99.986)	
Total train loss: 0.0031
Avg Loading time: 0.0030 seconds
Avg Batch time: 0.0721 seconds

Train time: 28.375852346420288
 * Prec@1 93.610 Prec@5 99.780 Loss 0.2260
Avg Loading time: 0.0487 seconds
Avg Batch time: 0.0653 seconds

Best acc: 93.620
--------------------------------------------------------------------------------
Test time: 5.832695484161377

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.016)	BT: 0.079 (0.077)	Loss 0.0011 (0.0032)	Prec@1 100.000 (99.960)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.046 (0.066)	Loss 0.0015 (0.0029)	Prec@1 100.000 (99.980)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.072 (0.068)	Loss 0.0020 (0.0029)	Prec@1 100.000 (99.987)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.072 (0.069)	Loss 0.0018 (0.0028)	Prec@1 100.000 (99.990)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.003)	BT: 0.067 (0.070)	Loss 0.0015 (0.0027)	Prec@1 100.000 (99.990)	
Total train loss: 0.0027
Avg Loading time: 0.0035 seconds
Avg Batch time: 0.0702 seconds

Train time: 27.587785243988037
 * Prec@1 93.460 Prec@5 99.770 Loss 0.2260
Avg Loading time: 0.0505 seconds
Avg Batch time: 0.0658 seconds

Best acc: 93.620
--------------------------------------------------------------------------------
Test time: 5.90066385269165

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.016)	BT: 0.071 (0.086)	Loss 0.0018 (0.0026)	Prec@1 100.000 (99.990)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.070 (0.080)	Loss 0.0012 (0.0025)	Prec@1 100.000 (99.990)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.086 (0.077)	Loss 0.0014 (0.0025)	Prec@1 100.000 (99.993)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.085 (0.072)	Loss 0.0018 (0.0024)	Prec@1 100.000 (99.995)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.067 (0.073)	Loss 0.0010 (0.0024)	Prec@1 100.000 (99.994)	
Total train loss: 0.0024
Avg Loading time: 0.0038 seconds
Avg Batch time: 0.0726 seconds

Train time: 28.520779848098755
 * Prec@1 93.600 Prec@5 99.750 Loss 0.2250
Avg Loading time: 0.0514 seconds
Avg Batch time: 0.0653 seconds

Best acc: 93.620
--------------------------------------------------------------------------------
Test time: 5.852463960647583

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.012)	BT: 0.072 (0.087)	Loss 0.0025 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.078 (0.081)	Loss 0.0026 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.083 (0.078)	Loss 0.0015 (0.0022)	Prec@1 100.000 (99.993)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.003)	BT: 0.072 (0.077)	Loss 0.0011 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.003)	BT: 0.071 (0.077)	Loss 0.0012 (0.0022)	Prec@1 100.000 (99.994)	
Total train loss: 0.0022
Avg Loading time: 0.0027 seconds
Avg Batch time: 0.0766 seconds

Train time: 30.119978427886963
 * Prec@1 93.660 Prec@5 99.760 Loss 0.2231
Avg Loading time: 0.0500 seconds
Avg Batch time: 0.0636 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 6.158851146697998

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.069 (0.090)	Loss 0.0020 (0.0023)	Prec@1 100.000 (99.980)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.072 (0.083)	Loss 0.0019 (0.0022)	Prec@1 100.000 (99.985)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.070 (0.080)	Loss 0.0027 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.075 (0.079)	Loss 0.0016 (0.0021)	Prec@1 100.000 (99.992)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.003)	BT: 0.070 (0.078)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0030 seconds
Avg Batch time: 0.0784 seconds

Train time: 30.80182433128357
 * Prec@1 93.660 Prec@5 99.740 Loss 0.2250
Avg Loading time: 0.0487 seconds
Avg Batch time: 0.0650 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 5.816662549972534

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.015)	BT: 0.070 (0.083)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.081 (0.075)	Loss 0.0020 (0.0022)	Prec@1 100.000 (99.985)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.071 (0.075)	Loss 0.0040 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.078 (0.075)	Loss 0.0014 (0.0022)	Prec@1 100.000 (99.992)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.003)	BT: 0.067 (0.071)	Loss 0.0012 (0.0022)	Prec@1 100.000 (99.994)	
Total train loss: 0.0022
Avg Loading time: 0.0031 seconds
Avg Batch time: 0.0711 seconds

Train time: 27.998955726623535
 * Prec@1 93.720 Prec@5 99.750 Loss 0.2242
Avg Loading time: 0.0504 seconds
Avg Batch time: 0.0642 seconds

Best acc: 93.720
--------------------------------------------------------------------------------
Test time: 6.20805549621582

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.016)	BT: 0.070 (0.089)	Loss 0.0039 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.071 (0.082)	Loss 0.0031 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.070 (0.080)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.085 (0.078)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.003)	BT: 0.073 (0.078)	Loss 0.0020 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0033 seconds
Avg Batch time: 0.0777 seconds

Train time: 30.516766786575317
 * Prec@1 93.730 Prec@5 99.770 Loss 0.2228
Avg Loading time: 0.0460 seconds
Avg Batch time: 0.0624 seconds

Best acc: 93.730
--------------------------------------------------------------------------------
Test time: 6.05011510848999

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.017)	BT: 0.070 (0.088)	Loss 0.0032 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.009)	BT: 0.073 (0.082)	Loss 0.0024 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.072 (0.080)	Loss 0.0024 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.077 (0.079)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.070 (0.078)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0036 seconds
Avg Batch time: 0.0784 seconds

Train time: 30.803820610046387
 * Prec@1 93.690 Prec@5 99.740 Loss 0.2242
Avg Loading time: 0.0478 seconds
Avg Batch time: 0.0645 seconds

Best acc: 93.730
--------------------------------------------------------------------------------
Test time: 5.785364866256714

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.013)	BT: 0.074 (0.088)	Loss 0.0012 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.072 (0.077)	Loss 0.0007 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.089 (0.077)	Loss 0.0029 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.070 (0.077)	Loss 0.0012 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.067 (0.076)	Loss 0.0018 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0028 seconds
Avg Batch time: 0.0763 seconds

Train time: 29.977004051208496
 * Prec@1 93.590 Prec@5 99.710 Loss 0.2231
Avg Loading time: 0.0457 seconds
Avg Batch time: 0.0632 seconds

Best acc: 93.730
--------------------------------------------------------------------------------
Test time: 5.682883024215698

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.013)	BT: 0.072 (0.088)	Loss 0.0023 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.072 (0.081)	Loss 0.0021 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.038 (0.076)	Loss 0.0060 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.082 (0.075)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.070 (0.075)	Loss 0.0032 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0027 seconds
Avg Batch time: 0.0752 seconds

Train time: 29.56768298149109
 * Prec@1 93.730 Prec@5 99.730 Loss 0.2230
Avg Loading time: 0.0503 seconds
Avg Batch time: 0.0659 seconds

Best acc: 93.730
--------------------------------------------------------------------------------
Test time: 5.877716064453125

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.013)	BT: 0.063 (0.080)	Loss 0.0011 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.069 (0.068)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.072 (0.070)	Loss 0.0029 (0.0021)	Prec@1 100.000 (99.987)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.070 (0.070)	Loss 0.0014 (0.0021)	Prec@1 100.000 (99.987)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.070 (0.071)	Loss 0.0036 (0.0020)	Prec@1 100.000 (99.988)	
Total train loss: 0.0020
Avg Loading time: 0.0028 seconds
Avg Batch time: 0.0710 seconds

Train time: 27.916709899902344
 * Prec@1 93.690 Prec@5 99.760 Loss 0.2240
Avg Loading time: 0.0476 seconds
Avg Batch time: 0.0634 seconds

Best acc: 93.730
--------------------------------------------------------------------------------
Test time: 5.691661834716797

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.071 (0.090)	Loss 0.0023 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.072 (0.080)	Loss 0.0015 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.070 (0.079)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.070 (0.078)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.070 (0.075)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0032 seconds
Avg Batch time: 0.0748 seconds

Train time: 29.41362690925598
 * Prec@1 93.810 Prec@5 99.740 Loss 0.2231
Avg Loading time: 0.0479 seconds
Avg Batch time: 0.0640 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 6.2156898975372314

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.013)	BT: 0.072 (0.084)	Loss 0.0024 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.070 (0.080)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.079 (0.078)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.083 (0.076)	Loss 0.0022 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.070 (0.074)	Loss 0.0015 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0029 seconds
Avg Batch time: 0.0743 seconds

Train time: 29.216274976730347
 * Prec@1 93.710 Prec@5 99.770 Loss 0.2244
Avg Loading time: 0.0464 seconds
Avg Batch time: 0.0621 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.55196213722229

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.014)	BT: 0.087 (0.084)	Loss 0.0021 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.089 (0.079)	Loss 0.0016 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.076 (0.078)	Loss 0.0058 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.072 (0.076)	Loss 0.0017 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.070 (0.075)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0031 seconds
Avg Batch time: 0.0751 seconds

Train time: 29.537283182144165
 * Prec@1 93.630 Prec@5 99.740 Loss 0.2266
Avg Loading time: 0.0458 seconds
Avg Batch time: 0.0613 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.548694372177124

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.013)	BT: 0.071 (0.085)	Loss 0.0030 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.072 (0.080)	Loss 0.0007 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.070 (0.078)	Loss 0.0007 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.073 (0.076)	Loss 0.0021 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.070 (0.075)	Loss 0.0009 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0027 seconds
Avg Batch time: 0.0752 seconds

Train time: 29.554351806640625
 * Prec@1 93.740 Prec@5 99.710 Loss 0.2228
Avg Loading time: 0.0476 seconds
Avg Batch time: 0.0621 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.562331438064575

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.012)	BT: 0.072 (0.086)	Loss 0.0019 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.067 (0.078)	Loss 0.0065 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.076 (0.077)	Loss 0.0028 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.079 (0.076)	Loss 0.0008 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.067 (0.075)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0026 seconds
Avg Batch time: 0.0753 seconds

Train time: 29.59223771095276
 * Prec@1 93.750 Prec@5 99.770 Loss 0.2224
Avg Loading time: 0.0429 seconds
Avg Batch time: 0.0594 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.368449687957764

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.014)	BT: 0.069 (0.087)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.080 (0.080)	Loss 0.0022 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.069 (0.078)	Loss 0.0023 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.069 (0.076)	Loss 0.0011 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.067 (0.075)	Loss 0.0009 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0030 seconds
Avg Batch time: 0.0752 seconds

Train time: 29.546558618545532
 * Prec@1 93.780 Prec@5 99.740 Loss 0.2238
Avg Loading time: 0.0436 seconds
Avg Batch time: 0.0602 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.386056900024414

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.013)	BT: 0.084 (0.086)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.980)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.074 (0.079)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.067 (0.077)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.067 (0.076)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.992)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.067 (0.075)	Loss 0.0038 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.0028 seconds
Avg Batch time: 0.0747 seconds

Train time: 29.312260150909424
 * Prec@1 93.780 Prec@5 99.730 Loss 0.2260
Avg Loading time: 0.0454 seconds
Avg Batch time: 0.0603 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.444861173629761

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.014)	BT: 0.066 (0.085)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.069 (0.079)	Loss 0.0031 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.067 (0.077)	Loss 0.0032 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.070 (0.076)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.067 (0.075)	Loss 0.0006 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.0029 seconds
Avg Batch time: 0.0751 seconds

Train time: 29.5248601436615
 * Prec@1 93.750 Prec@5 99.750 Loss 0.2236
Avg Loading time: 0.0462 seconds
Avg Batch time: 0.0612 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.478880167007446

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.023 (0.044)	BT: 0.060 (0.099)	Loss 0.0022 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.053)	BT: 0.049 (0.098)	Loss 0.0015 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.036)	BT: 0.084 (0.088)	Loss 0.0049 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.027)	BT: 0.069 (0.084)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.022)	BT: 0.066 (0.082)	Loss 0.0015 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0216 seconds
Avg Batch time: 0.0816 seconds

Train time: 32.092074155807495
 * Prec@1 93.700 Prec@5 99.760 Loss 0.2252
Avg Loading time: 0.0467 seconds
Avg Batch time: 0.0636 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.7143590450286865

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.014)	BT: 0.075 (0.088)	Loss 0.0020 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.031 (0.073)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.017 (0.010)	BT: 0.052 (0.066)	Loss 0.0014 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.035 (0.063)	Loss 0.0033 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.015 (0.013)	BT: 0.045 (0.061)	Loss 0.0023 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0131 seconds
Avg Batch time: 0.0608 seconds

Train time: 23.917410850524902
 * Prec@1 93.660 Prec@5 99.750 Loss 0.2230
Avg Loading time: 0.0502 seconds
Avg Batch time: 0.0643 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.75834321975708

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.067 (0.089)	Loss 0.0018 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.086 (0.081)	Loss 0.0014 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.045 (0.074)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.069 (0.071)	Loss 0.0018 (0.0020)	Prec@1 100.000 (99.992)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.034 (0.070)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.0054 seconds
Avg Batch time: 0.0700 seconds

Train time: 27.50821805000305
 * Prec@1 93.740 Prec@5 99.720 Loss 0.2230
Avg Loading time: 0.0495 seconds
Avg Batch time: 0.0656 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.885114431381226

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.013)	BT: 0.072 (0.086)	Loss 0.0010 (0.0018)	Prec@1 100.000 (99.990)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.067 (0.080)	Loss 0.0010 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.085 (0.078)	Loss 0.0012 (0.0018)	Prec@1 100.000 (99.993)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.053 (0.075)	Loss 0.0016 (0.0018)	Prec@1 100.000 (99.992)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.067 (0.074)	Loss 0.0026 (0.0019)	Prec@1 100.000 (99.992)	
Total train loss: 0.0019
Avg Loading time: 0.0028 seconds
Avg Batch time: 0.0738 seconds

Train time: 29.004591703414917
 * Prec@1 93.750 Prec@5 99.750 Loss 0.2230
Avg Loading time: 0.0485 seconds
Avg Batch time: 0.0623 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.5870866775512695

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.069 (0.089)	Loss 0.0017 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.073 (0.081)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.078 (0.078)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.078 (0.076)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.049 (0.075)	Loss 0.0035 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0035 seconds
Avg Batch time: 0.0753 seconds

Train time: 29.597095251083374
 * Prec@1 93.640 Prec@5 99.760 Loss 0.2244
Avg Loading time: 0.0473 seconds
Avg Batch time: 0.0652 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.807104587554932

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.013)	BT: 0.069 (0.075)	Loss 0.0018 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.083 (0.075)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.067 (0.072)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.072 (0.072)	Loss 0.0022 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.071 (0.072)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.994)	
Total train loss: 0.0019
Avg Loading time: 0.0028 seconds
Avg Batch time: 0.0723 seconds

Train time: 28.439041137695312
 * Prec@1 93.790 Prec@5 99.750 Loss 0.2236
Avg Loading time: 0.0441 seconds
Avg Batch time: 0.0614 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.487520456314087

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.073 (0.089)	Loss 0.0028 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.044 (0.079)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.072 (0.073)	Loss 0.0008 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.073 (0.073)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.072 (0.073)	Loss 0.0014 (0.0019)	Prec@1 100.000 (99.994)	
Total train loss: 0.0019
Avg Loading time: 0.0034 seconds
Avg Batch time: 0.0734 seconds

Train time: 28.85047960281372
 * Prec@1 93.710 Prec@5 99.750 Loss 0.2231
Avg Loading time: 0.0455 seconds
Avg Batch time: 0.0629 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.625255346298218

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.074 (0.090)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.085 (0.082)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.071 (0.080)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.065 (0.074)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.070 (0.072)	Loss 0.0010 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0031 seconds
Avg Batch time: 0.0723 seconds

Train time: 28.437443256378174
 * Prec@1 93.740 Prec@5 99.720 Loss 0.2228
Avg Loading time: 0.0487 seconds
Avg Batch time: 0.0661 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.901850461959839

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.015)	BT: 0.073 (0.092)	Loss 0.0016 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.069 (0.074)	Loss 0.0010 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.072 (0.072)	Loss 0.0045 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.072 (0.073)	Loss 0.0009 (0.0018)	Prec@1 100.000 (99.992)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.073 (0.074)	Loss 0.0024 (0.0018)	Prec@1 100.000 (99.994)	
Total train loss: 0.0019
Avg Loading time: 0.0033 seconds
Avg Batch time: 0.0734 seconds

Train time: 28.860668182373047
 * Prec@1 93.700 Prec@5 99.750 Loss 0.2222
Avg Loading time: 0.0469 seconds
Avg Batch time: 0.0664 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.871141672134399

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.073 (0.092)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.070 (0.084)	Loss 0.0018 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.072 (0.082)	Loss 0.0012 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.085 (0.078)	Loss 0.0009 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.070 (0.078)	Loss 0.0032 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0031 seconds
Avg Batch time: 0.0778 seconds

Train time: 30.573179006576538
 * Prec@1 93.740 Prec@5 99.750 Loss 0.2242
Avg Loading time: 0.0471 seconds
Avg Batch time: 0.0652 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.813349723815918

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.012)	BT: 0.074 (0.089)	Loss 0.0009 (0.0017)	Prec@1 100.000 (99.990)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.087 (0.083)	Loss 0.0028 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.084 (0.081)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.072 (0.080)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.069 (0.078)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.988)	
Total train loss: 0.0019
Avg Loading time: 0.0026 seconds
Avg Batch time: 0.0780 seconds

Train time: 30.665126085281372
 * Prec@1 93.760 Prec@5 99.750 Loss 0.2218
Avg Loading time: 0.0465 seconds
Avg Batch time: 0.0653 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.846074819564819

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.016)	BT: 0.074 (0.091)	Loss 0.0010 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.073 (0.083)	Loss 0.0032 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.084 (0.081)	Loss 0.0016 (0.0017)	Prec@1 100.000 (99.997)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.071 (0.080)	Loss 0.0013 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.070 (0.079)	Loss 0.0040 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0035 seconds
Avg Batch time: 0.0787 seconds

Train time: 30.954792022705078
 * Prec@1 93.750 Prec@5 99.750 Loss 0.2250
Avg Loading time: 0.0458 seconds
Avg Batch time: 0.0623 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.5696656703948975

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.070 (0.085)	Loss 0.0012 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.076 (0.080)	Loss 0.0008 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.089 (0.082)	Loss 0.0017 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.043 (0.078)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.067 (0.075)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0051 seconds
Avg Batch time: 0.0746 seconds

Train time: 29.323440074920654
 * Prec@1 93.690 Prec@5 99.740 Loss 0.2244
Avg Loading time: 0.0455 seconds
Avg Batch time: 0.0641 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.7577433586120605

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.016)	BT: 0.090 (0.086)	Loss 0.0033 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.070 (0.081)	Loss 0.0015 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.085 (0.077)	Loss 0.0029 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.072 (0.077)	Loss 0.0018 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.070 (0.077)	Loss 0.0031 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0035 seconds
Avg Batch time: 0.0769 seconds

Train time: 30.225573778152466
 * Prec@1 93.690 Prec@5 99.740 Loss 0.2236
Avg Loading time: 0.0486 seconds
Avg Batch time: 0.0647 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.7972331047058105

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.015)	BT: 0.073 (0.087)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.070 (0.078)	Loss 0.0010 (0.0018)	Prec@1 100.000 (99.990)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.001 (0.005)	BT: 0.094 (0.075)	Loss 0.0022 (0.0018)	Prec@1 100.000 (99.993)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.034 (0.075)	Loss 0.0007 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.071 (0.074)	Loss 0.0017 (0.0018)	Prec@1 100.000 (99.996)	
Total train loss: 0.0018
Avg Loading time: 0.0033 seconds
Avg Batch time: 0.0741 seconds

Train time: 29.122148990631104
 * Prec@1 93.750 Prec@5 99.770 Loss 0.2240
Avg Loading time: 0.0483 seconds
Avg Batch time: 0.0660 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.875898122787476

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.081 (0.082)	Loss 0.0019 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.069 (0.076)	Loss 0.0012 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.073 (0.075)	Loss 0.0014 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.092 (0.075)	Loss 0.0013 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.070 (0.075)	Loss 0.0021 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0029 seconds
Avg Batch time: 0.0746 seconds

Train time: 29.322932958602905
 * Prec@1 93.580 Prec@5 99.740 Loss 0.2244
Avg Loading time: 0.0451 seconds
Avg Batch time: 0.0616 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.527450084686279

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.081 (0.088)	Loss 0.0033 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.069 (0.078)	Loss 0.0014 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.072 (0.076)	Loss 0.0012 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.069 (0.075)	Loss 0.0009 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.070 (0.075)	Loss 0.0012 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0029 seconds
Avg Batch time: 0.0750 seconds

Train time: 29.486194849014282
 * Prec@1 93.700 Prec@5 99.750 Loss 0.2234
Avg Loading time: 0.0434 seconds
Avg Batch time: 0.0610 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.453264474868774

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.013)	BT: 0.073 (0.087)	Loss 0.0006 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.073 (0.080)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.083 (0.078)	Loss 0.0018 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.070 (0.077)	Loss 0.0013 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.071 (0.075)	Loss 0.0010 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0027 seconds
Avg Batch time: 0.0750 seconds

Train time: 29.49846076965332
 * Prec@1 93.750 Prec@5 99.760 Loss 0.2234
Avg Loading time: 0.0437 seconds
Avg Batch time: 0.0601 seconds

Best acc: 93.810
--------------------------------------------------------------------------------
Test time: 5.394286632537842

