
      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 5
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/train/relu5
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/test/relu5
ResNet18(
  (conv6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv1): Sequential(
    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu6): ReLU(inplace=True)
  (conv7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu7): ReLU(inplace=True)
  (conv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 9.860 Prec@5 47.270 Loss 2.3320
Avg Loading time: 0.5722 seconds
Avg Batch time: 0.6211 seconds

Pre-trained Prec@1 with 5 layers frozen: 9.859999656677246 	 Loss: 2.33203125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (3.294)	BT: 0.060 (3.366)	Loss 0.3337 (0.6996)	Prec@1 88.281 (78.085)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (3.019)	BT: 0.071 (3.091)	Loss 0.4597 (0.5729)	Prec@1 83.594 (81.606)	
Epoch: [0][233/391]	LR: 0.1	DT: 2.307 (2.753)	BT: 2.393 (2.824)	Loss 0.2898 (0.5083)	Prec@1 91.406 (83.547)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (2.475)	BT: 0.062 (2.546)	Loss 0.3999 (0.4706)	Prec@1 89.062 (84.643)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (2.231)	BT: 0.064 (2.302)	Loss 0.4028 (0.4426)	Prec@1 86.719 (85.425)	
Total train loss: 0.4423
Avg Loading time: 2.2251 seconds
Avg Batch time: 2.2964 seconds

Train time: 898.0537097454071
 * Prec@1 86.850 Prec@5 99.530 Loss 0.3884
Avg Loading time: 0.1152 seconds
Avg Batch time: 0.1614 seconds

Best acc: 86.850
--------------------------------------------------------------------------------
Test time: 13.921835899353027

Epoch: [1][77/391]	LR: 0.1	DT: 0.096 (0.075)	BT: 0.173 (0.175)	Loss 0.1777 (0.2321)	Prec@1 92.188 (92.228)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.094 (0.068)	BT: 0.190 (0.163)	Loss 0.2399 (0.2262)	Prec@1 92.188 (92.353)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.061 (0.068)	BT: 0.146 (0.161)	Loss 0.2585 (0.2340)	Prec@1 89.844 (91.970)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.068)	BT: 0.095 (0.158)	Loss 0.1554 (0.2345)	Prec@1 95.312 (92.005)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.081 (0.069)	BT: 0.151 (0.158)	Loss 0.2896 (0.2318)	Prec@1 89.844 (92.107)	
Total train loss: 0.2318
Avg Loading time: 0.0687 seconds
Avg Batch time: 0.1583 seconds

Train time: 62.07915997505188
 * Prec@1 85.220 Prec@5 99.390 Loss 0.4541
Avg Loading time: 0.1101 seconds
Avg Batch time: 0.1573 seconds

Best acc: 86.850
--------------------------------------------------------------------------------
Test time: 13.218504905700684

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.081)	BT: 0.085 (0.174)	Loss 0.0837 (0.1372)	Prec@1 96.875 (95.473)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.043 (0.073)	BT: 0.149 (0.162)	Loss 0.1552 (0.1440)	Prec@1 93.750 (95.152)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.058 (0.072)	BT: 0.137 (0.162)	Loss 0.1740 (0.1487)	Prec@1 92.188 (94.955)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.078 (0.069)	BT: 0.193 (0.158)	Loss 0.1368 (0.1516)	Prec@1 95.312 (94.787)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.083 (0.068)	BT: 0.158 (0.157)	Loss 0.1736 (0.1569)	Prec@1 91.406 (94.587)	
Total train loss: 0.1570
Avg Loading time: 0.0683 seconds
Avg Batch time: 0.1573 seconds

Train time: 61.7459397315979
 * Prec@1 87.210 Prec@5 99.330 Loss 0.3892
Avg Loading time: 0.1093 seconds
Avg Batch time: 0.1536 seconds

Best acc: 87.210
--------------------------------------------------------------------------------
Test time: 13.428591251373291

Epoch: [3][77/391]	LR: 0.1	DT: 0.125 (0.081)	BT: 0.197 (0.171)	Loss 0.1562 (0.1052)	Prec@1 95.312 (96.464)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.073)	BT: 0.140 (0.163)	Loss 0.0861 (0.0993)	Prec@1 96.875 (96.645)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.095 (0.071)	BT: 0.178 (0.160)	Loss 0.1587 (0.1032)	Prec@1 96.094 (96.438)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.147 (0.070)	BT: 0.249 (0.158)	Loss 0.1830 (0.1057)	Prec@1 96.094 (96.342)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.062 (0.068)	BT: 0.124 (0.157)	Loss 0.0917 (0.1085)	Prec@1 96.875 (96.250)	
Total train loss: 0.1085
Avg Loading time: 0.0681 seconds
Avg Batch time: 0.1569 seconds

Train time: 61.49914288520813
 * Prec@1 89.320 Prec@5 99.610 Loss 0.3379
Avg Loading time: 0.1101 seconds
Avg Batch time: 0.1544 seconds

Best acc: 89.320
--------------------------------------------------------------------------------
Test time: 13.464414834976196

Epoch: [4][77/391]	LR: 0.1	DT: 0.077 (0.081)	BT: 0.205 (0.168)	Loss 0.1465 (0.0771)	Prec@1 96.875 (97.586)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.070)	BT: 0.076 (0.159)	Loss 0.1090 (0.0800)	Prec@1 96.094 (97.381)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.072 (0.068)	BT: 0.170 (0.158)	Loss 0.0858 (0.0870)	Prec@1 98.438 (97.095)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.053 (0.068)	BT: 0.123 (0.157)	Loss 0.1113 (0.0880)	Prec@1 96.094 (97.025)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.069)	BT: 0.067 (0.157)	Loss 0.0652 (0.0912)	Prec@1 98.438 (96.893)	
Total train loss: 0.0915
Avg Loading time: 0.0692 seconds
Avg Batch time: 0.1571 seconds

Train time: 61.6105797290802
 * Prec@1 88.020 Prec@5 99.300 Loss 0.3911
Avg Loading time: 0.1106 seconds
Avg Batch time: 0.1561 seconds

Best acc: 89.320
--------------------------------------------------------------------------------
Test time: 13.219942569732666

Epoch: [5][77/391]	LR: 0.1	DT: 0.048 (0.077)	BT: 0.118 (0.167)	Loss 0.0836 (0.0723)	Prec@1 97.656 (97.666)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.122 (0.071)	BT: 0.205 (0.163)	Loss 0.0291 (0.0673)	Prec@1 100.000 (97.902)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.074 (0.065)	BT: 0.146 (0.158)	Loss 0.0883 (0.0685)	Prec@1 96.875 (97.786)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.071 (0.065)	BT: 0.150 (0.156)	Loss 0.0601 (0.0710)	Prec@1 98.438 (97.709)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.060 (0.064)	BT: 0.158 (0.155)	Loss 0.1190 (0.0710)	Prec@1 97.656 (97.718)	
Total train loss: 0.0711
Avg Loading time: 0.0635 seconds
Avg Batch time: 0.1551 seconds

Train time: 60.86571455001831
 * Prec@1 89.080 Prec@5 99.400 Loss 0.3706
Avg Loading time: 0.1081 seconds
Avg Batch time: 0.1554 seconds

Best acc: 89.320
--------------------------------------------------------------------------------
Test time: 13.40680742263794

Epoch: [6][77/391]	LR: 0.1	DT: 0.073 (0.074)	BT: 0.138 (0.164)	Loss 0.0511 (0.0523)	Prec@1 98.438 (98.307)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.140 (0.070)	BT: 0.221 (0.161)	Loss 0.0568 (0.0489)	Prec@1 97.656 (98.387)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.069 (0.065)	BT: 0.157 (0.157)	Loss 0.0245 (0.0495)	Prec@1 100.000 (98.367)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.001 (0.066)	BT: 0.076 (0.157)	Loss 0.0967 (0.0531)	Prec@1 97.656 (98.217)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.108 (0.065)	BT: 0.172 (0.155)	Loss 0.0640 (0.0581)	Prec@1 97.656 (98.059)	
Total train loss: 0.0581
Avg Loading time: 0.0649 seconds
Avg Batch time: 0.1544 seconds

Train time: 60.509838819503784
 * Prec@1 89.200 Prec@5 99.650 Loss 0.3679
Avg Loading time: 0.1075 seconds
Avg Batch time: 0.1548 seconds

Best acc: 89.320
--------------------------------------------------------------------------------
Test time: 13.06433367729187

Epoch: [7][77/391]	LR: 0.1	DT: 0.076 (0.076)	BT: 0.164 (0.161)	Loss 0.0559 (0.0544)	Prec@1 96.875 (98.157)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.066)	BT: 0.135 (0.157)	Loss 0.0260 (0.0474)	Prec@1 97.656 (98.453)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.065)	BT: 0.085 (0.154)	Loss 0.0183 (0.0500)	Prec@1 100.000 (98.421)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.066 (0.064)	BT: 0.142 (0.155)	Loss 0.0279 (0.0519)	Prec@1 100.000 (98.315)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.044 (0.064)	BT: 0.128 (0.153)	Loss 0.0728 (0.0545)	Prec@1 98.438 (98.217)	
Total train loss: 0.0545
Avg Loading time: 0.0635 seconds
Avg Batch time: 0.1532 seconds

Train time: 60.13849997520447
 * Prec@1 89.750 Prec@5 99.510 Loss 0.3447
Avg Loading time: 0.1111 seconds
Avg Batch time: 0.1615 seconds

Best acc: 89.750
--------------------------------------------------------------------------------
Test time: 14.03152060508728

Epoch: [8][77/391]	LR: 0.1	DT: 0.070 (0.074)	BT: 0.142 (0.167)	Loss 0.0714 (0.0474)	Prec@1 99.219 (98.518)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.156 (0.071)	BT: 0.225 (0.163)	Loss 0.0365 (0.0485)	Prec@1 97.656 (98.407)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.060 (0.066)	BT: 0.139 (0.158)	Loss 0.0252 (0.0476)	Prec@1 99.219 (98.488)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.065 (0.067)	BT: 0.150 (0.158)	Loss 0.0372 (0.0467)	Prec@1 98.438 (98.528)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.069)	BT: 0.077 (0.158)	Loss 0.0290 (0.0469)	Prec@1 99.219 (98.516)	
Total train loss: 0.0469
Avg Loading time: 0.0686 seconds
Avg Batch time: 0.1579 seconds

Train time: 61.95040965080261
 * Prec@1 90.430 Prec@5 99.620 Loss 0.3379
Avg Loading time: 0.1134 seconds
Avg Batch time: 0.1612 seconds

Best acc: 90.430
--------------------------------------------------------------------------------
Test time: 14.047826051712036

Epoch: [9][77/391]	LR: 0.1	DT: 0.229 (0.074)	BT: 0.315 (0.176)	Loss 0.0258 (0.0372)	Prec@1 98.438 (98.808)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.151 (0.069)	BT: 0.245 (0.166)	Loss 0.0580 (0.0418)	Prec@1 96.875 (98.693)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.068)	BT: 0.084 (0.161)	Loss 0.0448 (0.0413)	Prec@1 98.438 (98.685)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.139 (0.068)	BT: 0.225 (0.160)	Loss 0.1536 (0.0425)	Prec@1 94.531 (98.628)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.059 (0.068)	BT: 0.127 (0.158)	Loss 0.0324 (0.0437)	Prec@1 100.000 (98.582)	
Total train loss: 0.0438
Avg Loading time: 0.0680 seconds
Avg Batch time: 0.1576 seconds

Train time: 61.84277963638306
 * Prec@1 89.710 Prec@5 99.380 Loss 0.3733
Avg Loading time: 0.1130 seconds
Avg Batch time: 0.1606 seconds

Best acc: 90.430
--------------------------------------------------------------------------------
Test time: 13.36487364768982

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.078)	BT: 0.082 (0.173)	Loss 0.0152 (0.0232)	Prec@1 100.000 (99.339)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.046 (0.070)	BT: 0.120 (0.160)	Loss 0.0110 (0.0179)	Prec@1 100.000 (99.534)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.060 (0.070)	BT: 0.134 (0.160)	Loss 0.0027 (0.0160)	Prec@1 100.000 (99.586)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.070)	BT: 0.081 (0.158)	Loss 0.0184 (0.0144)	Prec@1 99.219 (99.642)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.038 (0.069)	BT: 0.113 (0.158)	Loss 0.0023 (0.0135)	Prec@1 100.000 (99.688)	
Total train loss: 0.0135
Avg Loading time: 0.0688 seconds
Avg Batch time: 0.1577 seconds

Train time: 61.88229727745056
 * Prec@1 93.920 Prec@5 99.720 Loss 0.2120
Avg Loading time: 0.1035 seconds
Avg Batch time: 0.1522 seconds

Best acc: 93.920
--------------------------------------------------------------------------------
Test time: 13.299062967300415

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.086)	BT: 0.074 (0.178)	Loss 0.0024 (0.0054)	Prec@1 100.000 (99.940)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.089 (0.076)	BT: 0.187 (0.165)	Loss 0.0019 (0.0049)	Prec@1 100.000 (99.950)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.074)	BT: 0.090 (0.165)	Loss 0.0031 (0.0047)	Prec@1 100.000 (99.953)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.112 (0.070)	BT: 0.209 (0.160)	Loss 0.0020 (0.0046)	Prec@1 100.000 (99.962)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.069)	BT: 0.070 (0.159)	Loss 0.0022 (0.0046)	Prec@1 100.000 (99.962)	
Total train loss: 0.0046
Avg Loading time: 0.0685 seconds
Avg Batch time: 0.1592 seconds

Train time: 62.49027395248413
 * Prec@1 94.070 Prec@5 99.720 Loss 0.2061
Avg Loading time: 0.1108 seconds
Avg Batch time: 0.1586 seconds

Best acc: 94.070
--------------------------------------------------------------------------------
Test time: 13.81617259979248

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.056 (0.076)	BT: 0.121 (0.166)	Loss 0.0029 (0.0035)	Prec@1 100.000 (99.990)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.079 (0.071)	BT: 0.155 (0.161)	Loss 0.0068 (0.0035)	Prec@1 100.000 (99.995)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.057 (0.068)	BT: 0.147 (0.157)	Loss 0.0027 (0.0036)	Prec@1 100.000 (99.997)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.066)	BT: 0.085 (0.157)	Loss 0.0020 (0.0035)	Prec@1 100.000 (99.992)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.122 (0.066)	BT: 0.199 (0.157)	Loss 0.0034 (0.0035)	Prec@1 100.000 (99.990)	
Total train loss: 0.0035
Avg Loading time: 0.0660 seconds
Avg Batch time: 0.1572 seconds

Train time: 61.705262422561646
 * Prec@1 94.050 Prec@5 99.740 Loss 0.2040
Avg Loading time: 0.1125 seconds
Avg Batch time: 0.1602 seconds

Best acc: 94.070
--------------------------------------------------------------------------------
Test time: 13.464614629745483

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.211 (0.076)	BT: 0.302 (0.171)	Loss 0.0015 (0.0032)	Prec@1 100.000 (99.990)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.104 (0.074)	BT: 0.187 (0.166)	Loss 0.0013 (0.0032)	Prec@1 100.000 (99.990)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.061 (0.072)	BT: 0.147 (0.161)	Loss 0.0016 (0.0032)	Prec@1 100.000 (99.987)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.113 (0.072)	BT: 0.196 (0.161)	Loss 0.0021 (0.0032)	Prec@1 100.000 (99.987)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.161 (0.071)	BT: 0.232 (0.158)	Loss 0.0030 (0.0033)	Prec@1 100.000 (99.986)	
Total train loss: 0.0033
Avg Loading time: 0.0706 seconds
Avg Batch time: 0.1581 seconds

Train time: 62.06262421607971
 * Prec@1 94.170 Prec@5 99.720 Loss 0.2052
Avg Loading time: 0.1175 seconds
Avg Batch time: 0.1686 seconds

Best acc: 94.170
--------------------------------------------------------------------------------
Test time: 14.59220004081726

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.080 (0.078)	BT: 0.154 (0.164)	Loss 0.0041 (0.0031)	Prec@1 100.000 (99.980)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.068)	BT: 0.089 (0.160)	Loss 0.0013 (0.0029)	Prec@1 100.000 (99.990)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.180 (0.067)	BT: 0.282 (0.156)	Loss 0.0020 (0.0029)	Prec@1 100.000 (99.993)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.068)	BT: 0.101 (0.157)	Loss 0.0011 (0.0028)	Prec@1 100.000 (99.995)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.128 (0.067)	BT: 0.204 (0.156)	Loss 0.0065 (0.0029)	Prec@1 100.000 (99.992)	
Total train loss: 0.0029
Avg Loading time: 0.0673 seconds
Avg Batch time: 0.1557 seconds

Train time: 61.11639380455017
 * Prec@1 94.220 Prec@5 99.750 Loss 0.2039
Avg Loading time: 0.1094 seconds
Avg Batch time: 0.1572 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 13.628593921661377

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.084)	BT: 0.111 (0.175)	Loss 0.0011 (0.0026)	Prec@1 100.000 (100.000)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.071 (0.075)	BT: 0.157 (0.163)	Loss 0.0059 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.091 (0.071)	BT: 0.180 (0.158)	Loss 0.0017 (0.0025)	Prec@1 100.000 (100.000)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.071)	BT: 0.065 (0.157)	Loss 0.0021 (0.0025)	Prec@1 100.000 (99.997)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.069)	BT: 0.076 (0.155)	Loss 0.0015 (0.0025)	Prec@1 100.000 (99.996)	
Total train loss: 0.0026
Avg Loading time: 0.0689 seconds
Avg Batch time: 0.1550 seconds

Train time: 60.811150312423706
 * Prec@1 94.150 Prec@5 99.710 Loss 0.2048
Avg Loading time: 0.1137 seconds
Avg Batch time: 0.1589 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 13.281188011169434

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.078 (0.063)	BT: 0.142 (0.143)	Loss 0.0010 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.112 (0.059)	BT: 0.187 (0.134)	Loss 0.0027 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.058)	BT: 0.097 (0.132)	Loss 0.0016 (0.0023)	Prec@1 100.000 (99.993)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.058)	BT: 0.062 (0.132)	Loss 0.0011 (0.0024)	Prec@1 100.000 (99.992)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.073)	BT: 0.061 (0.146)	Loss 0.0022 (0.0024)	Prec@1 100.000 (99.990)	
Total train loss: 0.0024
Avg Loading time: 0.0729 seconds
Avg Batch time: 0.1462 seconds

Train time: 57.30980181694031
 * Prec@1 94.060 Prec@5 99.720 Loss 0.2042
Avg Loading time: 0.3166 seconds
Avg Batch time: 0.3482 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 28.244136095046997

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.278)	BT: 0.068 (0.354)	Loss 0.0033 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.283)	BT: 0.073 (0.358)	Loss 0.0033 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.488 (0.285)	BT: 0.574 (0.360)	Loss 0.0027 (0.0023)	Prec@1 100.000 (99.997)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.277)	BT: 0.065 (0.352)	Loss 0.0014 (0.0024)	Prec@1 100.000 (99.995)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.277)	BT: 0.063 (0.351)	Loss 0.0017 (0.0023)	Prec@1 100.000 (99.996)	
Total train loss: 0.0023
Avg Loading time: 0.2764 seconds
Avg Batch time: 0.3503 seconds

Train time: 137.09510493278503
 * Prec@1 94.200 Prec@5 99.720 Loss 0.2040
Avg Loading time: 0.3507 seconds
Avg Batch time: 0.3855 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 31.165123462677002

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.223)	BT: 0.065 (0.296)	Loss 0.0027 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.137)	BT: 0.062 (0.214)	Loss 0.0039 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.110)	BT: 0.078 (0.189)	Loss 0.0005 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.056 (0.095)	BT: 0.142 (0.176)	Loss 0.0035 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.089)	BT: 0.098 (0.173)	Loss 0.0123 (0.0022)	Prec@1 99.219 (99.992)	
Total train loss: 0.0022
Avg Loading time: 0.0886 seconds
Avg Batch time: 0.1723 seconds

Train time: 67.57302856445312
 * Prec@1 94.200 Prec@5 99.760 Loss 0.2031
Avg Loading time: 0.1153 seconds
Avg Batch time: 0.1573 seconds

Best acc: 94.220
--------------------------------------------------------------------------------
Test time: 13.199828624725342

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.076 (0.085)	BT: 0.139 (0.179)	Loss 0.0014 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.038 (0.074)	BT: 0.133 (0.165)	Loss 0.0024 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.083 (0.073)	BT: 0.150 (0.164)	Loss 0.0019 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.071)	BT: 0.099 (0.160)	Loss 0.0035 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.068 (0.072)	BT: 0.137 (0.161)	Loss 0.0010 (0.0021)	Prec@1 100.000 (100.000)	
Total train loss: 0.0021
Avg Loading time: 0.0717 seconds
Avg Batch time: 0.1605 seconds

Train time: 62.954169034957886
 * Prec@1 94.230 Prec@5 99.710 Loss 0.2017
Avg Loading time: 0.1065 seconds
Avg Batch time: 0.1529 seconds

Best acc: 94.230
--------------------------------------------------------------------------------
Test time: 13.367678165435791

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.134 (0.076)	BT: 0.215 (0.170)	Loss 0.0011 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.051 (0.067)	BT: 0.119 (0.159)	Loss 0.0024 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.055 (0.067)	BT: 0.149 (0.158)	Loss 0.0009 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.061 (0.066)	BT: 0.143 (0.157)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.136 (0.066)	BT: 0.221 (0.156)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0662 seconds
Avg Batch time: 0.1560 seconds

Train time: 61.236748933792114
 * Prec@1 94.280 Prec@5 99.710 Loss 0.2010
Avg Loading time: 0.1092 seconds
Avg Batch time: 0.1602 seconds

Best acc: 94.280
--------------------------------------------------------------------------------
Test time: 13.919036388397217

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.065 (0.084)	BT: 0.141 (0.175)	Loss 0.0012 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.064 (0.081)	BT: 0.160 (0.173)	Loss 0.0017 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.160 (0.076)	BT: 0.243 (0.167)	Loss 0.0015 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.046 (0.074)	BT: 0.116 (0.165)	Loss 0.0013 (0.0022)	Prec@1 100.000 (99.992)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.054 (0.073)	BT: 0.128 (0.162)	Loss 0.0013 (0.0022)	Prec@1 100.000 (99.992)	
Total train loss: 0.0022
Avg Loading time: 0.0727 seconds
Avg Batch time: 0.1620 seconds

Train time: 63.546632051467896
 * Prec@1 94.320 Prec@5 99.740 Loss 0.2017
Avg Loading time: 0.1119 seconds
Avg Batch time: 0.1632 seconds

Best acc: 94.320
--------------------------------------------------------------------------------
Test time: 14.105970621109009

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.074)	BT: 0.101 (0.165)	Loss 0.0019 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.054 (0.074)	BT: 0.120 (0.163)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.096 (0.070)	BT: 0.176 (0.157)	Loss 0.0028 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.056 (0.071)	BT: 0.199 (0.160)	Loss 0.0019 (0.0021)	Prec@1 100.000 (99.992)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.105 (0.070)	BT: 0.199 (0.159)	Loss 0.0035 (0.0021)	Prec@1 100.000 (99.992)	
Total train loss: 0.0021
Avg Loading time: 0.0697 seconds
Avg Batch time: 0.1586 seconds

Train time: 62.201350927352905
 * Prec@1 94.300 Prec@5 99.700 Loss 0.2020
Avg Loading time: 0.1144 seconds
Avg Batch time: 0.1662 seconds

Best acc: 94.320
--------------------------------------------------------------------------------
Test time: 13.925797939300537

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.067)	BT: 0.100 (0.166)	Loss 0.0014 (0.0027)	Prec@1 100.000 (99.980)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.062)	BT: 0.136 (0.161)	Loss 0.0024 (0.0024)	Prec@1 100.000 (99.990)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.088 (0.065)	BT: 0.174 (0.160)	Loss 0.0011 (0.0025)	Prec@1 100.000 (99.987)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.093 (0.065)	BT: 0.170 (0.160)	Loss 0.0013 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.070 (0.065)	BT: 0.153 (0.159)	Loss 0.0022 (0.0023)	Prec@1 100.000 (99.990)	
Total train loss: 0.0023
Avg Loading time: 0.0645 seconds
Avg Batch time: 0.1586 seconds

Train time: 62.23126196861267
 * Prec@1 94.220 Prec@5 99.710 Loss 0.2040
Avg Loading time: 0.1085 seconds
Avg Batch time: 0.1597 seconds

Best acc: 94.320
--------------------------------------------------------------------------------
Test time: 13.325815677642822

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.132 (0.083)	BT: 0.211 (0.179)	Loss 0.0017 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.136 (0.074)	BT: 0.223 (0.168)	Loss 0.0055 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.068 (0.073)	BT: 0.160 (0.168)	Loss 0.0016 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.074 (0.072)	BT: 0.170 (0.166)	Loss 0.0008 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.100 (0.071)	BT: 0.185 (0.165)	Loss 0.0013 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0021
Avg Loading time: 0.0710 seconds
Avg Batch time: 0.1647 seconds

Train time: 64.5825502872467
 * Prec@1 94.270 Prec@5 99.720 Loss 0.2019
Avg Loading time: 0.1042 seconds
Avg Batch time: 0.1572 seconds

Best acc: 94.320
--------------------------------------------------------------------------------
Test time: 13.199934005737305

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.065 (0.072)	BT: 0.134 (0.166)	Loss 0.0017 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.119 (0.068)	BT: 0.202 (0.160)	Loss 0.0036 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.069 (0.070)	BT: 0.187 (0.160)	Loss 0.0011 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.054 (0.070)	BT: 0.147 (0.160)	Loss 0.0017 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.121 (0.070)	BT: 0.188 (0.159)	Loss 0.0031 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0696 seconds
Avg Batch time: 0.1587 seconds

Train time: 62.27435827255249
 * Prec@1 94.300 Prec@5 99.700 Loss 0.2014
Avg Loading time: 0.1154 seconds
Avg Batch time: 0.1603 seconds

Best acc: 94.320
--------------------------------------------------------------------------------
Test time: 13.444563388824463

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.080 (0.075)	BT: 0.153 (0.171)	Loss 0.0016 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.070)	BT: 0.130 (0.170)	Loss 0.0012 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.067 (0.065)	BT: 0.143 (0.162)	Loss 0.0014 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.078 (0.066)	BT: 0.157 (0.164)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.140 (0.067)	BT: 0.220 (0.162)	Loss 0.0018 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0665 seconds
Avg Batch time: 0.1619 seconds

Train time: 63.52681255340576
 * Prec@1 94.290 Prec@5 99.700 Loss 0.2010
Avg Loading time: 0.1120 seconds
Avg Batch time: 0.1682 seconds

Best acc: 94.320
--------------------------------------------------------------------------------
Test time: 14.084371566772461

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.052 (0.072)	BT: 0.135 (0.167)	Loss 0.0011 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.061 (0.071)	BT: 0.151 (0.164)	Loss 0.0026 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.191 (0.069)	BT: 0.281 (0.160)	Loss 0.0024 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.045 (0.068)	BT: 0.110 (0.158)	Loss 0.0009 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.087 (0.068)	BT: 0.158 (0.158)	Loss 0.0007 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0674 seconds
Avg Batch time: 0.1575 seconds

Train time: 61.79939675331116
 * Prec@1 94.290 Prec@5 99.710 Loss 0.2034
Avg Loading time: 0.1131 seconds
Avg Batch time: 0.1629 seconds

Best acc: 94.320
--------------------------------------------------------------------------------
Test time: 13.985166549682617

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.079)	BT: 0.103 (0.181)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.980)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.080 (0.070)	BT: 0.172 (0.166)	Loss 0.0016 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.069)	BT: 0.103 (0.167)	Loss 0.0025 (0.0021)	Prec@1 100.000 (99.993)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.043 (0.067)	BT: 0.137 (0.164)	Loss 0.0018 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.069)	BT: 0.079 (0.165)	Loss 0.0018 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0684 seconds
Avg Batch time: 0.1651 seconds

Train time: 64.77389812469482
 * Prec@1 94.170 Prec@5 99.690 Loss 0.2032
Avg Loading time: 0.1136 seconds
Avg Batch time: 0.1630 seconds

Best acc: 94.320
--------------------------------------------------------------------------------
Test time: 13.687089920043945

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.118 (0.079)	BT: 0.187 (0.172)	Loss 0.0019 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.071 (0.073)	BT: 0.144 (0.163)	Loss 0.0028 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.057 (0.069)	BT: 0.163 (0.161)	Loss 0.0016 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.085 (0.068)	BT: 0.183 (0.161)	Loss 0.0032 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.036 (0.067)	BT: 0.126 (0.160)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0671 seconds
Avg Batch time: 0.1601 seconds

Train time: 62.78709578514099
 * Prec@1 94.160 Prec@5 99.720 Loss 0.2037
Avg Loading time: 0.1076 seconds
Avg Batch time: 0.1606 seconds

Best acc: 94.320
--------------------------------------------------------------------------------
Test time: 13.462982177734375

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.045 (0.078)	BT: 0.159 (0.169)	Loss 0.0017 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.049 (0.075)	BT: 0.129 (0.166)	Loss 0.0016 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.072)	BT: 0.080 (0.163)	Loss 0.0026 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.070 (0.070)	BT: 0.149 (0.162)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.094 (0.070)	BT: 0.163 (0.161)	Loss 0.0024 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0696 seconds
Avg Batch time: 0.1612 seconds

Train time: 63.219743728637695
 * Prec@1 94.240 Prec@5 99.710 Loss 0.2017
Avg Loading time: 0.1109 seconds
Avg Batch time: 0.1653 seconds

Best acc: 94.320
--------------------------------------------------------------------------------
Test time: 13.86414122581482

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.104 (0.076)	BT: 0.202 (0.173)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.041 (0.070)	BT: 0.116 (0.165)	Loss 0.0042 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.120 (0.069)	BT: 0.192 (0.163)	Loss 0.0021 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.052 (0.068)	BT: 0.124 (0.161)	Loss 0.0031 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.059 (0.068)	BT: 0.140 (0.160)	Loss 0.0021 (0.0022)	Prec@1 100.000 (99.992)	
Total train loss: 0.0022
Avg Loading time: 0.0679 seconds
Avg Batch time: 0.1603 seconds

Train time: 62.90151786804199
 * Prec@1 94.360 Prec@5 99.710 Loss 0.2004
Avg Loading time: 0.1068 seconds
Avg Batch time: 0.1546 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 13.49672532081604

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.079 (0.075)	BT: 0.148 (0.176)	Loss 0.0018 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.034 (0.070)	BT: 0.106 (0.165)	Loss 0.0017 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.070)	BT: 0.136 (0.164)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.993)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.049 (0.069)	BT: 0.127 (0.163)	Loss 0.0022 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.158 (0.069)	BT: 0.231 (0.163)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.992)	
Total train loss: 0.0021
Avg Loading time: 0.0685 seconds
Avg Batch time: 0.1627 seconds

Train time: 63.83713388442993
 * Prec@1 94.270 Prec@5 99.700 Loss 0.2018
Avg Loading time: 0.1156 seconds
Avg Batch time: 0.1713 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 14.33156156539917

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.073)	BT: 0.087 (0.170)	Loss 0.0016 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.062 (0.075)	BT: 0.172 (0.170)	Loss 0.0026 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.055 (0.070)	BT: 0.151 (0.161)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.146 (0.071)	BT: 0.221 (0.162)	Loss 0.0015 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.045 (0.070)	BT: 0.122 (0.158)	Loss 0.0015 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0695 seconds
Avg Batch time: 0.1582 seconds

Train time: 62.01389265060425
 * Prec@1 94.360 Prec@5 99.690 Loss 0.2000
Avg Loading time: 0.0984 seconds
Avg Batch time: 0.1305 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 11.094298839569092

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.044 (0.062)	BT: 0.109 (0.137)	Loss 0.0037 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.052 (0.057)	BT: 0.122 (0.130)	Loss 0.0028 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.071)	BT: 0.071 (0.142)	Loss 0.0058 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.216 (0.081)	BT: 0.289 (0.152)	Loss 0.0015 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.077)	BT: 0.067 (0.149)	Loss 0.0021 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0765 seconds
Avg Batch time: 0.1486 seconds

Train time: 58.23734664916992
 * Prec@1 94.250 Prec@5 99.710 Loss 0.2006
Avg Loading time: 0.1548 seconds
Avg Batch time: 0.1920 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 15.868931770324707

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.161)	BT: 0.062 (0.229)	Loss 0.0023 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.566 (0.169)	BT: 0.639 (0.239)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.175)	BT: 0.065 (0.246)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.178)	BT: 0.062 (0.250)	Loss 0.0015 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.182)	BT: 0.064 (0.254)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.1816 seconds
Avg Batch time: 0.2536 seconds

Train time: 99.30346989631653
 * Prec@1 94.250 Prec@5 99.720 Loss 0.2031
Avg Loading time: 0.1613 seconds
Avg Batch time: 0.1997 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 16.554786920547485

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.074)	BT: 0.123 (0.171)	Loss 0.0019 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.065)	BT: 0.100 (0.156)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.070 (0.065)	BT: 0.146 (0.156)	Loss 0.0010 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.067 (0.066)	BT: 0.151 (0.154)	Loss 0.0020 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.067)	BT: 0.074 (0.155)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0669 seconds
Avg Batch time: 0.1551 seconds

Train time: 60.83558797836304
 * Prec@1 94.250 Prec@5 99.710 Loss 0.2026
Avg Loading time: 0.1113 seconds
Avg Batch time: 0.1556 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 13.05966305732727

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.042 (0.072)	BT: 0.130 (0.162)	Loss 0.0015 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.101 (0.069)	BT: 0.182 (0.158)	Loss 0.0042 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.064 (0.069)	BT: 0.142 (0.155)	Loss 0.0024 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.067)	BT: 0.117 (0.154)	Loss 0.0007 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.107 (0.066)	BT: 0.206 (0.153)	Loss 0.0032 (0.0021)	Prec@1 100.000 (99.992)	
Total train loss: 0.0021
Avg Loading time: 0.0660 seconds
Avg Batch time: 0.1525 seconds

Train time: 59.818477630615234
 * Prec@1 94.150 Prec@5 99.710 Loss 0.2020
Avg Loading time: 0.1065 seconds
Avg Batch time: 0.1527 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 12.764823913574219

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.071 (0.077)	BT: 0.150 (0.167)	Loss 0.0017 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.070)	BT: 0.092 (0.158)	Loss 0.0013 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.069 (0.067)	BT: 0.138 (0.155)	Loss 0.0012 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.134 (0.065)	BT: 0.203 (0.153)	Loss 0.0026 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.065)	BT: 0.063 (0.151)	Loss 0.0023 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0646 seconds
Avg Batch time: 0.1512 seconds

Train time: 59.351848125457764
 * Prec@1 94.350 Prec@5 99.720 Loss 0.2021
Avg Loading time: 0.1104 seconds
Avg Batch time: 0.1580 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 13.261192321777344

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.145 (0.075)	BT: 0.227 (0.164)	Loss 0.0032 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.068)	BT: 0.068 (0.157)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.068)	BT: 0.105 (0.158)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.127 (0.066)	BT: 0.215 (0.156)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.051 (0.066)	BT: 0.120 (0.155)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0662 seconds
Avg Batch time: 0.1546 seconds

Train time: 60.61605358123779
 * Prec@1 94.350 Prec@5 99.730 Loss 0.2030
Avg Loading time: 0.1097 seconds
Avg Batch time: 0.1527 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 12.850170135498047

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.037 (0.076)	BT: 0.127 (0.163)	Loss 0.0032 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.083 (0.072)	BT: 0.161 (0.157)	Loss 0.0008 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.073 (0.069)	BT: 0.226 (0.154)	Loss 0.0017 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.079 (0.069)	BT: 0.163 (0.155)	Loss 0.0011 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.084 (0.068)	BT: 0.157 (0.153)	Loss 0.0010 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0675 seconds
Avg Batch time: 0.1528 seconds

Train time: 59.97565317153931
 * Prec@1 94.280 Prec@5 99.730 Loss 0.2025
Avg Loading time: 0.1081 seconds
Avg Batch time: 0.1508 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 12.640964984893799

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.072)	BT: 0.095 (0.169)	Loss 0.0011 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.066)	BT: 0.079 (0.158)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.207 (0.063)	BT: 0.295 (0.156)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.063)	BT: 0.106 (0.155)	Loss 0.0044 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.084 (0.063)	BT: 0.179 (0.154)	Loss 0.0040 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0631 seconds
Avg Batch time: 0.1542 seconds

Train time: 60.511526584625244
 * Prec@1 94.210 Prec@5 99.680 Loss 0.2032
Avg Loading time: 0.1078 seconds
Avg Batch time: 0.1582 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 13.212674856185913

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.064)	BT: 0.077 (0.160)	Loss 0.0014 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.032 (0.063)	BT: 0.130 (0.155)	Loss 0.0023 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.062)	BT: 0.102 (0.155)	Loss 0.0026 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.122 (0.061)	BT: 0.206 (0.153)	Loss 0.0018 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.091 (0.061)	BT: 0.161 (0.153)	Loss 0.0023 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0607 seconds
Avg Batch time: 0.1523 seconds

Train time: 59.70076513290405
 * Prec@1 94.310 Prec@5 99.670 Loss 0.2018
Avg Loading time: 0.1093 seconds
Avg Batch time: 0.1568 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 13.188802003860474

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.071)	BT: 0.100 (0.166)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.146 (0.066)	BT: 0.213 (0.160)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.062)	BT: 0.114 (0.156)	Loss 0.0006 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.070 (0.061)	BT: 0.222 (0.155)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.071 (0.060)	BT: 0.151 (0.154)	Loss 0.0014 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0596 seconds
Avg Batch time: 0.1537 seconds

Train time: 60.32651376724243
 * Prec@1 94.220 Prec@5 99.720 Loss 0.2020
Avg Loading time: 0.1114 seconds
Avg Batch time: 0.1549 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 12.998011589050293

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.055 (0.072)	BT: 0.152 (0.167)	Loss 0.0018 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.038 (0.067)	BT: 0.140 (0.160)	Loss 0.0013 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.189 (0.064)	BT: 0.270 (0.157)	Loss 0.0031 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.072 (0.063)	BT: 0.153 (0.155)	Loss 0.0019 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.051 (0.062)	BT: 0.129 (0.153)	Loss 0.0015 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0616 seconds
Avg Batch time: 0.1527 seconds

Train time: 59.89784121513367
 * Prec@1 94.230 Prec@5 99.720 Loss 0.2006
Avg Loading time: 0.1077 seconds
Avg Batch time: 0.1600 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 13.40846872329712

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.139 (0.073)	BT: 0.215 (0.163)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.069 (0.069)	BT: 0.164 (0.158)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.068)	BT: 0.081 (0.156)	Loss 0.0013 (0.0022)	Prec@1 100.000 (99.993)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.055 (0.066)	BT: 0.144 (0.154)	Loss 0.0022 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.078 (0.065)	BT: 0.149 (0.153)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0653 seconds
Avg Batch time: 0.1531 seconds

Train time: 60.06548190116882
 * Prec@1 94.320 Prec@5 99.670 Loss 0.2015
Avg Loading time: 0.1052 seconds
Avg Batch time: 0.1509 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 12.825268268585205

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.063 (0.076)	BT: 0.136 (0.169)	Loss 0.0022 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.175 (0.065)	BT: 0.273 (0.154)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.064)	BT: 0.103 (0.153)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.066 (0.062)	BT: 0.152 (0.150)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.104 (0.061)	BT: 0.182 (0.149)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.0606 seconds
Avg Batch time: 0.1488 seconds

Train time: 58.40260052680969
 * Prec@1 94.290 Prec@5 99.700 Loss 0.2013
Avg Loading time: 0.1121 seconds
Avg Batch time: 0.1583 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 13.28551173210144

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.004 (0.071)	BT: 0.085 (0.165)	Loss 0.0019 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.069)	BT: 0.112 (0.160)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.051 (0.065)	BT: 0.121 (0.153)	Loss 0.0015 (0.0023)	Prec@1 100.000 (99.993)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.167 (0.065)	BT: 0.244 (0.153)	Loss 0.0012 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.090 (0.063)	BT: 0.159 (0.151)	Loss 0.0010 (0.0022)	Prec@1 100.000 (99.992)	
Total train loss: 0.0022
Avg Loading time: 0.0631 seconds
Avg Batch time: 0.1512 seconds

Train time: 59.24994969367981
 * Prec@1 94.280 Prec@5 99.680 Loss 0.2031
Avg Loading time: 0.1113 seconds
Avg Batch time: 0.1630 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 13.676335573196411

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.064)	BT: 0.079 (0.160)	Loss 0.0038 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.064)	BT: 0.087 (0.158)	Loss 0.0013 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.061)	BT: 0.115 (0.154)	Loss 0.0017 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.094 (0.061)	BT: 0.168 (0.153)	Loss 0.0007 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.161 (0.060)	BT: 0.241 (0.153)	Loss 0.0024 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0602 seconds
Avg Batch time: 0.1527 seconds

Train time: 59.911112785339355
 * Prec@1 94.310 Prec@5 99.690 Loss 0.2014
Avg Loading time: 0.1084 seconds
Avg Batch time: 0.1565 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 13.165931940078735

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.045 (0.069)	BT: 0.115 (0.160)	Loss 0.0020 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.064 (0.063)	BT: 0.139 (0.156)	Loss 0.0018 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.062)	BT: 0.123 (0.154)	Loss 0.0013 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.190 (0.062)	BT: 0.274 (0.156)	Loss 0.0028 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.049 (0.060)	BT: 0.133 (0.150)	Loss 0.0018 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0594 seconds
Avg Batch time: 0.1499 seconds

Train time: 58.75331902503967
 * Prec@1 94.330 Prec@5 99.730 Loss 0.2007
Avg Loading time: 0.0915 seconds
Avg Batch time: 0.1326 seconds

Best acc: 94.360
--------------------------------------------------------------------------------
Test time: 11.211200952529907


      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 7
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/train/relu7
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/test/relu7
ResNet18(
  (conv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 9.700 Prec@5 52.780 Loss 2.2852
Avg Loading time: 0.0615 seconds
Avg Batch time: 0.0967 seconds

Pre-trained Prec@1 with 7 layers frozen: 9.699999809265137 	 Loss: 2.28515625

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (1.077)	BT: 0.043 (1.123)	Loss 0.3538 (0.6512)	Prec@1 85.938 (79.497)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (0.986)	BT: 0.047 (1.032)	Loss 0.3284 (0.5383)	Prec@1 90.625 (82.507)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (0.970)	BT: 0.046 (1.014)	Loss 0.4080 (0.4860)	Prec@1 84.375 (84.075)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (0.901)	BT: 0.039 (0.946)	Loss 0.3091 (0.4501)	Prec@1 92.188 (85.244)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.163 (0.840)	BT: 0.203 (0.885)	Loss 0.2854 (0.4245)	Prec@1 87.500 (86.012)	
Total train loss: 0.4243
Avg Loading time: 0.8379 seconds
Avg Batch time: 0.8826 seconds

Train time: 345.3087692260742
 * Prec@1 87.420 Prec@5 99.540 Loss 0.3647
Avg Loading time: 0.0656 seconds
Avg Batch time: 0.0821 seconds

Best acc: 87.420
--------------------------------------------------------------------------------
Test time: 7.701837778091431

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.037)	BT: 0.038 (0.088)	Loss 0.1783 (0.2124)	Prec@1 94.531 (93.219)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.029)	BT: 0.039 (0.081)	Loss 0.2169 (0.2170)	Prec@1 91.406 (92.839)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.061 (0.076)	Loss 0.2281 (0.2178)	Prec@1 93.750 (92.738)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.039 (0.022)	BT: 0.092 (0.075)	Loss 0.2087 (0.2197)	Prec@1 94.531 (92.736)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.039 (0.074)	Loss 0.2532 (0.2228)	Prec@1 91.406 (92.600)	
Total train loss: 0.2227
Avg Loading time: 0.0220 seconds
Avg Batch time: 0.0737 seconds

Train time: 29.052984952926636
 * Prec@1 91.100 Prec@5 99.710 Loss 0.2737
Avg Loading time: 0.0588 seconds
Avg Batch time: 0.0793 seconds

Best acc: 91.100
--------------------------------------------------------------------------------
Test time: 7.5366833209991455

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.032)	BT: 0.069 (0.083)	Loss 0.0786 (0.1302)	Prec@1 98.438 (95.663)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.056 (0.076)	Loss 0.1290 (0.1328)	Prec@1 96.094 (95.478)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.039 (0.021)	BT: 0.085 (0.074)	Loss 0.1126 (0.1387)	Prec@1 94.531 (95.266)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.001 (0.021)	BT: 0.055 (0.073)	Loss 0.2590 (0.1433)	Prec@1 92.188 (95.127)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.019)	BT: 0.039 (0.071)	Loss 0.1780 (0.1489)	Prec@1 95.312 (94.940)	
Total train loss: 0.1489
Avg Loading time: 0.0194 seconds
Avg Batch time: 0.0714 seconds

Train time: 28.125597953796387
 * Prec@1 89.760 Prec@5 99.700 Loss 0.3018
Avg Loading time: 0.0597 seconds
Avg Batch time: 0.0812 seconds

Best acc: 91.100
--------------------------------------------------------------------------------
Test time: 7.173285722732544

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.031)	BT: 0.102 (0.086)	Loss 0.0781 (0.0827)	Prec@1 97.656 (97.556)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.025)	BT: 0.076 (0.079)	Loss 0.0713 (0.0902)	Prec@1 98.438 (97.150)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.062 (0.076)	Loss 0.1296 (0.0948)	Prec@1 96.094 (97.019)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.044 (0.076)	Loss 0.0972 (0.1006)	Prec@1 94.531 (96.792)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.048 (0.075)	Loss 0.1328 (0.1045)	Prec@1 92.969 (96.589)	
Total train loss: 0.1048
Avg Loading time: 0.0215 seconds
Avg Batch time: 0.0752 seconds

Train time: 29.60310411453247
 * Prec@1 89.650 Prec@5 99.550 Loss 0.3398
Avg Loading time: 0.0547 seconds
Avg Batch time: 0.0763 seconds

Best acc: 91.100
--------------------------------------------------------------------------------
Test time: 6.740488529205322

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.032)	BT: 0.051 (0.087)	Loss 0.0359 (0.0724)	Prec@1 99.219 (97.696)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.021)	BT: 0.057 (0.076)	Loss 0.0494 (0.0695)	Prec@1 98.438 (97.791)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.021)	BT: 0.088 (0.075)	Loss 0.0980 (0.0716)	Prec@1 95.312 (97.696)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.069 (0.075)	Loss 0.0393 (0.0734)	Prec@1 98.438 (97.619)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.026 (0.021)	BT: 0.065 (0.074)	Loss 0.0935 (0.0789)	Prec@1 96.875 (97.402)	
Total train loss: 0.0792
Avg Loading time: 0.0207 seconds
Avg Batch time: 0.0738 seconds

Train time: 29.085748434066772
 * Prec@1 88.470 Prec@5 99.610 Loss 0.3718
Avg Loading time: 0.0603 seconds
Avg Batch time: 0.0772 seconds

Best acc: 91.100
--------------------------------------------------------------------------------
Test time: 6.808196306228638

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.031)	BT: 0.057 (0.085)	Loss 0.2417 (0.0651)	Prec@1 92.969 (97.847)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.056 (0.024)	BT: 0.096 (0.078)	Loss 0.0542 (0.0646)	Prec@1 97.656 (97.842)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.052 (0.077)	Loss 0.0760 (0.0666)	Prec@1 96.875 (97.827)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.024 (0.023)	BT: 0.070 (0.077)	Loss 0.0319 (0.0700)	Prec@1 99.219 (97.681)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.041 (0.076)	Loss 0.0930 (0.0718)	Prec@1 96.875 (97.644)	
Total train loss: 0.0718
Avg Loading time: 0.0218 seconds
Avg Batch time: 0.0758 seconds

Train time: 29.875967025756836
 * Prec@1 90.090 Prec@5 99.530 Loss 0.3325
Avg Loading time: 0.0566 seconds
Avg Batch time: 0.0778 seconds

Best acc: 91.100
--------------------------------------------------------------------------------
Test time: 6.853215217590332

Epoch: [6][77/391]	LR: 0.1	DT: 0.037 (0.031)	BT: 0.094 (0.085)	Loss 0.0855 (0.0490)	Prec@1 97.656 (98.468)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.046 (0.075)	Loss 0.0548 (0.0445)	Prec@1 98.438 (98.668)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.020)	BT: 0.056 (0.072)	Loss 0.0250 (0.0453)	Prec@1 99.219 (98.621)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.092 (0.021)	BT: 0.129 (0.074)	Loss 0.0175 (0.0461)	Prec@1 100.000 (98.555)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.020)	BT: 0.040 (0.073)	Loss 0.0636 (0.0495)	Prec@1 97.656 (98.431)	
Total train loss: 0.0496
Avg Loading time: 0.0202 seconds
Avg Batch time: 0.0725 seconds

Train time: 28.603597402572632
 * Prec@1 88.860 Prec@5 99.520 Loss 0.3799
Avg Loading time: 0.0559 seconds
Avg Batch time: 0.0737 seconds

Best acc: 91.100
--------------------------------------------------------------------------------
Test time: 6.667405128479004

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.032)	BT: 0.075 (0.087)	Loss 0.0775 (0.0513)	Prec@1 97.656 (98.327)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.039 (0.078)	Loss 0.0477 (0.0502)	Prec@1 97.656 (98.392)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.061 (0.075)	Loss 0.0634 (0.0495)	Prec@1 96.875 (98.411)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.021)	BT: 0.048 (0.073)	Loss 0.0413 (0.0507)	Prec@1 98.438 (98.377)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.014 (0.021)	BT: 0.052 (0.072)	Loss 0.0475 (0.0514)	Prec@1 97.656 (98.375)	
Total train loss: 0.0513
Avg Loading time: 0.0211 seconds
Avg Batch time: 0.0719 seconds

Train time: 28.349315643310547
 * Prec@1 90.750 Prec@5 99.550 Loss 0.3293
Avg Loading time: 0.0659 seconds
Avg Batch time: 0.0833 seconds

Best acc: 91.100
--------------------------------------------------------------------------------
Test time: 7.320358753204346

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.033)	BT: 0.054 (0.082)	Loss 0.0185 (0.0284)	Prec@1 100.000 (99.229)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.025)	BT: 0.068 (0.077)	Loss 0.0112 (0.0290)	Prec@1 100.000 (99.169)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.095 (0.025)	BT: 0.133 (0.076)	Loss 0.0193 (0.0314)	Prec@1 99.219 (99.038)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.075 (0.025)	BT: 0.129 (0.076)	Loss 0.0278 (0.0351)	Prec@1 100.000 (98.946)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.124 (0.025)	BT: 0.173 (0.075)	Loss 0.0116 (0.0382)	Prec@1 100.000 (98.822)	
Total train loss: 0.0382
Avg Loading time: 0.0246 seconds
Avg Batch time: 0.0752 seconds

Train time: 29.61963653564453
 * Prec@1 90.680 Prec@5 99.590 Loss 0.3118
Avg Loading time: 0.0600 seconds
Avg Batch time: 0.0777 seconds

Best acc: 91.100
--------------------------------------------------------------------------------
Test time: 6.907024145126343

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.029)	BT: 0.052 (0.083)	Loss 0.0109 (0.0276)	Prec@1 100.000 (99.229)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.039 (0.075)	Loss 0.0393 (0.0273)	Prec@1 98.438 (99.204)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.107 (0.022)	BT: 0.151 (0.073)	Loss 0.0569 (0.0302)	Prec@1 97.656 (99.112)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.039 (0.073)	Loss 0.0645 (0.0331)	Prec@1 97.656 (99.006)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.025 (0.023)	BT: 0.064 (0.074)	Loss 0.0594 (0.0371)	Prec@1 97.656 (98.868)	
Total train loss: 0.0371
Avg Loading time: 0.0229 seconds
Avg Batch time: 0.0743 seconds

Train time: 29.209077835083008
 * Prec@1 90.280 Prec@5 99.480 Loss 0.3474
Avg Loading time: 0.0505 seconds
Avg Batch time: 0.0708 seconds

Best acc: 91.100
--------------------------------------------------------------------------------
Test time: 6.32695746421814

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.029)	BT: 0.048 (0.088)	Loss 0.0230 (0.0269)	Prec@1 98.438 (99.209)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.021 (0.023)	BT: 0.098 (0.077)	Loss 0.0114 (0.0205)	Prec@1 100.000 (99.409)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.001 (0.022)	BT: 0.067 (0.074)	Loss 0.0051 (0.0175)	Prec@1 100.000 (99.533)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.029 (0.021)	BT: 0.066 (0.073)	Loss 0.0032 (0.0153)	Prec@1 100.000 (99.602)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.022 (0.022)	BT: 0.064 (0.074)	Loss 0.0071 (0.0137)	Prec@1 100.000 (99.659)	
Total train loss: 0.0137
Avg Loading time: 0.0217 seconds
Avg Batch time: 0.0736 seconds

Train time: 29.025456428527832
 * Prec@1 93.560 Prec@5 99.720 Loss 0.2206
Avg Loading time: 0.0590 seconds
Avg Batch time: 0.0769 seconds

Best acc: 93.560
--------------------------------------------------------------------------------
Test time: 7.246209621429443

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.066 (0.036)	BT: 0.105 (0.088)	Loss 0.0072 (0.0045)	Prec@1 100.000 (99.970)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.027)	BT: 0.058 (0.079)	Loss 0.0033 (0.0052)	Prec@1 100.000 (99.930)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.027 (0.025)	BT: 0.065 (0.076)	Loss 0.0032 (0.0050)	Prec@1 100.000 (99.937)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.023)	BT: 0.042 (0.073)	Loss 0.0044 (0.0049)	Prec@1 100.000 (99.942)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.027 (0.022)	BT: 0.065 (0.072)	Loss 0.0027 (0.0047)	Prec@1 100.000 (99.954)	
Total train loss: 0.0047
Avg Loading time: 0.0219 seconds
Avg Batch time: 0.0721 seconds

Train time: 28.411482334136963
 * Prec@1 93.820 Prec@5 99.700 Loss 0.2172
Avg Loading time: 0.0604 seconds
Avg Batch time: 0.0806 seconds

Best acc: 93.820
--------------------------------------------------------------------------------
Test time: 7.5938401222229

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.037)	BT: 0.043 (0.086)	Loss 0.0035 (0.0041)	Prec@1 100.000 (99.970)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.104 (0.026)	BT: 0.148 (0.077)	Loss 0.0026 (0.0039)	Prec@1 100.000 (99.970)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.026 (0.025)	BT: 0.070 (0.075)	Loss 0.0022 (0.0037)	Prec@1 100.000 (99.973)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.024)	BT: 0.044 (0.075)	Loss 0.0030 (0.0037)	Prec@1 100.000 (99.972)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.023)	BT: 0.051 (0.073)	Loss 0.0022 (0.0036)	Prec@1 100.000 (99.978)	
Total train loss: 0.0036
Avg Loading time: 0.0230 seconds
Avg Batch time: 0.0734 seconds

Train time: 28.93027400970459
 * Prec@1 93.850 Prec@5 99.690 Loss 0.2170
Avg Loading time: 0.0627 seconds
Avg Batch time: 0.0802 seconds

Best acc: 93.850
--------------------------------------------------------------------------------
Test time: 7.599063158035278

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.041 (0.034)	BT: 0.084 (0.085)	Loss 0.0023 (0.0033)	Prec@1 100.000 (99.980)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.025 (0.025)	BT: 0.071 (0.075)	Loss 0.0015 (0.0033)	Prec@1 100.000 (99.985)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.062 (0.074)	Loss 0.0013 (0.0033)	Prec@1 100.000 (99.977)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.067 (0.023)	BT: 0.105 (0.073)	Loss 0.0031 (0.0033)	Prec@1 100.000 (99.980)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.023)	BT: 0.037 (0.073)	Loss 0.0019 (0.0032)	Prec@1 100.000 (99.984)	
Total train loss: 0.0032
Avg Loading time: 0.0226 seconds
Avg Batch time: 0.0725 seconds

Train time: 28.5620219707489
 * Prec@1 93.960 Prec@5 99.660 Loss 0.2166
Avg Loading time: 0.0635 seconds
Avg Batch time: 0.0788 seconds

Best acc: 93.960
--------------------------------------------------------------------------------
Test time: 7.38074803352356

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.120 (0.034)	BT: 0.162 (0.086)	Loss 0.0080 (0.0030)	Prec@1 100.000 (100.000)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.042 (0.078)	Loss 0.0009 (0.0029)	Prec@1 100.000 (100.000)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.001 (0.022)	BT: 0.041 (0.074)	Loss 0.0028 (0.0029)	Prec@1 100.000 (99.997)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.021)	BT: 0.063 (0.073)	Loss 0.0023 (0.0028)	Prec@1 100.000 (99.997)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.021)	BT: 0.037 (0.072)	Loss 0.0011 (0.0027)	Prec@1 100.000 (99.998)	
Total train loss: 0.0027
Avg Loading time: 0.0206 seconds
Avg Batch time: 0.0718 seconds

Train time: 28.338276624679565
 * Prec@1 93.870 Prec@5 99.660 Loss 0.2142
Avg Loading time: 0.0620 seconds
Avg Batch time: 0.0829 seconds

Best acc: 93.960
--------------------------------------------------------------------------------
Test time: 7.302492618560791

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.029)	BT: 0.059 (0.084)	Loss 0.0012 (0.0026)	Prec@1 100.000 (100.000)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.013 (0.025)	BT: 0.062 (0.078)	Loss 0.0028 (0.0028)	Prec@1 100.000 (99.995)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.026 (0.022)	BT: 0.065 (0.076)	Loss 0.0019 (0.0027)	Prec@1 100.000 (99.993)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.021)	BT: 0.055 (0.074)	Loss 0.0028 (0.0026)	Prec@1 100.000 (99.995)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.019)	BT: 0.041 (0.073)	Loss 0.0021 (0.0027)	Prec@1 100.000 (99.992)	
Total train loss: 0.0027
Avg Loading time: 0.0185 seconds
Avg Batch time: 0.0726 seconds

Train time: 28.597593069076538
 * Prec@1 93.900 Prec@5 99.680 Loss 0.2152
Avg Loading time: 0.0610 seconds
Avg Batch time: 0.0806 seconds

Best acc: 93.960
--------------------------------------------------------------------------------
Test time: 7.106910467147827

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.034)	BT: 0.063 (0.088)	Loss 0.0035 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.086 (0.079)	Loss 0.0011 (0.0024)	Prec@1 100.000 (99.995)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.058 (0.023)	BT: 0.103 (0.076)	Loss 0.0019 (0.0024)	Prec@1 100.000 (99.997)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.021)	BT: 0.042 (0.074)	Loss 0.0025 (0.0024)	Prec@1 100.000 (99.995)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.017 (0.021)	BT: 0.067 (0.074)	Loss 0.0012 (0.0023)	Prec@1 100.000 (99.996)	
Total train loss: 0.0023
Avg Loading time: 0.0208 seconds
Avg Batch time: 0.0743 seconds

Train time: 29.271969318389893
 * Prec@1 94.070 Prec@5 99.660 Loss 0.2112
Avg Loading time: 0.0582 seconds
Avg Batch time: 0.0777 seconds

Best acc: 94.070
--------------------------------------------------------------------------------
Test time: 7.315789461135864

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.034)	BT: 0.041 (0.088)	Loss 0.0018 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.055 (0.080)	Loss 0.0013 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.048 (0.022)	BT: 0.088 (0.076)	Loss 0.0043 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.051 (0.075)	Loss 0.0027 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.059 (0.022)	BT: 0.102 (0.075)	Loss 0.0015 (0.0022)	Prec@1 100.000 (100.000)	
Total train loss: 0.0022
Avg Loading time: 0.0218 seconds
Avg Batch time: 0.0744 seconds

Train time: 29.269805192947388
 * Prec@1 94.080 Prec@5 99.680 Loss 0.2134
Avg Loading time: 0.0597 seconds
Avg Batch time: 0.0804 seconds

Best acc: 94.080
--------------------------------------------------------------------------------
Test time: 7.711988210678101

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.022 (0.027)	BT: 0.060 (0.079)	Loss 0.0015 (0.0024)	Prec@1 100.000 (99.990)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.018 (0.023)	BT: 0.068 (0.076)	Loss 0.0021 (0.0023)	Prec@1 100.000 (99.995)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.058 (0.076)	Loss 0.0017 (0.0023)	Prec@1 100.000 (99.997)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.026 (0.020)	BT: 0.064 (0.073)	Loss 0.0018 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.049 (0.021)	BT: 0.087 (0.073)	Loss 0.0012 (0.0022)	Prec@1 100.000 (99.998)	
Total train loss: 0.0022
Avg Loading time: 0.0206 seconds
Avg Batch time: 0.0729 seconds

Train time: 28.74019503593445
 * Prec@1 93.920 Prec@5 99.650 Loss 0.2114
Avg Loading time: 0.0638 seconds
Avg Batch time: 0.0834 seconds

Best acc: 94.080
--------------------------------------------------------------------------------
Test time: 7.31059455871582

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.029)	BT: 0.040 (0.081)	Loss 0.0009 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.024)	BT: 0.058 (0.076)	Loss 0.0019 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.001 (0.022)	BT: 0.067 (0.074)	Loss 0.0012 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.023)	BT: 0.050 (0.074)	Loss 0.0014 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.031 (0.022)	BT: 0.072 (0.073)	Loss 0.0024 (0.0022)	Prec@1 100.000 (99.994)	
Total train loss: 0.0022
Avg Loading time: 0.0216 seconds
Avg Batch time: 0.0726 seconds

Train time: 28.55304527282715
 * Prec@1 94.080 Prec@5 99.640 Loss 0.2136
Avg Loading time: 0.0609 seconds
Avg Batch time: 0.0782 seconds

Best acc: 94.080
--------------------------------------------------------------------------------
Test time: 6.932893991470337

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.076 (0.036)	BT: 0.116 (0.088)	Loss 0.0027 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.022 (0.027)	BT: 0.061 (0.078)	Loss 0.0007 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.024 (0.023)	BT: 0.079 (0.075)	Loss 0.0029 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.054 (0.076)	Loss 0.0014 (0.0020)	Prec@1 100.000 (99.992)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.037 (0.076)	Loss 0.0020 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.0228 seconds
Avg Batch time: 0.0756 seconds

Train time: 29.80254864692688
 * Prec@1 93.910 Prec@5 99.660 Loss 0.2122
Avg Loading time: 0.0552 seconds
Avg Batch time: 0.0762 seconds

Best acc: 94.080
--------------------------------------------------------------------------------
Test time: 6.733253717422485

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.129 (0.033)	BT: 0.168 (0.089)	Loss 0.0022 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.027)	BT: 0.061 (0.081)	Loss 0.0024 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.046 (0.076)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.020)	BT: 0.037 (0.074)	Loss 0.0019 (0.0021)	Prec@1 100.000 (99.992)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.021)	BT: 0.039 (0.074)	Loss 0.0021 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0206 seconds
Avg Batch time: 0.0741 seconds

Train time: 29.150185585021973
 * Prec@1 94.090 Prec@5 99.640 Loss 0.2136
Avg Loading time: 0.0561 seconds
Avg Batch time: 0.0753 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 7.179790496826172

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.022 (0.028)	BT: 0.076 (0.080)	Loss 0.0024 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.041 (0.026)	BT: 0.080 (0.077)	Loss 0.0116 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.021 (0.024)	BT: 0.058 (0.075)	Loss 0.0015 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.001 (0.023)	BT: 0.056 (0.073)	Loss 0.0017 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.044 (0.020)	BT: 0.088 (0.072)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.998)	
Total train loss: 0.0021
Avg Loading time: 0.0203 seconds
Avg Batch time: 0.0714 seconds

Train time: 28.169371366500854
 * Prec@1 94.000 Prec@5 99.650 Loss 0.2137
Avg Loading time: 0.0550 seconds
Avg Batch time: 0.0729 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 6.539843797683716

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.030)	BT: 0.055 (0.084)	Loss 0.0017 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.057 (0.076)	Loss 0.0029 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.065 (0.073)	Loss 0.0014 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.040 (0.072)	Loss 0.0061 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.049 (0.021)	BT: 0.087 (0.071)	Loss 0.0006 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.0211 seconds
Avg Batch time: 0.0711 seconds

Train time: 27.972275972366333
 * Prec@1 94.000 Prec@5 99.660 Loss 0.2114
Avg Loading time: 0.0552 seconds
Avg Batch time: 0.0733 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 6.519557237625122

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.022 (0.036)	BT: 0.068 (0.087)	Loss 0.0026 (0.0023)	Prec@1 100.000 (99.980)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.029)	BT: 0.056 (0.081)	Loss 0.0025 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.053 (0.078)	Loss 0.0014 (0.0022)	Prec@1 100.000 (99.993)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.041 (0.076)	Loss 0.0023 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.041 (0.074)	Loss 0.0013 (0.0022)	Prec@1 100.000 (99.994)	
Total train loss: 0.0022
Avg Loading time: 0.0228 seconds
Avg Batch time: 0.0744 seconds

Train time: 29.309638023376465
 * Prec@1 94.020 Prec@5 99.650 Loss 0.2122
Avg Loading time: 0.0581 seconds
Avg Batch time: 0.0807 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 7.115479230880737

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.031)	BT: 0.063 (0.082)	Loss 0.0030 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.025)	BT: 0.039 (0.078)	Loss 0.0046 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.027 (0.027)	BT: 0.071 (0.080)	Loss 0.0022 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.055 (0.079)	Loss 0.0026 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.044 (0.025)	BT: 0.081 (0.077)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0247 seconds
Avg Batch time: 0.0766 seconds

Train time: 30.09267568588257
 * Prec@1 93.950 Prec@5 99.660 Loss 0.2133
Avg Loading time: 0.0591 seconds
Avg Batch time: 0.0787 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 6.9374680519104

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.031)	BT: 0.068 (0.088)	Loss 0.0009 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.001 (0.023)	BT: 0.048 (0.077)	Loss 0.0014 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.068 (0.022)	BT: 0.109 (0.075)	Loss 0.0013 (0.0022)	Prec@1 100.000 (99.987)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.021)	BT: 0.065 (0.074)	Loss 0.0014 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.021)	BT: 0.059 (0.074)	Loss 0.0009 (0.0022)	Prec@1 100.000 (99.990)	
Total train loss: 0.0022
Avg Loading time: 0.0210 seconds
Avg Batch time: 0.0737 seconds

Train time: 29.031410455703735
 * Prec@1 93.930 Prec@5 99.670 Loss 0.2136
Avg Loading time: 0.0554 seconds
Avg Batch time: 0.0745 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 6.599919557571411

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.036)	BT: 0.047 (0.091)	Loss 0.0094 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.029)	BT: 0.056 (0.084)	Loss 0.0022 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.014 (0.024)	BT: 0.056 (0.078)	Loss 0.0052 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.048 (0.022)	BT: 0.088 (0.076)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.021)	BT: 0.039 (0.075)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.0206 seconds
Avg Batch time: 0.0750 seconds

Train time: 29.561485767364502
 * Prec@1 94.020 Prec@5 99.660 Loss 0.2140
Avg Loading time: 0.0610 seconds
Avg Batch time: 0.0803 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 7.10627555847168

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.028)	BT: 0.058 (0.082)	Loss 0.0013 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.063 (0.076)	Loss 0.0018 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.087 (0.019)	BT: 0.127 (0.073)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.019)	BT: 0.059 (0.073)	Loss 0.0017 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.018)	BT: 0.040 (0.072)	Loss 0.0010 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.0184 seconds
Avg Batch time: 0.0719 seconds

Train time: 28.311599254608154
 * Prec@1 94.080 Prec@5 99.640 Loss 0.2112
Avg Loading time: 0.0607 seconds
Avg Batch time: 0.0828 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 7.305928945541382

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.027)	BT: 0.055 (0.083)	Loss 0.0011 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.050 (0.076)	Loss 0.0021 (0.0021)	Prec@1 100.000 (99.985)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.049 (0.068)	Loss 0.0020 (0.0022)	Prec@1 100.000 (99.987)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.017 (0.013)	BT: 0.067 (0.065)	Loss 0.0014 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.040 (0.013)	BT: 0.078 (0.063)	Loss 0.0016 (0.0021)	Prec@1 100.000 (99.992)	
Total train loss: 0.0022
Avg Loading time: 0.0125 seconds
Avg Batch time: 0.0633 seconds

Train time: 24.938549041748047
 * Prec@1 94.000 Prec@5 99.640 Loss 0.2128
Avg Loading time: 0.0495 seconds
Avg Batch time: 0.0644 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.736423969268799

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.052 (0.066)	Loss 0.0017 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.013)	BT: 0.052 (0.061)	Loss 0.0025 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.030 (0.012)	BT: 0.070 (0.060)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.040 (0.059)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.035 (0.011)	BT: 0.074 (0.059)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0114 seconds
Avg Batch time: 0.0587 seconds

Train time: 23.094116687774658
 * Prec@1 94.080 Prec@5 99.650 Loss 0.2136
Avg Loading time: 0.0495 seconds
Avg Batch time: 0.0648 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.775818824768066

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.022 (0.024)	BT: 0.062 (0.071)	Loss 0.0031 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.021)	BT: 0.042 (0.066)	Loss 0.0034 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.059 (0.063)	Loss 0.0022 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.022 (0.015)	BT: 0.061 (0.062)	Loss 0.0011 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.042 (0.014)	BT: 0.082 (0.061)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0021
Avg Loading time: 0.0143 seconds
Avg Batch time: 0.0607 seconds

Train time: 23.89494776725769
 * Prec@1 94.080 Prec@5 99.650 Loss 0.2130
Avg Loading time: 0.0514 seconds
Avg Batch time: 0.0664 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.906112194061279

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.019 (0.017)	BT: 0.078 (0.068)	Loss 0.0013 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.018 (0.016)	BT: 0.058 (0.064)	Loss 0.0016 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.025 (0.016)	BT: 0.064 (0.062)	Loss 0.0008 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.018 (0.017)	BT: 0.055 (0.062)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.035 (0.017)	BT: 0.074 (0.061)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0165 seconds
Avg Batch time: 0.0611 seconds

Train time: 24.029134035110474
 * Prec@1 93.950 Prec@5 99.650 Loss 0.2124
Avg Loading time: 0.0495 seconds
Avg Batch time: 0.0642 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.716673851013184

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.022 (0.020)	BT: 0.062 (0.068)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.018)	BT: 0.054 (0.064)	Loss 0.0014 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.040 (0.063)	Loss 0.0010 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.026 (0.016)	BT: 0.065 (0.062)	Loss 0.0015 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.050 (0.016)	BT: 0.092 (0.061)	Loss 0.0039 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0163 seconds
Avg Batch time: 0.0614 seconds

Train time: 24.166715145111084
 * Prec@1 94.040 Prec@5 99.670 Loss 0.2146
Avg Loading time: 0.0484 seconds
Avg Batch time: 0.0637 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.693041086196899

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.023 (0.019)	BT: 0.063 (0.068)	Loss 0.0011 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.022 (0.017)	BT: 0.076 (0.064)	Loss 0.0008 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.055 (0.063)	Loss 0.0042 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.014 (0.017)	BT: 0.053 (0.062)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.039 (0.061)	Loss 0.0008 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0158 seconds
Avg Batch time: 0.0609 seconds

Train time: 23.961968183517456
 * Prec@1 94.040 Prec@5 99.650 Loss 0.2112
Avg Loading time: 0.0530 seconds
Avg Batch time: 0.0673 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.979834318161011

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.019)	BT: 0.040 (0.068)	Loss 0.0022 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.016 (0.015)	BT: 0.054 (0.063)	Loss 0.0022 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.017 (0.014)	BT: 0.055 (0.061)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.014)	BT: 0.051 (0.060)	Loss 0.0020 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.038 (0.013)	BT: 0.075 (0.059)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0126 seconds
Avg Batch time: 0.0590 seconds

Train time: 23.22357964515686
 * Prec@1 93.960 Prec@5 99.640 Loss 0.2122
Avg Loading time: 0.0498 seconds
Avg Batch time: 0.0642 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.740089416503906

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.018 (0.019)	BT: 0.070 (0.069)	Loss 0.0006 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.014)	BT: 0.040 (0.063)	Loss 0.0021 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.048 (0.061)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.021 (0.011)	BT: 0.062 (0.060)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.040 (0.010)	BT: 0.079 (0.059)	Loss 0.0024 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0104 seconds
Avg Batch time: 0.0590 seconds

Train time: 23.24226212501526
 * Prec@1 94.010 Prec@5 99.660 Loss 0.2115
Avg Loading time: 0.0494 seconds
Avg Batch time: 0.0657 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.859471321105957

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.023)	BT: 0.055 (0.071)	Loss 0.0014 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.056 (0.063)	Loss 0.0008 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.013)	BT: 0.041 (0.061)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.016 (0.012)	BT: 0.056 (0.060)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.040 (0.060)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0119 seconds
Avg Batch time: 0.0595 seconds

Train time: 23.42165231704712
 * Prec@1 93.980 Prec@5 99.670 Loss 0.2128
Avg Loading time: 0.0533 seconds
Avg Batch time: 0.0679 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 6.040072202682495

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.056 (0.068)	Loss 0.0029 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.016 (0.016)	BT: 0.053 (0.063)	Loss 0.0016 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.021 (0.016)	BT: 0.059 (0.061)	Loss 0.0013 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.014)	BT: 0.056 (0.061)	Loss 0.0009 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.042 (0.014)	BT: 0.081 (0.060)	Loss 0.0009 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0136 seconds
Avg Batch time: 0.0600 seconds

Train time: 23.622602462768555
 * Prec@1 94.060 Prec@5 99.650 Loss 0.2115
Avg Loading time: 0.0511 seconds
Avg Batch time: 0.0664 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.90436863899231

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.019)	BT: 0.048 (0.068)	Loss 0.0016 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.040 (0.061)	Loss 0.0021 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.028 (0.012)	BT: 0.067 (0.060)	Loss 0.0020 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.039 (0.059)	Loss 0.0026 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.041 (0.011)	BT: 0.081 (0.059)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0111 seconds
Avg Batch time: 0.0587 seconds

Train time: 23.068819046020508
 * Prec@1 94.060 Prec@5 99.640 Loss 0.2118
Avg Loading time: 0.0493 seconds
Avg Batch time: 0.0644 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.747709035873413

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.019)	BT: 0.040 (0.068)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.015)	BT: 0.054 (0.063)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.034 (0.013)	BT: 0.071 (0.061)	Loss 0.0021 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.013)	BT: 0.055 (0.060)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.012)	BT: 0.040 (0.059)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0120 seconds
Avg Batch time: 0.0590 seconds

Train time: 23.21160364151001
 * Prec@1 94.020 Prec@5 99.640 Loss 0.2115
Avg Loading time: 0.0511 seconds
Avg Batch time: 0.0662 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.892415285110474

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.016)	BT: 0.050 (0.069)	Loss 0.0035 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.012)	BT: 0.055 (0.063)	Loss 0.0015 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.041 (0.060)	Loss 0.0014 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.040 (0.060)	Loss 0.0031 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.039 (0.059)	Loss 0.0011 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.0100 seconds
Avg Batch time: 0.0588 seconds

Train time: 23.156692266464233
 * Prec@1 94.030 Prec@5 99.640 Loss 0.2126
Avg Loading time: 0.0505 seconds
Avg Batch time: 0.0662 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.880162000656128

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.018)	BT: 0.050 (0.067)	Loss 0.0020 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.016)	BT: 0.043 (0.065)	Loss 0.0010 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.016 (0.014)	BT: 0.056 (0.062)	Loss 0.0018 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.023 (0.014)	BT: 0.071 (0.061)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.042 (0.013)	BT: 0.082 (0.060)	Loss 0.0031 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0129 seconds
Avg Batch time: 0.0598 seconds

Train time: 23.519821166992188
 * Prec@1 93.960 Prec@5 99.650 Loss 0.2152
Avg Loading time: 0.0500 seconds
Avg Batch time: 0.0645 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.764439105987549

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.016 (0.022)	BT: 0.067 (0.072)	Loss 0.0049 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.083 (0.018)	BT: 0.124 (0.066)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.015)	BT: 0.040 (0.063)	Loss 0.0028 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.022 (0.014)	BT: 0.061 (0.062)	Loss 0.0021 (0.0019)	Prec@1 100.000 (99.992)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.044 (0.014)	BT: 0.083 (0.061)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.992)	
Total train loss: 0.0019
Avg Loading time: 0.0135 seconds
Avg Batch time: 0.0611 seconds

Train time: 24.050490140914917
 * Prec@1 94.080 Prec@5 99.650 Loss 0.2114
Avg Loading time: 0.0572 seconds
Avg Batch time: 0.0729 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 6.442992210388184

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.020)	BT: 0.047 (0.069)	Loss 0.0015 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.015)	BT: 0.054 (0.063)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.021 (0.015)	BT: 0.063 (0.062)	Loss 0.0053 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.053 (0.014)	BT: 0.106 (0.061)	Loss 0.0038 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.013)	BT: 0.039 (0.060)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0128 seconds
Avg Batch time: 0.0600 seconds

Train time: 23.63660740852356
 * Prec@1 93.810 Prec@5 99.660 Loss 0.2166
Avg Loading time: 0.0531 seconds
Avg Batch time: 0.0673 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.967617750167847

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.019)	BT: 0.056 (0.068)	Loss 0.0032 (0.0024)	Prec@1 100.000 (99.990)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.051 (0.062)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.022 (0.013)	BT: 0.079 (0.061)	Loss 0.0022 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.012)	BT: 0.040 (0.061)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.012)	BT: 0.039 (0.060)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0124 seconds
Avg Batch time: 0.0602 seconds

Train time: 23.695321559906006
 * Prec@1 93.990 Prec@5 99.660 Loss 0.2102
Avg Loading time: 0.0528 seconds
Avg Batch time: 0.0673 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.96120810508728

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.022 (0.019)	BT: 0.061 (0.069)	Loss 0.0029 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.021 (0.017)	BT: 0.065 (0.064)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.016)	BT: 0.058 (0.063)	Loss 0.0014 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.056 (0.062)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.039 (0.013)	BT: 0.082 (0.061)	Loss 0.0028 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0130 seconds
Avg Batch time: 0.0607 seconds

Train time: 23.90573000907898
 * Prec@1 94.050 Prec@5 99.650 Loss 0.2130
Avg Loading time: 0.0505 seconds
Avg Batch time: 0.0663 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.91097617149353

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.017)	BT: 0.040 (0.068)	Loss 0.0018 (0.0026)	Prec@1 100.000 (99.970)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.024 (0.017)	BT: 0.062 (0.064)	Loss 0.0023 (0.0024)	Prec@1 100.000 (99.985)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.020 (0.016)	BT: 0.060 (0.062)	Loss 0.0018 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.022 (0.015)	BT: 0.061 (0.061)	Loss 0.0025 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.049 (0.015)	BT: 0.088 (0.061)	Loss 0.0014 (0.0021)	Prec@1 100.000 (99.992)	
Total train loss: 0.0021
Avg Loading time: 0.0149 seconds
Avg Batch time: 0.0608 seconds

Train time: 23.906039714813232
 * Prec@1 93.960 Prec@5 99.640 Loss 0.2150
Avg Loading time: 0.0592 seconds
Avg Batch time: 0.0746 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 6.566453695297241

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.055 (0.070)	Loss 0.0011 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.016)	BT: 0.040 (0.064)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.015)	BT: 0.053 (0.062)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.042 (0.062)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.992)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.013)	BT: 0.040 (0.061)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.994)	
Total train loss: 0.0019
Avg Loading time: 0.0133 seconds
Avg Batch time: 0.0607 seconds

Train time: 23.89273762702942
 * Prec@1 93.970 Prec@5 99.640 Loss 0.2137
Avg Loading time: 0.0519 seconds
Avg Batch time: 0.0669 seconds

Best acc: 94.090
--------------------------------------------------------------------------------
Test time: 5.956587553024292

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.015 (0.021)	BT: 0.072 (0.070)	Loss 0.0027 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.016)	BT: 0.043 (0.064)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.055 (0.062)	Loss 0.0037 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.023 (0.013)	BT: 0.073 (0.061)	Loss 0.0027 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.041 (0.012)	BT: 0.080 (0.060)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.0118 seconds
Avg Batch time: 0.0599 seconds

Train time: 23.564791679382324
 * Prec@1 94.160 Prec@5 99.640 Loss 0.2124
Avg Loading time: 0.0482 seconds
Avg Batch time: 0.0636 seconds

Best acc: 94.160
--------------------------------------------------------------------------------
Test time: 6.152681350708008


      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 9
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/train/relu9
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/test/relu9
ResNet18(
  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 10.270 Prec@5 51.580 Loss 2.2969
Avg Loading time: 0.0504 seconds
Avg Batch time: 0.0783 seconds

Pre-trained Prec@1 with 9 layers frozen: 10.269999504089355 	 Loss: 2.296875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.588 (0.679)	BT: 0.633 (0.720)	Loss 0.4607 (0.6203)	Prec@1 84.375 (80.268)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (0.641)	BT: 0.037 (0.681)	Loss 0.3831 (0.5220)	Prec@1 85.938 (82.983)	
Epoch: [0][233/391]	LR: 0.1	DT: 1.462 (0.631)	BT: 1.507 (0.672)	Loss 0.3599 (0.4701)	Prec@1 90.625 (84.545)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (0.625)	BT: 0.035 (0.665)	Loss 0.2974 (0.4372)	Prec@1 92.188 (85.577)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (0.620)	BT: 0.035 (0.660)	Loss 0.3601 (0.4118)	Prec@1 87.500 (86.402)	
Total train loss: 0.4116
Avg Loading time: 0.6185 seconds
Avg Batch time: 0.6583 seconds

Train time: 257.5802307128906
 * Prec@1 89.550 Prec@5 99.600 Loss 0.3040
Avg Loading time: 0.0511 seconds
Avg Batch time: 0.0651 seconds

Best acc: 89.550
--------------------------------------------------------------------------------
Test time: 6.217520475387573

Epoch: [1][77/391]	LR: 0.1	DT: 0.021 (0.026)	BT: 0.053 (0.064)	Loss 0.1780 (0.1828)	Prec@1 91.406 (93.830)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.045 (0.060)	Loss 0.4219 (0.1934)	Prec@1 85.938 (93.510)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.025 (0.023)	BT: 0.056 (0.058)	Loss 0.1395 (0.1998)	Prec@1 94.531 (93.229)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.035 (0.058)	Loss 0.2061 (0.2005)	Prec@1 91.406 (93.187)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.047 (0.022)	BT: 0.085 (0.057)	Loss 0.2930 (0.2044)	Prec@1 89.844 (93.049)	
Total train loss: 0.2045
Avg Loading time: 0.0216 seconds
Avg Batch time: 0.0571 seconds

Train time: 22.49606728553772
 * Prec@1 89.850 Prec@5 99.720 Loss 0.2952
Avg Loading time: 0.0488 seconds
Avg Batch time: 0.0625 seconds

Best acc: 89.850
--------------------------------------------------------------------------------
Test time: 6.039903402328491

Epoch: [2][77/391]	LR: 0.1	DT: 0.024 (0.028)	BT: 0.055 (0.065)	Loss 0.0860 (0.1178)	Prec@1 97.656 (96.084)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.021 (0.025)	BT: 0.054 (0.060)	Loss 0.1129 (0.1216)	Prec@1 97.656 (96.014)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.020 (0.024)	BT: 0.052 (0.058)	Loss 0.1161 (0.1224)	Prec@1 95.312 (95.910)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.077 (0.024)	BT: 0.108 (0.058)	Loss 0.1378 (0.1255)	Prec@1 96.094 (95.776)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.048 (0.023)	BT: 0.079 (0.057)	Loss 0.1361 (0.1328)	Prec@1 94.531 (95.497)	
Total train loss: 0.1331
Avg Loading time: 0.0233 seconds
Avg Batch time: 0.0570 seconds

Train time: 22.46399998664856
 * Prec@1 89.060 Prec@5 99.600 Loss 0.3391
Avg Loading time: 0.0478 seconds
Avg Batch time: 0.0618 seconds

Best acc: 89.850
--------------------------------------------------------------------------------
Test time: 5.543084144592285

Epoch: [3][77/391]	LR: 0.1	DT: 0.026 (0.028)	BT: 0.058 (0.066)	Loss 0.0780 (0.0808)	Prec@1 96.875 (97.386)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.016 (0.024)	BT: 0.051 (0.060)	Loss 0.1447 (0.0801)	Prec@1 93.750 (97.366)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.038 (0.059)	Loss 0.1273 (0.0861)	Prec@1 96.094 (97.075)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.017 (0.023)	BT: 0.049 (0.058)	Loss 0.0451 (0.0901)	Prec@1 98.438 (96.948)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.042 (0.023)	BT: 0.078 (0.057)	Loss 0.0648 (0.0953)	Prec@1 96.875 (96.725)	
Total train loss: 0.0953
Avg Loading time: 0.0228 seconds
Avg Batch time: 0.0573 seconds

Train time: 22.55488896369934
 * Prec@1 87.150 Prec@5 99.640 Loss 0.4343
Avg Loading time: 0.0515 seconds
Avg Batch time: 0.0659 seconds

Best acc: 89.850
--------------------------------------------------------------------------------
Test time: 5.875498533248901

Epoch: [4][77/391]	LR: 0.1	DT: 0.030 (0.028)	BT: 0.065 (0.064)	Loss 0.0647 (0.0659)	Prec@1 98.438 (97.867)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.018 (0.025)	BT: 0.050 (0.060)	Loss 0.0646 (0.0654)	Prec@1 98.438 (97.902)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.029 (0.024)	BT: 0.061 (0.059)	Loss 0.0580 (0.0666)	Prec@1 97.656 (97.840)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.023 (0.023)	BT: 0.071 (0.058)	Loss 0.0710 (0.0704)	Prec@1 97.656 (97.691)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.020 (0.023)	BT: 0.052 (0.057)	Loss 0.1209 (0.0726)	Prec@1 97.656 (97.606)	
Total train loss: 0.0727
Avg Loading time: 0.0229 seconds
Avg Batch time: 0.0572 seconds

Train time: 22.54075527191162
 * Prec@1 90.820 Prec@5 99.640 Loss 0.3057
Avg Loading time: 0.0476 seconds
Avg Batch time: 0.0612 seconds

Best acc: 90.820
--------------------------------------------------------------------------------
Test time: 5.971458196640015

Epoch: [5][77/391]	LR: 0.1	DT: 0.017 (0.029)	BT: 0.069 (0.065)	Loss 0.0581 (0.0588)	Prec@1 97.656 (98.077)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.015 (0.025)	BT: 0.046 (0.060)	Loss 0.0410 (0.0554)	Prec@1 98.438 (98.197)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.034 (0.024)	BT: 0.065 (0.059)	Loss 0.0914 (0.0526)	Prec@1 96.875 (98.324)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.036 (0.024)	BT: 0.068 (0.058)	Loss 0.0493 (0.0544)	Prec@1 97.656 (98.252)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.019 (0.023)	BT: 0.051 (0.058)	Loss 0.0569 (0.0576)	Prec@1 99.219 (98.151)	
Total train loss: 0.0577
Avg Loading time: 0.0231 seconds
Avg Batch time: 0.0576 seconds

Train time: 22.66636824607849
 * Prec@1 89.960 Prec@5 99.550 Loss 0.3381
Avg Loading time: 0.0492 seconds
Avg Batch time: 0.0633 seconds

Best acc: 90.820
--------------------------------------------------------------------------------
Test time: 5.6302995681762695

Epoch: [6][77/391]	LR: 0.1	DT: 0.022 (0.030)	BT: 0.054 (0.069)	Loss 0.0317 (0.0458)	Prec@1 99.219 (98.548)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.014 (0.025)	BT: 0.045 (0.061)	Loss 0.0262 (0.0455)	Prec@1 100.000 (98.613)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.050 (0.059)	Loss 0.0742 (0.0431)	Prec@1 96.875 (98.648)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.023 (0.023)	BT: 0.055 (0.058)	Loss 0.0891 (0.0437)	Prec@1 97.656 (98.608)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.042 (0.022)	BT: 0.074 (0.057)	Loss 0.0791 (0.0465)	Prec@1 96.875 (98.512)	
Total train loss: 0.0466
Avg Loading time: 0.0219 seconds
Avg Batch time: 0.0568 seconds

Train time: 22.404213905334473
 * Prec@1 90.730 Prec@5 99.680 Loss 0.3257
Avg Loading time: 0.0470 seconds
Avg Batch time: 0.0609 seconds

Best acc: 90.820
--------------------------------------------------------------------------------
Test time: 5.468493938446045

Epoch: [7][77/391]	LR: 0.1	DT: 0.021 (0.029)	BT: 0.053 (0.065)	Loss 0.0456 (0.0459)	Prec@1 98.438 (98.508)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.025 (0.024)	BT: 0.056 (0.059)	Loss 0.0332 (0.0428)	Prec@1 99.219 (98.608)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.024 (0.023)	BT: 0.056 (0.058)	Loss 0.0208 (0.0442)	Prec@1 100.000 (98.591)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.019 (0.023)	BT: 0.053 (0.057)	Loss 0.0144 (0.0453)	Prec@1 100.000 (98.565)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.044 (0.022)	BT: 0.081 (0.057)	Loss 0.0604 (0.0462)	Prec@1 97.656 (98.544)	
Total train loss: 0.0463
Avg Loading time: 0.0222 seconds
Avg Batch time: 0.0567 seconds

Train time: 22.32656693458557
 * Prec@1 90.380 Prec@5 99.370 Loss 0.3608
Avg Loading time: 0.0483 seconds
Avg Batch time: 0.0622 seconds

Best acc: 90.820
--------------------------------------------------------------------------------
Test time: 5.682787656784058

Epoch: [8][77/391]	LR: 0.1	DT: 0.032 (0.028)	BT: 0.066 (0.065)	Loss 0.0532 (0.0344)	Prec@1 98.438 (98.938)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.021 (0.025)	BT: 0.053 (0.060)	Loss 0.0303 (0.0365)	Prec@1 98.438 (98.878)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.034 (0.024)	BT: 0.066 (0.059)	Loss 0.0407 (0.0359)	Prec@1 98.438 (98.878)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.020 (0.023)	BT: 0.052 (0.058)	Loss 0.0574 (0.0354)	Prec@1 97.656 (98.908)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.045 (0.023)	BT: 0.076 (0.058)	Loss 0.0328 (0.0383)	Prec@1 99.219 (98.774)	
Total train loss: 0.0383
Avg Loading time: 0.0231 seconds
Avg Batch time: 0.0575 seconds

Train time: 22.631207942962646
 * Prec@1 90.630 Prec@5 99.570 Loss 0.3193
Avg Loading time: 0.0484 seconds
Avg Batch time: 0.0616 seconds

Best acc: 90.820
--------------------------------------------------------------------------------
Test time: 5.5034332275390625

Epoch: [9][77/391]	LR: 0.1	DT: 0.022 (0.030)	BT: 0.069 (0.066)	Loss 0.0150 (0.0245)	Prec@1 100.000 (99.199)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.020 (0.026)	BT: 0.052 (0.061)	Loss 0.0155 (0.0217)	Prec@1 100.000 (99.339)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.068 (0.025)	BT: 0.100 (0.059)	Loss 0.0321 (0.0218)	Prec@1 98.438 (99.349)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.024 (0.023)	BT: 0.061 (0.058)	Loss 0.0218 (0.0243)	Prec@1 99.219 (99.261)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.045 (0.023)	BT: 0.079 (0.057)	Loss 0.0721 (0.0269)	Prec@1 98.438 (99.169)	
Total train loss: 0.0269
Avg Loading time: 0.0227 seconds
Avg Batch time: 0.0570 seconds

Train time: 22.423051595687866
 * Prec@1 90.840 Prec@5 99.380 Loss 0.3472
Avg Loading time: 0.0497 seconds
Avg Batch time: 0.0635 seconds

Best acc: 90.840
--------------------------------------------------------------------------------
Test time: 6.127305746078491

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.012 (0.027)	BT: 0.050 (0.064)	Loss 0.0108 (0.0164)	Prec@1 99.219 (99.579)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.025 (0.024)	BT: 0.056 (0.059)	Loss 0.0034 (0.0142)	Prec@1 100.000 (99.654)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.025 (0.023)	BT: 0.057 (0.057)	Loss 0.0082 (0.0123)	Prec@1 100.000 (99.723)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.021 (0.023)	BT: 0.051 (0.056)	Loss 0.0123 (0.0111)	Prec@1 99.219 (99.757)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.042 (0.022)	BT: 0.073 (0.056)	Loss 0.0064 (0.0104)	Prec@1 100.000 (99.772)	
Total train loss: 0.0104
Avg Loading time: 0.0223 seconds
Avg Batch time: 0.0560 seconds

Train time: 22.07115364074707
 * Prec@1 93.290 Prec@5 99.720 Loss 0.2375
Avg Loading time: 0.0482 seconds
Avg Batch time: 0.0613 seconds

Best acc: 93.290
--------------------------------------------------------------------------------
Test time: 5.975127220153809

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.027 (0.030)	BT: 0.059 (0.067)	Loss 0.0013 (0.0044)	Prec@1 100.000 (99.930)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.023 (0.025)	BT: 0.053 (0.061)	Loss 0.0038 (0.0043)	Prec@1 100.000 (99.940)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.024)	BT: 0.032 (0.059)	Loss 0.0032 (0.0042)	Prec@1 100.000 (99.957)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.018 (0.023)	BT: 0.055 (0.058)	Loss 0.0022 (0.0041)	Prec@1 100.000 (99.962)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.050 (0.023)	BT: 0.081 (0.057)	Loss 0.0024 (0.0039)	Prec@1 100.000 (99.970)	
Total train loss: 0.0039
Avg Loading time: 0.0229 seconds
Avg Batch time: 0.0572 seconds

Train time: 22.524075508117676
 * Prec@1 93.410 Prec@5 99.730 Loss 0.2322
Avg Loading time: 0.0476 seconds
Avg Batch time: 0.0622 seconds

Best acc: 93.410
--------------------------------------------------------------------------------
Test time: 6.8266425132751465

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.031 (0.028)	BT: 0.063 (0.065)	Loss 0.0132 (0.0033)	Prec@1 100.000 (100.000)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.022 (0.025)	BT: 0.053 (0.060)	Loss 0.0096 (0.0033)	Prec@1 100.000 (100.000)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.028 (0.024)	BT: 0.063 (0.059)	Loss 0.0012 (0.0033)	Prec@1 100.000 (99.993)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.014 (0.023)	BT: 0.046 (0.058)	Loss 0.0024 (0.0033)	Prec@1 100.000 (99.985)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.043 (0.023)	BT: 0.072 (0.057)	Loss 0.0013 (0.0033)	Prec@1 100.000 (99.982)	
Total train loss: 0.0033
Avg Loading time: 0.0226 seconds
Avg Batch time: 0.0568 seconds

Train time: 22.356276750564575
 * Prec@1 93.370 Prec@5 99.740 Loss 0.2336
Avg Loading time: 0.0483 seconds
Avg Batch time: 0.0622 seconds

Best acc: 93.410
--------------------------------------------------------------------------------
Test time: 5.570083856582642

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.030 (0.029)	BT: 0.062 (0.065)	Loss 0.0012 (0.0029)	Prec@1 100.000 (99.990)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.025 (0.025)	BT: 0.057 (0.060)	Loss 0.0031 (0.0030)	Prec@1 100.000 (99.985)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.018 (0.023)	BT: 0.050 (0.058)	Loss 0.0021 (0.0030)	Prec@1 100.000 (99.990)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.014 (0.022)	BT: 0.046 (0.057)	Loss 0.0016 (0.0030)	Prec@1 100.000 (99.987)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.017 (0.022)	BT: 0.049 (0.057)	Loss 0.0061 (0.0030)	Prec@1 100.000 (99.990)	
Total train loss: 0.0030
Avg Loading time: 0.0221 seconds
Avg Batch time: 0.0567 seconds

Train time: 22.334431648254395
 * Prec@1 93.460 Prec@5 99.730 Loss 0.2352
Avg Loading time: 0.0489 seconds
Avg Batch time: 0.0634 seconds

Best acc: 93.460
--------------------------------------------------------------------------------
Test time: 6.109847784042358

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.017 (0.029)	BT: 0.051 (0.065)	Loss 0.0036 (0.0027)	Prec@1 100.000 (99.990)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.024 (0.025)	BT: 0.058 (0.060)	Loss 0.0011 (0.0024)	Prec@1 100.000 (99.995)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.028 (0.023)	BT: 0.060 (0.058)	Loss 0.0015 (0.0024)	Prec@1 100.000 (99.997)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.027 (0.023)	BT: 0.061 (0.058)	Loss 0.0017 (0.0025)	Prec@1 100.000 (99.995)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.047 (0.023)	BT: 0.076 (0.057)	Loss 0.0018 (0.0025)	Prec@1 100.000 (99.996)	
Total train loss: 0.0025
Avg Loading time: 0.0227 seconds
Avg Batch time: 0.0569 seconds

Train time: 22.4190936088562
 * Prec@1 93.460 Prec@5 99.710 Loss 0.2316
Avg Loading time: 0.0468 seconds
Avg Batch time: 0.0616 seconds

Best acc: 93.460
--------------------------------------------------------------------------------
Test time: 6.066221475601196

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.018 (0.028)	BT: 0.050 (0.066)	Loss 0.0026 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.019 (0.025)	BT: 0.049 (0.061)	Loss 0.0013 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.020 (0.024)	BT: 0.053 (0.059)	Loss 0.0024 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.022 (0.024)	BT: 0.055 (0.059)	Loss 0.0016 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.020 (0.023)	BT: 0.052 (0.058)	Loss 0.0012 (0.0022)	Prec@1 100.000 (100.000)	
Total train loss: 0.0022
Avg Loading time: 0.0232 seconds
Avg Batch time: 0.0577 seconds

Train time: 22.734482288360596
 * Prec@1 93.490 Prec@5 99.740 Loss 0.2300
Avg Loading time: 0.0496 seconds
Avg Batch time: 0.0632 seconds

Best acc: 93.490
--------------------------------------------------------------------------------
Test time: 7.011375427246094

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.017 (0.026)	BT: 0.049 (0.064)	Loss 0.0019 (0.0024)	Prec@1 100.000 (99.990)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.018 (0.024)	BT: 0.048 (0.060)	Loss 0.0026 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.024 (0.023)	BT: 0.057 (0.059)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.993)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.023 (0.023)	BT: 0.053 (0.058)	Loss 0.0009 (0.0021)	Prec@1 100.000 (99.992)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.021 (0.022)	BT: 0.056 (0.057)	Loss 0.0017 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0224 seconds
Avg Batch time: 0.0570 seconds

Train time: 22.455994129180908
 * Prec@1 93.600 Prec@5 99.700 Loss 0.2266
Avg Loading time: 0.0503 seconds
Avg Batch time: 0.0638 seconds

Best acc: 93.600
--------------------------------------------------------------------------------
Test time: 6.188902378082275

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.030 (0.028)	BT: 0.062 (0.065)	Loss 0.0028 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.026 (0.024)	BT: 0.062 (0.060)	Loss 0.0024 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.027 (0.024)	BT: 0.061 (0.059)	Loss 0.0013 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.024)	BT: 0.032 (0.058)	Loss 0.0027 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.018 (0.023)	BT: 0.048 (0.058)	Loss 0.0015 (0.0022)	Prec@1 100.000 (99.998)	
Total train loss: 0.0022
Avg Loading time: 0.0234 seconds
Avg Batch time: 0.0579 seconds

Train time: 22.81976294517517
 * Prec@1 93.600 Prec@5 99.730 Loss 0.2303
Avg Loading time: 0.0499 seconds
Avg Batch time: 0.0627 seconds

Best acc: 93.600
--------------------------------------------------------------------------------
Test time: 5.6387224197387695

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.025 (0.029)	BT: 0.057 (0.066)	Loss 0.0020 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.019 (0.025)	BT: 0.051 (0.061)	Loss 0.0016 (0.0022)	Prec@1 100.000 (99.985)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.018 (0.023)	BT: 0.050 (0.059)	Loss 0.0014 (0.0022)	Prec@1 100.000 (99.987)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.023 (0.023)	BT: 0.056 (0.058)	Loss 0.0026 (0.0021)	Prec@1 100.000 (99.987)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.038 (0.022)	BT: 0.070 (0.057)	Loss 0.0024 (0.0021)	Prec@1 100.000 (99.990)	
Total train loss: 0.0021
Avg Loading time: 0.0223 seconds
Avg Batch time: 0.0572 seconds

Train time: 22.526127576828003
 * Prec@1 93.620 Prec@5 99.740 Loss 0.2310
Avg Loading time: 0.0498 seconds
Avg Batch time: 0.0653 seconds

Best acc: 93.620
--------------------------------------------------------------------------------
Test time: 6.2676379680633545

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.022 (0.030)	BT: 0.054 (0.066)	Loss 0.0037 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.018 (0.026)	BT: 0.056 (0.060)	Loss 0.0042 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.044 (0.059)	Loss 0.0010 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.026 (0.023)	BT: 0.059 (0.058)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.013 (0.023)	BT: 0.046 (0.057)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0229 seconds
Avg Batch time: 0.0569 seconds

Train time: 22.388031005859375
 * Prec@1 93.580 Prec@5 99.740 Loss 0.2292
Avg Loading time: 0.0522 seconds
Avg Batch time: 0.0659 seconds

Best acc: 93.620
--------------------------------------------------------------------------------
Test time: 5.866678714752197

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.016 (0.029)	BT: 0.048 (0.066)	Loss 0.0022 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.031 (0.026)	BT: 0.063 (0.061)	Loss 0.0012 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.018 (0.024)	BT: 0.050 (0.059)	Loss 0.0019 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.027 (0.022)	BT: 0.059 (0.058)	Loss 0.0017 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.042 (0.022)	BT: 0.071 (0.057)	Loss 0.0016 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0017
Avg Loading time: 0.0220 seconds
Avg Batch time: 0.0569 seconds

Train time: 22.414356231689453
 * Prec@1 93.610 Prec@5 99.730 Loss 0.2312
Avg Loading time: 0.0624 seconds
Avg Batch time: 0.0767 seconds

Best acc: 93.620
--------------------------------------------------------------------------------
Test time: 11.291519165039062

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.029 (0.027)	BT: 0.063 (0.065)	Loss 0.0012 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.020 (0.024)	BT: 0.057 (0.060)	Loss 0.0008 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.016 (0.023)	BT: 0.052 (0.058)	Loss 0.0020 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.021 (0.023)	BT: 0.060 (0.057)	Loss 0.0008 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.041 (0.022)	BT: 0.072 (0.057)	Loss 0.0020 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0223 seconds
Avg Batch time: 0.0567 seconds

Train time: 22.335938930511475
 * Prec@1 93.660 Prec@5 99.740 Loss 0.2292
Avg Loading time: 0.0495 seconds
Avg Batch time: 0.0637 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 9.176408290863037

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.023 (0.030)	BT: 0.056 (0.066)	Loss 0.0027 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.048 (0.061)	Loss 0.0016 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.013 (0.024)	BT: 0.045 (0.059)	Loss 0.0054 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.021 (0.023)	BT: 0.056 (0.058)	Loss 0.0010 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.046 (0.022)	BT: 0.078 (0.057)	Loss 0.0032 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0224 seconds
Avg Batch time: 0.0568 seconds

Train time: 22.365665912628174
 * Prec@1 93.590 Prec@5 99.720 Loss 0.2286
Avg Loading time: 0.0780 seconds
Avg Batch time: 0.0922 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 8.378188371658325

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.020 (0.028)	BT: 0.052 (0.066)	Loss 0.0010 (0.0015)	Prec@1 100.000 (100.000)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.021 (0.025)	BT: 0.054 (0.061)	Loss 0.0012 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.027 (0.024)	BT: 0.059 (0.059)	Loss 0.0025 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.021 (0.023)	BT: 0.053 (0.058)	Loss 0.0008 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.023 (0.022)	BT: 0.052 (0.057)	Loss 0.0031 (0.0018)	Prec@1 100.000 (99.996)	
Total train loss: 0.0018
Avg Loading time: 0.0222 seconds
Avg Batch time: 0.0567 seconds

Train time: 22.3192720413208
 * Prec@1 93.550 Prec@5 99.720 Loss 0.2300
Avg Loading time: 0.0520 seconds
Avg Batch time: 0.0660 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 7.447529077529907

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.015 (0.027)	BT: 0.047 (0.065)	Loss 0.0029 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.020 (0.024)	BT: 0.055 (0.060)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.019 (0.023)	BT: 0.051 (0.058)	Loss 0.0009 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.018 (0.022)	BT: 0.049 (0.057)	Loss 0.0008 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.032 (0.057)	Loss 0.0014 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0219 seconds
Avg Batch time: 0.0568 seconds

Train time: 22.41000986099243
 * Prec@1 93.620 Prec@5 99.710 Loss 0.2288
Avg Loading time: 0.0474 seconds
Avg Batch time: 0.0623 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 5.867201328277588

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.025 (0.025)	BT: 0.057 (0.064)	Loss 0.0017 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.017 (0.023)	BT: 0.050 (0.059)	Loss 0.0017 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.015 (0.022)	BT: 0.047 (0.058)	Loss 0.0007 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.021 (0.022)	BT: 0.053 (0.057)	Loss 0.0015 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.044 (0.021)	BT: 0.076 (0.057)	Loss 0.0012 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0214 seconds
Avg Batch time: 0.0565 seconds

Train time: 22.23454761505127
 * Prec@1 93.650 Prec@5 99.720 Loss 0.2303
Avg Loading time: 0.0516 seconds
Avg Batch time: 0.0655 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 6.097622871398926

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.018 (0.028)	BT: 0.048 (0.065)	Loss 0.0018 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.021 (0.024)	BT: 0.053 (0.060)	Loss 0.0009 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.043 (0.059)	Loss 0.0051 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.028 (0.023)	BT: 0.061 (0.058)	Loss 0.0031 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.017 (0.023)	BT: 0.048 (0.057)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.0226 seconds
Avg Batch time: 0.0572 seconds

Train time: 22.497493267059326
 * Prec@1 93.620 Prec@5 99.720 Loss 0.2321
Avg Loading time: 0.0519 seconds
Avg Batch time: 0.0667 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 6.065645694732666

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.018 (0.025)	BT: 0.050 (0.064)	Loss 0.0102 (0.0021)	Prec@1 99.219 (99.990)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.024 (0.023)	BT: 0.056 (0.059)	Loss 0.0008 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.024 (0.023)	BT: 0.058 (0.058)	Loss 0.0019 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.019 (0.023)	BT: 0.051 (0.058)	Loss 0.0023 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.045 (0.022)	BT: 0.077 (0.057)	Loss 0.0010 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0220 seconds
Avg Batch time: 0.0567 seconds

Train time: 22.307049989700317
 * Prec@1 93.500 Prec@5 99.700 Loss 0.2286
Avg Loading time: 0.0507 seconds
Avg Batch time: 0.0645 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 7.912931680679321

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.017 (0.028)	BT: 0.049 (0.065)	Loss 0.0035 (0.0018)	Prec@1 100.000 (99.990)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.025 (0.024)	BT: 0.059 (0.059)	Loss 0.0016 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.062 (0.023)	BT: 0.095 (0.058)	Loss 0.0007 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.023 (0.023)	BT: 0.055 (0.057)	Loss 0.0013 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.016 (0.022)	BT: 0.052 (0.057)	Loss 0.0013 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0223 seconds
Avg Batch time: 0.0567 seconds

Train time: 22.291301488876343
 * Prec@1 93.660 Prec@5 99.740 Loss 0.2286
Avg Loading time: 0.0470 seconds
Avg Batch time: 0.0612 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 6.555191516876221

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.028)	BT: 0.044 (0.064)	Loss 0.0021 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.029 (0.025)	BT: 0.061 (0.059)	Loss 0.0012 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.033 (0.024)	BT: 0.065 (0.058)	Loss 0.0017 (0.0018)	Prec@1 100.000 (99.993)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.032 (0.057)	Loss 0.0012 (0.0018)	Prec@1 100.000 (99.992)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.015 (0.023)	BT: 0.046 (0.057)	Loss 0.0011 (0.0018)	Prec@1 100.000 (99.994)	
Total train loss: 0.0018
Avg Loading time: 0.0227 seconds
Avg Batch time: 0.0567 seconds

Train time: 22.355802297592163
 * Prec@1 93.610 Prec@5 99.740 Loss 0.2296
Avg Loading time: 0.0638 seconds
Avg Batch time: 0.0795 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 9.84335970878601

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.041 (0.025)	BT: 0.078 (0.065)	Loss 0.0011 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.021 (0.023)	BT: 0.050 (0.061)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.016 (0.023)	BT: 0.048 (0.059)	Loss 0.0006 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.015 (0.022)	BT: 0.047 (0.058)	Loss 0.0015 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.044 (0.022)	BT: 0.076 (0.057)	Loss 0.0035 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0221 seconds
Avg Batch time: 0.0574 seconds

Train time: 22.572688341140747
 * Prec@1 93.560 Prec@5 99.710 Loss 0.2308
Avg Loading time: 0.0459 seconds
Avg Batch time: 0.0606 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 5.852577447891235

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.024 (0.028)	BT: 0.061 (0.065)	Loss 0.0015 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.028 (0.024)	BT: 0.059 (0.060)	Loss 0.0024 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.015 (0.022)	BT: 0.047 (0.058)	Loss 0.0035 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.018 (0.022)	BT: 0.050 (0.058)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.041 (0.022)	BT: 0.072 (0.057)	Loss 0.0015 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0221 seconds
Avg Batch time: 0.0571 seconds

Train time: 22.49704933166504
 * Prec@1 93.620 Prec@5 99.720 Loss 0.2281
Avg Loading time: 0.0488 seconds
Avg Batch time: 0.0627 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 7.252102851867676

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.025 (0.028)	BT: 0.061 (0.064)	Loss 0.0026 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.025)	BT: 0.045 (0.060)	Loss 0.0025 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.014 (0.023)	BT: 0.046 (0.058)	Loss 0.0045 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.018 (0.023)	BT: 0.050 (0.058)	Loss 0.0014 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.012 (0.023)	BT: 0.042 (0.057)	Loss 0.0013 (0.0018)	Prec@1 100.000 (99.996)	
Total train loss: 0.0018
Avg Loading time: 0.0227 seconds
Avg Batch time: 0.0570 seconds

Train time: 22.462659120559692
 * Prec@1 93.560 Prec@5 99.720 Loss 0.2294
Avg Loading time: 0.0502 seconds
Avg Batch time: 0.0650 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 7.826164245605469

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.025 (0.027)	BT: 0.054 (0.063)	Loss 0.0016 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.031 (0.022)	BT: 0.068 (0.058)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.022 (0.022)	BT: 0.054 (0.057)	Loss 0.0015 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.023 (0.022)	BT: 0.055 (0.057)	Loss 0.0020 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.044 (0.022)	BT: 0.075 (0.056)	Loss 0.0023 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0215 seconds
Avg Batch time: 0.0561 seconds

Train time: 22.10125422477722
 * Prec@1 93.500 Prec@5 99.730 Loss 0.2278
Avg Loading time: 0.0473 seconds
Avg Batch time: 0.0615 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 6.357248306274414

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.018 (0.028)	BT: 0.051 (0.066)	Loss 0.0018 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.029 (0.024)	BT: 0.063 (0.060)	Loss 0.0009 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.023)	BT: 0.032 (0.059)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.014 (0.022)	BT: 0.048 (0.057)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.992)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.041 (0.022)	BT: 0.075 (0.057)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.0217 seconds
Avg Batch time: 0.0564 seconds

Train time: 22.230475902557373
 * Prec@1 93.540 Prec@5 99.710 Loss 0.2271
Avg Loading time: 0.0466 seconds
Avg Batch time: 0.0611 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 10.170439720153809

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.018 (0.026)	BT: 0.050 (0.066)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.020 (0.024)	BT: 0.052 (0.061)	Loss 0.0018 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.025 (0.023)	BT: 0.059 (0.059)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.022)	BT: 0.030 (0.058)	Loss 0.0017 (0.0018)	Prec@1 100.000 (99.992)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.037 (0.022)	BT: 0.072 (0.057)	Loss 0.0043 (0.0018)	Prec@1 100.000 (99.994)	
Total train loss: 0.0018
Avg Loading time: 0.0216 seconds
Avg Batch time: 0.0569 seconds

Train time: 22.400717735290527
 * Prec@1 93.570 Prec@5 99.730 Loss 0.2280
Avg Loading time: 0.0483 seconds
Avg Batch time: 0.0621 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 6.06668758392334

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.020 (0.027)	BT: 0.053 (0.063)	Loss 0.0013 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.025 (0.024)	BT: 0.057 (0.059)	Loss 0.0013 (0.0017)	Prec@1 100.000 (99.995)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.017 (0.023)	BT: 0.048 (0.058)	Loss 0.0009 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.022)	BT: 0.032 (0.057)	Loss 0.0015 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.014 (0.022)	BT: 0.045 (0.056)	Loss 0.0023 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0219 seconds
Avg Batch time: 0.0564 seconds

Train time: 22.19347882270813
 * Prec@1 93.520 Prec@5 99.740 Loss 0.2288
Avg Loading time: 0.0448 seconds
Avg Batch time: 0.0597 seconds

Best acc: 93.660
--------------------------------------------------------------------------------
Test time: 6.255450487136841

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.026 (0.025)	BT: 0.059 (0.063)	Loss 0.0039 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.017 (0.021)	BT: 0.055 (0.058)	Loss 0.0011 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.016 (0.020)	BT: 0.048 (0.057)	Loss 0.0018 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.014 (0.019)	BT: 0.046 (0.055)	Loss 0.0017 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.040 (0.019)	BT: 0.072 (0.054)	Loss 0.0015 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0185 seconds
Avg Batch time: 0.0544 seconds

Train time: 21.426395416259766
 * Prec@1 93.700 Prec@5 99.720 Loss 0.2296
Avg Loading time: 0.0516 seconds
Avg Batch time: 0.0657 seconds

Best acc: 93.700
--------------------------------------------------------------------------------
Test time: 9.125272989273071

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.021 (0.027)	BT: 0.050 (0.063)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.016 (0.022)	BT: 0.049 (0.058)	Loss 0.0008 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.014 (0.021)	BT: 0.046 (0.056)	Loss 0.0017 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.037 (0.055)	Loss 0.0020 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.039 (0.019)	BT: 0.071 (0.054)	Loss 0.0026 (0.0019)	Prec@1 100.000 (99.994)	
Total train loss: 0.0019
Avg Loading time: 0.0194 seconds
Avg Batch time: 0.0542 seconds

Train time: 21.3730046749115
 * Prec@1 93.580 Prec@5 99.720 Loss 0.2281
Avg Loading time: 0.0484 seconds
Avg Batch time: 0.0624 seconds

Best acc: 93.700
--------------------------------------------------------------------------------
Test time: 7.134839057922363

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.072 (0.033)	BT: 0.105 (0.070)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.016 (0.026)	BT: 0.049 (0.062)	Loss 0.0020 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.017 (0.023)	BT: 0.050 (0.059)	Loss 0.0036 (0.0018)	Prec@1 100.000 (99.993)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.020 (0.021)	BT: 0.055 (0.057)	Loss 0.0014 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.011 (0.020)	BT: 0.042 (0.056)	Loss 0.0010 (0.0018)	Prec@1 100.000 (99.996)	
Total train loss: 0.0018
Avg Loading time: 0.0201 seconds
Avg Batch time: 0.0557 seconds

Train time: 21.897606134414673
 * Prec@1 93.470 Prec@5 99.720 Loss 0.2294
Avg Loading time: 0.0467 seconds
Avg Batch time: 0.0611 seconds

Best acc: 93.700
--------------------------------------------------------------------------------
Test time: 5.893972396850586

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.028)	BT: 0.038 (0.066)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.023 (0.022)	BT: 0.057 (0.058)	Loss 0.0017 (0.0017)	Prec@1 100.000 (99.995)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.019 (0.020)	BT: 0.053 (0.056)	Loss 0.0058 (0.0018)	Prec@1 100.000 (99.993)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.015 (0.019)	BT: 0.047 (0.055)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.038 (0.019)	BT: 0.074 (0.054)	Loss 0.0051 (0.0019)	Prec@1 100.000 (99.992)	
Total train loss: 0.0019
Avg Loading time: 0.0187 seconds
Avg Batch time: 0.0543 seconds

Train time: 21.38709259033203
 * Prec@1 93.600 Prec@5 99.710 Loss 0.2303
Avg Loading time: 0.0473 seconds
Avg Batch time: 0.0630 seconds

Best acc: 93.700
--------------------------------------------------------------------------------
Test time: 6.754373073577881

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.015 (0.026)	BT: 0.049 (0.064)	Loss 0.0005 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.014 (0.023)	BT: 0.060 (0.059)	Loss 0.0020 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.021)	BT: 0.048 (0.056)	Loss 0.0008 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.022 (0.019)	BT: 0.054 (0.055)	Loss 0.0007 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.049 (0.018)	BT: 0.081 (0.054)	Loss 0.0025 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0184 seconds
Avg Batch time: 0.0543 seconds

Train time: 21.34805393218994
 * Prec@1 93.560 Prec@5 99.730 Loss 0.2294
Avg Loading time: 0.0470 seconds
Avg Batch time: 0.0618 seconds

Best acc: 93.700
--------------------------------------------------------------------------------
Test time: 8.632826805114746

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.021 (0.028)	BT: 0.054 (0.065)	Loss 0.0009 (0.0017)	Prec@1 100.000 (99.990)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.017 (0.023)	BT: 0.051 (0.059)	Loss 0.0017 (0.0020)	Prec@1 100.000 (99.985)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.022)	BT: 0.032 (0.057)	Loss 0.0025 (0.0019)	Prec@1 100.000 (99.987)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.020 (0.022)	BT: 0.054 (0.057)	Loss 0.0018 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.048 (0.021)	BT: 0.079 (0.056)	Loss 0.0015 (0.0019)	Prec@1 100.000 (99.990)	
Total train loss: 0.0019
Avg Loading time: 0.0208 seconds
Avg Batch time: 0.0556 seconds

Train time: 21.896510124206543
 * Prec@1 93.670 Prec@5 99.740 Loss 0.2274
Avg Loading time: 0.0490 seconds
Avg Batch time: 0.0623 seconds

Best acc: 93.700
--------------------------------------------------------------------------------
Test time: 6.524643182754517

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.025 (0.030)	BT: 0.056 (0.065)	Loss 0.0009 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.019 (0.027)	BT: 0.052 (0.061)	Loss 0.0019 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.018 (0.025)	BT: 0.052 (0.059)	Loss 0.0017 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.024)	BT: 0.032 (0.058)	Loss 0.0019 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.040 (0.023)	BT: 0.072 (0.057)	Loss 0.0058 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0234 seconds
Avg Batch time: 0.0574 seconds

Train time: 22.59330701828003
 * Prec@1 93.580 Prec@5 99.740 Loss 0.2300
Avg Loading time: 0.0473 seconds
Avg Batch time: 0.0615 seconds

Best acc: 93.700
--------------------------------------------------------------------------------
Test time: 7.802517414093018

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.017 (0.029)	BT: 0.050 (0.065)	Loss 0.0009 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.021 (0.025)	BT: 0.053 (0.060)	Loss 0.0009 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.031 (0.025)	BT: 0.062 (0.059)	Loss 0.0011 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.117 (0.025)	BT: 0.151 (0.059)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.052 (0.024)	BT: 0.087 (0.058)	Loss 0.0015 (0.0017)	Prec@1 100.000 (100.000)	
Total train loss: 0.0017
Avg Loading time: 0.0241 seconds
Avg Batch time: 0.0580 seconds

Train time: 22.79748773574829
 * Prec@1 93.560 Prec@5 99.720 Loss 0.2290
Avg Loading time: 0.0501 seconds
Avg Batch time: 0.0635 seconds

Best acc: 93.700
--------------------------------------------------------------------------------
Test time: 6.184688329696655

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.025)	BT: 0.043 (0.064)	Loss 0.0077 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.019 (0.020)	BT: 0.053 (0.057)	Loss 0.0019 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.034 (0.019)	BT: 0.066 (0.055)	Loss 0.0017 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.019)	BT: 0.049 (0.055)	Loss 0.0021 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.050 (0.019)	BT: 0.081 (0.055)	Loss 0.0042 (0.0019)	Prec@1 100.000 (99.994)	
Total train loss: 0.0019
Avg Loading time: 0.0188 seconds
Avg Batch time: 0.0544 seconds

Train time: 21.44097399711609
 * Prec@1 93.690 Prec@5 99.720 Loss 0.2294
Avg Loading time: 0.0524 seconds
Avg Batch time: 0.0677 seconds

Best acc: 93.700
--------------------------------------------------------------------------------
Test time: 6.365234136581421

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.031 (0.028)	BT: 0.064 (0.065)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.980)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.020 (0.025)	BT: 0.051 (0.060)	Loss 0.0012 (0.0018)	Prec@1 100.000 (99.990)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.027 (0.024)	BT: 0.059 (0.059)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.035 (0.024)	BT: 0.067 (0.058)	Loss 0.0011 (0.0018)	Prec@1 100.000 (99.992)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.020 (0.023)	BT: 0.051 (0.057)	Loss 0.0017 (0.0018)	Prec@1 100.000 (99.994)	
Total train loss: 0.0018
Avg Loading time: 0.0234 seconds
Avg Batch time: 0.0572 seconds

Train time: 22.520470142364502
 * Prec@1 93.710 Prec@5 99.730 Loss 0.2299
Avg Loading time: 0.0463 seconds
Avg Batch time: 0.0618 seconds

Best acc: 93.710
--------------------------------------------------------------------------------
Test time: 6.364738464355469

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.018 (0.029)	BT: 0.050 (0.064)	Loss 0.0017 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.024 (0.026)	BT: 0.056 (0.060)	Loss 0.0012 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.020 (0.025)	BT: 0.052 (0.058)	Loss 0.0022 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.017 (0.024)	BT: 0.049 (0.058)	Loss 0.0011 (0.0017)	Prec@1 100.000 (99.997)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.048 (0.023)	BT: 0.079 (0.057)	Loss 0.0023 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0234 seconds
Avg Batch time: 0.0572 seconds

Train time: 22.493966102600098
 * Prec@1 93.660 Prec@5 99.750 Loss 0.2306
Avg Loading time: 0.0495 seconds
Avg Batch time: 0.0631 seconds

Best acc: 93.710
--------------------------------------------------------------------------------
Test time: 10.202027082443237

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.028 (0.033)	BT: 0.060 (0.069)	Loss 0.0023 (0.0015)	Prec@1 100.000 (100.000)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.031 (0.028)	BT: 0.064 (0.062)	Loss 0.0022 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.028 (0.026)	BT: 0.060 (0.060)	Loss 0.0018 (0.0017)	Prec@1 100.000 (99.997)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.017 (0.026)	BT: 0.049 (0.060)	Loss 0.0015 (0.0017)	Prec@1 100.000 (99.997)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.047 (0.026)	BT: 0.078 (0.059)	Loss 0.0018 (0.0017)	Prec@1 100.000 (99.998)	
Total train loss: 0.0017
Avg Loading time: 0.0255 seconds
Avg Batch time: 0.0592 seconds

Train time: 23.292086362838745
 * Prec@1 93.520 Prec@5 99.720 Loss 0.2316
Avg Loading time: 0.0495 seconds
Avg Batch time: 0.0642 seconds

Best acc: 93.710
--------------------------------------------------------------------------------
Test time: 7.125048637390137

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.020 (0.027)	BT: 0.052 (0.064)	Loss 0.0012 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.020 (0.024)	BT: 0.052 (0.059)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.018 (0.024)	BT: 0.050 (0.058)	Loss 0.0014 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.049 (0.057)	Loss 0.0013 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.020 (0.023)	BT: 0.051 (0.056)	Loss 0.0017 (0.0017)	Prec@1 100.000 (99.998)	
Total train loss: 0.0017
Avg Loading time: 0.0225 seconds
Avg Batch time: 0.0561 seconds

Train time: 22.08666968345642
 * Prec@1 93.690 Prec@5 99.730 Loss 0.2296
Avg Loading time: 0.0490 seconds
Avg Batch time: 0.0631 seconds

Best acc: 93.710
--------------------------------------------------------------------------------
Test time: 6.699740886688232

