
      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.005
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 9
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar100/resnet18
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/train/relu9
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/test/relu9
ResNet18(
  (conv10): QConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): QConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): QConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): QConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=512, out_features=100, bias=False)
  (bn19): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 0.640 Prec@5 4.240 Loss 4.6172
Avg Loading time: 0.4862 seconds
Avg Batch time: 0.5091 seconds

Pre-trained Prec@1 with 9 layers frozen: 0.6399999856948853 	 Loss: 4.6171875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.005	DT: 0.000 (1.184)	BT: 0.036 (1.226)	Loss 2.5488 (3.4272)	Prec@1 42.969 (25.841)	
Epoch: [0][155/391]	LR: 0.005	DT: 0.090 (1.065)	BT: 0.127 (1.106)	Loss 2.4492 (2.9246)	Prec@1 54.688 (37.375)	
Epoch: [0][233/391]	LR: 0.005	DT: 0.000 (1.025)	BT: 0.036 (1.066)	Loss 2.2480 (2.7113)	Prec@1 48.438 (42.398)	
Epoch: [0][311/391]	LR: 0.005	DT: 0.000 (0.988)	BT: 0.037 (1.029)	Loss 2.1738 (2.6046)	Prec@1 51.562 (45.007)	
Epoch: [0][389/391]	LR: 0.005	DT: 0.000 (0.976)	BT: 0.038 (1.017)	Loss 2.2207 (2.5469)	Prec@1 52.344 (46.705)	
Total train loss: 2.5468
Avg Loading time: 0.9733 seconds
Avg Batch time: 1.0140 seconds

Train time: 396.63614654541016
 * Prec@1 55.690 Prec@5 84.310 Loss 2.1562
Avg Loading time: 0.0722 seconds
Avg Batch time: 0.0913 seconds

Best acc: 55.690
--------------------------------------------------------------------------------
Test time: 19.497401237487793

Epoch: [1][77/391]	LR: 0.005	DT: 0.016 (0.023)	BT: 0.065 (0.065)	Loss 2.1191 (2.2015)	Prec@1 57.031 (54.046)	
Epoch: [1][155/391]	LR: 0.005	DT: 0.000 (0.020)	BT: 0.046 (0.060)	Loss 2.2246 (2.1688)	Prec@1 52.344 (54.703)	
Epoch: [1][233/391]	LR: 0.005	DT: 0.019 (0.019)	BT: 0.050 (0.058)	Loss 1.9150 (2.1353)	Prec@1 58.594 (55.065)	
Epoch: [1][311/391]	LR: 0.005	DT: 0.032 (0.020)	BT: 0.066 (0.058)	Loss 2.0938 (2.1145)	Prec@1 46.875 (55.133)	
Epoch: [1][389/391]	LR: 0.005	DT: 0.050 (0.020)	BT: 0.092 (0.058)	Loss 2.0078 (2.0989)	Prec@1 53.125 (55.064)	
Total train loss: 2.0987
Avg Loading time: 0.0196 seconds
Avg Batch time: 0.0580 seconds

Train time: 22.78743815422058
 * Prec@1 56.490 Prec@5 85.380 Loss 1.9551
Avg Loading time: 0.0475 seconds
Avg Batch time: 0.0628 seconds

Best acc: 56.490
--------------------------------------------------------------------------------
Test time: 6.7049760818481445

Epoch: [2][77/391]	LR: 0.005	DT: 0.026 (0.024)	BT: 0.057 (0.064)	Loss 2.0820 (1.9969)	Prec@1 51.562 (54.698)	
Epoch: [2][155/391]	LR: 0.005	DT: 0.031 (0.022)	BT: 0.062 (0.060)	Loss 1.7939 (1.9924)	Prec@1 60.938 (54.527)	
Epoch: [2][233/391]	LR: 0.005	DT: 0.015 (0.021)	BT: 0.047 (0.058)	Loss 1.9160 (1.9684)	Prec@1 53.125 (55.105)	
Epoch: [2][311/391]	LR: 0.005	DT: 0.032 (0.022)	BT: 0.066 (0.057)	Loss 1.9238 (1.9516)	Prec@1 53.906 (55.329)	
Epoch: [2][389/391]	LR: 0.005	DT: 0.017 (0.021)	BT: 0.047 (0.056)	Loss 1.7109 (1.9389)	Prec@1 63.281 (55.381)	
Total train loss: 1.9390
Avg Loading time: 0.0213 seconds
Avg Batch time: 0.0563 seconds

Train time: 22.12568473815918
 * Prec@1 55.400 Prec@5 84.660 Loss 1.8867
Avg Loading time: 0.0470 seconds
Avg Batch time: 0.0652 seconds

Best acc: 56.490
--------------------------------------------------------------------------------
Test time: 6.335741758346558

Epoch: [3][77/391]	LR: 0.005	DT: 0.029 (0.028)	BT: 0.061 (0.067)	Loss 1.7520 (1.8994)	Prec@1 56.250 (55.599)	
Epoch: [3][155/391]	LR: 0.005	DT: 0.015 (0.023)	BT: 0.046 (0.061)	Loss 1.9170 (1.9158)	Prec@1 55.469 (55.369)	
Epoch: [3][233/391]	LR: 0.005	DT: 0.018 (0.023)	BT: 0.051 (0.060)	Loss 2.2109 (1.9105)	Prec@1 40.625 (55.132)	
Epoch: [3][311/391]	LR: 0.005	DT: 0.025 (0.023)	BT: 0.056 (0.059)	Loss 1.8896 (1.8955)	Prec@1 52.344 (55.271)	
Epoch: [3][389/391]	LR: 0.005	DT: 0.017 (0.022)	BT: 0.047 (0.058)	Loss 1.8916 (1.8797)	Prec@1 49.219 (55.252)	
Total train loss: 1.8797
Avg Loading time: 0.0218 seconds
Avg Batch time: 0.0576 seconds

Train time: 22.629172325134277
 * Prec@1 57.000 Prec@5 85.970 Loss 1.7471
Avg Loading time: 0.0478 seconds
Avg Batch time: 0.0628 seconds

Best acc: 57.000
--------------------------------------------------------------------------------
Test time: 7.320013999938965

Epoch: [4][77/391]	LR: 0.005	DT: 0.081 (0.026)	BT: 0.112 (0.066)	Loss 1.7520 (1.7451)	Prec@1 59.375 (57.131)	
Epoch: [4][155/391]	LR: 0.005	DT: 0.017 (0.021)	BT: 0.048 (0.060)	Loss 1.6182 (1.7629)	Prec@1 57.812 (56.450)	
Epoch: [4][233/391]	LR: 0.005	DT: 0.023 (0.021)	BT: 0.054 (0.059)	Loss 2.0000 (1.7696)	Prec@1 49.219 (56.210)	
Epoch: [4][311/391]	LR: 0.005	DT: 0.016 (0.021)	BT: 0.050 (0.058)	Loss 1.8057 (1.7732)	Prec@1 57.812 (56.140)	
Epoch: [4][389/391]	LR: 0.005	DT: 0.059 (0.020)	BT: 0.092 (0.057)	Loss 1.9014 (1.7682)	Prec@1 48.438 (56.324)	
Total train loss: 1.7682
Avg Loading time: 0.0198 seconds
Avg Batch time: 0.0573 seconds

Train time: 22.52368426322937
 * Prec@1 57.560 Prec@5 86.280 Loss 1.6943
Avg Loading time: 0.0474 seconds
Avg Batch time: 0.0640 seconds

Best acc: 57.560
--------------------------------------------------------------------------------
Test time: 12.180158138275146

Epoch: [5][77/391]	LR: 0.005	DT: 0.033 (0.037)	BT: 0.064 (0.074)	Loss 1.7578 (1.7355)	Prec@1 57.812 (56.470)	
Epoch: [5][155/391]	LR: 0.005	DT: 0.023 (0.025)	BT: 0.056 (0.065)	Loss 1.6455 (1.7184)	Prec@1 58.594 (57.056)	
Epoch: [5][233/391]	LR: 0.005	DT: 0.023 (0.023)	BT: 0.054 (0.061)	Loss 1.8594 (1.7266)	Prec@1 57.812 (56.811)	
Epoch: [5][311/391]	LR: 0.005	DT: 0.029 (0.023)	BT: 0.060 (0.060)	Loss 1.8633 (1.7309)	Prec@1 54.688 (56.738)	
Epoch: [5][389/391]	LR: 0.005	DT: 0.022 (0.022)	BT: 0.057 (0.059)	Loss 1.7266 (1.7270)	Prec@1 54.688 (56.715)	
Total train loss: 1.7264
Avg Loading time: 0.0223 seconds
Avg Batch time: 0.0588 seconds

Train time: 23.082616329193115
 * Prec@1 58.100 Prec@5 86.900 Loss 1.6348
Avg Loading time: 0.0462 seconds
Avg Batch time: 0.0622 seconds

Best acc: 58.100
--------------------------------------------------------------------------------
Test time: 11.500890254974365

Epoch: [6][77/391]	LR: 0.005	DT: 0.000 (0.020)	BT: 0.037 (0.067)	Loss 1.6045 (1.6404)	Prec@1 60.156 (58.944)	
Epoch: [6][155/391]	LR: 0.005	DT: 0.016 (0.017)	BT: 0.049 (0.061)	Loss 1.6934 (1.6776)	Prec@1 54.688 (57.908)	
Epoch: [6][233/391]	LR: 0.005	DT: 0.023 (0.018)	BT: 0.061 (0.060)	Loss 1.6143 (1.6863)	Prec@1 56.250 (57.552)	
Epoch: [6][311/391]	LR: 0.005	DT: 0.000 (0.018)	BT: 0.043 (0.059)	Loss 1.5576 (1.6879)	Prec@1 59.375 (57.424)	
Epoch: [6][389/391]	LR: 0.005	DT: 0.045 (0.018)	BT: 0.075 (0.058)	Loss 1.8633 (1.6810)	Prec@1 49.219 (57.410)	
Total train loss: 1.6809
Avg Loading time: 0.0178 seconds
Avg Batch time: 0.0579 seconds

Train time: 22.776698350906372
 * Prec@1 56.320 Prec@5 85.220 Loss 1.7598
Avg Loading time: 0.0515 seconds
Avg Batch time: 0.0666 seconds

Best acc: 58.100
--------------------------------------------------------------------------------
Test time: 9.161266088485718

Epoch: [7][77/391]	LR: 0.005	DT: 0.018 (0.027)	BT: 0.049 (0.066)	Loss 1.8525 (1.6532)	Prec@1 50.000 (57.342)	
Epoch: [7][155/391]	LR: 0.005	DT: 0.031 (0.024)	BT: 0.062 (0.061)	Loss 1.5967 (1.6494)	Prec@1 60.938 (57.707)	
Epoch: [7][233/391]	LR: 0.005	DT: 0.031 (0.024)	BT: 0.063 (0.060)	Loss 1.5576 (1.6434)	Prec@1 63.281 (57.595)	
Epoch: [7][311/391]	LR: 0.005	DT: 0.000 (0.022)	BT: 0.041 (0.059)	Loss 1.5166 (1.6356)	Prec@1 69.531 (57.777)	
Epoch: [7][389/391]	LR: 0.005	DT: 0.046 (0.021)	BT: 0.076 (0.058)	Loss 1.6973 (1.6317)	Prec@1 57.812 (57.837)	
Total train loss: 1.6323
Avg Loading time: 0.0212 seconds
Avg Batch time: 0.0579 seconds

Train time: 22.787954807281494
 * Prec@1 56.660 Prec@5 85.350 Loss 1.7266
Avg Loading time: 0.0474 seconds
Avg Batch time: 0.0631 seconds

Best acc: 58.100
--------------------------------------------------------------------------------
Test time: 9.558625936508179

Epoch: [8][77/391]	LR: 0.005	DT: 0.020 (0.024)	BT: 0.053 (0.065)	Loss 1.4199 (1.6049)	Prec@1 62.500 (58.584)	
Epoch: [8][155/391]	LR: 0.005	DT: 0.024 (0.021)	BT: 0.055 (0.060)	Loss 1.3604 (1.6123)	Prec@1 63.281 (58.549)	
Epoch: [8][233/391]	LR: 0.005	DT: 0.029 (0.020)	BT: 0.062 (0.058)	Loss 1.5615 (1.6137)	Prec@1 57.812 (58.524)	
Epoch: [8][311/391]	LR: 0.005	DT: 0.032 (0.021)	BT: 0.089 (0.058)	Loss 1.5830 (1.6201)	Prec@1 55.469 (58.153)	
Epoch: [8][389/391]	LR: 0.005	DT: 0.054 (0.021)	BT: 0.087 (0.058)	Loss 1.6533 (1.6163)	Prec@1 51.562 (58.165)	
Total train loss: 1.6165
Avg Loading time: 0.0207 seconds
Avg Batch time: 0.0576 seconds

Train time: 22.63450837135315
 * Prec@1 58.990 Prec@5 87.200 Loss 1.5615
Avg Loading time: 0.0489 seconds
Avg Batch time: 0.0645 seconds

Best acc: 58.990
--------------------------------------------------------------------------------
Test time: 13.983473300933838

Epoch: [9][77/391]	LR: 0.005	DT: 0.025 (0.034)	BT: 0.089 (0.071)	Loss 1.6172 (1.5838)	Prec@1 63.281 (58.874)	
Epoch: [9][155/391]	LR: 0.005	DT: 0.030 (0.028)	BT: 0.061 (0.063)	Loss 1.5107 (1.5871)	Prec@1 58.594 (58.639)	
Epoch: [9][233/391]	LR: 0.005	DT: 0.018 (0.026)	BT: 0.048 (0.061)	Loss 1.6377 (1.5890)	Prec@1 55.469 (58.333)	
Epoch: [9][311/391]	LR: 0.005	DT: 0.000 (0.025)	BT: 0.055 (0.060)	Loss 1.8008 (1.5922)	Prec@1 53.125 (58.278)	
Epoch: [9][389/391]	LR: 0.005	DT: 0.043 (0.023)	BT: 0.076 (0.059)	Loss 1.5576 (1.5929)	Prec@1 57.031 (58.197)	
Total train loss: 1.5934
Avg Loading time: 0.0233 seconds
Avg Batch time: 0.0589 seconds

Train time: 23.186965942382812
 * Prec@1 59.490 Prec@5 87.280 Loss 1.5469
Avg Loading time: 0.0498 seconds
Avg Batch time: 0.0651 seconds

Best acc: 59.490
--------------------------------------------------------------------------------
Test time: 12.321433544158936

Epoch: [10][77/391]	LR: 0.001	DT: 0.089 (0.021)	BT: 0.148 (0.064)	Loss 1.5107 (1.5703)	Prec@1 64.844 (58.544)	
Epoch: [10][155/391]	LR: 0.001	DT: 0.014 (0.022)	BT: 0.065 (0.061)	Loss 1.5322 (1.5606)	Prec@1 62.500 (59.120)	
Epoch: [10][233/391]	LR: 0.001	DT: 0.026 (0.021)	BT: 0.057 (0.059)	Loss 1.5469 (1.5649)	Prec@1 59.375 (59.048)	
Epoch: [10][311/391]	LR: 0.001	DT: 0.020 (0.021)	BT: 0.052 (0.058)	Loss 1.6211 (1.5630)	Prec@1 57.812 (59.014)	
Epoch: [10][389/391]	LR: 0.001	DT: 0.045 (0.022)	BT: 0.078 (0.058)	Loss 1.7139 (1.5618)	Prec@1 56.250 (59.105)	
Total train loss: 1.5620
Avg Loading time: 0.0216 seconds
Avg Batch time: 0.0578 seconds

Train time: 22.724947214126587
 * Prec@1 59.390 Prec@5 87.210 Loss 1.5371
Avg Loading time: 0.0479 seconds
Avg Batch time: 0.0637 seconds

Best acc: 59.490
--------------------------------------------------------------------------------
Test time: 8.381239652633667

Epoch: [11][77/391]	LR: 0.001	DT: 0.020 (0.026)	BT: 0.082 (0.065)	Loss 1.3652 (1.5547)	Prec@1 66.406 (58.944)	
Epoch: [11][155/391]	LR: 0.001	DT: 0.033 (0.024)	BT: 0.064 (0.061)	Loss 1.5889 (1.5702)	Prec@1 55.469 (58.714)	
Epoch: [11][233/391]	LR: 0.001	DT: 0.015 (0.023)	BT: 0.049 (0.059)	Loss 1.4434 (1.5701)	Prec@1 61.719 (58.667)	
Epoch: [11][311/391]	LR: 0.001	DT: 0.024 (0.023)	BT: 0.057 (0.058)	Loss 1.3867 (1.5651)	Prec@1 63.281 (58.839)	
Epoch: [11][389/391]	LR: 0.001	DT: 0.044 (0.023)	BT: 0.074 (0.058)	Loss 1.5664 (1.5602)	Prec@1 55.469 (59.028)	
Total train loss: 1.5602
Avg Loading time: 0.0230 seconds
Avg Batch time: 0.0575 seconds

Train time: 22.58987522125244
 * Prec@1 59.460 Prec@5 87.450 Loss 1.5322
Avg Loading time: 0.0473 seconds
Avg Batch time: 0.0619 seconds

Best acc: 59.490
--------------------------------------------------------------------------------
Test time: 9.276968002319336

Epoch: [12][77/391]	LR: 0.001	DT: 0.021 (0.025)	BT: 0.052 (0.065)	Loss 1.3555 (1.5658)	Prec@1 69.531 (58.654)	
Epoch: [12][155/391]	LR: 0.001	DT: 0.017 (0.022)	BT: 0.054 (0.060)	Loss 1.4844 (1.5526)	Prec@1 64.844 (59.120)	
Epoch: [12][233/391]	LR: 0.001	DT: 0.022 (0.022)	BT: 0.056 (0.059)	Loss 1.7051 (1.5542)	Prec@1 55.469 (59.218)	
Epoch: [12][311/391]	LR: 0.001	DT: 0.028 (0.022)	BT: 0.060 (0.058)	Loss 1.5029 (1.5573)	Prec@1 62.500 (59.095)	
Epoch: [12][389/391]	LR: 0.001	DT: 0.059 (0.022)	BT: 0.092 (0.058)	Loss 1.6055 (1.5602)	Prec@1 53.906 (59.149)	
Total train loss: 1.5605
Avg Loading time: 0.0220 seconds
Avg Batch time: 0.0576 seconds

Train time: 22.653076171875
 * Prec@1 59.500 Prec@5 87.450 Loss 1.5342
Avg Loading time: 0.0485 seconds
Avg Batch time: 0.0632 seconds

Best acc: 59.500
--------------------------------------------------------------------------------
Test time: 11.955607414245605

Epoch: [13][77/391]	LR: 0.001	DT: 0.018 (0.027)	BT: 0.050 (0.066)	Loss 1.5156 (1.5573)	Prec@1 64.844 (59.135)	
Epoch: [13][155/391]	LR: 0.001	DT: 0.019 (0.024)	BT: 0.057 (0.062)	Loss 1.4902 (1.5508)	Prec@1 62.500 (59.059)	
Epoch: [13][233/391]	LR: 0.001	DT: 0.015 (0.023)	BT: 0.057 (0.060)	Loss 1.8291 (1.5547)	Prec@1 53.125 (59.118)	
Epoch: [13][311/391]	LR: 0.001	DT: 0.030 (0.023)	BT: 0.064 (0.060)	Loss 1.6436 (1.5586)	Prec@1 53.906 (58.937)	
Epoch: [13][389/391]	LR: 0.001	DT: 0.046 (0.023)	BT: 0.076 (0.059)	Loss 1.5137 (1.5599)	Prec@1 60.156 (58.900)	
Total train loss: 1.5602
Avg Loading time: 0.0232 seconds
Avg Batch time: 0.0591 seconds

Train time: 23.225406408309937
 * Prec@1 59.580 Prec@5 87.380 Loss 1.5371
Avg Loading time: 0.0472 seconds
Avg Batch time: 0.0638 seconds

Best acc: 59.580
--------------------------------------------------------------------------------
Test time: 9.49944019317627

Epoch: [14][77/391]	LR: 0.001	DT: 0.025 (0.048)	BT: 0.058 (0.086)	Loss 1.4756 (1.5503)	Prec@1 60.938 (59.215)	
Epoch: [14][155/391]	LR: 0.001	DT: 0.027 (0.034)	BT: 0.058 (0.071)	Loss 1.4668 (1.5483)	Prec@1 64.062 (59.405)	
Epoch: [14][233/391]	LR: 0.001	DT: 0.015 (0.030)	BT: 0.049 (0.066)	Loss 1.5107 (1.5438)	Prec@1 57.812 (59.615)	
Epoch: [14][311/391]	LR: 0.001	DT: 0.027 (0.027)	BT: 0.061 (0.064)	Loss 1.6436 (1.5504)	Prec@1 59.375 (59.403)	
Epoch: [14][389/391]	LR: 0.001	DT: 0.052 (0.026)	BT: 0.082 (0.062)	Loss 1.4775 (1.5560)	Prec@1 53.906 (59.235)	
Total train loss: 1.5561
Avg Loading time: 0.0256 seconds
Avg Batch time: 0.0621 seconds

Train time: 24.41281771659851
 * Prec@1 59.590 Prec@5 87.310 Loss 1.5312
Avg Loading time: 0.0493 seconds
Avg Batch time: 0.0639 seconds

Best acc: 59.590
--------------------------------------------------------------------------------
Test time: 12.489482164382935

Epoch: [15][77/391]	LR: 0.001	DT: 0.029 (0.034)	BT: 0.060 (0.071)	Loss 1.4697 (1.5490)	Prec@1 60.156 (59.125)	
Epoch: [15][155/391]	LR: 0.001	DT: 0.030 (0.027)	BT: 0.061 (0.063)	Loss 1.6338 (1.5588)	Prec@1 57.031 (58.814)	
Epoch: [15][233/391]	LR: 0.001	DT: 0.021 (0.025)	BT: 0.072 (0.061)	Loss 1.5166 (1.5531)	Prec@1 61.719 (58.968)	
Epoch: [15][311/391]	LR: 0.001	DT: 0.016 (0.024)	BT: 0.052 (0.059)	Loss 1.7188 (1.5543)	Prec@1 57.031 (59.107)	
Epoch: [15][389/391]	LR: 0.001	DT: 0.049 (0.023)	BT: 0.090 (0.059)	Loss 1.7568 (1.5558)	Prec@1 53.125 (59.137)	
Total train loss: 1.5560
Avg Loading time: 0.0231 seconds
Avg Batch time: 0.0586 seconds

Train time: 23.069563627243042
 * Prec@1 59.580 Prec@5 87.370 Loss 1.5342
Avg Loading time: 0.0460 seconds
Avg Batch time: 0.0621 seconds

Best acc: 59.590
--------------------------------------------------------------------------------
Test time: 8.664746522903442

Epoch: [16][77/391]	LR: 0.001	DT: 0.019 (0.029)	BT: 0.050 (0.065)	Loss 1.4971 (1.5651)	Prec@1 60.156 (59.115)	
Epoch: [16][155/391]	LR: 0.001	DT: 0.032 (0.025)	BT: 0.069 (0.060)	Loss 1.5068 (1.5545)	Prec@1 60.938 (59.295)	
Epoch: [16][233/391]	LR: 0.001	DT: 0.018 (0.022)	BT: 0.054 (0.058)	Loss 1.4209 (1.5586)	Prec@1 57.031 (59.268)	
Epoch: [16][311/391]	LR: 0.001	DT: 0.018 (0.022)	BT: 0.050 (0.058)	Loss 1.6006 (1.5552)	Prec@1 56.250 (59.405)	
Epoch: [16][389/391]	LR: 0.001	DT: 0.040 (0.021)	BT: 0.073 (0.057)	Loss 1.6631 (1.5564)	Prec@1 53.125 (59.237)	
Total train loss: 1.5564
Avg Loading time: 0.0213 seconds
Avg Batch time: 0.0568 seconds

Train time: 22.32042360305786
 * Prec@1 59.520 Prec@5 87.510 Loss 1.5303
Avg Loading time: 0.0444 seconds
Avg Batch time: 0.0630 seconds

Best acc: 59.590
--------------------------------------------------------------------------------
Test time: 7.228820323944092

Epoch: [17][77/391]	LR: 0.001	DT: 0.015 (0.031)	BT: 0.046 (0.068)	Loss 1.5156 (1.5449)	Prec@1 58.594 (59.265)	
Epoch: [17][155/391]	LR: 0.001	DT: 0.025 (0.027)	BT: 0.062 (0.063)	Loss 1.5889 (1.5445)	Prec@1 60.156 (59.335)	
Epoch: [17][233/391]	LR: 0.001	DT: 0.061 (0.025)	BT: 0.110 (0.060)	Loss 1.6611 (1.5574)	Prec@1 61.719 (59.034)	
Epoch: [17][311/391]	LR: 0.001	DT: 0.014 (0.024)	BT: 0.047 (0.059)	Loss 1.4922 (1.5532)	Prec@1 61.719 (59.170)	
Epoch: [17][389/391]	LR: 0.001	DT: 0.056 (0.023)	BT: 0.089 (0.058)	Loss 1.4551 (1.5545)	Prec@1 59.375 (59.139)	
Total train loss: 1.5543
Avg Loading time: 0.0225 seconds
Avg Batch time: 0.0581 seconds

Train time: 22.852047204971313
 * Prec@1 59.500 Prec@5 87.310 Loss 1.5352
Avg Loading time: 0.0446 seconds
Avg Batch time: 0.0611 seconds

Best acc: 59.590
--------------------------------------------------------------------------------
Test time: 9.741043090820312

Epoch: [18][77/391]	LR: 0.001	DT: 0.023 (0.024)	BT: 0.054 (0.064)	Loss 1.5332 (1.5487)	Prec@1 63.281 (59.465)	
Epoch: [18][155/391]	LR: 0.001	DT: 0.028 (0.021)	BT: 0.062 (0.060)	Loss 1.5625 (1.5492)	Prec@1 57.031 (59.545)	
Epoch: [18][233/391]	LR: 0.001	DT: 0.024 (0.020)	BT: 0.059 (0.058)	Loss 1.7363 (1.5576)	Prec@1 53.906 (59.065)	
Epoch: [18][311/391]	LR: 0.001	DT: 0.020 (0.021)	BT: 0.051 (0.057)	Loss 1.4961 (1.5540)	Prec@1 60.156 (59.077)	
Epoch: [18][389/391]	LR: 0.001	DT: 0.055 (0.020)	BT: 0.094 (0.057)	Loss 1.6084 (1.5541)	Prec@1 53.906 (59.227)	
Total train loss: 1.5540
Avg Loading time: 0.0201 seconds
Avg Batch time: 0.0568 seconds

Train time: 22.31853151321411
 * Prec@1 59.440 Prec@5 87.530 Loss 1.5342
Avg Loading time: 0.0473 seconds
Avg Batch time: 0.0628 seconds

Best acc: 59.590
--------------------------------------------------------------------------------
Test time: 8.46968388557434

Epoch: [19][77/391]	LR: 0.001	DT: 0.000 (0.164)	BT: 0.030 (0.200)	Loss 1.6641 (1.5447)	Prec@1 57.031 (60.036)	
Epoch: [19][155/391]	LR: 0.001	DT: 0.000 (0.162)	BT: 0.033 (0.197)	Loss 1.6982 (1.5584)	Prec@1 57.031 (59.505)	
Epoch: [19][233/391]	LR: 0.001	DT: 0.261 (0.207)	BT: 0.304 (0.244)	Loss 1.4951 (1.5487)	Prec@1 64.062 (59.652)	
Epoch: [19][311/391]	LR: 0.001	DT: 0.000 (0.218)	BT: 0.033 (0.255)	Loss 1.5078 (1.5464)	Prec@1 59.375 (59.693)	
Epoch: [19][389/391]	LR: 0.001	DT: 0.000 (0.227)	BT: 0.030 (0.264)	Loss 1.6582 (1.5523)	Prec@1 60.938 (59.443)	
Total train loss: 1.5522
Avg Loading time: 0.2263 seconds
Avg Batch time: 0.2637 seconds

Train time: 103.24737524986267
 * Prec@1 59.530 Prec@5 87.410 Loss 1.5312
Avg Loading time: 0.3725 seconds
Avg Batch time: 0.3905 seconds

Best acc: 59.590
--------------------------------------------------------------------------------
Test time: 38.71130084991455

Epoch: [20][77/391]	LR: 0.0002	DT: 0.000 (0.405)	BT: 0.034 (0.445)	Loss 1.4854 (1.5452)	Prec@1 59.375 (59.515)	
Epoch: [20][155/391]	LR: 0.0002	DT: 0.000 (0.400)	BT: 0.039 (0.439)	Loss 1.4805 (1.5514)	Prec@1 60.156 (59.345)	
Epoch: [20][233/391]	LR: 0.0002	DT: 0.000 (0.387)	BT: 0.050 (0.427)	Loss 1.5771 (1.5540)	Prec@1 58.594 (59.275)	
Epoch: [20][311/391]	LR: 0.0002	DT: 0.000 (0.371)	BT: 0.035 (0.411)	Loss 1.5879 (1.5541)	Prec@1 63.281 (59.365)	
Epoch: [20][389/391]	LR: 0.0002	DT: 0.000 (0.372)	BT: 0.036 (0.412)	Loss 1.6943 (1.5522)	Prec@1 56.250 (59.379)	
Total train loss: 1.5522
Avg Loading time: 0.3709 seconds
Avg Batch time: 0.4110 seconds

Train time: 160.79528284072876
 * Prec@1 59.360 Prec@5 87.310 Loss 1.5273
Avg Loading time: 0.4386 seconds
Avg Batch time: 0.4552 seconds

Best acc: 59.590
--------------------------------------------------------------------------------
Test time: 42.996827363967896

Epoch: [21][77/391]	LR: 0.0002	DT: 0.057 (0.420)	BT: 0.094 (0.463)	Loss 1.4326 (1.5465)	Prec@1 62.500 (59.285)	
Epoch: [21][155/391]	LR: 0.0002	DT: 0.000 (0.384)	BT: 0.039 (0.426)	Loss 1.4961 (1.5557)	Prec@1 61.719 (59.105)	
Epoch: [21][233/391]	LR: 0.0002	DT: 0.069 (0.383)	BT: 0.117 (0.426)	Loss 1.5977 (1.5496)	Prec@1 55.469 (59.178)	
Epoch: [21][311/391]	LR: 0.0002	DT: 0.000 (0.317)	BT: 0.055 (0.359)	Loss 1.7080 (1.5465)	Prec@1 62.500 (59.295)	
Epoch: [21][389/391]	LR: 0.0002	DT: 0.000 (0.261)	BT: 0.030 (0.303)	Loss 1.5059 (1.5472)	Prec@1 57.031 (59.223)	
Total train loss: 1.5478
Avg Loading time: 0.2606 seconds
Avg Batch time: 0.3020 seconds

Train time: 118.20129632949829
 * Prec@1 59.700 Prec@5 87.400 Loss 1.5293
Avg Loading time: 0.0499 seconds
Avg Batch time: 0.0664 seconds

Best acc: 59.700
--------------------------------------------------------------------------------
Test time: 13.275874614715576

Epoch: [22][77/391]	LR: 0.0002	DT: 0.000 (0.028)	BT: 0.046 (0.067)	Loss 1.4834 (1.5341)	Prec@1 61.719 (59.736)	
Epoch: [22][155/391]	LR: 0.0002	DT: 0.024 (0.021)	BT: 0.059 (0.060)	Loss 1.4658 (1.5391)	Prec@1 60.156 (59.891)	
Epoch: [22][233/391]	LR: 0.0002	DT: 0.027 (0.021)	BT: 0.058 (0.059)	Loss 1.4961 (1.5429)	Prec@1 60.938 (59.639)	
Epoch: [22][311/391]	LR: 0.0002	DT: 0.018 (0.021)	BT: 0.051 (0.058)	Loss 1.4658 (1.5441)	Prec@1 58.594 (59.588)	
Epoch: [22][389/391]	LR: 0.0002	DT: 0.043 (0.021)	BT: 0.073 (0.057)	Loss 1.6777 (1.5520)	Prec@1 52.344 (59.399)	
Total train loss: 1.5520
Avg Loading time: 0.0205 seconds
Avg Batch time: 0.0572 seconds

Train time: 22.493417978286743
 * Prec@1 59.530 Prec@5 87.360 Loss 1.5381
Avg Loading time: 0.0451 seconds
Avg Batch time: 0.0609 seconds

Best acc: 59.700
--------------------------------------------------------------------------------
Test time: 5.4972240924835205

Epoch: [23][77/391]	LR: 0.0002	DT: 0.023 (0.029)	BT: 0.061 (0.067)	Loss 1.6826 (1.5551)	Prec@1 55.469 (59.345)	
Epoch: [23][155/391]	LR: 0.0002	DT: 0.029 (0.026)	BT: 0.061 (0.062)	Loss 1.6543 (1.5512)	Prec@1 54.688 (59.385)	
Epoch: [23][233/391]	LR: 0.0002	DT: 0.024 (0.025)	BT: 0.077 (0.060)	Loss 1.5361 (1.5468)	Prec@1 60.156 (59.335)	
Epoch: [23][311/391]	LR: 0.0002	DT: 0.031 (0.024)	BT: 0.062 (0.059)	Loss 1.3311 (1.5498)	Prec@1 65.625 (59.395)	
Epoch: [23][389/391]	LR: 0.0002	DT: 0.023 (0.023)	BT: 0.061 (0.059)	Loss 1.3721 (1.5505)	Prec@1 67.969 (59.321)	
Total train loss: 1.5502
Avg Loading time: 0.0234 seconds
Avg Batch time: 0.0585 seconds

Train time: 22.972183227539062
 * Prec@1 59.200 Prec@5 87.260 Loss 1.5303
Avg Loading time: 0.0490 seconds
Avg Batch time: 0.0635 seconds

Best acc: 59.700
--------------------------------------------------------------------------------
Test time: 5.764074087142944

Epoch: [24][77/391]	LR: 0.0002	DT: 0.019 (0.025)	BT: 0.051 (0.064)	Loss 1.5146 (1.5689)	Prec@1 57.812 (59.034)	
Epoch: [24][155/391]	LR: 0.0002	DT: 0.028 (0.021)	BT: 0.059 (0.059)	Loss 1.5410 (1.5554)	Prec@1 58.594 (59.165)	
Epoch: [24][233/391]	LR: 0.0002	DT: 0.019 (0.021)	BT: 0.050 (0.058)	Loss 1.8027 (1.5563)	Prec@1 49.219 (59.171)	
Epoch: [24][311/391]	LR: 0.0002	DT: 0.020 (0.020)	BT: 0.052 (0.057)	Loss 1.4336 (1.5517)	Prec@1 64.844 (59.292)	
Epoch: [24][389/391]	LR: 0.0002	DT: 0.044 (0.020)	BT: 0.082 (0.056)	Loss 1.5928 (1.5516)	Prec@1 53.906 (59.209)	
Total train loss: 1.5513
Avg Loading time: 0.0204 seconds
Avg Batch time: 0.0561 seconds

Train time: 22.0370934009552
 * Prec@1 59.770 Prec@5 87.460 Loss 1.5342
Avg Loading time: 0.0475 seconds
Avg Batch time: 0.0627 seconds

Best acc: 59.770
--------------------------------------------------------------------------------
Test time: 6.046009302139282

Epoch: [25][77/391]	LR: 0.0002	DT: 0.018 (0.023)	BT: 0.053 (0.065)	Loss 1.6318 (1.5610)	Prec@1 57.031 (59.235)	
Epoch: [25][155/391]	LR: 0.0002	DT: 0.000 (0.021)	BT: 0.042 (0.060)	Loss 1.2588 (1.5507)	Prec@1 69.531 (59.500)	
Epoch: [25][233/391]	LR: 0.0002	DT: 0.027 (0.021)	BT: 0.060 (0.058)	Loss 1.7715 (1.5578)	Prec@1 52.344 (59.251)	
Epoch: [25][311/391]	LR: 0.0002	DT: 0.031 (0.021)	BT: 0.062 (0.057)	Loss 1.3760 (1.5564)	Prec@1 64.062 (59.150)	
Epoch: [25][389/391]	LR: 0.0002	DT: 0.041 (0.021)	BT: 0.080 (0.057)	Loss 1.7197 (1.5515)	Prec@1 54.688 (59.371)	
Total train loss: 1.5518
Avg Loading time: 0.0206 seconds
Avg Batch time: 0.0568 seconds

Train time: 22.351006746292114
 * Prec@1 59.530 Prec@5 87.470 Loss 1.5342
Avg Loading time: 0.0465 seconds
Avg Batch time: 0.0617 seconds

Best acc: 59.770
--------------------------------------------------------------------------------
Test time: 5.483518362045288

Epoch: [26][77/391]	LR: 0.0002	DT: 0.000 (0.022)	BT: 0.032 (0.063)	Loss 1.7393 (1.5503)	Prec@1 53.125 (59.165)	
Epoch: [26][155/391]	LR: 0.0002	DT: 0.021 (0.021)	BT: 0.055 (0.059)	Loss 1.4502 (1.5345)	Prec@1 60.938 (59.590)	
Epoch: [26][233/391]	LR: 0.0002	DT: 0.023 (0.020)	BT: 0.054 (0.058)	Loss 1.5625 (1.5448)	Prec@1 60.938 (59.565)	
Epoch: [26][311/391]	LR: 0.0002	DT: 0.033 (0.021)	BT: 0.068 (0.057)	Loss 1.5547 (1.5485)	Prec@1 58.594 (59.503)	
Epoch: [26][389/391]	LR: 0.0002	DT: 0.013 (0.021)	BT: 0.044 (0.057)	Loss 1.6729 (1.5505)	Prec@1 52.344 (59.299)	
Total train loss: 1.5506
Avg Loading time: 0.0210 seconds
Avg Batch time: 0.0568 seconds

Train time: 22.303884744644165
 * Prec@1 59.560 Prec@5 87.380 Loss 1.5332
Avg Loading time: 0.0497 seconds
Avg Batch time: 0.0642 seconds

Best acc: 59.770
--------------------------------------------------------------------------------
Test time: 6.196835994720459

Epoch: [27][77/391]	LR: 0.0002	DT: 0.016 (0.025)	BT: 0.050 (0.062)	Loss 1.6006 (1.5741)	Prec@1 61.719 (58.844)	
Epoch: [27][155/391]	LR: 0.0002	DT: 0.016 (0.022)	BT: 0.049 (0.059)	Loss 1.5967 (1.5595)	Prec@1 60.156 (59.225)	
Epoch: [27][233/391]	LR: 0.0002	DT: 0.030 (0.022)	BT: 0.064 (0.058)	Loss 1.6123 (1.5529)	Prec@1 57.031 (59.255)	
Epoch: [27][311/391]	LR: 0.0002	DT: 0.000 (0.021)	BT: 0.046 (0.057)	Loss 1.4707 (1.5507)	Prec@1 64.844 (59.362)	
Epoch: [27][389/391]	LR: 0.0002	DT: 0.045 (0.021)	BT: 0.077 (0.056)	Loss 1.4131 (1.5494)	Prec@1 67.969 (59.417)	
Total train loss: 1.5494
Avg Loading time: 0.0206 seconds
Avg Batch time: 0.0564 seconds

Train time: 22.148633003234863
 * Prec@1 59.620 Prec@5 87.540 Loss 1.5283
Avg Loading time: 0.0481 seconds
Avg Batch time: 0.0629 seconds

Best acc: 59.770
--------------------------------------------------------------------------------
Test time: 6.6450417041778564

Epoch: [28][77/391]	LR: 0.0002	DT: 0.016 (0.022)	BT: 0.050 (0.066)	Loss 1.5684 (1.5706)	Prec@1 55.469 (59.034)	
Epoch: [28][155/391]	LR: 0.0002	DT: 0.028 (0.024)	BT: 0.062 (0.062)	Loss 1.4727 (1.5710)	Prec@1 57.031 (58.559)	
Epoch: [28][233/391]	LR: 0.0002	DT: 0.034 (0.022)	BT: 0.066 (0.060)	Loss 1.4082 (1.5563)	Prec@1 60.938 (59.148)	
Epoch: [28][311/391]	LR: 0.0002	DT: 0.021 (0.022)	BT: 0.057 (0.059)	Loss 1.5371 (1.5540)	Prec@1 60.938 (59.230)	
Epoch: [28][389/391]	LR: 0.0002	DT: 0.048 (0.021)	BT: 0.078 (0.058)	Loss 1.3857 (1.5508)	Prec@1 60.156 (59.319)	
Total train loss: 1.5508
Avg Loading time: 0.0209 seconds
Avg Batch time: 0.0579 seconds

Train time: 22.745487928390503
 * Prec@1 59.490 Prec@5 87.470 Loss 1.5352
Avg Loading time: 0.0469 seconds
Avg Batch time: 0.0623 seconds

Best acc: 59.770
--------------------------------------------------------------------------------
Test time: 5.56877064704895

Epoch: [29][77/391]	LR: 0.0002	DT: 0.020 (0.026)	BT: 0.055 (0.065)	Loss 1.5264 (1.5471)	Prec@1 60.938 (59.946)	
Epoch: [29][155/391]	LR: 0.0002	DT: 0.025 (0.023)	BT: 0.057 (0.060)	Loss 1.5693 (1.5566)	Prec@1 60.156 (59.350)	
Epoch: [29][233/391]	LR: 0.0002	DT: 0.013 (0.022)	BT: 0.058 (0.058)	Loss 1.7373 (1.5564)	Prec@1 58.594 (59.475)	
Epoch: [29][311/391]	LR: 0.0002	DT: 0.032 (0.022)	BT: 0.069 (0.058)	Loss 1.4668 (1.5542)	Prec@1 57.031 (59.378)	
Epoch: [29][389/391]	LR: 0.0002	DT: 0.000 (0.022)	BT: 0.030 (0.057)	Loss 1.5957 (1.5517)	Prec@1 54.688 (59.393)	
Total train loss: 1.5517
Avg Loading time: 0.0218 seconds
Avg Batch time: 0.0571 seconds

Train time: 22.43225407600403
 * Prec@1 59.630 Prec@5 87.370 Loss 1.5254
Avg Loading time: 0.0487 seconds
Avg Batch time: 0.0642 seconds

Best acc: 59.770
--------------------------------------------------------------------------------
Test time: 5.761455059051514

Epoch: [30][77/391]	LR: 4e-05	DT: 0.000 (0.025)	BT: 0.059 (0.065)	Loss 1.6787 (1.5284)	Prec@1 59.375 (59.926)	
Epoch: [30][155/391]	LR: 4e-05	DT: 0.027 (0.024)	BT: 0.061 (0.061)	Loss 1.4502 (1.5394)	Prec@1 62.500 (59.680)	
Epoch: [30][233/391]	LR: 4e-05	DT: 0.018 (0.023)	BT: 0.049 (0.059)	Loss 1.5996 (1.5438)	Prec@1 57.812 (59.652)	
Epoch: [30][311/391]	LR: 4e-05	DT: 0.020 (0.022)	BT: 0.057 (0.058)	Loss 1.6943 (1.5521)	Prec@1 56.250 (59.438)	
Epoch: [30][389/391]	LR: 4e-05	DT: 0.044 (0.021)	BT: 0.082 (0.057)	Loss 1.6074 (1.5514)	Prec@1 60.156 (59.389)	
Total train loss: 1.5514
Avg Loading time: 0.0207 seconds
Avg Batch time: 0.0569 seconds

Train time: 22.358785390853882
 * Prec@1 59.380 Prec@5 87.160 Loss 1.5303
Avg Loading time: 0.0512 seconds
Avg Batch time: 0.0661 seconds

Best acc: 59.770
--------------------------------------------------------------------------------
Test time: 6.143140077590942

Epoch: [31][77/391]	LR: 4e-05	DT: 0.034 (0.025)	BT: 0.065 (0.067)	Loss 1.5273 (1.5467)	Prec@1 63.281 (59.445)	
Epoch: [31][155/391]	LR: 4e-05	DT: 0.020 (0.024)	BT: 0.057 (0.062)	Loss 1.6016 (1.5408)	Prec@1 56.250 (59.856)	
Epoch: [31][233/391]	LR: 4e-05	DT: 0.024 (0.024)	BT: 0.054 (0.061)	Loss 1.4678 (1.5566)	Prec@1 63.281 (59.175)	
Epoch: [31][311/391]	LR: 4e-05	DT: 0.014 (0.023)	BT: 0.045 (0.060)	Loss 1.8525 (1.5509)	Prec@1 50.781 (59.295)	
Epoch: [31][389/391]	LR: 4e-05	DT: 0.044 (0.023)	BT: 0.076 (0.059)	Loss 1.6562 (1.5505)	Prec@1 50.000 (59.311)	
Total train loss: 1.5508
Avg Loading time: 0.0230 seconds
Avg Batch time: 0.0590 seconds

Train time: 23.209399223327637
 * Prec@1 59.660 Prec@5 87.670 Loss 1.5322
Avg Loading time: 0.0452 seconds
Avg Batch time: 0.0614 seconds

Best acc: 59.770
--------------------------------------------------------------------------------
Test time: 10.980544090270996

Epoch: [32][77/391]	LR: 4e-05	DT: 0.027 (0.026)	BT: 0.061 (0.064)	Loss 1.6729 (1.5511)	Prec@1 56.250 (59.936)	
Epoch: [32][155/391]	LR: 4e-05	DT: 0.000 (0.023)	BT: 0.030 (0.059)	Loss 1.4492 (1.5500)	Prec@1 64.062 (59.796)	
Epoch: [32][233/391]	LR: 4e-05	DT: 0.017 (0.022)	BT: 0.048 (0.058)	Loss 1.6221 (1.5499)	Prec@1 54.688 (59.749)	
Epoch: [32][311/391]	LR: 4e-05	DT: 0.019 (0.022)	BT: 0.050 (0.057)	Loss 1.4209 (1.5500)	Prec@1 60.156 (59.533)	
Epoch: [32][389/391]	LR: 4e-05	DT: 0.045 (0.022)	BT: 0.078 (0.057)	Loss 1.7207 (1.5484)	Prec@1 57.031 (59.507)	
Total train loss: 1.5483
Avg Loading time: 0.0217 seconds
Avg Batch time: 0.0568 seconds

Train time: 22.317718982696533
 * Prec@1 59.930 Prec@5 87.630 Loss 1.5283
Avg Loading time: 0.0487 seconds
Avg Batch time: 0.0652 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 12.726659774780273

Epoch: [33][77/391]	LR: 4e-05	DT: 0.022 (0.049)	BT: 0.056 (0.085)	Loss 1.6846 (1.5344)	Prec@1 53.125 (59.706)	
Epoch: [33][155/391]	LR: 4e-05	DT: 0.039 (0.035)	BT: 0.073 (0.071)	Loss 1.4971 (1.5495)	Prec@1 64.062 (58.914)	
Epoch: [33][233/391]	LR: 4e-05	DT: 0.016 (0.030)	BT: 0.050 (0.066)	Loss 1.5527 (1.5458)	Prec@1 60.156 (59.075)	
Epoch: [33][311/391]	LR: 4e-05	DT: 0.016 (0.027)	BT: 0.047 (0.063)	Loss 1.5596 (1.5511)	Prec@1 60.938 (59.155)	
Epoch: [33][389/391]	LR: 4e-05	DT: 0.000 (0.026)	BT: 0.034 (0.061)	Loss 1.5107 (1.5506)	Prec@1 60.938 (59.177)	
Total train loss: 1.5510
Avg Loading time: 0.0257 seconds
Avg Batch time: 0.0611 seconds

Train time: 24.00671362876892
 * Prec@1 59.500 Prec@5 87.170 Loss 1.5273
Avg Loading time: 0.0483 seconds
Avg Batch time: 0.0629 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 5.764931917190552

Epoch: [34][77/391]	LR: 4e-05	DT: 0.021 (0.027)	BT: 0.052 (0.065)	Loss 1.6396 (1.5439)	Prec@1 62.500 (59.555)	
Epoch: [34][155/391]	LR: 4e-05	DT: 0.032 (0.022)	BT: 0.066 (0.060)	Loss 1.5430 (1.5462)	Prec@1 59.375 (59.340)	
Epoch: [34][233/391]	LR: 4e-05	DT: 0.020 (0.022)	BT: 0.054 (0.059)	Loss 1.6201 (1.5478)	Prec@1 52.344 (59.395)	
Epoch: [34][311/391]	LR: 4e-05	DT: 0.021 (0.021)	BT: 0.053 (0.058)	Loss 1.6670 (1.5519)	Prec@1 58.594 (59.242)	
Epoch: [34][389/391]	LR: 4e-05	DT: 0.040 (0.021)	BT: 0.071 (0.057)	Loss 1.6924 (1.5494)	Prec@1 51.562 (59.349)	
Total train loss: 1.5495
Avg Loading time: 0.0206 seconds
Avg Batch time: 0.0568 seconds

Train time: 22.289173126220703
 * Prec@1 59.520 Prec@5 87.400 Loss 1.5273
Avg Loading time: 0.0497 seconds
Avg Batch time: 0.0647 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 6.273846387863159

Epoch: [35][77/391]	LR: 4e-05	DT: 0.022 (0.023)	BT: 0.056 (0.064)	Loss 1.4238 (1.5346)	Prec@1 67.188 (59.836)	
Epoch: [35][155/391]	LR: 4e-05	DT: 0.016 (0.021)	BT: 0.050 (0.059)	Loss 1.4404 (1.5455)	Prec@1 61.719 (59.315)	
Epoch: [35][233/391]	LR: 4e-05	DT: 0.020 (0.020)	BT: 0.060 (0.058)	Loss 1.3867 (1.5394)	Prec@1 68.750 (59.585)	
Epoch: [35][311/391]	LR: 4e-05	DT: 0.034 (0.020)	BT: 0.065 (0.057)	Loss 1.7207 (1.5421)	Prec@1 53.125 (59.480)	
Epoch: [35][389/391]	LR: 4e-05	DT: 0.019 (0.020)	BT: 0.051 (0.057)	Loss 1.7109 (1.5474)	Prec@1 54.688 (59.353)	
Total train loss: 1.5479
Avg Loading time: 0.0196 seconds
Avg Batch time: 0.0566 seconds

Train time: 22.222830057144165
 * Prec@1 59.350 Prec@5 87.570 Loss 1.5293
Avg Loading time: 0.0510 seconds
Avg Batch time: 0.0654 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 12.816249370574951

Epoch: [36][77/391]	LR: 4e-05	DT: 0.017 (0.025)	BT: 0.048 (0.065)	Loss 1.4971 (1.5555)	Prec@1 64.062 (59.034)	
Epoch: [36][155/391]	LR: 4e-05	DT: 0.022 (0.023)	BT: 0.058 (0.061)	Loss 1.3555 (1.5557)	Prec@1 63.281 (59.135)	
Epoch: [36][233/391]	LR: 4e-05	DT: 0.022 (0.022)	BT: 0.053 (0.058)	Loss 1.3203 (1.5547)	Prec@1 62.500 (59.018)	
Epoch: [36][311/391]	LR: 4e-05	DT: 0.017 (0.021)	BT: 0.050 (0.057)	Loss 1.4893 (1.5472)	Prec@1 61.719 (59.252)	
Epoch: [36][389/391]	LR: 4e-05	DT: 0.023 (0.021)	BT: 0.053 (0.057)	Loss 1.6748 (1.5485)	Prec@1 56.250 (59.271)	
Total train loss: 1.5488
Avg Loading time: 0.0206 seconds
Avg Batch time: 0.0571 seconds

Train time: 22.485011339187622
 * Prec@1 59.670 Prec@5 87.420 Loss 1.5322
Avg Loading time: 0.0447 seconds
Avg Batch time: 0.0610 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 12.811411142349243

Epoch: [37][77/391]	LR: 4e-05	DT: 0.027 (0.025)	BT: 0.061 (0.063)	Loss 1.4746 (1.5636)	Prec@1 61.719 (58.954)	
Epoch: [37][155/391]	LR: 4e-05	DT: 0.025 (0.024)	BT: 0.063 (0.061)	Loss 1.6045 (1.5531)	Prec@1 61.719 (59.410)	
Epoch: [37][233/391]	LR: 4e-05	DT: 0.027 (0.023)	BT: 0.062 (0.060)	Loss 1.6963 (1.5508)	Prec@1 51.562 (59.358)	
Epoch: [37][311/391]	LR: 4e-05	DT: 0.028 (0.023)	BT: 0.059 (0.059)	Loss 1.6533 (1.5514)	Prec@1 61.719 (59.325)	
Epoch: [37][389/391]	LR: 4e-05	DT: 0.048 (0.023)	BT: 0.080 (0.058)	Loss 1.7734 (1.5500)	Prec@1 47.656 (59.279)	
Total train loss: 1.5498
Avg Loading time: 0.0227 seconds
Avg Batch time: 0.0583 seconds

Train time: 22.92227268218994
 * Prec@1 59.350 Prec@5 87.340 Loss 1.5303
Avg Loading time: 0.0552 seconds
Avg Batch time: 0.0731 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 12.782942771911621

Epoch: [38][77/391]	LR: 4e-05	DT: 0.031 (0.025)	BT: 0.084 (0.065)	Loss 1.5674 (1.5714)	Prec@1 56.250 (58.353)	
Epoch: [38][155/391]	LR: 4e-05	DT: 0.014 (0.021)	BT: 0.048 (0.060)	Loss 1.5859 (1.5655)	Prec@1 53.125 (58.794)	
Epoch: [38][233/391]	LR: 4e-05	DT: 0.018 (0.021)	BT: 0.050 (0.058)	Loss 1.3467 (1.5572)	Prec@1 65.625 (58.994)	
Epoch: [38][311/391]	LR: 4e-05	DT: 0.018 (0.020)	BT: 0.052 (0.057)	Loss 1.5234 (1.5574)	Prec@1 59.375 (58.999)	
Epoch: [38][389/391]	LR: 4e-05	DT: 0.019 (0.020)	BT: 0.051 (0.056)	Loss 1.5674 (1.5529)	Prec@1 64.062 (59.267)	
Total train loss: 1.5526
Avg Loading time: 0.0203 seconds
Avg Batch time: 0.0563 seconds

Train time: 22.100744247436523
 * Prec@1 59.650 Prec@5 87.460 Loss 1.5283
Avg Loading time: 0.0481 seconds
Avg Batch time: 0.0636 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 8.016520977020264

Epoch: [39][77/391]	LR: 4e-05	DT: 0.000 (0.025)	BT: 0.032 (0.064)	Loss 1.4805 (1.5556)	Prec@1 61.719 (58.804)	
Epoch: [39][155/391]	LR: 4e-05	DT: 0.027 (0.023)	BT: 0.058 (0.061)	Loss 1.6006 (1.5522)	Prec@1 59.375 (59.009)	
Epoch: [39][233/391]	LR: 4e-05	DT: 0.027 (0.023)	BT: 0.058 (0.059)	Loss 1.6377 (1.5477)	Prec@1 60.938 (59.328)	
Epoch: [39][311/391]	LR: 4e-05	DT: 0.019 (0.023)	BT: 0.051 (0.058)	Loss 1.7021 (1.5494)	Prec@1 58.594 (59.290)	
Epoch: [39][389/391]	LR: 4e-05	DT: 0.042 (0.023)	BT: 0.072 (0.058)	Loss 1.5898 (1.5513)	Prec@1 59.375 (59.167)	
Total train loss: 1.5517
Avg Loading time: 0.0227 seconds
Avg Batch time: 0.0580 seconds

Train time: 22.83307194709778
 * Prec@1 59.660 Prec@5 87.350 Loss 1.5303
Avg Loading time: 0.0507 seconds
Avg Batch time: 0.0671 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 6.4700727462768555

Epoch: [40][77/391]	LR: 8.000000000000001e-06	DT: 0.015 (0.025)	BT: 0.046 (0.065)	Loss 1.3613 (1.5634)	Prec@1 64.062 (58.764)	
Epoch: [40][155/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.021)	BT: 0.032 (0.059)	Loss 1.6699 (1.5492)	Prec@1 60.156 (59.155)	
Epoch: [40][233/391]	LR: 8.000000000000001e-06	DT: 0.015 (0.019)	BT: 0.047 (0.057)	Loss 1.6094 (1.5546)	Prec@1 59.375 (58.954)	
Epoch: [40][311/391]	LR: 8.000000000000001e-06	DT: 0.028 (0.018)	BT: 0.065 (0.056)	Loss 1.3682 (1.5517)	Prec@1 66.406 (59.082)	
Epoch: [40][389/391]	LR: 8.000000000000001e-06	DT: 0.038 (0.018)	BT: 0.068 (0.055)	Loss 1.5479 (1.5532)	Prec@1 57.812 (59.097)	
Total train loss: 1.5532
Avg Loading time: 0.0180 seconds
Avg Batch time: 0.0550 seconds

Train time: 21.641403675079346
 * Prec@1 59.420 Prec@5 87.370 Loss 1.5303
Avg Loading time: 0.0472 seconds
Avg Batch time: 0.0620 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 12.561823844909668

Epoch: [41][77/391]	LR: 8.000000000000001e-06	DT: 0.024 (0.027)	BT: 0.056 (0.066)	Loss 1.4961 (1.5500)	Prec@1 58.594 (59.615)	
Epoch: [41][155/391]	LR: 8.000000000000001e-06	DT: 0.030 (0.024)	BT: 0.061 (0.061)	Loss 1.7490 (1.5556)	Prec@1 53.906 (59.430)	
Epoch: [41][233/391]	LR: 8.000000000000001e-06	DT: 0.028 (0.024)	BT: 0.060 (0.060)	Loss 1.5645 (1.5529)	Prec@1 60.938 (59.338)	
Epoch: [41][311/391]	LR: 8.000000000000001e-06	DT: 0.018 (0.024)	BT: 0.051 (0.059)	Loss 1.5371 (1.5529)	Prec@1 57.031 (59.235)	
Epoch: [41][389/391]	LR: 8.000000000000001e-06	DT: 0.062 (0.023)	BT: 0.092 (0.058)	Loss 1.5039 (1.5502)	Prec@1 57.812 (59.409)	
Total train loss: 1.5505
Avg Loading time: 0.0230 seconds
Avg Batch time: 0.0578 seconds

Train time: 22.709273099899292
 * Prec@1 59.440 Prec@5 87.340 Loss 1.5361
Avg Loading time: 0.0498 seconds
Avg Batch time: 0.0645 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 13.323066711425781

Epoch: [42][77/391]	LR: 8.000000000000001e-06	DT: 0.027 (0.022)	BT: 0.058 (0.063)	Loss 1.7568 (1.5552)	Prec@1 56.250 (58.994)	
Epoch: [42][155/391]	LR: 8.000000000000001e-06	DT: 0.022 (0.021)	BT: 0.061 (0.059)	Loss 1.5625 (1.5486)	Prec@1 56.250 (59.255)	
Epoch: [42][233/391]	LR: 8.000000000000001e-06	DT: 0.032 (0.020)	BT: 0.071 (0.058)	Loss 1.4199 (1.5562)	Prec@1 63.281 (59.058)	
Epoch: [42][311/391]	LR: 8.000000000000001e-06	DT: 0.018 (0.020)	BT: 0.051 (0.057)	Loss 1.6191 (1.5558)	Prec@1 54.688 (59.039)	
Epoch: [42][389/391]	LR: 8.000000000000001e-06	DT: 0.050 (0.020)	BT: 0.081 (0.057)	Loss 1.6025 (1.5532)	Prec@1 61.719 (59.131)	
Total train loss: 1.5534
Avg Loading time: 0.0200 seconds
Avg Batch time: 0.0566 seconds

Train time: 22.273264408111572
 * Prec@1 59.520 Prec@5 87.400 Loss 1.5303
Avg Loading time: 0.0466 seconds
Avg Batch time: 0.0617 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 5.931182384490967

Epoch: [43][77/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.021)	BT: 0.046 (0.065)	Loss 1.4990 (1.5424)	Prec@1 62.500 (60.016)	
Epoch: [43][155/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.021)	BT: 0.062 (0.061)	Loss 1.5566 (1.5450)	Prec@1 61.719 (59.485)	
Epoch: [43][233/391]	LR: 8.000000000000001e-06	DT: 0.029 (0.019)	BT: 0.059 (0.059)	Loss 1.3516 (1.5502)	Prec@1 63.281 (59.492)	
Epoch: [43][311/391]	LR: 8.000000000000001e-06	DT: 0.016 (0.019)	BT: 0.047 (0.058)	Loss 1.6006 (1.5537)	Prec@1 54.688 (59.262)	
Epoch: [43][389/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.018)	BT: 0.033 (0.058)	Loss 1.5537 (1.5514)	Prec@1 54.688 (59.343)	
Total train loss: 1.5515
Avg Loading time: 0.0184 seconds
Avg Batch time: 0.0574 seconds

Train time: 22.570372819900513
 * Prec@1 59.450 Prec@5 87.420 Loss 1.5322
Avg Loading time: 0.0481 seconds
Avg Batch time: 0.0655 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 12.263463497161865

Epoch: [44][77/391]	LR: 8.000000000000001e-06	DT: 0.030 (0.029)	BT: 0.062 (0.065)	Loss 1.5020 (1.5516)	Prec@1 66.406 (59.205)	
Epoch: [44][155/391]	LR: 8.000000000000001e-06	DT: 0.021 (0.026)	BT: 0.056 (0.061)	Loss 1.8691 (1.5551)	Prec@1 48.438 (59.165)	
Epoch: [44][233/391]	LR: 8.000000000000001e-06	DT: 0.020 (0.025)	BT: 0.051 (0.059)	Loss 1.7178 (1.5521)	Prec@1 54.688 (59.178)	
Epoch: [44][311/391]	LR: 8.000000000000001e-06	DT: 0.029 (0.024)	BT: 0.060 (0.059)	Loss 1.4443 (1.5489)	Prec@1 61.719 (59.362)	
Epoch: [44][389/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.024)	BT: 0.032 (0.058)	Loss 1.8301 (1.5511)	Prec@1 50.781 (59.293)	
Total train loss: 1.5518
Avg Loading time: 0.0239 seconds
Avg Batch time: 0.0581 seconds

Train time: 22.841725826263428
 * Prec@1 59.350 Prec@5 87.400 Loss 1.5303
Avg Loading time: 0.0462 seconds
Avg Batch time: 0.0612 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 8.39529299736023

Epoch: [45][77/391]	LR: 8.000000000000001e-06	DT: 0.020 (0.029)	BT: 0.052 (0.067)	Loss 1.4033 (1.5416)	Prec@1 64.062 (59.535)	
Epoch: [45][155/391]	LR: 8.000000000000001e-06	DT: 0.017 (0.025)	BT: 0.057 (0.061)	Loss 1.5088 (1.5513)	Prec@1 56.250 (59.310)	
Epoch: [45][233/391]	LR: 8.000000000000001e-06	DT: 0.015 (0.023)	BT: 0.050 (0.059)	Loss 1.7119 (1.5506)	Prec@1 55.469 (59.332)	
Epoch: [45][311/391]	LR: 8.000000000000001e-06	DT: 0.020 (0.022)	BT: 0.071 (0.057)	Loss 1.6152 (1.5509)	Prec@1 54.688 (59.367)	
Epoch: [45][389/391]	LR: 8.000000000000001e-06	DT: 0.039 (0.020)	BT: 0.070 (0.056)	Loss 1.5557 (1.5512)	Prec@1 57.812 (59.339)	
Total train loss: 1.5509
Avg Loading time: 0.0203 seconds
Avg Batch time: 0.0562 seconds

Train time: 22.132320880889893
 * Prec@1 59.500 Prec@5 87.260 Loss 1.5352
Avg Loading time: 0.0473 seconds
Avg Batch time: 0.0634 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 13.538455486297607

Epoch: [46][77/391]	LR: 8.000000000000001e-06	DT: 0.024 (0.026)	BT: 0.056 (0.064)	Loss 1.6699 (1.5404)	Prec@1 57.031 (60.587)	
Epoch: [46][155/391]	LR: 8.000000000000001e-06	DT: 0.012 (0.022)	BT: 0.046 (0.059)	Loss 1.5596 (1.5503)	Prec@1 60.938 (59.485)	
Epoch: [46][233/391]	LR: 8.000000000000001e-06	DT: 0.017 (0.020)	BT: 0.070 (0.056)	Loss 1.4893 (1.5478)	Prec@1 61.719 (59.519)	
Epoch: [46][311/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.018)	BT: 0.051 (0.055)	Loss 1.5811 (1.5503)	Prec@1 57.031 (59.250)	
Epoch: [46][389/391]	LR: 8.000000000000001e-06	DT: 0.044 (0.018)	BT: 0.075 (0.054)	Loss 1.5273 (1.5507)	Prec@1 59.375 (59.371)	
Total train loss: 1.5506
Avg Loading time: 0.0179 seconds
Avg Batch time: 0.0544 seconds

Train time: 21.34611463546753
 * Prec@1 59.600 Prec@5 87.330 Loss 1.5332
Avg Loading time: 0.0464 seconds
Avg Batch time: 0.0604 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 6.033756732940674

Epoch: [47][77/391]	LR: 8.000000000000001e-06	DT: 0.021 (0.022)	BT: 0.054 (0.061)	Loss 1.5293 (1.5506)	Prec@1 60.156 (58.964)	
Epoch: [47][155/391]	LR: 8.000000000000001e-06	DT: 0.011 (0.018)	BT: 0.042 (0.056)	Loss 1.6016 (1.5569)	Prec@1 64.062 (59.115)	
Epoch: [47][233/391]	LR: 8.000000000000001e-06	DT: 0.031 (0.018)	BT: 0.063 (0.055)	Loss 1.4834 (1.5625)	Prec@1 64.062 (58.964)	
Epoch: [47][311/391]	LR: 8.000000000000001e-06	DT: 0.015 (0.017)	BT: 0.052 (0.054)	Loss 1.3320 (1.5535)	Prec@1 64.062 (59.147)	
Epoch: [47][389/391]	LR: 8.000000000000001e-06	DT: 0.011 (0.016)	BT: 0.041 (0.054)	Loss 1.4102 (1.5512)	Prec@1 67.188 (59.287)	
Total train loss: 1.5516
Avg Loading time: 0.0163 seconds
Avg Batch time: 0.0534 seconds

Train time: 20.98459005355835
 * Prec@1 59.450 Prec@5 87.320 Loss 1.5332
Avg Loading time: 0.0490 seconds
Avg Batch time: 0.0643 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 14.085194826126099

Epoch: [48][77/391]	LR: 8.000000000000001e-06	DT: 0.023 (0.020)	BT: 0.055 (0.061)	Loss 1.9082 (1.5537)	Prec@1 48.438 (59.285)	
Epoch: [48][155/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.018)	BT: 0.032 (0.056)	Loss 1.3896 (1.5565)	Prec@1 62.500 (59.365)	
Epoch: [48][233/391]	LR: 8.000000000000001e-06	DT: 0.015 (0.016)	BT: 0.049 (0.054)	Loss 1.7021 (1.5548)	Prec@1 58.594 (59.472)	
Epoch: [48][311/391]	LR: 8.000000000000001e-06	DT: 0.014 (0.016)	BT: 0.050 (0.053)	Loss 1.4404 (1.5497)	Prec@1 64.062 (59.478)	
Epoch: [48][389/391]	LR: 8.000000000000001e-06	DT: 0.040 (0.015)	BT: 0.071 (0.053)	Loss 1.5254 (1.5505)	Prec@1 62.500 (59.393)	
Total train loss: 1.5505
Avg Loading time: 0.0151 seconds
Avg Batch time: 0.0528 seconds

Train time: 20.748744249343872
 * Prec@1 59.630 Prec@5 87.400 Loss 1.5283
Avg Loading time: 0.0431 seconds
Avg Batch time: 0.0594 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 9.66569209098816

Epoch: [49][77/391]	LR: 8.000000000000001e-06	DT: 0.027 (0.023)	BT: 0.063 (0.062)	Loss 1.6504 (1.5202)	Prec@1 50.000 (59.946)	
Epoch: [49][155/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.019)	BT: 0.035 (0.058)	Loss 1.7412 (1.5400)	Prec@1 53.906 (59.670)	
Epoch: [49][233/391]	LR: 8.000000000000001e-06	DT: 0.026 (0.019)	BT: 0.063 (0.056)	Loss 1.6514 (1.5469)	Prec@1 58.594 (59.502)	
Epoch: [49][311/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.018)	BT: 0.033 (0.055)	Loss 1.5645 (1.5487)	Prec@1 57.812 (59.418)	
Epoch: [49][389/391]	LR: 8.000000000000001e-06	DT: 0.040 (0.017)	BT: 0.077 (0.054)	Loss 1.4141 (1.5491)	Prec@1 63.281 (59.457)	
Total train loss: 1.5494
Avg Loading time: 0.0170 seconds
Avg Batch time: 0.0540 seconds

Train time: 21.22591495513916
 * Prec@1 59.410 Prec@5 87.480 Loss 1.5322
Avg Loading time: 0.0479 seconds
Avg Batch time: 0.0626 seconds

Best acc: 59.930
--------------------------------------------------------------------------------
Test time: 8.764379978179932

