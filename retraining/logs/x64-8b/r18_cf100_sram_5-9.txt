
      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 5
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar100/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/train/relu5
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/test/relu5
ResNet18(
  (conv6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv1): Sequential(
    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu6): ReLU(inplace=True)
  (conv7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu7): ReLU(inplace=True)
  (conv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=100, bias=False)
  (bn19): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 0.880 Prec@5 4.820 Loss 4.6094
Avg Loading time: 1.0840 seconds
Avg Batch time: 1.1232 seconds

Pre-trained Prec@1 with 5 layers frozen: 0.8799999952316284 	 Loss: 4.609375

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (3.521)	BT: 0.056 (3.586)	Loss 2.1699 (2.4944)	Prec@1 42.969 (39.113)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (3.618)	BT: 0.057 (3.683)	Loss 1.3447 (2.1114)	Prec@1 64.062 (46.054)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (3.757)	BT: 0.067 (3.821)	Loss 1.5107 (1.9399)	Prec@1 60.938 (49.416)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (3.650)	BT: 0.057 (3.714)	Loss 1.4062 (1.8111)	Prec@1 58.594 (52.138)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (3.506)	BT: 0.057 (3.571)	Loss 1.3721 (1.7265)	Prec@1 64.844 (53.980)	
Total train loss: 1.7262
Avg Loading time: 3.4971 seconds
Avg Batch time: 3.5617 seconds

Train time: 1392.731942653656
 * Prec@1 57.800 Prec@5 86.110 Loss 1.5557
Avg Loading time: 0.2049 seconds
Avg Batch time: 0.2307 seconds

Best acc: 57.800
--------------------------------------------------------------------------------
Test time: 19.330472707748413

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.144)	BT: 0.052 (0.210)	Loss 1.0117 (1.0729)	Prec@1 75.000 (68.990)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.244 (0.124)	BT: 0.306 (0.190)	Loss 1.0469 (1.0854)	Prec@1 66.406 (68.820)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.124)	BT: 0.069 (0.191)	Loss 1.2402 (1.0895)	Prec@1 65.625 (68.677)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.124)	BT: 0.095 (0.191)	Loss 0.9375 (1.0893)	Prec@1 71.094 (68.650)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.121)	BT: 0.058 (0.189)	Loss 0.8970 (1.0832)	Prec@1 67.188 (68.754)	
Total train loss: 1.0832
Avg Loading time: 0.1212 seconds
Avg Batch time: 0.1888 seconds

Train time: 73.97816228866577
 * Prec@1 60.870 Prec@5 87.840 Loss 1.4277
Avg Loading time: 0.1693 seconds
Avg Batch time: 0.1967 seconds

Best acc: 60.870
--------------------------------------------------------------------------------
Test time: 17.277638912200928

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.157)	BT: 0.057 (0.220)	Loss 0.5850 (0.7271)	Prec@1 83.594 (78.626)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.148)	BT: 0.058 (0.211)	Loss 0.9614 (0.7595)	Prec@1 71.875 (77.474)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (0.142)	BT: 0.083 (0.205)	Loss 0.8516 (0.7802)	Prec@1 74.219 (76.743)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.130)	BT: 0.059 (0.194)	Loss 1.0918 (0.7991)	Prec@1 69.531 (76.157)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.127)	BT: 0.058 (0.191)	Loss 0.9766 (0.8083)	Prec@1 69.531 (75.801)	
Total train loss: 0.8086
Avg Loading time: 0.1263 seconds
Avg Batch time: 0.1904 seconds

Train time: 74.5599467754364
 * Prec@1 65.770 Prec@5 89.890 Loss 1.2705
Avg Loading time: 0.1594 seconds
Avg Batch time: 0.1911 seconds

Best acc: 65.770
--------------------------------------------------------------------------------
Test time: 16.25268054008484

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.122)	BT: 0.063 (0.189)	Loss 0.5186 (0.5145)	Prec@1 78.906 (84.505)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.107)	BT: 0.059 (0.175)	Loss 0.7529 (0.5418)	Prec@1 78.125 (83.679)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.595 (0.113)	BT: 0.663 (0.181)	Loss 0.5142 (0.5705)	Prec@1 84.375 (82.886)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.237 (0.112)	BT: 0.305 (0.180)	Loss 0.5244 (0.5874)	Prec@1 82.031 (82.284)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.115)	BT: 0.059 (0.183)	Loss 0.7373 (0.6104)	Prec@1 78.125 (81.599)	
Total train loss: 0.6103
Avg Loading time: 0.1150 seconds
Avg Batch time: 0.1828 seconds

Train time: 71.58643198013306
 * Prec@1 65.890 Prec@5 89.450 Loss 1.2930
Avg Loading time: 0.1450 seconds
Avg Batch time: 0.1746 seconds

Best acc: 65.890
--------------------------------------------------------------------------------
Test time: 14.914777755737305

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.117)	BT: 0.058 (0.185)	Loss 0.4324 (0.4014)	Prec@1 85.938 (87.790)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.059 (0.105)	BT: 0.120 (0.172)	Loss 0.3508 (0.4100)	Prec@1 89.062 (87.555)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.106)	BT: 0.091 (0.174)	Loss 0.5508 (0.4241)	Prec@1 82.812 (87.026)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.112)	BT: 0.081 (0.180)	Loss 0.6514 (0.4424)	Prec@1 79.688 (86.371)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.111)	BT: 0.070 (0.180)	Loss 0.7822 (0.4652)	Prec@1 76.562 (85.609)	
Total train loss: 0.4658
Avg Loading time: 0.1104 seconds
Avg Batch time: 0.1792 seconds

Train time: 70.19121241569519
 * Prec@1 63.510 Prec@5 88.580 Loss 1.4287
Avg Loading time: 0.1944 seconds
Avg Batch time: 0.2244 seconds

Best acc: 65.890
--------------------------------------------------------------------------------
Test time: 18.50322437286377

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.147)	BT: 0.059 (0.213)	Loss 0.2388 (0.3226)	Prec@1 92.969 (90.204)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.136)	BT: 0.058 (0.202)	Loss 0.4683 (0.3140)	Prec@1 82.812 (90.325)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.000 (0.132)	BT: 0.058 (0.199)	Loss 0.4714 (0.3250)	Prec@1 84.375 (89.901)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.130)	BT: 0.059 (0.197)	Loss 0.5474 (0.3441)	Prec@1 83.594 (89.293)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.124)	BT: 0.070 (0.191)	Loss 0.4973 (0.3608)	Prec@1 81.250 (88.760)	
Total train loss: 0.3609
Avg Loading time: 0.1232 seconds
Avg Batch time: 0.1909 seconds

Train time: 74.71973466873169
 * Prec@1 64.990 Prec@5 88.170 Loss 1.4443
Avg Loading time: 0.1419 seconds
Avg Batch time: 0.1719 seconds

Best acc: 65.890
--------------------------------------------------------------------------------
Test time: 14.267197847366333

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.123)	BT: 0.079 (0.189)	Loss 0.2136 (0.2411)	Prec@1 94.531 (92.819)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.119)	BT: 0.093 (0.184)	Loss 0.3706 (0.2413)	Prec@1 88.281 (92.748)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.690 (0.115)	BT: 0.748 (0.180)	Loss 0.2839 (0.2549)	Prec@1 91.406 (92.351)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.112)	BT: 0.059 (0.178)	Loss 0.2939 (0.2623)	Prec@1 91.406 (92.027)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.111)	BT: 0.059 (0.177)	Loss 0.2971 (0.2774)	Prec@1 92.969 (91.488)	
Total train loss: 0.2776
Avg Loading time: 0.1106 seconds
Avg Batch time: 0.1766 seconds

Train time: 69.11310529708862
 * Prec@1 65.640 Prec@5 88.610 Loss 1.4805
Avg Loading time: 0.1789 seconds
Avg Batch time: 0.2080 seconds

Best acc: 65.890
--------------------------------------------------------------------------------
Test time: 17.074069499969482

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.112)	BT: 0.091 (0.179)	Loss 0.1465 (0.2061)	Prec@1 96.094 (94.000)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.032 (0.110)	BT: 0.090 (0.177)	Loss 0.2151 (0.1990)	Prec@1 92.969 (94.131)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.225 (0.110)	BT: 0.282 (0.178)	Loss 0.1915 (0.2067)	Prec@1 94.531 (93.833)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.116)	BT: 0.059 (0.183)	Loss 0.3613 (0.2184)	Prec@1 88.281 (93.419)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.121)	BT: 0.059 (0.188)	Loss 0.3101 (0.2291)	Prec@1 89.844 (93.091)	
Total train loss: 0.2293
Avg Loading time: 0.1206 seconds
Avg Batch time: 0.1877 seconds

Train time: 73.47820377349854
 * Prec@1 66.440 Prec@5 88.910 Loss 1.4795
Avg Loading time: 0.2160 seconds
Avg Batch time: 0.2431 seconds

Best acc: 66.440
--------------------------------------------------------------------------------
Test time: 20.370903253555298

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.158)	BT: 0.059 (0.221)	Loss 0.2007 (0.1803)	Prec@1 93.750 (94.782)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.163)	BT: 0.058 (0.227)	Loss 0.1648 (0.1801)	Prec@1 96.875 (94.817)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.164)	BT: 0.059 (0.228)	Loss 0.1299 (0.1777)	Prec@1 95.312 (94.858)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.162)	BT: 0.059 (0.226)	Loss 0.1469 (0.1806)	Prec@1 96.875 (94.664)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.167)	BT: 0.060 (0.231)	Loss 0.2717 (0.1897)	Prec@1 89.844 (94.355)	
Total train loss: 0.1902
Avg Loading time: 0.1665 seconds
Avg Batch time: 0.2307 seconds

Train time: 90.29674553871155
 * Prec@1 64.930 Prec@5 87.880 Loss 1.5254
Avg Loading time: 0.1903 seconds
Avg Batch time: 0.2176 seconds

Best acc: 66.440
--------------------------------------------------------------------------------
Test time: 17.845316171646118

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.180)	BT: 0.057 (0.246)	Loss 0.1210 (0.1661)	Prec@1 94.531 (95.172)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.252 (0.159)	BT: 0.309 (0.225)	Loss 0.2107 (0.1571)	Prec@1 92.969 (95.418)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.141)	BT: 0.109 (0.208)	Loss 0.2240 (0.1621)	Prec@1 93.750 (95.249)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.142)	BT: 0.058 (0.208)	Loss 0.2356 (0.1704)	Prec@1 94.531 (94.954)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.143)	BT: 0.058 (0.210)	Loss 0.1844 (0.1766)	Prec@1 95.312 (94.780)	
Total train loss: 0.1770
Avg Loading time: 0.1430 seconds
Avg Batch time: 0.2094 seconds

Train time: 81.95873475074768
 * Prec@1 67.630 Prec@5 88.990 Loss 1.4072
Avg Loading time: 0.1577 seconds
Avg Batch time: 0.1862 seconds

Best acc: 67.630
--------------------------------------------------------------------------------
Test time: 15.894015312194824

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.115)	BT: 0.076 (0.186)	Loss 0.0572 (0.0999)	Prec@1 98.438 (97.266)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.101)	BT: 0.078 (0.172)	Loss 0.0413 (0.0827)	Prec@1 98.438 (97.842)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.099)	BT: 0.084 (0.169)	Loss 0.0294 (0.0747)	Prec@1 100.000 (98.090)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.099)	BT: 0.096 (0.169)	Loss 0.0260 (0.0692)	Prec@1 99.219 (98.275)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.103)	BT: 0.058 (0.173)	Loss 0.0533 (0.0648)	Prec@1 99.219 (98.433)	
Total train loss: 0.0650
Avg Loading time: 0.1027 seconds
Avg Batch time: 0.1731 seconds

Train time: 67.79098892211914
 * Prec@1 74.890 Prec@5 92.540 Loss 1.0684
Avg Loading time: 0.1673 seconds
Avg Batch time: 0.1964 seconds

Best acc: 74.890
--------------------------------------------------------------------------------
Test time: 16.663520097732544

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.106)	BT: 0.084 (0.172)	Loss 0.0465 (0.0279)	Prec@1 99.219 (99.519)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.105)	BT: 0.081 (0.172)	Loss 0.0202 (0.0273)	Prec@1 100.000 (99.624)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.099)	BT: 0.080 (0.167)	Loss 0.0163 (0.0277)	Prec@1 100.000 (99.629)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.091)	BT: 0.058 (0.158)	Loss 0.0154 (0.0271)	Prec@1 100.000 (99.627)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.095)	BT: 0.058 (0.161)	Loss 0.0289 (0.0271)	Prec@1 100.000 (99.631)	
Total train loss: 0.0271
Avg Loading time: 0.0943 seconds
Avg Batch time: 0.1610 seconds

Train time: 63.04709553718567
 * Prec@1 75.180 Prec@5 92.530 Loss 1.0596
Avg Loading time: 0.1531 seconds
Avg Batch time: 0.1826 seconds

Best acc: 75.180
--------------------------------------------------------------------------------
Test time: 15.560847997665405

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.110)	BT: 0.086 (0.178)	Loss 0.0476 (0.0213)	Prec@1 98.438 (99.760)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.100)	BT: 0.080 (0.169)	Loss 0.0144 (0.0208)	Prec@1 100.000 (99.760)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.095)	BT: 0.069 (0.165)	Loss 0.0165 (0.0200)	Prec@1 100.000 (99.780)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.040 (0.094)	BT: 0.099 (0.163)	Loss 0.0202 (0.0201)	Prec@1 99.219 (99.767)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.094)	BT: 0.058 (0.164)	Loss 0.0286 (0.0204)	Prec@1 100.000 (99.770)	
Total train loss: 0.0204
Avg Loading time: 0.0940 seconds
Avg Batch time: 0.1632 seconds

Train time: 63.92158842086792
 * Prec@1 75.540 Prec@5 92.350 Loss 1.0674
Avg Loading time: 0.1285 seconds
Avg Batch time: 0.1581 seconds

Best acc: 75.540
--------------------------------------------------------------------------------
Test time: 13.662150621414185

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.108)	BT: 0.057 (0.178)	Loss 0.0110 (0.0160)	Prec@1 100.000 (99.840)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.108)	BT: 0.098 (0.176)	Loss 0.0441 (0.0159)	Prec@1 99.219 (99.865)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.103)	BT: 0.058 (0.170)	Loss 0.0089 (0.0157)	Prec@1 100.000 (99.883)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.101)	BT: 0.060 (0.168)	Loss 0.0304 (0.0160)	Prec@1 99.219 (99.857)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.099)	BT: 0.062 (0.166)	Loss 0.0214 (0.0162)	Prec@1 100.000 (99.840)	
Total train loss: 0.0163
Avg Loading time: 0.0986 seconds
Avg Batch time: 0.1660 seconds

Train time: 65.02312111854553
 * Prec@1 75.180 Prec@5 92.450 Loss 1.0732
Avg Loading time: 0.1714 seconds
Avg Batch time: 0.1999 seconds

Best acc: 75.540
--------------------------------------------------------------------------------
Test time: 16.447057723999023

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.070)	BT: 0.102 (0.143)	Loss 0.0075 (0.0139)	Prec@1 100.000 (99.860)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.061)	BT: 0.100 (0.134)	Loss 0.0151 (0.0142)	Prec@1 100.000 (99.860)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.073 (0.061)	BT: 0.131 (0.134)	Loss 0.0299 (0.0143)	Prec@1 99.219 (99.873)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.068 (0.061)	BT: 0.126 (0.133)	Loss 0.0146 (0.0141)	Prec@1 100.000 (99.897)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.059)	BT: 0.078 (0.131)	Loss 0.0105 (0.0141)	Prec@1 100.000 (99.896)	
Total train loss: 0.0142
Avg Loading time: 0.0587 seconds
Avg Batch time: 0.1306 seconds

Train time: 51.22092032432556
 * Prec@1 75.520 Prec@5 92.270 Loss 1.0654
Avg Loading time: 0.1020 seconds
Avg Batch time: 0.1390 seconds

Best acc: 75.540
--------------------------------------------------------------------------------
Test time: 11.641695737838745

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.046 (0.064)	BT: 0.141 (0.142)	Loss 0.0054 (0.0126)	Prec@1 100.000 (99.940)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.219 (0.059)	BT: 0.295 (0.133)	Loss 0.0225 (0.0130)	Prec@1 100.000 (99.940)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.100 (0.059)	BT: 0.214 (0.133)	Loss 0.0136 (0.0129)	Prec@1 100.000 (99.927)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.069 (0.060)	BT: 0.127 (0.133)	Loss 0.0397 (0.0130)	Prec@1 99.219 (99.930)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.059)	BT: 0.061 (0.132)	Loss 0.0371 (0.0132)	Prec@1 99.219 (99.920)	
Total train loss: 0.0132
Avg Loading time: 0.0588 seconds
Avg Batch time: 0.1315 seconds

Train time: 51.48917770385742
 * Prec@1 75.280 Prec@5 92.310 Loss 1.0732
Avg Loading time: 0.1092 seconds
Avg Batch time: 0.1433 seconds

Best acc: 75.540
--------------------------------------------------------------------------------
Test time: 11.963419914245605

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.064 (0.064)	BT: 0.153 (0.143)	Loss 0.0071 (0.0119)	Prec@1 100.000 (99.920)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.059)	BT: 0.071 (0.134)	Loss 0.0137 (0.0124)	Prec@1 100.000 (99.890)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.055)	BT: 0.079 (0.130)	Loss 0.0152 (0.0122)	Prec@1 100.000 (99.903)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.001 (0.052)	BT: 0.070 (0.128)	Loss 0.0075 (0.0120)	Prec@1 100.000 (99.910)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.035 (0.052)	BT: 0.093 (0.127)	Loss 0.0088 (0.0118)	Prec@1 100.000 (99.912)	
Total train loss: 0.0119
Avg Loading time: 0.0516 seconds
Avg Batch time: 0.1272 seconds

Train time: 49.79538559913635
 * Prec@1 75.620 Prec@5 92.400 Loss 1.0723
Avg Loading time: 0.0960 seconds
Avg Batch time: 0.1303 seconds

Best acc: 75.620
--------------------------------------------------------------------------------
Test time: 11.475192308425903

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.054 (0.068)	BT: 0.108 (0.141)	Loss 0.0443 (0.0113)	Prec@1 99.219 (99.910)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.070)	BT: 0.079 (0.142)	Loss 0.0112 (0.0112)	Prec@1 100.000 (99.930)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.076)	BT: 0.060 (0.146)	Loss 0.0104 (0.0107)	Prec@1 100.000 (99.947)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.154 (0.086)	BT: 0.218 (0.156)	Loss 0.0214 (0.0107)	Prec@1 100.000 (99.955)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.091)	BT: 0.058 (0.160)	Loss 0.0553 (0.0107)	Prec@1 99.219 (99.946)	
Total train loss: 0.0107
Avg Loading time: 0.0904 seconds
Avg Batch time: 0.1600 seconds

Train time: 62.626694202423096
 * Prec@1 75.550 Prec@5 92.350 Loss 1.0732
Avg Loading time: 0.1706 seconds
Avg Batch time: 0.1989 seconds

Best acc: 75.620
--------------------------------------------------------------------------------
Test time: 16.356262922286987

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.084)	BT: 0.091 (0.153)	Loss 0.0079 (0.0103)	Prec@1 100.000 (99.950)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.081)	BT: 0.079 (0.150)	Loss 0.0056 (0.0102)	Prec@1 100.000 (99.940)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.080 (0.089)	BT: 0.140 (0.157)	Loss 0.0228 (0.0106)	Prec@1 100.000 (99.937)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.088)	BT: 0.085 (0.157)	Loss 0.0113 (0.0106)	Prec@1 100.000 (99.935)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.086)	BT: 0.078 (0.156)	Loss 0.0070 (0.0105)	Prec@1 100.000 (99.938)	
Total train loss: 0.0105
Avg Loading time: 0.0860 seconds
Avg Batch time: 0.1553 seconds

Train time: 60.85453534126282
 * Prec@1 75.400 Prec@5 92.390 Loss 1.0762
Avg Loading time: 0.1581 seconds
Avg Batch time: 0.1859 seconds

Best acc: 75.620
--------------------------------------------------------------------------------
Test time: 15.308191299438477

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.100)	BT: 0.058 (0.167)	Loss 0.0057 (0.0100)	Prec@1 100.000 (99.990)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.095)	BT: 0.058 (0.160)	Loss 0.0130 (0.0099)	Prec@1 100.000 (99.975)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.105)	BT: 0.058 (0.171)	Loss 0.0031 (0.0095)	Prec@1 100.000 (99.977)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.105)	BT: 0.075 (0.172)	Loss 0.0111 (0.0096)	Prec@1 100.000 (99.965)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.103)	BT: 0.058 (0.170)	Loss 0.0041 (0.0096)	Prec@1 100.000 (99.964)	
Total train loss: 0.0096
Avg Loading time: 0.1027 seconds
Avg Batch time: 0.1695 seconds

Train time: 66.4120044708252
 * Prec@1 75.370 Prec@5 92.260 Loss 1.0781
Avg Loading time: 0.1458 seconds
Avg Batch time: 0.1755 seconds

Best acc: 75.620
--------------------------------------------------------------------------------
Test time: 14.490190982818604

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.129)	BT: 0.074 (0.197)	Loss 0.0124 (0.0095)	Prec@1 100.000 (99.950)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.119)	BT: 0.099 (0.188)	Loss 0.0082 (0.0091)	Prec@1 100.000 (99.960)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.115)	BT: 0.074 (0.184)	Loss 0.0038 (0.0090)	Prec@1 100.000 (99.957)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.118)	BT: 0.081 (0.185)	Loss 0.0083 (0.0089)	Prec@1 100.000 (99.957)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.381 (0.120)	BT: 0.442 (0.187)	Loss 0.0087 (0.0090)	Prec@1 100.000 (99.956)	
Total train loss: 0.0090
Avg Loading time: 0.1197 seconds
Avg Batch time: 0.1870 seconds

Train time: 73.24553298950195
 * Prec@1 75.220 Prec@5 92.360 Loss 1.0742
Avg Loading time: 0.1961 seconds
Avg Batch time: 0.2231 seconds

Best acc: 75.620
--------------------------------------------------------------------------------
Test time: 18.301037788391113

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.135)	BT: 0.058 (0.201)	Loss 0.0130 (0.0094)	Prec@1 100.000 (99.940)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.127)	BT: 0.058 (0.193)	Loss 0.0036 (0.0097)	Prec@1 100.000 (99.925)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.122)	BT: 0.130 (0.190)	Loss 0.0127 (0.0097)	Prec@1 100.000 (99.940)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.119)	BT: 0.084 (0.188)	Loss 0.0077 (0.0094)	Prec@1 100.000 (99.937)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.122)	BT: 0.059 (0.190)	Loss 0.0080 (0.0093)	Prec@1 100.000 (99.942)	
Total train loss: 0.0093
Avg Loading time: 0.1218 seconds
Avg Batch time: 0.1896 seconds

Train time: 74.23809456825256
 * Prec@1 75.690 Prec@5 92.400 Loss 1.0771
Avg Loading time: 0.1573 seconds
Avg Batch time: 0.1856 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 15.81373929977417

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.122)	BT: 0.074 (0.190)	Loss 0.0051 (0.0088)	Prec@1 100.000 (99.970)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.131 (0.121)	BT: 0.194 (0.189)	Loss 0.0047 (0.0087)	Prec@1 100.000 (99.970)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.002 (0.114)	BT: 0.089 (0.182)	Loss 0.0081 (0.0089)	Prec@1 100.000 (99.973)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.117)	BT: 0.058 (0.185)	Loss 0.0094 (0.0087)	Prec@1 100.000 (99.970)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.284 (0.122)	BT: 0.340 (0.189)	Loss 0.0286 (0.0091)	Prec@1 99.219 (99.956)	
Total train loss: 0.0091
Avg Loading time: 0.1218 seconds
Avg Batch time: 0.1888 seconds

Train time: 73.93499875068665
 * Prec@1 75.450 Prec@5 92.170 Loss 1.0762
Avg Loading time: 0.2143 seconds
Avg Batch time: 0.2430 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 19.87405228614807

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.127)	BT: 0.057 (0.197)	Loss 0.0037 (0.0089)	Prec@1 100.000 (99.940)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.127)	BT: 0.054 (0.195)	Loss 0.0101 (0.0088)	Prec@1 100.000 (99.960)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.136)	BT: 0.079 (0.203)	Loss 0.0091 (0.0088)	Prec@1 100.000 (99.957)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.133)	BT: 0.062 (0.201)	Loss 0.0046 (0.0090)	Prec@1 100.000 (99.950)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.130)	BT: 0.076 (0.198)	Loss 0.0249 (0.0089)	Prec@1 99.219 (99.946)	
Total train loss: 0.0090
Avg Loading time: 0.1300 seconds
Avg Batch time: 0.1973 seconds

Train time: 77.26968765258789
 * Prec@1 75.420 Prec@5 92.180 Loss 1.0771
Avg Loading time: 0.1727 seconds
Avg Batch time: 0.1990 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 16.37749195098877

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.150)	BT: 0.060 (0.213)	Loss 0.0046 (0.0096)	Prec@1 100.000 (99.920)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.139)	BT: 0.071 (0.204)	Loss 0.0101 (0.0091)	Prec@1 100.000 (99.945)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.135)	BT: 0.073 (0.201)	Loss 0.0063 (0.0092)	Prec@1 100.000 (99.943)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.136)	BT: 0.105 (0.202)	Loss 0.0086 (0.0091)	Prec@1 100.000 (99.945)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.139)	BT: 0.058 (0.205)	Loss 0.0083 (0.0092)	Prec@1 100.000 (99.936)	
Total train loss: 0.0092
Avg Loading time: 0.1386 seconds
Avg Batch time: 0.2041 seconds

Train time: 79.92899870872498
 * Prec@1 75.550 Prec@5 92.280 Loss 1.0723
Avg Loading time: 0.1800 seconds
Avg Batch time: 0.2100 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 17.22205901145935

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.136)	BT: 0.063 (0.200)	Loss 0.0060 (0.0091)	Prec@1 100.000 (99.950)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.133)	BT: 0.063 (0.198)	Loss 0.0069 (0.0088)	Prec@1 100.000 (99.940)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.879 (0.133)	BT: 0.946 (0.199)	Loss 0.0041 (0.0090)	Prec@1 100.000 (99.937)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.126)	BT: 0.059 (0.192)	Loss 0.0152 (0.0087)	Prec@1 100.000 (99.945)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.129)	BT: 0.081 (0.195)	Loss 0.0075 (0.0087)	Prec@1 100.000 (99.950)	
Total train loss: 0.0087
Avg Loading time: 0.1289 seconds
Avg Batch time: 0.1949 seconds

Train time: 76.30022954940796
 * Prec@1 75.340 Prec@5 92.110 Loss 1.0850
Avg Loading time: 0.1660 seconds
Avg Batch time: 0.1949 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 16.031073570251465

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.064 (0.135)	BT: 0.122 (0.204)	Loss 0.0042 (0.0082)	Prec@1 100.000 (99.960)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.131)	BT: 0.058 (0.199)	Loss 0.0182 (0.0087)	Prec@1 100.000 (99.960)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.129)	BT: 0.096 (0.197)	Loss 0.0060 (0.0086)	Prec@1 100.000 (99.960)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.130)	BT: 0.057 (0.198)	Loss 0.0078 (0.0086)	Prec@1 100.000 (99.950)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 1.087 (0.130)	BT: 1.144 (0.199)	Loss 0.0169 (0.0086)	Prec@1 100.000 (99.946)	
Total train loss: 0.0086
Avg Loading time: 0.1299 seconds
Avg Batch time: 0.1982 seconds

Train time: 77.598952293396
 * Prec@1 75.490 Prec@5 92.180 Loss 1.0791
Avg Loading time: 0.1584 seconds
Avg Batch time: 0.1874 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 15.413673162460327

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.118 (0.120)	BT: 0.180 (0.183)	Loss 0.0050 (0.0078)	Prec@1 100.000 (99.970)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.042 (0.117)	BT: 0.108 (0.182)	Loss 0.0061 (0.0085)	Prec@1 100.000 (99.955)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.114)	BT: 0.061 (0.179)	Loss 0.0040 (0.0086)	Prec@1 100.000 (99.957)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.114)	BT: 0.061 (0.180)	Loss 0.0080 (0.0087)	Prec@1 100.000 (99.952)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.113)	BT: 0.058 (0.179)	Loss 0.0134 (0.0087)	Prec@1 99.219 (99.952)	
Total train loss: 0.0088
Avg Loading time: 0.1128 seconds
Avg Batch time: 0.1785 seconds

Train time: 69.90961337089539
 * Prec@1 75.350 Prec@5 92.250 Loss 1.0820
Avg Loading time: 0.1783 seconds
Avg Batch time: 0.2086 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 17.17328906059265

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.144)	BT: 0.054 (0.208)	Loss 0.0067 (0.0097)	Prec@1 100.000 (99.930)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.130)	BT: 0.059 (0.195)	Loss 0.0118 (0.0096)	Prec@1 100.000 (99.940)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.128)	BT: 0.071 (0.194)	Loss 0.0048 (0.0093)	Prec@1 100.000 (99.940)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.122)	BT: 0.090 (0.188)	Loss 0.0092 (0.0091)	Prec@1 100.000 (99.945)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.120)	BT: 0.062 (0.186)	Loss 0.0081 (0.0091)	Prec@1 100.000 (99.948)	
Total train loss: 0.0091
Avg Loading time: 0.1193 seconds
Avg Batch time: 0.1854 seconds

Train time: 72.5993025302887
 * Prec@1 75.600 Prec@5 92.150 Loss 1.0801
Avg Loading time: 0.1629 seconds
Avg Batch time: 0.1929 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 15.992585182189941

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.121)	BT: 0.059 (0.185)	Loss 0.0035 (0.0084)	Prec@1 100.000 (99.970)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.121)	BT: 0.058 (0.184)	Loss 0.0089 (0.0085)	Prec@1 100.000 (99.975)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.124)	BT: 0.058 (0.188)	Loss 0.0178 (0.0087)	Prec@1 100.000 (99.970)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.114)	BT: 0.058 (0.178)	Loss 0.0063 (0.0087)	Prec@1 100.000 (99.967)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.114)	BT: 0.057 (0.178)	Loss 0.0173 (0.0087)	Prec@1 100.000 (99.966)	
Total train loss: 0.0087
Avg Loading time: 0.1136 seconds
Avg Batch time: 0.1781 seconds

Train time: 69.7160906791687
 * Prec@1 75.580 Prec@5 92.270 Loss 1.0703
Avg Loading time: 0.1771 seconds
Avg Batch time: 0.2064 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 16.93070697784424

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.188 (0.125)	BT: 0.254 (0.191)	Loss 0.0052 (0.0084)	Prec@1 100.000 (99.960)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.179 (0.108)	BT: 0.245 (0.174)	Loss 0.0075 (0.0087)	Prec@1 100.000 (99.965)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.695 (0.108)	BT: 0.754 (0.174)	Loss 0.0092 (0.0090)	Prec@1 100.000 (99.957)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.109)	BT: 0.059 (0.176)	Loss 0.0046 (0.0088)	Prec@1 100.000 (99.950)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.107)	BT: 0.059 (0.174)	Loss 0.0111 (0.0088)	Prec@1 100.000 (99.948)	
Total train loss: 0.0088
Avg Loading time: 0.1071 seconds
Avg Batch time: 0.1738 seconds

Train time: 68.08483576774597
 * Prec@1 75.310 Prec@5 92.300 Loss 1.0801
Avg Loading time: 0.1492 seconds
Avg Batch time: 0.1774 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 14.647796630859375

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.009 (0.125)	BT: 0.087 (0.190)	Loss 0.0129 (0.0097)	Prec@1 100.000 (99.960)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.114)	BT: 0.071 (0.181)	Loss 0.0093 (0.0090)	Prec@1 100.000 (99.965)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.107)	BT: 0.078 (0.173)	Loss 0.0081 (0.0089)	Prec@1 100.000 (99.960)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.100)	BT: 0.066 (0.167)	Loss 0.0060 (0.0089)	Prec@1 100.000 (99.957)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.134)	BT: 0.058 (0.200)	Loss 0.0059 (0.0089)	Prec@1 100.000 (99.952)	
Total train loss: 0.0089
Avg Loading time: 0.1335 seconds
Avg Batch time: 0.1995 seconds

Train time: 78.0784604549408
 * Prec@1 75.560 Prec@5 92.330 Loss 1.0693
Avg Loading time: 0.5419 seconds
Avg Batch time: 0.5695 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 45.621989250183105

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.372)	BT: 0.057 (0.437)	Loss 0.0086 (0.0090)	Prec@1 100.000 (99.950)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.514 (0.329)	BT: 0.578 (0.394)	Loss 0.0062 (0.0087)	Prec@1 100.000 (99.960)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.329)	BT: 0.078 (0.395)	Loss 0.0139 (0.0087)	Prec@1 100.000 (99.957)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.338)	BT: 0.076 (0.402)	Loss 0.0079 (0.0087)	Prec@1 100.000 (99.957)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.337)	BT: 0.059 (0.401)	Loss 0.0031 (0.0086)	Prec@1 100.000 (99.952)	
Total train loss: 0.0086
Avg Loading time: 0.3363 seconds
Avg Batch time: 0.4005 seconds

Train time: 156.72910571098328
 * Prec@1 75.610 Prec@5 92.090 Loss 1.0771
Avg Loading time: 0.4437 seconds
Avg Batch time: 0.4705 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 37.78878664970398

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.383)	BT: 0.060 (0.448)	Loss 0.0110 (0.0090)	Prec@1 100.000 (99.950)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.358)	BT: 0.081 (0.423)	Loss 0.0118 (0.0086)	Prec@1 100.000 (99.965)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.036 (0.337)	BT: 0.103 (0.403)	Loss 0.0264 (0.0086)	Prec@1 99.219 (99.957)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.303)	BT: 0.059 (0.370)	Loss 0.0034 (0.0086)	Prec@1 100.000 (99.962)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.289)	BT: 0.057 (0.355)	Loss 0.0040 (0.0086)	Prec@1 100.000 (99.958)	
Total train loss: 0.0087
Avg Loading time: 0.2884 seconds
Avg Batch time: 0.3545 seconds

Train time: 138.69177103042603
 * Prec@1 75.400 Prec@5 92.210 Loss 1.0781
Avg Loading time: 0.1061 seconds
Avg Batch time: 0.1357 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 11.370315551757812

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.090)	BT: 0.058 (0.155)	Loss 0.0066 (0.0086)	Prec@1 100.000 (99.980)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.090 (0.088)	BT: 0.151 (0.153)	Loss 0.0052 (0.0087)	Prec@1 100.000 (99.955)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.087 (0.080)	BT: 0.169 (0.147)	Loss 0.0062 (0.0084)	Prec@1 100.000 (99.963)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.078)	BT: 0.079 (0.144)	Loss 0.0044 (0.0083)	Prec@1 100.000 (99.965)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.079)	BT: 0.058 (0.146)	Loss 0.0086 (0.0083)	Prec@1 100.000 (99.968)	
Total train loss: 0.0083
Avg Loading time: 0.0788 seconds
Avg Batch time: 0.1460 seconds

Train time: 57.19543743133545
 * Prec@1 75.320 Prec@5 92.210 Loss 1.0820
Avg Loading time: 0.1344 seconds
Avg Batch time: 0.1650 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 13.697002410888672

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.085)	BT: 0.061 (0.153)	Loss 0.0049 (0.0095)	Prec@1 100.000 (99.950)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.072)	BT: 0.067 (0.142)	Loss 0.0082 (0.0093)	Prec@1 100.000 (99.950)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.599 (0.078)	BT: 0.663 (0.147)	Loss 0.0066 (0.0090)	Prec@1 100.000 (99.960)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.077)	BT: 0.060 (0.146)	Loss 0.0083 (0.0091)	Prec@1 100.000 (99.957)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.080)	BT: 0.058 (0.149)	Loss 0.0128 (0.0089)	Prec@1 100.000 (99.956)	
Total train loss: 0.0090
Avg Loading time: 0.0796 seconds
Avg Batch time: 0.1490 seconds

Train time: 58.36359906196594
 * Prec@1 75.510 Prec@5 92.170 Loss 1.0732
Avg Loading time: 0.1169 seconds
Avg Batch time: 0.1462 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 12.23116135597229

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.081)	BT: 0.060 (0.151)	Loss 0.0062 (0.0090)	Prec@1 100.000 (99.950)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.082)	BT: 0.074 (0.151)	Loss 0.0041 (0.0092)	Prec@1 100.000 (99.935)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.048 (0.077)	BT: 0.107 (0.146)	Loss 0.0127 (0.0092)	Prec@1 100.000 (99.940)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.705 (0.081)	BT: 0.771 (0.151)	Loss 0.0165 (0.0091)	Prec@1 100.000 (99.947)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.079)	BT: 0.063 (0.149)	Loss 0.0099 (0.0090)	Prec@1 100.000 (99.956)	
Total train loss: 0.0090
Avg Loading time: 0.0790 seconds
Avg Batch time: 0.1484 seconds

Train time: 58.12367820739746
 * Prec@1 75.550 Prec@5 92.090 Loss 1.0723
Avg Loading time: 0.1758 seconds
Avg Batch time: 0.2019 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 16.59512996673584

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.098)	BT: 0.102 (0.167)	Loss 0.0072 (0.0097)	Prec@1 100.000 (99.930)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.095)	BT: 0.058 (0.162)	Loss 0.0024 (0.0099)	Prec@1 100.000 (99.905)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.597 (0.097)	BT: 0.668 (0.164)	Loss 0.0085 (0.0098)	Prec@1 100.000 (99.910)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.093)	BT: 0.079 (0.160)	Loss 0.0044 (0.0096)	Prec@1 100.000 (99.920)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.094)	BT: 0.061 (0.161)	Loss 0.0092 (0.0094)	Prec@1 100.000 (99.932)	
Total train loss: 0.0095
Avg Loading time: 0.0938 seconds
Avg Batch time: 0.1603 seconds

Train time: 62.748055934906006
 * Prec@1 75.500 Prec@5 92.140 Loss 1.0820
Avg Loading time: 0.1542 seconds
Avg Batch time: 0.1808 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 14.916116714477539

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.124)	BT: 0.064 (0.190)	Loss 0.0091 (0.0081)	Prec@1 100.000 (99.950)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.110)	BT: 0.069 (0.178)	Loss 0.0052 (0.0085)	Prec@1 100.000 (99.960)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.103)	BT: 0.067 (0.171)	Loss 0.0057 (0.0087)	Prec@1 100.000 (99.950)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.105)	BT: 0.054 (0.171)	Loss 0.0035 (0.0086)	Prec@1 100.000 (99.947)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.108)	BT: 0.054 (0.174)	Loss 0.0032 (0.0087)	Prec@1 100.000 (99.950)	
Total train loss: 0.0087
Avg Loading time: 0.1077 seconds
Avg Batch time: 0.1738 seconds

Train time: 68.0429334640503
 * Prec@1 75.270 Prec@5 92.160 Loss 1.0801
Avg Loading time: 0.2079 seconds
Avg Batch time: 0.2350 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 19.3171603679657

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.114)	BT: 0.054 (0.179)	Loss 0.0120 (0.0087)	Prec@1 100.000 (99.940)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.418 (0.116)	BT: 0.482 (0.181)	Loss 0.0036 (0.0088)	Prec@1 100.000 (99.955)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.720 (0.114)	BT: 0.781 (0.180)	Loss 0.0074 (0.0090)	Prec@1 100.000 (99.950)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.111)	BT: 0.058 (0.177)	Loss 0.0070 (0.0088)	Prec@1 100.000 (99.952)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.110)	BT: 0.058 (0.176)	Loss 0.0085 (0.0089)	Prec@1 100.000 (99.952)	
Total train loss: 0.0089
Avg Loading time: 0.1098 seconds
Avg Batch time: 0.1753 seconds

Train time: 68.65721797943115
 * Prec@1 75.270 Prec@5 92.140 Loss 1.0713
Avg Loading time: 0.1414 seconds
Avg Batch time: 0.1729 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 14.361645221710205

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.130)	BT: 0.076 (0.194)	Loss 0.0117 (0.0087)	Prec@1 100.000 (99.920)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.425 (0.125)	BT: 0.487 (0.192)	Loss 0.0106 (0.0084)	Prec@1 100.000 (99.950)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.120)	BT: 0.089 (0.187)	Loss 0.0072 (0.0085)	Prec@1 100.000 (99.953)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.115)	BT: 0.061 (0.182)	Loss 0.0069 (0.0086)	Prec@1 100.000 (99.955)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.120)	BT: 0.059 (0.187)	Loss 0.0045 (0.0086)	Prec@1 100.000 (99.952)	
Total train loss: 0.0087
Avg Loading time: 0.1199 seconds
Avg Batch time: 0.1867 seconds

Train time: 73.11060094833374
 * Prec@1 75.590 Prec@5 92.280 Loss 1.0811
Avg Loading time: 0.1801 seconds
Avg Batch time: 0.2094 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 17.17458462715149

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.115)	BT: 0.068 (0.182)	Loss 0.0063 (0.0089)	Prec@1 100.000 (99.940)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.120)	BT: 0.060 (0.187)	Loss 0.0255 (0.0089)	Prec@1 99.219 (99.935)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.127)	BT: 0.057 (0.194)	Loss 0.0065 (0.0088)	Prec@1 100.000 (99.943)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.122)	BT: 0.082 (0.189)	Loss 0.0064 (0.0087)	Prec@1 100.000 (99.950)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.120)	BT: 0.058 (0.186)	Loss 0.0054 (0.0089)	Prec@1 100.000 (99.950)	
Total train loss: 0.0088
Avg Loading time: 0.1194 seconds
Avg Batch time: 0.1855 seconds

Train time: 72.64664363861084
 * Prec@1 75.340 Prec@5 92.250 Loss 1.0732
Avg Loading time: 0.1586 seconds
Avg Batch time: 0.1876 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 15.501119136810303

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.140)	BT: 0.058 (0.207)	Loss 0.0064 (0.0086)	Prec@1 100.000 (99.950)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.041 (0.133)	BT: 0.102 (0.199)	Loss 0.0079 (0.0085)	Prec@1 100.000 (99.955)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.123)	BT: 0.105 (0.191)	Loss 0.0113 (0.0086)	Prec@1 100.000 (99.960)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.122)	BT: 0.058 (0.190)	Loss 0.0036 (0.0084)	Prec@1 100.000 (99.967)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.121)	BT: 0.057 (0.189)	Loss 0.0088 (0.0084)	Prec@1 100.000 (99.968)	
Total train loss: 0.0084
Avg Loading time: 0.1206 seconds
Avg Batch time: 0.1891 seconds

Train time: 74.02245378494263
 * Prec@1 75.610 Prec@5 92.210 Loss 1.0732
Avg Loading time: 0.1596 seconds
Avg Batch time: 0.1880 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 15.483555793762207

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.113)	BT: 0.059 (0.183)	Loss 0.0052 (0.0080)	Prec@1 100.000 (99.980)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.104)	BT: 0.058 (0.172)	Loss 0.0243 (0.0082)	Prec@1 99.219 (99.965)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.060 (0.109)	BT: 0.118 (0.177)	Loss 0.0051 (0.0081)	Prec@1 100.000 (99.970)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.106)	BT: 0.058 (0.172)	Loss 0.0040 (0.0082)	Prec@1 100.000 (99.972)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.109)	BT: 0.058 (0.176)	Loss 0.0106 (0.0083)	Prec@1 100.000 (99.966)	
Total train loss: 0.0083
Avg Loading time: 0.1091 seconds
Avg Batch time: 0.1754 seconds

Train time: 68.70001864433289
 * Prec@1 75.580 Prec@5 92.260 Loss 1.0791
Avg Loading time: 0.1912 seconds
Avg Batch time: 0.2187 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 17.929065227508545

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.114)	BT: 0.058 (0.180)	Loss 0.0053 (0.0081)	Prec@1 100.000 (99.980)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.102)	BT: 0.062 (0.168)	Loss 0.0068 (0.0084)	Prec@1 100.000 (99.970)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.106)	BT: 0.069 (0.172)	Loss 0.0059 (0.0088)	Prec@1 100.000 (99.963)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.107)	BT: 0.055 (0.172)	Loss 0.0198 (0.0088)	Prec@1 99.219 (99.955)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.104)	BT: 0.071 (0.170)	Loss 0.0051 (0.0088)	Prec@1 100.000 (99.958)	
Total train loss: 0.0088
Avg Loading time: 0.1042 seconds
Avg Batch time: 0.1696 seconds

Train time: 66.39542531967163
 * Prec@1 75.490 Prec@5 92.190 Loss 1.0752
Avg Loading time: 0.1404 seconds
Avg Batch time: 0.1708 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 14.189857721328735

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.135)	BT: 0.060 (0.203)	Loss 0.0053 (0.0085)	Prec@1 100.000 (99.930)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.122)	BT: 0.085 (0.190)	Loss 0.0113 (0.0087)	Prec@1 100.000 (99.950)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.244 (0.117)	BT: 0.309 (0.184)	Loss 0.0054 (0.0088)	Prec@1 100.000 (99.940)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.228 (0.113)	BT: 0.288 (0.180)	Loss 0.0053 (0.0087)	Prec@1 100.000 (99.942)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.114)	BT: 0.059 (0.180)	Loss 0.0036 (0.0088)	Prec@1 100.000 (99.942)	
Total train loss: 0.0088
Avg Loading time: 0.1132 seconds
Avg Batch time: 0.1797 seconds

Train time: 70.37800335884094
 * Prec@1 75.570 Prec@5 92.120 Loss 1.0811
Avg Loading time: 0.1581 seconds
Avg Batch time: 0.1860 seconds

Best acc: 75.690
--------------------------------------------------------------------------------
Test time: 15.368896484375

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.132)	BT: 0.067 (0.195)	Loss 0.0039 (0.0099)	Prec@1 100.000 (99.930)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.187 (0.115)	BT: 0.252 (0.181)	Loss 0.0073 (0.0095)	Prec@1 100.000 (99.960)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.357 (0.112)	BT: 0.426 (0.178)	Loss 0.0210 (0.0092)	Prec@1 99.219 (99.963)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.110)	BT: 0.085 (0.177)	Loss 0.0226 (0.0092)	Prec@1 99.219 (99.957)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.110)	BT: 0.059 (0.176)	Loss 0.0087 (0.0092)	Prec@1 100.000 (99.960)	
Total train loss: 0.0092
Avg Loading time: 0.1098 seconds
Avg Batch time: 0.1756 seconds

Train time: 68.77445363998413
 * Prec@1 75.740 Prec@5 92.210 Loss 1.0684
Avg Loading time: 0.1369 seconds
Avg Batch time: 0.1673 seconds

Best acc: 75.740
--------------------------------------------------------------------------------
Test time: 14.37159776687622

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.119)	BT: 0.054 (0.187)	Loss 0.0035 (0.0075)	Prec@1 100.000 (99.960)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.109)	BT: 0.090 (0.178)	Loss 0.0049 (0.0080)	Prec@1 100.000 (99.955)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.112)	BT: 0.065 (0.181)	Loss 0.0062 (0.0084)	Prec@1 100.000 (99.953)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.109)	BT: 0.060 (0.178)	Loss 0.0116 (0.0085)	Prec@1 100.000 (99.955)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.114)	BT: 0.059 (0.182)	Loss 0.0114 (0.0086)	Prec@1 100.000 (99.954)	
Total train loss: 0.0086
Avg Loading time: 0.1133 seconds
Avg Batch time: 0.1819 seconds

Train time: 71.25246214866638
 * Prec@1 75.250 Prec@5 92.080 Loss 1.0791
Avg Loading time: 0.1791 seconds
Avg Batch time: 0.2046 seconds

Best acc: 75.740
--------------------------------------------------------------------------------
Test time: 16.83069658279419

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.108)	BT: 0.117 (0.176)	Loss 0.0082 (0.0083)	Prec@1 100.000 (99.970)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.100)	BT: 0.079 (0.166)	Loss 0.0143 (0.0085)	Prec@1 100.000 (99.955)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.114 (0.103)	BT: 0.169 (0.168)	Loss 0.0066 (0.0086)	Prec@1 100.000 (99.957)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.105)	BT: 0.077 (0.172)	Loss 0.0190 (0.0086)	Prec@1 99.219 (99.955)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.110)	BT: 0.059 (0.177)	Loss 0.0055 (0.0088)	Prec@1 100.000 (99.950)	
Total train loss: 0.0088
Avg Loading time: 0.1098 seconds
Avg Batch time: 0.1766 seconds

Train time: 69.17280530929565
 * Prec@1 75.330 Prec@5 92.280 Loss 1.0752
Avg Loading time: 0.1448 seconds
Avg Batch time: 0.1719 seconds

Best acc: 75.740
--------------------------------------------------------------------------------
Test time: 14.241956949234009

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.091)	BT: 0.058 (0.164)	Loss 0.0125 (0.0085)	Prec@1 100.000 (99.970)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.086)	BT: 0.087 (0.159)	Loss 0.0140 (0.0087)	Prec@1 100.000 (99.965)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.073)	BT: 0.080 (0.146)	Loss 0.0136 (0.0087)	Prec@1 100.000 (99.967)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.073 (0.068)	BT: 0.130 (0.142)	Loss 0.0060 (0.0087)	Prec@1 100.000 (99.967)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.077)	BT: 0.058 (0.151)	Loss 0.0121 (0.0091)	Prec@1 100.000 (99.960)	
Total train loss: 0.0091
Avg Loading time: 0.0773 seconds
Avg Batch time: 0.1504 seconds

Train time: 58.88360810279846
 * Prec@1 75.410 Prec@5 92.190 Loss 1.0820
Avg Loading time: 0.1461 seconds
Avg Batch time: 0.1747 seconds

Best acc: 75.740
--------------------------------------------------------------------------------
Test time: 14.431283235549927


      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 7
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar100/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/train/relu7
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/test/relu7
ResNet18(
  (conv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=100, bias=False)
  (bn19): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 0.990 Prec@5 4.780 Loss 4.6055
Avg Loading time: 0.9479 seconds
Avg Batch time: 0.9722 seconds

Pre-trained Prec@1 with 7 layers frozen: 0.9899999499320984 	 Loss: 4.60546875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (1.322)	BT: 0.046 (1.369)	Loss 2.0898 (2.3720)	Prec@1 47.656 (42.077)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.010 (1.317)	BT: 0.057 (1.365)	Loss 1.6387 (2.0464)	Prec@1 54.688 (47.691)	
Epoch: [0][233/391]	LR: 0.1	DT: 2.394 (1.407)	BT: 2.447 (1.454)	Loss 1.4365 (1.8704)	Prec@1 59.375 (51.082)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (1.455)	BT: 0.038 (1.503)	Loss 1.5254 (1.7677)	Prec@1 60.938 (53.057)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (1.514)	BT: 0.043 (1.562)	Loss 1.3408 (1.6859)	Prec@1 58.594 (54.760)	
Total train loss: 1.6856
Avg Loading time: 1.5100 seconds
Avg Batch time: 1.5578 seconds

Train time: 609.1989986896515
 * Prec@1 59.400 Prec@5 86.550 Loss 1.4824
Avg Loading time: 0.1245 seconds
Avg Batch time: 0.1396 seconds

Best acc: 59.400
--------------------------------------------------------------------------------
Test time: 12.131740808486938

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.135)	BT: 0.042 (0.176)	Loss 1.1182 (1.0200)	Prec@1 60.938 (70.693)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.114)	BT: 0.039 (0.155)	Loss 0.8389 (1.0267)	Prec@1 76.562 (70.287)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.108)	BT: 0.040 (0.149)	Loss 1.2148 (1.0371)	Prec@1 66.406 (69.925)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.100)	BT: 0.039 (0.142)	Loss 1.0137 (1.0476)	Prec@1 70.312 (69.579)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.097)	BT: 0.039 (0.139)	Loss 1.1309 (1.0500)	Prec@1 71.094 (69.559)	
Total train loss: 1.0502
Avg Loading time: 0.0968 seconds
Avg Batch time: 0.1392 seconds

Train time: 54.52269649505615
 * Prec@1 65.920 Prec@5 90.220 Loss 1.2148
Avg Loading time: 0.1258 seconds
Avg Batch time: 0.1428 seconds

Best acc: 65.920
--------------------------------------------------------------------------------
Test time: 12.407649993896484

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.121)	BT: 0.044 (0.165)	Loss 0.7026 (0.6943)	Prec@1 81.250 (79.467)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.116)	BT: 0.049 (0.159)	Loss 0.6025 (0.7286)	Prec@1 82.812 (78.035)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.191 (0.108)	BT: 0.229 (0.151)	Loss 0.8491 (0.7534)	Prec@1 75.781 (77.404)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.102)	BT: 0.052 (0.146)	Loss 0.9468 (0.7727)	Prec@1 69.531 (76.830)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.101)	BT: 0.040 (0.145)	Loss 0.7695 (0.7877)	Prec@1 77.344 (76.370)	
Total train loss: 0.7881
Avg Loading time: 0.1010 seconds
Avg Batch time: 0.1446 seconds

Train time: 56.71938419342041
 * Prec@1 66.340 Prec@5 90.130 Loss 1.2275
Avg Loading time: 0.1490 seconds
Avg Batch time: 0.1664 seconds

Best acc: 66.340
--------------------------------------------------------------------------------
Test time: 14.240097761154175

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.112)	BT: 0.037 (0.156)	Loss 0.3699 (0.5300)	Prec@1 88.281 (83.634)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.104)	BT: 0.058 (0.150)	Loss 0.5010 (0.5322)	Prec@1 82.031 (83.719)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.174 (0.098)	BT: 0.223 (0.143)	Loss 0.6279 (0.5594)	Prec@1 80.469 (82.686)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.102)	BT: 0.047 (0.147)	Loss 0.5879 (0.5741)	Prec@1 79.688 (82.259)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.099)	BT: 0.041 (0.144)	Loss 0.7847 (0.5909)	Prec@1 77.344 (81.891)	
Total train loss: 0.5913
Avg Loading time: 0.0991 seconds
Avg Batch time: 0.1441 seconds

Train time: 56.47832536697388
 * Prec@1 66.110 Prec@5 90.650 Loss 1.2422
Avg Loading time: 0.1565 seconds
Avg Batch time: 0.1720 seconds

Best acc: 66.340
--------------------------------------------------------------------------------
Test time: 14.25200366973877

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.074)	BT: 0.040 (0.119)	Loss 0.4363 (0.3722)	Prec@1 86.719 (88.812)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.074)	BT: 0.039 (0.119)	Loss 0.5483 (0.3878)	Prec@1 81.250 (88.196)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.082)	BT: 0.039 (0.127)	Loss 0.4280 (0.4039)	Prec@1 85.938 (87.794)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.084)	BT: 0.040 (0.130)	Loss 0.5884 (0.4220)	Prec@1 77.344 (87.129)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.088)	BT: 0.040 (0.133)	Loss 0.4719 (0.4447)	Prec@1 84.375 (86.326)	
Total train loss: 0.4446
Avg Loading time: 0.0878 seconds
Avg Batch time: 0.1331 seconds

Train time: 52.17533278465271
 * Prec@1 66.510 Prec@5 89.300 Loss 1.3164
Avg Loading time: 0.1262 seconds
Avg Batch time: 0.1436 seconds

Best acc: 66.510
--------------------------------------------------------------------------------
Test time: 12.456769466400146

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.108)	BT: 0.040 (0.152)	Loss 0.2981 (0.2960)	Prec@1 92.969 (90.795)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.094)	BT: 0.040 (0.140)	Loss 0.3311 (0.3009)	Prec@1 89.844 (90.840)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.000 (0.096)	BT: 0.055 (0.141)	Loss 0.4607 (0.3064)	Prec@1 83.594 (90.585)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.094)	BT: 0.044 (0.138)	Loss 0.3037 (0.3187)	Prec@1 92.188 (90.177)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.096)	BT: 0.040 (0.140)	Loss 0.5220 (0.3367)	Prec@1 85.156 (89.597)	
Total train loss: 0.3367
Avg Loading time: 0.0958 seconds
Avg Batch time: 0.1398 seconds

Train time: 54.829891204833984
 * Prec@1 66.240 Prec@5 89.160 Loss 1.3965
Avg Loading time: 0.1131 seconds
Avg Batch time: 0.1309 seconds

Best acc: 66.510
--------------------------------------------------------------------------------
Test time: 10.96656608581543

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.100)	BT: 0.040 (0.145)	Loss 0.2148 (0.2305)	Prec@1 93.750 (93.049)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.092 (0.091)	BT: 0.138 (0.137)	Loss 0.3977 (0.2421)	Prec@1 88.281 (92.483)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.089)	BT: 0.040 (0.134)	Loss 0.2290 (0.2504)	Prec@1 92.188 (92.291)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.093)	BT: 0.040 (0.137)	Loss 0.3835 (0.2591)	Prec@1 88.281 (92.032)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.091)	BT: 0.039 (0.136)	Loss 0.3340 (0.2704)	Prec@1 89.062 (91.663)	
Total train loss: 0.2708
Avg Loading time: 0.0907 seconds
Avg Batch time: 0.1354 seconds

Train time: 53.04572939872742
 * Prec@1 67.130 Prec@5 89.510 Loss 1.3848
Avg Loading time: 0.1652 seconds
Avg Batch time: 0.1819 seconds

Best acc: 67.130
--------------------------------------------------------------------------------
Test time: 15.493097305297852

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.093)	BT: 0.038 (0.135)	Loss 0.1066 (0.1890)	Prec@1 97.656 (94.581)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.099)	BT: 0.050 (0.142)	Loss 0.2213 (0.1789)	Prec@1 93.750 (94.827)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.106)	BT: 0.047 (0.151)	Loss 0.1942 (0.1834)	Prec@1 95.312 (94.658)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.100)	BT: 0.040 (0.145)	Loss 0.1968 (0.1934)	Prec@1 95.312 (94.313)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.099)	BT: 0.037 (0.143)	Loss 0.2318 (0.2064)	Prec@1 92.188 (93.862)	
Total train loss: 0.2070
Avg Loading time: 0.0988 seconds
Avg Batch time: 0.1431 seconds

Train time: 56.11580300331116
 * Prec@1 66.600 Prec@5 88.900 Loss 1.4443
Avg Loading time: 0.1351 seconds
Avg Batch time: 0.1522 seconds

Best acc: 67.130
--------------------------------------------------------------------------------
Test time: 12.711625337600708

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.090)	BT: 0.039 (0.134)	Loss 0.1836 (0.1641)	Prec@1 94.531 (95.212)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.087)	BT: 0.040 (0.130)	Loss 0.1709 (0.1604)	Prec@1 93.750 (95.333)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.114 (0.088)	BT: 0.156 (0.131)	Loss 0.2610 (0.1620)	Prec@1 89.844 (95.309)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.083)	BT: 0.041 (0.125)	Loss 0.1591 (0.1669)	Prec@1 95.312 (95.147)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.214 (0.086)	BT: 0.255 (0.129)	Loss 0.2527 (0.1736)	Prec@1 92.969 (94.874)	
Total train loss: 0.1738
Avg Loading time: 0.0856 seconds
Avg Batch time: 0.1288 seconds

Train time: 50.52383589744568
 * Prec@1 66.980 Prec@5 89.020 Loss 1.4082
Avg Loading time: 0.1399 seconds
Avg Batch time: 0.1582 seconds

Best acc: 67.130
--------------------------------------------------------------------------------
Test time: 13.150099754333496

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.105)	BT: 0.039 (0.148)	Loss 0.1859 (0.1394)	Prec@1 93.750 (95.964)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.097)	BT: 0.040 (0.140)	Loss 0.1188 (0.1389)	Prec@1 97.656 (96.034)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.095)	BT: 0.040 (0.138)	Loss 0.1451 (0.1436)	Prec@1 94.531 (95.810)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.097)	BT: 0.040 (0.140)	Loss 0.1605 (0.1504)	Prec@1 96.094 (95.585)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.100)	BT: 0.059 (0.144)	Loss 0.2401 (0.1568)	Prec@1 90.625 (95.399)	
Total train loss: 0.1571
Avg Loading time: 0.0994 seconds
Avg Batch time: 0.1434 seconds

Train time: 56.178141832351685
 * Prec@1 68.210 Prec@5 89.830 Loss 1.3643
Avg Loading time: 0.1496 seconds
Avg Batch time: 0.1658 seconds

Best acc: 68.210
--------------------------------------------------------------------------------
Test time: 14.270113945007324

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.099)	BT: 0.046 (0.145)	Loss 0.0366 (0.0902)	Prec@1 99.219 (97.606)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.094)	BT: 0.039 (0.139)	Loss 0.0418 (0.0775)	Prec@1 99.219 (98.032)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.335 (0.091)	BT: 0.383 (0.136)	Loss 0.0193 (0.0701)	Prec@1 100.000 (98.241)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.092)	BT: 0.039 (0.138)	Loss 0.0373 (0.0654)	Prec@1 99.219 (98.417)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.096)	BT: 0.039 (0.141)	Loss 0.0433 (0.0616)	Prec@1 99.219 (98.548)	
Total train loss: 0.0616
Avg Loading time: 0.0954 seconds
Avg Batch time: 0.1412 seconds

Train time: 55.28565263748169
 * Prec@1 74.010 Prec@5 92.250 Loss 1.0820
Avg Loading time: 0.1394 seconds
Avg Batch time: 0.1560 seconds

Best acc: 74.010
--------------------------------------------------------------------------------
Test time: 13.446078062057495

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.082)	BT: 0.041 (0.127)	Loss 0.0246 (0.0262)	Prec@1 99.219 (99.639)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.093)	BT: 0.044 (0.137)	Loss 0.0354 (0.0264)	Prec@1 100.000 (99.609)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.105)	BT: 0.041 (0.148)	Loss 0.0111 (0.0264)	Prec@1 100.000 (99.609)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.104)	BT: 0.042 (0.149)	Loss 0.0327 (0.0264)	Prec@1 99.219 (99.609)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.105)	BT: 0.039 (0.150)	Loss 0.0142 (0.0260)	Prec@1 100.000 (99.617)	
Total train loss: 0.0260
Avg Loading time: 0.1048 seconds
Avg Batch time: 0.1492 seconds

Train time: 58.448766469955444
 * Prec@1 74.310 Prec@5 92.340 Loss 1.0830
Avg Loading time: 0.1351 seconds
Avg Batch time: 0.1516 seconds

Best acc: 74.310
--------------------------------------------------------------------------------
Test time: 13.225666284561157

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.122)	BT: 0.040 (0.165)	Loss 0.0147 (0.0174)	Prec@1 100.000 (99.870)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.101)	BT: 0.041 (0.146)	Loss 0.0198 (0.0181)	Prec@1 99.219 (99.820)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.061 (0.092)	BT: 0.122 (0.139)	Loss 0.0058 (0.0186)	Prec@1 100.000 (99.796)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.094)	BT: 0.040 (0.140)	Loss 0.0164 (0.0187)	Prec@1 100.000 (99.790)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.094)	BT: 0.040 (0.140)	Loss 0.0207 (0.0191)	Prec@1 99.219 (99.772)	
Total train loss: 0.0191
Avg Loading time: 0.0937 seconds
Avg Batch time: 0.1394 seconds

Train time: 54.64201617240906
 * Prec@1 74.660 Prec@5 92.380 Loss 1.0771
Avg Loading time: 0.1139 seconds
Avg Batch time: 0.1304 seconds

Best acc: 74.660
--------------------------------------------------------------------------------
Test time: 11.41100788116455

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.092)	BT: 0.054 (0.138)	Loss 0.0116 (0.0153)	Prec@1 100.000 (99.900)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.088)	BT: 0.042 (0.134)	Loss 0.0290 (0.0159)	Prec@1 99.219 (99.870)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.088)	BT: 0.040 (0.133)	Loss 0.0156 (0.0156)	Prec@1 100.000 (99.870)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.082)	BT: 0.053 (0.127)	Loss 0.0090 (0.0157)	Prec@1 100.000 (99.867)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.080)	BT: 0.039 (0.126)	Loss 0.0064 (0.0155)	Prec@1 100.000 (99.860)	
Total train loss: 0.0156
Avg Loading time: 0.0800 seconds
Avg Batch time: 0.1258 seconds

Train time: 49.27320885658264
 * Prec@1 74.620 Prec@5 92.340 Loss 1.0752
Avg Loading time: 0.1398 seconds
Avg Batch time: 0.1572 seconds

Best acc: 74.660
--------------------------------------------------------------------------------
Test time: 13.080119132995605

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.042)	BT: 0.054 (0.091)	Loss 0.0146 (0.0136)	Prec@1 100.000 (99.920)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.039)	BT: 0.045 (0.087)	Loss 0.0126 (0.0137)	Prec@1 100.000 (99.910)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.042 (0.038)	BT: 0.088 (0.086)	Loss 0.0234 (0.0138)	Prec@1 99.219 (99.897)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.054 (0.032)	BT: 0.111 (0.081)	Loss 0.0173 (0.0138)	Prec@1 100.000 (99.895)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.028)	BT: 0.041 (0.078)	Loss 0.0619 (0.0138)	Prec@1 99.219 (99.890)	
Total train loss: 0.0139
Avg Loading time: 0.0275 seconds
Avg Batch time: 0.0781 seconds

Train time: 30.68358302116394
 * Prec@1 74.590 Prec@5 92.210 Loss 1.0859
Avg Loading time: 0.0728 seconds
Avg Batch time: 0.0904 seconds

Best acc: 74.660
--------------------------------------------------------------------------------
Test time: 7.789310693740845

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.103)	BT: 0.040 (0.147)	Loss 0.0095 (0.0130)	Prec@1 100.000 (99.880)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.076)	BT: 0.066 (0.123)	Loss 0.0084 (0.0130)	Prec@1 100.000 (99.890)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.062)	BT: 0.052 (0.109)	Loss 0.0051 (0.0130)	Prec@1 100.000 (99.883)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.057)	BT: 0.040 (0.104)	Loss 0.0092 (0.0129)	Prec@1 100.000 (99.892)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.058)	BT: 0.038 (0.104)	Loss 0.0248 (0.0128)	Prec@1 99.219 (99.896)	
Total train loss: 0.0130
Avg Loading time: 0.0578 seconds
Avg Batch time: 0.1042 seconds

Train time: 40.86354374885559
 * Prec@1 74.790 Prec@5 92.360 Loss 1.0791
Avg Loading time: 0.0982 seconds
Avg Batch time: 0.1174 seconds

Best acc: 74.790
--------------------------------------------------------------------------------
Test time: 10.425305604934692

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.167 (0.089)	BT: 0.208 (0.135)	Loss 0.0110 (0.0119)	Prec@1 100.000 (99.910)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.074)	BT: 0.056 (0.121)	Loss 0.0102 (0.0120)	Prec@1 100.000 (99.890)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.205 (0.067)	BT: 0.252 (0.114)	Loss 0.0110 (0.0116)	Prec@1 100.000 (99.900)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.067)	BT: 0.040 (0.114)	Loss 0.0144 (0.0116)	Prec@1 100.000 (99.905)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.070)	BT: 0.041 (0.116)	Loss 0.0122 (0.0119)	Prec@1 100.000 (99.900)	
Total train loss: 0.0119
Avg Loading time: 0.0697 seconds
Avg Batch time: 0.1158 seconds

Train time: 45.42155742645264
 * Prec@1 75.070 Prec@5 92.500 Loss 1.0771
Avg Loading time: 0.0908 seconds
Avg Batch time: 0.1111 seconds

Best acc: 75.070
--------------------------------------------------------------------------------
Test time: 10.603485107421875

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.086)	BT: 0.040 (0.129)	Loss 0.0122 (0.0100)	Prec@1 99.219 (99.950)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.071)	BT: 0.047 (0.115)	Loss 0.0057 (0.0103)	Prec@1 100.000 (99.925)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.139 (0.061)	BT: 0.188 (0.107)	Loss 0.0075 (0.0104)	Prec@1 100.000 (99.923)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.064)	BT: 0.039 (0.111)	Loss 0.0121 (0.0104)	Prec@1 100.000 (99.925)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.063)	BT: 0.038 (0.110)	Loss 0.0068 (0.0107)	Prec@1 100.000 (99.926)	
Total train loss: 0.0108
Avg Loading time: 0.0630 seconds
Avg Batch time: 0.1100 seconds

Train time: 43.1275155544281
 * Prec@1 74.810 Prec@5 92.340 Loss 1.0820
Avg Loading time: 0.1064 seconds
Avg Batch time: 0.1242 seconds

Best acc: 75.070
--------------------------------------------------------------------------------
Test time: 10.480214357376099

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.065)	BT: 0.040 (0.113)	Loss 0.0149 (0.0093)	Prec@1 100.000 (99.950)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.067)	BT: 0.051 (0.115)	Loss 0.0070 (0.0094)	Prec@1 100.000 (99.930)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.068)	BT: 0.068 (0.114)	Loss 0.0044 (0.0095)	Prec@1 100.000 (99.933)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.064)	BT: 0.051 (0.110)	Loss 0.0052 (0.0095)	Prec@1 100.000 (99.935)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.060)	BT: 0.054 (0.106)	Loss 0.0156 (0.0098)	Prec@1 100.000 (99.940)	
Total train loss: 0.0098
Avg Loading time: 0.0594 seconds
Avg Batch time: 0.1056 seconds

Train time: 41.405176401138306
 * Prec@1 74.810 Prec@5 92.230 Loss 1.0840
Avg Loading time: 0.0720 seconds
Avg Batch time: 0.0910 seconds

Best acc: 75.070
--------------------------------------------------------------------------------
Test time: 7.890547275543213

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.031)	BT: 0.048 (0.080)	Loss 0.0090 (0.0098)	Prec@1 100.000 (99.900)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.063 (0.017)	BT: 0.101 (0.065)	Loss 0.0121 (0.0095)	Prec@1 100.000 (99.930)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.027)	BT: 0.039 (0.073)	Loss 0.0091 (0.0098)	Prec@1 100.000 (99.937)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 1.312 (0.059)	BT: 1.365 (0.105)	Loss 0.0036 (0.0098)	Prec@1 100.000 (99.935)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.109)	BT: 0.045 (0.155)	Loss 0.0059 (0.0099)	Prec@1 100.000 (99.930)	
Total train loss: 0.0100
Avg Loading time: 0.1085 seconds
Avg Batch time: 0.1543 seconds

Train time: 60.4531626701355
 * Prec@1 75.060 Prec@5 92.200 Loss 1.0859
Avg Loading time: 0.1399 seconds
Avg Batch time: 0.1569 seconds

Best acc: 75.070
--------------------------------------------------------------------------------
Test time: 13.01666522026062

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.114)	BT: 0.041 (0.157)	Loss 0.0087 (0.0080)	Prec@1 100.000 (99.970)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.143)	BT: 0.047 (0.186)	Loss 0.0049 (0.0085)	Prec@1 100.000 (99.955)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 2.270 (0.194)	BT: 2.321 (0.238)	Loss 0.0084 (0.0086)	Prec@1 100.000 (99.953)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.236)	BT: 0.041 (0.280)	Loss 0.0092 (0.0085)	Prec@1 100.000 (99.950)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.302)	BT: 0.046 (0.347)	Loss 0.0102 (0.0086)	Prec@1 100.000 (99.952)	
Total train loss: 0.0086
Avg Loading time: 0.3015 seconds
Avg Batch time: 0.3457 seconds

Train time: 135.27320504188538
 * Prec@1 75.060 Prec@5 92.150 Loss 1.0859
Avg Loading time: 0.5826 seconds
Avg Batch time: 0.6000 seconds

Best acc: 75.070
--------------------------------------------------------------------------------
Test time: 48.05643320083618

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.753)	BT: 0.040 (0.797)	Loss 0.0058 (0.0086)	Prec@1 100.000 (99.980)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.682)	BT: 0.044 (0.726)	Loss 0.0081 (0.0084)	Prec@1 100.000 (99.970)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.650)	BT: 0.047 (0.695)	Loss 0.0032 (0.0085)	Prec@1 100.000 (99.963)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.625)	BT: 0.047 (0.670)	Loss 0.0078 (0.0084)	Prec@1 100.000 (99.957)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.618)	BT: 0.047 (0.663)	Loss 0.0079 (0.0086)	Prec@1 100.000 (99.954)	
Total train loss: 0.0087
Avg Loading time: 0.6163 seconds
Avg Batch time: 0.6612 seconds

Train time: 258.63044357299805
 * Prec@1 74.970 Prec@5 92.320 Loss 1.0840
Avg Loading time: 0.5588 seconds
Avg Batch time: 0.5761 seconds

Best acc: 75.070
--------------------------------------------------------------------------------
Test time: 46.13145184516907

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.143)	BT: 0.052 (0.185)	Loss 0.0043 (0.0082)	Prec@1 100.000 (99.960)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.175 (0.133)	BT: 0.213 (0.176)	Loss 0.0110 (0.0087)	Prec@1 100.000 (99.960)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.133)	BT: 0.039 (0.176)	Loss 0.0059 (0.0085)	Prec@1 100.000 (99.970)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.129)	BT: 0.038 (0.172)	Loss 0.0054 (0.0086)	Prec@1 100.000 (99.955)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.124)	BT: 0.039 (0.167)	Loss 0.0172 (0.0086)	Prec@1 100.000 (99.950)	
Total train loss: 0.0086
Avg Loading time: 0.1237 seconds
Avg Batch time: 0.1670 seconds

Train time: 65.39237380027771
 * Prec@1 75.210 Prec@5 92.200 Loss 1.0811
Avg Loading time: 0.1201 seconds
Avg Batch time: 0.1361 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 11.863341808319092

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.107)	BT: 0.040 (0.152)	Loss 0.0080 (0.0101)	Prec@1 100.000 (99.930)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.127 (0.113)	BT: 0.167 (0.158)	Loss 0.0039 (0.0093)	Prec@1 100.000 (99.930)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.678 (0.113)	BT: 0.735 (0.158)	Loss 0.0127 (0.0089)	Prec@1 100.000 (99.940)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.113)	BT: 0.065 (0.158)	Loss 0.0096 (0.0091)	Prec@1 100.000 (99.937)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.107)	BT: 0.039 (0.151)	Loss 0.0111 (0.0088)	Prec@1 100.000 (99.946)	
Total train loss: 0.0088
Avg Loading time: 0.1063 seconds
Avg Batch time: 0.1512 seconds

Train time: 59.24134039878845
 * Prec@1 75.140 Prec@5 92.220 Loss 1.0801
Avg Loading time: 0.1315 seconds
Avg Batch time: 0.1482 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 12.372725248336792

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.094)	BT: 0.047 (0.139)	Loss 0.0024 (0.0086)	Prec@1 100.000 (99.930)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.097)	BT: 0.040 (0.143)	Loss 0.0044 (0.0088)	Prec@1 100.000 (99.930)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.102)	BT: 0.039 (0.147)	Loss 0.0115 (0.0092)	Prec@1 100.000 (99.920)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.105)	BT: 0.040 (0.150)	Loss 0.0093 (0.0090)	Prec@1 100.000 (99.927)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.102)	BT: 0.047 (0.147)	Loss 0.0119 (0.0089)	Prec@1 100.000 (99.940)	
Total train loss: 0.0089
Avg Loading time: 0.1015 seconds
Avg Batch time: 0.1467 seconds

Train time: 57.49121975898743
 * Prec@1 74.830 Prec@5 92.270 Loss 1.0820
Avg Loading time: 0.1297 seconds
Avg Batch time: 0.1468 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 12.41214108467102

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.038 (0.156)	BT: 0.077 (0.200)	Loss 0.0030 (0.0083)	Prec@1 100.000 (99.950)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.127)	BT: 0.037 (0.171)	Loss 0.0103 (0.0087)	Prec@1 100.000 (99.955)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.117 (0.117)	BT: 0.155 (0.161)	Loss 0.0071 (0.0086)	Prec@1 100.000 (99.963)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.113)	BT: 0.039 (0.157)	Loss 0.0084 (0.0087)	Prec@1 100.000 (99.960)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.112)	BT: 0.039 (0.156)	Loss 0.0055 (0.0086)	Prec@1 100.000 (99.954)	
Total train loss: 0.0087
Avg Loading time: 0.1118 seconds
Avg Batch time: 0.1560 seconds

Train time: 61.140743017196655
 * Prec@1 74.980 Prec@5 92.250 Loss 1.0791
Avg Loading time: 0.1236 seconds
Avg Batch time: 0.1419 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 11.875134229660034

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.108)	BT: 0.040 (0.152)	Loss 0.0065 (0.0087)	Prec@1 100.000 (99.940)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.106)	BT: 0.044 (0.150)	Loss 0.0093 (0.0083)	Prec@1 100.000 (99.960)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.104)	BT: 0.046 (0.149)	Loss 0.0062 (0.0080)	Prec@1 100.000 (99.963)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.102)	BT: 0.040 (0.146)	Loss 0.0237 (0.0078)	Prec@1 99.219 (99.970)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.102)	BT: 0.052 (0.146)	Loss 0.0084 (0.0080)	Prec@1 100.000 (99.964)	
Total train loss: 0.0080
Avg Loading time: 0.1013 seconds
Avg Batch time: 0.1460 seconds

Train time: 57.191521406173706
 * Prec@1 74.800 Prec@5 92.040 Loss 1.0820
Avg Loading time: 0.1474 seconds
Avg Batch time: 0.1662 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 13.773528337478638

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.089)	BT: 0.049 (0.133)	Loss 0.0111 (0.0088)	Prec@1 100.000 (99.950)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.086)	BT: 0.043 (0.130)	Loss 0.0068 (0.0081)	Prec@1 100.000 (99.965)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.090)	BT: 0.042 (0.134)	Loss 0.0049 (0.0081)	Prec@1 100.000 (99.967)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.094)	BT: 0.054 (0.139)	Loss 0.0053 (0.0080)	Prec@1 100.000 (99.965)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.098)	BT: 0.038 (0.142)	Loss 0.0054 (0.0081)	Prec@1 100.000 (99.960)	
Total train loss: 0.0081
Avg Loading time: 0.0975 seconds
Avg Batch time: 0.1421 seconds

Train time: 55.72787070274353
 * Prec@1 74.860 Prec@5 92.210 Loss 1.0879
Avg Loading time: 0.1642 seconds
Avg Batch time: 0.1812 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 14.97458529472351

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.102)	BT: 0.041 (0.149)	Loss 0.0029 (0.0082)	Prec@1 100.000 (99.980)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.527 (0.109)	BT: 0.574 (0.155)	Loss 0.0090 (0.0084)	Prec@1 100.000 (99.965)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.055 (0.106)	BT: 0.111 (0.151)	Loss 0.0041 (0.0085)	Prec@1 100.000 (99.960)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.103)	BT: 0.046 (0.149)	Loss 0.0058 (0.0087)	Prec@1 100.000 (99.960)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.104)	BT: 0.043 (0.149)	Loss 0.0080 (0.0087)	Prec@1 100.000 (99.960)	
Total train loss: 0.0087
Avg Loading time: 0.1034 seconds
Avg Batch time: 0.1487 seconds

Train time: 58.26397204399109
 * Prec@1 74.940 Prec@5 92.090 Loss 1.0820
Avg Loading time: 0.1039 seconds
Avg Batch time: 0.1206 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 10.173577070236206

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.099)	BT: 0.038 (0.143)	Loss 0.0046 (0.0091)	Prec@1 100.000 (99.920)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.095)	BT: 0.045 (0.140)	Loss 0.0046 (0.0083)	Prec@1 100.000 (99.935)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 1.039 (0.096)	BT: 1.088 (0.141)	Loss 0.0263 (0.0083)	Prec@1 99.219 (99.933)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.098)	BT: 0.037 (0.143)	Loss 0.0076 (0.0082)	Prec@1 100.000 (99.942)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.093)	BT: 0.037 (0.138)	Loss 0.0201 (0.0083)	Prec@1 100.000 (99.942)	
Total train loss: 0.0083
Avg Loading time: 0.0929 seconds
Avg Batch time: 0.1376 seconds

Train time: 53.89243745803833
 * Prec@1 75.010 Prec@5 92.170 Loss 1.0879
Avg Loading time: 0.1577 seconds
Avg Batch time: 0.1760 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 14.581677436828613

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.107)	BT: 0.040 (0.151)	Loss 0.0039 (0.0100)	Prec@1 100.000 (99.890)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.103)	BT: 0.048 (0.146)	Loss 0.0073 (0.0095)	Prec@1 100.000 (99.925)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.101)	BT: 0.039 (0.144)	Loss 0.0047 (0.0091)	Prec@1 100.000 (99.937)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.251 (0.099)	BT: 0.300 (0.142)	Loss 0.0069 (0.0089)	Prec@1 100.000 (99.947)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.100)	BT: 0.038 (0.143)	Loss 0.0056 (0.0089)	Prec@1 100.000 (99.950)	
Total train loss: 0.0089
Avg Loading time: 0.0996 seconds
Avg Batch time: 0.1426 seconds

Train time: 55.915653228759766
 * Prec@1 75.140 Prec@5 92.270 Loss 1.0840
Avg Loading time: 0.1605 seconds
Avg Batch time: 0.1772 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 14.668949127197266

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.001 (0.093)	BT: 0.043 (0.136)	Loss 0.0050 (0.0086)	Prec@1 100.000 (99.950)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.089)	BT: 0.040 (0.132)	Loss 0.0028 (0.0090)	Prec@1 100.000 (99.940)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.096)	BT: 0.041 (0.140)	Loss 0.0112 (0.0089)	Prec@1 100.000 (99.947)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.095)	BT: 0.050 (0.139)	Loss 0.0089 (0.0089)	Prec@1 100.000 (99.952)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.098)	BT: 0.039 (0.142)	Loss 0.0067 (0.0090)	Prec@1 100.000 (99.948)	
Total train loss: 0.0090
Avg Loading time: 0.0973 seconds
Avg Batch time: 0.1414 seconds

Train time: 55.40295386314392
 * Prec@1 74.870 Prec@5 92.050 Loss 1.0947
Avg Loading time: 0.1699 seconds
Avg Batch time: 0.1877 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 15.465702772140503

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.086)	BT: 0.039 (0.132)	Loss 0.0069 (0.0078)	Prec@1 100.000 (99.980)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.087)	BT: 0.045 (0.133)	Loss 0.0089 (0.0081)	Prec@1 100.000 (99.960)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.098)	BT: 0.062 (0.144)	Loss 0.0049 (0.0085)	Prec@1 100.000 (99.953)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.100)	BT: 0.038 (0.146)	Loss 0.0040 (0.0085)	Prec@1 100.000 (99.952)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.103)	BT: 0.049 (0.149)	Loss 0.0039 (0.0084)	Prec@1 100.000 (99.958)	
Total train loss: 0.0085
Avg Loading time: 0.1032 seconds
Avg Batch time: 0.1489 seconds

Train time: 58.32712960243225
 * Prec@1 74.860 Prec@5 92.240 Loss 1.0850
Avg Loading time: 0.1437 seconds
Avg Batch time: 0.1588 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 13.18615174293518

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.158)	BT: 0.052 (0.202)	Loss 0.0062 (0.0080)	Prec@1 100.000 (99.970)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.122)	BT: 0.044 (0.167)	Loss 0.0058 (0.0084)	Prec@1 100.000 (99.975)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 1.083 (0.119)	BT: 1.145 (0.163)	Loss 0.0053 (0.0085)	Prec@1 100.000 (99.967)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.117)	BT: 0.041 (0.161)	Loss 0.0085 (0.0084)	Prec@1 100.000 (99.962)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.125)	BT: 0.043 (0.169)	Loss 0.0067 (0.0083)	Prec@1 100.000 (99.970)	
Total train loss: 0.0083
Avg Loading time: 0.1245 seconds
Avg Batch time: 0.1685 seconds

Train time: 65.98265099525452
 * Prec@1 75.100 Prec@5 92.190 Loss 1.0820
Avg Loading time: 0.0969 seconds
Avg Batch time: 0.1156 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 9.792787551879883

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.218)	BT: 0.044 (0.263)	Loss 0.0056 (0.0087)	Prec@1 100.000 (99.940)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.229)	BT: 0.040 (0.274)	Loss 0.0042 (0.0083)	Prec@1 100.000 (99.940)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.179)	BT: 0.040 (0.223)	Loss 0.0075 (0.0082)	Prec@1 100.000 (99.937)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.152)	BT: 0.039 (0.196)	Loss 0.0061 (0.0084)	Prec@1 100.000 (99.937)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.141)	BT: 0.049 (0.184)	Loss 0.0103 (0.0085)	Prec@1 100.000 (99.946)	
Total train loss: 0.0085
Avg Loading time: 0.1402 seconds
Avg Batch time: 0.1840 seconds

Train time: 72.07075953483582
 * Prec@1 74.860 Prec@5 92.130 Loss 1.0830
Avg Loading time: 0.1077 seconds
Avg Batch time: 0.1249 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 10.508930683135986

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.062)	BT: 0.048 (0.108)	Loss 0.0058 (0.0082)	Prec@1 100.000 (99.980)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.039)	BT: 0.067 (0.088)	Loss 0.0151 (0.0082)	Prec@1 100.000 (99.985)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.034)	BT: 0.059 (0.083)	Loss 0.0171 (0.0083)	Prec@1 100.000 (99.980)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.162 (0.040)	BT: 0.210 (0.089)	Loss 0.0071 (0.0082)	Prec@1 100.000 (99.977)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.042)	BT: 0.040 (0.091)	Loss 0.0072 (0.0082)	Prec@1 100.000 (99.978)	
Total train loss: 0.0082
Avg Loading time: 0.0422 seconds
Avg Batch time: 0.0905 seconds

Train time: 35.49463152885437
 * Prec@1 75.090 Prec@5 92.170 Loss 1.0811
Avg Loading time: 0.0749 seconds
Avg Batch time: 0.0927 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 7.993844509124756

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.050)	BT: 0.040 (0.099)	Loss 0.0081 (0.0080)	Prec@1 100.000 (99.940)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.086 (0.044)	BT: 0.134 (0.092)	Loss 0.0035 (0.0084)	Prec@1 100.000 (99.920)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.040)	BT: 0.053 (0.089)	Loss 0.0078 (0.0083)	Prec@1 100.000 (99.937)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.037)	BT: 0.039 (0.087)	Loss 0.0037 (0.0083)	Prec@1 100.000 (99.942)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.041)	BT: 0.039 (0.090)	Loss 0.0078 (0.0083)	Prec@1 100.000 (99.946)	
Total train loss: 0.0083
Avg Loading time: 0.0412 seconds
Avg Batch time: 0.0894 seconds

Train time: 35.08056950569153
 * Prec@1 74.860 Prec@5 92.230 Loss 1.0908
Avg Loading time: 0.0805 seconds
Avg Batch time: 0.0979 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 8.37234616279602

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.048)	BT: 0.064 (0.097)	Loss 0.0037 (0.0087)	Prec@1 100.000 (99.960)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.046)	BT: 0.051 (0.095)	Loss 0.0077 (0.0084)	Prec@1 100.000 (99.955)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.217 (0.046)	BT: 0.265 (0.094)	Loss 0.0089 (0.0081)	Prec@1 100.000 (99.957)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.100 (0.048)	BT: 0.138 (0.095)	Loss 0.0058 (0.0082)	Prec@1 100.000 (99.955)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.042)	BT: 0.038 (0.090)	Loss 0.0051 (0.0081)	Prec@1 100.000 (99.954)	
Total train loss: 0.0081
Avg Loading time: 0.0416 seconds
Avg Batch time: 0.0897 seconds

Train time: 35.21751880645752
 * Prec@1 75.180 Prec@5 92.090 Loss 1.0830
Avg Loading time: 0.0625 seconds
Avg Batch time: 0.0801 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 6.982951641082764

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.003 (0.056)	BT: 0.057 (0.104)	Loss 0.0078 (0.0084)	Prec@1 100.000 (99.980)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.058)	BT: 0.046 (0.106)	Loss 0.0032 (0.0082)	Prec@1 100.000 (99.970)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.320 (0.054)	BT: 0.360 (0.102)	Loss 0.0062 (0.0081)	Prec@1 100.000 (99.970)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.173 (0.047)	BT: 0.220 (0.095)	Loss 0.0086 (0.0081)	Prec@1 100.000 (99.970)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.046)	BT: 0.038 (0.094)	Loss 0.0040 (0.0082)	Prec@1 100.000 (99.966)	
Total train loss: 0.0082
Avg Loading time: 0.0463 seconds
Avg Batch time: 0.0943 seconds

Train time: 37.01613903045654
 * Prec@1 74.910 Prec@5 92.090 Loss 1.0850
Avg Loading time: 0.0800 seconds
Avg Batch time: 0.0983 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 8.426612615585327

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.043)	BT: 0.040 (0.092)	Loss 0.0179 (0.0092)	Prec@1 100.000 (99.980)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.041)	BT: 0.050 (0.089)	Loss 0.0044 (0.0085)	Prec@1 100.000 (99.965)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.294 (0.035)	BT: 0.349 (0.084)	Loss 0.0090 (0.0082)	Prec@1 100.000 (99.967)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.035)	BT: 0.056 (0.084)	Loss 0.0072 (0.0084)	Prec@1 100.000 (99.962)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.038)	BT: 0.040 (0.087)	Loss 0.0052 (0.0083)	Prec@1 100.000 (99.960)	
Total train loss: 0.0083
Avg Loading time: 0.0382 seconds
Avg Batch time: 0.0870 seconds

Train time: 34.1397762298584
 * Prec@1 74.910 Prec@5 92.140 Loss 1.0908
Avg Loading time: 0.0638 seconds
Avg Batch time: 0.0845 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 7.320496559143066

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.046)	BT: 0.057 (0.095)	Loss 0.0055 (0.0084)	Prec@1 100.000 (99.940)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.033)	BT: 0.040 (0.084)	Loss 0.0048 (0.0088)	Prec@1 100.000 (99.920)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.033)	BT: 0.050 (0.084)	Loss 0.0158 (0.0086)	Prec@1 100.000 (99.937)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.402 (0.036)	BT: 0.480 (0.087)	Loss 0.0056 (0.0084)	Prec@1 100.000 (99.945)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.224 (0.038)	BT: 0.265 (0.087)	Loss 0.0068 (0.0082)	Prec@1 100.000 (99.950)	
Total train loss: 0.0082
Avg Loading time: 0.0376 seconds
Avg Batch time: 0.0873 seconds

Train time: 34.30838751792908
 * Prec@1 75.020 Prec@5 92.120 Loss 1.0850
Avg Loading time: 0.0894 seconds
Avg Batch time: 0.1045 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 8.88949203491211

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.039)	BT: 0.041 (0.088)	Loss 0.0067 (0.0085)	Prec@1 100.000 (99.970)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.035)	BT: 0.052 (0.084)	Loss 0.0032 (0.0084)	Prec@1 100.000 (99.975)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.020 (0.032)	BT: 0.059 (0.082)	Loss 0.0058 (0.0081)	Prec@1 100.000 (99.977)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.082 (0.032)	BT: 0.120 (0.082)	Loss 0.0060 (0.0081)	Prec@1 100.000 (99.975)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.095 (0.032)	BT: 0.134 (0.082)	Loss 0.0035 (0.0083)	Prec@1 100.000 (99.964)	
Total train loss: 0.0083
Avg Loading time: 0.0320 seconds
Avg Batch time: 0.0819 seconds

Train time: 32.104345083236694
 * Prec@1 74.900 Prec@5 92.110 Loss 1.0908
Avg Loading time: 0.0584 seconds
Avg Batch time: 0.0778 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 6.826634645462036

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.030)	BT: 0.054 (0.084)	Loss 0.0077 (0.0085)	Prec@1 100.000 (99.960)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.049 (0.076)	Loss 0.0066 (0.0086)	Prec@1 100.000 (99.960)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.026)	BT: 0.041 (0.079)	Loss 0.0060 (0.0085)	Prec@1 100.000 (99.963)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.070 (0.026)	BT: 0.108 (0.077)	Loss 0.0033 (0.0085)	Prec@1 100.000 (99.962)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.028)	BT: 0.042 (0.079)	Loss 0.0045 (0.0084)	Prec@1 100.000 (99.964)	
Total train loss: 0.0085
Avg Loading time: 0.0280 seconds
Avg Batch time: 0.0786 seconds

Train time: 30.893440008163452
 * Prec@1 74.920 Prec@5 92.150 Loss 1.0811
Avg Loading time: 0.0773 seconds
Avg Batch time: 0.0946 seconds

Best acc: 75.210
--------------------------------------------------------------------------------
Test time: 8.147593021392822

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.057)	BT: 0.038 (0.105)	Loss 0.0074 (0.0080)	Prec@1 100.000 (99.950)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.049)	BT: 0.041 (0.096)	Loss 0.0132 (0.0083)	Prec@1 99.219 (99.945)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.023 (0.046)	BT: 0.065 (0.092)	Loss 0.0061 (0.0083)	Prec@1 100.000 (99.947)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.045)	BT: 0.039 (0.092)	Loss 0.0050 (0.0085)	Prec@1 100.000 (99.937)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.049)	BT: 0.040 (0.095)	Loss 0.0093 (0.0082)	Prec@1 100.000 (99.948)	
Total train loss: 0.0083
Avg Loading time: 0.0487 seconds
Avg Batch time: 0.0951 seconds

Train time: 37.31746864318848
 * Prec@1 75.250 Prec@5 92.210 Loss 1.0791
Avg Loading time: 0.0697 seconds
Avg Batch time: 0.0864 seconds

Best acc: 75.250
--------------------------------------------------------------------------------
Test time: 7.929202556610107

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.070)	BT: 0.040 (0.114)	Loss 0.0080 (0.0083)	Prec@1 100.000 (99.940)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.064)	BT: 0.055 (0.111)	Loss 0.0061 (0.0078)	Prec@1 100.000 (99.945)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.195 (0.061)	BT: 0.239 (0.108)	Loss 0.0174 (0.0079)	Prec@1 100.000 (99.960)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.382 (0.061)	BT: 0.450 (0.108)	Loss 0.0067 (0.0080)	Prec@1 100.000 (99.962)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.062)	BT: 0.038 (0.108)	Loss 0.0075 (0.0082)	Prec@1 100.000 (99.958)	
Total train loss: 0.0082
Avg Loading time: 0.0618 seconds
Avg Batch time: 0.1081 seconds

Train time: 42.411664962768555
 * Prec@1 74.940 Prec@5 92.150 Loss 1.0820
Avg Loading time: 0.1083 seconds
Avg Batch time: 0.1255 seconds

Best acc: 75.250
--------------------------------------------------------------------------------
Test time: 10.56046986579895

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.058)	BT: 0.040 (0.104)	Loss 0.0116 (0.0091)	Prec@1 100.000 (99.950)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.054)	BT: 0.039 (0.101)	Loss 0.0074 (0.0084)	Prec@1 100.000 (99.970)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.059)	BT: 0.038 (0.105)	Loss 0.0114 (0.0086)	Prec@1 100.000 (99.953)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.060)	BT: 0.041 (0.106)	Loss 0.0046 (0.0086)	Prec@1 100.000 (99.955)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.065)	BT: 0.039 (0.111)	Loss 0.0148 (0.0085)	Prec@1 100.000 (99.952)	
Total train loss: 0.0086
Avg Loading time: 0.0650 seconds
Avg Batch time: 0.1103 seconds

Train time: 43.22048044204712
 * Prec@1 75.020 Prec@5 92.130 Loss 1.0957
Avg Loading time: 0.1114 seconds
Avg Batch time: 0.1290 seconds

Best acc: 75.250
--------------------------------------------------------------------------------
Test time: 10.842247247695923

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.070)	BT: 0.038 (0.116)	Loss 0.0060 (0.0084)	Prec@1 100.000 (99.930)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.080)	BT: 0.042 (0.126)	Loss 0.0067 (0.0080)	Prec@1 100.000 (99.945)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.085)	BT: 0.042 (0.130)	Loss 0.0039 (0.0082)	Prec@1 100.000 (99.957)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.703 (0.092)	BT: 0.750 (0.137)	Loss 0.0042 (0.0082)	Prec@1 100.000 (99.957)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.407 (0.101)	BT: 0.450 (0.146)	Loss 0.0036 (0.0081)	Prec@1 100.000 (99.960)	
Total train loss: 0.0081
Avg Loading time: 0.1011 seconds
Avg Batch time: 0.1455 seconds

Train time: 56.994526863098145
 * Prec@1 74.970 Prec@5 92.180 Loss 1.0791
Avg Loading time: 0.1101 seconds
Avg Batch time: 0.1271 seconds

Best acc: 75.250
--------------------------------------------------------------------------------
Test time: 10.708558320999146

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.106)	BT: 0.041 (0.149)	Loss 0.0223 (0.0091)	Prec@1 99.219 (99.940)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.096)	BT: 0.040 (0.140)	Loss 0.0067 (0.0085)	Prec@1 100.000 (99.950)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.102)	BT: 0.038 (0.147)	Loss 0.0081 (0.0085)	Prec@1 100.000 (99.953)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.099)	BT: 0.040 (0.144)	Loss 0.0047 (0.0082)	Prec@1 100.000 (99.957)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.100)	BT: 0.039 (0.145)	Loss 0.0070 (0.0082)	Prec@1 100.000 (99.960)	
Total train loss: 0.0082
Avg Loading time: 0.0999 seconds
Avg Batch time: 0.1444 seconds

Train time: 56.59399604797363
 * Prec@1 74.940 Prec@5 92.340 Loss 1.0781
Avg Loading time: 0.1306 seconds
Avg Batch time: 0.1479 seconds

Best acc: 75.250
--------------------------------------------------------------------------------
Test time: 12.322880268096924

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.035 (0.082)	BT: 0.073 (0.127)	Loss 0.0114 (0.0082)	Prec@1 100.000 (99.980)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.084)	BT: 0.052 (0.129)	Loss 0.0049 (0.0076)	Prec@1 100.000 (99.975)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.673 (0.083)	BT: 0.713 (0.127)	Loss 0.0193 (0.0081)	Prec@1 99.219 (99.960)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.085)	BT: 0.040 (0.131)	Loss 0.0164 (0.0080)	Prec@1 100.000 (99.955)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.089)	BT: 0.037 (0.133)	Loss 0.0096 (0.0082)	Prec@1 100.000 (99.952)	
Total train loss: 0.0082
Avg Loading time: 0.0888 seconds
Avg Batch time: 0.1332 seconds

Train time: 52.193710803985596
 * Prec@1 74.620 Prec@5 92.220 Loss 1.0938
Avg Loading time: 0.1486 seconds
Avg Batch time: 0.1653 seconds

Best acc: 75.250
--------------------------------------------------------------------------------
Test time: 13.709541082382202

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.092)	BT: 0.051 (0.137)	Loss 0.0095 (0.0092)	Prec@1 100.000 (99.970)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.588 (0.089)	BT: 0.627 (0.135)	Loss 0.0038 (0.0087)	Prec@1 100.000 (99.970)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.347 (0.085)	BT: 0.387 (0.130)	Loss 0.0101 (0.0084)	Prec@1 100.000 (99.980)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.169 (0.088)	BT: 0.207 (0.132)	Loss 0.0055 (0.0082)	Prec@1 100.000 (99.972)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.091)	BT: 0.040 (0.136)	Loss 0.0042 (0.0082)	Prec@1 100.000 (99.972)	
Total train loss: 0.0082
Avg Loading time: 0.0912 seconds
Avg Batch time: 0.1352 seconds

Train time: 53.029823303222656
 * Prec@1 75.040 Prec@5 92.200 Loss 1.0771
Avg Loading time: 0.1313 seconds
Avg Batch time: 0.1473 seconds

Best acc: 75.250
--------------------------------------------------------------------------------
Test time: 12.290910959243774


      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 9
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar100/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/train/relu9
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/test/relu9
ResNet18(
  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=100, bias=False)
  (bn19): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 0.660 Prec@5 4.270 Loss 4.6172
Avg Loading time: 1.8323 seconds
Avg Batch time: 1.8544 seconds

Pre-trained Prec@1 with 9 layers frozen: 0.6599999666213989 	 Loss: 4.6171875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (2.549)	BT: 0.040 (2.590)	Loss 1.5898 (2.2638)	Prec@1 56.250 (44.161)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (2.465)	BT: 0.037 (2.506)	Loss 1.7480 (1.9619)	Prec@1 51.562 (49.604)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (2.437)	BT: 0.035 (2.477)	Loss 1.4492 (1.8017)	Prec@1 60.156 (52.584)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.060 (2.384)	BT: 0.089 (2.424)	Loss 1.2637 (1.6952)	Prec@1 66.406 (54.565)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (2.385)	BT: 0.037 (2.425)	Loss 1.2480 (1.6216)	Prec@1 64.062 (56.204)	
Total train loss: 1.6213
Avg Loading time: 2.3793 seconds
Avg Batch time: 2.4186 seconds

Train time: 945.8392972946167
 * Prec@1 62.720 Prec@5 89.790 Loss 1.3242
Avg Loading time: 0.1953 seconds
Avg Batch time: 0.2107 seconds

Best acc: 62.720
--------------------------------------------------------------------------------
Test time: 17.75776958465576

Epoch: [1][77/391]	LR: 0.1	DT: 0.001 (0.131)	BT: 0.031 (0.164)	Loss 1.0889 (0.9839)	Prec@1 72.656 (71.194)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.121)	BT: 0.044 (0.157)	Loss 0.9053 (0.9933)	Prec@1 73.438 (70.853)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.118)	BT: 0.034 (0.155)	Loss 0.8423 (1.0019)	Prec@1 74.219 (70.663)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.120)	BT: 0.034 (0.156)	Loss 1.0068 (1.0122)	Prec@1 69.531 (70.508)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.117)	BT: 0.034 (0.153)	Loss 0.9487 (1.0111)	Prec@1 71.875 (70.591)	
Total train loss: 1.0113
Avg Loading time: 0.1165 seconds
Avg Batch time: 0.1527 seconds

Train time: 59.851194620132446
 * Prec@1 66.660 Prec@5 90.810 Loss 1.1816
Avg Loading time: 0.1347 seconds
Avg Batch time: 0.1488 seconds

Best acc: 66.660
--------------------------------------------------------------------------------
Test time: 12.860402822494507

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.123)	BT: 0.046 (0.160)	Loss 0.7510 (0.6527)	Prec@1 77.344 (80.629)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.067 (0.112)	BT: 0.109 (0.149)	Loss 0.6260 (0.6804)	Prec@1 80.469 (79.597)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.164 (0.102)	BT: 0.196 (0.139)	Loss 0.7144 (0.6999)	Prec@1 77.344 (78.953)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.098)	BT: 0.030 (0.136)	Loss 0.8618 (0.7234)	Prec@1 75.781 (78.320)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.097)	BT: 0.032 (0.135)	Loss 0.7202 (0.7395)	Prec@1 78.125 (77.885)	
Total train loss: 0.7396
Avg Loading time: 0.0966 seconds
Avg Batch time: 0.1346 seconds

Train time: 52.75601577758789
 * Prec@1 67.010 Prec@5 90.820 Loss 1.1973
Avg Loading time: 0.1208 seconds
Avg Batch time: 0.1365 seconds

Best acc: 67.010
--------------------------------------------------------------------------------
Test time: 11.898371458053589

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.044)	BT: 0.044 (0.087)	Loss 0.4177 (0.4623)	Prec@1 87.500 (86.098)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.193 (0.054)	BT: 0.238 (0.094)	Loss 0.6113 (0.4850)	Prec@1 77.344 (85.342)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.052)	BT: 0.045 (0.093)	Loss 0.7266 (0.5119)	Prec@1 78.125 (84.435)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.051)	BT: 0.043 (0.092)	Loss 0.6172 (0.5364)	Prec@1 79.688 (83.719)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.050)	BT: 0.033 (0.091)	Loss 0.5132 (0.5499)	Prec@1 85.156 (83.331)	
Total train loss: 0.5501
Avg Loading time: 0.0504 seconds
Avg Batch time: 0.0908 seconds

Train time: 35.5994553565979
 * Prec@1 66.700 Prec@5 90.340 Loss 1.2607
Avg Loading time: 0.0583 seconds
Avg Batch time: 0.0769 seconds

Best acc: 67.010
--------------------------------------------------------------------------------
Test time: 6.745147943496704

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.046)	BT: 0.034 (0.087)	Loss 0.3652 (0.3416)	Prec@1 89.844 (89.854)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.043)	BT: 0.040 (0.084)	Loss 0.3667 (0.3424)	Prec@1 89.062 (89.834)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.041)	BT: 0.032 (0.082)	Loss 0.5781 (0.3599)	Prec@1 79.688 (89.123)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.042)	BT: 0.048 (0.083)	Loss 0.4360 (0.3770)	Prec@1 85.156 (88.484)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.041)	BT: 0.033 (0.083)	Loss 0.5923 (0.3963)	Prec@1 83.594 (87.879)	
Total train loss: 0.3964
Avg Loading time: 0.0409 seconds
Avg Batch time: 0.0825 seconds

Train time: 32.40328240394592
 * Prec@1 66.960 Prec@5 89.840 Loss 1.2930
Avg Loading time: 0.0810 seconds
Avg Batch time: 0.0979 seconds

Best acc: 67.010
--------------------------------------------------------------------------------
Test time: 8.344748973846436

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.050)	BT: 0.032 (0.091)	Loss 0.1802 (0.2625)	Prec@1 95.312 (92.418)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.043)	BT: 0.047 (0.085)	Loss 0.2590 (0.2586)	Prec@1 90.625 (92.383)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.272 (0.042)	BT: 0.310 (0.084)	Loss 0.2705 (0.2724)	Prec@1 92.188 (91.877)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.042)	BT: 0.033 (0.084)	Loss 0.4875 (0.2874)	Prec@1 85.156 (91.351)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.042)	BT: 0.035 (0.084)	Loss 0.3809 (0.3001)	Prec@1 91.406 (90.944)	
Total train loss: 0.3002
Avg Loading time: 0.0420 seconds
Avg Batch time: 0.0838 seconds

Train time: 32.922462940216064
 * Prec@1 66.760 Prec@5 88.860 Loss 1.3672
Avg Loading time: 0.0667 seconds
Avg Batch time: 0.0829 seconds

Best acc: 67.010
--------------------------------------------------------------------------------
Test time: 7.165580987930298

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.053)	BT: 0.042 (0.092)	Loss 0.1193 (0.1994)	Prec@1 97.656 (93.990)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.044)	BT: 0.035 (0.084)	Loss 0.2441 (0.2049)	Prec@1 94.531 (93.855)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.047)	BT: 0.030 (0.087)	Loss 0.1757 (0.2120)	Prec@1 93.750 (93.596)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.043)	BT: 0.041 (0.084)	Loss 0.2629 (0.2185)	Prec@1 92.969 (93.362)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.042)	BT: 0.032 (0.082)	Loss 0.3665 (0.2294)	Prec@1 86.719 (92.953)	
Total train loss: 0.2296
Avg Loading time: 0.0417 seconds
Avg Batch time: 0.0822 seconds

Train time: 32.29480004310608
 * Prec@1 66.210 Prec@5 88.440 Loss 1.4355
Avg Loading time: 0.0775 seconds
Avg Batch time: 0.0941 seconds

Best acc: 67.010
--------------------------------------------------------------------------------
Test time: 8.126800537109375

Epoch: [7][77/391]	LR: 0.1	DT: 0.001 (0.059)	BT: 0.064 (0.101)	Loss 0.1707 (0.1741)	Prec@1 93.750 (95.082)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.052)	BT: 0.041 (0.095)	Loss 0.2201 (0.1710)	Prec@1 94.531 (95.092)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.045)	BT: 0.034 (0.087)	Loss 0.1120 (0.1717)	Prec@1 96.094 (94.995)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.044)	BT: 0.033 (0.086)	Loss 0.2028 (0.1763)	Prec@1 96.875 (94.732)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.045)	BT: 0.037 (0.087)	Loss 0.2576 (0.1882)	Prec@1 89.062 (94.305)	
Total train loss: 0.1884
Avg Loading time: 0.0451 seconds
Avg Batch time: 0.0870 seconds

Train time: 34.16961908340454
 * Prec@1 65.830 Prec@5 88.430 Loss 1.4922
Avg Loading time: 0.0736 seconds
Avg Batch time: 0.0913 seconds

Best acc: 67.010
--------------------------------------------------------------------------------
Test time: 7.88491678237915

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.049)	BT: 0.032 (0.094)	Loss 0.1105 (0.1487)	Prec@1 97.656 (95.623)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.045)	BT: 0.043 (0.086)	Loss 0.1876 (0.1460)	Prec@1 95.312 (95.843)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.041)	BT: 0.034 (0.083)	Loss 0.1231 (0.1491)	Prec@1 97.656 (95.700)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.042)	BT: 0.032 (0.084)	Loss 0.1998 (0.1571)	Prec@1 95.312 (95.450)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.041)	BT: 0.035 (0.083)	Loss 0.1439 (0.1628)	Prec@1 95.312 (95.210)	
Total train loss: 0.1629
Avg Loading time: 0.0409 seconds
Avg Batch time: 0.0827 seconds

Train time: 32.50360155105591
 * Prec@1 68.710 Prec@5 89.700 Loss 1.3682
Avg Loading time: 0.0640 seconds
Avg Batch time: 0.0825 seconds

Best acc: 68.710
--------------------------------------------------------------------------------
Test time: 7.761407136917114

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.049)	BT: 0.062 (0.090)	Loss 0.1226 (0.1244)	Prec@1 95.312 (96.384)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.046)	BT: 0.069 (0.090)	Loss 0.0991 (0.1262)	Prec@1 98.438 (96.299)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.046)	BT: 0.058 (0.090)	Loss 0.1771 (0.1276)	Prec@1 94.531 (96.351)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.046)	BT: 0.035 (0.088)	Loss 0.2097 (0.1324)	Prec@1 95.312 (96.221)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.043)	BT: 0.032 (0.084)	Loss 0.1345 (0.1389)	Prec@1 96.094 (96.028)	
Total train loss: 0.1392
Avg Loading time: 0.0427 seconds
Avg Batch time: 0.0842 seconds

Train time: 33.017706871032715
 * Prec@1 67.770 Prec@5 89.350 Loss 1.4355
Avg Loading time: 0.0476 seconds
Avg Batch time: 0.0634 seconds

Best acc: 68.710
--------------------------------------------------------------------------------
Test time: 5.61710262298584

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.171)	BT: 0.037 (0.211)	Loss 0.0626 (0.0861)	Prec@1 99.219 (97.666)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 1.303 (0.258)	BT: 1.349 (0.298)	Loss 0.0665 (0.0743)	Prec@1 99.219 (98.067)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.283)	BT: 0.037 (0.322)	Loss 0.0423 (0.0667)	Prec@1 98.438 (98.331)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.001 (0.252)	BT: 0.033 (0.291)	Loss 0.0316 (0.0622)	Prec@1 100.000 (98.498)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.261)	BT: 0.031 (0.300)	Loss 0.0392 (0.0579)	Prec@1 99.219 (98.634)	
Total train loss: 0.0580
Avg Loading time: 0.2649 seconds
Avg Batch time: 0.3031 seconds

Train time: 118.61238980293274
 * Prec@1 73.380 Prec@5 92.060 Loss 1.1221
Avg Loading time: 0.4906 seconds
Avg Batch time: 0.5060 seconds

Best acc: 73.380
--------------------------------------------------------------------------------
Test time: 41.05780053138733

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.570)	BT: 0.037 (0.608)	Loss 0.0217 (0.0272)	Prec@1 99.219 (99.599)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.653)	BT: 0.035 (0.691)	Loss 0.0433 (0.0258)	Prec@1 99.219 (99.634)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.670)	BT: 0.036 (0.707)	Loss 0.0201 (0.0254)	Prec@1 100.000 (99.633)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 3.348 (0.654)	BT: 3.391 (0.691)	Loss 0.0117 (0.0251)	Prec@1 100.000 (99.649)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.640)	BT: 0.037 (0.677)	Loss 0.0206 (0.0242)	Prec@1 100.000 (99.679)	
Total train loss: 0.0242
Avg Loading time: 0.6384 seconds
Avg Batch time: 0.6757 seconds

Train time: 264.29782128334045
 * Prec@1 73.910 Prec@5 92.260 Loss 1.1035
Avg Loading time: 0.7519 seconds
Avg Batch time: 0.7669 seconds

Best acc: 73.910
--------------------------------------------------------------------------------
Test time: 61.677993059158325

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.717)	BT: 0.032 (0.754)	Loss 0.0239 (0.0185)	Prec@1 100.000 (99.820)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.072 (0.712)	BT: 0.116 (0.750)	Loss 0.0136 (0.0189)	Prec@1 100.000 (99.795)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.041 (0.547)	BT: 0.072 (0.585)	Loss 0.0173 (0.0194)	Prec@1 100.000 (99.783)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.449)	BT: 0.037 (0.487)	Loss 0.0120 (0.0190)	Prec@1 100.000 (99.790)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.384)	BT: 0.030 (0.422)	Loss 0.0161 (0.0187)	Prec@1 99.219 (99.790)	
Total train loss: 0.0187
Avg Loading time: 0.3832 seconds
Avg Batch time: 0.4207 seconds

Train time: 164.59234404563904
 * Prec@1 74.330 Prec@5 92.070 Loss 1.1035
Avg Loading time: 0.1495 seconds
Avg Batch time: 0.1646 seconds

Best acc: 74.330
--------------------------------------------------------------------------------
Test time: 14.066028833389282

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.186 (0.191)	BT: 0.222 (0.230)	Loss 0.0135 (0.0162)	Prec@1 100.000 (99.850)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.217)	BT: 0.038 (0.255)	Loss 0.0128 (0.0159)	Prec@1 100.000 (99.865)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.312)	BT: 0.037 (0.351)	Loss 0.0166 (0.0154)	Prec@1 100.000 (99.870)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.341)	BT: 0.033 (0.379)	Loss 0.0214 (0.0149)	Prec@1 100.000 (99.880)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.323)	BT: 0.032 (0.362)	Loss 0.0097 (0.0152)	Prec@1 100.000 (99.864)	
Total train loss: 0.0154
Avg Loading time: 0.3222 seconds
Avg Batch time: 0.3608 seconds

Train time: 141.20601344108582
 * Prec@1 74.230 Prec@5 92.010 Loss 1.1084
Avg Loading time: 0.2984 seconds
Avg Batch time: 0.3134 seconds

Best acc: 74.330
--------------------------------------------------------------------------------
Test time: 25.374006986618042

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.224)	BT: 0.037 (0.260)	Loss 0.0066 (0.0130)	Prec@1 100.000 (99.890)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.356 (0.219)	BT: 0.400 (0.256)	Loss 0.0124 (0.0127)	Prec@1 100.000 (99.900)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 2.007 (0.227)	BT: 2.051 (0.265)	Loss 0.0098 (0.0126)	Prec@1 100.000 (99.900)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.237)	BT: 0.032 (0.275)	Loss 0.0321 (0.0128)	Prec@1 99.219 (99.897)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.246)	BT: 0.031 (0.284)	Loss 0.0068 (0.0130)	Prec@1 100.000 (99.890)	
Total train loss: 0.0131
Avg Loading time: 0.2459 seconds
Avg Batch time: 0.2837 seconds

Train time: 111.05075764656067
 * Prec@1 73.940 Prec@5 92.080 Loss 1.1035
Avg Loading time: 0.3508 seconds
Avg Batch time: 0.3660 seconds

Best acc: 74.330
--------------------------------------------------------------------------------
Test time: 29.53914999961853

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.270)	BT: 0.032 (0.308)	Loss 0.0149 (0.0111)	Prec@1 99.219 (99.920)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.269)	BT: 0.036 (0.308)	Loss 0.0108 (0.0113)	Prec@1 100.000 (99.940)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.262)	BT: 0.043 (0.300)	Loss 0.0153 (0.0112)	Prec@1 100.000 (99.943)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.232)	BT: 0.032 (0.271)	Loss 0.0139 (0.0111)	Prec@1 100.000 (99.935)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.212)	BT: 0.034 (0.249)	Loss 0.0138 (0.0114)	Prec@1 100.000 (99.926)	
Total train loss: 0.0114
Avg Loading time: 0.2122 seconds
Avg Batch time: 0.2495 seconds

Train time: 97.68560075759888
 * Prec@1 74.330 Prec@5 91.930 Loss 1.1035
Avg Loading time: 0.1428 seconds
Avg Batch time: 0.1591 seconds

Best acc: 74.330
--------------------------------------------------------------------------------
Test time: 13.169616222381592

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.163)	BT: 0.034 (0.200)	Loss 0.0072 (0.0106)	Prec@1 100.000 (99.920)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.162)	BT: 0.032 (0.199)	Loss 0.0106 (0.0111)	Prec@1 100.000 (99.915)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.324 (0.160)	BT: 0.368 (0.197)	Loss 0.0064 (0.0112)	Prec@1 100.000 (99.920)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.112 (0.159)	BT: 0.144 (0.196)	Loss 0.0115 (0.0114)	Prec@1 100.000 (99.915)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.158)	BT: 0.037 (0.195)	Loss 0.0044 (0.0112)	Prec@1 100.000 (99.916)	
Total train loss: 0.0112
Avg Loading time: 0.1573 seconds
Avg Batch time: 0.1947 seconds

Train time: 76.23146152496338
 * Prec@1 74.270 Prec@5 92.030 Loss 1.1084
Avg Loading time: 0.1673 seconds
Avg Batch time: 0.1828 seconds

Best acc: 74.330
--------------------------------------------------------------------------------
Test time: 15.060590982437134

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.148)	BT: 0.048 (0.183)	Loss 0.0084 (0.0104)	Prec@1 100.000 (99.970)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.150)	BT: 0.035 (0.186)	Loss 0.0077 (0.0096)	Prec@1 100.000 (99.985)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.147)	BT: 0.032 (0.183)	Loss 0.0092 (0.0095)	Prec@1 100.000 (99.967)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.623 (0.148)	BT: 0.662 (0.185)	Loss 0.0055 (0.0101)	Prec@1 100.000 (99.945)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.152)	BT: 0.031 (0.189)	Loss 0.0066 (0.0102)	Prec@1 100.000 (99.942)	
Total train loss: 0.0102
Avg Loading time: 0.1516 seconds
Avg Batch time: 0.1884 seconds

Train time: 73.75877356529236
 * Prec@1 74.330 Prec@5 91.920 Loss 1.1094
Avg Loading time: 0.1773 seconds
Avg Batch time: 0.1923 seconds

Best acc: 74.330
--------------------------------------------------------------------------------
Test time: 15.81058931350708

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.044 (0.170)	BT: 0.077 (0.206)	Loss 0.0068 (0.0093)	Prec@1 100.000 (99.900)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 2.125 (0.164)	BT: 2.165 (0.201)	Loss 0.0081 (0.0093)	Prec@1 100.000 (99.935)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.163)	BT: 0.032 (0.200)	Loss 0.0079 (0.0097)	Prec@1 100.000 (99.927)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.164)	BT: 0.030 (0.201)	Loss 0.0093 (0.0096)	Prec@1 100.000 (99.937)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.168)	BT: 0.032 (0.204)	Loss 0.0062 (0.0096)	Prec@1 100.000 (99.938)	
Total train loss: 0.0096
Avg Loading time: 0.1673 seconds
Avg Batch time: 0.2036 seconds

Train time: 79.7546694278717
 * Prec@1 74.260 Prec@5 92.050 Loss 1.1143
Avg Loading time: 0.1702 seconds
Avg Batch time: 0.1865 seconds

Best acc: 74.330
--------------------------------------------------------------------------------
Test time: 15.360169172286987

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.151)	BT: 0.045 (0.188)	Loss 0.0061 (0.0080)	Prec@1 100.000 (99.970)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 1.046 (0.163)	BT: 1.086 (0.199)	Loss 0.0042 (0.0083)	Prec@1 100.000 (99.970)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.165)	BT: 0.038 (0.202)	Loss 0.0054 (0.0084)	Prec@1 100.000 (99.967)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.165)	BT: 0.048 (0.202)	Loss 0.0130 (0.0084)	Prec@1 100.000 (99.967)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.162)	BT: 0.031 (0.199)	Loss 0.0053 (0.0087)	Prec@1 100.000 (99.960)	
Total train loss: 0.0087
Avg Loading time: 0.1620 seconds
Avg Batch time: 0.1988 seconds

Train time: 77.85492157936096
 * Prec@1 74.330 Prec@5 91.990 Loss 1.1123
Avg Loading time: 0.2312 seconds
Avg Batch time: 0.2464 seconds

Best acc: 74.330
--------------------------------------------------------------------------------
Test time: 20.104714393615723

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.177)	BT: 0.032 (0.213)	Loss 0.0137 (0.0081)	Prec@1 100.000 (99.990)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.187)	BT: 0.034 (0.224)	Loss 0.0044 (0.0082)	Prec@1 100.000 (99.975)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 1.548 (0.187)	BT: 1.581 (0.225)	Loss 0.0130 (0.0083)	Prec@1 100.000 (99.967)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.178)	BT: 0.031 (0.215)	Loss 0.0172 (0.0084)	Prec@1 100.000 (99.962)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.181)	BT: 0.037 (0.218)	Loss 0.0039 (0.0084)	Prec@1 100.000 (99.954)	
Total train loss: 0.0084
Avg Loading time: 0.1804 seconds
Avg Batch time: 0.2179 seconds

Train time: 85.33316206932068
 * Prec@1 74.220 Prec@5 92.090 Loss 1.1113
Avg Loading time: 0.1891 seconds
Avg Batch time: 0.2049 seconds

Best acc: 74.330
--------------------------------------------------------------------------------
Test time: 16.784241914749146

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.149)	BT: 0.034 (0.186)	Loss 0.0051 (0.0092)	Prec@1 100.000 (99.920)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.208 (0.120)	BT: 0.242 (0.158)	Loss 0.0072 (0.0087)	Prec@1 100.000 (99.945)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.099)	BT: 0.031 (0.137)	Loss 0.0143 (0.0086)	Prec@1 100.000 (99.950)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.096)	BT: 0.033 (0.134)	Loss 0.0067 (0.0083)	Prec@1 100.000 (99.957)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.097)	BT: 0.032 (0.135)	Loss 0.0036 (0.0084)	Prec@1 100.000 (99.956)	
Total train loss: 0.0084
Avg Loading time: 0.0971 seconds
Avg Batch time: 0.1347 seconds

Train time: 52.7549192905426
 * Prec@1 74.370 Prec@5 92.000 Loss 1.1094
Avg Loading time: 0.1268 seconds
Avg Batch time: 0.1434 seconds

Best acc: 74.370
--------------------------------------------------------------------------------
Test time: 12.397724628448486

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.103)	BT: 0.034 (0.139)	Loss 0.0087 (0.0085)	Prec@1 100.000 (99.940)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.185 (0.100)	BT: 0.219 (0.138)	Loss 0.0064 (0.0082)	Prec@1 100.000 (99.940)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.313 (0.095)	BT: 0.351 (0.134)	Loss 0.0056 (0.0085)	Prec@1 100.000 (99.933)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.105)	BT: 0.033 (0.143)	Loss 0.0108 (0.0084)	Prec@1 100.000 (99.927)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.107)	BT: 0.032 (0.145)	Loss 0.0063 (0.0084)	Prec@1 100.000 (99.938)	
Total train loss: 0.0084
Avg Loading time: 0.1066 seconds
Avg Batch time: 0.1449 seconds

Train time: 56.80072045326233
 * Prec@1 74.460 Prec@5 92.080 Loss 1.1172
Avg Loading time: 0.1585 seconds
Avg Batch time: 0.1743 seconds

Best acc: 74.460
--------------------------------------------------------------------------------
Test time: 14.900198936462402

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.086)	BT: 0.032 (0.125)	Loss 0.0059 (0.0079)	Prec@1 100.000 (99.940)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.104)	BT: 0.031 (0.142)	Loss 0.0062 (0.0078)	Prec@1 100.000 (99.960)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.104)	BT: 0.032 (0.142)	Loss 0.0109 (0.0081)	Prec@1 100.000 (99.947)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.110)	BT: 0.050 (0.148)	Loss 0.0143 (0.0082)	Prec@1 100.000 (99.950)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.102)	BT: 0.032 (0.140)	Loss 0.0044 (0.0081)	Prec@1 100.000 (99.950)	
Total train loss: 0.0081
Avg Loading time: 0.1014 seconds
Avg Batch time: 0.1400 seconds

Train time: 54.841360330581665
 * Prec@1 74.490 Prec@5 92.040 Loss 1.1143
Avg Loading time: 0.0994 seconds
Avg Batch time: 0.1168 seconds

Best acc: 74.490
--------------------------------------------------------------------------------
Test time: 10.344011545181274

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.068)	BT: 0.037 (0.108)	Loss 0.0050 (0.0075)	Prec@1 100.000 (99.970)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.063)	BT: 0.032 (0.102)	Loss 0.0048 (0.0077)	Prec@1 100.000 (99.970)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.474 (0.063)	BT: 0.519 (0.102)	Loss 0.0085 (0.0079)	Prec@1 100.000 (99.967)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.059)	BT: 0.040 (0.099)	Loss 0.0049 (0.0081)	Prec@1 100.000 (99.960)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.055)	BT: 0.032 (0.096)	Loss 0.0049 (0.0083)	Prec@1 100.000 (99.956)	
Total train loss: 0.0083
Avg Loading time: 0.0553 seconds
Avg Batch time: 0.0954 seconds

Train time: 37.42525672912598
 * Prec@1 74.580 Prec@5 92.130 Loss 1.1104
Avg Loading time: 0.0738 seconds
Avg Batch time: 0.0903 seconds

Best acc: 74.580
--------------------------------------------------------------------------------
Test time: 8.244860410690308

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.069)	BT: 0.039 (0.106)	Loss 0.0223 (0.0091)	Prec@1 100.000 (99.910)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.054)	BT: 0.032 (0.092)	Loss 0.0053 (0.0089)	Prec@1 100.000 (99.920)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.303 (0.053)	BT: 0.343 (0.092)	Loss 0.0036 (0.0086)	Prec@1 100.000 (99.933)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.234 (0.054)	BT: 0.272 (0.093)	Loss 0.0052 (0.0083)	Prec@1 100.000 (99.945)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.053)	BT: 0.032 (0.093)	Loss 0.0115 (0.0082)	Prec@1 100.000 (99.948)	
Total train loss: 0.0082
Avg Loading time: 0.0530 seconds
Avg Batch time: 0.0928 seconds

Train time: 36.38552236557007
 * Prec@1 74.700 Prec@5 92.040 Loss 1.1084
Avg Loading time: 0.0768 seconds
Avg Batch time: 0.0949 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 8.58409070968628

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.054)	BT: 0.034 (0.092)	Loss 0.0058 (0.0084)	Prec@1 100.000 (99.970)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.362 (0.054)	BT: 0.396 (0.094)	Loss 0.0041 (0.0085)	Prec@1 100.000 (99.960)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.046)	BT: 0.037 (0.087)	Loss 0.0053 (0.0084)	Prec@1 100.000 (99.967)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.060)	BT: 0.067 (0.100)	Loss 0.0080 (0.0082)	Prec@1 100.000 (99.970)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.067)	BT: 0.033 (0.107)	Loss 0.0039 (0.0081)	Prec@1 100.000 (99.964)	
Total train loss: 0.0082
Avg Loading time: 0.0683 seconds
Avg Batch time: 0.1079 seconds

Train time: 42.29960346221924
 * Prec@1 74.530 Prec@5 91.910 Loss 1.1123
Avg Loading time: 0.1009 seconds
Avg Batch time: 0.1180 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 9.98419713973999

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.128)	BT: 0.040 (0.166)	Loss 0.0079 (0.0080)	Prec@1 100.000 (99.970)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.017 (0.110)	BT: 0.052 (0.148)	Loss 0.0230 (0.0080)	Prec@1 99.219 (99.970)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.122 (0.115)	BT: 0.157 (0.154)	Loss 0.0080 (0.0082)	Prec@1 100.000 (99.963)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.123)	BT: 0.046 (0.161)	Loss 0.0105 (0.0084)	Prec@1 100.000 (99.960)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.550 (0.130)	BT: 0.589 (0.168)	Loss 0.0105 (0.0084)	Prec@1 100.000 (99.952)	
Total train loss: 0.0084
Avg Loading time: 0.1300 seconds
Avg Batch time: 0.1680 seconds

Train time: 65.80694580078125
 * Prec@1 74.590 Prec@5 91.930 Loss 1.1133
Avg Loading time: 0.2202 seconds
Avg Batch time: 0.2360 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 19.297410011291504

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.174)	BT: 0.033 (0.211)	Loss 0.0062 (0.0083)	Prec@1 100.000 (99.960)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.517 (0.146)	BT: 0.560 (0.183)	Loss 0.0078 (0.0082)	Prec@1 100.000 (99.960)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.262 (0.135)	BT: 0.302 (0.173)	Loss 0.0061 (0.0083)	Prec@1 100.000 (99.947)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.133)	BT: 0.034 (0.171)	Loss 0.0162 (0.0083)	Prec@1 100.000 (99.947)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.130)	BT: 0.044 (0.168)	Loss 0.0133 (0.0081)	Prec@1 100.000 (99.954)	
Total train loss: 0.0081
Avg Loading time: 0.1301 seconds
Avg Batch time: 0.1677 seconds

Train time: 65.74694991111755
 * Prec@1 74.240 Prec@5 92.190 Loss 1.1123
Avg Loading time: 0.1540 seconds
Avg Batch time: 0.1691 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 13.989922046661377

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.091)	BT: 0.034 (0.129)	Loss 0.0040 (0.0087)	Prec@1 100.000 (99.980)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.076 (0.089)	BT: 0.108 (0.129)	Loss 0.0086 (0.0087)	Prec@1 100.000 (99.970)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.092)	BT: 0.031 (0.131)	Loss 0.0068 (0.0084)	Prec@1 100.000 (99.973)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.099)	BT: 0.032 (0.137)	Loss 0.0128 (0.0084)	Prec@1 100.000 (99.972)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.096)	BT: 0.035 (0.134)	Loss 0.0064 (0.0083)	Prec@1 100.000 (99.974)	
Total train loss: 0.0083
Avg Loading time: 0.0962 seconds
Avg Batch time: 0.1338 seconds

Train time: 52.4343478679657
 * Prec@1 74.360 Prec@5 92.050 Loss 1.1113
Avg Loading time: 0.1581 seconds
Avg Batch time: 0.1740 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 14.4333975315094

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.134)	BT: 0.038 (0.173)	Loss 0.0052 (0.0083)	Prec@1 100.000 (99.940)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.127)	BT: 0.033 (0.166)	Loss 0.0094 (0.0080)	Prec@1 100.000 (99.950)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.125)	BT: 0.039 (0.164)	Loss 0.0057 (0.0082)	Prec@1 100.000 (99.943)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.123)	BT: 0.032 (0.162)	Loss 0.0080 (0.0084)	Prec@1 100.000 (99.945)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.119)	BT: 0.032 (0.157)	Loss 0.0054 (0.0083)	Prec@1 100.000 (99.948)	
Total train loss: 0.0083
Avg Loading time: 0.1185 seconds
Avg Batch time: 0.1570 seconds

Train time: 61.48694729804993
 * Prec@1 74.340 Prec@5 92.060 Loss 1.1113
Avg Loading time: 0.1387 seconds
Avg Batch time: 0.1560 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 12.949246168136597

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.238 (0.118)	BT: 0.278 (0.156)	Loss 0.0052 (0.0089)	Prec@1 100.000 (99.900)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.107)	BT: 0.032 (0.145)	Loss 0.0049 (0.0083)	Prec@1 100.000 (99.930)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.107)	BT: 0.032 (0.144)	Loss 0.0070 (0.0082)	Prec@1 100.000 (99.940)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.112)	BT: 0.032 (0.150)	Loss 0.0089 (0.0082)	Prec@1 100.000 (99.937)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.118)	BT: 0.030 (0.156)	Loss 0.0072 (0.0080)	Prec@1 100.000 (99.942)	
Total train loss: 0.0081
Avg Loading time: 0.1179 seconds
Avg Batch time: 0.1556 seconds

Train time: 60.961296796798706
 * Prec@1 74.320 Prec@5 92.100 Loss 1.1113
Avg Loading time: 0.1681 seconds
Avg Batch time: 0.1837 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 15.178285360336304

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.127)	BT: 0.031 (0.165)	Loss 0.0150 (0.0074)	Prec@1 99.219 (99.950)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.119)	BT: 0.053 (0.157)	Loss 0.0077 (0.0079)	Prec@1 100.000 (99.940)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.228 (0.121)	BT: 0.279 (0.160)	Loss 0.0126 (0.0079)	Prec@1 99.219 (99.947)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.130)	BT: 0.047 (0.168)	Loss 0.0037 (0.0079)	Prec@1 100.000 (99.957)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.124)	BT: 0.032 (0.162)	Loss 0.0027 (0.0079)	Prec@1 100.000 (99.956)	
Total train loss: 0.0079
Avg Loading time: 0.1255 seconds
Avg Batch time: 0.1638 seconds

Train time: 64.15423822402954
 * Prec@1 74.420 Prec@5 92.070 Loss 1.1094
Avg Loading time: 0.1750 seconds
Avg Batch time: 0.1893 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 15.563726425170898

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.125)	BT: 0.032 (0.161)	Loss 0.0111 (0.0073)	Prec@1 99.219 (99.980)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.130)	BT: 0.043 (0.166)	Loss 0.0043 (0.0073)	Prec@1 100.000 (99.980)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.073 (0.136)	BT: 0.124 (0.173)	Loss 0.0054 (0.0073)	Prec@1 100.000 (99.970)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.132)	BT: 0.032 (0.169)	Loss 0.0043 (0.0076)	Prec@1 100.000 (99.970)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.133)	BT: 0.032 (0.170)	Loss 0.0037 (0.0078)	Prec@1 100.000 (99.962)	
Total train loss: 0.0079
Avg Loading time: 0.1325 seconds
Avg Batch time: 0.1698 seconds

Train time: 66.52056765556335
 * Prec@1 74.420 Prec@5 91.980 Loss 1.1094
Avg Loading time: 0.1573 seconds
Avg Batch time: 0.1733 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 14.283474922180176

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.408 (0.155)	BT: 0.447 (0.191)	Loss 0.0038 (0.0082)	Prec@1 100.000 (99.940)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.145)	BT: 0.034 (0.182)	Loss 0.0052 (0.0078)	Prec@1 100.000 (99.955)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.139)	BT: 0.033 (0.176)	Loss 0.0263 (0.0079)	Prec@1 99.219 (99.953)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.143)	BT: 0.032 (0.180)	Loss 0.0047 (0.0078)	Prec@1 100.000 (99.957)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.161)	BT: 0.038 (0.198)	Loss 0.0073 (0.0080)	Prec@1 100.000 (99.954)	
Total train loss: 0.0080
Avg Loading time: 0.1606 seconds
Avg Batch time: 0.1979 seconds

Train time: 77.53374099731445
 * Prec@1 74.400 Prec@5 92.100 Loss 1.1055
Avg Loading time: 0.3061 seconds
Avg Batch time: 0.3220 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 26.06890296936035

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.322)	BT: 0.038 (0.361)	Loss 0.0067 (0.0073)	Prec@1 100.000 (99.990)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.313)	BT: 0.038 (0.353)	Loss 0.0140 (0.0078)	Prec@1 100.000 (99.980)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.319)	BT: 0.039 (0.358)	Loss 0.0075 (0.0076)	Prec@1 100.000 (99.977)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.561 (0.323)	BT: 0.600 (0.362)	Loss 0.0094 (0.0077)	Prec@1 100.000 (99.977)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.341)	BT: 0.037 (0.380)	Loss 0.0160 (0.0078)	Prec@1 99.219 (99.966)	
Total train loss: 0.0078
Avg Loading time: 0.3402 seconds
Avg Batch time: 0.3795 seconds

Train time: 148.53748226165771
 * Prec@1 74.350 Prec@5 92.050 Loss 1.1094
Avg Loading time: 0.3780 seconds
Avg Batch time: 0.3933 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 31.70987033843994

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.353)	BT: 0.038 (0.393)	Loss 0.0026 (0.0075)	Prec@1 100.000 (99.960)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.321)	BT: 0.039 (0.361)	Loss 0.0047 (0.0077)	Prec@1 100.000 (99.970)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.337 (0.317)	BT: 0.386 (0.356)	Loss 0.0047 (0.0081)	Prec@1 100.000 (99.960)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 2.331 (0.316)	BT: 2.379 (0.355)	Loss 0.0038 (0.0080)	Prec@1 100.000 (99.962)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.313)	BT: 0.030 (0.352)	Loss 0.0153 (0.0079)	Prec@1 100.000 (99.964)	
Total train loss: 0.0080
Avg Loading time: 0.3118 seconds
Avg Batch time: 0.3509 seconds

Train time: 137.3537347316742
 * Prec@1 74.460 Prec@5 92.060 Loss 1.1152
Avg Loading time: 0.3023 seconds
Avg Batch time: 0.3171 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 25.706180095672607

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.275)	BT: 0.032 (0.313)	Loss 0.0047 (0.0077)	Prec@1 100.000 (99.940)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.289)	BT: 0.041 (0.327)	Loss 0.0039 (0.0074)	Prec@1 100.000 (99.960)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.283)	BT: 0.038 (0.321)	Loss 0.0055 (0.0076)	Prec@1 100.000 (99.963)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.275)	BT: 0.034 (0.313)	Loss 0.0090 (0.0077)	Prec@1 100.000 (99.957)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.268)	BT: 0.037 (0.306)	Loss 0.0051 (0.0079)	Prec@1 100.000 (99.958)	
Total train loss: 0.0079
Avg Loading time: 0.2669 seconds
Avg Batch time: 0.3056 seconds

Train time: 119.61848616600037
 * Prec@1 74.430 Prec@5 92.120 Loss 1.1113
Avg Loading time: 0.2369 seconds
Avg Batch time: 0.2522 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 20.76215362548828

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.269)	BT: 0.034 (0.307)	Loss 0.0048 (0.0085)	Prec@1 100.000 (99.920)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.272)	BT: 0.037 (0.310)	Loss 0.0322 (0.0085)	Prec@1 99.219 (99.925)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.822 (0.257)	BT: 0.860 (0.295)	Loss 0.0098 (0.0085)	Prec@1 100.000 (99.930)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.243)	BT: 0.043 (0.281)	Loss 0.0047 (0.0082)	Prec@1 100.000 (99.942)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.228)	BT: 0.037 (0.266)	Loss 0.0054 (0.0081)	Prec@1 100.000 (99.948)	
Total train loss: 0.0082
Avg Loading time: 0.2272 seconds
Avg Batch time: 0.2654 seconds

Train time: 103.8604645729065
 * Prec@1 74.590 Prec@5 92.050 Loss 1.1084
Avg Loading time: 0.2043 seconds
Avg Batch time: 0.2212 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 18.101773500442505

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.231)	BT: 0.037 (0.267)	Loss 0.0105 (0.0087)	Prec@1 100.000 (99.930)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.240)	BT: 0.035 (0.278)	Loss 0.0171 (0.0082)	Prec@1 100.000 (99.950)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.240)	BT: 0.038 (0.278)	Loss 0.0327 (0.0081)	Prec@1 100.000 (99.960)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.233)	BT: 0.049 (0.271)	Loss 0.0022 (0.0082)	Prec@1 100.000 (99.955)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.225)	BT: 0.035 (0.263)	Loss 0.0059 (0.0081)	Prec@1 100.000 (99.956)	
Total train loss: 0.0081
Avg Loading time: 0.2259 seconds
Avg Batch time: 0.2637 seconds

Train time: 103.20636296272278
 * Prec@1 74.380 Prec@5 92.120 Loss 1.1104
Avg Loading time: 0.1478 seconds
Avg Batch time: 0.1657 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 13.706865787506104

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.084)	BT: 0.034 (0.124)	Loss 0.0074 (0.0083)	Prec@1 100.000 (99.940)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.337 (0.081)	BT: 0.371 (0.121)	Loss 0.0038 (0.0079)	Prec@1 100.000 (99.960)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.064)	BT: 0.042 (0.106)	Loss 0.0091 (0.0080)	Prec@1 99.219 (99.960)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.074)	BT: 0.053 (0.115)	Loss 0.0072 (0.0080)	Prec@1 100.000 (99.957)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.719 (0.084)	BT: 0.751 (0.124)	Loss 0.0028 (0.0080)	Prec@1 100.000 (99.960)	
Total train loss: 0.0080
Avg Loading time: 0.0841 seconds
Avg Batch time: 0.1238 seconds

Train time: 48.50542950630188
 * Prec@1 74.650 Prec@5 92.110 Loss 1.1104
Avg Loading time: 0.1444 seconds
Avg Batch time: 0.1600 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 13.317570924758911

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.126)	BT: 0.032 (0.164)	Loss 0.0119 (0.0080)	Prec@1 99.219 (99.950)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.121)	BT: 0.044 (0.159)	Loss 0.0093 (0.0083)	Prec@1 100.000 (99.950)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.119)	BT: 0.039 (0.157)	Loss 0.0058 (0.0086)	Prec@1 100.000 (99.953)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.120)	BT: 0.039 (0.158)	Loss 0.0069 (0.0085)	Prec@1 100.000 (99.950)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.117)	BT: 0.032 (0.154)	Loss 0.0100 (0.0083)	Prec@1 100.000 (99.952)	
Total train loss: 0.0083
Avg Loading time: 0.1166 seconds
Avg Batch time: 0.1541 seconds

Train time: 60.413129806518555
 * Prec@1 74.320 Prec@5 92.120 Loss 1.1104
Avg Loading time: 0.1570 seconds
Avg Batch time: 0.1728 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 14.321431636810303

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.566 (0.111)	BT: 0.600 (0.148)	Loss 0.0114 (0.0087)	Prec@1 100.000 (99.930)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.110)	BT: 0.032 (0.148)	Loss 0.0027 (0.0080)	Prec@1 100.000 (99.965)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.100)	BT: 0.032 (0.138)	Loss 0.0057 (0.0083)	Prec@1 100.000 (99.950)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.105)	BT: 0.032 (0.143)	Loss 0.0410 (0.0081)	Prec@1 99.219 (99.955)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.338 (0.094)	BT: 0.369 (0.133)	Loss 0.0089 (0.0082)	Prec@1 100.000 (99.954)	
Total train loss: 0.0082
Avg Loading time: 0.0939 seconds
Avg Batch time: 0.1324 seconds

Train time: 51.92254400253296
 * Prec@1 74.510 Prec@5 92.140 Loss 1.1104
Avg Loading time: 0.0933 seconds
Avg Batch time: 0.1098 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 9.3245849609375

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.045)	BT: 0.039 (0.090)	Loss 0.0058 (0.0079)	Prec@1 100.000 (99.950)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.116 (0.040)	BT: 0.156 (0.083)	Loss 0.0042 (0.0084)	Prec@1 100.000 (99.940)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.047)	BT: 0.045 (0.089)	Loss 0.0063 (0.0082)	Prec@1 100.000 (99.953)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.412 (0.046)	BT: 0.444 (0.089)	Loss 0.0050 (0.0081)	Prec@1 100.000 (99.957)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.045)	BT: 0.036 (0.088)	Loss 0.0090 (0.0079)	Prec@1 100.000 (99.964)	
Total train loss: 0.0079
Avg Loading time: 0.0445 seconds
Avg Batch time: 0.0877 seconds

Train time: 34.45666170120239
 * Prec@1 74.340 Prec@5 91.990 Loss 1.1152
Avg Loading time: 0.0502 seconds
Avg Batch time: 0.0716 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 6.313603401184082

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.062)	BT: 0.076 (0.105)	Loss 0.0091 (0.0078)	Prec@1 100.000 (99.980)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.048)	BT: 0.052 (0.092)	Loss 0.0098 (0.0082)	Prec@1 100.000 (99.950)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.047)	BT: 0.032 (0.090)	Loss 0.0129 (0.0079)	Prec@1 100.000 (99.957)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.190 (0.046)	BT: 0.222 (0.089)	Loss 0.0119 (0.0079)	Prec@1 99.219 (99.957)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.046)	BT: 0.032 (0.087)	Loss 0.0048 (0.0079)	Prec@1 100.000 (99.960)	
Total train loss: 0.0081
Avg Loading time: 0.0454 seconds
Avg Batch time: 0.0871 seconds

Train time: 34.16915678977966
 * Prec@1 74.280 Prec@5 92.170 Loss 1.1133
Avg Loading time: 0.0680 seconds
Avg Batch time: 0.0859 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 7.493439674377441

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.088)	BT: 0.043 (0.127)	Loss 0.0052 (0.0077)	Prec@1 100.000 (99.990)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.075)	BT: 0.032 (0.113)	Loss 0.0073 (0.0081)	Prec@1 100.000 (99.955)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.076)	BT: 0.032 (0.114)	Loss 0.0057 (0.0082)	Prec@1 100.000 (99.960)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.081)	BT: 0.045 (0.119)	Loss 0.0073 (0.0083)	Prec@1 100.000 (99.947)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.082)	BT: 0.037 (0.120)	Loss 0.0257 (0.0084)	Prec@1 100.000 (99.946)	
Total train loss: 0.0084
Avg Loading time: 0.0820 seconds
Avg Batch time: 0.1194 seconds

Train time: 46.80342102050781
 * Prec@1 74.300 Prec@5 92.070 Loss 1.1182
Avg Loading time: 0.1175 seconds
Avg Batch time: 0.1346 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 11.280942678451538

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.086)	BT: 0.046 (0.122)	Loss 0.0105 (0.0082)	Prec@1 100.000 (99.960)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.082)	BT: 0.064 (0.122)	Loss 0.0075 (0.0080)	Prec@1 100.000 (99.970)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.690 (0.085)	BT: 0.726 (0.125)	Loss 0.0091 (0.0079)	Prec@1 100.000 (99.967)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.082)	BT: 0.045 (0.122)	Loss 0.0096 (0.0079)	Prec@1 100.000 (99.967)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.082)	BT: 0.029 (0.121)	Loss 0.0074 (0.0079)	Prec@1 100.000 (99.968)	
Total train loss: 0.0079
Avg Loading time: 0.0818 seconds
Avg Batch time: 0.1208 seconds

Train time: 47.3150475025177
 * Prec@1 74.550 Prec@5 92.050 Loss 1.1064
Avg Loading time: 0.0993 seconds
Avg Batch time: 0.1154 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 9.716094017028809

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.088)	BT: 0.046 (0.125)	Loss 0.0055 (0.0079)	Prec@1 100.000 (99.940)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.089)	BT: 0.042 (0.129)	Loss 0.0036 (0.0079)	Prec@1 100.000 (99.955)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.084)	BT: 0.036 (0.124)	Loss 0.0054 (0.0082)	Prec@1 100.000 (99.950)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.081)	BT: 0.032 (0.121)	Loss 0.0058 (0.0081)	Prec@1 100.000 (99.957)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.082)	BT: 0.033 (0.122)	Loss 0.0050 (0.0079)	Prec@1 100.000 (99.962)	
Total train loss: 0.0079
Avg Loading time: 0.0821 seconds
Avg Batch time: 0.1219 seconds

Train time: 47.79671931266785
 * Prec@1 74.450 Prec@5 92.150 Loss 1.1055
Avg Loading time: 0.0881 seconds
Avg Batch time: 0.1059 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 9.039680480957031

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.091)	BT: 0.044 (0.128)	Loss 0.0072 (0.0084)	Prec@1 100.000 (99.900)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.087)	BT: 0.040 (0.126)	Loss 0.0066 (0.0081)	Prec@1 100.000 (99.930)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.076)	BT: 0.030 (0.115)	Loss 0.0032 (0.0080)	Prec@1 100.000 (99.937)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.078)	BT: 0.032 (0.117)	Loss 0.0069 (0.0079)	Prec@1 100.000 (99.942)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.081)	BT: 0.031 (0.121)	Loss 0.0035 (0.0079)	Prec@1 100.000 (99.946)	
Total train loss: 0.0079
Avg Loading time: 0.0809 seconds
Avg Batch time: 0.1203 seconds

Train time: 47.176254987716675
 * Prec@1 74.470 Prec@5 92.120 Loss 1.1006
Avg Loading time: 0.1462 seconds
Avg Batch time: 0.1625 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 13.487160921096802

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.075 (0.079)	BT: 0.113 (0.120)	Loss 0.0163 (0.0074)	Prec@1 99.219 (99.950)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.083)	BT: 0.032 (0.122)	Loss 0.0127 (0.0077)	Prec@1 100.000 (99.945)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.088)	BT: 0.033 (0.126)	Loss 0.0051 (0.0078)	Prec@1 100.000 (99.947)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.090)	BT: 0.036 (0.129)	Loss 0.0042 (0.0079)	Prec@1 100.000 (99.950)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.590 (0.089)	BT: 0.631 (0.128)	Loss 0.0102 (0.0079)	Prec@1 100.000 (99.950)	
Total train loss: 0.0080
Avg Loading time: 0.0892 seconds
Avg Batch time: 0.1279 seconds

Train time: 50.128055810928345
 * Prec@1 74.290 Prec@5 92.170 Loss 1.1162
Avg Loading time: 0.1483 seconds
Avg Batch time: 0.1640 seconds

Best acc: 74.700
--------------------------------------------------------------------------------
Test time: 13.556034803390503

