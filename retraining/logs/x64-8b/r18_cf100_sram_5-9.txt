
      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.02
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 3
          frozen_layers: 5
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar100/resnet18
DEVICE: cuda
GPU Id(s) being used: 3
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/train/relu5
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/test/relu5
ResNet18(
  (conv6): QConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv1): Sequential(
    (0): QConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu6): ReLU(inplace=True)
  (conv7): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu7): ReLU(inplace=True)
  (conv8): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): QConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): QConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): QConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): QConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=512, out_features=100, bias=False)
  (bn19): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 0.900 Prec@5 4.730 Loss 4.6094
Avg Loading time: 4.7473 seconds
Avg Batch time: 9.0822 seconds

Pre-trained Prec@1 with 5 layers frozen: 0.8999999761581421 	 Loss: 4.609375

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.02	DT: 0.000 (4.401)	BT: 0.511 (8.985)	Loss 2.4609 (3.0031)	Prec@1 41.406 (33.153)	
Epoch: [0][155/391]	LR: 0.02	DT: 0.693 (3.395)	BT: 1.214 (6.781)	Loss 2.1523 (2.6388)	Prec@1 51.562 (39.453)	
Epoch: [0][233/391]	LR: 0.02	DT: 34.745 (3.288)	BT: 77.334 (6.794)	Loss 2.0117 (2.4600)	Prec@1 52.344 (42.378)	
Epoch: [0][311/391]	LR: 0.02	DT: 0.000 (3.220)	BT: 0.509 (7.032)	Loss 1.9668 (2.3783)	Prec@1 52.344 (43.672)	
Epoch: [0][389/391]	LR: 0.02	DT: 0.000 (3.248)	BT: 0.509 (7.334)	Loss 1.8496 (2.3005)	Prec@1 54.688 (44.860)	
Total train loss: 2.3005
Avg Loading time: 3.2395 seconds
Avg Batch time: 7.3164 seconds

Train time: 2860.8066685199738
 * Prec@1 1.460 Prec@5 11.910 Loss inf
Avg Loading time: 2.7646 seconds
Avg Batch time: 5.8943 seconds

Best acc: 1.460
--------------------------------------------------------------------------------
Test time: 466.7670781612396

Epoch: [1][77/391]	LR: 0.02	DT: 0.000 (2.589)	BT: 0.520 (4.354)	Loss 1.8086 (1.9201)	Prec@1 50.000 (50.881)	
Epoch: [1][155/391]	LR: 0.02	DT: 2.700 (2.839)	BT: 3.214 (3.978)	Loss 1.6650 (1.8737)	Prec@1 59.375 (52.003)	
Epoch: [1][233/391]	LR: 0.02	DT: 10.828 (2.751)	BT: 11.342 (3.810)	Loss 1.9004 (1.8615)	Prec@1 57.031 (52.107)	
Epoch: [1][311/391]	LR: 0.02	DT: 0.000 (2.740)	BT: 0.509 (3.855)	Loss 1.8652 (1.8798)	Prec@1 50.000 (51.482)	
Epoch: [1][389/391]	LR: 0.02	DT: 0.000 (2.591)	BT: 0.512 (4.030)	Loss 1.9307 (1.9188)	Prec@1 50.000 (50.335)	
Total train loss: 1.9192
Avg Loading time: 2.5839 seconds
Avg Batch time: 4.0203 seconds

Train time: 1572.0467715263367
 * Prec@1 2.890 Prec@5 11.290 Loss inf
Avg Loading time: 1.6082 seconds
Avg Batch time: 4.6609 seconds

Best acc: 2.890
--------------------------------------------------------------------------------
Test time: 369.38643765449524

Epoch: [2][77/391]	LR: 0.02	DT: 0.163 (0.936)	BT: 0.683 (1.835)	Loss 1.8574 (2.1767)	Prec@1 53.906 (44.241)	
Epoch: [2][155/391]	LR: 0.02	DT: 0.000 (0.832)	BT: 0.520 (1.537)	Loss 2.1914 (2.1553)	Prec@1 44.531 (44.541)	
Epoch: [2][233/391]	LR: 0.02	DT: 3.210 (0.854)	BT: 3.727 (1.496)	Loss 2.1348 (2.1376)	Prec@1 45.312 (44.882)	
Epoch: [2][311/391]	LR: 0.02	DT: 0.000 (0.996)	BT: 0.513 (1.607)	Loss 2.3223 (2.1239)	Prec@1 40.625 (45.055)	
Epoch: [2][389/391]	LR: 0.02	DT: 6.357 (1.265)	BT: 6.874 (1.856)	Loss 2.1484 (2.1021)	Prec@1 41.406 (45.507)	
Total train loss: 2.1023
Avg Loading time: 1.2618 seconds
Avg Batch time: 1.8520 seconds

Train time: 724.2518379688263
 * Prec@1 0.950 Prec@5 5.130 Loss inf
Avg Loading time: 1.6716 seconds
Avg Batch time: 3.3591 seconds

Best acc: 2.890
--------------------------------------------------------------------------------
Test time: 266.0597710609436

Epoch: [3][77/391]	LR: 0.02	DT: 0.000 (1.517)	BT: 0.512 (4.204)	Loss 2.0742 (1.9011)	Prec@1 42.188 (49.489)	
Epoch: [3][155/391]	LR: 0.02	DT: 1.522 (1.700)	BT: 2.038 (3.685)	Loss 1.9893 (1.8943)	Prec@1 46.875 (50.030)	
Epoch: [3][233/391]	LR: 0.02	DT: 8.156 (2.073)	BT: 8.671 (3.568)	Loss 1.7666 (1.8888)	Prec@1 53.906 (50.154)	
Epoch: [3][311/391]	LR: 0.02	DT: 0.000 (2.263)	BT: 0.506 (3.511)	Loss 1.6797 (1.8773)	Prec@1 53.125 (50.346)	
Epoch: [3][389/391]	LR: 0.02	DT: 0.000 (2.354)	BT: 0.508 (3.533)	Loss 1.7939 (1.8612)	Prec@1 49.219 (50.729)	
Total train loss: 1.8607
Avg Loading time: 2.3481 seconds
Avg Batch time: 3.5245 seconds

Train time: 1378.2194294929504
 * Prec@1 45.300 Prec@5 75.510 Loss 2.1094
Avg Loading time: 1.9144 seconds
Avg Batch time: 4.9242 seconds

Best acc: 45.300
--------------------------------------------------------------------------------
Test time: 390.1920049190521

Epoch: [4][77/391]	LR: 0.02	DT: 0.000 (1.536)	BT: 0.513 (5.455)	Loss 1.6973 (1.7039)	Prec@1 60.938 (54.748)	
Epoch: [4][155/391]	LR: 0.02	DT: 0.000 (1.369)	BT: 0.510 (4.354)	Loss 1.5352 (1.7153)	Prec@1 58.594 (54.162)	
Epoch: [4][233/391]	LR: 0.02	DT: 0.924 (1.662)	BT: 1.443 (3.952)	Loss 1.7051 (1.7081)	Prec@1 51.562 (54.294)	
Epoch: [4][311/391]	LR: 0.02	DT: 7.535 (1.908)	BT: 8.051 (3.753)	Loss 1.7432 (1.7224)	Prec@1 60.938 (54.016)	
Epoch: [4][389/391]	LR: 0.02	DT: 0.000 (1.955)	BT: 0.509 (3.534)	Loss 1.8516 (1.7322)	Prec@1 53.125 (53.704)	
Total train loss: 1.7326
Avg Loading time: 1.9496 seconds
Avg Batch time: 3.5255 seconds

Train time: 1378.6104633808136
 * Prec@1 38.800 Prec@5 69.910 Loss 2.4004
Avg Loading time: 1.2730 seconds
Avg Batch time: 1.8087 seconds

Best acc: 45.300
--------------------------------------------------------------------------------
Test time: 143.652006149292

Epoch: [5][77/391]	LR: 0.02	DT: 0.000 (0.900)	BT: 0.511 (1.414)	Loss 1.4609 (1.7092)	Prec@1 60.156 (53.546)	
Epoch: [5][155/391]	LR: 0.02	DT: 0.000 (0.966)	BT: 0.513 (1.479)	Loss 1.9170 (1.6990)	Prec@1 50.000 (53.841)	
Epoch: [5][233/391]	LR: 0.02	DT: 0.000 (1.033)	BT: 0.511 (1.675)	Loss 1.8457 (1.7054)	Prec@1 50.781 (53.689)	
Epoch: [5][311/391]	LR: 0.02	DT: 0.000 (1.150)	BT: 0.515 (1.952)	Loss 1.7842 (1.7091)	Prec@1 50.781 (53.746)	
Epoch: [5][389/391]	LR: 0.02	DT: 0.000 (1.201)	BT: 0.514 (2.253)	Loss 1.6816 (1.7274)	Prec@1 55.469 (53.470)	
Total train loss: 1.7277
Avg Loading time: 1.1978 seconds
Avg Batch time: 2.2483 seconds

Train time: 879.2075724601746
 * Prec@1 15.930 Prec@5 35.440 Loss 4.0586
Avg Loading time: 1.6238 seconds
Avg Batch time: 4.6086 seconds

Best acc: 45.300
--------------------------------------------------------------------------------
Test time: 364.7406105995178

Epoch: [6][77/391]	LR: 0.02	DT: 0.000 (1.789)	BT: 0.510 (4.645)	Loss 1.8633 (1.7428)	Prec@1 51.562 (52.754)	
Epoch: [6][155/391]	LR: 0.02	DT: 1.919 (1.941)	BT: 2.435 (4.203)	Loss 1.9023 (1.7307)	Prec@1 45.312 (52.870)	
Epoch: [6][233/391]	LR: 0.02	DT: 11.417 (2.351)	BT: 11.930 (4.030)	Loss 1.8008 (1.7141)	Prec@1 51.562 (53.198)	
Epoch: [6][311/391]	LR: 0.02	DT: 0.304 (2.447)	BT: 0.814 (3.835)	Loss 1.6504 (1.6992)	Prec@1 55.469 (53.468)	
Epoch: [6][389/391]	LR: 0.02	DT: 0.000 (2.229)	BT: 0.507 (3.442)	Loss 1.7578 (1.6949)	Prec@1 54.688 (53.686)	
Total train loss: 1.6950
Avg Loading time: 2.2236 seconds
Avg Batch time: 3.4336 seconds

Train time: 1342.6486682891846
 * Prec@1 2.290 Prec@5 14.800 Loss inf
Avg Loading time: 0.7181 seconds
Avg Batch time: 0.8924 seconds

Best acc: 45.300
--------------------------------------------------------------------------------
Test time: 71.18210411071777

Epoch: [7][77/391]	LR: 0.02	DT: 0.000 (0.421)	BT: 0.512 (0.935)	Loss 1.3955 (1.7352)	Prec@1 58.594 (53.656)	
Epoch: [7][155/391]	LR: 0.02	DT: 0.000 (0.413)	BT: 0.514 (0.927)	Loss 1.8691 (1.7524)	Prec@1 52.344 (52.890)	
Epoch: [7][233/391]	LR: 0.02	DT: 1.106 (0.393)	BT: 1.618 (0.908)	Loss 1.9297 (1.9232)	Prec@1 43.750 (49.065)	
Epoch: [7][311/391]	LR: 0.02	DT: 0.000 (0.537)	BT: 0.509 (1.051)	Loss 1.7744 (1.9153)	Prec@1 48.438 (49.031)	
Epoch: [7][389/391]	LR: 0.02	DT: 0.000 (0.788)	BT: 0.512 (1.304)	Loss 1.7363 (1.8883)	Prec@1 50.781 (49.497)	
Total train loss: 1.8885
Avg Loading time: 0.7865 seconds
Avg Batch time: 1.3010 seconds

Train time: 508.8226146697998
 * Prec@1 41.470 Prec@5 70.480 Loss 2.3359
Avg Loading time: 1.3659 seconds
Avg Batch time: 4.0706 seconds

Best acc: 45.300
--------------------------------------------------------------------------------
Test time: 322.251558303833

Epoch: [8][77/391]	LR: 0.02	DT: 0.000 (1.773)	BT: 0.506 (3.823)	Loss 1.8135 (1.7254)	Prec@1 49.219 (52.815)	
Epoch: [8][155/391]	LR: 0.02	DT: 0.000 (1.807)	BT: 0.511 (3.472)	Loss 1.7783 (1.7453)	Prec@1 53.125 (52.569)	
Epoch: [8][233/391]	LR: 0.02	DT: 0.000 (1.559)	BT: 0.526 (3.481)	Loss 1.7432 (1.7444)	Prec@1 49.219 (52.641)	
Epoch: [8][311/391]	LR: 0.02	DT: 0.000 (1.441)	BT: 0.514 (3.488)	Loss 1.7051 (1.7394)	Prec@1 53.906 (52.742)	
Epoch: [8][389/391]	LR: 0.02	DT: 0.000 (1.541)	BT: 0.501 (3.435)	Loss 1.8906 (1.7372)	Prec@1 54.688 (52.766)	
Total train loss: 1.7372
Avg Loading time: 1.5369 seconds
Avg Batch time: 3.4270 seconds

Train time: 1340.0563418865204
 * Prec@1 44.290 Prec@5 74.660 Loss 2.1641
Avg Loading time: 2.1204 seconds
Avg Batch time: 3.4302 seconds

Best acc: 45.300
--------------------------------------------------------------------------------
Test time: 271.67261838912964

Epoch: [9][77/391]	LR: 0.02	DT: 0.000 (2.658)	BT: 0.510 (3.556)	Loss 1.7129 (1.7088)	Prec@1 50.781 (53.195)	
Epoch: [9][155/391]	LR: 0.02	DT: 0.000 (2.365)	BT: 0.514 (4.032)	Loss 1.5762 (1.7223)	Prec@1 56.250 (52.825)	
Epoch: [9][233/391]	LR: 0.02	DT: 7.544 (2.460)	BT: 8.059 (3.999)	Loss 1.8486 (1.7197)	Prec@1 49.219 (53.048)	
Epoch: [9][311/391]	LR: 0.02	DT: 0.000 (2.581)	BT: 0.513 (3.863)	Loss 1.7305 (1.7313)	Prec@1 50.000 (52.689)	
Epoch: [9][389/391]	LR: 0.02	DT: 0.000 (2.528)	BT: 0.512 (3.657)	Loss 1.6416 (1.7496)	Prec@1 50.000 (52.418)	
Total train loss: 1.7502
Avg Loading time: 2.5219 seconds
Avg Batch time: 3.6487 seconds

Train time: 1426.7736415863037
 * Prec@1 35.860 Prec@5 66.750 Loss 2.5332
Avg Loading time: 1.8120 seconds
Avg Batch time: 2.3412 seconds

Best acc: 45.300
--------------------------------------------------------------------------------
Test time: 185.6156771183014

Epoch: [10][77/391]	LR: 0.004	DT: 0.000 (0.996)	BT: 0.514 (1.894)	Loss 1.7441 (1.7623)	Prec@1 52.344 (52.594)	
Epoch: [10][155/391]	LR: 0.004	DT: 0.000 (0.914)	BT: 0.508 (1.620)	Loss 1.7588 (1.7424)	Prec@1 51.562 (52.930)	
Epoch: [10][233/391]	LR: 0.004	DT: 2.320 (1.059)	BT: 2.837 (1.701)	Loss 1.7080 (1.7382)	Prec@1 49.219 (52.935)	
Epoch: [10][311/391]	LR: 0.004	DT: 0.000 (1.175)	BT: 0.507 (1.785)	Loss 1.6729 (1.7322)	Prec@1 57.812 (53.067)	
Epoch: [10][389/391]	LR: 0.004	DT: 0.000 (1.432)	BT: 0.512 (2.100)	Loss 1.8945 (1.7330)	Prec@1 43.750 (53.103)	
Total train loss: 1.7329
Avg Loading time: 1.4285 seconds
Avg Batch time: 2.0954 seconds

Train time: 819.4270491600037
 * Prec@1 51.710 Prec@5 81.210 Loss 1.8066
Avg Loading time: 1.4013 seconds
Avg Batch time: 3.4916 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 276.9855077266693

Epoch: [11][77/391]	LR: 0.004	DT: 0.000 (1.600)	BT: 0.510 (4.037)	Loss 1.7041 (1.7284)	Prec@1 52.344 (53.566)	
Epoch: [11][155/391]	LR: 0.004	DT: 2.778 (1.543)	BT: 3.295 (3.683)	Loss 1.7061 (1.7296)	Prec@1 53.906 (53.441)	
Epoch: [11][233/391]	LR: 0.004	DT: 0.000 (1.617)	BT: 0.510 (3.727)	Loss 1.6016 (1.7274)	Prec@1 58.594 (53.472)	
Epoch: [11][311/391]	LR: 0.004	DT: 0.000 (1.698)	BT: 0.513 (3.889)	Loss 1.7354 (1.7387)	Prec@1 58.594 (53.183)	
Epoch: [11][389/391]	LR: 0.004	DT: 0.000 (1.763)	BT: 0.507 (3.850)	Loss 1.4277 (1.7428)	Prec@1 61.719 (52.927)	
Total train loss: 1.7429
Avg Loading time: 1.7584 seconds
Avg Batch time: 3.8405 seconds

Train time: 1501.7627413272858
 * Prec@1 50.840 Prec@5 80.640 Loss 1.8252
Avg Loading time: 1.7667 seconds
Avg Batch time: 4.5780 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 362.325076341629

Epoch: [12][77/391]	LR: 0.004	DT: 0.808 (1.735)	BT: 1.321 (3.618)	Loss 1.7695 (1.7565)	Prec@1 45.312 (51.973)	
Epoch: [12][155/391]	LR: 0.004	DT: 0.000 (2.227)	BT: 0.511 (3.425)	Loss 1.7432 (1.7728)	Prec@1 51.562 (51.753)	
Epoch: [12][233/391]	LR: 0.004	DT: 5.206 (2.369)	BT: 5.718 (3.337)	Loss 1.7617 (1.7831)	Prec@1 50.000 (51.586)	
Epoch: [12][311/391]	LR: 0.004	DT: 0.000 (2.306)	BT: 0.507 (3.160)	Loss 1.7256 (1.7893)	Prec@1 52.344 (51.552)	
Epoch: [12][389/391]	LR: 0.004	DT: 0.000 (2.197)	BT: 0.507 (2.983)	Loss 1.7852 (1.7955)	Prec@1 53.906 (51.452)	
Total train loss: 1.7956
Avg Loading time: 2.1914 seconds
Avg Batch time: 2.9758 seconds

Train time: 1163.669732093811
 * Prec@1 48.090 Prec@5 79.070 Loss 1.9502
Avg Loading time: 1.2193 seconds
Avg Batch time: 2.4863 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 197.08471703529358

Epoch: [13][77/391]	LR: 0.004	DT: 0.000 (1.547)	BT: 0.513 (2.059)	Loss 1.9170 (1.7974)	Prec@1 51.562 (52.053)	
Epoch: [13][155/391]	LR: 0.004	DT: 0.000 (1.542)	BT: 0.512 (2.053)	Loss 1.9326 (1.8002)	Prec@1 46.875 (51.953)	
Epoch: [13][233/391]	LR: 0.004	DT: 2.754 (1.542)	BT: 3.269 (2.052)	Loss 1.7158 (1.8144)	Prec@1 56.250 (51.426)	
Epoch: [13][311/391]	LR: 0.004	DT: 0.000 (1.663)	BT: 0.512 (2.462)	Loss 1.6416 (1.8222)	Prec@1 52.344 (51.004)	
Epoch: [13][389/391]	LR: 0.004	DT: 0.000 (1.755)	BT: 0.506 (2.727)	Loss 1.8447 (1.8291)	Prec@1 50.000 (50.793)	
Total train loss: 1.8293
Avg Loading time: 1.7505 seconds
Avg Batch time: 2.7206 seconds

Train time: 1063.877907037735
 * Prec@1 45.280 Prec@5 76.800 Loss 2.0742
Avg Loading time: 1.7008 seconds
Avg Batch time: 5.0447 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 399.180269241333

Epoch: [14][77/391]	LR: 0.004	DT: 0.000 (1.632)	BT: 0.498 (2.184)	Loss 1.8389 (1.8233)	Prec@1 45.312 (50.711)	
Epoch: [14][155/391]	LR: 0.004	DT: 0.000 (1.634)	BT: 0.500 (2.185)	Loss 1.8633 (1.8304)	Prec@1 50.000 (50.796)	
Epoch: [14][233/391]	LR: 0.004	DT: 0.375 (1.520)	BT: 0.873 (2.055)	Loss 1.8994 (1.8440)	Prec@1 50.781 (50.481)	
Epoch: [14][311/391]	LR: 0.004	DT: 0.000 (1.431)	BT: 0.497 (1.957)	Loss 1.8281 (1.8528)	Prec@1 53.125 (50.336)	
Epoch: [14][389/391]	LR: 0.004	DT: 0.000 (1.391)	BT: 0.497 (1.912)	Loss 1.9326 (1.8553)	Prec@1 47.656 (50.142)	
Total train loss: 1.8555
Avg Loading time: 1.3877 seconds
Avg Batch time: 1.9082 seconds

Train time: 746.2105090618134
 * Prec@1 46.500 Prec@5 77.770 Loss 2.0215
Avg Loading time: 1.5971 seconds
Avg Batch time: 1.7675 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 140.31575179100037

Epoch: [15][77/391]	LR: 0.004	DT: 0.000 (1.316)	BT: 0.503 (1.868)	Loss 1.9443 (1.8444)	Prec@1 50.000 (50.831)	
Epoch: [15][155/391]	LR: 0.004	DT: 0.000 (1.280)	BT: 0.502 (1.807)	Loss 1.7002 (1.8573)	Prec@1 50.781 (49.875)	
Epoch: [15][233/391]	LR: 0.004	DT: 0.896 (1.294)	BT: 1.398 (1.812)	Loss 1.8906 (1.8673)	Prec@1 50.000 (49.459)	
Epoch: [15][311/391]	LR: 0.004	DT: 0.000 (1.272)	BT: 0.500 (1.786)	Loss 1.7754 (1.8740)	Prec@1 50.000 (49.472)	
Epoch: [15][389/391]	LR: 0.004	DT: 0.000 (1.285)	BT: 0.498 (1.796)	Loss 1.9980 (1.8771)	Prec@1 45.312 (49.365)	
Total train loss: 1.8774
Avg Loading time: 1.2814 seconds
Avg Batch time: 1.7925 seconds

Train time: 700.9886119365692
 * Prec@1 46.150 Prec@5 77.000 Loss 2.0469
Avg Loading time: 1.6556 seconds
Avg Batch time: 1.8686 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 148.27901530265808

Epoch: [16][77/391]	LR: 0.004	DT: 0.000 (1.371)	BT: 0.501 (1.871)	Loss 1.7812 (1.8606)	Prec@1 48.438 (49.199)	
Epoch: [16][155/391]	LR: 0.004	DT: 0.000 (1.370)	BT: 0.500 (1.870)	Loss 2.0215 (1.8786)	Prec@1 43.750 (48.958)	
Epoch: [16][233/391]	LR: 0.004	DT: 0.000 (1.307)	BT: 0.500 (1.808)	Loss 1.7549 (1.8731)	Prec@1 53.125 (49.276)	
Epoch: [16][311/391]	LR: 0.004	DT: 0.000 (1.198)	BT: 0.496 (1.699)	Loss 1.8730 (1.8824)	Prec@1 45.312 (49.189)	
Epoch: [16][389/391]	LR: 0.004	DT: 0.000 (1.109)	BT: 0.497 (1.610)	Loss 2.0625 (1.8900)	Prec@1 42.969 (48.992)	
Total train loss: 1.8898
Avg Loading time: 1.1062 seconds
Avg Batch time: 1.6065 seconds

Train time: 628.2560458183289
 * Prec@1 44.450 Prec@5 75.790 Loss 2.0859
Avg Loading time: 1.5418 seconds
Avg Batch time: 1.7130 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 136.00958561897278

Epoch: [17][77/391]	LR: 0.004	DT: 0.000 (1.205)	BT: 0.498 (1.706)	Loss 1.9854 (1.8909)	Prec@1 46.875 (48.938)	
Epoch: [17][155/391]	LR: 0.004	DT: 0.000 (0.920)	BT: 0.500 (1.421)	Loss 2.1816 (1.8897)	Prec@1 42.969 (49.094)	
Epoch: [17][233/391]	LR: 0.004	DT: 0.652 (0.829)	BT: 1.156 (1.330)	Loss 1.9395 (1.8784)	Prec@1 48.438 (49.329)	
Epoch: [17][311/391]	LR: 0.004	DT: 0.000 (0.766)	BT: 0.501 (1.267)	Loss 1.9043 (1.8836)	Prec@1 48.438 (49.299)	
Epoch: [17][389/391]	LR: 0.004	DT: 0.000 (0.731)	BT: 0.494 (1.232)	Loss 2.0059 (1.8828)	Prec@1 48.438 (49.291)	
Total train loss: 1.8829
Avg Loading time: 0.7288 seconds
Avg Batch time: 1.2294 seconds

Train time: 480.7909963130951
 * Prec@1 46.390 Prec@5 77.550 Loss 2.0137
Avg Loading time: 1.1663 seconds
Avg Batch time: 1.3459 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 106.98123931884766

Epoch: [18][77/391]	LR: 0.004	DT: 0.000 (0.962)	BT: 0.499 (1.463)	Loss 1.9805 (1.8929)	Prec@1 48.438 (48.768)	
Epoch: [18][155/391]	LR: 0.004	DT: 0.000 (1.302)	BT: 0.499 (1.802)	Loss 1.9580 (1.8812)	Prec@1 44.531 (49.184)	
Epoch: [18][233/391]	LR: 0.004	DT: 0.000 (1.398)	BT: 0.500 (1.898)	Loss 2.1777 (1.8846)	Prec@1 45.312 (49.165)	
Epoch: [18][311/391]	LR: 0.004	DT: 0.000 (1.344)	BT: 0.498 (1.843)	Loss 1.8740 (1.8900)	Prec@1 46.094 (48.996)	
Epoch: [18][389/391]	LR: 0.004	DT: 0.000 (1.330)	BT: 0.497 (1.830)	Loss 1.8027 (1.8937)	Prec@1 47.656 (48.944)	
Total train loss: 1.8936
Avg Loading time: 1.3268 seconds
Avg Batch time: 1.8261 seconds

Train time: 714.1147406101227
 * Prec@1 44.890 Prec@5 75.840 Loss 2.0762
Avg Loading time: 1.6288 seconds
Avg Batch time: 1.8550 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 147.2231285572052

Epoch: [19][77/391]	LR: 0.004	DT: 0.000 (1.359)	BT: 0.498 (1.860)	Loss 1.8408 (1.9128)	Prec@1 54.688 (49.069)	
Epoch: [19][155/391]	LR: 0.004	DT: 0.000 (1.348)	BT: 0.496 (1.848)	Loss 1.9844 (1.9072)	Prec@1 42.969 (48.753)	
Epoch: [19][233/391]	LR: 0.004	DT: 0.000 (1.348)	BT: 0.497 (1.848)	Loss 1.8359 (1.8984)	Prec@1 48.438 (48.695)	
Epoch: [19][311/391]	LR: 0.004	DT: 0.000 (1.314)	BT: 0.498 (1.814)	Loss 1.8477 (1.9012)	Prec@1 49.219 (48.605)	
Epoch: [19][389/391]	LR: 0.004	DT: 0.000 (1.327)	BT: 0.500 (1.828)	Loss 1.6260 (1.9002)	Prec@1 54.688 (48.810)	
Total train loss: 1.8998
Avg Loading time: 1.3240 seconds
Avg Batch time: 1.8237 seconds

Train time: 713.1824040412903
 * Prec@1 41.150 Prec@5 72.150 Loss 2.2871
Avg Loading time: 1.7185 seconds
Avg Batch time: 1.9233 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 152.60397386550903

Epoch: [20][77/391]	LR: 0.0008	DT: 0.000 (1.427)	BT: 0.500 (1.978)	Loss 1.8271 (1.8486)	Prec@1 48.438 (50.551)	
Epoch: [20][155/391]	LR: 0.0008	DT: 0.000 (1.393)	BT: 0.498 (1.918)	Loss 1.9307 (1.8579)	Prec@1 47.656 (49.955)	
Epoch: [20][233/391]	LR: 0.0008	DT: 0.000 (1.380)	BT: 0.498 (1.897)	Loss 1.7695 (1.8468)	Prec@1 47.656 (50.073)	
Epoch: [20][311/391]	LR: 0.0008	DT: 0.000 (1.346)	BT: 0.498 (1.858)	Loss 1.9590 (1.8487)	Prec@1 41.406 (50.063)	
Epoch: [20][389/391]	LR: 0.0008	DT: 0.000 (1.348)	BT: 0.497 (1.858)	Loss 1.7695 (1.8493)	Prec@1 54.688 (50.046)	
Total train loss: 1.8492
Avg Loading time: 1.3444 seconds
Avg Batch time: 1.8537 seconds

Train time: 724.8976511955261
 * Prec@1 46.540 Prec@5 77.520 Loss 2.0273
Avg Loading time: 1.7492 seconds
Avg Batch time: 2.0259 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 160.69318461418152

Epoch: [21][77/391]	LR: 0.0008	DT: 0.000 (1.713)	BT: 0.500 (2.265)	Loss 1.9131 (1.8418)	Prec@1 43.750 (50.310)	
Epoch: [21][155/391]	LR: 0.0008	DT: 0.000 (1.708)	BT: 0.501 (2.258)	Loss 1.9580 (1.8518)	Prec@1 50.781 (49.644)	
Epoch: [21][233/391]	LR: 0.0008	DT: 0.856 (1.580)	BT: 1.361 (2.113)	Loss 1.9922 (1.8449)	Prec@1 48.438 (49.903)	
Epoch: [21][311/391]	LR: 0.0008	DT: 0.000 (1.440)	BT: 0.502 (1.965)	Loss 1.7900 (1.8383)	Prec@1 50.781 (50.153)	
Epoch: [21][389/391]	LR: 0.0008	DT: 0.000 (1.290)	BT: 0.497 (1.810)	Loss 1.8330 (1.8408)	Prec@1 50.000 (50.244)	
Total train loss: 1.8408
Avg Loading time: 1.2867 seconds
Avg Batch time: 1.8065 seconds

Train time: 706.4399516582489
 * Prec@1 47.270 Prec@5 77.820 Loss 1.9971
Avg Loading time: 1.0846 seconds
Avg Batch time: 1.2513 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 99.51864194869995

Epoch: [22][77/391]	LR: 0.0008	DT: 0.000 (0.707)	BT: 0.500 (1.207)	Loss 1.7871 (1.8213)	Prec@1 48.438 (51.112)	
Epoch: [22][155/391]	LR: 0.0008	DT: 0.000 (0.690)	BT: 0.498 (1.190)	Loss 1.8389 (1.8209)	Prec@1 53.906 (50.936)	
Epoch: [22][233/391]	LR: 0.0008	DT: 1.916 (0.670)	BT: 2.420 (1.170)	Loss 1.8379 (1.8293)	Prec@1 55.469 (50.858)	
Epoch: [22][311/391]	LR: 0.0008	DT: 0.000 (0.615)	BT: 0.501 (1.115)	Loss 1.9922 (1.8372)	Prec@1 46.094 (50.498)	
Epoch: [22][389/391]	LR: 0.0008	DT: 0.000 (0.618)	BT: 0.497 (1.118)	Loss 1.7314 (1.8435)	Prec@1 57.812 (50.391)	
Total train loss: 1.8435
Avg Loading time: 0.6163 seconds
Avg Batch time: 1.1162 seconds

Train time: 436.5391697883606
 * Prec@1 48.340 Prec@5 78.640 Loss 1.9443
Avg Loading time: 0.9615 seconds
Avg Batch time: 1.1267 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 89.68362164497375

Epoch: [23][77/391]	LR: 0.0008	DT: 0.000 (0.605)	BT: 0.502 (1.106)	Loss 2.0332 (1.8425)	Prec@1 47.656 (50.240)	
Epoch: [23][155/391]	LR: 0.0008	DT: 0.000 (0.627)	BT: 0.501 (1.128)	Loss 1.7695 (1.8375)	Prec@1 56.250 (50.200)	
Epoch: [23][233/391]	LR: 0.0008	DT: 0.702 (0.644)	BT: 1.206 (1.145)	Loss 1.9258 (1.8349)	Prec@1 53.906 (50.237)	
Epoch: [23][311/391]	LR: 0.0008	DT: 0.000 (0.641)	BT: 0.500 (1.142)	Loss 2.0176 (1.8385)	Prec@1 47.656 (50.258)	
Epoch: [23][389/391]	LR: 0.0008	DT: 0.000 (0.764)	BT: 0.497 (1.264)	Loss 1.5557 (1.8391)	Prec@1 52.344 (50.286)	
Total train loss: 1.8398
Avg Loading time: 0.7616 seconds
Avg Batch time: 1.2620 seconds

Train time: 493.5766952037811
 * Prec@1 47.870 Prec@5 78.320 Loss 1.9678
Avg Loading time: 1.6373 seconds
Avg Batch time: 1.8657 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 148.07373070716858

Epoch: [24][77/391]	LR: 0.0008	DT: 0.000 (1.386)	BT: 0.499 (1.938)	Loss 1.8223 (1.8475)	Prec@1 50.781 (50.100)	
Epoch: [24][155/391]	LR: 0.0008	DT: 0.000 (1.377)	BT: 0.501 (1.903)	Loss 1.9697 (1.8424)	Prec@1 55.469 (50.120)	
Epoch: [24][233/391]	LR: 0.0008	DT: 0.214 (1.372)	BT: 0.715 (1.890)	Loss 1.9297 (1.8444)	Prec@1 46.875 (50.037)	
Epoch: [24][311/391]	LR: 0.0008	DT: 0.000 (1.340)	BT: 0.499 (1.854)	Loss 1.8906 (1.8428)	Prec@1 48.438 (50.240)	
Epoch: [24][389/391]	LR: 0.0008	DT: 0.000 (1.344)	BT: 0.498 (1.854)	Loss 1.7637 (1.8390)	Prec@1 49.219 (50.238)	
Total train loss: 1.8391
Avg Loading time: 1.3402 seconds
Avg Batch time: 1.8506 seconds

Train time: 723.6853828430176
 * Prec@1 47.190 Prec@5 77.880 Loss 1.9971
Avg Loading time: 1.6679 seconds
Avg Batch time: 1.9340 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 153.44790625572205

Epoch: [25][77/391]	LR: 0.0008	DT: 0.000 (1.619)	BT: 0.501 (2.273)	Loss 1.9141 (1.8362)	Prec@1 47.656 (50.431)	
Epoch: [25][155/391]	LR: 0.0008	DT: 0.000 (1.685)	BT: 0.498 (2.288)	Loss 1.9326 (1.8252)	Prec@1 50.000 (50.501)	
Epoch: [25][233/391]	LR: 0.0008	DT: 1.911 (1.712)	BT: 2.415 (2.281)	Loss 1.8955 (1.8294)	Prec@1 49.219 (50.497)	
Epoch: [25][311/391]	LR: 0.0008	DT: 0.000 (1.623)	BT: 0.498 (2.175)	Loss 1.7988 (1.8338)	Prec@1 46.875 (50.316)	
Epoch: [25][389/391]	LR: 0.0008	DT: 0.000 (1.567)	BT: 0.497 (2.109)	Loss 1.8574 (1.8369)	Prec@1 49.219 (50.218)	
Total train loss: 1.8374
Avg Loading time: 1.5630 seconds
Avg Batch time: 2.1044 seconds

Train time: 822.9099130630493
 * Prec@1 47.650 Prec@5 78.230 Loss 1.9775
Avg Loading time: 1.6778 seconds
Avg Batch time: 1.9534 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 154.99925875663757

Epoch: [26][77/391]	LR: 0.0008	DT: 0.000 (1.541)	BT: 0.501 (2.092)	Loss 1.7266 (1.8383)	Prec@1 51.562 (50.150)	
Epoch: [26][155/391]	LR: 0.0008	DT: 0.000 (1.563)	BT: 0.498 (2.115)	Loss 1.9580 (1.8442)	Prec@1 47.656 (49.940)	
Epoch: [26][233/391]	LR: 0.0008	DT: 0.000 (1.599)	BT: 0.500 (2.134)	Loss 1.6709 (1.8387)	Prec@1 57.031 (50.244)	
Epoch: [26][311/391]	LR: 0.0008	DT: 0.000 (1.563)	BT: 0.501 (2.102)	Loss 1.9512 (1.8412)	Prec@1 46.094 (50.265)	
Epoch: [26][389/391]	LR: 0.0008	DT: 0.000 (1.558)	BT: 0.498 (2.089)	Loss 1.9229 (1.8421)	Prec@1 48.438 (50.248)	
Total train loss: 1.8420
Avg Loading time: 1.5542 seconds
Avg Batch time: 2.0845 seconds

Train time: 815.1602284908295
 * Prec@1 48.280 Prec@5 78.750 Loss 1.9395
Avg Loading time: 1.5325 seconds
Avg Batch time: 1.6772 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 133.16158866882324

Epoch: [27][77/391]	LR: 0.0008	DT: 0.000 (0.896)	BT: 0.501 (1.397)	Loss 1.8760 (1.8551)	Prec@1 49.219 (49.850)	
Epoch: [27][155/391]	LR: 0.0008	DT: 0.000 (0.854)	BT: 0.499 (1.354)	Loss 1.8271 (1.8403)	Prec@1 50.000 (50.336)	
Epoch: [27][233/391]	LR: 0.0008	DT: 0.000 (0.862)	BT: 0.501 (1.362)	Loss 1.6650 (1.8333)	Prec@1 54.688 (50.454)	
Epoch: [27][311/391]	LR: 0.0008	DT: 0.000 (0.844)	BT: 0.500 (1.344)	Loss 1.7314 (1.8389)	Prec@1 51.562 (50.305)	
Epoch: [27][389/391]	LR: 0.0008	DT: 0.000 (0.856)	BT: 0.499 (1.357)	Loss 1.9297 (1.8402)	Prec@1 51.562 (50.329)	
Total train loss: 1.8404
Avg Loading time: 0.8542 seconds
Avg Batch time: 1.3540 seconds

Train time: 529.5463726520538
 * Prec@1 47.670 Prec@5 78.100 Loss 1.9727
Avg Loading time: 1.6799 seconds
Avg Batch time: 1.8869 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 149.70370626449585

Epoch: [28][77/391]	LR: 0.0008	DT: 0.000 (0.870)	BT: 0.496 (1.371)	Loss 1.8887 (1.8255)	Prec@1 52.344 (50.741)	
Epoch: [28][155/391]	LR: 0.0008	DT: 0.000 (0.801)	BT: 0.496 (1.302)	Loss 1.7373 (1.8359)	Prec@1 50.000 (50.666)	
Epoch: [28][233/391]	LR: 0.0008	DT: 1.705 (0.750)	BT: 2.208 (1.250)	Loss 1.9404 (1.8357)	Prec@1 43.750 (50.624)	
Epoch: [28][311/391]	LR: 0.0008	DT: 0.000 (0.728)	BT: 0.500 (1.229)	Loss 1.9600 (1.8316)	Prec@1 46.094 (50.714)	
Epoch: [28][389/391]	LR: 0.0008	DT: 0.000 (0.726)	BT: 0.497 (1.226)	Loss 1.7803 (1.8354)	Prec@1 49.219 (50.455)	
Total train loss: 1.8355
Avg Loading time: 0.7239 seconds
Avg Batch time: 1.2241 seconds

Train time: 478.7338387966156
 * Prec@1 47.160 Prec@5 77.590 Loss 2.0039
Avg Loading time: 1.1174 seconds
Avg Batch time: 1.2545 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 99.764897108078

Epoch: [29][77/391]	LR: 0.0008	DT: 0.000 (1.354)	BT: 0.498 (1.905)	Loss 1.7402 (1.8194)	Prec@1 50.781 (50.701)	
Epoch: [29][155/391]	LR: 0.0008	DT: 0.000 (1.582)	BT: 0.500 (2.108)	Loss 2.1270 (1.8305)	Prec@1 42.188 (50.586)	
Epoch: [29][233/391]	LR: 0.0008	DT: 1.736 (1.659)	BT: 2.237 (2.177)	Loss 2.0469 (1.8324)	Prec@1 46.094 (50.745)	
Epoch: [29][311/391]	LR: 0.0008	DT: 0.000 (1.564)	BT: 0.501 (2.077)	Loss 1.6416 (1.8330)	Prec@1 55.469 (50.598)	
Epoch: [29][389/391]	LR: 0.0008	DT: 0.000 (1.501)	BT: 0.501 (2.012)	Loss 2.0430 (1.8349)	Prec@1 43.750 (50.481)	
Total train loss: 1.8353
Avg Loading time: 1.4972 seconds
Avg Batch time: 2.0077 seconds

Train time: 785.1166632175446
 * Prec@1 47.390 Prec@5 77.940 Loss 1.9746
Avg Loading time: 1.6385 seconds
Avg Batch time: 1.9046 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 151.12053871154785

Epoch: [30][77/391]	LR: 0.00016	DT: 0.000 (1.391)	BT: 0.500 (1.944)	Loss 1.9082 (1.7997)	Prec@1 46.094 (51.743)	
Epoch: [30][155/391]	LR: 0.00016	DT: 0.000 (1.427)	BT: 0.503 (1.953)	Loss 1.8711 (1.8103)	Prec@1 47.656 (51.643)	
Epoch: [30][233/391]	LR: 0.00016	DT: 0.000 (1.538)	BT: 0.500 (2.090)	Loss 2.0332 (1.8242)	Prec@1 52.344 (51.002)	
Epoch: [30][311/391]	LR: 0.00016	DT: 0.000 (1.640)	BT: 0.499 (2.256)	Loss 1.8623 (1.8254)	Prec@1 53.906 (50.846)	
Epoch: [30][389/391]	LR: 0.00016	DT: 0.000 (1.654)	BT: 0.500 (2.257)	Loss 1.9971 (1.8234)	Prec@1 46.094 (50.877)	
Total train loss: 1.8235
Avg Loading time: 1.6502 seconds
Avg Batch time: 2.2525 seconds

Train time: 880.8412957191467
 * Prec@1 47.400 Prec@5 78.130 Loss 1.9805
Avg Loading time: 1.9156 seconds
Avg Batch time: 2.2840 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 181.11572980880737

Epoch: [31][77/391]	LR: 0.00016	DT: 0.000 (1.402)	BT: 0.498 (1.953)	Loss 1.8018 (1.8361)	Prec@1 50.781 (49.700)	
Epoch: [31][155/391]	LR: 0.00016	DT: 0.000 (1.432)	BT: 0.498 (1.958)	Loss 2.0039 (1.8362)	Prec@1 47.656 (50.240)	
Epoch: [31][233/391]	LR: 0.00016	DT: 1.814 (1.434)	BT: 2.318 (1.951)	Loss 1.8984 (1.8293)	Prec@1 42.969 (50.674)	
Epoch: [31][311/391]	LR: 0.00016	DT: 0.000 (1.407)	BT: 0.499 (1.920)	Loss 1.7959 (1.8293)	Prec@1 50.000 (50.656)	
Epoch: [31][389/391]	LR: 0.00016	DT: 0.000 (1.510)	BT: 0.497 (2.051)	Loss 1.9502 (1.8263)	Prec@1 50.781 (50.693)	
Total train loss: 1.8264
Avg Loading time: 1.5062 seconds
Avg Batch time: 2.0466 seconds

Train time: 800.3449413776398
 * Prec@1 47.760 Prec@5 78.140 Loss 1.9717
Avg Loading time: 1.8971 seconds
Avg Batch time: 2.1062 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 167.03263425827026

Epoch: [32][77/391]	LR: 0.00016	DT: 0.000 (1.155)	BT: 0.497 (1.707)	Loss 1.8955 (1.8246)	Prec@1 50.781 (50.741)	
Epoch: [32][155/391]	LR: 0.00016	DT: 0.000 (1.057)	BT: 0.500 (1.584)	Loss 1.8604 (1.8154)	Prec@1 48.438 (51.112)	
Epoch: [32][233/391]	LR: 0.00016	DT: 0.000 (1.012)	BT: 0.501 (1.530)	Loss 1.8457 (1.8212)	Prec@1 48.438 (50.978)	
Epoch: [32][311/391]	LR: 0.00016	DT: 0.000 (0.994)	BT: 0.500 (1.507)	Loss 1.6436 (1.8224)	Prec@1 56.250 (51.012)	
Epoch: [32][389/391]	LR: 0.00016	DT: 0.000 (0.960)	BT: 0.498 (1.470)	Loss 1.9150 (1.8281)	Prec@1 42.188 (50.865)	
Total train loss: 1.8283
Avg Loading time: 0.9572 seconds
Avg Batch time: 1.4675 seconds

Train time: 573.925360918045
 * Prec@1 47.760 Prec@5 78.160 Loss 1.9756
Avg Loading time: 1.7224 seconds
Avg Batch time: 2.1051 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 166.96979570388794

Epoch: [33][77/391]	LR: 0.00016	DT: 0.000 (1.827)	BT: 0.498 (2.379)	Loss 1.9023 (1.8353)	Prec@1 48.438 (50.461)	
Epoch: [33][155/391]	LR: 0.00016	DT: 0.000 (1.526)	BT: 0.506 (2.052)	Loss 1.6865 (1.8303)	Prec@1 54.688 (50.531)	
Epoch: [33][233/391]	LR: 0.00016	DT: 1.464 (1.250)	BT: 1.968 (1.768)	Loss 2.1426 (1.8289)	Prec@1 46.875 (50.548)	
Epoch: [33][311/391]	LR: 0.00016	DT: 0.000 (1.078)	BT: 0.501 (1.591)	Loss 1.6748 (1.8299)	Prec@1 57.031 (50.543)	
Epoch: [33][389/391]	LR: 0.00016	DT: 0.000 (1.000)	BT: 0.498 (1.511)	Loss 1.8779 (1.8279)	Prec@1 48.438 (50.585)	
Total train loss: 1.8279
Avg Loading time: 0.9974 seconds
Avg Batch time: 1.5077 seconds

Train time: 589.6297545433044
 * Prec@1 47.250 Prec@5 78.020 Loss 1.9775
Avg Loading time: 1.1391 seconds
Avg Batch time: 1.2997 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 103.3209388256073

Epoch: [34][77/391]	LR: 0.00016	DT: 0.000 (0.986)	BT: 0.501 (1.487)	Loss 1.9043 (1.8273)	Prec@1 47.656 (50.621)	
Epoch: [34][155/391]	LR: 0.00016	DT: 0.000 (1.258)	BT: 0.503 (1.759)	Loss 2.0371 (1.8313)	Prec@1 50.000 (50.551)	
Epoch: [34][233/391]	LR: 0.00016	DT: 0.116 (1.331)	BT: 0.622 (1.833)	Loss 1.5293 (1.8230)	Prec@1 62.500 (50.775)	
Epoch: [34][311/391]	LR: 0.00016	DT: 0.000 (1.418)	BT: 0.498 (1.919)	Loss 1.9697 (1.8229)	Prec@1 49.219 (50.891)	
Epoch: [34][389/391]	LR: 0.00016	DT: 0.000 (1.463)	BT: 0.500 (1.964)	Loss 1.8877 (1.8257)	Prec@1 54.688 (50.847)	
Total train loss: 1.8257
Avg Loading time: 1.4593 seconds
Avg Batch time: 1.9603 seconds

Train time: 766.5792620182037
 * Prec@1 47.590 Prec@5 78.090 Loss 1.9775
Avg Loading time: 1.8503 seconds
Avg Batch time: 2.2837 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 181.08778882026672

Epoch: [35][77/391]	LR: 0.00016	DT: 0.000 (1.609)	BT: 0.500 (2.161)	Loss 1.7578 (1.8096)	Prec@1 53.906 (51.272)	
Epoch: [35][155/391]	LR: 0.00016	DT: 0.000 (1.498)	BT: 0.497 (2.024)	Loss 1.9893 (1.8198)	Prec@1 46.875 (51.067)	
Epoch: [35][233/391]	LR: 0.00016	DT: 0.000 (1.446)	BT: 0.500 (1.963)	Loss 1.9707 (1.8215)	Prec@1 46.875 (50.958)	
Epoch: [35][311/391]	LR: 0.00016	DT: 0.000 (1.401)	BT: 0.501 (1.914)	Loss 1.6758 (1.8268)	Prec@1 53.125 (50.794)	
Epoch: [35][389/391]	LR: 0.00016	DT: 0.000 (1.390)	BT: 0.499 (1.901)	Loss 1.6924 (1.8277)	Prec@1 50.000 (50.721)	
Total train loss: 1.8277
Avg Loading time: 1.3865 seconds
Avg Batch time: 1.8967 seconds

Train time: 741.72354388237
 * Prec@1 47.600 Prec@5 78.380 Loss 1.9756
Avg Loading time: 1.7802 seconds
Avg Batch time: 1.9931 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 158.10446071624756

Epoch: [36][77/391]	LR: 0.00016	DT: 0.000 (1.490)	BT: 0.498 (2.041)	Loss 1.8232 (1.8128)	Prec@1 52.344 (50.801)	
Epoch: [36][155/391]	LR: 0.00016	DT: 0.000 (1.515)	BT: 0.499 (2.040)	Loss 1.9658 (1.8262)	Prec@1 56.250 (50.596)	
Epoch: [36][233/391]	LR: 0.00016	DT: 1.775 (1.530)	BT: 2.281 (2.047)	Loss 1.9561 (1.8215)	Prec@1 43.750 (50.704)	
Epoch: [36][311/391]	LR: 0.00016	DT: 0.000 (1.499)	BT: 0.500 (2.012)	Loss 1.5059 (1.8267)	Prec@1 57.031 (50.819)	
Epoch: [36][389/391]	LR: 0.00016	DT: 0.000 (1.483)	BT: 0.498 (1.993)	Loss 1.8750 (1.8274)	Prec@1 50.781 (50.707)	
Total train loss: 1.8274
Avg Loading time: 1.4792 seconds
Avg Batch time: 1.9890 seconds

Train time: 777.8106026649475
 * Prec@1 47.880 Prec@5 78.180 Loss 1.9756
Avg Loading time: 1.9563 seconds
Avg Batch time: 2.3822 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 188.849711894989

Epoch: [37][77/391]	LR: 0.00016	DT: 0.000 (1.593)	BT: 0.498 (2.195)	Loss 1.7354 (1.8351)	Prec@1 52.344 (50.371)	
Epoch: [37][155/391]	LR: 0.00016	DT: 0.000 (1.367)	BT: 0.500 (1.919)	Loss 1.5654 (1.8206)	Prec@1 58.594 (50.831)	
Epoch: [37][233/391]	LR: 0.00016	DT: 0.000 (1.194)	BT: 0.501 (1.729)	Loss 2.1367 (1.8302)	Prec@1 41.406 (50.698)	
Epoch: [37][311/391]	LR: 0.00016	DT: 0.000 (1.099)	BT: 0.499 (1.625)	Loss 1.9199 (1.8360)	Prec@1 51.562 (50.626)	
Epoch: [37][389/391]	LR: 0.00016	DT: 0.000 (1.059)	BT: 0.497 (1.581)	Loss 1.6807 (1.8292)	Prec@1 55.469 (50.809)	
Total train loss: 1.8291
Avg Loading time: 1.0565 seconds
Avg Batch time: 1.5773 seconds

Train time: 616.8402564525604
 * Prec@1 47.340 Prec@5 78.080 Loss 1.9893
Avg Loading time: 1.3455 seconds
Avg Batch time: 1.5062 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 119.66701126098633

Epoch: [38][77/391]	LR: 0.00016	DT: 0.000 (1.507)	BT: 0.501 (2.058)	Loss 1.7871 (1.8232)	Prec@1 50.000 (51.242)	
Epoch: [38][155/391]	LR: 0.00016	DT: 0.000 (1.563)	BT: 0.499 (2.088)	Loss 2.1289 (1.8262)	Prec@1 49.219 (50.921)	
Epoch: [38][233/391]	LR: 0.00016	DT: 1.090 (1.443)	BT: 1.592 (1.960)	Loss 1.8994 (1.8244)	Prec@1 43.750 (50.835)	
Epoch: [38][311/391]	LR: 0.00016	DT: 0.000 (1.302)	BT: 0.498 (1.815)	Loss 1.9072 (1.8208)	Prec@1 50.781 (50.799)	
Epoch: [38][389/391]	LR: 0.00016	DT: 0.000 (1.216)	BT: 0.498 (1.726)	Loss 1.7070 (1.8224)	Prec@1 53.125 (50.859)	
Total train loss: 1.8223
Avg Loading time: 1.2131 seconds
Avg Batch time: 1.7228 seconds

Train time: 673.743878364563
 * Prec@1 48.050 Prec@5 78.090 Loss 1.9697
Avg Loading time: 1.2790 seconds
Avg Batch time: 1.4360 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 114.09720301628113

Epoch: [39][77/391]	LR: 0.00016	DT: 0.000 (0.789)	BT: 0.498 (1.290)	Loss 1.7852 (1.8265)	Prec@1 48.438 (50.821)	
Epoch: [39][155/391]	LR: 0.00016	DT: 0.000 (0.828)	BT: 0.500 (1.329)	Loss 1.7227 (1.8326)	Prec@1 53.906 (50.836)	
Epoch: [39][233/391]	LR: 0.00016	DT: 2.981 (1.018)	BT: 3.483 (1.519)	Loss 1.9131 (1.8262)	Prec@1 41.406 (50.758)	
Epoch: [39][311/391]	LR: 0.00016	DT: 0.000 (1.088)	BT: 0.501 (1.589)	Loss 1.7988 (1.8288)	Prec@1 52.344 (50.644)	
Epoch: [39][389/391]	LR: 0.00016	DT: 0.000 (1.156)	BT: 0.500 (1.656)	Loss 1.9678 (1.8317)	Prec@1 44.531 (50.507)	
Total train loss: 1.8319
Avg Loading time: 1.1530 seconds
Avg Batch time: 1.6531 seconds

Train time: 646.4509541988373
 * Prec@1 47.630 Prec@5 78.060 Loss 1.9717
Avg Loading time: 1.7096 seconds
Avg Batch time: 1.9866 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 157.60649466514587

Epoch: [40][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.462)	BT: 0.498 (2.013)	Loss 1.9033 (1.8344)	Prec@1 52.344 (50.310)	
Epoch: [40][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.474)	BT: 0.498 (1.999)	Loss 1.9600 (1.8150)	Prec@1 52.344 (50.886)	
Epoch: [40][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.468)	BT: 0.495 (1.985)	Loss 1.6348 (1.8111)	Prec@1 53.125 (50.945)	
Epoch: [40][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.452)	BT: 0.501 (1.964)	Loss 1.9639 (1.8220)	Prec@1 40.625 (50.518)	
Epoch: [40][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.472)	BT: 0.498 (1.982)	Loss 1.7998 (1.8235)	Prec@1 50.781 (50.521)	
Total train loss: 1.8238
Avg Loading time: 1.4685 seconds
Avg Batch time: 1.9777 seconds

Train time: 773.4035804271698
 * Prec@1 47.310 Prec@5 77.970 Loss 1.9902
Avg Loading time: 1.8326 seconds
Avg Batch time: 2.2037 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 174.76287579536438

Epoch: [41][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.737)	BT: 0.498 (2.289)	Loss 1.8828 (1.8364)	Prec@1 51.562 (50.581)	
Epoch: [41][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.615)	BT: 0.502 (2.141)	Loss 1.8604 (1.8319)	Prec@1 50.000 (50.696)	
Epoch: [41][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.554)	BT: 0.500 (2.072)	Loss 1.9111 (1.8347)	Prec@1 46.875 (50.628)	
Epoch: [41][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.487)	BT: 0.499 (2.000)	Loss 1.8320 (1.8295)	Prec@1 50.000 (50.568)	
Epoch: [41][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.469)	BT: 0.499 (1.980)	Loss 1.7764 (1.8265)	Prec@1 50.781 (50.749)	
Total train loss: 1.8265
Avg Loading time: 1.4652 seconds
Avg Batch time: 1.9756 seconds

Train time: 772.5618369579315
 * Prec@1 47.590 Prec@5 77.850 Loss 1.9844
Avg Loading time: 1.7629 seconds
Avg Batch time: 1.9813 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 157.1916525363922

Epoch: [42][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.480)	BT: 0.504 (2.035)	Loss 1.8975 (1.8258)	Prec@1 49.219 (50.921)	
Epoch: [42][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.195)	BT: 0.505 (1.725)	Loss 2.0645 (1.8290)	Prec@1 42.188 (50.851)	
Epoch: [42][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.087)	BT: 0.501 (1.609)	Loss 1.7549 (1.8218)	Prec@1 50.781 (50.858)	
Epoch: [42][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.033)	BT: 0.503 (1.552)	Loss 1.5781 (1.8220)	Prec@1 56.250 (50.891)	
Epoch: [42][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.019)	BT: 0.506 (1.534)	Loss 2.0586 (1.8229)	Prec@1 45.312 (50.893)	
Total train loss: 1.8225
Avg Loading time: 1.0161 seconds
Avg Batch time: 1.5313 seconds

Train time: 598.841299533844
 * Prec@1 47.540 Prec@5 78.050 Loss 1.9775
Avg Loading time: 1.3932 seconds
Avg Batch time: 1.5681 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 124.54623436927795

Epoch: [43][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.457)	BT: 0.504 (2.015)	Loss 1.8789 (1.8303)	Prec@1 50.000 (51.062)	
Epoch: [43][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.545)	BT: 0.503 (2.076)	Loss 1.7783 (1.8382)	Prec@1 49.219 (50.586)	
Epoch: [43][233/391]	LR: 3.2000000000000005e-05	DT: 0.611 (1.573)	BT: 1.120 (2.096)	Loss 1.9209 (1.8279)	Prec@1 52.344 (50.684)	
Epoch: [43][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.487)	BT: 0.504 (2.006)	Loss 1.9326 (1.8234)	Prec@1 45.312 (50.826)	
Epoch: [43][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.365)	BT: 0.503 (1.881)	Loss 1.6826 (1.8212)	Prec@1 58.594 (50.925)	
Total train loss: 1.8213
Avg Loading time: 1.3612 seconds
Avg Batch time: 1.8773 seconds

Train time: 734.1519885063171
 * Prec@1 48.080 Prec@5 78.340 Loss 1.9580
Avg Loading time: 1.2896 seconds
Avg Batch time: 1.4551 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 115.60974383354187

Epoch: [44][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (0.905)	BT: 0.509 (1.411)	Loss 2.0469 (1.7948)	Prec@1 46.094 (51.993)	
Epoch: [44][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (0.934)	BT: 0.501 (1.440)	Loss 1.9199 (1.8113)	Prec@1 42.969 (51.312)	
Epoch: [44][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (0.947)	BT: 0.506 (1.453)	Loss 1.8047 (1.8207)	Prec@1 49.219 (50.982)	
Epoch: [44][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (0.966)	BT: 0.505 (1.471)	Loss 1.9004 (1.8275)	Prec@1 45.312 (50.739)	
Epoch: [44][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.101)	BT: 0.504 (1.627)	Loss 1.8721 (1.8257)	Prec@1 53.906 (50.835)	
Total train loss: 1.8260
Avg Loading time: 1.0985 seconds
Avg Batch time: 1.6237 seconds

Train time: 634.9858224391937
 * Prec@1 47.520 Prec@5 77.880 Loss 1.9824
Avg Loading time: 2.0556 seconds
Avg Batch time: 2.4843 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 196.90911436080933

Epoch: [45][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.825)	BT: 0.505 (2.585)	Loss 1.7334 (1.8272)	Prec@1 53.906 (50.711)	
Epoch: [45][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.696)	BT: 0.506 (2.328)	Loss 1.7881 (1.8295)	Prec@1 51.562 (50.581)	
Epoch: [45][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.641)	BT: 0.504 (2.230)	Loss 1.7607 (1.8236)	Prec@1 55.469 (50.771)	
Epoch: [45][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.551)	BT: 0.500 (2.119)	Loss 1.8711 (1.8227)	Prec@1 46.875 (50.764)	
Epoch: [45][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.522)	BT: 0.499 (2.077)	Loss 1.6641 (1.8257)	Prec@1 59.375 (50.749)	
Total train loss: 1.8258
Avg Loading time: 1.5179 seconds
Avg Batch time: 2.0722 seconds

Train time: 810.3548250198364
 * Prec@1 47.640 Prec@5 78.250 Loss 1.9746
Avg Loading time: 1.8261 seconds
Avg Batch time: 2.0938 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 166.09352612495422

Epoch: [46][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.539)	BT: 0.503 (2.095)	Loss 1.8389 (1.8241)	Prec@1 51.562 (50.551)	
Epoch: [46][155/391]	LR: 3.2000000000000005e-05	DT: 0.001 (1.491)	BT: 0.502 (2.020)	Loss 1.8936 (1.8236)	Prec@1 49.219 (50.511)	
Epoch: [46][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.532)	BT: 0.498 (2.070)	Loss 1.7666 (1.8195)	Prec@1 51.562 (50.721)	
Epoch: [46][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.551)	BT: 0.503 (2.080)	Loss 1.6182 (1.8291)	Prec@1 50.000 (50.506)	
Epoch: [46][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.580)	BT: 0.501 (2.105)	Loss 1.8691 (1.8286)	Prec@1 51.562 (50.543)	
Total train loss: 1.8290
Avg Loading time: 1.5764 seconds
Avg Batch time: 2.1004 seconds

Train time: 821.391683101654
 * Prec@1 47.610 Prec@5 78.250 Loss 1.9756
Avg Loading time: 2.0570 seconds
Avg Batch time: 2.3028 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 182.5784673690796

Epoch: [47][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.575)	BT: 0.502 (2.131)	Loss 1.7461 (1.8354)	Prec@1 50.781 (50.521)	
Epoch: [47][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.353)	BT: 0.505 (1.885)	Loss 1.8076 (1.8316)	Prec@1 46.875 (50.371)	
Epoch: [47][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.185)	BT: 0.503 (1.707)	Loss 1.6299 (1.8265)	Prec@1 59.375 (50.561)	
Epoch: [47][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.100)	BT: 0.503 (1.618)	Loss 1.8740 (1.8251)	Prec@1 46.094 (50.556)	
Epoch: [47][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.055)	BT: 0.501 (1.571)	Loss 2.0898 (1.8220)	Prec@1 39.844 (50.695)	
Total train loss: 1.8228
Avg Loading time: 1.0524 seconds
Avg Batch time: 1.5680 seconds

Train time: 613.1935374736786
 * Prec@1 48.090 Prec@5 78.380 Loss 1.9629
Avg Loading time: 1.2874 seconds
Avg Batch time: 1.4541 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 115.54533672332764

Epoch: [48][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.390)	BT: 0.501 (1.892)	Loss 1.7246 (1.8500)	Prec@1 45.312 (50.130)	
Epoch: [48][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.454)	BT: 0.506 (1.956)	Loss 2.0117 (1.8319)	Prec@1 48.438 (50.401)	
Epoch: [48][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.449)	BT: 0.501 (1.952)	Loss 1.9580 (1.8353)	Prec@1 48.438 (50.721)	
Epoch: [48][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.500)	BT: 0.499 (2.028)	Loss 1.7871 (1.8265)	Prec@1 52.344 (50.881)	
Epoch: [48][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.552)	BT: 0.501 (2.074)	Loss 1.8145 (1.8267)	Prec@1 56.250 (50.645)	
Total train loss: 1.8263
Avg Loading time: 1.5476 seconds
Avg Batch time: 2.0691 seconds

Train time: 809.1431248188019
 * Prec@1 47.660 Prec@5 77.790 Loss 1.9932
Avg Loading time: 1.1845 seconds
Avg Batch time: 1.3427 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 106.729807138443

Epoch: [49][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (0.819)	BT: 0.510 (1.326)	Loss 1.9600 (1.8395)	Prec@1 48.438 (50.381)	
Epoch: [49][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (0.769)	BT: 0.502 (1.275)	Loss 1.7910 (1.8341)	Prec@1 53.906 (50.496)	
Epoch: [49][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (0.798)	BT: 0.502 (1.303)	Loss 1.8477 (1.8334)	Prec@1 57.812 (50.728)	
Epoch: [49][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (0.786)	BT: 0.502 (1.291)	Loss 1.9492 (1.8301)	Prec@1 48.438 (50.724)	
Epoch: [49][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (0.924)	BT: 0.501 (1.428)	Loss 1.5557 (1.8262)	Prec@1 56.250 (50.637)	
Total train loss: 1.8261
Avg Loading time: 0.9215 seconds
Avg Batch time: 1.4255 seconds

Train time: 557.4872901439667
 * Prec@1 47.710 Prec@5 78.180 Loss 1.9775
Avg Loading time: 1.8144 seconds
Avg Batch time: 2.0834 seconds

Best acc: 51.710
--------------------------------------------------------------------------------
Test time: 165.24168610572815


      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.02
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 3
          frozen_layers: 7
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar100/resnet18
DEVICE: cuda
GPU Id(s) being used: 3
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/train/relu7
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/test/relu7
ResNet18(
  (conv8): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): QConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): QConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): QConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): QConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=512, out_features=100, bias=False)
  (bn19): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 1.040 Prec@5 4.710 Loss 4.6055
Avg Loading time: 2.9286 seconds
Avg Batch time: 3.5625 seconds

Pre-trained Prec@1 with 7 layers frozen: 1.0399999618530273 	 Loss: 4.60546875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.02	DT: 0.000 (3.001)	BT: 0.353 (3.865)	Loss 2.2500 (2.7962)	Prec@1 46.094 (38.371)	
Epoch: [0][155/391]	LR: 0.02	DT: 0.386 (3.024)	BT: 0.735 (3.887)	Loss 1.8145 (2.3859)	Prec@1 58.594 (46.019)	
Epoch: [0][233/391]	LR: 0.02	DT: 0.000 (3.006)	BT: 0.347 (3.868)	Loss 1.8076 (2.2084)	Prec@1 53.125 (48.718)	
Epoch: [0][311/391]	LR: 0.02	DT: 0.000 (2.891)	BT: 0.346 (3.740)	Loss 1.7871 (2.1399)	Prec@1 59.375 (49.574)	
Epoch: [0][389/391]	LR: 0.02	DT: 0.000 (2.803)	BT: 0.350 (3.644)	Loss 1.8320 (2.0831)	Prec@1 44.531 (50.102)	
Total train loss: 2.0826
Avg Loading time: 2.7954 seconds
Avg Batch time: 3.6350 seconds

Train time: 1421.4091455936432
 * Prec@1 14.640 Prec@5 37.110 Loss 3.7129
Avg Loading time: 1.7615 seconds
Avg Batch time: 2.0279 seconds

Best acc: 14.640
--------------------------------------------------------------------------------
Test time: 161.33809876441956

Epoch: [1][77/391]	LR: 0.02	DT: 0.000 (1.754)	BT: 0.347 (2.154)	Loss 2.1602 (1.9349)	Prec@1 48.438 (51.492)	
Epoch: [1][155/391]	LR: 0.02	DT: 0.000 (1.760)	BT: 0.348 (2.159)	Loss 1.7100 (1.9466)	Prec@1 59.375 (50.731)	
Epoch: [1][233/391]	LR: 0.02	DT: 0.000 (1.737)	BT: 0.348 (2.119)	Loss 2.0098 (1.9715)	Prec@1 47.656 (49.886)	
Epoch: [1][311/391]	LR: 0.02	DT: 0.000 (1.594)	BT: 0.349 (1.968)	Loss 1.6084 (1.9615)	Prec@1 60.938 (49.815)	
Epoch: [1][389/391]	LR: 0.02	DT: 0.000 (1.522)	BT: 0.346 (1.891)	Loss 2.9258 (1.9553)	Prec@1 32.031 (49.790)	
Total train loss: 1.9568
Avg Loading time: 1.5184 seconds
Avg Batch time: 1.8863 seconds

Train time: 737.6801569461823
 * Prec@1 1.600 Prec@5 5.690 Loss inf
Avg Loading time: 1.6793 seconds
Avg Batch time: 1.8412 seconds

Best acc: 14.640
--------------------------------------------------------------------------------
Test time: 146.1333339214325

Epoch: [2][77/391]	LR: 0.02	DT: 0.000 (1.552)	BT: 0.347 (1.901)	Loss 1.9316 (2.1129)	Prec@1 50.000 (44.912)	
Epoch: [2][155/391]	LR: 0.02	DT: 0.000 (1.406)	BT: 0.346 (1.754)	Loss 1.6025 (1.9904)	Prec@1 59.375 (48.017)	
Epoch: [2][233/391]	LR: 0.02	DT: 0.000 (1.492)	BT: 0.350 (1.840)	Loss 1.8154 (1.9017)	Prec@1 51.562 (50.100)	
Epoch: [2][311/391]	LR: 0.02	DT: 0.000 (1.498)	BT: 0.346 (1.846)	Loss 1.7393 (1.8405)	Prec@1 52.344 (51.537)	
Epoch: [2][389/391]	LR: 0.02	DT: 0.000 (1.479)	BT: 0.346 (1.827)	Loss 1.5381 (1.7959)	Prec@1 60.938 (52.714)	
Total train loss: 1.7956
Avg Loading time: 1.4752 seconds
Avg Batch time: 1.8227 seconds

Train time: 712.7917058467865
 * Prec@1 1.360 Prec@5 14.130 Loss inf
Avg Loading time: 1.7453 seconds
Avg Batch time: 1.9070 seconds

Best acc: 14.640
--------------------------------------------------------------------------------
Test time: 151.3414089679718

Epoch: [3][77/391]	LR: 0.02	DT: 0.000 (1.540)	BT: 0.347 (1.888)	Loss 1.2939 (1.5514)	Prec@1 60.938 (58.764)	
Epoch: [3][155/391]	LR: 0.02	DT: 0.000 (1.258)	BT: 0.346 (1.606)	Loss 1.4951 (1.5336)	Prec@1 60.938 (58.669)	
Epoch: [3][233/391]	LR: 0.02	DT: 0.000 (1.118)	BT: 0.347 (1.467)	Loss 1.2061 (1.5354)	Prec@1 67.969 (58.510)	
Epoch: [3][311/391]	LR: 0.02	DT: 0.000 (1.019)	BT: 0.347 (1.367)	Loss 1.5479 (1.5342)	Prec@1 57.031 (58.634)	
Epoch: [3][389/391]	LR: 0.02	DT: 0.000 (0.969)	BT: 0.348 (1.317)	Loss 1.6934 (1.5676)	Prec@1 56.250 (57.700)	
Total train loss: 1.5680
Avg Loading time: 0.9664 seconds
Avg Batch time: 1.3143 seconds

Train time: 514.0316541194916
 * Prec@1 5.130 Prec@5 19.610 Loss inf
Avg Loading time: 1.2096 seconds
Avg Batch time: 1.3123 seconds

Best acc: 14.640
--------------------------------------------------------------------------------
Test time: 104.35010433197021

Epoch: [4][77/391]	LR: 0.02	DT: 0.000 (1.178)	BT: 0.347 (1.527)	Loss 2.0625 (1.9506)	Prec@1 45.312 (49.469)	
Epoch: [4][155/391]	LR: 0.02	DT: 0.000 (1.496)	BT: 0.348 (1.844)	Loss 1.7715 (1.8854)	Prec@1 53.125 (50.275)	
Epoch: [4][233/391]	LR: 0.02	DT: 0.000 (1.588)	BT: 0.348 (1.937)	Loss 1.5576 (1.8245)	Prec@1 56.250 (51.552)	
Epoch: [4][311/391]	LR: 0.02	DT: 0.000 (1.555)	BT: 0.348 (1.903)	Loss 1.5781 (1.7920)	Prec@1 51.562 (52.081)	
Epoch: [4][389/391]	LR: 0.02	DT: 0.000 (1.501)	BT: 0.346 (1.849)	Loss 1.6240 (1.7804)	Prec@1 57.031 (52.312)	
Total train loss: 1.7801
Avg Loading time: 1.4975 seconds
Avg Batch time: 1.8450 seconds

Train time: 721.5126404762268
 * Prec@1 5.590 Prec@5 16.360 Loss 5.2500
Avg Loading time: 1.5969 seconds
Avg Batch time: 1.7005 seconds

Best acc: 14.640
--------------------------------------------------------------------------------
Test time: 135.01897764205933

Epoch: [5][77/391]	LR: 0.02	DT: 0.000 (1.420)	BT: 0.349 (1.768)	Loss 2.0312 (1.7056)	Prec@1 50.781 (53.956)	
Epoch: [5][155/391]	LR: 0.02	DT: 0.000 (1.406)	BT: 0.346 (1.755)	Loss 2.3555 (1.8282)	Prec@1 44.531 (50.556)	
Epoch: [5][233/391]	LR: 0.02	DT: 1.689 (1.415)	BT: 2.039 (1.764)	Loss 2.6895 (2.1700)	Prec@1 33.594 (43.717)	
Epoch: [5][311/391]	LR: 0.02	DT: 0.000 (1.427)	BT: 0.347 (1.775)	Loss 1.9531 (2.1381)	Prec@1 45.312 (44.151)	
Epoch: [5][389/391]	LR: 0.02	DT: 0.000 (1.439)	BT: 0.346 (1.787)	Loss 1.9668 (2.0967)	Prec@1 52.344 (44.944)	
Total train loss: 2.0962
Avg Loading time: 1.4356 seconds
Avg Batch time: 1.7833 seconds

Train time: 697.3834178447723
 * Prec@1 4.540 Prec@5 15.300 Loss inf
Avg Loading time: 1.9841 seconds
Avg Batch time: 2.3488 seconds

Best acc: 14.640
--------------------------------------------------------------------------------
Test time: 186.2488067150116

Epoch: [6][77/391]	LR: 0.02	DT: 0.000 (1.899)	BT: 0.347 (2.453)	Loss 1.8369 (1.8587)	Prec@1 46.875 (49.469)	
Epoch: [6][155/391]	LR: 0.02	DT: 0.000 (1.844)	BT: 0.348 (2.320)	Loss 2.4629 (1.9153)	Prec@1 30.469 (48.543)	
Epoch: [6][233/391]	LR: 0.02	DT: 0.000 (1.747)	BT: 0.347 (2.180)	Loss 1.9766 (1.9210)	Prec@1 44.531 (48.220)	
Epoch: [6][311/391]	LR: 0.02	DT: 0.000 (1.651)	BT: 0.347 (2.062)	Loss 2.1250 (1.9425)	Prec@1 42.188 (47.811)	
Epoch: [6][389/391]	LR: 0.02	DT: 0.000 (1.541)	BT: 0.346 (1.940)	Loss 1.8623 (1.9469)	Prec@1 51.562 (47.786)	
Total train loss: 1.9466
Avg Loading time: 1.5375 seconds
Avg Batch time: 1.9359 seconds

Train time: 757.0892231464386
 * Prec@1 4.670 Prec@5 17.260 Loss 5.9219
Avg Loading time: 1.3370 seconds
Avg Batch time: 1.4456 seconds

Best acc: 14.640
--------------------------------------------------------------------------------
Test time: 114.87932968139648

Epoch: [7][77/391]	LR: 0.02	DT: 0.000 (1.122)	BT: 0.351 (1.471)	Loss 1.9473 (1.9029)	Prec@1 44.531 (49.048)	
Epoch: [7][155/391]	LR: 0.02	DT: 0.000 (1.119)	BT: 0.348 (1.467)	Loss 1.9395 (1.9149)	Prec@1 44.531 (48.588)	
Epoch: [7][233/391]	LR: 0.02	DT: 3.168 (1.118)	BT: 3.517 (1.466)	Loss 2.2109 (1.9557)	Prec@1 35.938 (47.626)	
Epoch: [7][311/391]	LR: 0.02	DT: 0.000 (1.130)	BT: 0.347 (1.478)	Loss 2.1562 (1.9625)	Prec@1 40.625 (47.393)	
Epoch: [7][389/391]	LR: 0.02	DT: 0.000 (1.230)	BT: 0.346 (1.578)	Loss 2.0898 (1.9568)	Prec@1 41.406 (47.386)	
Total train loss: 1.9566
Avg Loading time: 1.2270 seconds
Avg Batch time: 1.5749 seconds

Train time: 615.9091682434082
 * Prec@1 30.160 Prec@5 60.510 Loss 2.8887
Avg Loading time: 1.7295 seconds
Avg Batch time: 1.9949 seconds

Best acc: 30.160
--------------------------------------------------------------------------------
Test time: 158.78852200508118

Epoch: [8][77/391]	LR: 0.02	DT: 0.000 (1.859)	BT: 0.347 (2.361)	Loss 1.4639 (1.8358)	Prec@1 57.812 (50.080)	
Epoch: [8][155/391]	LR: 0.02	DT: 0.000 (1.829)	BT: 0.346 (2.280)	Loss 1.8564 (1.8324)	Prec@1 52.344 (50.310)	
Epoch: [8][233/391]	LR: 0.02	DT: 0.098 (1.768)	BT: 0.446 (2.185)	Loss 2.3262 (1.9284)	Prec@1 37.500 (48.067)	
Epoch: [8][311/391]	LR: 0.02	DT: 0.000 (1.530)	BT: 0.347 (1.929)	Loss 2.1211 (1.9696)	Prec@1 46.875 (47.058)	
Epoch: [8][389/391]	LR: 0.02	DT: 0.000 (1.366)	BT: 0.346 (1.755)	Loss 2.0195 (1.9678)	Prec@1 46.875 (47.248)	
Total train loss: 1.9681
Avg Loading time: 1.3628 seconds
Avg Batch time: 1.7513 seconds

Train time: 684.9062738418579
 * Prec@1 36.580 Prec@5 68.900 Loss 2.4883
Avg Loading time: 0.9790 seconds
Avg Batch time: 1.0934 seconds

Best acc: 36.580
--------------------------------------------------------------------------------
Test time: 87.53219056129456

Epoch: [9][77/391]	LR: 0.02	DT: 0.000 (0.736)	BT: 0.348 (1.085)	Loss 1.7705 (1.8916)	Prec@1 53.906 (48.868)	
Epoch: [9][155/391]	LR: 0.02	DT: 1.162 (0.761)	BT: 1.512 (1.110)	Loss 1.7305 (1.9007)	Prec@1 55.469 (48.573)	
Epoch: [9][233/391]	LR: 0.02	DT: 0.238 (0.772)	BT: 0.587 (1.120)	Loss 2.0078 (1.9212)	Prec@1 43.750 (48.160)	
Epoch: [9][311/391]	LR: 0.02	DT: 1.148 (0.828)	BT: 1.496 (1.176)	Loss 1.8232 (1.9174)	Prec@1 53.125 (48.195)	
Epoch: [9][389/391]	LR: 0.02	DT: 0.000 (0.949)	BT: 0.346 (1.297)	Loss 2.1738 (1.9289)	Prec@1 42.188 (48.073)	
Total train loss: 1.9288
Avg Loading time: 0.9464 seconds
Avg Batch time: 1.2943 seconds

Train time: 506.20456075668335
 * Prec@1 4.330 Prec@5 18.880 Loss inf
Avg Loading time: 1.8306 seconds
Avg Batch time: 2.1500 seconds

Best acc: 36.580
--------------------------------------------------------------------------------
Test time: 170.53919005393982

Epoch: [10][77/391]	LR: 0.004	DT: 0.000 (1.761)	BT: 0.346 (2.314)	Loss 1.6943 (1.8491)	Prec@1 51.562 (50.361)	
Epoch: [10][155/391]	LR: 0.004	DT: 0.000 (1.735)	BT: 0.348 (2.211)	Loss 1.8477 (1.8394)	Prec@1 52.344 (50.371)	
Epoch: [10][233/391]	LR: 0.004	DT: 0.000 (1.641)	BT: 0.347 (2.074)	Loss 1.8301 (1.8358)	Prec@1 50.781 (50.324)	
Epoch: [10][311/391]	LR: 0.004	DT: 0.000 (1.541)	BT: 0.348 (1.952)	Loss 1.7305 (1.8302)	Prec@1 52.344 (50.396)	
Epoch: [10][389/391]	LR: 0.004	DT: 0.000 (1.524)	BT: 0.346 (1.923)	Loss 2.0000 (1.8297)	Prec@1 43.750 (50.483)	
Total train loss: 1.8298
Avg Loading time: 1.5201 seconds
Avg Batch time: 1.9185 seconds

Train time: 750.2695419788361
 * Prec@1 50.230 Prec@5 80.200 Loss 1.8594
Avg Loading time: 1.7338 seconds
Avg Batch time: 1.8900 seconds

Best acc: 50.230
--------------------------------------------------------------------------------
Test time: 150.48669576644897

Epoch: [11][77/391]	LR: 0.004	DT: 0.000 (1.579)	BT: 0.350 (1.979)	Loss 1.8223 (1.8279)	Prec@1 52.344 (50.421)	
Epoch: [11][155/391]	LR: 0.004	DT: 0.000 (1.530)	BT: 0.348 (1.906)	Loss 1.8359 (1.8179)	Prec@1 52.344 (50.671)	
Epoch: [11][233/391]	LR: 0.004	DT: 1.679 (1.515)	BT: 2.032 (1.882)	Loss 1.6797 (1.8075)	Prec@1 55.469 (50.905)	
Epoch: [11][311/391]	LR: 0.004	DT: 0.000 (1.474)	BT: 0.349 (1.836)	Loss 2.0938 (1.8085)	Prec@1 42.969 (50.911)	
Epoch: [11][389/391]	LR: 0.004	DT: 0.000 (1.467)	BT: 0.348 (1.827)	Loss 2.0566 (1.8089)	Prec@1 40.625 (50.917)	
Total train loss: 1.8089
Avg Loading time: 1.4632 seconds
Avg Batch time: 1.8227 seconds

Train time: 712.7799458503723
 * Prec@1 41.900 Prec@5 71.810 Loss 2.2695
Avg Loading time: 1.6650 seconds
Avg Batch time: 1.8146 seconds

Best acc: 50.230
--------------------------------------------------------------------------------
Test time: 144.0343883037567

Epoch: [12][77/391]	LR: 0.004	DT: 0.000 (0.840)	BT: 0.351 (1.190)	Loss 1.7842 (1.7865)	Prec@1 47.656 (51.603)	
Epoch: [12][155/391]	LR: 0.004	DT: 0.000 (0.844)	BT: 0.350 (1.194)	Loss 2.0488 (1.7843)	Prec@1 46.875 (51.337)	
Epoch: [12][233/391]	LR: 0.004	DT: 0.000 (0.823)	BT: 0.350 (1.173)	Loss 1.8271 (1.7916)	Prec@1 46.875 (51.209)	
Epoch: [12][311/391]	LR: 0.004	DT: 0.726 (0.818)	BT: 1.078 (1.168)	Loss 1.9023 (1.7974)	Prec@1 46.875 (51.027)	
Epoch: [12][389/391]	LR: 0.004	DT: 0.135 (0.791)	BT: 0.487 (1.142)	Loss 1.6211 (1.8021)	Prec@1 57.031 (50.861)	
Total train loss: 1.8018
Avg Loading time: 0.7894 seconds
Avg Batch time: 1.1392 seconds

Train time: 445.53667879104614
 * Prec@1 43.810 Prec@5 74.930 Loss 2.1719
Avg Loading time: 0.9474 seconds
Avg Batch time: 1.0524 seconds

Best acc: 50.230
--------------------------------------------------------------------------------
Test time: 83.8138747215271

Epoch: [13][77/391]	LR: 0.004	DT: 0.000 (1.399)	BT: 0.350 (1.749)	Loss 1.9404 (1.8088)	Prec@1 44.531 (51.012)	
Epoch: [13][155/391]	LR: 0.004	DT: 0.000 (1.335)	BT: 0.350 (1.685)	Loss 1.8262 (1.7955)	Prec@1 51.562 (51.212)	
Epoch: [13][233/391]	LR: 0.004	DT: 2.763 (1.323)	BT: 3.114 (1.673)	Loss 1.7529 (1.8020)	Prec@1 53.906 (50.801)	
Epoch: [13][311/391]	LR: 0.004	DT: 0.000 (1.295)	BT: 0.347 (1.645)	Loss 1.9766 (1.8088)	Prec@1 44.531 (50.654)	
Epoch: [13][389/391]	LR: 0.004	DT: 0.000 (1.295)	BT: 0.347 (1.644)	Loss 1.8545 (1.8053)	Prec@1 56.250 (50.851)	
Total train loss: 1.8055
Avg Loading time: 1.2913 seconds
Avg Batch time: 1.6399 seconds

Train time: 641.3126890659332
 * Prec@1 49.810 Prec@5 80.210 Loss 1.8604
Avg Loading time: 1.7076 seconds
Avg Batch time: 1.8521 seconds

Best acc: 50.230
--------------------------------------------------------------------------------
Test time: 147.00780606269836

Epoch: [14][77/391]	LR: 0.004	DT: 0.000 (1.608)	BT: 0.348 (2.009)	Loss 1.9043 (1.8173)	Prec@1 48.438 (50.351)	
Epoch: [14][155/391]	LR: 0.004	DT: 0.000 (1.197)	BT: 0.348 (1.572)	Loss 1.6934 (1.8042)	Prec@1 47.656 (50.836)	
Epoch: [14][233/391]	LR: 0.004	DT: 2.747 (1.048)	BT: 3.098 (1.414)	Loss 1.9023 (1.7939)	Prec@1 49.219 (51.212)	
Epoch: [14][311/391]	LR: 0.004	DT: 0.000 (0.944)	BT: 0.347 (1.305)	Loss 1.8271 (1.7980)	Prec@1 51.562 (51.022)	
Epoch: [14][389/391]	LR: 0.004	DT: 0.000 (0.898)	BT: 0.354 (1.257)	Loss 1.9941 (1.7970)	Prec@1 42.188 (51.136)	
Total train loss: 1.7972
Avg Loading time: 0.8956 seconds
Avg Batch time: 1.2541 seconds

Train time: 490.47728419303894
 * Prec@1 47.580 Prec@5 78.690 Loss 1.9619
Avg Loading time: 1.0552 seconds
Avg Batch time: 1.1561 seconds

Best acc: 50.230
--------------------------------------------------------------------------------
Test time: 91.99065971374512

Epoch: [15][77/391]	LR: 0.004	DT: 0.502 (1.150)	BT: 0.851 (1.501)	Loss 1.6924 (1.7915)	Prec@1 51.562 (51.753)	
Epoch: [15][155/391]	LR: 0.004	DT: 0.000 (1.292)	BT: 0.348 (1.642)	Loss 1.7725 (1.8084)	Prec@1 51.562 (50.826)	
Epoch: [15][233/391]	LR: 0.004	DT: 0.550 (1.320)	BT: 0.900 (1.670)	Loss 1.9141 (1.7992)	Prec@1 51.562 (50.945)	
Epoch: [15][311/391]	LR: 0.004	DT: 0.000 (1.316)	BT: 0.348 (1.665)	Loss 2.0938 (1.8169)	Prec@1 42.969 (50.498)	
Epoch: [15][389/391]	LR: 0.004	DT: 0.001 (1.331)	BT: 0.348 (1.680)	Loss 2.0195 (1.8412)	Prec@1 52.344 (49.934)	
Total train loss: 1.8416
Avg Loading time: 1.3280 seconds
Avg Batch time: 1.6766 seconds

Train time: 655.6704289913177
 * Prec@1 48.140 Prec@5 79.170 Loss 1.9248
Avg Loading time: 1.7291 seconds
Avg Batch time: 1.8365 seconds

Best acc: 50.230
--------------------------------------------------------------------------------
Test time: 145.7491898536682

Epoch: [16][77/391]	LR: 0.004	DT: 0.000 (1.556)	BT: 0.349 (1.905)	Loss 1.8535 (1.8396)	Prec@1 51.562 (50.341)	
Epoch: [16][155/391]	LR: 0.004	DT: 0.000 (1.551)	BT: 0.347 (1.900)	Loss 1.9004 (1.8373)	Prec@1 50.781 (50.185)	
Epoch: [16][233/391]	LR: 0.004	DT: 0.090 (1.521)	BT: 0.439 (1.869)	Loss 1.7344 (1.8323)	Prec@1 53.125 (50.297)	
Epoch: [16][311/391]	LR: 0.004	DT: 0.000 (1.502)	BT: 0.347 (1.851)	Loss 1.9971 (1.8340)	Prec@1 42.969 (50.275)	
Epoch: [16][389/391]	LR: 0.004	DT: 0.000 (1.535)	BT: 0.346 (1.883)	Loss 1.3311 (1.8349)	Prec@1 64.062 (50.268)	
Total train loss: 1.8350
Avg Loading time: 1.5309 seconds
Avg Batch time: 1.8788 seconds

Train time: 734.7505893707275
 * Prec@1 44.430 Prec@5 76.720 Loss 2.0703
Avg Loading time: 1.8265 seconds
Avg Batch time: 2.0768 seconds

Best acc: 50.230
--------------------------------------------------------------------------------
Test time: 164.74780440330505

Epoch: [17][77/391]	LR: 0.004	DT: 0.000 (1.731)	BT: 0.349 (2.133)	Loss 1.5908 (1.8180)	Prec@1 52.344 (50.831)	
Epoch: [17][155/391]	LR: 0.004	DT: 0.000 (1.654)	BT: 0.348 (2.030)	Loss 1.6211 (1.8179)	Prec@1 58.594 (50.481)	
Epoch: [17][233/391]	LR: 0.004	DT: 0.000 (1.500)	BT: 0.352 (1.867)	Loss 1.7705 (1.8161)	Prec@1 50.000 (50.631)	
Epoch: [17][311/391]	LR: 0.004	DT: 0.000 (1.313)	BT: 0.349 (1.675)	Loss 1.9160 (1.8168)	Prec@1 50.781 (50.634)	
Epoch: [17][389/391]	LR: 0.004	DT: 0.000 (1.211)	BT: 0.348 (1.571)	Loss 1.9561 (1.8128)	Prec@1 53.125 (50.893)	
Total train loss: 1.8124
Avg Loading time: 1.2075 seconds
Avg Batch time: 1.5671 seconds

Train time: 612.8529005050659
 * Prec@1 45.720 Prec@5 76.450 Loss 2.0762
Avg Loading time: 1.1808 seconds
Avg Batch time: 1.2886 seconds

Best acc: 50.230
--------------------------------------------------------------------------------
Test time: 102.46925687789917

Epoch: [18][77/391]	LR: 0.004	DT: 0.000 (0.933)	BT: 0.349 (1.283)	Loss 1.7432 (1.8009)	Prec@1 53.125 (51.182)	
Epoch: [18][155/391]	LR: 0.004	DT: 0.000 (1.061)	BT: 0.350 (1.411)	Loss 1.9551 (1.8142)	Prec@1 48.438 (50.806)	
Epoch: [18][233/391]	LR: 0.004	DT: 0.000 (1.289)	BT: 0.349 (1.656)	Loss 1.8799 (1.8056)	Prec@1 46.094 (50.935)	
Epoch: [18][311/391]	LR: 0.004	DT: 0.000 (1.377)	BT: 0.349 (1.739)	Loss 1.8730 (1.8050)	Prec@1 46.875 (51.007)	
Epoch: [18][389/391]	LR: 0.004	DT: 0.000 (1.373)	BT: 0.349 (1.733)	Loss 1.9102 (1.8059)	Prec@1 47.656 (50.992)	
Total train loss: 1.8060
Avg Loading time: 1.3697 seconds
Avg Batch time: 1.7293 seconds

Train time: 676.2638912200928
 * Prec@1 49.840 Prec@5 79.830 Loss 1.8721
Avg Loading time: 1.6615 seconds
Avg Batch time: 1.7698 seconds

Best acc: 50.230
--------------------------------------------------------------------------------
Test time: 140.4940595626831

Epoch: [19][77/391]	LR: 0.004	DT: 0.000 (1.491)	BT: 0.349 (1.840)	Loss 1.7148 (1.7930)	Prec@1 50.000 (51.342)	
Epoch: [19][155/391]	LR: 0.004	DT: 0.898 (1.492)	BT: 1.247 (1.840)	Loss 1.7256 (1.7983)	Prec@1 56.250 (50.866)	
Epoch: [19][233/391]	LR: 0.004	DT: 0.632 (1.471)	BT: 0.982 (1.820)	Loss 1.6318 (1.8013)	Prec@1 51.562 (50.821)	
Epoch: [19][311/391]	LR: 0.004	DT: 0.000 (1.315)	BT: 0.348 (1.664)	Loss 1.7744 (1.8090)	Prec@1 54.688 (50.689)	
Epoch: [19][389/391]	LR: 0.004	DT: 0.000 (1.212)	BT: 0.349 (1.561)	Loss 1.6865 (1.8083)	Prec@1 53.906 (50.813)	
Total train loss: 1.8082
Avg Loading time: 1.2093 seconds
Avg Batch time: 1.5573 seconds

Train time: 609.0153958797455
 * Prec@1 49.780 Prec@5 79.860 Loss 1.8691
Avg Loading time: 1.0790 seconds
Avg Batch time: 1.1834 seconds

Best acc: 50.230
--------------------------------------------------------------------------------
Test time: 94.15712070465088

Epoch: [20][77/391]	LR: 0.0008	DT: 0.000 (0.844)	BT: 0.349 (1.193)	Loss 1.8418 (1.7946)	Prec@1 54.688 (51.613)	
Epoch: [20][155/391]	LR: 0.0008	DT: 0.000 (0.856)	BT: 0.350 (1.205)	Loss 2.0039 (1.8004)	Prec@1 46.094 (51.167)	
Epoch: [20][233/391]	LR: 0.0008	DT: 0.000 (0.845)	BT: 0.348 (1.195)	Loss 1.9668 (1.8002)	Prec@1 47.656 (50.948)	
Epoch: [20][311/391]	LR: 0.0008	DT: 0.000 (0.948)	BT: 0.349 (1.297)	Loss 1.5635 (1.7919)	Prec@1 58.594 (51.194)	
Epoch: [20][389/391]	LR: 0.0008	DT: 0.000 (1.048)	BT: 0.348 (1.397)	Loss 1.7705 (1.7875)	Prec@1 53.906 (51.382)	
Total train loss: 1.7872
Avg Loading time: 1.0451 seconds
Avg Batch time: 1.3940 seconds

Train time: 545.1833863258362
 * Prec@1 50.490 Prec@5 80.330 Loss 1.8428
Avg Loading time: 1.8724 seconds
Avg Batch time: 1.9798 seconds

Best acc: 50.490
--------------------------------------------------------------------------------
Test time: 157.56728172302246

Epoch: [21][77/391]	LR: 0.0008	DT: 0.000 (1.766)	BT: 0.348 (2.167)	Loss 1.8096 (1.7590)	Prec@1 46.094 (51.963)	
Epoch: [21][155/391]	LR: 0.0008	DT: 0.000 (1.779)	BT: 0.348 (2.154)	Loss 1.9092 (1.7620)	Prec@1 53.906 (51.863)	
Epoch: [21][233/391]	LR: 0.0008	DT: 0.000 (1.758)	BT: 0.350 (2.143)	Loss 1.6416 (1.7717)	Prec@1 54.688 (51.706)	
Epoch: [21][311/391]	LR: 0.0008	DT: 0.000 (1.675)	BT: 0.350 (2.051)	Loss 1.9482 (1.7818)	Prec@1 50.000 (51.545)	
Epoch: [21][389/391]	LR: 0.0008	DT: 0.000 (1.588)	BT: 0.348 (1.959)	Loss 1.8789 (1.7871)	Prec@1 40.625 (51.342)	
Total train loss: 1.7873
Avg Loading time: 1.5843 seconds
Avg Batch time: 1.9544 seconds

Train time: 764.3084225654602
 * Prec@1 50.600 Prec@5 80.410 Loss 1.8418
Avg Loading time: 1.5797 seconds
Avg Batch time: 1.7374 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 138.4443175792694

Epoch: [22][77/391]	LR: 0.0008	DT: 0.000 (1.405)	BT: 0.350 (1.755)	Loss 1.7217 (1.7826)	Prec@1 47.656 (51.352)	
Epoch: [22][155/391]	LR: 0.0008	DT: 0.266 (1.509)	BT: 0.616 (1.884)	Loss 1.8760 (1.7847)	Prec@1 53.906 (51.152)	
Epoch: [22][233/391]	LR: 0.0008	DT: 0.000 (1.618)	BT: 0.348 (1.984)	Loss 1.6064 (1.7836)	Prec@1 54.688 (51.356)	
Epoch: [22][311/391]	LR: 0.0008	DT: 0.000 (1.616)	BT: 0.348 (1.991)	Loss 1.7949 (1.7833)	Prec@1 48.438 (51.427)	
Epoch: [22][389/391]	LR: 0.0008	DT: 0.000 (1.504)	BT: 0.347 (1.873)	Loss 1.6504 (1.7853)	Prec@1 57.031 (51.398)	
Total train loss: 1.7853
Avg Loading time: 1.5003 seconds
Avg Batch time: 1.8692 seconds

Train time: 730.9718198776245
 * Prec@1 50.330 Prec@5 80.590 Loss 1.8418
Avg Loading time: 1.2018 seconds
Avg Batch time: 1.2752 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 101.41578960418701

Epoch: [23][77/391]	LR: 0.0008	DT: 0.000 (0.991)	BT: 0.350 (1.340)	Loss 1.8750 (1.8035)	Prec@1 46.094 (50.431)	
Epoch: [23][155/391]	LR: 0.0008	DT: 0.000 (0.956)	BT: 0.348 (1.305)	Loss 1.8164 (1.7890)	Prec@1 52.344 (50.957)	
Epoch: [23][233/391]	LR: 0.0008	DT: 0.000 (0.951)	BT: 0.348 (1.300)	Loss 1.8398 (1.7844)	Prec@1 46.094 (51.299)	
Epoch: [23][311/391]	LR: 0.0008	DT: 0.000 (0.985)	BT: 0.347 (1.334)	Loss 1.6934 (1.7863)	Prec@1 56.250 (51.247)	
Epoch: [23][389/391]	LR: 0.0008	DT: 0.000 (1.074)	BT: 0.346 (1.423)	Loss 1.6904 (1.7866)	Prec@1 58.594 (51.164)	
Total train loss: 1.7866
Avg Loading time: 1.0718 seconds
Avg Batch time: 1.4199 seconds

Train time: 555.3247663974762
 * Prec@1 50.210 Prec@5 80.590 Loss 1.8418
Avg Loading time: 1.6538 seconds
Avg Batch time: 1.8228 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 144.68951964378357

Epoch: [24][77/391]	LR: 0.0008	DT: 0.000 (1.506)	BT: 0.348 (1.854)	Loss 1.7031 (1.7774)	Prec@1 56.250 (51.562)	
Epoch: [24][155/391]	LR: 0.0008	DT: 1.330 (1.492)	BT: 1.679 (1.841)	Loss 1.7432 (1.7735)	Prec@1 52.344 (51.828)	
Epoch: [24][233/391]	LR: 0.0008	DT: 0.755 (1.483)	BT: 1.105 (1.832)	Loss 1.9258 (1.7795)	Prec@1 50.000 (51.786)	
Epoch: [24][311/391]	LR: 0.0008	DT: 0.000 (1.445)	BT: 0.347 (1.794)	Loss 1.6436 (1.7813)	Prec@1 56.250 (51.700)	
Epoch: [24][389/391]	LR: 0.0008	DT: 0.000 (1.444)	BT: 0.349 (1.793)	Loss 2.1934 (1.7846)	Prec@1 39.844 (51.595)	
Total train loss: 1.7845
Avg Loading time: 1.4398 seconds
Avg Batch time: 1.7887 seconds

Train time: 699.5026767253876
 * Prec@1 50.240 Prec@5 80.610 Loss 1.8447
Avg Loading time: 1.4709 seconds
Avg Batch time: 1.6269 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 129.19236493110657

Epoch: [25][77/391]	LR: 0.0008	DT: 0.000 (1.038)	BT: 0.351 (1.388)	Loss 1.7471 (1.7891)	Prec@1 57.812 (51.723)	
Epoch: [25][155/391]	LR: 0.0008	DT: 0.000 (0.964)	BT: 0.364 (1.314)	Loss 1.6895 (1.7832)	Prec@1 57.031 (51.618)	
Epoch: [25][233/391]	LR: 0.0008	DT: 0.351 (0.917)	BT: 0.703 (1.267)	Loss 1.7910 (1.7917)	Prec@1 51.562 (51.309)	
Epoch: [25][311/391]	LR: 0.0008	DT: 0.000 (0.910)	BT: 0.347 (1.259)	Loss 1.8926 (1.7865)	Prec@1 54.688 (51.352)	
Epoch: [25][389/391]	LR: 0.0008	DT: 0.000 (0.910)	BT: 0.347 (1.259)	Loss 1.7217 (1.7846)	Prec@1 55.469 (51.462)	
Total train loss: 1.7846
Avg Loading time: 0.9077 seconds
Avg Batch time: 1.2566 seconds

Train time: 491.46277952194214
 * Prec@1 50.280 Prec@5 80.770 Loss 1.8418
Avg Loading time: 1.1426 seconds
Avg Batch time: 1.2594 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 100.19018411636353

Epoch: [26][77/391]	LR: 0.0008	DT: 0.000 (1.437)	BT: 0.350 (1.787)	Loss 1.9102 (1.7805)	Prec@1 49.219 (51.522)	
Epoch: [26][155/391]	LR: 0.0008	DT: 0.000 (1.416)	BT: 0.350 (1.791)	Loss 2.1094 (1.7910)	Prec@1 42.969 (51.442)	
Epoch: [26][233/391]	LR: 0.0008	DT: 0.000 (1.543)	BT: 0.349 (1.927)	Loss 1.5859 (1.7826)	Prec@1 54.688 (51.532)	
Epoch: [26][311/391]	LR: 0.0008	DT: 0.000 (1.566)	BT: 0.349 (1.941)	Loss 1.6338 (1.7836)	Prec@1 54.688 (51.445)	
Epoch: [26][389/391]	LR: 0.0008	DT: 0.000 (1.542)	BT: 0.349 (1.922)	Loss 1.9229 (1.7845)	Prec@1 47.656 (51.486)	
Total train loss: 1.7842
Avg Loading time: 1.5376 seconds
Avg Batch time: 1.9174 seconds

Train time: 749.8344116210938
 * Prec@1 50.370 Prec@5 80.420 Loss 1.8428
Avg Loading time: 1.6477 seconds
Avg Batch time: 1.7640 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 140.0441370010376

Epoch: [27][77/391]	LR: 0.0008	DT: 0.000 (1.469)	BT: 0.349 (1.819)	Loss 1.7842 (1.7954)	Prec@1 50.000 (51.122)	
Epoch: [27][155/391]	LR: 0.0008	DT: 0.000 (1.448)	BT: 0.347 (1.798)	Loss 1.5449 (1.7770)	Prec@1 57.031 (51.573)	
Epoch: [27][233/391]	LR: 0.0008	DT: 0.000 (1.449)	BT: 0.347 (1.798)	Loss 1.7471 (1.7875)	Prec@1 50.781 (51.362)	
Epoch: [27][311/391]	LR: 0.0008	DT: 0.000 (1.422)	BT: 0.348 (1.771)	Loss 1.7031 (1.7900)	Prec@1 51.562 (51.342)	
Epoch: [27][389/391]	LR: 0.0008	DT: 0.000 (1.422)	BT: 0.346 (1.771)	Loss 1.9180 (1.7839)	Prec@1 49.219 (51.532)	
Total train loss: 1.7840
Avg Loading time: 1.4186 seconds
Avg Batch time: 1.7671 seconds

Train time: 691.0649194717407
 * Prec@1 50.270 Prec@5 80.520 Loss 1.8418
Avg Loading time: 1.6075 seconds
Avg Batch time: 1.7645 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 140.0605869293213

Epoch: [28][77/391]	LR: 0.0008	DT: 0.000 (1.031)	BT: 0.347 (1.379)	Loss 1.3203 (1.7983)	Prec@1 61.719 (51.242)	
Epoch: [28][155/391]	LR: 0.0008	DT: 0.000 (1.003)	BT: 0.346 (1.351)	Loss 1.6699 (1.7915)	Prec@1 50.781 (51.422)	
Epoch: [28][233/391]	LR: 0.0008	DT: 0.175 (0.988)	BT: 0.524 (1.336)	Loss 1.6680 (1.7907)	Prec@1 50.781 (51.259)	
Epoch: [28][311/391]	LR: 0.0008	DT: 0.000 (0.959)	BT: 0.346 (1.307)	Loss 1.8105 (1.7892)	Prec@1 50.000 (51.242)	
Epoch: [28][389/391]	LR: 0.0008	DT: 0.000 (0.949)	BT: 0.346 (1.298)	Loss 1.9648 (1.7851)	Prec@1 43.750 (51.444)	
Total train loss: 1.7853
Avg Loading time: 0.9471 seconds
Avg Batch time: 1.2948 seconds

Train time: 506.3879873752594
 * Prec@1 50.370 Prec@5 80.600 Loss 1.8398
Avg Loading time: 1.4681 seconds
Avg Batch time: 1.5569 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 123.6925880908966

Epoch: [29][77/391]	LR: 0.0008	DT: 0.000 (1.459)	BT: 0.347 (1.858)	Loss 1.8213 (1.7924)	Prec@1 53.906 (51.102)	
Epoch: [29][155/391]	LR: 0.0008	DT: 0.000 (1.507)	BT: 0.346 (1.880)	Loss 1.8467 (1.7859)	Prec@1 43.750 (51.167)	
Epoch: [29][233/391]	LR: 0.0008	DT: 1.424 (1.591)	BT: 1.775 (1.956)	Loss 1.5322 (1.7770)	Prec@1 58.594 (51.412)	
Epoch: [29][311/391]	LR: 0.0008	DT: 0.000 (1.586)	BT: 0.347 (1.947)	Loss 1.8184 (1.7801)	Prec@1 51.562 (51.342)	
Epoch: [29][389/391]	LR: 0.0008	DT: 0.000 (1.606)	BT: 0.346 (1.964)	Loss 1.8242 (1.7821)	Prec@1 46.875 (51.424)	
Total train loss: 1.7825
Avg Loading time: 1.6019 seconds
Avg Batch time: 1.9596 seconds

Train time: 766.3443374633789
 * Prec@1 50.250 Prec@5 80.480 Loss 1.8398
Avg Loading time: 1.7613 seconds
Avg Batch time: 1.9177 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 152.18530249595642

Epoch: [30][77/391]	LR: 0.00016	DT: 0.000 (1.338)	BT: 0.351 (1.740)	Loss 1.6826 (1.7686)	Prec@1 57.031 (51.853)	
Epoch: [30][155/391]	LR: 0.00016	DT: 0.000 (1.487)	BT: 0.347 (1.863)	Loss 1.6182 (1.7698)	Prec@1 53.906 (51.743)	
Epoch: [30][233/391]	LR: 0.00016	DT: 0.000 (1.256)	BT: 0.348 (1.623)	Loss 1.5693 (1.7696)	Prec@1 56.250 (51.639)	
Epoch: [30][311/391]	LR: 0.00016	DT: 0.000 (1.104)	BT: 0.347 (1.467)	Loss 1.7158 (1.7774)	Prec@1 52.344 (51.522)	
Epoch: [30][389/391]	LR: 0.00016	DT: 0.000 (1.011)	BT: 0.346 (1.371)	Loss 1.8574 (1.7797)	Prec@1 51.562 (51.466)	
Total train loss: 1.7798
Avg Loading time: 1.0084 seconds
Avg Batch time: 1.3680 seconds

Train time: 535.0002477169037
 * Prec@1 50.250 Prec@5 80.590 Loss 1.8418
Avg Loading time: 0.9716 seconds
Avg Batch time: 1.0578 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 84.24034929275513

Epoch: [31][77/391]	LR: 0.00016	DT: 0.000 (0.810)	BT: 0.347 (1.157)	Loss 1.7158 (1.7748)	Prec@1 57.031 (51.713)	
Epoch: [31][155/391]	LR: 0.00016	DT: 0.000 (0.791)	BT: 0.349 (1.139)	Loss 1.8174 (1.7798)	Prec@1 56.250 (51.462)	
Epoch: [31][233/391]	LR: 0.00016	DT: 0.000 (0.987)	BT: 0.348 (1.336)	Loss 1.9385 (1.7854)	Prec@1 49.219 (51.466)	
Epoch: [31][311/391]	LR: 0.00016	DT: 0.000 (1.073)	BT: 0.347 (1.422)	Loss 2.0195 (1.7855)	Prec@1 46.094 (51.392)	
Epoch: [31][389/391]	LR: 0.00016	DT: 0.000 (1.120)	BT: 0.346 (1.468)	Loss 1.9170 (1.7812)	Prec@1 48.438 (51.482)	
Total train loss: 1.7810
Avg Loading time: 1.1171 seconds
Avg Batch time: 1.4650 seconds

Train time: 572.9605553150177
 * Prec@1 50.090 Prec@5 80.600 Loss 1.8428
Avg Loading time: 1.7164 seconds
Avg Batch time: 1.8253 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 144.86661624908447

Epoch: [32][77/391]	LR: 0.00016	DT: 0.000 (1.458)	BT: 0.349 (1.859)	Loss 1.7598 (1.7761)	Prec@1 50.000 (52.284)	
Epoch: [32][155/391]	LR: 0.00016	DT: 0.000 (1.464)	BT: 0.349 (1.839)	Loss 1.7754 (1.7859)	Prec@1 50.781 (51.698)	
Epoch: [32][233/391]	LR: 0.00016	DT: 11.167 (1.466)	BT: 11.520 (1.833)	Loss 1.8105 (1.7853)	Prec@1 48.438 (51.576)	
Epoch: [32][311/391]	LR: 0.00016	DT: 0.000 (1.429)	BT: 0.350 (1.791)	Loss 1.6035 (1.7773)	Prec@1 53.906 (51.738)	
Epoch: [32][389/391]	LR: 0.00016	DT: 0.000 (1.418)	BT: 0.349 (1.778)	Loss 1.8047 (1.7781)	Prec@1 51.562 (51.729)	
Total train loss: 1.7780
Avg Loading time: 1.4145 seconds
Avg Batch time: 1.7742 seconds

Train time: 693.851548910141
 * Prec@1 50.140 Prec@5 80.640 Loss 1.8398
Avg Loading time: 1.6786 seconds
Avg Batch time: 1.8462 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 146.53439140319824

Epoch: [33][77/391]	LR: 0.00016	DT: 0.000 (1.528)	BT: 0.351 (1.879)	Loss 1.7197 (1.7525)	Prec@1 54.688 (52.173)	
Epoch: [33][155/391]	LR: 0.00016	DT: 0.000 (1.493)	BT: 0.350 (1.843)	Loss 1.8125 (1.7738)	Prec@1 43.750 (51.327)	
Epoch: [33][233/391]	LR: 0.00016	DT: 1.816 (1.319)	BT: 2.165 (1.668)	Loss 1.7842 (1.7836)	Prec@1 55.469 (51.205)	
Epoch: [33][311/391]	LR: 0.00016	DT: 0.000 (1.165)	BT: 0.347 (1.514)	Loss 1.6172 (1.7829)	Prec@1 51.562 (51.290)	
Epoch: [33][389/391]	LR: 0.00016	DT: 0.000 (1.074)	BT: 0.346 (1.423)	Loss 1.8721 (1.7810)	Prec@1 50.000 (51.422)	
Total train loss: 1.7815
Avg Loading time: 1.0714 seconds
Avg Batch time: 1.4199 seconds

Train time: 555.3268804550171
 * Prec@1 50.400 Prec@5 80.680 Loss 1.8389
Avg Loading time: 0.9886 seconds
Avg Batch time: 1.0928 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 87.00158715248108

Epoch: [34][77/391]	LR: 0.00016	DT: 0.000 (0.750)	BT: 0.348 (1.099)	Loss 1.8389 (1.7674)	Prec@1 49.219 (51.863)	
Epoch: [34][155/391]	LR: 0.00016	DT: 0.000 (0.723)	BT: 0.349 (1.073)	Loss 1.5498 (1.7788)	Prec@1 57.031 (51.723)	
Epoch: [34][233/391]	LR: 0.00016	DT: 0.278 (0.755)	BT: 0.632 (1.105)	Loss 1.9160 (1.7757)	Prec@1 51.562 (51.683)	
Epoch: [34][311/391]	LR: 0.00016	DT: 1.511 (0.857)	BT: 1.863 (1.207)	Loss 1.8213 (1.7772)	Prec@1 50.000 (51.633)	
Epoch: [34][389/391]	LR: 0.00016	DT: 0.000 (0.992)	BT: 0.357 (1.342)	Loss 1.7246 (1.7787)	Prec@1 53.125 (51.492)	
Total train loss: 1.7790
Avg Loading time: 0.9892 seconds
Avg Batch time: 1.3393 seconds

Train time: 523.8134806156158
 * Prec@1 50.410 Prec@5 80.490 Loss 1.8418
Avg Loading time: 1.8861 seconds
Avg Batch time: 2.0388 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 161.7461895942688

Epoch: [35][77/391]	LR: 0.00016	DT: 0.000 (1.741)	BT: 0.350 (2.143)	Loss 1.5762 (1.7743)	Prec@1 59.375 (51.883)	
Epoch: [35][155/391]	LR: 0.00016	DT: 0.000 (1.559)	BT: 0.350 (1.935)	Loss 1.7139 (1.7846)	Prec@1 47.656 (51.437)	
Epoch: [35][233/391]	LR: 0.00016	DT: 3.270 (1.489)	BT: 3.623 (1.856)	Loss 1.5195 (1.7761)	Prec@1 60.938 (51.509)	
Epoch: [35][311/391]	LR: 0.00016	DT: 0.000 (1.428)	BT: 0.349 (1.791)	Loss 1.9600 (1.7781)	Prec@1 42.188 (51.430)	
Epoch: [35][389/391]	LR: 0.00016	DT: 0.000 (1.414)	BT: 0.348 (1.774)	Loss 1.8398 (1.7793)	Prec@1 48.438 (51.492)	
Total train loss: 1.7796
Avg Loading time: 1.4101 seconds
Avg Batch time: 1.7700 seconds

Train time: 692.205560207367
 * Prec@1 50.500 Prec@5 80.610 Loss 1.8398
Avg Loading time: 1.7033 seconds
Avg Batch time: 1.8082 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 143.52379512786865

Epoch: [36][77/391]	LR: 0.00016	DT: 0.000 (1.035)	BT: 0.349 (1.385)	Loss 1.9004 (1.7849)	Prec@1 46.875 (51.552)	
Epoch: [36][155/391]	LR: 0.00016	DT: 0.000 (0.903)	BT: 0.350 (1.253)	Loss 1.8037 (1.7855)	Prec@1 57.812 (51.332)	
Epoch: [36][233/391]	LR: 0.00016	DT: 0.699 (0.856)	BT: 1.052 (1.206)	Loss 1.9697 (1.7848)	Prec@1 41.406 (51.312)	
Epoch: [36][311/391]	LR: 0.00016	DT: 0.000 (0.813)	BT: 0.350 (1.163)	Loss 1.8525 (1.7827)	Prec@1 58.594 (51.620)	
Epoch: [36][389/391]	LR: 0.00016	DT: 0.000 (0.813)	BT: 0.349 (1.163)	Loss 1.9531 (1.7820)	Prec@1 46.094 (51.621)	
Total train loss: 1.7817
Avg Loading time: 0.8113 seconds
Avg Batch time: 1.1609 seconds

Train time: 454.03445959091187
 * Prec@1 50.330 Prec@5 80.660 Loss 1.8418
Avg Loading time: 1.1497 seconds
Avg Batch time: 1.2468 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 99.18761014938354

Epoch: [37][77/391]	LR: 0.00016	DT: 0.000 (1.314)	BT: 0.348 (1.664)	Loss 1.7793 (1.7853)	Prec@1 50.781 (51.482)	
Epoch: [37][155/391]	LR: 0.00016	DT: 0.000 (1.406)	BT: 0.347 (1.755)	Loss 1.5947 (1.7840)	Prec@1 54.688 (51.608)	
Epoch: [37][233/391]	LR: 0.00016	DT: 0.000 (1.427)	BT: 0.347 (1.775)	Loss 1.6807 (1.7820)	Prec@1 53.125 (51.686)	
Epoch: [37][311/391]	LR: 0.00016	DT: 0.000 (1.426)	BT: 0.347 (1.774)	Loss 1.6299 (1.7759)	Prec@1 56.250 (51.723)	
Epoch: [37][389/391]	LR: 0.00016	DT: 0.000 (1.428)	BT: 0.346 (1.776)	Loss 1.8838 (1.7779)	Prec@1 46.094 (51.597)	
Total train loss: 1.7780
Avg Loading time: 1.4241 seconds
Avg Batch time: 1.7715 seconds

Train time: 692.7996442317963
 * Prec@1 50.560 Prec@5 80.620 Loss 1.8398
Avg Loading time: 1.7507 seconds
Avg Batch time: 1.8573 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 147.40573167800903

Epoch: [38][77/391]	LR: 0.00016	DT: 0.000 (1.758)	BT: 0.347 (2.159)	Loss 1.9189 (1.7867)	Prec@1 50.000 (51.522)	
Epoch: [38][155/391]	LR: 0.00016	DT: 0.976 (1.745)	BT: 1.326 (2.120)	Loss 1.6982 (1.7785)	Prec@1 50.781 (51.928)	
Epoch: [38][233/391]	LR: 0.00016	DT: 0.000 (1.745)	BT: 0.348 (2.111)	Loss 1.5791 (1.7747)	Prec@1 56.250 (51.976)	
Epoch: [38][311/391]	LR: 0.00016	DT: 0.000 (1.699)	BT: 0.347 (2.060)	Loss 1.7725 (1.7757)	Prec@1 49.219 (51.931)	
Epoch: [38][389/391]	LR: 0.00016	DT: 0.000 (1.608)	BT: 0.346 (1.966)	Loss 1.9424 (1.7778)	Prec@1 47.656 (51.723)	
Total train loss: 1.7779
Avg Loading time: 1.6034 seconds
Avg Batch time: 1.9613 seconds

Train time: 766.9942896366119
 * Prec@1 50.430 Prec@5 80.580 Loss 1.8389
Avg Loading time: 1.5808 seconds
Avg Batch time: 1.7927 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 142.30590176582336

Epoch: [39][77/391]	LR: 0.00016	DT: 0.000 (1.241)	BT: 0.347 (1.589)	Loss 2.1074 (1.7833)	Prec@1 46.094 (51.813)	
Epoch: [39][155/391]	LR: 0.00016	DT: 0.000 (1.195)	BT: 0.346 (1.543)	Loss 1.8477 (1.7855)	Prec@1 49.219 (51.823)	
Epoch: [39][233/391]	LR: 0.00016	DT: 2.055 (1.066)	BT: 2.406 (1.413)	Loss 1.9551 (1.7837)	Prec@1 46.875 (51.833)	
Epoch: [39][311/391]	LR: 0.00016	DT: 0.000 (0.992)	BT: 0.347 (1.340)	Loss 1.8223 (1.7844)	Prec@1 46.875 (51.805)	
Epoch: [39][389/391]	LR: 0.00016	DT: 0.000 (1.013)	BT: 0.346 (1.361)	Loss 1.6855 (1.7794)	Prec@1 52.344 (51.741)	
Total train loss: 1.7794
Avg Loading time: 1.0107 seconds
Avg Batch time: 1.3582 seconds

Train time: 531.1790330410004
 * Prec@1 50.420 Prec@5 80.450 Loss 1.8428
Avg Loading time: 1.6492 seconds
Avg Batch time: 1.7433 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 138.39544463157654

Epoch: [40][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.496)	BT: 0.347 (1.845)	Loss 1.8945 (1.7850)	Prec@1 46.094 (51.342)	
Epoch: [40][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.494)	BT: 0.348 (1.842)	Loss 1.8545 (1.7782)	Prec@1 49.219 (51.422)	
Epoch: [40][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.505)	BT: 0.347 (1.854)	Loss 1.8398 (1.7729)	Prec@1 53.125 (51.569)	
Epoch: [40][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.494)	BT: 0.348 (1.842)	Loss 1.7588 (1.7741)	Prec@1 54.688 (51.645)	
Epoch: [40][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.488)	BT: 0.346 (1.836)	Loss 1.7510 (1.7765)	Prec@1 53.125 (51.687)	
Total train loss: 1.7765
Avg Loading time: 1.4840 seconds
Avg Batch time: 1.8319 seconds

Train time: 716.4007306098938
 * Prec@1 50.440 Prec@5 80.740 Loss 1.8389
Avg Loading time: 1.8106 seconds
Avg Batch time: 1.9587 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 155.39538598060608

Epoch: [41][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.513)	BT: 0.347 (1.862)	Loss 1.7158 (1.7815)	Prec@1 55.469 (51.472)	
Epoch: [41][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.508)	BT: 0.347 (1.857)	Loss 1.9355 (1.7893)	Prec@1 49.219 (51.387)	
Epoch: [41][233/391]	LR: 3.2000000000000005e-05	DT: 4.824 (1.496)	BT: 5.173 (1.844)	Loss 1.9434 (1.7845)	Prec@1 51.562 (51.469)	
Epoch: [41][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.319)	BT: 0.348 (1.668)	Loss 2.1426 (1.7814)	Prec@1 42.969 (51.618)	
Epoch: [41][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.218)	BT: 0.346 (1.567)	Loss 1.8008 (1.7807)	Prec@1 48.438 (51.434)	
Total train loss: 1.7807
Avg Loading time: 1.2153 seconds
Avg Batch time: 1.5631 seconds

Train time: 611.2852509021759
 * Prec@1 50.410 Prec@5 80.570 Loss 1.8418
Avg Loading time: 1.0434 seconds
Avg Batch time: 1.1531 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 91.77449035644531

Epoch: [42][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (0.809)	BT: 0.347 (1.158)	Loss 1.7324 (1.7814)	Prec@1 52.344 (51.613)	
Epoch: [42][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (0.855)	BT: 0.349 (1.204)	Loss 1.8408 (1.7785)	Prec@1 56.250 (51.547)	
Epoch: [42][233/391]	LR: 3.2000000000000005e-05	DT: 1.142 (0.901)	BT: 1.489 (1.250)	Loss 1.7305 (1.7795)	Prec@1 52.344 (51.583)	
Epoch: [42][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.001)	BT: 0.347 (1.349)	Loss 1.5615 (1.7727)	Prec@1 59.375 (51.790)	
Epoch: [42][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.143)	BT: 0.346 (1.491)	Loss 1.7227 (1.7777)	Prec@1 57.031 (51.689)	
Total train loss: 1.7779
Avg Loading time: 1.1401 seconds
Avg Batch time: 1.4880 seconds

Train time: 581.950585603714
 * Prec@1 50.300 Prec@5 80.510 Loss 1.8398
Avg Loading time: 1.8789 seconds
Avg Batch time: 2.1377 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 169.56199312210083

Epoch: [43][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.777)	BT: 0.350 (2.229)	Loss 1.7100 (1.7877)	Prec@1 57.812 (51.793)	
Epoch: [43][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.791)	BT: 0.350 (2.192)	Loss 1.7383 (1.7852)	Prec@1 53.906 (51.753)	
Epoch: [43][233/391]	LR: 3.2000000000000005e-05	DT: 0.078 (1.692)	BT: 0.428 (2.093)	Loss 1.7383 (1.7805)	Prec@1 50.000 (51.846)	
Epoch: [43][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.605)	BT: 0.350 (1.993)	Loss 1.6738 (1.7813)	Prec@1 55.469 (51.760)	
Epoch: [43][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.558)	BT: 0.348 (1.938)	Loss 1.8066 (1.7781)	Prec@1 58.594 (51.767)	
Total train loss: 1.7784
Avg Loading time: 1.5538 seconds
Avg Batch time: 1.9341 seconds

Train time: 756.3531677722931
 * Prec@1 50.390 Prec@5 80.540 Loss 1.8398
Avg Loading time: 1.7167 seconds
Avg Batch time: 1.8204 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 144.48064541816711

Epoch: [44][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.331)	BT: 0.350 (1.733)	Loss 1.7871 (1.7738)	Prec@1 48.438 (51.332)	
Epoch: [44][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.193)	BT: 0.346 (1.568)	Loss 1.7373 (1.7631)	Prec@1 51.562 (51.918)	
Epoch: [44][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.123)	BT: 0.348 (1.490)	Loss 1.7871 (1.7737)	Prec@1 48.438 (51.482)	
Epoch: [44][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.062)	BT: 0.347 (1.424)	Loss 1.7354 (1.7730)	Prec@1 52.344 (51.723)	
Epoch: [44][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.041)	BT: 0.346 (1.400)	Loss 1.7939 (1.7756)	Prec@1 52.344 (51.759)	
Total train loss: 1.7753
Avg Loading time: 1.0380 seconds
Avg Batch time: 1.3966 seconds

Train time: 546.2077686786652
 * Prec@1 50.400 Prec@5 80.520 Loss 1.8398
Avg Loading time: 1.3477 seconds
Avg Batch time: 1.4476 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 115.03497767448425

Epoch: [45][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.441)	BT: 0.347 (1.841)	Loss 1.9277 (1.7741)	Prec@1 49.219 (51.833)	
Epoch: [45][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.472)	BT: 0.347 (1.846)	Loss 1.7764 (1.7732)	Prec@1 52.344 (51.828)	
Epoch: [45][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.474)	BT: 0.348 (1.857)	Loss 1.6025 (1.7820)	Prec@1 52.344 (51.679)	
Epoch: [45][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.430)	BT: 0.347 (1.804)	Loss 1.8262 (1.7808)	Prec@1 50.000 (51.638)	
Epoch: [45][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.428)	BT: 0.346 (1.796)	Loss 1.8770 (1.7792)	Prec@1 48.438 (51.661)	
Total train loss: 1.7791
Avg Loading time: 1.4239 seconds
Avg Batch time: 1.7920 seconds

Train time: 700.8170652389526
 * Prec@1 50.460 Prec@5 80.730 Loss 1.8418
Avg Loading time: 1.6895 seconds
Avg Batch time: 1.8582 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 147.46979904174805

Epoch: [46][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.493)	BT: 0.347 (1.841)	Loss 1.6494 (1.7766)	Prec@1 55.469 (51.012)	
Epoch: [46][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.486)	BT: 0.349 (1.833)	Loss 1.9434 (1.7767)	Prec@1 46.094 (51.312)	
Epoch: [46][233/391]	LR: 3.2000000000000005e-05	DT: 1.702 (1.517)	BT: 2.054 (1.865)	Loss 1.9414 (1.7838)	Prec@1 53.125 (51.212)	
Epoch: [46][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.542)	BT: 0.347 (1.890)	Loss 1.6396 (1.7812)	Prec@1 60.938 (51.385)	
Epoch: [46][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.564)	BT: 0.346 (1.912)	Loss 1.8330 (1.7780)	Prec@1 48.438 (51.508)	
Total train loss: 1.7780
Avg Loading time: 1.5602 seconds
Avg Batch time: 1.9081 seconds

Train time: 746.2016649246216
 * Prec@1 50.340 Prec@5 80.380 Loss 1.8418
Avg Loading time: 1.7741 seconds
Avg Batch time: 2.1392 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 169.68179893493652

Epoch: [47][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (0.939)	BT: 0.349 (1.288)	Loss 1.8301 (1.7813)	Prec@1 52.344 (51.603)	
Epoch: [47][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (0.807)	BT: 0.346 (1.156)	Loss 1.6133 (1.7799)	Prec@1 59.375 (51.593)	
Epoch: [47][233/391]	LR: 3.2000000000000005e-05	DT: 1.290 (0.720)	BT: 1.640 (1.068)	Loss 1.8965 (1.7812)	Prec@1 50.781 (51.576)	
Epoch: [47][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (0.704)	BT: 0.348 (1.053)	Loss 1.9385 (1.7821)	Prec@1 45.312 (51.405)	
Epoch: [47][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (0.683)	BT: 0.346 (1.031)	Loss 1.7295 (1.7756)	Prec@1 50.000 (51.544)	
Total train loss: 1.7760
Avg Loading time: 0.6813 seconds
Avg Batch time: 1.0291 seconds

Train time: 402.5106325149536
 * Prec@1 50.520 Prec@5 80.600 Loss 1.8398
Avg Loading time: 1.0999 seconds
Avg Batch time: 1.1813 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 93.9818320274353

Epoch: [48][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.467)	BT: 0.347 (1.816)	Loss 1.6992 (1.7738)	Prec@1 49.219 (51.212)	
Epoch: [48][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.420)	BT: 0.347 (1.769)	Loss 1.7256 (1.7733)	Prec@1 52.344 (51.312)	
Epoch: [48][233/391]	LR: 3.2000000000000005e-05	DT: 8.661 (1.397)	BT: 9.011 (1.745)	Loss 1.7939 (1.7766)	Prec@1 51.562 (51.492)	
Epoch: [48][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.389)	BT: 0.347 (1.737)	Loss 1.8994 (1.7810)	Prec@1 51.562 (51.500)	
Epoch: [48][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.400)	BT: 0.346 (1.748)	Loss 1.9551 (1.7767)	Prec@1 46.094 (51.715)	
Total train loss: 1.7766
Avg Loading time: 1.3960 seconds
Avg Batch time: 1.7438 seconds

Train time: 681.9647827148438
 * Prec@1 50.210 Prec@5 80.570 Loss 1.8418
Avg Loading time: 1.6504 seconds
Avg Batch time: 1.8071 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 143.43884944915771

Epoch: [49][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.543)	BT: 0.349 (1.892)	Loss 1.8711 (1.7940)	Prec@1 44.531 (51.382)	
Epoch: [49][155/391]	LR: 3.2000000000000005e-05	DT: 0.881 (1.517)	BT: 1.232 (1.867)	Loss 1.9023 (1.7881)	Prec@1 42.188 (51.467)	
Epoch: [49][233/391]	LR: 3.2000000000000005e-05	DT: 0.362 (1.461)	BT: 0.714 (1.811)	Loss 1.8086 (1.7828)	Prec@1 53.906 (51.419)	
Epoch: [49][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.311)	BT: 0.349 (1.661)	Loss 1.6670 (1.7834)	Prec@1 55.469 (51.430)	
Epoch: [49][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.226)	BT: 0.348 (1.576)	Loss 1.8447 (1.7799)	Prec@1 46.875 (51.532)	
Total train loss: 1.7797
Avg Loading time: 1.2228 seconds
Avg Batch time: 1.5724 seconds

Train time: 614.9252009391785
 * Prec@1 50.480 Prec@5 80.670 Loss 1.8398
Avg Loading time: 1.2181 seconds
Avg Batch time: 1.3245 seconds

Best acc: 50.600
--------------------------------------------------------------------------------
Test time: 105.29131245613098


      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.02
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 3
          frozen_layers: 9
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar100/resnet18
DEVICE: cuda
GPU Id(s) being used: 3
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/train/relu9
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/test/relu9
ResNet18(
  (conv10): QConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): QConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): QConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): QConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=512, out_features=100, bias=False)
  (bn19): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 0.640 Prec@5 4.240 Loss 4.6172
Avg Loading time: 2.1321 seconds
Avg Batch time: 2.6817 seconds

Pre-trained Prec@1 with 9 layers frozen: 0.6399999856948853 	 Loss: 4.6171875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.02	DT: 0.000 (3.283)	BT: 0.249 (4.045)	Loss 2.2930 (2.8030)	Prec@1 46.875 (37.810)	
Epoch: [0][155/391]	LR: 0.02	DT: 0.000 (3.222)	BT: 0.249 (3.984)	Loss 3.2773 (2.9081)	Prec@1 25.000 (33.444)	
Epoch: [0][233/391]	LR: 0.02	DT: 0.567 (3.224)	BT: 0.817 (3.986)	Loss 3.0449 (2.8796)	Prec@1 25.781 (32.812)	
Epoch: [0][311/391]	LR: 0.02	DT: 0.000 (3.184)	BT: 0.248 (3.933)	Loss 2.2285 (2.7707)	Prec@1 39.062 (34.783)	
Epoch: [0][389/391]	LR: 0.02	DT: 0.000 (3.218)	BT: 0.248 (3.970)	Loss 1.8682 (2.6471)	Prec@1 55.469 (37.005)	
Total train loss: 2.6465
Avg Loading time: 3.2097 seconds
Avg Batch time: 3.9600 seconds

Train time: 1548.512069940567
 * Prec@1 46.650 Prec@5 77.550 Loss 2.0957
Avg Loading time: 1.8211 seconds
Avg Batch time: 1.9990 seconds

Best acc: 46.650
--------------------------------------------------------------------------------
Test time: 159.0173408985138

Epoch: [1][77/391]	LR: 0.02	DT: 0.000 (1.404)	BT: 0.246 (1.654)	Loss 2.4316 (2.0693)	Prec@1 36.719 (47.346)	
Epoch: [1][155/391]	LR: 0.02	DT: 0.000 (1.426)	BT: 0.249 (1.675)	Loss 1.9609 (2.0366)	Prec@1 45.312 (47.887)	
Epoch: [1][233/391]	LR: 0.02	DT: 0.000 (1.397)	BT: 0.248 (1.646)	Loss 1.8828 (2.0329)	Prec@1 53.125 (48.054)	
Epoch: [1][311/391]	LR: 0.02	DT: 0.000 (1.418)	BT: 0.247 (1.667)	Loss 2.2930 (2.1171)	Prec@1 40.625 (45.969)	
Epoch: [1][389/391]	LR: 0.02	DT: 0.000 (1.318)	BT: 0.248 (1.567)	Loss 2.0742 (2.1375)	Prec@1 51.562 (45.319)	
Total train loss: 2.1379
Avg Loading time: 1.3150 seconds
Avg Batch time: 1.5639 seconds

Train time: 611.5955307483673
 * Prec@1 4.290 Prec@5 14.020 Loss 5.3125
Avg Loading time: 1.0934 seconds
Avg Batch time: 1.1631 seconds

Best acc: 46.650
--------------------------------------------------------------------------------
Test time: 92.57123756408691

Epoch: [2][77/391]	LR: 0.02	DT: 0.000 (0.908)	BT: 0.249 (1.158)	Loss 2.2285 (2.0900)	Prec@1 44.531 (45.813)	
Epoch: [2][155/391]	LR: 0.02	DT: 0.000 (0.878)	BT: 0.250 (1.128)	Loss 2.0840 (2.1065)	Prec@1 46.875 (45.172)	
Epoch: [2][233/391]	LR: 0.02	DT: 0.000 (0.875)	BT: 0.249 (1.125)	Loss 2.0234 (2.0901)	Prec@1 49.219 (45.620)	
Epoch: [2][311/391]	LR: 0.02	DT: 0.000 (0.900)	BT: 0.249 (1.150)	Loss 2.0625 (2.0788)	Prec@1 45.312 (45.841)	
Epoch: [2][389/391]	LR: 0.02	DT: 0.000 (0.972)	BT: 0.247 (1.222)	Loss 1.8164 (2.0738)	Prec@1 46.094 (45.891)	
Total train loss: 2.0738
Avg Loading time: 0.9696 seconds
Avg Batch time: 1.2189 seconds

Train time: 476.71911430358887
 * Prec@1 15.460 Prec@5 39.200 Loss 4.2383
Avg Loading time: 1.7600 seconds
Avg Batch time: 1.8290 seconds

Best acc: 46.650
--------------------------------------------------------------------------------
Test time: 145.162513256073

Epoch: [3][77/391]	LR: 0.02	DT: 0.000 (1.648)	BT: 0.248 (1.898)	Loss 1.7822 (1.9265)	Prec@1 45.312 (48.658)	
Epoch: [3][155/391]	LR: 0.02	DT: 0.236 (1.606)	BT: 0.487 (1.855)	Loss 2.0293 (1.9346)	Prec@1 46.094 (48.448)	
Epoch: [3][233/391]	LR: 0.02	DT: 7.471 (1.563)	BT: 7.720 (1.813)	Loss 2.0547 (1.9327)	Prec@1 45.312 (48.384)	
Epoch: [3][311/391]	LR: 0.02	DT: 0.000 (1.539)	BT: 0.249 (1.789)	Loss 1.8662 (1.9125)	Prec@1 46.875 (48.906)	
Epoch: [3][389/391]	LR: 0.02	DT: 0.000 (1.527)	BT: 0.248 (1.776)	Loss 1.8486 (1.8969)	Prec@1 46.094 (49.161)	
Total train loss: 1.8970
Avg Loading time: 1.5231 seconds
Avg Batch time: 1.7723 seconds

Train time: 693.1331388950348
 * Prec@1 39.960 Prec@5 71.100 Loss 2.3223
Avg Loading time: 1.7093 seconds
Avg Batch time: 1.8400 seconds

Best acc: 46.650
--------------------------------------------------------------------------------
Test time: 146.03302764892578

Epoch: [4][77/391]	LR: 0.02	DT: 0.000 (1.253)	BT: 0.249 (1.502)	Loss 1.7852 (1.7198)	Prec@1 53.125 (53.245)	
Epoch: [4][155/391]	LR: 0.02	DT: 0.000 (1.099)	BT: 0.249 (1.347)	Loss 1.7080 (1.7461)	Prec@1 53.125 (52.830)	
Epoch: [4][233/391]	LR: 0.02	DT: 0.000 (1.084)	BT: 0.248 (1.333)	Loss 1.9531 (1.7627)	Prec@1 50.000 (52.477)	
Epoch: [4][311/391]	LR: 0.02	DT: 0.000 (0.995)	BT: 0.249 (1.244)	Loss 1.9619 (1.7664)	Prec@1 47.656 (52.181)	
Epoch: [4][389/391]	LR: 0.02	DT: 0.000 (0.935)	BT: 0.248 (1.184)	Loss 1.8545 (1.7650)	Prec@1 50.000 (52.210)	
Total train loss: 1.7651
Avg Loading time: 0.9327 seconds
Avg Batch time: 1.1813 seconds

Train time: 462.04246950149536
 * Prec@1 40.640 Prec@5 71.660 Loss 2.3145
Avg Loading time: 1.3739 seconds
Avg Batch time: 1.4458 seconds

Best acc: 46.650
--------------------------------------------------------------------------------
Test time: 114.89957427978516

Epoch: [5][77/391]	LR: 0.02	DT: 0.000 (1.440)	BT: 0.249 (1.690)	Loss 1.6846 (1.7057)	Prec@1 56.250 (53.756)	
Epoch: [5][155/391]	LR: 0.02	DT: 0.000 (1.618)	BT: 0.249 (1.868)	Loss 1.8711 (1.6976)	Prec@1 50.781 (53.916)	
Epoch: [5][233/391]	LR: 0.02	DT: 3.315 (1.552)	BT: 3.566 (1.802)	Loss 1.8428 (1.7074)	Prec@1 52.344 (53.496)	
Epoch: [5][311/391]	LR: 0.02	DT: 0.000 (1.463)	BT: 0.248 (1.713)	Loss 1.8955 (1.7030)	Prec@1 48.438 (53.518)	
Epoch: [5][389/391]	LR: 0.02	DT: 0.000 (1.425)	BT: 0.248 (1.674)	Loss 1.5391 (1.7050)	Prec@1 60.938 (53.444)	
Total train loss: 1.7044
Avg Loading time: 1.4210 seconds
Avg Batch time: 1.6701 seconds

Train time: 653.1374683380127
 * Prec@1 44.560 Prec@5 75.000 Loss 2.1699
Avg Loading time: 1.6607 seconds
Avg Batch time: 1.7303 seconds

Best acc: 46.650
--------------------------------------------------------------------------------
Test time: 137.3770034313202

Epoch: [6][77/391]	LR: 0.02	DT: 0.000 (1.585)	BT: 0.248 (1.835)	Loss 1.6514 (1.6570)	Prec@1 55.469 (55.028)	
Epoch: [6][155/391]	LR: 0.02	DT: 0.000 (1.576)	BT: 0.248 (1.826)	Loss 1.6729 (1.6799)	Prec@1 52.344 (54.567)	
Epoch: [6][233/391]	LR: 0.02	DT: 0.000 (1.583)	BT: 0.248 (1.832)	Loss 1.4531 (1.6793)	Prec@1 60.938 (54.384)	
Epoch: [6][311/391]	LR: 0.02	DT: 0.000 (1.544)	BT: 0.248 (1.793)	Loss 1.6172 (1.6744)	Prec@1 53.125 (54.562)	
Epoch: [6][389/391]	LR: 0.02	DT: 0.000 (1.542)	BT: 0.248 (1.791)	Loss 1.6982 (1.6648)	Prec@1 52.344 (54.796)	
Total train loss: 1.6647
Avg Loading time: 1.5378 seconds
Avg Batch time: 1.7867 seconds

Train time: 698.7517111301422
 * Prec@1 18.990 Prec@5 43.760 Loss 3.7246
Avg Loading time: 1.8055 seconds
Avg Batch time: 1.8782 seconds

Best acc: 46.650
--------------------------------------------------------------------------------
Test time: 149.0579764842987

Epoch: [7][77/391]	LR: 0.02	DT: 0.000 (1.570)	BT: 0.246 (1.870)	Loss 1.8672 (1.6094)	Prec@1 51.562 (55.449)	
Epoch: [7][155/391]	LR: 0.02	DT: 0.000 (1.585)	BT: 0.248 (1.858)	Loss 1.5059 (1.6290)	Prec@1 59.375 (55.454)	
Epoch: [7][233/391]	LR: 0.02	DT: 0.000 (1.416)	BT: 0.255 (1.681)	Loss 1.6396 (1.6533)	Prec@1 57.031 (54.814)	
Epoch: [7][311/391]	LR: 0.02	DT: 0.000 (1.272)	BT: 0.248 (1.533)	Loss 1.7803 (1.6531)	Prec@1 53.906 (54.843)	
Epoch: [7][389/391]	LR: 0.02	DT: 0.000 (1.184)	BT: 0.247 (1.443)	Loss 1.7686 (1.6550)	Prec@1 49.219 (54.924)	
Total train loss: 1.6556
Avg Loading time: 1.1813 seconds
Avg Batch time: 1.4399 seconds

Train time: 563.1607730388641
 * Prec@1 31.250 Prec@5 64.030 Loss 2.9609
Avg Loading time: 1.0654 seconds
Avg Batch time: 1.1398 seconds

Best acc: 46.650
--------------------------------------------------------------------------------
Test time: 90.7973804473877

Epoch: [8][77/391]	LR: 0.02	DT: 0.000 (0.976)	BT: 0.247 (1.224)	Loss 1.3682 (1.6117)	Prec@1 61.719 (55.479)	
Epoch: [8][155/391]	LR: 0.02	DT: 0.000 (0.968)	BT: 0.249 (1.216)	Loss 1.6123 (1.6249)	Prec@1 53.906 (55.394)	
Epoch: [8][233/391]	LR: 0.02	DT: 0.000 (1.017)	BT: 0.248 (1.266)	Loss 1.3799 (1.6275)	Prec@1 63.281 (55.686)	
Epoch: [8][311/391]	LR: 0.02	DT: 2.355 (1.128)	BT: 2.605 (1.377)	Loss 1.5186 (1.6325)	Prec@1 59.375 (55.649)	
Epoch: [8][389/391]	LR: 0.02	DT: 0.122 (1.233)	BT: 0.373 (1.482)	Loss 1.7627 (1.6238)	Prec@1 53.906 (55.931)	
Total train loss: 1.6244
Avg Loading time: 1.2302 seconds
Avg Batch time: 1.4790 seconds

Train time: 578.4046037197113
 * Prec@1 29.970 Prec@5 61.070 Loss 2.8809
Avg Loading time: 1.7481 seconds
Avg Batch time: 2.0340 seconds

Best acc: 46.650
--------------------------------------------------------------------------------
Test time: 161.35951042175293

Epoch: [9][77/391]	LR: 0.02	DT: 0.000 (2.018)	BT: 0.246 (2.574)	Loss 1.6094 (1.5721)	Prec@1 60.938 (56.981)	
Epoch: [9][155/391]	LR: 0.02	DT: 1.550 (2.132)	BT: 1.802 (2.534)	Loss 1.4473 (1.5987)	Prec@1 57.031 (56.065)	
Epoch: [9][233/391]	LR: 0.02	DT: 0.443 (2.001)	BT: 0.693 (2.351)	Loss 1.6973 (1.6062)	Prec@1 49.219 (55.976)	
Epoch: [9][311/391]	LR: 0.02	DT: 0.000 (1.735)	BT: 0.247 (2.060)	Loss 1.8232 (1.6183)	Prec@1 46.875 (55.839)	
Epoch: [9][389/391]	LR: 0.02	DT: 0.000 (1.548)	BT: 0.245 (1.857)	Loss 1.7422 (1.6230)	Prec@1 48.438 (55.845)	
Total train loss: 1.6235
Avg Loading time: 1.5444 seconds
Avg Batch time: 1.8531 seconds

Train time: 724.7083811759949
 * Prec@1 6.180 Prec@5 20.190 Loss 6.0742
Avg Loading time: 1.1109 seconds
Avg Batch time: 1.1954 seconds

Best acc: 46.650
--------------------------------------------------------------------------------
Test time: 95.11451649665833

Epoch: [10][77/391]	LR: 0.004	DT: 0.000 (0.981)	BT: 0.251 (1.229)	Loss 1.6807 (1.5995)	Prec@1 56.250 (56.350)	
Epoch: [10][155/391]	LR: 0.004	DT: 0.000 (0.980)	BT: 0.248 (1.228)	Loss 1.6895 (1.5820)	Prec@1 58.594 (56.806)	
Epoch: [10][233/391]	LR: 0.004	DT: 0.000 (0.994)	BT: 0.248 (1.242)	Loss 1.4785 (1.5790)	Prec@1 58.594 (57.021)	
Epoch: [10][311/391]	LR: 0.004	DT: 0.000 (1.091)	BT: 0.248 (1.339)	Loss 1.3936 (1.5702)	Prec@1 64.062 (57.069)	
Epoch: [10][389/391]	LR: 0.004	DT: 0.000 (1.163)	BT: 0.248 (1.411)	Loss 1.5020 (1.5630)	Prec@1 58.594 (57.276)	
Total train loss: 1.5634
Avg Loading time: 1.1596 seconds
Avg Batch time: 1.4077 seconds

Train time: 550.5369832515717
 * Prec@1 55.280 Prec@5 83.780 Loss 1.6641
Avg Loading time: 1.7199 seconds
Avg Batch time: 1.8483 seconds

Best acc: 55.280
--------------------------------------------------------------------------------
Test time: 147.16280245780945

Epoch: [11][77/391]	LR: 0.004	DT: 0.000 (1.645)	BT: 0.248 (1.895)	Loss 1.4756 (1.5511)	Prec@1 62.500 (57.853)	
Epoch: [11][155/391]	LR: 0.004	DT: 0.815 (1.606)	BT: 1.066 (1.856)	Loss 1.5449 (1.5579)	Prec@1 62.500 (57.487)	
Epoch: [11][233/391]	LR: 0.004	DT: 1.055 (1.598)	BT: 1.306 (1.848)	Loss 1.5059 (1.5568)	Prec@1 60.156 (57.575)	
Epoch: [11][311/391]	LR: 0.004	DT: 0.000 (1.551)	BT: 0.248 (1.800)	Loss 1.3652 (1.5566)	Prec@1 67.188 (57.582)	
Epoch: [11][389/391]	LR: 0.004	DT: 0.000 (1.553)	BT: 0.247 (1.802)	Loss 1.5752 (1.5516)	Prec@1 58.594 (57.760)	
Total train loss: 1.5513
Avg Loading time: 1.5486 seconds
Avg Batch time: 1.7975 seconds

Train time: 702.9438633918762
 * Prec@1 55.080 Prec@5 83.810 Loss 1.6465
Avg Loading time: 2.0412 seconds
Avg Batch time: 2.1630 seconds

Best acc: 55.280
--------------------------------------------------------------------------------
Test time: 171.5434718132019

Epoch: [12][77/391]	LR: 0.004	DT: 0.000 (2.187)	BT: 0.247 (2.949)	Loss 1.2617 (1.5401)	Prec@1 66.406 (57.742)	
Epoch: [12][155/391]	LR: 0.004	DT: 0.000 (2.171)	BT: 0.247 (2.932)	Loss 1.6016 (1.5317)	Prec@1 55.469 (58.223)	
Epoch: [12][233/391]	LR: 0.004	DT: 0.000 (2.190)	BT: 0.249 (2.952)	Loss 1.8066 (1.5369)	Prec@1 51.562 (58.136)	
Epoch: [12][311/391]	LR: 0.004	DT: 0.000 (2.196)	BT: 0.253 (2.843)	Loss 1.5176 (1.5409)	Prec@1 55.469 (57.865)	
Epoch: [12][389/391]	LR: 0.004	DT: 0.000 (2.024)	BT: 0.257 (2.822)	Loss 1.5537 (1.5457)	Prec@1 55.469 (57.790)	
Total train loss: 1.5458
Avg Loading time: 2.0188 seconds
Avg Batch time: 2.8155 seconds

Train time: 1100.9886298179626
 * Prec@1 54.910 Prec@5 84.000 Loss 1.6543
Avg Loading time: 1.2618 seconds
Avg Batch time: 2.8641 seconds

Best acc: 55.280
--------------------------------------------------------------------------------
Test time: 226.96000242233276

Epoch: [13][77/391]	LR: 0.004	DT: 0.000 (1.825)	BT: 0.246 (2.278)	Loss 1.3955 (1.5346)	Prec@1 61.719 (58.373)	
Epoch: [13][155/391]	LR: 0.004	DT: 0.504 (1.755)	BT: 0.763 (2.350)	Loss 1.5342 (1.5342)	Prec@1 57.812 (58.183)	
Epoch: [13][233/391]	LR: 0.004	DT: 0.000 (1.634)	BT: 0.247 (2.370)	Loss 1.6660 (1.5394)	Prec@1 50.781 (57.989)	
Epoch: [13][311/391]	LR: 0.004	DT: 0.266 (1.597)	BT: 0.518 (2.501)	Loss 1.5537 (1.5436)	Prec@1 56.250 (57.810)	
Epoch: [13][389/391]	LR: 0.004	DT: 0.000 (1.622)	BT: 0.249 (2.512)	Loss 1.5068 (1.5438)	Prec@1 57.812 (57.823)	
Total train loss: 1.5442
Avg Loading time: 1.6177 seconds
Avg Batch time: 2.5064 seconds

Train time: 980.1529643535614
 * Prec@1 55.280 Prec@5 83.960 Loss 1.6562
Avg Loading time: 1.2539 seconds
Avg Batch time: 3.2466 seconds

Best acc: 55.280
--------------------------------------------------------------------------------
Test time: 257.16270542144775

Epoch: [14][77/391]	LR: 0.004	DT: 0.000 (1.385)	BT: 0.249 (3.174)	Loss 1.4814 (1.5291)	Prec@1 58.594 (58.654)	
Epoch: [14][155/391]	LR: 0.004	DT: 0.249 (1.501)	BT: 0.498 (2.712)	Loss 1.6787 (1.5299)	Prec@1 58.594 (58.449)	
Epoch: [14][233/391]	LR: 0.004	DT: 0.000 (1.665)	BT: 0.251 (2.556)	Loss 1.4414 (1.5338)	Prec@1 57.812 (58.136)	
Epoch: [14][311/391]	LR: 0.004	DT: 0.000 (1.536)	BT: 0.249 (2.266)	Loss 1.5264 (1.5347)	Prec@1 60.156 (57.943)	
Epoch: [14][389/391]	LR: 0.004	DT: 0.000 (1.432)	BT: 0.246 (2.066)	Loss 1.3691 (1.5394)	Prec@1 60.938 (57.869)	
Total train loss: 1.5394
Avg Loading time: 1.4287 seconds
Avg Batch time: 2.0616 seconds

Train time: 806.2177040576935
 * Prec@1 55.290 Prec@5 83.840 Loss 1.6572
Avg Loading time: 1.2823 seconds
Avg Batch time: 1.3663 seconds

Best acc: 55.290
--------------------------------------------------------------------------------
Test time: 109.09711337089539

Epoch: [15][77/391]	LR: 0.004	DT: 0.000 (1.392)	BT: 0.247 (2.026)	Loss 1.4355 (1.5299)	Prec@1 58.594 (58.203)	
Epoch: [15][155/391]	LR: 0.004	DT: 0.000 (1.456)	BT: 0.250 (1.898)	Loss 1.3955 (1.5349)	Prec@1 60.938 (58.158)	
Epoch: [15][233/391]	LR: 0.004	DT: 11.289 (1.484)	BT: 11.540 (1.861)	Loss 1.5459 (1.5350)	Prec@1 54.688 (58.009)	
Epoch: [15][311/391]	LR: 0.004	DT: 1.764 (1.469)	BT: 2.013 (1.815)	Loss 1.8447 (1.5376)	Prec@1 48.438 (57.963)	
Epoch: [15][389/391]	LR: 0.004	DT: 0.000 (1.469)	BT: 0.247 (1.795)	Loss 1.8945 (1.5361)	Prec@1 45.312 (57.979)	
Total train loss: 1.5363
Avg Loading time: 1.4653 seconds
Avg Batch time: 1.7913 seconds

Train time: 700.5082819461823
 * Prec@1 55.310 Prec@5 83.850 Loss 1.6436
Avg Loading time: 1.7505 seconds
Avg Batch time: 1.8621 seconds

Best acc: 55.310
--------------------------------------------------------------------------------
Test time: 148.25494647026062

Epoch: [16][77/391]	LR: 0.004	DT: 0.000 (1.581)	BT: 0.248 (1.830)	Loss 1.4902 (1.5279)	Prec@1 61.719 (58.103)	
Epoch: [16][155/391]	LR: 0.004	DT: 0.000 (1.604)	BT: 0.248 (1.853)	Loss 1.4346 (1.5290)	Prec@1 59.375 (58.263)	
Epoch: [16][233/391]	LR: 0.004	DT: 0.338 (1.613)	BT: 0.590 (1.862)	Loss 1.3525 (1.5374)	Prec@1 62.500 (57.919)	
Epoch: [16][311/391]	LR: 0.004	DT: 0.000 (1.630)	BT: 0.248 (1.892)	Loss 1.5693 (1.5372)	Prec@1 57.031 (57.963)	
Epoch: [16][389/391]	LR: 0.004	DT: 0.000 (1.703)	BT: 0.249 (2.003)	Loss 1.5635 (1.5392)	Prec@1 51.562 (57.804)	
Total train loss: 1.5392
Avg Loading time: 1.6988 seconds
Avg Batch time: 1.9987 seconds

Train time: 781.6338875293732
 * Prec@1 55.180 Prec@5 83.960 Loss 1.6484
Avg Loading time: 2.0758 seconds
Avg Batch time: 2.4413 seconds

Best acc: 55.310
--------------------------------------------------------------------------------
Test time: 193.5284721851349

Epoch: [17][77/391]	LR: 0.004	DT: 0.000 (1.858)	BT: 0.252 (2.261)	Loss 1.4707 (1.5290)	Prec@1 57.812 (57.943)	
Epoch: [17][155/391]	LR: 0.004	DT: 0.000 (1.658)	BT: 0.249 (2.010)	Loss 1.6963 (1.5335)	Prec@1 57.031 (57.883)	
Epoch: [17][233/391]	LR: 0.004	DT: 0.000 (1.560)	BT: 0.249 (1.878)	Loss 1.6709 (1.5407)	Prec@1 54.688 (57.742)	
Epoch: [17][311/391]	LR: 0.004	DT: 0.000 (1.371)	BT: 0.249 (1.672)	Loss 1.5947 (1.5392)	Prec@1 61.719 (57.815)	
Epoch: [17][389/391]	LR: 0.004	DT: 0.000 (1.245)	BT: 0.247 (1.535)	Loss 1.6279 (1.5382)	Prec@1 55.469 (57.843)	
Total train loss: 1.5377
Avg Loading time: 1.2420 seconds
Avg Batch time: 1.5319 seconds

Train time: 599.1049885749817
 * Prec@1 54.920 Prec@5 84.170 Loss 1.6484
Avg Loading time: 1.0051 seconds
Avg Batch time: 1.0889 seconds

Best acc: 55.310
--------------------------------------------------------------------------------
Test time: 86.70239591598511

Epoch: [18][77/391]	LR: 0.004	DT: 0.000 (0.891)	BT: 0.248 (1.140)	Loss 1.5596 (1.5374)	Prec@1 57.031 (57.332)	
Epoch: [18][155/391]	LR: 0.004	DT: 0.000 (0.908)	BT: 0.249 (1.157)	Loss 1.6914 (1.5326)	Prec@1 55.469 (57.933)	
Epoch: [18][233/391]	LR: 0.004	DT: 0.000 (0.909)	BT: 0.246 (1.159)	Loss 1.6582 (1.5410)	Prec@1 53.125 (57.809)	
Epoch: [18][311/391]	LR: 0.004	DT: 0.000 (0.978)	BT: 0.245 (1.227)	Loss 1.3379 (1.5356)	Prec@1 62.500 (57.968)	
Epoch: [18][389/391]	LR: 0.004	DT: 0.000 (1.084)	BT: 0.246 (1.333)	Loss 1.6221 (1.5372)	Prec@1 53.906 (57.939)	
Total train loss: 1.5374
Avg Loading time: 1.0814 seconds
Avg Batch time: 1.3295 seconds

Train time: 519.9806575775146
 * Prec@1 55.240 Prec@5 83.840 Loss 1.6514
Avg Loading time: 1.6875 seconds
Avg Batch time: 1.8756 seconds

Best acc: 55.310
--------------------------------------------------------------------------------
Test time: 148.8352735042572

Epoch: [19][77/391]	LR: 0.004	DT: 0.000 (1.629)	BT: 0.245 (1.877)	Loss 1.7344 (1.5227)	Prec@1 52.344 (58.253)	
Epoch: [19][155/391]	LR: 0.004	DT: 0.914 (1.606)	BT: 1.162 (1.853)	Loss 1.7822 (1.5349)	Prec@1 53.125 (57.863)	
Epoch: [19][233/391]	LR: 0.004	DT: 8.137 (1.524)	BT: 8.387 (1.772)	Loss 1.5791 (1.5340)	Prec@1 53.906 (57.782)	
Epoch: [19][311/391]	LR: 0.004	DT: 0.000 (1.394)	BT: 0.245 (1.641)	Loss 1.4268 (1.5363)	Prec@1 61.719 (57.792)	
Epoch: [19][389/391]	LR: 0.004	DT: 0.000 (1.310)	BT: 0.245 (1.557)	Loss 1.5332 (1.5357)	Prec@1 58.594 (57.770)	
Total train loss: 1.5358
Avg Loading time: 1.3065 seconds
Avg Batch time: 1.5539 seconds

Train time: 607.7019426822662
 * Prec@1 55.130 Prec@5 83.800 Loss 1.6494
Avg Loading time: 1.2595 seconds
Avg Batch time: 1.3390 seconds

Best acc: 55.310
--------------------------------------------------------------------------------
Test time: 106.43215012550354

Epoch: [20][77/391]	LR: 0.0008	DT: 0.000 (1.148)	BT: 0.249 (1.397)	Loss 1.6133 (1.5329)	Prec@1 54.688 (57.883)	
Epoch: [20][155/391]	LR: 0.0008	DT: 0.000 (1.130)	BT: 0.247 (1.378)	Loss 1.5127 (1.5284)	Prec@1 62.500 (58.118)	
Epoch: [20][233/391]	LR: 0.0008	DT: 0.000 (1.186)	BT: 0.246 (1.434)	Loss 1.4912 (1.5297)	Prec@1 61.719 (58.176)	
Epoch: [20][311/391]	LR: 0.0008	DT: 1.235 (1.280)	BT: 1.483 (1.527)	Loss 1.4590 (1.5291)	Prec@1 56.250 (58.083)	
Epoch: [20][389/391]	LR: 0.0008	DT: 0.000 (1.312)	BT: 0.245 (1.560)	Loss 1.5732 (1.5269)	Prec@1 57.812 (58.141)	
Total train loss: 1.5270
Avg Loading time: 1.3091 seconds
Avg Batch time: 1.5564 seconds

Train time: 608.6995825767517
 * Prec@1 55.330 Prec@5 84.060 Loss 1.6396
Avg Loading time: 1.9307 seconds
Avg Batch time: 2.2644 seconds

Best acc: 55.330
--------------------------------------------------------------------------------
Test time: 180.00433993339539

Epoch: [21][77/391]	LR: 0.0008	DT: 0.000 (2.063)	BT: 0.247 (2.618)	Loss 1.3809 (1.5187)	Prec@1 58.594 (58.373)	
Epoch: [21][155/391]	LR: 0.0008	DT: 0.001 (2.038)	BT: 0.250 (2.567)	Loss 1.5322 (1.5261)	Prec@1 56.250 (58.008)	
Epoch: [21][233/391]	LR: 0.0008	DT: 0.000 (1.922)	BT: 0.249 (2.375)	Loss 1.6689 (1.5196)	Prec@1 60.156 (58.310)	
Epoch: [21][311/391]	LR: 0.0008	DT: 0.000 (1.755)	BT: 0.248 (2.156)	Loss 1.7949 (1.5211)	Prec@1 48.438 (58.233)	
Epoch: [21][389/391]	LR: 0.0008	DT: 0.000 (1.678)	BT: 0.249 (2.049)	Loss 1.5039 (1.5210)	Prec@1 55.469 (58.295)	
Total train loss: 1.5212
Avg Loading time: 1.6740 seconds
Avg Batch time: 2.0447 seconds

Train time: 799.5973303318024
 * Prec@1 55.130 Prec@5 84.100 Loss 1.6436
Avg Loading time: 1.6793 seconds
Avg Batch time: 1.7593 seconds

Best acc: 55.330
--------------------------------------------------------------------------------
Test time: 139.6489760875702

Epoch: [22][77/391]	LR: 0.0008	DT: 0.000 (1.506)	BT: 0.248 (1.808)	Loss 1.3936 (1.4929)	Prec@1 63.281 (58.984)	
Epoch: [22][155/391]	LR: 0.0008	DT: 0.000 (1.534)	BT: 0.249 (1.809)	Loss 1.2969 (1.5061)	Prec@1 64.844 (58.689)	
Epoch: [22][233/391]	LR: 0.0008	DT: 0.000 (1.551)	BT: 0.249 (1.817)	Loss 1.5977 (1.5113)	Prec@1 55.469 (58.470)	
Epoch: [22][311/391]	LR: 0.0008	DT: 0.000 (1.522)	BT: 0.248 (1.784)	Loss 1.5049 (1.5174)	Prec@1 56.250 (58.316)	
Epoch: [22][389/391]	LR: 0.0008	DT: 0.000 (1.526)	BT: 0.249 (1.786)	Loss 1.6436 (1.5255)	Prec@1 53.125 (58.129)	
Total train loss: 1.5254
Avg Loading time: 1.5224 seconds
Avg Batch time: 1.7818 seconds

Train time: 696.8131074905396
 * Prec@1 55.460 Prec@5 84.060 Loss 1.6436
Avg Loading time: 1.6628 seconds
Avg Batch time: 1.8534 seconds

Best acc: 55.460
--------------------------------------------------------------------------------
Test time: 147.5456211566925

Epoch: [23][77/391]	LR: 0.0008	DT: 0.000 (1.244)	BT: 0.250 (1.494)	Loss 1.6133 (1.5218)	Prec@1 54.688 (58.524)	
Epoch: [23][155/391]	LR: 0.0008	DT: 0.000 (1.136)	BT: 0.249 (1.385)	Loss 1.7393 (1.5292)	Prec@1 54.688 (58.188)	
Epoch: [23][233/391]	LR: 0.0008	DT: 0.000 (1.077)	BT: 0.250 (1.326)	Loss 1.4932 (1.5173)	Prec@1 63.281 (58.514)	
Epoch: [23][311/391]	LR: 0.0008	DT: 0.000 (0.998)	BT: 0.248 (1.247)	Loss 1.2305 (1.5207)	Prec@1 66.406 (58.474)	
Epoch: [23][389/391]	LR: 0.0008	DT: 0.000 (0.983)	BT: 0.248 (1.232)	Loss 1.3506 (1.5211)	Prec@1 65.625 (58.277)	
Total train loss: 1.5207
Avg Loading time: 0.9802 seconds
Avg Batch time: 1.2294 seconds

Train time: 480.8267991542816
 * Prec@1 55.150 Prec@5 84.060 Loss 1.6436
Avg Loading time: 1.1750 seconds
Avg Batch time: 1.2549 seconds

Best acc: 55.460
--------------------------------------------------------------------------------
Test time: 99.78713846206665

Epoch: [24][77/391]	LR: 0.0008	DT: 0.000 (1.130)	BT: 0.248 (1.379)	Loss 1.4502 (1.5428)	Prec@1 56.250 (57.302)	
Epoch: [24][155/391]	LR: 0.0008	DT: 0.000 (1.348)	BT: 0.248 (1.597)	Loss 1.4746 (1.5254)	Prec@1 57.812 (57.988)	
Epoch: [24][233/391]	LR: 0.0008	DT: 0.000 (1.397)	BT: 0.248 (1.646)	Loss 1.7627 (1.5229)	Prec@1 50.781 (57.996)	
Epoch: [24][311/391]	LR: 0.0008	DT: 0.000 (1.431)	BT: 0.248 (1.680)	Loss 1.4531 (1.5222)	Prec@1 57.812 (58.083)	
Epoch: [24][389/391]	LR: 0.0008	DT: 0.000 (1.425)	BT: 0.248 (1.674)	Loss 1.3994 (1.5218)	Prec@1 60.156 (58.071)	
Total train loss: 1.5218
Avg Loading time: 1.4215 seconds
Avg Batch time: 1.6702 seconds

Train time: 653.1471140384674
 * Prec@1 55.460 Prec@5 84.090 Loss 1.6416
Avg Loading time: 1.1922 seconds
Avg Batch time: 1.2775 seconds

Best acc: 55.460
--------------------------------------------------------------------------------
Test time: 101.5742564201355

Epoch: [25][77/391]	LR: 0.0008	DT: 0.000 (1.293)	BT: 0.249 (1.542)	Loss 1.6797 (1.5216)	Prec@1 52.344 (58.814)	
Epoch: [25][155/391]	LR: 0.0008	DT: 0.000 (1.298)	BT: 0.250 (1.547)	Loss 1.3154 (1.5250)	Prec@1 65.625 (58.464)	
Epoch: [25][233/391]	LR: 0.0008	DT: 0.000 (1.286)	BT: 0.248 (1.535)	Loss 1.6973 (1.5262)	Prec@1 54.688 (58.240)	
Epoch: [25][311/391]	LR: 0.0008	DT: 0.000 (1.185)	BT: 0.249 (1.435)	Loss 1.2793 (1.5207)	Prec@1 65.625 (58.266)	
Epoch: [25][389/391]	LR: 0.0008	DT: 0.000 (1.123)	BT: 0.245 (1.372)	Loss 1.6299 (1.5207)	Prec@1 55.469 (58.243)	
Total train loss: 1.5208
Avg Loading time: 1.1200 seconds
Avg Batch time: 1.3691 seconds

Train time: 535.4451313018799
 * Prec@1 55.310 Prec@5 83.970 Loss 1.6396
Avg Loading time: 1.5474 seconds
Avg Batch time: 1.6113 seconds

Best acc: 55.460
--------------------------------------------------------------------------------
Test time: 127.93147230148315

Epoch: [26][77/391]	LR: 0.0008	DT: 0.000 (1.366)	BT: 0.249 (1.616)	Loss 1.8086 (1.5239)	Prec@1 45.312 (57.963)	
Epoch: [26][155/391]	LR: 0.0008	DT: 0.728 (1.371)	BT: 0.980 (1.620)	Loss 1.3643 (1.5087)	Prec@1 58.594 (58.413)	
Epoch: [26][233/391]	LR: 0.0008	DT: 0.000 (1.406)	BT: 0.249 (1.656)	Loss 1.5410 (1.5184)	Prec@1 58.594 (58.297)	
Epoch: [26][311/391]	LR: 0.0008	DT: 0.000 (1.391)	BT: 0.248 (1.640)	Loss 1.5596 (1.5203)	Prec@1 64.844 (58.348)	
Epoch: [26][389/391]	LR: 0.0008	DT: 0.000 (1.408)	BT: 0.250 (1.657)	Loss 1.6260 (1.5220)	Prec@1 56.250 (58.259)	
Total train loss: 1.5218
Avg Loading time: 1.4045 seconds
Avg Batch time: 1.6535 seconds

Train time: 646.6628303527832
 * Prec@1 55.240 Prec@5 84.020 Loss 1.6396
Avg Loading time: 1.7523 seconds
Avg Batch time: 1.8344 seconds

Best acc: 55.460
--------------------------------------------------------------------------------
Test time: 145.5679829120636

Epoch: [27][77/391]	LR: 0.0008	DT: 0.000 (1.622)	BT: 0.249 (1.870)	Loss 1.6074 (1.5321)	Prec@1 54.688 (57.963)	
Epoch: [27][155/391]	LR: 0.0008	DT: 0.000 (1.604)	BT: 0.248 (1.852)	Loss 1.5107 (1.5251)	Prec@1 60.156 (58.078)	
Epoch: [27][233/391]	LR: 0.0008	DT: 0.000 (1.610)	BT: 0.248 (1.859)	Loss 1.6162 (1.5184)	Prec@1 53.906 (58.260)	
Epoch: [27][311/391]	LR: 0.0008	DT: 0.000 (1.571)	BT: 0.249 (1.819)	Loss 1.6328 (1.5136)	Prec@1 54.688 (58.383)	
Epoch: [27][389/391]	LR: 0.0008	DT: 0.000 (1.549)	BT: 0.247 (1.798)	Loss 1.2285 (1.5195)	Prec@1 66.406 (58.297)	
Total train loss: 1.5198
Avg Loading time: 1.5455 seconds
Avg Batch time: 1.7938 seconds

Train time: 701.507429599762
 * Prec@1 55.480 Prec@5 84.090 Loss 1.6367
Avg Loading time: 1.7377 seconds
Avg Batch time: 1.8113 seconds

Best acc: 55.480
--------------------------------------------------------------------------------
Test time: 144.2502031326294

Epoch: [28][77/391]	LR: 0.0008	DT: 0.000 (1.521)	BT: 0.247 (1.821)	Loss 1.4502 (1.5330)	Prec@1 59.375 (58.003)	
Epoch: [28][155/391]	LR: 0.0008	DT: 0.000 (1.553)	BT: 0.249 (1.827)	Loss 1.6768 (1.5385)	Prec@1 52.344 (57.777)	
Epoch: [28][233/391]	LR: 0.0008	DT: 10.849 (1.554)	BT: 11.100 (1.821)	Loss 1.4619 (1.5232)	Prec@1 61.719 (58.216)	
Epoch: [28][311/391]	LR: 0.0008	DT: 0.000 (1.533)	BT: 0.248 (1.795)	Loss 1.5791 (1.5231)	Prec@1 56.250 (58.266)	
Epoch: [28][389/391]	LR: 0.0008	DT: 0.000 (1.434)	BT: 0.248 (1.693)	Loss 1.3799 (1.5190)	Prec@1 63.281 (58.315)	
Total train loss: 1.5190
Avg Loading time: 1.4299 seconds
Avg Batch time: 1.6891 seconds

Train time: 660.5832233428955
 * Prec@1 55.380 Prec@5 83.940 Loss 1.6416
Avg Loading time: 1.1080 seconds
Avg Batch time: 1.1963 seconds

Best acc: 55.480
--------------------------------------------------------------------------------
Test time: 95.16323637962341

Epoch: [29][77/391]	LR: 0.0008	DT: 0.000 (1.088)	BT: 0.248 (1.337)	Loss 1.6094 (1.5298)	Prec@1 58.594 (58.073)	
Epoch: [29][155/391]	LR: 0.0008	DT: 0.000 (1.019)	BT: 0.248 (1.269)	Loss 1.4424 (1.5284)	Prec@1 60.156 (57.883)	
Epoch: [29][233/391]	LR: 0.0008	DT: 0.000 (0.983)	BT: 0.250 (1.233)	Loss 1.7275 (1.5308)	Prec@1 54.688 (58.060)	
Epoch: [29][311/391]	LR: 0.0008	DT: 0.000 (0.931)	BT: 0.247 (1.180)	Loss 1.5020 (1.5261)	Prec@1 60.156 (58.095)	
Epoch: [29][389/391]	LR: 0.0008	DT: 0.000 (0.943)	BT: 0.248 (1.192)	Loss 1.4346 (1.5239)	Prec@1 59.375 (58.169)	
Total train loss: 1.5240
Avg Loading time: 0.9401 seconds
Avg Batch time: 1.1892 seconds

Train time: 465.1057975292206
 * Prec@1 55.140 Prec@5 84.060 Loss 1.6357
Avg Loading time: 1.8104 seconds
Avg Batch time: 2.0466 seconds

Best acc: 55.480
--------------------------------------------------------------------------------
Test time: 162.34906721115112

Epoch: [30][77/391]	LR: 0.00016	DT: 0.000 (1.575)	BT: 0.251 (1.876)	Loss 1.5508 (1.4876)	Prec@1 57.812 (59.034)	
Epoch: [30][155/391]	LR: 0.00016	DT: 0.000 (1.419)	BT: 0.248 (1.694)	Loss 1.4912 (1.5043)	Prec@1 59.375 (58.439)	
Epoch: [30][233/391]	LR: 0.00016	DT: 0.119 (1.185)	BT: 0.370 (1.452)	Loss 1.6338 (1.5087)	Prec@1 54.688 (58.497)	
Epoch: [30][311/391]	LR: 0.00016	DT: 0.000 (1.089)	BT: 0.247 (1.351)	Loss 1.6387 (1.5198)	Prec@1 55.469 (58.321)	
Epoch: [30][389/391]	LR: 0.00016	DT: 0.000 (1.065)	BT: 0.247 (1.325)	Loss 1.6260 (1.5180)	Prec@1 59.375 (58.397)	
Total train loss: 1.5180
Avg Loading time: 1.0625 seconds
Avg Batch time: 1.3219 seconds

Train time: 517.015175819397
 * Prec@1 55.250 Prec@5 84.110 Loss 1.6396
Avg Loading time: 1.2685 seconds
Avg Batch time: 1.3428 seconds

Best acc: 55.480
--------------------------------------------------------------------------------
Test time: 106.75991988182068

Epoch: [31][77/391]	LR: 0.00016	DT: 0.000 (1.181)	BT: 0.249 (1.431)	Loss 1.4512 (1.5101)	Prec@1 64.062 (58.283)	
Epoch: [31][155/391]	LR: 0.00016	DT: 0.000 (1.234)	BT: 0.250 (1.484)	Loss 1.5518 (1.5105)	Prec@1 60.156 (58.439)	
Epoch: [31][233/391]	LR: 0.00016	DT: 0.000 (1.350)	BT: 0.250 (1.600)	Loss 1.3994 (1.5260)	Prec@1 57.031 (57.976)	
Epoch: [31][311/391]	LR: 0.00016	DT: 1.324 (1.373)	BT: 1.573 (1.623)	Loss 2.0039 (1.5234)	Prec@1 46.094 (58.035)	
Epoch: [31][389/391]	LR: 0.00016	DT: 0.000 (1.387)	BT: 0.248 (1.637)	Loss 1.6406 (1.5188)	Prec@1 51.562 (58.201)	
Total train loss: 1.5192
Avg Loading time: 1.3835 seconds
Avg Batch time: 1.6327 seconds

Train time: 638.5234849452972
 * Prec@1 55.450 Prec@5 84.130 Loss 1.6367
Avg Loading time: 1.7433 seconds
Avg Batch time: 1.8650 seconds

Best acc: 55.480
--------------------------------------------------------------------------------
Test time: 147.94309282302856

Epoch: [32][77/391]	LR: 0.00016	DT: 0.000 (1.817)	BT: 0.248 (2.067)	Loss 1.5645 (1.5258)	Prec@1 57.031 (58.474)	
Epoch: [32][155/391]	LR: 0.00016	DT: 0.000 (1.745)	BT: 0.246 (1.994)	Loss 1.5898 (1.5227)	Prec@1 57.812 (58.589)	
Epoch: [32][233/391]	LR: 0.00016	DT: 0.000 (1.651)	BT: 0.248 (1.900)	Loss 1.6123 (1.5242)	Prec@1 55.469 (58.470)	
Epoch: [32][311/391]	LR: 0.00016	DT: 0.000 (1.645)	BT: 0.248 (1.894)	Loss 1.3525 (1.5226)	Prec@1 60.156 (58.454)	
Epoch: [32][389/391]	LR: 0.00016	DT: 0.000 (1.625)	BT: 0.248 (1.874)	Loss 1.6025 (1.5175)	Prec@1 57.812 (58.524)	
Total train loss: 1.5175
Avg Loading time: 1.6212 seconds
Avg Batch time: 1.8699 seconds

Train time: 731.2598094940186
 * Prec@1 55.360 Prec@5 84.170 Loss 1.6377
Avg Loading time: 1.8526 seconds
Avg Batch time: 1.9655 seconds

Best acc: 55.480
--------------------------------------------------------------------------------
Test time: 155.93328952789307

Epoch: [33][77/391]	LR: 0.00016	DT: 0.000 (1.742)	BT: 0.248 (2.196)	Loss 1.6953 (1.4984)	Prec@1 55.469 (58.814)	
Epoch: [33][155/391]	LR: 0.00016	DT: 0.770 (1.693)	BT: 1.018 (2.070)	Loss 1.5801 (1.5152)	Prec@1 57.031 (58.343)	
Epoch: [33][233/391]	LR: 0.00016	DT: 1.393 (1.661)	BT: 1.643 (1.995)	Loss 1.3037 (1.5140)	Prec@1 66.406 (58.480)	
Epoch: [33][311/391]	LR: 0.00016	DT: 0.000 (1.728)	BT: 0.246 (2.040)	Loss 1.6260 (1.5184)	Prec@1 58.594 (58.283)	
Epoch: [33][389/391]	LR: 0.00016	DT: 0.223 (1.807)	BT: 0.470 (2.107)	Loss 1.4658 (1.5191)	Prec@1 55.469 (58.335)	
Total train loss: 1.5196
Avg Loading time: 1.8029 seconds
Avg Batch time: 2.1022 seconds

Train time: 822.0915060043335
 * Prec@1 55.110 Prec@5 84.010 Loss 1.6416
Avg Loading time: 2.0555 seconds
Avg Batch time: 2.3913 seconds

Best acc: 55.480
--------------------------------------------------------------------------------
Test time: 189.55844807624817

Epoch: [34][77/391]	LR: 0.00016	DT: 0.000 (1.752)	BT: 0.248 (2.052)	Loss 1.5146 (1.5231)	Prec@1 57.812 (57.652)	
Epoch: [34][155/391]	LR: 0.00016	DT: 0.000 (1.719)	BT: 0.248 (2.045)	Loss 1.6309 (1.5243)	Prec@1 55.469 (57.833)	
Epoch: [34][233/391]	LR: 0.00016	DT: 2.218 (1.469)	BT: 2.468 (1.769)	Loss 1.5967 (1.5231)	Prec@1 56.250 (58.136)	
Epoch: [34][311/391]	LR: 0.00016	DT: 0.000 (1.280)	BT: 0.248 (1.568)	Loss 1.4941 (1.5206)	Prec@1 66.406 (58.236)	
Epoch: [34][389/391]	LR: 0.00016	DT: 0.000 (1.166)	BT: 0.247 (1.446)	Loss 1.6826 (1.5192)	Prec@1 53.125 (58.327)	
Total train loss: 1.5192
Avg Loading time: 1.1630 seconds
Avg Batch time: 1.4423 seconds

Train time: 564.0739827156067
 * Prec@1 55.400 Prec@5 84.160 Loss 1.6387
Avg Loading time: 1.1127 seconds
Avg Batch time: 1.1918 seconds

Best acc: 55.480
--------------------------------------------------------------------------------
Test time: 94.80646467208862

Epoch: [35][77/391]	LR: 0.00016	DT: 0.000 (0.962)	BT: 0.248 (1.212)	Loss 1.4551 (1.5106)	Prec@1 60.938 (58.524)	
Epoch: [35][155/391]	LR: 0.00016	DT: 0.000 (0.975)	BT: 0.249 (1.224)	Loss 1.6162 (1.5139)	Prec@1 57.812 (58.604)	
Epoch: [35][233/391]	LR: 0.00016	DT: 0.000 (1.108)	BT: 0.251 (1.357)	Loss 1.2383 (1.5108)	Prec@1 65.625 (58.564)	
Epoch: [35][311/391]	LR: 0.00016	DT: 0.000 (1.196)	BT: 0.248 (1.458)	Loss 1.7842 (1.5132)	Prec@1 51.562 (58.481)	
Epoch: [35][389/391]	LR: 0.00016	DT: 0.000 (1.175)	BT: 0.247 (1.434)	Loss 1.6699 (1.5181)	Prec@1 50.000 (58.458)	
Total train loss: 1.5182
Avg Loading time: 1.1716 seconds
Avg Batch time: 1.4308 seconds

Train time: 559.5758447647095
 * Prec@1 55.080 Prec@5 84.150 Loss 1.6396
Avg Loading time: 1.2603 seconds
Avg Batch time: 1.3452 seconds

Best acc: 55.480
--------------------------------------------------------------------------------
Test time: 106.94021582603455

Epoch: [36][77/391]	LR: 0.00016	DT: 0.000 (1.074)	BT: 0.248 (1.324)	Loss 1.4824 (1.5245)	Prec@1 61.719 (58.413)	
Epoch: [36][155/391]	LR: 0.00016	DT: 0.000 (1.086)	BT: 0.248 (1.335)	Loss 1.4297 (1.5211)	Prec@1 65.625 (58.779)	
Epoch: [36][233/391]	LR: 0.00016	DT: 5.047 (1.090)	BT: 5.300 (1.339)	Loss 1.4238 (1.5207)	Prec@1 56.250 (58.677)	
Epoch: [36][311/391]	LR: 0.00016	DT: 0.000 (1.150)	BT: 0.249 (1.400)	Loss 1.4678 (1.5151)	Prec@1 64.062 (58.601)	
Epoch: [36][389/391]	LR: 0.00016	DT: 0.000 (1.215)	BT: 0.248 (1.465)	Loss 1.4941 (1.5172)	Prec@1 62.500 (58.480)	
Total train loss: 1.5174
Avg Loading time: 1.2123 seconds
Avg Batch time: 1.4615 seconds

Train time: 571.5708146095276
 * Prec@1 55.380 Prec@5 84.070 Loss 1.6416
Avg Loading time: 1.8717 seconds
Avg Batch time: 2.0494 seconds

Best acc: 55.480
--------------------------------------------------------------------------------
Test time: 162.54540467262268

Epoch: [37][77/391]	LR: 0.00016	DT: 0.000 (1.927)	BT: 0.249 (2.433)	Loss 1.6230 (1.5283)	Prec@1 57.031 (58.063)	
Epoch: [37][155/391]	LR: 0.00016	DT: 0.000 (2.082)	BT: 0.248 (2.664)	Loss 1.5234 (1.5222)	Prec@1 57.812 (58.363)	
Epoch: [37][233/391]	LR: 0.00016	DT: 0.000 (1.980)	BT: 0.249 (2.468)	Loss 1.6699 (1.5237)	Prec@1 50.781 (58.353)	
Epoch: [37][311/391]	LR: 0.00016	DT: 0.000 (1.938)	BT: 0.248 (2.367)	Loss 1.6318 (1.5218)	Prec@1 57.812 (58.466)	
Epoch: [37][389/391]	LR: 0.00016	DT: 0.000 (1.993)	BT: 0.247 (2.426)	Loss 1.5049 (1.5202)	Prec@1 53.906 (58.417)	
Total train loss: 1.5198
Avg Loading time: 1.9875 seconds
Avg Batch time: 2.4204 seconds

Train time: 946.5197384357452
 * Prec@1 55.350 Prec@5 84.040 Loss 1.6357
Avg Loading time: 2.5228 seconds
Avg Batch time: 3.0948 seconds

Best acc: 55.480
--------------------------------------------------------------------------------
Test time: 245.15846252441406

Epoch: [38][77/391]	LR: 0.00016	DT: 0.000 (2.262)	BT: 0.248 (2.870)	Loss 1.5918 (1.5247)	Prec@1 53.906 (58.534)	
Epoch: [38][155/391]	LR: 0.00016	DT: 0.000 (2.214)	BT: 0.247 (2.642)	Loss 1.5273 (1.5270)	Prec@1 63.281 (58.238)	
Epoch: [38][233/391]	LR: 0.00016	DT: 0.000 (2.140)	BT: 0.246 (2.579)	Loss 1.3369 (1.5210)	Prec@1 61.719 (58.387)	
Epoch: [38][311/391]	LR: 0.00016	DT: 0.000 (2.074)	BT: 0.246 (2.517)	Loss 1.3008 (1.5226)	Prec@1 64.844 (58.216)	
Epoch: [38][389/391]	LR: 0.00016	DT: 0.000 (1.980)	BT: 0.245 (2.424)	Loss 1.4395 (1.5199)	Prec@1 64.844 (58.169)	
Total train loss: 1.5200
Avg Loading time: 1.9746 seconds
Avg Batch time: 2.4187 seconds

Train time: 945.828697681427
 * Prec@1 55.610 Prec@5 84.030 Loss 1.6348
Avg Loading time: 2.0773 seconds
Avg Batch time: 2.4643 seconds

Best acc: 55.610
--------------------------------------------------------------------------------
Test time: 195.7751326560974

Epoch: [39][77/391]	LR: 0.00016	DT: 0.000 (2.120)	BT: 0.248 (2.524)	Loss 1.4863 (1.5250)	Prec@1 57.812 (57.833)	
Epoch: [39][155/391]	LR: 0.00016	DT: 0.000 (2.100)	BT: 0.250 (2.452)	Loss 1.5039 (1.5184)	Prec@1 60.938 (58.544)	
Epoch: [39][233/391]	LR: 0.00016	DT: 17.607 (2.052)	BT: 21.858 (2.455)	Loss 1.7734 (1.5157)	Prec@1 50.781 (58.417)	
Epoch: [39][311/391]	LR: 0.00016	DT: 0.000 (1.954)	BT: 0.248 (2.356)	Loss 1.6543 (1.5175)	Prec@1 57.812 (58.268)	
Epoch: [39][389/391]	LR: 0.00016	DT: 0.000 (1.792)	BT: 0.248 (2.164)	Loss 1.5918 (1.5205)	Prec@1 54.688 (58.273)	
Total train loss: 1.5208
Avg Loading time: 1.7872 seconds
Avg Batch time: 2.1585 seconds

Train time: 844.1170909404755
 * Prec@1 55.310 Prec@5 84.040 Loss 1.6396
Avg Loading time: 1.1419 seconds
Avg Batch time: 1.2252 seconds

Best acc: 55.610
--------------------------------------------------------------------------------
Test time: 97.45357871055603

Epoch: [40][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.153)	BT: 0.249 (1.402)	Loss 1.2393 (1.5217)	Prec@1 65.625 (58.704)	
Epoch: [40][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.114)	BT: 0.249 (1.363)	Loss 1.5312 (1.5038)	Prec@1 59.375 (58.824)	
Epoch: [40][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.117)	BT: 0.248 (1.366)	Loss 1.6719 (1.5135)	Prec@1 53.906 (58.387)	
Epoch: [40][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.164)	BT: 0.249 (1.413)	Loss 1.3350 (1.5143)	Prec@1 64.062 (58.363)	
Epoch: [40][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.265)	BT: 0.248 (1.535)	Loss 1.4990 (1.5195)	Prec@1 60.938 (58.239)	
Total train loss: 1.5195
Avg Loading time: 1.2621 seconds
Avg Batch time: 1.5315 seconds

Train time: 598.9543373584747
 * Prec@1 55.210 Prec@5 84.230 Loss 1.6396
Avg Loading time: 1.5855 seconds
Avg Batch time: 1.6745 seconds

Best acc: 55.610
--------------------------------------------------------------------------------
Test time: 132.94306230545044

Epoch: [41][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.659)	BT: 0.248 (1.909)	Loss 1.4531 (1.5192)	Prec@1 64.062 (58.233)	
Epoch: [41][155/391]	LR: 3.2000000000000005e-05	DT: 1.052 (1.626)	BT: 1.304 (1.875)	Loss 1.6523 (1.5222)	Prec@1 53.125 (58.243)	
Epoch: [41][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.604)	BT: 0.248 (1.853)	Loss 1.5459 (1.5196)	Prec@1 55.469 (58.257)	
Epoch: [41][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.829)	BT: 0.248 (2.117)	Loss 1.4727 (1.5181)	Prec@1 60.156 (58.273)	
Epoch: [41][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (1.995)	BT: 0.247 (2.275)	Loss 1.4102 (1.5166)	Prec@1 60.156 (58.375)	
Total train loss: 1.5167
Avg Loading time: 1.9902 seconds
Avg Batch time: 2.2699 seconds

Train time: 887.6832194328308
 * Prec@1 55.320 Prec@5 84.070 Loss 1.6338
Avg Loading time: 2.4035 seconds
Avg Batch time: 2.9483 seconds

Best acc: 55.610
--------------------------------------------------------------------------------
Test time: 233.5748951435089

Epoch: [42][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.317)	BT: 0.247 (3.078)	Loss 1.5986 (1.5179)	Prec@1 57.031 (58.283)	
Epoch: [42][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.234)	BT: 0.248 (2.969)	Loss 1.5918 (1.5117)	Prec@1 51.562 (58.514)	
Epoch: [42][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.884)	BT: 0.248 (3.629)	Loss 1.5215 (1.5250)	Prec@1 65.625 (58.143)	
Epoch: [42][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.111)	BT: 0.248 (3.847)	Loss 1.5732 (1.5242)	Prec@1 53.125 (58.186)	
Epoch: [42][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.276)	BT: 0.247 (4.018)	Loss 1.6348 (1.5195)	Prec@1 57.812 (58.247)	
Total train loss: 1.5196
Avg Loading time: 3.2681 seconds
Avg Batch time: 4.0079 seconds

Train time: 1567.2165341377258
 * Prec@1 55.410 Prec@5 84.050 Loss 1.6348
Avg Loading time: 4.1745 seconds
Avg Batch time: 4.7700 seconds

Best acc: 55.610
--------------------------------------------------------------------------------
Test time: 377.5075249671936

Epoch: [43][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.463)	BT: 0.247 (5.225)	Loss 1.5273 (1.5162)	Prec@1 53.906 (58.183)	
Epoch: [43][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.380)	BT: 0.252 (5.141)	Loss 1.5469 (1.5144)	Prec@1 59.375 (58.729)	
Epoch: [43][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.340)	BT: 0.247 (5.101)	Loss 1.4238 (1.5149)	Prec@1 63.281 (58.654)	
Epoch: [43][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.274)	BT: 0.248 (5.022)	Loss 1.6113 (1.5210)	Prec@1 52.344 (58.336)	
Epoch: [43][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.281)	BT: 0.249 (5.032)	Loss 1.4062 (1.5185)	Prec@1 59.375 (58.297)	
Total train loss: 1.5184
Avg Loading time: 4.2700 seconds
Avg Batch time: 5.0192 seconds

Train time: 1962.6458086967468
 * Prec@1 55.350 Prec@5 84.040 Loss 1.6416
Avg Loading time: 4.5286 seconds
Avg Batch time: 5.1240 seconds

Best acc: 55.610
--------------------------------------------------------------------------------
Test time: 405.4975793361664

Epoch: [44][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.824)	BT: 0.247 (5.584)	Loss 1.4814 (1.5204)	Prec@1 61.719 (58.454)	
Epoch: [44][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.575)	BT: 0.246 (5.335)	Loss 1.6553 (1.5194)	Prec@1 58.594 (58.233)	
Epoch: [44][233/391]	LR: 3.2000000000000005e-05	DT: 1.225 (4.338)	BT: 1.473 (5.098)	Loss 1.7119 (1.5210)	Prec@1 59.375 (58.263)	
Epoch: [44][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.997)	BT: 0.246 (4.744)	Loss 1.3477 (1.5097)	Prec@1 62.500 (58.591)	
Epoch: [44][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.760)	BT: 0.245 (4.500)	Loss 1.4961 (1.5163)	Prec@1 60.938 (58.520)	
Total train loss: 1.5167
Avg Loading time: 3.7504 seconds
Avg Batch time: 4.4886 seconds

Train time: 1755.1814012527466
 * Prec@1 55.060 Prec@5 84.110 Loss 1.6396
Avg Loading time: 3.1664 seconds
Avg Batch time: 3.7606 seconds

Best acc: 55.610
--------------------------------------------------------------------------------
Test time: 297.7398672103882

Epoch: [45][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.978)	BT: 0.247 (3.637)	Loss 1.4756 (1.5098)	Prec@1 57.812 (58.784)	
Epoch: [45][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.986)	BT: 0.249 (3.697)	Loss 1.4238 (1.5271)	Prec@1 62.500 (58.373)	
Epoch: [45][233/391]	LR: 3.2000000000000005e-05	DT: 2.636 (3.015)	BT: 2.887 (3.742)	Loss 1.6650 (1.5196)	Prec@1 53.906 (58.664)	
Epoch: [45][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.005)	BT: 0.249 (3.728)	Loss 1.5156 (1.5227)	Prec@1 57.812 (58.514)	
Epoch: [45][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (3.073)	BT: 0.246 (3.804)	Loss 1.6133 (1.5211)	Prec@1 59.375 (58.492)	
Total train loss: 1.5207
Avg Loading time: 3.0653 seconds
Avg Batch time: 3.7949 seconds

Train time: 1483.9231297969818
 * Prec@1 55.130 Prec@5 83.920 Loss 1.6445
Avg Loading time: 4.0716 seconds
Avg Batch time: 4.6569 seconds

Best acc: 55.610
--------------------------------------------------------------------------------
Test time: 368.56309962272644

Epoch: [46][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.080)	BT: 0.247 (4.840)	Loss 1.5576 (1.5087)	Prec@1 55.469 (58.604)	
Epoch: [46][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.112)	BT: 0.246 (4.872)	Loss 1.4844 (1.5123)	Prec@1 59.375 (58.439)	
Epoch: [46][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.136)	BT: 0.246 (4.896)	Loss 1.5049 (1.5128)	Prec@1 55.469 (58.280)	
Epoch: [46][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.020)	BT: 0.246 (4.766)	Loss 1.4658 (1.5134)	Prec@1 60.156 (58.411)	
Epoch: [46][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.025)	BT: 0.245 (4.774)	Loss 1.4033 (1.5205)	Prec@1 62.500 (58.287)	
Total train loss: 1.5205
Avg Loading time: 4.0147 seconds
Avg Batch time: 4.7624 seconds

Train time: 1862.2312154769897
 * Prec@1 55.350 Prec@5 83.970 Loss 1.6416
Avg Loading time: 4.3550 seconds
Avg Batch time: 4.9354 seconds

Best acc: 55.610
--------------------------------------------------------------------------------
Test time: 390.5557038784027

Epoch: [47][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.468)	BT: 0.247 (5.231)	Loss 1.5283 (1.5130)	Prec@1 59.375 (58.373)	
Epoch: [47][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.412)	BT: 0.247 (5.174)	Loss 1.6113 (1.5118)	Prec@1 57.031 (58.689)	
Epoch: [47][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.366)	BT: 0.249 (5.128)	Loss 1.5283 (1.5224)	Prec@1 64.844 (58.403)	
Epoch: [47][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.253)	BT: 0.249 (5.001)	Loss 1.3047 (1.5160)	Prec@1 63.281 (58.491)	
Epoch: [47][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.221)	BT: 0.248 (4.973)	Loss 1.4473 (1.5169)	Prec@1 61.719 (58.460)	
Total train loss: 1.5169
Avg Loading time: 4.2107 seconds
Avg Batch time: 4.9603 seconds

Train time: 1939.6284265518188
 * Prec@1 55.450 Prec@5 84.110 Loss 1.6377
Avg Loading time: 4.2957 seconds
Avg Batch time: 4.8910 seconds

Best acc: 55.610
--------------------------------------------------------------------------------
Test time: 387.043119430542

Epoch: [48][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.348)	BT: 0.246 (5.109)	Loss 1.7520 (1.5184)	Prec@1 50.000 (58.053)	
Epoch: [48][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.253)	BT: 0.246 (5.014)	Loss 1.5283 (1.5247)	Prec@1 55.469 (57.923)	
Epoch: [48][233/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.341)	BT: 0.246 (5.101)	Loss 1.6533 (1.5261)	Prec@1 52.344 (58.009)	
Epoch: [48][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.265)	BT: 0.247 (5.013)	Loss 1.4600 (1.5173)	Prec@1 64.844 (58.216)	
Epoch: [48][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (4.156)	BT: 0.245 (4.895)	Loss 1.5049 (1.5185)	Prec@1 59.375 (58.247)	
Total train loss: 1.5183
Avg Loading time: 4.1449 seconds
Avg Batch time: 4.8832 seconds

Train time: 1909.4891774654388
 * Prec@1 55.280 Prec@5 84.010 Loss 1.6416
Avg Loading time: 2.6424 seconds
Avg Batch time: 3.2623 seconds

Best acc: 55.610
--------------------------------------------------------------------------------
Test time: 258.38431549072266

Epoch: [49][77/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.387)	BT: 0.246 (2.994)	Loss 1.4707 (1.4914)	Prec@1 58.594 (59.125)	
Epoch: [49][155/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.349)	BT: 0.248 (2.778)	Loss 1.6787 (1.5115)	Prec@1 52.344 (58.559)	
Epoch: [49][233/391]	LR: 3.2000000000000005e-05	DT: 15.967 (2.171)	BT: 20.223 (2.557)	Loss 1.8291 (1.5209)	Prec@1 50.000 (58.166)	
Epoch: [49][311/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.291)	BT: 0.248 (2.759)	Loss 1.6035 (1.5162)	Prec@1 53.125 (58.351)	
Epoch: [49][389/391]	LR: 3.2000000000000005e-05	DT: 0.000 (2.371)	BT: 0.245 (2.887)	Loss 1.5547 (1.5181)	Prec@1 52.344 (58.305)	
Total train loss: 1.5183
Avg Loading time: 2.3648 seconds
Avg Batch time: 2.8797 seconds

Train time: 1126.1045589447021
 * Prec@1 55.350 Prec@5 84.080 Loss 1.6367
Avg Loading time: 3.0932 seconds
Avg Batch time: 3.6892 seconds

Best acc: 55.610
--------------------------------------------------------------------------------
Test time: 292.0957808494568

