
      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 0
          frozen_layers: 11
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 0
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/train/relu11
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/test/relu11
ResNet18(
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 9.320 Prec@5 52.010 Loss 2.2969
Avg Loading time: 0.0866 seconds
Avg Batch time: 0.1094 seconds

Pre-trained Prec@1 with 11 layers frozen: 9.319999694824219 	 Loss: 2.296875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.136 (0.954)	BT: 0.156 (0.981)	Loss 0.4478 (0.6675)	Prec@1 84.375 (78.876)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (1.408)	BT: 0.026 (1.435)	Loss 0.4441 (0.5470)	Prec@1 88.281 (82.317)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (1.804)	BT: 0.028 (1.831)	Loss 0.2539 (0.4920)	Prec@1 90.625 (83.861)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (1.856)	BT: 0.026 (1.883)	Loss 0.3821 (0.4560)	Prec@1 85.938 (84.876)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (1.834)	BT: 0.026 (1.861)	Loss 0.2993 (0.4292)	Prec@1 89.844 (85.695)	
Total train loss: 0.4291
Avg Loading time: 1.8291 seconds
Avg Batch time: 1.8564 seconds

Train time: 725.9644598960876
 * Prec@1 87.880 Prec@5 99.620 Loss 0.3655
Avg Loading time: 0.7455 seconds
Avg Batch time: 0.7557 seconds

Best acc: 87.880
--------------------------------------------------------------------------------
Test time: 60.75865173339844

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.718)	BT: 0.025 (0.744)	Loss 0.1892 (0.2019)	Prec@1 92.969 (93.470)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.687)	BT: 0.026 (0.714)	Loss 0.1953 (0.2053)	Prec@1 92.969 (93.174)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.721 (0.558)	BT: 0.752 (0.585)	Loss 0.1917 (0.2121)	Prec@1 93.750 (92.969)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.475)	BT: 0.021 (0.501)	Loss 0.2252 (0.2163)	Prec@1 92.188 (92.778)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.436)	BT: 0.026 (0.463)	Loss 0.2106 (0.2184)	Prec@1 92.188 (92.682)	
Total train loss: 0.2184
Avg Loading time: 0.4351 seconds
Avg Batch time: 0.4618 seconds

Train time: 180.70607829093933
 * Prec@1 89.840 Prec@5 99.750 Loss 0.3081
Avg Loading time: 0.2721 seconds
Avg Batch time: 0.2820 seconds

Best acc: 89.840
--------------------------------------------------------------------------------
Test time: 23.423861265182495

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.229)	BT: 0.021 (0.255)	Loss 0.0833 (0.1174)	Prec@1 96.875 (96.364)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.149)	BT: 0.021 (0.174)	Loss 0.1508 (0.1272)	Prec@1 96.094 (95.878)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (0.106)	BT: 0.035 (0.132)	Loss 0.0739 (0.1346)	Prec@1 96.875 (95.503)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.001 (0.081)	BT: 0.051 (0.109)	Loss 0.1973 (0.1388)	Prec@1 92.188 (95.380)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.068)	BT: 0.022 (0.096)	Loss 0.1539 (0.1406)	Prec@1 94.531 (95.284)	
Total train loss: 0.1406
Avg Loading time: 0.0679 seconds
Avg Batch time: 0.0957 seconds

Train time: 37.65991473197937
 * Prec@1 89.160 Prec@5 99.760 Loss 0.3364
Avg Loading time: 0.0379 seconds
Avg Batch time: 0.0502 seconds

Best acc: 89.840
--------------------------------------------------------------------------------
Test time: 4.630096912384033

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.015)	BT: 0.027 (0.045)	Loss 0.0397 (0.0780)	Prec@1 99.219 (97.556)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.015)	BT: 0.057 (0.046)	Loss 0.0825 (0.0802)	Prec@1 97.656 (97.376)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.012)	BT: 0.022 (0.044)	Loss 0.0530 (0.0861)	Prec@1 98.438 (97.129)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.044 (0.046)	Loss 0.1713 (0.0910)	Prec@1 92.969 (96.955)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.043 (0.047)	Loss 0.1196 (0.0941)	Prec@1 96.094 (96.829)	
Total train loss: 0.0943
Avg Loading time: 0.0137 seconds
Avg Batch time: 0.0466 seconds

Train time: 18.426156282424927
 * Prec@1 90.240 Prec@5 99.550 Loss 0.3245
Avg Loading time: 0.0470 seconds
Avg Batch time: 0.0618 seconds

Best acc: 90.240
--------------------------------------------------------------------------------
Test time: 5.962046146392822

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.020)	BT: 0.037 (0.057)	Loss 0.0968 (0.0679)	Prec@1 96.875 (97.867)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.020)	BT: 0.047 (0.056)	Loss 0.0757 (0.0656)	Prec@1 96.875 (97.832)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.009 (0.019)	BT: 0.044 (0.053)	Loss 0.0259 (0.0689)	Prec@1 100.000 (97.803)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.019)	BT: 0.036 (0.053)	Loss 0.0832 (0.0746)	Prec@1 98.438 (97.614)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.018)	BT: 0.020 (0.052)	Loss 0.0713 (0.0787)	Prec@1 96.875 (97.438)	
Total train loss: 0.0788
Avg Loading time: 0.0180 seconds
Avg Batch time: 0.0514 seconds

Train time: 20.304015398025513
 * Prec@1 91.290 Prec@5 99.710 Loss 0.2859
Avg Loading time: 0.0377 seconds
Avg Batch time: 0.0513 seconds

Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 5.09876275062561

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.029)	BT: 0.033 (0.062)	Loss 0.0690 (0.0535)	Prec@1 98.438 (98.367)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.021)	BT: 0.036 (0.056)	Loss 0.0760 (0.0546)	Prec@1 96.094 (98.267)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.000 (0.019)	BT: 0.044 (0.053)	Loss 0.1376 (0.0569)	Prec@1 94.531 (98.130)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.015)	BT: 0.034 (0.049)	Loss 0.1025 (0.0614)	Prec@1 96.875 (97.969)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.013)	BT: 0.021 (0.047)	Loss 0.0872 (0.0636)	Prec@1 95.312 (97.871)	
Total train loss: 0.0636
Avg Loading time: 0.0133 seconds
Avg Batch time: 0.0464 seconds

Train time: 18.325299501419067
 * Prec@1 90.310 Prec@5 99.500 Loss 0.3347
Avg Loading time: 0.0445 seconds
Avg Batch time: 0.0566 seconds

Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 5.108529806137085

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.019)	BT: 0.029 (0.050)	Loss 0.0205 (0.0479)	Prec@1 99.219 (98.417)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.012)	BT: 0.063 (0.044)	Loss 0.0200 (0.0459)	Prec@1 99.219 (98.533)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.012)	BT: 0.023 (0.044)	Loss 0.0246 (0.0459)	Prec@1 100.000 (98.551)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.050 (0.045)	Loss 0.0984 (0.0483)	Prec@1 96.094 (98.443)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.023 (0.046)	Loss 0.0470 (0.0524)	Prec@1 97.656 (98.283)	
Total train loss: 0.0526
Avg Loading time: 0.0139 seconds
Avg Batch time: 0.0458 seconds

Train time: 18.09134840965271
 * Prec@1 89.600 Prec@5 99.600 Loss 0.3545
Avg Loading time: 0.0377 seconds
Avg Batch time: 0.0514 seconds

Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 4.7300848960876465

Epoch: [7][77/391]	LR: 0.1	DT: 0.067 (0.033)	BT: 0.089 (0.066)	Loss 0.0374 (0.0388)	Prec@1 98.438 (98.848)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.027)	BT: 0.033 (0.059)	Loss 0.0168 (0.0371)	Prec@1 100.000 (98.863)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.027 (0.053)	Loss 0.0829 (0.0396)	Prec@1 95.312 (98.761)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.021)	BT: 0.022 (0.053)	Loss 0.0257 (0.0401)	Prec@1 99.219 (98.743)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.020)	BT: 0.023 (0.051)	Loss 0.0164 (0.0417)	Prec@1 100.000 (98.658)	
Total train loss: 0.0417
Avg Loading time: 0.0199 seconds
Avg Batch time: 0.0509 seconds

Train time: 20.104838848114014
 * Prec@1 91.060 Prec@5 99.790 Loss 0.3086
Avg Loading time: 0.0468 seconds
Avg Batch time: 0.0582 seconds

Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 5.301919937133789

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.035 (0.061)	Loss 0.0363 (0.0271)	Prec@1 99.219 (99.209)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.019)	BT: 0.031 (0.053)	Loss 0.0494 (0.0277)	Prec@1 97.656 (99.189)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.174 (0.017)	BT: 0.204 (0.050)	Loss 0.0170 (0.0283)	Prec@1 99.219 (99.159)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.015)	BT: 0.032 (0.049)	Loss 0.0417 (0.0295)	Prec@1 98.438 (99.109)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.020 (0.046)	Loss 0.0187 (0.0325)	Prec@1 100.000 (99.032)	
Total train loss: 0.0326
Avg Loading time: 0.0136 seconds
Avg Batch time: 0.0463 seconds

Train time: 18.230565071105957
 * Prec@1 90.150 Prec@5 99.720 Loss 0.3394
Avg Loading time: 0.0344 seconds
Avg Batch time: 0.0459 seconds

Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 4.32943868637085

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.029)	BT: 0.027 (0.060)	Loss 0.0313 (0.0220)	Prec@1 98.438 (99.399)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.018)	BT: 0.030 (0.048)	Loss 0.0140 (0.0220)	Prec@1 100.000 (99.394)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.013)	BT: 0.033 (0.043)	Loss 0.0228 (0.0232)	Prec@1 100.000 (99.366)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.015)	BT: 0.021 (0.046)	Loss 0.0131 (0.0230)	Prec@1 100.000 (99.387)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.015)	BT: 0.022 (0.046)	Loss 0.0179 (0.0244)	Prec@1 100.000 (99.331)	
Total train loss: 0.0244
Avg Loading time: 0.0152 seconds
Avg Batch time: 0.0462 seconds

Train time: 18.25076985359192
 * Prec@1 90.760 Prec@5 99.690 Loss 0.3330
Avg Loading time: 0.0434 seconds
Avg Batch time: 0.0567 seconds

Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 5.15553617477417

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.031)	BT: 0.026 (0.063)	Loss 0.0059 (0.0166)	Prec@1 100.000 (99.589)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.047 (0.058)	Loss 0.0084 (0.0128)	Prec@1 100.000 (99.700)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.062 (0.021)	BT: 0.091 (0.054)	Loss 0.0052 (0.0109)	Prec@1 100.000 (99.763)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.019)	BT: 0.024 (0.052)	Loss 0.0026 (0.0104)	Prec@1 100.000 (99.772)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.020 (0.051)	Loss 0.0184 (0.0095)	Prec@1 99.219 (99.800)	
Total train loss: 0.0095
Avg Loading time: 0.0180 seconds
Avg Batch time: 0.0505 seconds

Train time: 19.94502329826355
 * Prec@1 93.270 Prec@5 99.780 Loss 0.2312
Avg Loading time: 0.0455 seconds
Avg Batch time: 0.0579 seconds

Best acc: 93.270
--------------------------------------------------------------------------------
Test time: 5.702784776687622

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.033)	BT: 0.034 (0.065)	Loss 0.0028 (0.0042)	Prec@1 100.000 (99.970)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.024)	BT: 0.028 (0.056)	Loss 0.0030 (0.0044)	Prec@1 100.000 (99.965)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.021)	BT: 0.021 (0.053)	Loss 0.0071 (0.0042)	Prec@1 100.000 (99.970)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.034 (0.051)	Loss 0.0056 (0.0042)	Prec@1 100.000 (99.960)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.032 (0.050)	Loss 0.0037 (0.0041)	Prec@1 100.000 (99.966)	
Total train loss: 0.0041
Avg Loading time: 0.0179 seconds
Avg Batch time: 0.0500 seconds

Train time: 19.742112398147583
 * Prec@1 93.420 Prec@5 99.730 Loss 0.2318
Avg Loading time: 0.0343 seconds
Avg Batch time: 0.0457 seconds

Best acc: 93.420
--------------------------------------------------------------------------------
Test time: 4.736029386520386

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.024)	BT: 0.047 (0.057)	Loss 0.0060 (0.0032)	Prec@1 100.000 (99.980)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.017)	BT: 0.031 (0.051)	Loss 0.0033 (0.0032)	Prec@1 100.000 (99.980)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.007 (0.013)	BT: 0.032 (0.045)	Loss 0.0026 (0.0032)	Prec@1 100.000 (99.980)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.039 (0.044)	Loss 0.0047 (0.0032)	Prec@1 100.000 (99.985)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.021 (0.045)	Loss 0.0022 (0.0032)	Prec@1 100.000 (99.986)	
Total train loss: 0.0032
Avg Loading time: 0.0143 seconds
Avg Batch time: 0.0454 seconds

Train time: 17.946949243545532
 * Prec@1 93.490 Prec@5 99.750 Loss 0.2322
Avg Loading time: 0.0527 seconds
Avg Batch time: 0.0641 seconds

Best acc: 93.490
--------------------------------------------------------------------------------
Test time: 6.170900344848633

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.027)	BT: 0.042 (0.060)	Loss 0.0011 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.021)	BT: 0.034 (0.055)	Loss 0.0017 (0.0025)	Prec@1 100.000 (99.995)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.020)	BT: 0.024 (0.053)	Loss 0.0013 (0.0026)	Prec@1 100.000 (99.990)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.040 (0.051)	Loss 0.0016 (0.0027)	Prec@1 100.000 (99.990)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.017)	BT: 0.024 (0.051)	Loss 0.0026 (0.0027)	Prec@1 100.000 (99.992)	
Total train loss: 0.0027
Avg Loading time: 0.0169 seconds
Avg Batch time: 0.0505 seconds

Train time: 19.948476552963257
 * Prec@1 93.430 Prec@5 99.690 Loss 0.2324
Avg Loading time: 0.0379 seconds
Avg Batch time: 0.0507 seconds

Best acc: 93.490
--------------------------------------------------------------------------------
Test time: 4.708863019943237

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.029)	BT: 0.029 (0.062)	Loss 0.0033 (0.0025)	Prec@1 100.000 (100.000)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.022 (0.056)	Loss 0.0021 (0.0026)	Prec@1 100.000 (99.980)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.032 (0.054)	Loss 0.0035 (0.0026)	Prec@1 100.000 (99.983)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.128 (0.022)	BT: 0.150 (0.054)	Loss 0.0020 (0.0026)	Prec@1 100.000 (99.987)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.020)	BT: 0.021 (0.052)	Loss 0.0027 (0.0026)	Prec@1 100.000 (99.988)	
Total train loss: 0.0026
Avg Loading time: 0.0199 seconds
Avg Batch time: 0.0520 seconds

Train time: 20.531089067459106
 * Prec@1 93.510 Prec@5 99.690 Loss 0.2292
Avg Loading time: 0.0361 seconds
Avg Batch time: 0.0454 seconds

Best acc: 93.510
--------------------------------------------------------------------------------
Test time: 4.608974933624268

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.026)	BT: 0.028 (0.060)	Loss 0.0070 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.019)	BT: 0.035 (0.053)	Loss 0.0008 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.022 (0.046)	Loss 0.0038 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.024 (0.012)	BT: 0.056 (0.044)	Loss 0.0019 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.024 (0.044)	Loss 0.0020 (0.0022)	Prec@1 100.000 (100.000)	
Total train loss: 0.0022
Avg Loading time: 0.0126 seconds
Avg Batch time: 0.0442 seconds

Train time: 17.462400436401367
 * Prec@1 93.620 Prec@5 99.730 Loss 0.2286
Avg Loading time: 0.0440 seconds
Avg Batch time: 0.0571 seconds

Best acc: 93.620
--------------------------------------------------------------------------------
Test time: 5.634835243225098

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.034)	BT: 0.039 (0.066)	Loss 0.0010 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.024 (0.055)	Loss 0.0016 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.020)	BT: 0.042 (0.053)	Loss 0.0017 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.019)	BT: 0.041 (0.052)	Loss 0.0033 (0.0023)	Prec@1 100.000 (99.987)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.022 (0.052)	Loss 0.0017 (0.0023)	Prec@1 100.000 (99.988)	
Total train loss: 0.0023
Avg Loading time: 0.0183 seconds
Avg Batch time: 0.0515 seconds

Train time: 20.394059658050537
 * Prec@1 93.640 Prec@5 99.730 Loss 0.2290
Avg Loading time: 0.0459 seconds
Avg Batch time: 0.0580 seconds

Best acc: 93.640
--------------------------------------------------------------------------------
Test time: 5.714041709899902

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.029)	BT: 0.033 (0.062)	Loss 0.0012 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.023)	BT: 0.046 (0.055)	Loss 0.0091 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.020)	BT: 0.055 (0.052)	Loss 0.0012 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.023 (0.050)	Loss 0.0019 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.023 (0.050)	Loss 0.0030 (0.0022)	Prec@1 100.000 (99.996)	
Total train loss: 0.0022
Avg Loading time: 0.0181 seconds
Avg Batch time: 0.0501 seconds

Train time: 19.80530047416687
 * Prec@1 93.590 Prec@5 99.710 Loss 0.2300
Avg Loading time: 0.0346 seconds
Avg Batch time: 0.0437 seconds

Best acc: 93.640
--------------------------------------------------------------------------------
Test time: 4.061338424682617

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.032)	BT: 0.032 (0.065)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.021)	BT: 0.021 (0.053)	Loss 0.0039 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.016)	BT: 0.027 (0.049)	Loss 0.0008 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.039 (0.045)	Loss 0.0014 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.026 (0.045)	Loss 0.0037 (0.0021)	Prec@1 100.000 (100.000)	
Total train loss: 0.0021
Avg Loading time: 0.0133 seconds
Avg Batch time: 0.0447 seconds

Train time: 17.674538135528564
 * Prec@1 93.710 Prec@5 99.720 Loss 0.2284
Avg Loading time: 0.0380 seconds
Avg Batch time: 0.0525 seconds

Best acc: 93.710
--------------------------------------------------------------------------------
Test time: 5.219633102416992

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.024)	BT: 0.045 (0.059)	Loss 0.0016 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.019)	BT: 0.032 (0.052)	Loss 0.0008 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.017)	BT: 0.027 (0.049)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.001 (0.017)	BT: 0.031 (0.049)	Loss 0.0027 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.016)	BT: 0.022 (0.048)	Loss 0.0014 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0164 seconds
Avg Batch time: 0.0478 seconds

Train time: 18.882784605026245
 * Prec@1 93.660 Prec@5 99.740 Loss 0.2292
Avg Loading time: 0.0451 seconds
Avg Batch time: 0.0572 seconds

Best acc: 93.710
--------------------------------------------------------------------------------
Test time: 5.237161636352539

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.044 (0.061)	Loss 0.0014 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.089 (0.019)	BT: 0.114 (0.052)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.985)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.019)	BT: 0.021 (0.052)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.019)	BT: 0.025 (0.051)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.992)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.018)	BT: 0.028 (0.050)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.994)	
Total train loss: 0.0019
Avg Loading time: 0.0180 seconds
Avg Batch time: 0.0495 seconds

Train time: 19.575388193130493
 * Prec@1 93.720 Prec@5 99.710 Loss 0.2284
Avg Loading time: 0.0360 seconds
Avg Batch time: 0.0499 seconds

Best acc: 93.720
--------------------------------------------------------------------------------
Test time: 5.788315773010254

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.018)	BT: 0.032 (0.050)	Loss 0.0011 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.033 (0.046)	Loss 0.0005 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.016)	BT: 0.029 (0.046)	Loss 0.0007 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.013)	BT: 0.027 (0.043)	Loss 0.0020 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.019 (0.012)	BT: 0.041 (0.042)	Loss 0.0007 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0120 seconds
Avg Batch time: 0.0420 seconds

Train time: 16.606055974960327
 * Prec@1 93.590 Prec@5 99.720 Loss 0.2286
Avg Loading time: 0.0444 seconds
Avg Batch time: 0.0576 seconds

Best acc: 93.720
--------------------------------------------------------------------------------
Test time: 5.185189485549927

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.009 (0.033)	BT: 0.038 (0.063)	Loss 0.0019 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.046 (0.054)	Loss 0.0217 (0.0021)	Prec@1 99.219 (99.995)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.021)	BT: 0.035 (0.052)	Loss 0.0044 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.020)	BT: 0.040 (0.051)	Loss 0.0042 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.019)	BT: 0.022 (0.051)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0192 seconds
Avg Batch time: 0.0506 seconds

Train time: 19.99305248260498
 * Prec@1 93.700 Prec@5 99.720 Loss 0.2284
Avg Loading time: 0.0431 seconds
Avg Batch time: 0.0554 seconds

Best acc: 93.720
--------------------------------------------------------------------------------
Test time: 5.0701892375946045

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.032)	BT: 0.024 (0.062)	Loss 0.0024 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.020)	BT: 0.040 (0.051)	Loss 0.0014 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.166 (0.019)	BT: 0.192 (0.050)	Loss 0.0033 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.017)	BT: 0.049 (0.048)	Loss 0.0010 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.016)	BT: 0.021 (0.048)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0163 seconds
Avg Batch time: 0.0477 seconds

Train time: 18.857699394226074
 * Prec@1 93.680 Prec@5 99.730 Loss 0.2280
Avg Loading time: 0.0392 seconds
Avg Batch time: 0.0504 seconds

Best acc: 93.720
--------------------------------------------------------------------------------
Test time: 4.660299777984619

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.027 (0.048)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.084 (0.013)	BT: 0.104 (0.045)	Loss 0.0021 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.014)	BT: 0.034 (0.046)	Loss 0.0047 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.014)	BT: 0.025 (0.046)	Loss 0.0021 (0.0017)	Prec@1 100.000 (99.997)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.012)	BT: 0.020 (0.044)	Loss 0.0011 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0124 seconds
Avg Batch time: 0.0434 seconds

Train time: 17.126577138900757
 * Prec@1 93.590 Prec@5 99.710 Loss 0.2300
Avg Loading time: 0.0358 seconds
Avg Batch time: 0.0491 seconds

Best acc: 93.720
--------------------------------------------------------------------------------
Test time: 4.587012529373169

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.154 (0.025)	BT: 0.174 (0.057)	Loss 0.0011 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.020)	BT: 0.048 (0.052)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.020)	BT: 0.023 (0.052)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.020)	BT: 0.042 (0.051)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.018)	BT: 0.021 (0.050)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0184 seconds
Avg Batch time: 0.0497 seconds

Train time: 19.647021770477295
 * Prec@1 93.720 Prec@5 99.740 Loss 0.2281
Avg Loading time: 0.0381 seconds
Avg Batch time: 0.0507 seconds

Best acc: 93.720
--------------------------------------------------------------------------------
Test time: 4.673536062240601

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.073 (0.027)	BT: 0.111 (0.059)	Loss 0.0016 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.025 (0.056)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.019)	BT: 0.034 (0.052)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.016 (0.018)	BT: 0.039 (0.051)	Loss 0.0007 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.019)	BT: 0.028 (0.051)	Loss 0.0010 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0185 seconds
Avg Batch time: 0.0509 seconds

Train time: 20.090009450912476
 * Prec@1 93.620 Prec@5 99.710 Loss 0.2292
Avg Loading time: 0.0388 seconds
Avg Batch time: 0.0515 seconds

Best acc: 93.720
--------------------------------------------------------------------------------
Test time: 4.7457804679870605

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.025)	BT: 0.035 (0.061)	Loss 0.0027 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.018)	BT: 0.030 (0.051)	Loss 0.0010 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.013)	BT: 0.031 (0.046)	Loss 0.0031 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.090 (0.015)	BT: 0.118 (0.047)	Loss 0.0022 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.016)	BT: 0.020 (0.048)	Loss 0.0006 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0160 seconds
Avg Batch time: 0.0480 seconds

Train time: 18.959378480911255
 * Prec@1 93.550 Prec@5 99.720 Loss 0.2303
Avg Loading time: 0.0306 seconds
Avg Batch time: 0.0423 seconds

Best acc: 93.720
--------------------------------------------------------------------------------
Test time: 3.9965152740478516

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.053 (0.032)	BT: 0.081 (0.065)	Loss 0.0021 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.073 (0.026)	BT: 0.101 (0.058)	Loss 0.0035 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.050 (0.054)	Loss 0.0008 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.020)	BT: 0.022 (0.052)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.018)	BT: 0.024 (0.050)	Loss 0.0010 (0.0019)	Prec@1 100.000 (99.994)	
Total train loss: 0.0019
Avg Loading time: 0.0184 seconds
Avg Batch time: 0.0504 seconds

Train time: 19.912267923355103
 * Prec@1 93.610 Prec@5 99.710 Loss 0.2294
Avg Loading time: 0.0439 seconds
Avg Batch time: 0.0576 seconds

Best acc: 93.720
--------------------------------------------------------------------------------
Test time: 5.261799335479736

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.030)	BT: 0.025 (0.064)	Loss 0.0028 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.021)	BT: 0.035 (0.055)	Loss 0.0010 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.067 (0.019)	BT: 0.088 (0.052)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.018)	BT: 0.047 (0.050)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.018)	BT: 0.020 (0.049)	Loss 0.0017 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0176 seconds
Avg Batch time: 0.0491 seconds

Train time: 19.36699366569519
 * Prec@1 93.690 Prec@5 99.740 Loss 0.2286
Avg Loading time: 0.0436 seconds
Avg Batch time: 0.0567 seconds

Best acc: 93.720
--------------------------------------------------------------------------------
Test time: 5.165984869003296

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.026 (0.024)	BT: 0.050 (0.057)	Loss 0.0010 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.021)	BT: 0.032 (0.054)	Loss 0.0016 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.029 (0.049)	Loss 0.0034 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.022 (0.014)	BT: 0.044 (0.046)	Loss 0.0039 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.020 (0.048)	Loss 0.0029 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0165 seconds
Avg Batch time: 0.0476 seconds

Train time: 18.780404090881348
 * Prec@1 93.780 Prec@5 99.700 Loss 0.2274
Avg Loading time: 0.0349 seconds
Avg Batch time: 0.0479 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 4.815195322036743

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.040 (0.047)	Loss 0.0017 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.044 (0.047)	Loss 0.0021 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.022 (0.047)	Loss 0.0020 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.038 (0.016)	BT: 0.070 (0.047)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.021 (0.048)	Loss 0.0008 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0165 seconds
Avg Batch time: 0.0474 seconds

Train time: 18.765839099884033
 * Prec@1 93.690 Prec@5 99.730 Loss 0.2284
Avg Loading time: 0.0412 seconds
Avg Batch time: 0.0539 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 4.923811435699463

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.027 (0.057)	Loss 0.0016 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.018)	BT: 0.025 (0.052)	Loss 0.0030 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.112 (0.017)	BT: 0.133 (0.051)	Loss 0.0032 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.021 (0.049)	Loss 0.0009 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.031 (0.049)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0163 seconds
Avg Batch time: 0.0489 seconds

Train time: 19.291873455047607
 * Prec@1 93.710 Prec@5 99.710 Loss 0.2268
Avg Loading time: 0.0487 seconds
Avg Batch time: 0.0602 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 5.409308433532715

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.031)	BT: 0.021 (0.064)	Loss 0.0010 (0.0018)	Prec@1 100.000 (99.990)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.030 (0.053)	Loss 0.0018 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.018)	BT: 0.032 (0.051)	Loss 0.0011 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.032 (0.047)	Loss 0.0008 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.014)	BT: 0.029 (0.046)	Loss 0.0012 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0144 seconds
Avg Batch time: 0.0457 seconds

Train time: 18.112266778945923
 * Prec@1 93.640 Prec@5 99.720 Loss 0.2272
Avg Loading time: 0.0381 seconds
Avg Batch time: 0.0511 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 4.734400033950806

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.032 (0.053)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.980)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.013)	BT: 0.027 (0.042)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.123 (0.013)	BT: 0.155 (0.044)	Loss 0.0016 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.021 (0.045)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.025 (0.046)	Loss 0.0013 (0.0018)	Prec@1 100.000 (99.996)	
Total train loss: 0.0018
Avg Loading time: 0.0154 seconds
Avg Batch time: 0.0459 seconds

Train time: 18.106935024261475
 * Prec@1 93.720 Prec@5 99.720 Loss 0.2281
Avg Loading time: 0.0412 seconds
Avg Batch time: 0.0548 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 5.012988328933716

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.035)	BT: 0.037 (0.067)	Loss 0.0021 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.031 (0.056)	Loss 0.0022 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.021)	BT: 0.022 (0.054)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.021)	BT: 0.028 (0.053)	Loss 0.0010 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.020 (0.052)	Loss 0.0022 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0199 seconds
Avg Batch time: 0.0520 seconds

Train time: 20.536019325256348
 * Prec@1 93.630 Prec@5 99.710 Loss 0.2292
Avg Loading time: 0.0427 seconds
Avg Batch time: 0.0559 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 5.0486369132995605

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.041 (0.028)	BT: 0.062 (0.061)	Loss 0.0009 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.085 (0.022)	BT: 0.106 (0.054)	Loss 0.0015 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.019)	BT: 0.034 (0.050)	Loss 0.0034 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.019)	BT: 0.028 (0.050)	Loss 0.0015 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.020 (0.048)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0163 seconds
Avg Batch time: 0.0474 seconds

Train time: 18.67836570739746
 * Prec@1 93.730 Prec@5 99.700 Loss 0.2316
Avg Loading time: 0.0369 seconds
Avg Batch time: 0.0487 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 4.568979978561401

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.109 (0.025)	BT: 0.151 (0.058)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.013 (0.018)	BT: 0.034 (0.050)	Loss 0.0021 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.013)	BT: 0.026 (0.044)	Loss 0.0024 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.013)	BT: 0.025 (0.043)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.014)	BT: 0.023 (0.045)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0136 seconds
Avg Batch time: 0.0445 seconds

Train time: 17.604994535446167
 * Prec@1 93.640 Prec@5 99.720 Loss 0.2280
Avg Loading time: 0.0396 seconds
Avg Batch time: 0.0544 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 5.00748085975647

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.038)	BT: 0.036 (0.068)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.025)	BT: 0.046 (0.056)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.118 (0.022)	BT: 0.159 (0.054)	Loss 0.0021 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.019)	BT: 0.029 (0.051)	Loss 0.0007 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.018)	BT: 0.024 (0.050)	Loss 0.0016 (0.0018)	Prec@1 100.000 (99.996)	
Total train loss: 0.0018
Avg Loading time: 0.0176 seconds
Avg Batch time: 0.0495 seconds

Train time: 19.574509859085083
 * Prec@1 93.650 Prec@5 99.740 Loss 0.2278
Avg Loading time: 0.0406 seconds
Avg Batch time: 0.0544 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 5.004051923751831

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.027)	BT: 0.032 (0.061)	Loss 0.0038 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.021)	BT: 0.025 (0.053)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.026 (0.050)	Loss 0.0005 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.159 (0.019)	BT: 0.180 (0.051)	Loss 0.0017 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.019)	BT: 0.037 (0.051)	Loss 0.0009 (0.0018)	Prec@1 100.000 (99.996)	
Total train loss: 0.0018
Avg Loading time: 0.0187 seconds
Avg Batch time: 0.0507 seconds

Train time: 19.989628791809082
 * Prec@1 93.710 Prec@5 99.710 Loss 0.2292
Avg Loading time: 0.0362 seconds
Avg Batch time: 0.0489 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 4.501620531082153

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.027)	BT: 0.043 (0.059)	Loss 0.0009 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.021)	BT: 0.031 (0.054)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.016)	BT: 0.027 (0.049)	Loss 0.0011 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.013)	BT: 0.035 (0.045)	Loss 0.0020 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.027 (0.045)	Loss 0.0005 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0138 seconds
Avg Batch time: 0.0453 seconds

Train time: 17.947803258895874
 * Prec@1 93.730 Prec@5 99.690 Loss 0.2310
Avg Loading time: 0.0439 seconds
Avg Batch time: 0.0550 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 5.034777402877808

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.022)	BT: 0.037 (0.055)	Loss 0.0010 (0.0018)	Prec@1 100.000 (99.990)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.052 (0.019)	BT: 0.082 (0.051)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.017)	BT: 0.060 (0.050)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.018)	BT: 0.048 (0.050)	Loss 0.0075 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.045 (0.017)	BT: 0.065 (0.049)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0172 seconds
Avg Batch time: 0.0494 seconds

Train time: 19.50346827507019
 * Prec@1 93.700 Prec@5 99.740 Loss 0.2299
Avg Loading time: 0.0431 seconds
Avg Batch time: 0.0555 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 5.066271781921387

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.025)	BT: 0.037 (0.057)	Loss 0.0018 (0.0015)	Prec@1 100.000 (100.000)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.112 (0.021)	BT: 0.140 (0.053)	Loss 0.0023 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.019)	BT: 0.027 (0.050)	Loss 0.0009 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.018)	BT: 0.030 (0.050)	Loss 0.0068 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.018)	BT: 0.020 (0.050)	Loss 0.0011 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0177 seconds
Avg Batch time: 0.0495 seconds

Train time: 19.540600776672363
 * Prec@1 93.700 Prec@5 99.730 Loss 0.2286
Avg Loading time: 0.0396 seconds
Avg Batch time: 0.0539 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 4.910502910614014

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.031 (0.045)	Loss 0.0027 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.061 (0.013)	BT: 0.083 (0.043)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.030 (0.045)	Loss 0.0014 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.015)	BT: 0.032 (0.046)	Loss 0.0008 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.013)	BT: 0.020 (0.044)	Loss 0.0007 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0134 seconds
Avg Batch time: 0.0436 seconds

Train time: 17.18466567993164
 * Prec@1 93.720 Prec@5 99.710 Loss 0.2274
Avg Loading time: 0.0404 seconds
Avg Batch time: 0.0517 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 4.784726619720459

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.002 (0.026)	BT: 0.060 (0.059)	Loss 0.0016 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.018)	BT: 0.037 (0.053)	Loss 0.0010 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.021 (0.016)	BT: 0.044 (0.050)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.017)	BT: 0.029 (0.049)	Loss 0.0019 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.017)	BT: 0.027 (0.049)	Loss 0.0026 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0168 seconds
Avg Batch time: 0.0493 seconds

Train time: 19.485958576202393
 * Prec@1 93.620 Prec@5 99.710 Loss 0.2302
Avg Loading time: 0.0442 seconds
Avg Batch time: 0.0576 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 5.236377954483032

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.001 (0.026)	BT: 0.023 (0.059)	Loss 0.0008 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.035 (0.057)	Loss 0.0013 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.021)	BT: 0.038 (0.053)	Loss 0.0009 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.087 (0.021)	BT: 0.119 (0.053)	Loss 0.0015 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.020)	BT: 0.020 (0.052)	Loss 0.0008 (0.0017)	Prec@1 100.000 (100.000)	
Total train loss: 0.0017
Avg Loading time: 0.0199 seconds
Avg Batch time: 0.0518 seconds

Train time: 20.483474731445312
 * Prec@1 93.690 Prec@5 99.720 Loss 0.2286
Avg Loading time: 0.0465 seconds
Avg Batch time: 0.0591 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 5.358396768569946

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.037 (0.022)	BT: 0.069 (0.056)	Loss 0.0011 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.012)	BT: 0.045 (0.044)	Loss 0.0007 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.013)	BT: 0.021 (0.044)	Loss 0.0009 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.033 (0.046)	Loss 0.0019 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.021 (0.045)	Loss 0.0024 (0.0018)	Prec@1 100.000 (99.994)	
Total train loss: 0.0018
Avg Loading time: 0.0144 seconds
Avg Batch time: 0.0453 seconds

Train time: 17.922077655792236
 * Prec@1 93.540 Prec@5 99.710 Loss 0.2296
Avg Loading time: 0.0344 seconds
Avg Batch time: 0.0437 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 4.105688810348511

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.029)	BT: 0.031 (0.063)	Loss 0.0027 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.048 (0.023)	BT: 0.069 (0.056)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.019)	BT: 0.033 (0.052)	Loss 0.0024 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.018)	BT: 0.046 (0.051)	Loss 0.0018 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.018)	BT: 0.020 (0.050)	Loss 0.0022 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0177 seconds
Avg Batch time: 0.0498 seconds

Train time: 19.654253005981445
 * Prec@1 93.610 Prec@5 99.720 Loss 0.2296
Avg Loading time: 0.0356 seconds
Avg Batch time: 0.0492 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 4.546358585357666

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.032)	BT: 0.022 (0.066)	Loss 0.0009 (0.0018)	Prec@1 100.000 (99.990)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.027)	BT: 0.022 (0.060)	Loss 0.0008 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.026)	BT: 0.026 (0.058)	Loss 0.0023 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.025)	BT: 0.030 (0.057)	Loss 0.0011 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.024)	BT: 0.020 (0.055)	Loss 0.0018 (0.0017)	Prec@1 100.000 (99.998)	
Total train loss: 0.0017
Avg Loading time: 0.0239 seconds
Avg Batch time: 0.0553 seconds

Train time: 21.831782341003418
 * Prec@1 93.660 Prec@5 99.700 Loss 0.2290
Avg Loading time: 0.0552 seconds
Avg Batch time: 0.0677 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 5.993144989013672

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.030)	BT: 0.022 (0.060)	Loss 0.0026 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.021)	BT: 0.035 (0.050)	Loss 0.0022 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.020)	BT: 0.031 (0.050)	Loss 0.0044 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.020)	BT: 0.026 (0.050)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.019)	BT: 0.020 (0.050)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0191 seconds
Avg Batch time: 0.0494 seconds

Train time: 19.46381640434265
 * Prec@1 93.710 Prec@5 99.720 Loss 0.2290
Avg Loading time: 0.0413 seconds
Avg Batch time: 0.0541 seconds

Best acc: 93.780
--------------------------------------------------------------------------------
Test time: 4.971294641494751


      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 0
          frozen_layers: 13
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 0
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/train/relu13
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/test/relu13
ResNet18(
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 12.180 Prec@5 49.300 Loss 2.3125
Avg Loading time: 0.0782 seconds
Avg Batch time: 0.1031 seconds

Pre-trained Prec@1 with 13 layers frozen: 12.179999351501465 	 Loss: 2.3125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (0.956)	BT: 0.019 (0.979)	Loss 0.6201 (0.6585)	Prec@1 80.469 (79.517)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (0.840)	BT: 0.022 (0.863)	Loss 0.2896 (0.5440)	Prec@1 91.406 (82.552)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (0.799)	BT: 0.023 (0.822)	Loss 0.4487 (0.4885)	Prec@1 83.594 (84.261)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (0.762)	BT: 0.033 (0.785)	Loss 0.4055 (0.4509)	Prec@1 83.594 (85.364)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (0.685)	BT: 0.027 (0.707)	Loss 0.3435 (0.4251)	Prec@1 90.625 (86.128)	
Total train loss: 0.4249
Avg Loading time: 0.6830 seconds
Avg Batch time: 0.7055 seconds

Train time: 276.07844066619873
 * Prec@1 89.090 Prec@5 99.660 Loss 0.3267
Avg Loading time: 0.0559 seconds
Avg Batch time: 0.0661 seconds

Best acc: 89.090
--------------------------------------------------------------------------------
Test time: 6.177212238311768

Epoch: [1][77/391]	LR: 0.1	DT: 0.085 (0.041)	BT: 0.104 (0.068)	Loss 0.1498 (0.1893)	Prec@1 93.750 (93.770)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.030)	BT: 0.035 (0.057)	Loss 0.1774 (0.2016)	Prec@1 93.750 (93.369)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.029)	BT: 0.017 (0.055)	Loss 0.1821 (0.2092)	Prec@1 91.406 (92.945)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.019 (0.025)	BT: 0.035 (0.051)	Loss 0.2798 (0.2096)	Prec@1 88.281 (92.909)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.017 (0.048)	Loss 0.2720 (0.2138)	Prec@1 91.406 (92.754)	
Total train loss: 0.2136
Avg Loading time: 0.0230 seconds
Avg Batch time: 0.0479 seconds

Train time: 18.94771146774292
 * Prec@1 89.520 Prec@5 99.620 Loss 0.3132
Avg Loading time: 0.0421 seconds
Avg Batch time: 0.0530 seconds

Best acc: 89.520
--------------------------------------------------------------------------------
Test time: 5.194199800491333

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.027)	BT: 0.019 (0.053)	Loss 0.1177 (0.1145)	Prec@1 96.875 (96.174)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.020)	BT: 0.017 (0.042)	Loss 0.1438 (0.1113)	Prec@1 95.312 (96.209)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.015 (0.021)	BT: 0.036 (0.044)	Loss 0.1298 (0.1194)	Prec@1 96.094 (95.897)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.021)	BT: 0.025 (0.045)	Loss 0.1917 (0.1251)	Prec@1 94.531 (95.711)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.021)	BT: 0.017 (0.046)	Loss 0.1109 (0.1306)	Prec@1 96.094 (95.545)	
Total train loss: 0.1306
Avg Loading time: 0.0214 seconds
Avg Batch time: 0.0458 seconds

Train time: 18.09310483932495
 * Prec@1 88.460 Prec@5 99.660 Loss 0.3528
Avg Loading time: 0.0440 seconds
Avg Batch time: 0.0564 seconds

Best acc: 89.520
--------------------------------------------------------------------------------
Test time: 5.09474778175354

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.029)	BT: 0.035 (0.057)	Loss 0.0515 (0.0746)	Prec@1 99.219 (97.666)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.027 (0.051)	Loss 0.0389 (0.0784)	Prec@1 98.438 (97.496)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.016 (0.050)	Loss 0.0731 (0.0797)	Prec@1 97.656 (97.419)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.029 (0.050)	Loss 0.0548 (0.0839)	Prec@1 98.438 (97.218)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.043 (0.023)	BT: 0.062 (0.050)	Loss 0.0747 (0.0889)	Prec@1 97.656 (97.019)	
Total train loss: 0.0889
Avg Loading time: 0.0227 seconds
Avg Batch time: 0.0496 seconds

Train time: 19.613725185394287
 * Prec@1 90.170 Prec@5 99.630 Loss 0.3262
Avg Loading time: 0.0501 seconds
Avg Batch time: 0.0625 seconds

Best acc: 90.170
--------------------------------------------------------------------------------
Test time: 5.965876817703247

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.036)	BT: 0.019 (0.062)	Loss 0.0243 (0.0559)	Prec@1 99.219 (98.207)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.036 (0.027)	BT: 0.055 (0.054)	Loss 0.0799 (0.0575)	Prec@1 96.875 (98.152)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.025)	BT: 0.015 (0.051)	Loss 0.0585 (0.0598)	Prec@1 96.875 (98.084)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.029 (0.025)	BT: 0.049 (0.051)	Loss 0.0763 (0.0630)	Prec@1 96.094 (97.952)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.015 (0.048)	Loss 0.0729 (0.0650)	Prec@1 96.875 (97.849)	
Total train loss: 0.0651
Avg Loading time: 0.0229 seconds
Avg Batch time: 0.0483 seconds

Train time: 19.018752574920654
 * Prec@1 90.390 Prec@5 99.610 Loss 0.3289
Avg Loading time: 0.0368 seconds
Avg Batch time: 0.0476 seconds

Best acc: 90.390
--------------------------------------------------------------------------------
Test time: 4.747976779937744

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.030)	BT: 0.029 (0.058)	Loss 0.0591 (0.0441)	Prec@1 97.656 (98.688)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.011 (0.021)	BT: 0.027 (0.048)	Loss 0.0359 (0.0472)	Prec@1 98.438 (98.618)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.000 (0.019)	BT: 0.029 (0.043)	Loss 0.0418 (0.0474)	Prec@1 98.438 (98.591)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.018)	BT: 0.036 (0.042)	Loss 0.0713 (0.0507)	Prec@1 97.656 (98.493)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.018)	BT: 0.020 (0.043)	Loss 0.0414 (0.0542)	Prec@1 98.438 (98.331)	
Total train loss: 0.0543
Avg Loading time: 0.0180 seconds
Avg Batch time: 0.0427 seconds

Train time: 16.914605855941772
 * Prec@1 90.380 Prec@5 99.470 Loss 0.3398
Avg Loading time: 0.0395 seconds
Avg Batch time: 0.0520 seconds

Best acc: 90.390
--------------------------------------------------------------------------------
Test time: 4.7574687004089355

Epoch: [6][77/391]	LR: 0.1	DT: 0.025 (0.036)	BT: 0.042 (0.063)	Loss 0.0511 (0.0351)	Prec@1 98.438 (98.998)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.023 (0.028)	BT: 0.039 (0.054)	Loss 0.0253 (0.0346)	Prec@1 99.219 (98.968)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.025)	BT: 0.029 (0.052)	Loss 0.0288 (0.0346)	Prec@1 99.219 (98.975)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.019 (0.050)	Loss 0.0497 (0.0344)	Prec@1 98.438 (98.981)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.024 (0.049)	Loss 0.0464 (0.0366)	Prec@1 98.438 (98.916)	
Total train loss: 0.0367
Avg Loading time: 0.0233 seconds
Avg Batch time: 0.0493 seconds

Train time: 19.48687219619751
 * Prec@1 91.170 Prec@5 99.630 Loss 0.3071
Avg Loading time: 0.0467 seconds
Avg Batch time: 0.0582 seconds

Best acc: 91.170
--------------------------------------------------------------------------------
Test time: 5.557669639587402

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.036)	BT: 0.039 (0.063)	Loss 0.0226 (0.0260)	Prec@1 100.000 (99.339)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.036 (0.055)	Loss 0.0241 (0.0269)	Prec@1 99.219 (99.229)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.025)	BT: 0.018 (0.050)	Loss 0.0448 (0.0304)	Prec@1 99.219 (99.072)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.019 (0.049)	Loss 0.0765 (0.0318)	Prec@1 96.875 (99.041)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.024 (0.048)	Loss 0.0664 (0.0333)	Prec@1 98.438 (98.980)	
Total train loss: 0.0334
Avg Loading time: 0.0221 seconds
Avg Batch time: 0.0483 seconds

Train time: 19.09323239326477
 * Prec@1 90.060 Prec@5 99.650 Loss 0.3525
Avg Loading time: 0.0330 seconds
Avg Batch time: 0.0445 seconds

Best acc: 91.170
--------------------------------------------------------------------------------
Test time: 4.083027124404907

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.028 (0.055)	Loss 0.0298 (0.0330)	Prec@1 98.438 (98.908)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.197 (0.024)	BT: 0.228 (0.051)	Loss 0.0605 (0.0305)	Prec@1 99.219 (99.018)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.018 (0.048)	Loss 0.0125 (0.0308)	Prec@1 100.000 (99.012)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.019)	BT: 0.016 (0.044)	Loss 0.0839 (0.0335)	Prec@1 96.875 (98.943)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.018)	BT: 0.017 (0.043)	Loss 0.0408 (0.0347)	Prec@1 98.438 (98.908)	
Total train loss: 0.0348
Avg Loading time: 0.0183 seconds
Avg Batch time: 0.0431 seconds

Train time: 17.00505757331848
 * Prec@1 91.090 Prec@5 99.560 Loss 0.3137
Avg Loading time: 0.0419 seconds
Avg Batch time: 0.0540 seconds

Best acc: 91.170
--------------------------------------------------------------------------------
Test time: 4.9010515213012695

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.038 (0.054)	Loss 0.0073 (0.0270)	Prec@1 100.000 (99.229)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.155 (0.024)	BT: 0.171 (0.051)	Loss 0.0244 (0.0249)	Prec@1 99.219 (99.254)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.042 (0.051)	Loss 0.0289 (0.0270)	Prec@1 99.219 (99.195)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.037 (0.050)	Loss 0.0398 (0.0292)	Prec@1 97.656 (99.104)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.032 (0.050)	Loss 0.0232 (0.0312)	Prec@1 99.219 (99.022)	
Total train loss: 0.0311
Avg Loading time: 0.0230 seconds
Avg Batch time: 0.0499 seconds

Train time: 19.729214191436768
 * Prec@1 90.870 Prec@5 99.610 Loss 0.3364
Avg Loading time: 0.0481 seconds
Avg Batch time: 0.0591 seconds

Best acc: 91.170
--------------------------------------------------------------------------------
Test time: 5.298938274383545

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.032)	BT: 0.040 (0.062)	Loss 0.0055 (0.0181)	Prec@1 100.000 (99.609)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.026)	BT: 0.054 (0.056)	Loss 0.0048 (0.0148)	Prec@1 100.000 (99.674)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.013 (0.025)	BT: 0.045 (0.054)	Loss 0.0076 (0.0127)	Prec@1 100.000 (99.753)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.023)	BT: 0.023 (0.052)	Loss 0.0033 (0.0118)	Prec@1 100.000 (99.765)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.023)	BT: 0.056 (0.051)	Loss 0.0055 (0.0111)	Prec@1 100.000 (99.784)	
Total train loss: 0.0111
Avg Loading time: 0.0230 seconds
Avg Batch time: 0.0511 seconds

Train time: 20.211137533187866
 * Prec@1 92.920 Prec@5 99.700 Loss 0.2502
Avg Loading time: 0.0417 seconds
Avg Batch time: 0.0528 seconds

Best acc: 92.920
--------------------------------------------------------------------------------
Test time: 5.164048433303833

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.026)	BT: 0.026 (0.055)	Loss 0.0131 (0.0056)	Prec@1 100.000 (99.930)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.028 (0.044)	Loss 0.0018 (0.0051)	Prec@1 100.000 (99.960)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.020 (0.044)	Loss 0.0040 (0.0051)	Prec@1 100.000 (99.940)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.062 (0.019)	BT: 0.078 (0.045)	Loss 0.0041 (0.0049)	Prec@1 100.000 (99.950)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.018 (0.019)	BT: 0.033 (0.044)	Loss 0.0045 (0.0048)	Prec@1 100.000 (99.946)	
Total train loss: 0.0048
Avg Loading time: 0.0187 seconds
Avg Batch time: 0.0444 seconds

Train time: 17.554890155792236
 * Prec@1 92.960 Prec@5 99.670 Loss 0.2517
Avg Loading time: 0.0350 seconds
Avg Batch time: 0.0430 seconds

Best acc: 92.960
--------------------------------------------------------------------------------
Test time: 4.340049982070923

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.037)	BT: 0.041 (0.065)	Loss 0.0026 (0.0042)	Prec@1 100.000 (99.950)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.054 (0.033)	BT: 0.076 (0.059)	Loss 0.0024 (0.0039)	Prec@1 100.000 (99.975)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.030)	BT: 0.016 (0.056)	Loss 0.0093 (0.0038)	Prec@1 99.219 (99.980)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.031)	BT: 0.032 (0.057)	Loss 0.0022 (0.0038)	Prec@1 100.000 (99.977)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.030)	BT: 0.015 (0.055)	Loss 0.0071 (0.0037)	Prec@1 100.000 (99.976)	
Total train loss: 0.0037
Avg Loading time: 0.0297 seconds
Avg Batch time: 0.0551 seconds

Train time: 21.76911473274231
 * Prec@1 93.090 Prec@5 99.660 Loss 0.2498
Avg Loading time: 0.0524 seconds
Avg Batch time: 0.0631 seconds

Best acc: 93.090
--------------------------------------------------------------------------------
Test time: 6.011417627334595

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.037)	BT: 0.035 (0.064)	Loss 0.0171 (0.0040)	Prec@1 99.219 (99.970)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.027)	BT: 0.059 (0.054)	Loss 0.0025 (0.0033)	Prec@1 100.000 (99.985)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.015 (0.052)	Loss 0.0022 (0.0032)	Prec@1 100.000 (99.990)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.017 (0.051)	Loss 0.0010 (0.0031)	Prec@1 100.000 (99.992)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.017 (0.051)	Loss 0.0029 (0.0031)	Prec@1 100.000 (99.994)	
Total train loss: 0.0031
Avg Loading time: 0.0248 seconds
Avg Batch time: 0.0506 seconds

Train time: 19.99341654777527
 * Prec@1 93.190 Prec@5 99.680 Loss 0.2478
Avg Loading time: 0.0421 seconds
Avg Batch time: 0.0538 seconds

Best acc: 93.190
--------------------------------------------------------------------------------
Test time: 5.20395827293396

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.001 (0.029)	BT: 0.036 (0.056)	Loss 0.0022 (0.0028)	Prec@1 100.000 (99.990)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.020)	BT: 0.028 (0.045)	Loss 0.0026 (0.0031)	Prec@1 100.000 (99.990)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.019)	BT: 0.030 (0.043)	Loss 0.0019 (0.0031)	Prec@1 100.000 (99.990)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.020 (0.042)	Loss 0.0057 (0.0030)	Prec@1 100.000 (99.992)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.019)	BT: 0.015 (0.043)	Loss 0.0012 (0.0030)	Prec@1 100.000 (99.994)	
Total train loss: 0.0030
Avg Loading time: 0.0185 seconds
Avg Batch time: 0.0431 seconds

Train time: 17.091570615768433
 * Prec@1 93.290 Prec@5 99.700 Loss 0.2452
Avg Loading time: 0.0343 seconds
Avg Batch time: 0.0436 seconds

Best acc: 93.290
--------------------------------------------------------------------------------
Test time: 4.340038061141968

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.034)	BT: 0.019 (0.058)	Loss 0.0019 (0.0029)	Prec@1 100.000 (99.990)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.028)	BT: 0.047 (0.053)	Loss 0.0016 (0.0028)	Prec@1 100.000 (99.990)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.028)	BT: 0.030 (0.052)	Loss 0.0020 (0.0027)	Prec@1 100.000 (99.990)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.111 (0.026)	BT: 0.131 (0.051)	Loss 0.0032 (0.0027)	Prec@1 100.000 (99.992)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.019 (0.050)	Loss 0.0017 (0.0028)	Prec@1 100.000 (99.990)	
Total train loss: 0.0028
Avg Loading time: 0.0249 seconds
Avg Batch time: 0.0499 seconds

Train time: 19.741045236587524
 * Prec@1 93.310 Prec@5 99.660 Loss 0.2482
Avg Loading time: 0.0464 seconds
Avg Batch time: 0.0572 seconds

Best acc: 93.310
--------------------------------------------------------------------------------
Test time: 5.504465579986572

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.038)	BT: 0.015 (0.065)	Loss 0.0074 (0.0026)	Prec@1 100.000 (99.990)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.031)	BT: 0.016 (0.057)	Loss 0.0011 (0.0025)	Prec@1 100.000 (99.995)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.026)	BT: 0.041 (0.052)	Loss 0.0014 (0.0026)	Prec@1 100.000 (99.987)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.024)	BT: 0.033 (0.050)	Loss 0.0026 (0.0025)	Prec@1 100.000 (99.990)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.024)	BT: 0.017 (0.050)	Loss 0.0018 (0.0025)	Prec@1 100.000 (99.990)	
Total train loss: 0.0025
Avg Loading time: 0.0237 seconds
Avg Batch time: 0.0496 seconds

Train time: 19.576995134353638
 * Prec@1 93.340 Prec@5 99.660 Loss 0.2474
Avg Loading time: 0.0437 seconds
Avg Batch time: 0.0535 seconds

Best acc: 93.340
--------------------------------------------------------------------------------
Test time: 5.2347252368927

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.014 (0.033)	BT: 0.034 (0.059)	Loss 0.0015 (0.0023)	Prec@1 100.000 (99.980)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.106 (0.026)	BT: 0.123 (0.053)	Loss 0.0012 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.022 (0.048)	Loss 0.0010 (0.0023)	Prec@1 100.000 (99.993)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.020)	BT: 0.023 (0.045)	Loss 0.0007 (0.0023)	Prec@1 100.000 (99.992)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.020)	BT: 0.016 (0.045)	Loss 0.0012 (0.0023)	Prec@1 100.000 (99.994)	
Total train loss: 0.0023
Avg Loading time: 0.0197 seconds
Avg Batch time: 0.0449 seconds

Train time: 17.76852583885193
 * Prec@1 93.240 Prec@5 99.670 Loss 0.2456
Avg Loading time: 0.0426 seconds
Avg Batch time: 0.0540 seconds

Best acc: 93.340
--------------------------------------------------------------------------------
Test time: 4.881487131118774

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.024 (0.021)	BT: 0.039 (0.044)	Loss 0.0019 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.021)	BT: 0.043 (0.045)	Loss 0.0016 (0.0024)	Prec@1 100.000 (99.990)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.024 (0.047)	Loss 0.0023 (0.0024)	Prec@1 100.000 (99.987)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.021)	BT: 0.028 (0.047)	Loss 0.0018 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.020)	BT: 0.015 (0.046)	Loss 0.0009 (0.0023)	Prec@1 100.000 (99.988)	
Total train loss: 0.0023
Avg Loading time: 0.0202 seconds
Avg Batch time: 0.0456 seconds

Train time: 18.03209662437439
 * Prec@1 93.260 Prec@5 99.670 Loss 0.2491
Avg Loading time: 0.0484 seconds
Avg Batch time: 0.0576 seconds

Best acc: 93.340
--------------------------------------------------------------------------------
Test time: 5.162569761276245

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.033)	BT: 0.031 (0.061)	Loss 0.0019 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.021 (0.026)	BT: 0.054 (0.054)	Loss 0.0013 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.024)	BT: 0.015 (0.052)	Loss 0.0020 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.024)	BT: 0.029 (0.050)	Loss 0.0008 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.025 (0.049)	Loss 0.0060 (0.0022)	Prec@1 100.000 (99.992)	
Total train loss: 0.0022
Avg Loading time: 0.0220 seconds
Avg Batch time: 0.0488 seconds

Train time: 19.31398367881775
 * Prec@1 93.270 Prec@5 99.640 Loss 0.2476
Avg Loading time: 0.0429 seconds
Avg Batch time: 0.0538 seconds

Best acc: 93.340
--------------------------------------------------------------------------------
Test time: 4.846171140670776

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.035)	BT: 0.021 (0.061)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.030)	BT: 0.032 (0.056)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.168 (0.028)	BT: 0.186 (0.054)	Loss 0.0008 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.036 (0.052)	Loss 0.0042 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.020 (0.050)	Loss 0.0025 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0243 seconds
Avg Batch time: 0.0498 seconds

Train time: 19.589287996292114
 * Prec@1 93.330 Prec@5 99.660 Loss 0.2478
Avg Loading time: 0.0408 seconds
Avg Batch time: 0.0525 seconds

Best acc: 93.340
--------------------------------------------------------------------------------
Test time: 4.801882743835449

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.036)	BT: 0.016 (0.063)	Loss 0.0006 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.018 (0.050)	Loss 0.0037 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.021)	BT: 0.018 (0.045)	Loss 0.0018 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.057 (0.047)	Loss 0.0013 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.019 (0.047)	Loss 0.0049 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0215 seconds
Avg Batch time: 0.0471 seconds

Train time: 18.632461547851562
 * Prec@1 93.310 Prec@5 99.670 Loss 0.2465
Avg Loading time: 0.0472 seconds
Avg Batch time: 0.0577 seconds

Best acc: 93.340
--------------------------------------------------------------------------------
Test time: 5.155131578445435

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.034)	BT: 0.024 (0.060)	Loss 0.0013 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.030 (0.052)	Loss 0.0026 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.025)	BT: 0.041 (0.052)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.017 (0.051)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.017 (0.050)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0239 seconds
Avg Batch time: 0.0499 seconds

Train time: 19.691184997558594
 * Prec@1 93.300 Prec@5 99.670 Loss 0.2472
Avg Loading time: 0.0461 seconds
Avg Batch time: 0.0568 seconds

Best acc: 93.340
--------------------------------------------------------------------------------
Test time: 5.127338647842407

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.038 (0.035)	BT: 0.055 (0.061)	Loss 0.0010 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.029)	BT: 0.028 (0.055)	Loss 0.0017 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.005 (0.027)	BT: 0.022 (0.053)	Loss 0.0011 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.003 (0.026)	BT: 0.025 (0.052)	Loss 0.0009 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.025)	BT: 0.039 (0.051)	Loss 0.0041 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0252 seconds
Avg Batch time: 0.0508 seconds

Train time: 20.117008209228516
 * Prec@1 93.270 Prec@5 99.680 Loss 0.2438
Avg Loading time: 0.0339 seconds
Avg Batch time: 0.0439 seconds

Best acc: 93.340
--------------------------------------------------------------------------------
Test time: 4.103931427001953

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.034)	BT: 0.025 (0.060)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.027)	BT: 0.025 (0.052)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.066 (0.022)	BT: 0.085 (0.047)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.021)	BT: 0.030 (0.045)	Loss 0.0018 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.020)	BT: 0.025 (0.045)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0021
Avg Loading time: 0.0195 seconds
Avg Batch time: 0.0448 seconds

Train time: 17.739295482635498
 * Prec@1 93.220 Prec@5 99.660 Loss 0.2491
Avg Loading time: 0.0412 seconds
Avg Batch time: 0.0557 seconds

Best acc: 93.340
--------------------------------------------------------------------------------
Test time: 5.042438983917236

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.036)	BT: 0.022 (0.063)	Loss 0.0017 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.030 (0.053)	Loss 0.0021 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.021 (0.050)	Loss 0.0061 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.021)	BT: 0.024 (0.048)	Loss 0.0020 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.009 (0.020)	BT: 0.028 (0.047)	Loss 0.0028 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0201 seconds
Avg Batch time: 0.0472 seconds

Train time: 18.68357753753662
 * Prec@1 93.390 Prec@5 99.690 Loss 0.2446
Avg Loading time: 0.0450 seconds
Avg Batch time: 0.0568 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 5.494358777999878

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.032)	BT: 0.018 (0.058)	Loss 0.0010 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.027)	BT: 0.034 (0.053)	Loss 0.0037 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.001 (0.024)	BT: 0.031 (0.050)	Loss 0.0021 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.038 (0.050)	Loss 0.0007 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.016 (0.050)	Loss 0.0017 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0021
Avg Loading time: 0.0235 seconds
Avg Batch time: 0.0498 seconds

Train time: 19.676471948623657
 * Prec@1 93.290 Prec@5 99.650 Loss 0.2465
Avg Loading time: 0.0362 seconds
Avg Batch time: 0.0478 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.3925089836120605

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.011 (0.028)	BT: 0.029 (0.051)	Loss 0.0019 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.032 (0.045)	Loss 0.0015 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.021)	BT: 0.034 (0.046)	Loss 0.0015 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.135 (0.021)	BT: 0.156 (0.046)	Loss 0.0080 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.011 (0.019)	BT: 0.026 (0.044)	Loss 0.0036 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.0193 seconds
Avg Batch time: 0.0440 seconds

Train time: 17.35647416114807
 * Prec@1 93.230 Prec@5 99.680 Loss 0.2456
Avg Loading time: 0.0337 seconds
Avg Batch time: 0.0454 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.252913236618042

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.033)	BT: 0.026 (0.059)	Loss 0.0012 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.025)	BT: 0.020 (0.052)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.034 (0.024)	BT: 0.063 (0.051)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.027 (0.051)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.016 (0.049)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0221 seconds
Avg Batch time: 0.0486 seconds

Train time: 19.19803285598755
 * Prec@1 93.340 Prec@5 99.660 Loss 0.2476
Avg Loading time: 0.0383 seconds
Avg Batch time: 0.0531 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.847450494766235

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.035)	BT: 0.033 (0.061)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.029)	BT: 0.020 (0.057)	Loss 0.0064 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.025)	BT: 0.054 (0.052)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.025)	BT: 0.032 (0.052)	Loss 0.0030 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.020 (0.051)	Loss 0.0027 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0236 seconds
Avg Batch time: 0.0509 seconds

Train time: 20.089972496032715
 * Prec@1 93.290 Prec@5 99.660 Loss 0.2474
Avg Loading time: 0.0375 seconds
Avg Batch time: 0.0496 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.505770683288574

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.056 (0.032)	BT: 0.081 (0.059)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.019 (0.050)	Loss 0.0017 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.038 (0.020)	BT: 0.058 (0.044)	Loss 0.0048 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.040 (0.044)	Loss 0.0018 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.019 (0.045)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0198 seconds
Avg Batch time: 0.0448 seconds

Train time: 17.77002453804016
 * Prec@1 93.280 Prec@5 99.660 Loss 0.2478
Avg Loading time: 0.0364 seconds
Avg Batch time: 0.0488 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.74691104888916

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.040 (0.051)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.022)	BT: 0.020 (0.049)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.027 (0.047)	Loss 0.0018 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.046 (0.019)	BT: 0.069 (0.046)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.019 (0.047)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0195 seconds
Avg Batch time: 0.0464 seconds

Train time: 18.38792085647583
 * Prec@1 93.230 Prec@5 99.670 Loss 0.2478
Avg Loading time: 0.0403 seconds
Avg Batch time: 0.0521 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.743687629699707

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.036)	BT: 0.020 (0.060)	Loss 0.0007 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.028)	BT: 0.030 (0.053)	Loss 0.0018 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.026)	BT: 0.018 (0.052)	Loss 0.0015 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.081 (0.026)	BT: 0.106 (0.052)	Loss 0.0012 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.026 (0.051)	Loss 0.0050 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0240 seconds
Avg Batch time: 0.0509 seconds

Train time: 20.150697231292725
 * Prec@1 93.230 Prec@5 99.660 Loss 0.2494
Avg Loading time: 0.0361 seconds
Avg Batch time: 0.0479 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.37106466293335

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.032 (0.032)	BT: 0.057 (0.059)	Loss 0.0012 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.112 (0.024)	BT: 0.128 (0.051)	Loss 0.0026 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.021)	BT: 0.032 (0.048)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.022)	BT: 0.023 (0.049)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.016 (0.046)	Loss 0.0009 (0.0021)	Prec@1 100.000 (99.992)	
Total train loss: 0.0021
Avg Loading time: 0.0197 seconds
Avg Batch time: 0.0456 seconds

Train time: 17.967621326446533
 * Prec@1 93.280 Prec@5 99.690 Loss 0.2456
Avg Loading time: 0.0395 seconds
Avg Batch time: 0.0497 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.5688042640686035

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.035)	BT: 0.025 (0.060)	Loss 0.0022 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.043 (0.025)	BT: 0.059 (0.050)	Loss 0.0021 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.019 (0.021)	BT: 0.037 (0.044)	Loss 0.0020 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.061 (0.021)	BT: 0.098 (0.044)	Loss 0.0022 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.019 (0.044)	Loss 0.0015 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0200 seconds
Avg Batch time: 0.0440 seconds

Train time: 17.41960120201111
 * Prec@1 93.270 Prec@5 99.660 Loss 0.2452
Avg Loading time: 0.0473 seconds
Avg Batch time: 0.0609 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 5.420868873596191

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.039)	BT: 0.026 (0.063)	Loss 0.0016 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.028)	BT: 0.024 (0.054)	Loss 0.0019 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.173 (0.028)	BT: 0.191 (0.053)	Loss 0.0021 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.026)	BT: 0.040 (0.052)	Loss 0.0040 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.025)	BT: 0.016 (0.051)	Loss 0.0039 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0254 seconds
Avg Batch time: 0.0511 seconds

Train time: 20.220317602157593
 * Prec@1 93.120 Prec@5 99.700 Loss 0.2466
Avg Loading time: 0.0412 seconds
Avg Batch time: 0.0522 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.761376142501831

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.036)	BT: 0.024 (0.062)	Loss 0.0006 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.029)	BT: 0.018 (0.054)	Loss 0.0017 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.027)	BT: 0.025 (0.052)	Loss 0.0008 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.073 (0.025)	BT: 0.103 (0.051)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.016 (0.049)	Loss 0.0033 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0235 seconds
Avg Batch time: 0.0492 seconds

Train time: 19.43197226524353
 * Prec@1 93.120 Prec@5 99.670 Loss 0.2468
Avg Loading time: 0.0391 seconds
Avg Batch time: 0.0498 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.487685680389404

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.024 (0.028)	BT: 0.041 (0.054)	Loss 0.0026 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.027)	BT: 0.025 (0.054)	Loss 0.0018 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.017 (0.050)	Loss 0.0014 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.029 (0.046)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.030 (0.045)	Loss 0.0022 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0195 seconds
Avg Batch time: 0.0446 seconds

Train time: 17.63073754310608
 * Prec@1 93.240 Prec@5 99.650 Loss 0.2462
Avg Loading time: 0.0384 seconds
Avg Batch time: 0.0523 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.768669605255127

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.022 (0.027)	BT: 0.047 (0.057)	Loss 0.0011 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.023)	BT: 0.050 (0.052)	Loss 0.0028 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.023)	BT: 0.035 (0.051)	Loss 0.0078 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.022)	BT: 0.045 (0.049)	Loss 0.0032 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.021)	BT: 0.015 (0.049)	Loss 0.0007 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0214 seconds
Avg Batch time: 0.0487 seconds

Train time: 19.271361112594604
 * Prec@1 93.300 Prec@5 99.700 Loss 0.2469
Avg Loading time: 0.0354 seconds
Avg Batch time: 0.0479 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.4551942348480225

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.034)	BT: 0.046 (0.059)	Loss 0.0019 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.037 (0.052)	Loss 0.0044 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.266 (0.023)	BT: 0.281 (0.049)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.993)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.022)	BT: 0.018 (0.049)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.022)	BT: 0.016 (0.048)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0215 seconds
Avg Batch time: 0.0479 seconds

Train time: 18.9891140460968
 * Prec@1 93.370 Prec@5 99.680 Loss 0.2472
Avg Loading time: 0.0393 seconds
Avg Batch time: 0.0534 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.826288461685181

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.025)	BT: 0.026 (0.054)	Loss 0.0021 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.019)	BT: 0.026 (0.046)	Loss 0.0013 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.018)	BT: 0.021 (0.043)	Loss 0.0012 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.118 (0.020)	BT: 0.137 (0.044)	Loss 0.0019 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.019)	BT: 0.016 (0.044)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0192 seconds
Avg Batch time: 0.0439 seconds

Train time: 17.357256650924683
 * Prec@1 93.340 Prec@5 99.680 Loss 0.2454
Avg Loading time: 0.0329 seconds
Avg Batch time: 0.0412 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 3.8451669216156006

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.005 (0.034)	BT: 0.029 (0.060)	Loss 0.0011 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.029)	BT: 0.030 (0.054)	Loss 0.0015 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.026)	BT: 0.053 (0.051)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.025)	BT: 0.030 (0.050)	Loss 0.0022 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.024)	BT: 0.015 (0.049)	Loss 0.0015 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0244 seconds
Avg Batch time: 0.0494 seconds

Train time: 19.52308487892151
 * Prec@1 93.330 Prec@5 99.660 Loss 0.2444
Avg Loading time: 0.0393 seconds
Avg Batch time: 0.0505 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.633460283279419

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.098 (0.038)	BT: 0.129 (0.064)	Loss 0.0017 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.029)	BT: 0.031 (0.056)	Loss 0.0018 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.026)	BT: 0.037 (0.053)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.024)	BT: 0.018 (0.051)	Loss 0.0021 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.019 (0.050)	Loss 0.0034 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0229 seconds
Avg Batch time: 0.0496 seconds

Train time: 19.626848936080933
 * Prec@1 93.370 Prec@5 99.680 Loss 0.2507
Avg Loading time: 0.0440 seconds
Avg Batch time: 0.0555 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 5.020695924758911

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.032)	BT: 0.041 (0.059)	Loss 0.0017 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.012 (0.026)	BT: 0.030 (0.053)	Loss 0.0016 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.024)	BT: 0.027 (0.050)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.021)	BT: 0.021 (0.046)	Loss 0.0019 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.020)	BT: 0.016 (0.046)	Loss 0.0020 (0.0021)	Prec@1 100.000 (99.998)	
Total train loss: 0.0021
Avg Loading time: 0.0201 seconds
Avg Batch time: 0.0455 seconds

Train time: 18.01249408721924
 * Prec@1 93.310 Prec@5 99.690 Loss 0.2465
Avg Loading time: 0.0376 seconds
Avg Batch time: 0.0470 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.382890701293945

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.025)	BT: 0.023 (0.048)	Loss 0.0018 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.012 (0.018)	BT: 0.034 (0.040)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.017)	BT: 0.021 (0.041)	Loss 0.0017 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.017)	BT: 0.021 (0.042)	Loss 0.0038 (0.0020)	Prec@1 100.000 (99.992)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.017)	BT: 0.016 (0.043)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0174 seconds
Avg Batch time: 0.0429 seconds

Train time: 16.9857017993927
 * Prec@1 93.250 Prec@5 99.690 Loss 0.2468
Avg Loading time: 0.0395 seconds
Avg Batch time: 0.0514 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.6961658000946045

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.072 (0.033)	BT: 0.090 (0.057)	Loss 0.0020 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.015 (0.028)	BT: 0.043 (0.053)	Loss 0.0035 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.025)	BT: 0.043 (0.050)	Loss 0.0018 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.025)	BT: 0.031 (0.050)	Loss 0.0018 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.018 (0.049)	Loss 0.0020 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0230 seconds
Avg Batch time: 0.0487 seconds

Train time: 19.212775230407715
 * Prec@1 93.200 Prec@5 99.660 Loss 0.2480
Avg Loading time: 0.0487 seconds
Avg Batch time: 0.0581 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 5.270687103271484

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.030)	BT: 0.027 (0.060)	Loss 0.0017 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.007 (0.025)	BT: 0.037 (0.054)	Loss 0.0015 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.042 (0.052)	Loss 0.0013 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.022)	BT: 0.056 (0.050)	Loss 0.0016 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.021)	BT: 0.016 (0.049)	Loss 0.0021 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0208 seconds
Avg Batch time: 0.0491 seconds

Train time: 19.418335437774658
 * Prec@1 93.190 Prec@5 99.690 Loss 0.2465
Avg Loading time: 0.0354 seconds
Avg Batch time: 0.0437 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.074944496154785

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.027)	BT: 0.028 (0.056)	Loss 0.0012 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.016 (0.051)	Loss 0.0014 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.020)	BT: 0.031 (0.048)	Loss 0.0033 (0.0021)	Prec@1 100.000 (99.993)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.018)	BT: 0.035 (0.044)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.017)	BT: 0.022 (0.043)	Loss 0.0033 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0174 seconds
Avg Batch time: 0.0431 seconds

Train time: 17.0672709941864
 * Prec@1 93.240 Prec@5 99.670 Loss 0.2466
Avg Loading time: 0.0433 seconds
Avg Batch time: 0.0570 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 5.108836650848389

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.028)	BT: 0.018 (0.058)	Loss 0.0010 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.076 (0.024)	BT: 0.092 (0.052)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.021)	BT: 0.034 (0.049)	Loss 0.0037 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.004 (0.021)	BT: 0.034 (0.048)	Loss 0.0016 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.022)	BT: 0.019 (0.049)	Loss 0.0026 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0216 seconds
Avg Batch time: 0.0489 seconds

Train time: 19.354456186294556
 * Prec@1 93.250 Prec@5 99.680 Loss 0.2468
Avg Loading time: 0.0506 seconds
Avg Batch time: 0.0627 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 5.610095262527466

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.033)	BT: 0.069 (0.063)	Loss 0.0035 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.024 (0.024)	BT: 0.045 (0.054)	Loss 0.0013 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.072 (0.027)	BT: 0.095 (0.055)	Loss 0.0044 (0.0021)	Prec@1 100.000 (99.993)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.050 (0.026)	BT: 0.068 (0.054)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.025)	BT: 0.022 (0.052)	Loss 0.0018 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0252 seconds
Avg Batch time: 0.0524 seconds

Train time: 20.696526765823364
 * Prec@1 93.200 Prec@5 99.650 Loss 0.2468
Avg Loading time: 0.0358 seconds
Avg Batch time: 0.0486 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 4.4641852378845215


      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 0
          frozen_layers: 15
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 0
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/train/relu15
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/test/relu15
ResNet18(
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 14.650 Prec@5 49.820 Loss 2.3125
Avg Loading time: 0.0497 seconds
Avg Batch time: 0.0651 seconds

Pre-trained Prec@1 with 15 layers frozen: 14.649999618530273 	 Loss: 2.3125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (0.373)	BT: 0.011 (0.386)	Loss 0.4607 (0.7437)	Prec@1 85.938 (76.633)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (0.358)	BT: 0.014 (0.371)	Loss 0.4656 (0.6200)	Prec@1 82.812 (80.048)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (0.390)	BT: 0.011 (0.402)	Loss 0.4822 (0.5633)	Prec@1 83.594 (81.654)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (0.420)	BT: 0.010 (0.432)	Loss 0.4963 (0.5258)	Prec@1 81.250 (82.620)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (0.450)	BT: 0.010 (0.462)	Loss 0.3586 (0.5015)	Prec@1 89.062 (83.387)	
Total train loss: 0.5013
Avg Loading time: 0.4493 seconds
Avg Batch time: 0.4610 seconds

Train time: 180.46993565559387
 * Prec@1 85.420 Prec@5 99.470 Loss 0.4268
Avg Loading time: 0.0456 seconds
Avg Batch time: 0.0529 seconds

Best acc: 85.420
--------------------------------------------------------------------------------
Test time: 4.82683801651001

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.030)	BT: 0.011 (0.043)	Loss 0.3044 (0.3002)	Prec@1 90.625 (90.114)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.177 (0.029)	BT: 0.189 (0.042)	Loss 0.3755 (0.2952)	Prec@1 84.375 (90.084)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.030)	BT: 0.009 (0.044)	Loss 0.2666 (0.2962)	Prec@1 89.844 (89.901)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.031)	BT: 0.009 (0.044)	Loss 0.2739 (0.2966)	Prec@1 90.625 (89.904)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.114 (0.031)	BT: 0.128 (0.045)	Loss 0.2443 (0.2984)	Prec@1 93.750 (89.794)	
Total train loss: 0.2985
Avg Loading time: 0.0311 seconds
Avg Batch time: 0.0445 seconds

Train time: 17.645508766174316
 * Prec@1 86.440 Prec@5 99.640 Loss 0.3906
Avg Loading time: 0.0389 seconds
Avg Batch time: 0.0457 seconds

Best acc: 86.440
--------------------------------------------------------------------------------
Test time: 4.280427694320679

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.042)	BT: 0.014 (0.059)	Loss 0.3079 (0.2003)	Prec@1 89.062 (93.540)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.036)	BT: 0.009 (0.052)	Loss 0.1669 (0.2004)	Prec@1 94.531 (93.294)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.270 (0.036)	BT: 0.284 (0.050)	Loss 0.3022 (0.2109)	Prec@1 89.844 (92.835)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.130 (0.034)	BT: 0.139 (0.049)	Loss 0.2021 (0.2139)	Prec@1 92.188 (92.696)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.086 (0.033)	BT: 0.095 (0.048)	Loss 0.2988 (0.2191)	Prec@1 92.188 (92.540)	
Total train loss: 0.2191
Avg Loading time: 0.0333 seconds
Avg Batch time: 0.0476 seconds

Train time: 18.802104234695435
 * Prec@1 88.330 Prec@5 99.580 Loss 0.3567
Avg Loading time: 0.0406 seconds
Avg Batch time: 0.0475 seconds

Best acc: 88.330
--------------------------------------------------------------------------------
Test time: 4.444078683853149

Epoch: [3][77/391]	LR: 0.1	DT: 0.014 (0.037)	BT: 0.035 (0.053)	Loss 0.1599 (0.1499)	Prec@1 96.094 (94.661)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.030)	BT: 0.009 (0.045)	Loss 0.0964 (0.1586)	Prec@1 97.656 (94.466)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.026 (0.043)	Loss 0.1443 (0.1629)	Prec@1 92.969 (94.304)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.017 (0.027)	BT: 0.032 (0.042)	Loss 0.1022 (0.1642)	Prec@1 98.438 (94.246)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.032 (0.027)	BT: 0.041 (0.041)	Loss 0.1935 (0.1681)	Prec@1 91.406 (94.123)	
Total train loss: 0.1681
Avg Loading time: 0.0266 seconds
Avg Batch time: 0.0414 seconds

Train time: 16.381661653518677
 * Prec@1 87.800 Prec@5 99.600 Loss 0.3748
Avg Loading time: 0.0297 seconds
Avg Batch time: 0.0340 seconds

Best acc: 88.330
--------------------------------------------------------------------------------
Test time: 3.084162950515747

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.041)	BT: 0.010 (0.055)	Loss 0.1998 (0.1131)	Prec@1 92.969 (96.294)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.036)	BT: 0.024 (0.050)	Loss 0.1749 (0.1169)	Prec@1 93.750 (96.204)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.031)	BT: 0.010 (0.044)	Loss 0.1826 (0.1205)	Prec@1 96.094 (96.040)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.027)	BT: 0.010 (0.040)	Loss 0.1984 (0.1242)	Prec@1 92.188 (95.841)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.062 (0.027)	BT: 0.071 (0.040)	Loss 0.2217 (0.1291)	Prec@1 93.750 (95.587)	
Total train loss: 0.1291
Avg Loading time: 0.0268 seconds
Avg Batch time: 0.0401 seconds

Train time: 15.895113945007324
 * Prec@1 88.490 Prec@5 99.360 Loss 0.3899
Avg Loading time: 0.0450 seconds
Avg Batch time: 0.0519 seconds

Best acc: 88.490
--------------------------------------------------------------------------------
Test time: 4.760354280471802

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.041)	BT: 0.036 (0.056)	Loss 0.0515 (0.0930)	Prec@1 100.000 (97.105)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.038)	BT: 0.029 (0.052)	Loss 0.1290 (0.0925)	Prec@1 96.094 (97.065)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.160 (0.034)	BT: 0.177 (0.049)	Loss 0.1094 (0.0966)	Prec@1 95.312 (96.848)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.031)	BT: 0.010 (0.045)	Loss 0.1134 (0.1030)	Prec@1 98.438 (96.585)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.030)	BT: 0.009 (0.045)	Loss 0.1001 (0.1086)	Prec@1 95.312 (96.360)	
Total train loss: 0.1085
Avg Loading time: 0.0301 seconds
Avg Batch time: 0.0448 seconds

Train time: 17.780996799468994
 * Prec@1 88.490 Prec@5 99.540 Loss 0.3860
Avg Loading time: 0.0380 seconds
Avg Batch time: 0.0455 seconds

Best acc: 88.490
--------------------------------------------------------------------------------
Test time: 4.038994789123535

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.047)	BT: 0.013 (0.061)	Loss 0.0565 (0.0656)	Prec@1 98.438 (97.867)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.037)	BT: 0.030 (0.051)	Loss 0.0557 (0.0664)	Prec@1 99.219 (97.847)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.202 (0.033)	BT: 0.227 (0.048)	Loss 0.0768 (0.0696)	Prec@1 96.875 (97.806)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.030)	BT: 0.017 (0.045)	Loss 0.0991 (0.0739)	Prec@1 97.656 (97.591)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.029)	BT: 0.020 (0.044)	Loss 0.0584 (0.0766)	Prec@1 98.438 (97.484)	
Total train loss: 0.0767
Avg Loading time: 0.0286 seconds
Avg Batch time: 0.0436 seconds

Train time: 17.27805233001709
 * Prec@1 88.780 Prec@5 99.480 Loss 0.3943
Avg Loading time: 0.0456 seconds
Avg Batch time: 0.0523 seconds

Best acc: 88.780
--------------------------------------------------------------------------------
Test time: 4.803890705108643

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.039)	BT: 0.018 (0.054)	Loss 0.0623 (0.0620)	Prec@1 97.656 (98.057)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.029)	BT: 0.018 (0.043)	Loss 0.1091 (0.0590)	Prec@1 96.875 (98.137)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.014 (0.037)	Loss 0.1053 (0.0594)	Prec@1 96.094 (98.134)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.015 (0.037)	Loss 0.0781 (0.0597)	Prec@1 97.656 (98.122)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.012 (0.037)	Loss 0.0340 (0.0611)	Prec@1 99.219 (98.081)	
Total train loss: 0.0612
Avg Loading time: 0.0241 seconds
Avg Batch time: 0.0371 seconds

Train time: 14.688276529312134
 * Prec@1 88.160 Prec@5 99.260 Loss 0.4316
Avg Loading time: 0.0355 seconds
Avg Batch time: 0.0418 seconds

Best acc: 88.780
--------------------------------------------------------------------------------
Test time: 3.754263401031494

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.019 (0.036)	Loss 0.0256 (0.0518)	Prec@1 99.219 (98.327)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.019 (0.036)	Loss 0.0505 (0.0474)	Prec@1 99.219 (98.583)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.009 (0.037)	Loss 0.0270 (0.0481)	Prec@1 99.219 (98.541)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.015 (0.037)	Loss 0.1003 (0.0526)	Prec@1 96.875 (98.352)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.009 (0.037)	Loss 0.0230 (0.0555)	Prec@1 99.219 (98.211)	
Total train loss: 0.0556
Avg Loading time: 0.0235 seconds
Avg Batch time: 0.0371 seconds

Train time: 14.698585510253906
 * Prec@1 87.960 Prec@5 99.370 Loss 0.4409
Avg Loading time: 0.0375 seconds
Avg Batch time: 0.0430 seconds

Best acc: 88.780
--------------------------------------------------------------------------------
Test time: 3.840104341506958

Epoch: [9][77/391]	LR: 0.1	DT: 0.025 (0.039)	BT: 0.037 (0.053)	Loss 0.0157 (0.0423)	Prec@1 100.000 (98.828)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.029 (0.030)	BT: 0.040 (0.044)	Loss 0.1172 (0.0468)	Prec@1 97.656 (98.613)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.048 (0.029)	BT: 0.067 (0.043)	Loss 0.0236 (0.0476)	Prec@1 100.000 (98.598)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.011 (0.042)	Loss 0.0567 (0.0485)	Prec@1 98.438 (98.530)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.012 (0.026)	BT: 0.020 (0.040)	Loss 0.0886 (0.0500)	Prec@1 97.656 (98.482)	
Total train loss: 0.0499
Avg Loading time: 0.0261 seconds
Avg Batch time: 0.0398 seconds

Train time: 15.80148959159851
 * Prec@1 88.260 Prec@5 99.550 Loss 0.4248
Avg Loading time: 0.0383 seconds
Avg Batch time: 0.0451 seconds

Best acc: 88.780
--------------------------------------------------------------------------------
Test time: 4.014132261276245

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.037)	BT: 0.011 (0.050)	Loss 0.0261 (0.0304)	Prec@1 99.219 (99.159)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.030)	BT: 0.009 (0.044)	Loss 0.0065 (0.0240)	Prec@1 100.000 (99.439)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.027)	BT: 0.010 (0.040)	Loss 0.0153 (0.0212)	Prec@1 99.219 (99.536)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.063 (0.026)	BT: 0.073 (0.040)	Loss 0.0365 (0.0196)	Prec@1 99.219 (99.592)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.096 (0.028)	BT: 0.109 (0.041)	Loss 0.0060 (0.0181)	Prec@1 100.000 (99.647)	
Total train loss: 0.0180
Avg Loading time: 0.0275 seconds
Avg Batch time: 0.0413 seconds

Train time: 16.30847191810608
 * Prec@1 91.180 Prec@5 99.620 Loss 0.3171
Avg Loading time: 0.0444 seconds
Avg Batch time: 0.0528 seconds

Best acc: 91.180
--------------------------------------------------------------------------------
Test time: 4.8434367179870605

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.024)	BT: 0.019 (0.036)	Loss 0.0046 (0.0082)	Prec@1 100.000 (99.930)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.024)	BT: 0.011 (0.036)	Loss 0.0038 (0.0087)	Prec@1 100.000 (99.920)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.041 (0.026)	BT: 0.062 (0.039)	Loss 0.0080 (0.0084)	Prec@1 100.000 (99.923)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.026)	BT: 0.010 (0.038)	Loss 0.0109 (0.0082)	Prec@1 100.000 (99.930)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.024)	BT: 0.008 (0.036)	Loss 0.0066 (0.0082)	Prec@1 100.000 (99.936)	
Total train loss: 0.0082
Avg Loading time: 0.0235 seconds
Avg Batch time: 0.0361 seconds

Train time: 14.305210590362549
 * Prec@1 91.300 Prec@5 99.580 Loss 0.3179
Avg Loading time: 0.0294 seconds
Avg Batch time: 0.0353 seconds

Best acc: 91.300
--------------------------------------------------------------------------------
Test time: 3.3965060710906982

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.038)	BT: 0.013 (0.053)	Loss 0.0076 (0.0058)	Prec@1 100.000 (99.990)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.031)	BT: 0.024 (0.046)	Loss 0.0033 (0.0062)	Prec@1 100.000 (99.980)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.029)	BT: 0.023 (0.044)	Loss 0.0057 (0.0065)	Prec@1 100.000 (99.967)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.028)	BT: 0.010 (0.043)	Loss 0.0055 (0.0065)	Prec@1 100.000 (99.957)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.026)	BT: 0.010 (0.041)	Loss 0.0042 (0.0066)	Prec@1 100.000 (99.952)	
Total train loss: 0.0066
Avg Loading time: 0.0263 seconds
Avg Batch time: 0.0407 seconds

Train time: 16.118431568145752
 * Prec@1 91.250 Prec@5 99.530 Loss 0.3162
Avg Loading time: 0.0414 seconds
Avg Batch time: 0.0486 seconds

Best acc: 91.300
--------------------------------------------------------------------------------
Test time: 4.299091100692749

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.037)	BT: 0.014 (0.049)	Loss 0.0019 (0.0061)	Prec@1 100.000 (99.920)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.117 (0.032)	BT: 0.128 (0.044)	Loss 0.0043 (0.0061)	Prec@1 100.000 (99.925)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.030)	BT: 0.011 (0.043)	Loss 0.0031 (0.0060)	Prec@1 100.000 (99.930)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.029)	BT: 0.012 (0.042)	Loss 0.0057 (0.0060)	Prec@1 100.000 (99.937)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.017 (0.027)	BT: 0.029 (0.041)	Loss 0.0083 (0.0059)	Prec@1 100.000 (99.946)	
Total train loss: 0.0059
Avg Loading time: 0.0274 seconds
Avg Batch time: 0.0409 seconds

Train time: 16.2014262676239
 * Prec@1 91.200 Prec@5 99.500 Loss 0.3201
Avg Loading time: 0.0366 seconds
Avg Batch time: 0.0430 seconds

Best acc: 91.300
--------------------------------------------------------------------------------
Test time: 3.8739471435546875

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.037)	BT: 0.013 (0.052)	Loss 0.0044 (0.0045)	Prec@1 100.000 (99.990)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.214 (0.033)	BT: 0.223 (0.048)	Loss 0.0018 (0.0045)	Prec@1 100.000 (99.985)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.105 (0.030)	BT: 0.116 (0.045)	Loss 0.0066 (0.0046)	Prec@1 100.000 (99.987)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.029)	BT: 0.026 (0.043)	Loss 0.0031 (0.0047)	Prec@1 100.000 (99.982)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.026)	BT: 0.010 (0.040)	Loss 0.0073 (0.0047)	Prec@1 100.000 (99.982)	
Total train loss: 0.0047
Avg Loading time: 0.0264 seconds
Avg Batch time: 0.0404 seconds

Train time: 15.98172640800476
 * Prec@1 91.350 Prec@5 99.540 Loss 0.3242
Avg Loading time: 0.0387 seconds
Avg Batch time: 0.0442 seconds

Best acc: 91.350
--------------------------------------------------------------------------------
Test time: 4.197230339050293

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.035)	BT: 0.023 (0.049)	Loss 0.0024 (0.0044)	Prec@1 100.000 (99.990)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.034)	BT: 0.010 (0.047)	Loss 0.0095 (0.0046)	Prec@1 100.000 (99.980)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.028)	BT: 0.010 (0.041)	Loss 0.0051 (0.0045)	Prec@1 100.000 (99.983)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.001 (0.025)	BT: 0.021 (0.038)	Loss 0.0032 (0.0045)	Prec@1 100.000 (99.977)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.011 (0.025)	BT: 0.023 (0.038)	Loss 0.0035 (0.0044)	Prec@1 100.000 (99.980)	
Total train loss: 0.0044
Avg Loading time: 0.0251 seconds
Avg Batch time: 0.0381 seconds

Train time: 15.162644147872925
 * Prec@1 91.260 Prec@5 99.590 Loss 0.3223
Avg Loading time: 0.0346 seconds
Avg Batch time: 0.0430 seconds

Best acc: 91.350
--------------------------------------------------------------------------------
Test time: 3.8124759197235107

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.078 (0.039)	BT: 0.100 (0.054)	Loss 0.0029 (0.0041)	Prec@1 100.000 (99.990)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.033)	BT: 0.012 (0.047)	Loss 0.0024 (0.0041)	Prec@1 100.000 (99.985)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.033)	BT: 0.013 (0.047)	Loss 0.0025 (0.0041)	Prec@1 100.000 (99.987)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.031)	BT: 0.013 (0.045)	Loss 0.0060 (0.0041)	Prec@1 100.000 (99.985)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.142 (0.030)	BT: 0.151 (0.044)	Loss 0.0045 (0.0042)	Prec@1 100.000 (99.986)	
Total train loss: 0.0042
Avg Loading time: 0.0295 seconds
Avg Batch time: 0.0435 seconds

Train time: 17.240877389907837
 * Prec@1 91.310 Prec@5 99.520 Loss 0.3254
Avg Loading time: 0.0390 seconds
Avg Batch time: 0.0466 seconds

Best acc: 91.350
--------------------------------------------------------------------------------
Test time: 4.149087429046631

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.037)	BT: 0.011 (0.053)	Loss 0.0028 (0.0035)	Prec@1 100.000 (99.990)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.160 (0.035)	BT: 0.172 (0.051)	Loss 0.0046 (0.0035)	Prec@1 100.000 (99.995)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.032)	BT: 0.013 (0.047)	Loss 0.0031 (0.0036)	Prec@1 100.000 (99.993)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.030)	BT: 0.010 (0.045)	Loss 0.0026 (0.0037)	Prec@1 100.000 (99.987)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.029)	BT: 0.009 (0.044)	Loss 0.0028 (0.0036)	Prec@1 100.000 (99.990)	
Total train loss: 0.0036
Avg Loading time: 0.0292 seconds
Avg Batch time: 0.0438 seconds

Train time: 17.331042289733887
 * Prec@1 91.340 Prec@5 99.540 Loss 0.3223
Avg Loading time: 0.0356 seconds
Avg Batch time: 0.0441 seconds

Best acc: 91.350
--------------------------------------------------------------------------------
Test time: 3.965547800064087

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.033)	BT: 0.012 (0.048)	Loss 0.0040 (0.0031)	Prec@1 100.000 (100.000)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.012 (0.040)	Loss 0.0027 (0.0031)	Prec@1 100.000 (100.000)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.021)	BT: 0.010 (0.035)	Loss 0.0047 (0.0032)	Prec@1 100.000 (100.000)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.020)	BT: 0.009 (0.034)	Loss 0.0043 (0.0033)	Prec@1 100.000 (99.997)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.020)	BT: 0.009 (0.035)	Loss 0.0039 (0.0035)	Prec@1 100.000 (99.994)	
Total train loss: 0.0035
Avg Loading time: 0.0204 seconds
Avg Batch time: 0.0346 seconds

Train time: 13.700207233428955
 * Prec@1 91.400 Prec@5 99.520 Loss 0.3225
Avg Loading time: 0.0466 seconds
Avg Batch time: 0.0519 seconds

Best acc: 91.400
--------------------------------------------------------------------------------
Test time: 4.776259183883667

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.026)	BT: 0.008 (0.036)	Loss 0.0039 (0.0035)	Prec@1 100.000 (100.000)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.009 (0.023)	BT: 0.026 (0.034)	Loss 0.0013 (0.0035)	Prec@1 100.000 (99.995)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.217 (0.024)	BT: 0.237 (0.037)	Loss 0.0025 (0.0035)	Prec@1 100.000 (99.997)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.023)	BT: 0.022 (0.036)	Loss 0.0017 (0.0035)	Prec@1 100.000 (99.995)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.023)	BT: 0.022 (0.037)	Loss 0.0020 (0.0035)	Prec@1 100.000 (99.994)	
Total train loss: 0.0035
Avg Loading time: 0.0233 seconds
Avg Batch time: 0.0369 seconds

Train time: 14.63051724433899
 * Prec@1 91.360 Prec@5 99.570 Loss 0.3203
Avg Loading time: 0.0339 seconds
Avg Batch time: 0.0408 seconds

Best acc: 91.400
--------------------------------------------------------------------------------
Test time: 3.6591875553131104

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.046 (0.037)	BT: 0.056 (0.053)	Loss 0.0048 (0.0032)	Prec@1 100.000 (99.990)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.030)	BT: 0.021 (0.045)	Loss 0.0032 (0.0034)	Prec@1 100.000 (99.990)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.028)	BT: 0.019 (0.043)	Loss 0.0039 (0.0034)	Prec@1 100.000 (99.993)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.027)	BT: 0.011 (0.042)	Loss 0.0032 (0.0033)	Prec@1 100.000 (99.995)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.017 (0.041)	Loss 0.0017 (0.0033)	Prec@1 100.000 (99.996)	
Total train loss: 0.0033
Avg Loading time: 0.0257 seconds
Avg Batch time: 0.0409 seconds

Train time: 16.217593908309937
 * Prec@1 91.400 Prec@5 99.590 Loss 0.3213
Avg Loading time: 0.0394 seconds
Avg Batch time: 0.0462 seconds

Best acc: 91.400
--------------------------------------------------------------------------------
Test time: 4.113770484924316

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.038)	BT: 0.016 (0.050)	Loss 0.0022 (0.0033)	Prec@1 100.000 (100.000)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.031)	BT: 0.015 (0.045)	Loss 0.0021 (0.0034)	Prec@1 100.000 (100.000)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.030)	BT: 0.010 (0.045)	Loss 0.0032 (0.0034)	Prec@1 100.000 (99.997)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.028)	BT: 0.014 (0.044)	Loss 0.0020 (0.0034)	Prec@1 100.000 (99.992)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.027)	BT: 0.009 (0.043)	Loss 0.0033 (0.0034)	Prec@1 100.000 (99.994)	
Total train loss: 0.0034
Avg Loading time: 0.0273 seconds
Avg Batch time: 0.0425 seconds

Train time: 16.835976600646973
 * Prec@1 91.260 Prec@5 99.530 Loss 0.3203
Avg Loading time: 0.0415 seconds
Avg Batch time: 0.0485 seconds

Best acc: 91.400
--------------------------------------------------------------------------------
Test time: 4.280678033828735

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.027)	BT: 0.009 (0.039)	Loss 0.0029 (0.0033)	Prec@1 100.000 (99.990)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.013 (0.036)	Loss 0.0022 (0.0033)	Prec@1 100.000 (99.990)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.010 (0.035)	Loss 0.0029 (0.0034)	Prec@1 100.000 (99.987)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.013 (0.036)	Loss 0.0020 (0.0033)	Prec@1 100.000 (99.990)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.009 (0.036)	Loss 0.0065 (0.0033)	Prec@1 100.000 (99.990)	
Total train loss: 0.0033
Avg Loading time: 0.0226 seconds
Avg Batch time: 0.0359 seconds

Train time: 14.27003812789917
 * Prec@1 91.370 Prec@5 99.540 Loss 0.3218
Avg Loading time: 0.0324 seconds
Avg Batch time: 0.0365 seconds

Best acc: 91.400
--------------------------------------------------------------------------------
Test time: 3.276250123977661

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.040)	BT: 0.015 (0.055)	Loss 0.0019 (0.0030)	Prec@1 100.000 (100.000)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.031)	BT: 0.009 (0.047)	Loss 0.0039 (0.0033)	Prec@1 100.000 (99.995)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.028)	BT: 0.009 (0.044)	Loss 0.0040 (0.0033)	Prec@1 100.000 (99.997)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.024 (0.042)	Loss 0.0042 (0.0033)	Prec@1 100.000 (99.997)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.009 (0.041)	Loss 0.0019 (0.0033)	Prec@1 100.000 (99.994)	
Total train loss: 0.0033
Avg Loading time: 0.0257 seconds
Avg Batch time: 0.0411 seconds

Train time: 16.33152174949646
 * Prec@1 91.330 Prec@5 99.530 Loss 0.3218
Avg Loading time: 0.0352 seconds
Avg Batch time: 0.0418 seconds

Best acc: 91.400
--------------------------------------------------------------------------------
Test time: 3.7759323120117188

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.038)	BT: 0.010 (0.051)	Loss 0.0018 (0.0031)	Prec@1 100.000 (99.980)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.032)	BT: 0.009 (0.046)	Loss 0.0031 (0.0032)	Prec@1 100.000 (99.980)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.028)	BT: 0.018 (0.043)	Loss 0.0014 (0.0031)	Prec@1 100.000 (99.987)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.001 (0.027)	BT: 0.020 (0.042)	Loss 0.0025 (0.0031)	Prec@1 100.000 (99.990)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.020 (0.041)	Loss 0.0029 (0.0031)	Prec@1 100.000 (99.992)	
Total train loss: 0.0031
Avg Loading time: 0.0260 seconds
Avg Batch time: 0.0411 seconds

Train time: 16.26236605644226
 * Prec@1 91.410 Prec@5 99.540 Loss 0.3203
Avg Loading time: 0.0434 seconds
Avg Batch time: 0.0519 seconds

Best acc: 91.410
--------------------------------------------------------------------------------
Test time: 4.782630681991577

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.041)	BT: 0.012 (0.056)	Loss 0.0065 (0.0032)	Prec@1 100.000 (100.000)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.031)	BT: 0.010 (0.047)	Loss 0.0020 (0.0032)	Prec@1 100.000 (99.995)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.028)	BT: 0.009 (0.043)	Loss 0.0020 (0.0032)	Prec@1 100.000 (99.993)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.028)	BT: 0.009 (0.042)	Loss 0.0029 (0.0032)	Prec@1 100.000 (99.995)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.072 (0.026)	BT: 0.081 (0.041)	Loss 0.0023 (0.0032)	Prec@1 100.000 (99.994)	
Total train loss: 0.0032
Avg Loading time: 0.0263 seconds
Avg Batch time: 0.0407 seconds

Train time: 16.118215799331665
 * Prec@1 91.350 Prec@5 99.570 Loss 0.3179
Avg Loading time: 0.0330 seconds
Avg Batch time: 0.0379 seconds

Best acc: 91.410
--------------------------------------------------------------------------------
Test time: 3.465212821960449

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.032)	BT: 0.009 (0.045)	Loss 0.0015 (0.0034)	Prec@1 100.000 (99.990)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.029)	BT: 0.032 (0.042)	Loss 0.0013 (0.0035)	Prec@1 100.000 (99.985)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.009 (0.039)	Loss 0.0013 (0.0034)	Prec@1 100.000 (99.990)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.039 (0.024)	BT: 0.049 (0.036)	Loss 0.0024 (0.0034)	Prec@1 100.000 (99.990)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.009 (0.035)	Loss 0.0030 (0.0033)	Prec@1 100.000 (99.992)	
Total train loss: 0.0033
Avg Loading time: 0.0224 seconds
Avg Batch time: 0.0348 seconds

Train time: 13.795803546905518
 * Prec@1 91.420 Prec@5 99.560 Loss 0.3184
Avg Loading time: 0.0437 seconds
Avg Batch time: 0.0508 seconds

Best acc: 91.420
--------------------------------------------------------------------------------
Test time: 4.705942392349243

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.030)	BT: 0.020 (0.046)	Loss 0.0087 (0.0035)	Prec@1 100.000 (100.000)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.183 (0.028)	BT: 0.197 (0.043)	Loss 0.0043 (0.0039)	Prec@1 100.000 (99.970)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.027)	BT: 0.016 (0.043)	Loss 0.0038 (0.0036)	Prec@1 100.000 (99.977)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.020 (0.026)	BT: 0.031 (0.041)	Loss 0.0030 (0.0034)	Prec@1 100.000 (99.982)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.010 (0.041)	Loss 0.0025 (0.0033)	Prec@1 100.000 (99.986)	
Total train loss: 0.0033
Avg Loading time: 0.0257 seconds
Avg Batch time: 0.0408 seconds

Train time: 16.173728942871094
 * Prec@1 91.270 Prec@5 99.560 Loss 0.3262
Avg Loading time: 0.0366 seconds
Avg Batch time: 0.0438 seconds

Best acc: 91.420
--------------------------------------------------------------------------------
Test time: 3.8821558952331543

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.042)	BT: 0.019 (0.056)	Loss 0.0061 (0.0030)	Prec@1 100.000 (100.000)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.033)	BT: 0.019 (0.048)	Loss 0.0055 (0.0032)	Prec@1 100.000 (99.990)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.031)	BT: 0.016 (0.046)	Loss 0.0034 (0.0034)	Prec@1 100.000 (99.980)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.029)	BT: 0.010 (0.045)	Loss 0.0016 (0.0033)	Prec@1 100.000 (99.985)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.003 (0.028)	BT: 0.012 (0.043)	Loss 0.0018 (0.0033)	Prec@1 100.000 (99.988)	
Total train loss: 0.0033
Avg Loading time: 0.0282 seconds
Avg Batch time: 0.0429 seconds

Train time: 16.97679328918457
 * Prec@1 91.170 Prec@5 99.560 Loss 0.3240
Avg Loading time: 0.0436 seconds
Avg Batch time: 0.0530 seconds

Best acc: 91.420
--------------------------------------------------------------------------------
Test time: 4.6363067626953125

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.035)	BT: 0.017 (0.048)	Loss 0.0023 (0.0033)	Prec@1 100.000 (100.000)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.030)	BT: 0.032 (0.045)	Loss 0.0028 (0.0035)	Prec@1 100.000 (99.985)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.027)	BT: 0.018 (0.042)	Loss 0.0020 (0.0034)	Prec@1 100.000 (99.987)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.085 (0.023)	BT: 0.094 (0.037)	Loss 0.0151 (0.0034)	Prec@1 99.219 (99.985)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.010 (0.036)	Loss 0.0032 (0.0034)	Prec@1 100.000 (99.984)	
Total train loss: 0.0034
Avg Loading time: 0.0228 seconds
Avg Batch time: 0.0363 seconds

Train time: 14.45753002166748
 * Prec@1 91.300 Prec@5 99.540 Loss 0.3225
Avg Loading time: 0.0399 seconds
Avg Batch time: 0.0469 seconds

Best acc: 91.420
--------------------------------------------------------------------------------
Test time: 4.142526626586914

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.033)	BT: 0.016 (0.047)	Loss 0.0034 (0.0028)	Prec@1 100.000 (100.000)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.008 (0.036)	Loss 0.0033 (0.0030)	Prec@1 100.000 (99.995)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.022)	BT: 0.010 (0.035)	Loss 0.0017 (0.0030)	Prec@1 100.000 (99.997)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.010 (0.037)	Loss 0.0066 (0.0030)	Prec@1 100.000 (99.997)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.023)	BT: 0.009 (0.036)	Loss 0.0029 (0.0031)	Prec@1 100.000 (99.994)	
Total train loss: 0.0031
Avg Loading time: 0.0226 seconds
Avg Batch time: 0.0363 seconds

Train time: 14.402756690979004
 * Prec@1 91.280 Prec@5 99.590 Loss 0.3191
Avg Loading time: 0.0456 seconds
Avg Batch time: 0.0513 seconds

Best acc: 91.420
--------------------------------------------------------------------------------
Test time: 4.519145250320435

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.033)	BT: 0.016 (0.049)	Loss 0.0025 (0.0034)	Prec@1 100.000 (99.990)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.031)	BT: 0.018 (0.046)	Loss 0.0029 (0.0032)	Prec@1 100.000 (99.995)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.159 (0.028)	BT: 0.173 (0.044)	Loss 0.0053 (0.0032)	Prec@1 100.000 (99.993)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.026)	BT: 0.024 (0.041)	Loss 0.0022 (0.0032)	Prec@1 100.000 (99.995)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.026)	BT: 0.009 (0.041)	Loss 0.0017 (0.0032)	Prec@1 100.000 (99.994)	
Total train loss: 0.0032
Avg Loading time: 0.0256 seconds
Avg Batch time: 0.0410 seconds

Train time: 16.23140287399292
 * Prec@1 91.280 Prec@5 99.570 Loss 0.3225
Avg Loading time: 0.0417 seconds
Avg Batch time: 0.0488 seconds

Best acc: 91.420
--------------------------------------------------------------------------------
Test time: 4.3158392906188965

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.038)	BT: 0.013 (0.052)	Loss 0.0042 (0.0036)	Prec@1 100.000 (99.980)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.032)	BT: 0.015 (0.047)	Loss 0.0020 (0.0036)	Prec@1 100.000 (99.985)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.034)	BT: 0.012 (0.049)	Loss 0.0037 (0.0035)	Prec@1 100.000 (99.990)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.034)	BT: 0.016 (0.048)	Loss 0.0031 (0.0035)	Prec@1 100.000 (99.990)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.113 (0.032)	BT: 0.123 (0.046)	Loss 0.0026 (0.0033)	Prec@1 100.000 (99.992)	
Total train loss: 0.0034
Avg Loading time: 0.0318 seconds
Avg Batch time: 0.0460 seconds

Train time: 18.18286657333374
 * Prec@1 91.250 Prec@5 99.540 Loss 0.3232
Avg Loading time: 0.0522 seconds
Avg Batch time: 0.0587 seconds

Best acc: 91.420
--------------------------------------------------------------------------------
Test time: 5.10455060005188

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.032)	BT: 0.010 (0.045)	Loss 0.0027 (0.0032)	Prec@1 100.000 (99.990)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.031)	BT: 0.014 (0.044)	Loss 0.0016 (0.0030)	Prec@1 100.000 (99.995)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.032)	BT: 0.018 (0.045)	Loss 0.0032 (0.0031)	Prec@1 100.000 (99.997)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.001 (0.030)	BT: 0.019 (0.044)	Loss 0.0021 (0.0031)	Prec@1 100.000 (99.997)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.027)	BT: 0.009 (0.041)	Loss 0.0029 (0.0032)	Prec@1 100.000 (99.996)	
Total train loss: 0.0032
Avg Loading time: 0.0274 seconds
Avg Batch time: 0.0409 seconds

Train time: 16.216277837753296
 * Prec@1 91.320 Prec@5 99.570 Loss 0.3203
Avg Loading time: 0.0353 seconds
Avg Batch time: 0.0422 seconds

Best acc: 91.420
--------------------------------------------------------------------------------
Test time: 3.789578676223755

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.038)	BT: 0.027 (0.053)	Loss 0.0024 (0.0030)	Prec@1 100.000 (100.000)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.001 (0.033)	BT: 0.019 (0.049)	Loss 0.0022 (0.0033)	Prec@1 100.000 (99.995)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.031)	BT: 0.009 (0.047)	Loss 0.0028 (0.0032)	Prec@1 100.000 (99.997)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.031)	BT: 0.011 (0.046)	Loss 0.0024 (0.0032)	Prec@1 100.000 (99.997)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.029)	BT: 0.021 (0.044)	Loss 0.0035 (0.0033)	Prec@1 100.000 (99.996)	
Total train loss: 0.0033
Avg Loading time: 0.0287 seconds
Avg Batch time: 0.0439 seconds

Train time: 17.407239198684692
 * Prec@1 91.330 Prec@5 99.580 Loss 0.3210
Avg Loading time: 0.0463 seconds
Avg Batch time: 0.0521 seconds

Best acc: 91.420
--------------------------------------------------------------------------------
Test time: 4.534459352493286

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.038)	BT: 0.015 (0.055)	Loss 0.0023 (0.0035)	Prec@1 100.000 (99.990)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.036)	BT: 0.010 (0.050)	Loss 0.0036 (0.0033)	Prec@1 100.000 (99.995)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.034)	BT: 0.013 (0.049)	Loss 0.0021 (0.0032)	Prec@1 100.000 (99.997)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.285 (0.034)	BT: 0.295 (0.049)	Loss 0.0033 (0.0032)	Prec@1 100.000 (99.997)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.033)	BT: 0.009 (0.048)	Loss 0.0031 (0.0032)	Prec@1 100.000 (99.998)	
Total train loss: 0.0033
Avg Loading time: 0.0325 seconds
Avg Batch time: 0.0475 seconds

Train time: 18.768743753433228
 * Prec@1 91.250 Prec@5 99.540 Loss 0.3230
Avg Loading time: 0.0443 seconds
Avg Batch time: 0.0511 seconds

Best acc: 91.420
--------------------------------------------------------------------------------
Test time: 4.514275550842285

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.039)	BT: 0.019 (0.054)	Loss 0.0017 (0.0035)	Prec@1 100.000 (99.990)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.036)	BT: 0.015 (0.052)	Loss 0.0023 (0.0033)	Prec@1 100.000 (99.990)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.034)	BT: 0.011 (0.048)	Loss 0.0033 (0.0032)	Prec@1 100.000 (99.993)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.033)	BT: 0.023 (0.047)	Loss 0.0022 (0.0033)	Prec@1 100.000 (99.992)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.033)	BT: 0.009 (0.047)	Loss 0.0026 (0.0033)	Prec@1 100.000 (99.994)	
Total train loss: 0.0033
Avg Loading time: 0.0330 seconds
Avg Batch time: 0.0473 seconds

Train time: 18.691227436065674
 * Prec@1 91.360 Prec@5 99.570 Loss 0.3198
Avg Loading time: 0.0383 seconds
Avg Batch time: 0.0451 seconds

Best acc: 91.420
--------------------------------------------------------------------------------
Test time: 4.205527305603027

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.035)	BT: 0.017 (0.049)	Loss 0.0031 (0.0036)	Prec@1 100.000 (99.980)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.008 (0.032)	BT: 0.038 (0.047)	Loss 0.0013 (0.0034)	Prec@1 100.000 (99.990)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.123 (0.031)	BT: 0.136 (0.045)	Loss 0.0095 (0.0034)	Prec@1 100.000 (99.993)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.029)	BT: 0.018 (0.044)	Loss 0.0023 (0.0034)	Prec@1 100.000 (99.995)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.029)	BT: 0.010 (0.044)	Loss 0.0059 (0.0033)	Prec@1 100.000 (99.994)	
Total train loss: 0.0033
Avg Loading time: 0.0294 seconds
Avg Batch time: 0.0442 seconds

Train time: 17.516523122787476
 * Prec@1 91.440 Prec@5 99.550 Loss 0.3218
Avg Loading time: 0.0447 seconds
Avg Batch time: 0.0518 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 4.759006977081299

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.002 (0.044)	BT: 0.012 (0.058)	Loss 0.0016 (0.0033)	Prec@1 100.000 (99.980)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.037)	BT: 0.019 (0.051)	Loss 0.0029 (0.0033)	Prec@1 100.000 (99.985)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.091 (0.033)	BT: 0.100 (0.047)	Loss 0.0030 (0.0035)	Prec@1 100.000 (99.990)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.034)	BT: 0.014 (0.049)	Loss 0.0051 (0.0035)	Prec@1 100.000 (99.987)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.033)	BT: 0.009 (0.047)	Loss 0.0061 (0.0035)	Prec@1 100.000 (99.988)	
Total train loss: 0.0035
Avg Loading time: 0.0325 seconds
Avg Batch time: 0.0469 seconds

Train time: 18.54402732849121
 * Prec@1 91.430 Prec@5 99.560 Loss 0.3184
Avg Loading time: 0.0474 seconds
Avg Batch time: 0.0548 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 4.760308742523193

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.040)	BT: 0.032 (0.053)	Loss 0.0033 (0.0035)	Prec@1 100.000 (99.990)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.117 (0.033)	BT: 0.127 (0.047)	Loss 0.0019 (0.0035)	Prec@1 100.000 (99.980)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.001 (0.029)	BT: 0.023 (0.043)	Loss 0.0030 (0.0034)	Prec@1 100.000 (99.983)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.027)	BT: 0.010 (0.041)	Loss 0.0040 (0.0034)	Prec@1 100.000 (99.987)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.118 (0.025)	BT: 0.128 (0.039)	Loss 0.0021 (0.0034)	Prec@1 100.000 (99.988)	
Total train loss: 0.0034
Avg Loading time: 0.0252 seconds
Avg Batch time: 0.0392 seconds

Train time: 15.518359422683716
 * Prec@1 91.320 Prec@5 99.570 Loss 0.3203
Avg Loading time: 0.0398 seconds
Avg Batch time: 0.0469 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 4.164928674697876

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.041)	BT: 0.013 (0.055)	Loss 0.0029 (0.0033)	Prec@1 100.000 (100.000)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.030)	BT: 0.009 (0.043)	Loss 0.0029 (0.0031)	Prec@1 100.000 (100.000)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.026)	BT: 0.009 (0.039)	Loss 0.0021 (0.0030)	Prec@1 100.000 (99.997)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.027)	BT: 0.027 (0.040)	Loss 0.0010 (0.0031)	Prec@1 100.000 (99.992)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.025)	BT: 0.010 (0.040)	Loss 0.0014 (0.0031)	Prec@1 100.000 (99.992)	
Total train loss: 0.0031
Avg Loading time: 0.0254 seconds
Avg Batch time: 0.0398 seconds

Train time: 15.788381576538086
 * Prec@1 91.390 Prec@5 99.570 Loss 0.3191
Avg Loading time: 0.0431 seconds
Avg Batch time: 0.0506 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 4.485702753067017

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.035)	BT: 0.031 (0.051)	Loss 0.0043 (0.0032)	Prec@1 100.000 (99.990)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.031)	BT: 0.016 (0.047)	Loss 0.0029 (0.0033)	Prec@1 100.000 (99.985)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.029)	BT: 0.020 (0.045)	Loss 0.0034 (0.0032)	Prec@1 100.000 (99.990)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.233 (0.028)	BT: 0.246 (0.044)	Loss 0.0010 (0.0032)	Prec@1 100.000 (99.992)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.027)	BT: 0.017 (0.043)	Loss 0.0038 (0.0033)	Prec@1 100.000 (99.992)	
Total train loss: 0.0033
Avg Loading time: 0.0272 seconds
Avg Batch time: 0.0431 seconds

Train time: 17.052724361419678
 * Prec@1 91.340 Prec@5 99.590 Loss 0.3196
Avg Loading time: 0.0446 seconds
Avg Batch time: 0.0510 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 4.471325635910034

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.205 (0.046)	BT: 0.228 (0.061)	Loss 0.0017 (0.0035)	Prec@1 100.000 (99.980)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.036)	BT: 0.010 (0.051)	Loss 0.0028 (0.0035)	Prec@1 100.000 (99.990)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.035)	BT: 0.012 (0.050)	Loss 0.0048 (0.0033)	Prec@1 100.000 (99.993)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.034)	BT: 0.013 (0.049)	Loss 0.0018 (0.0033)	Prec@1 100.000 (99.995)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.033)	BT: 0.025 (0.049)	Loss 0.0020 (0.0032)	Prec@1 100.000 (99.996)	
Total train loss: 0.0032
Avg Loading time: 0.0331 seconds
Avg Batch time: 0.0485 seconds

Train time: 19.176445722579956
 * Prec@1 91.330 Prec@5 99.540 Loss 0.3215
Avg Loading time: 0.0406 seconds
Avg Batch time: 0.0484 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 4.2804036140441895

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.041 (0.033)	BT: 0.051 (0.045)	Loss 0.0014 (0.0031)	Prec@1 100.000 (100.000)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.012 (0.030)	BT: 0.022 (0.042)	Loss 0.0025 (0.0032)	Prec@1 100.000 (99.995)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.028)	BT: 0.011 (0.042)	Loss 0.0026 (0.0033)	Prec@1 100.000 (99.997)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.027)	BT: 0.014 (0.040)	Loss 0.0030 (0.0033)	Prec@1 100.000 (99.995)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.024)	BT: 0.009 (0.037)	Loss 0.0025 (0.0033)	Prec@1 100.000 (99.996)	
Total train loss: 0.0034
Avg Loading time: 0.0239 seconds
Avg Batch time: 0.0373 seconds

Train time: 14.72135615348816
 * Prec@1 91.320 Prec@5 99.560 Loss 0.3225
Avg Loading time: 0.0311 seconds
Avg Batch time: 0.0365 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 3.3687825202941895

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.038)	BT: 0.009 (0.052)	Loss 0.0013 (0.0029)	Prec@1 100.000 (99.980)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.032)	BT: 0.021 (0.047)	Loss 0.0017 (0.0031)	Prec@1 100.000 (99.985)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.029)	BT: 0.010 (0.044)	Loss 0.0088 (0.0032)	Prec@1 100.000 (99.990)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.027)	BT: 0.014 (0.042)	Loss 0.0014 (0.0032)	Prec@1 100.000 (99.990)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.027)	BT: 0.011 (0.042)	Loss 0.0023 (0.0032)	Prec@1 100.000 (99.990)	
Total train loss: 0.0032
Avg Loading time: 0.0266 seconds
Avg Batch time: 0.0415 seconds

Train time: 16.427406311035156
 * Prec@1 91.330 Prec@5 99.560 Loss 0.3220
Avg Loading time: 0.0458 seconds
Avg Batch time: 0.0530 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 4.600175857543945

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.038)	BT: 0.010 (0.052)	Loss 0.0025 (0.0032)	Prec@1 100.000 (100.000)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.032)	BT: 0.010 (0.047)	Loss 0.0024 (0.0030)	Prec@1 100.000 (99.995)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.031)	BT: 0.019 (0.046)	Loss 0.0012 (0.0031)	Prec@1 100.000 (99.997)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.031)	BT: 0.028 (0.046)	Loss 0.0023 (0.0031)	Prec@1 100.000 (99.992)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.030)	BT: 0.010 (0.045)	Loss 0.0030 (0.0032)	Prec@1 100.000 (99.992)	
Total train loss: 0.0032
Avg Loading time: 0.0295 seconds
Avg Batch time: 0.0446 seconds

Train time: 17.634258270263672
 * Prec@1 91.310 Prec@5 99.570 Loss 0.3257
Avg Loading time: 0.0391 seconds
Avg Batch time: 0.0473 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 4.188672304153442

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.214 (0.041)	BT: 0.227 (0.055)	Loss 0.0029 (0.0030)	Prec@1 100.000 (100.000)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.035)	BT: 0.031 (0.048)	Loss 0.0072 (0.0034)	Prec@1 100.000 (99.985)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.032)	BT: 0.020 (0.046)	Loss 0.0015 (0.0035)	Prec@1 100.000 (99.987)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.028)	BT: 0.010 (0.042)	Loss 0.0036 (0.0034)	Prec@1 100.000 (99.985)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.025)	BT: 0.009 (0.039)	Loss 0.0039 (0.0033)	Prec@1 100.000 (99.988)	
Total train loss: 0.0033
Avg Loading time: 0.0251 seconds
Avg Batch time: 0.0385 seconds

Train time: 15.194024562835693
 * Prec@1 91.300 Prec@5 99.550 Loss 0.3215
Avg Loading time: 0.0454 seconds
Avg Batch time: 0.0520 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 4.509222745895386

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.036)	BT: 0.010 (0.050)	Loss 0.0020 (0.0035)	Prec@1 100.000 (99.990)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.028)	BT: 0.009 (0.041)	Loss 0.0045 (0.0035)	Prec@1 100.000 (99.990)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.010 (0.036)	Loss 0.0022 (0.0036)	Prec@1 100.000 (99.983)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.024)	BT: 0.012 (0.036)	Loss 0.0047 (0.0036)	Prec@1 100.000 (99.985)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.024)	BT: 0.010 (0.037)	Loss 0.0024 (0.0035)	Prec@1 100.000 (99.984)	
Total train loss: 0.0035
Avg Loading time: 0.0243 seconds
Avg Batch time: 0.0372 seconds

Train time: 14.76732063293457
 * Prec@1 91.220 Prec@5 99.570 Loss 0.3232
Avg Loading time: 0.0393 seconds
Avg Batch time: 0.0455 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 4.058002233505249

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.043)	BT: 0.014 (0.058)	Loss 0.0049 (0.0033)	Prec@1 100.000 (99.990)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.034)	BT: 0.013 (0.049)	Loss 0.0037 (0.0033)	Prec@1 100.000 (99.990)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.186 (0.030)	BT: 0.221 (0.046)	Loss 0.0047 (0.0032)	Prec@1 100.000 (99.993)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.029)	BT: 0.049 (0.044)	Loss 0.0012 (0.0032)	Prec@1 100.000 (99.992)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.028)	BT: 0.011 (0.043)	Loss 0.0045 (0.0032)	Prec@1 100.000 (99.992)	
Total train loss: 0.0032
Avg Loading time: 0.0281 seconds
Avg Batch time: 0.0433 seconds

Train time: 17.126862049102783
 * Prec@1 91.380 Prec@5 99.520 Loss 0.3230
Avg Loading time: 0.0404 seconds
Avg Batch time: 0.0469 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 4.152235507965088

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.035)	BT: 0.009 (0.049)	Loss 0.0025 (0.0031)	Prec@1 100.000 (99.990)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.040 (0.030)	BT: 0.057 (0.044)	Loss 0.0015 (0.0034)	Prec@1 100.000 (99.990)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.090 (0.028)	BT: 0.100 (0.042)	Loss 0.0017 (0.0032)	Prec@1 100.000 (99.993)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.027)	BT: 0.009 (0.041)	Loss 0.0034 (0.0031)	Prec@1 100.000 (99.995)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.027)	BT: 0.009 (0.041)	Loss 0.0027 (0.0031)	Prec@1 100.000 (99.994)	
Total train loss: 0.0031
Avg Loading time: 0.0268 seconds
Avg Batch time: 0.0407 seconds

Train time: 16.161550998687744
 * Prec@1 91.350 Prec@5 99.560 Loss 0.3245
Avg Loading time: 0.0352 seconds
Avg Batch time: 0.0408 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 3.6647303104400635


      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 0
          frozen_layers: 17
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 0
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/train/relu17
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/test/relu17
ResNet18(
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 4.830 Prec@5 41.040 Loss 2.3613
Avg Loading time: 0.0582 seconds
Avg Batch time: 0.0723 seconds

Pre-trained Prec@1 with 17 layers frozen: 4.829999923706055 	 Loss: 2.361328125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.670 (0.651)	BT: 0.679 (0.658)	Loss 0.6953 (0.9826)	Prec@1 80.469 (68.810)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (0.695)	BT: 0.003 (0.703)	Loss 0.5708 (0.8366)	Prec@1 77.344 (72.616)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.517 (0.711)	BT: 0.527 (0.719)	Loss 0.7588 (0.7775)	Prec@1 70.312 (74.129)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (0.711)	BT: 0.004 (0.719)	Loss 0.4692 (0.7425)	Prec@1 82.812 (75.215)	
Epoch: [0][389/391]	LR: 0.1	DT: 1.593 (0.725)	BT: 1.604 (0.733)	Loss 0.5513 (0.7156)	Prec@1 80.469 (75.992)	
Total train loss: 0.7155
Avg Loading time: 0.7235 seconds
Avg Batch time: 0.7314 seconds

Train time: 286.101202249527
 * Prec@1 79.110 Prec@5 99.010 Loss 0.6055
Avg Loading time: 0.3111 seconds
Avg Batch time: 0.3154 seconds

Best acc: 79.110
--------------------------------------------------------------------------------
Test time: 25.05954098701477

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.174)	BT: 0.004 (0.181)	Loss 0.5923 (0.5950)	Prec@1 82.812 (79.497)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.166)	BT: 0.004 (0.172)	Loss 0.6509 (0.5902)	Prec@1 78.906 (79.908)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.064 (0.164)	BT: 0.075 (0.171)	Loss 0.5200 (0.5888)	Prec@1 83.594 (79.861)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.037 (0.152)	BT: 0.042 (0.159)	Loss 0.5688 (0.5869)	Prec@1 76.562 (79.920)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.089 (0.129)	BT: 0.093 (0.136)	Loss 0.5825 (0.5857)	Prec@1 82.031 (79.890)	
Total train loss: 0.5856
Avg Loading time: 0.1286 seconds
Avg Batch time: 0.1352 seconds

Train time: 53.00847005844116
 * Prec@1 79.930 Prec@5 99.170 Loss 0.5801
Avg Loading time: 0.0461 seconds
Avg Batch time: 0.0524 seconds

Best acc: 79.930
--------------------------------------------------------------------------------
Test time: 4.325676679611206

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.031)	BT: 0.004 (0.036)	Loss 0.6104 (0.5528)	Prec@1 77.344 (80.980)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.037)	BT: 0.009 (0.042)	Loss 0.5317 (0.5680)	Prec@1 85.938 (80.794)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.262 (0.040)	BT: 0.268 (0.047)	Loss 0.4932 (0.5647)	Prec@1 82.031 (80.716)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.040)	BT: 0.004 (0.047)	Loss 0.6216 (0.5660)	Prec@1 82.812 (80.652)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.040)	BT: 0.004 (0.047)	Loss 0.6626 (0.5670)	Prec@1 78.125 (80.605)	
Total train loss: 0.5672
Avg Loading time: 0.0396 seconds
Avg Batch time: 0.0472 seconds

Train time: 18.695873022079468
 * Prec@1 80.280 Prec@5 99.170 Loss 0.5723
Avg Loading time: 0.0476 seconds
Avg Batch time: 0.0542 seconds

Best acc: 80.280
--------------------------------------------------------------------------------
Test time: 4.535316467285156

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.046)	BT: 0.006 (0.055)	Loss 0.4988 (0.5347)	Prec@1 84.375 (81.811)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.038)	BT: 0.006 (0.048)	Loss 0.5010 (0.5419)	Prec@1 82.812 (81.571)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.059 (0.033)	BT: 0.063 (0.042)	Loss 0.4609 (0.5452)	Prec@1 83.594 (81.320)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.035)	BT: 0.017 (0.044)	Loss 0.3416 (0.5531)	Prec@1 89.062 (80.997)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.032)	BT: 0.005 (0.041)	Loss 0.6709 (0.5549)	Prec@1 77.344 (80.859)	
Total train loss: 0.5549
Avg Loading time: 0.0323 seconds
Avg Batch time: 0.0405 seconds

Train time: 15.988795518875122
 * Prec@1 79.920 Prec@5 99.220 Loss 0.5728
Avg Loading time: 0.0526 seconds
Avg Batch time: 0.0598 seconds

Best acc: 80.280
--------------------------------------------------------------------------------
Test time: 4.956303119659424

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.047)	BT: 0.006 (0.056)	Loss 0.6499 (0.5542)	Prec@1 78.906 (80.619)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.044)	BT: 0.004 (0.052)	Loss 0.4189 (0.5445)	Prec@1 85.156 (81.100)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.042)	BT: 0.005 (0.051)	Loss 0.7007 (0.5464)	Prec@1 78.906 (81.053)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.002 (0.040)	BT: 0.010 (0.049)	Loss 0.5684 (0.5458)	Prec@1 80.469 (80.987)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.040)	BT: 0.005 (0.049)	Loss 0.6631 (0.5473)	Prec@1 79.688 (80.976)	
Total train loss: 0.5474
Avg Loading time: 0.0398 seconds
Avg Batch time: 0.0489 seconds

Train time: 19.336464405059814
 * Prec@1 80.470 Prec@5 99.190 Loss 0.5596
Avg Loading time: 0.0422 seconds
Avg Batch time: 0.0469 seconds

Best acc: 80.470
--------------------------------------------------------------------------------
Test time: 3.877578020095825

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.042)	BT: 0.006 (0.051)	Loss 0.5947 (0.5322)	Prec@1 79.688 (81.661)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.034)	BT: 0.004 (0.043)	Loss 0.4985 (0.5458)	Prec@1 77.344 (81.260)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.242 (0.032)	BT: 0.247 (0.041)	Loss 0.4758 (0.5388)	Prec@1 83.594 (81.444)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.031)	BT: 0.011 (0.040)	Loss 0.5010 (0.5419)	Prec@1 82.812 (81.278)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.031)	BT: 0.008 (0.041)	Loss 0.6831 (0.5434)	Prec@1 73.438 (81.252)	
Total train loss: 0.5433
Avg Loading time: 0.0313 seconds
Avg Batch time: 0.0407 seconds

Train time: 16.12609052658081
 * Prec@1 81.160 Prec@5 99.280 Loss 0.5513
Avg Loading time: 0.0454 seconds
Avg Batch time: 0.0522 seconds

Best acc: 81.160
--------------------------------------------------------------------------------
Test time: 4.38160252571106

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.055)	BT: 0.005 (0.064)	Loss 0.4231 (0.5352)	Prec@1 82.812 (81.050)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.046)	BT: 0.015 (0.055)	Loss 0.6074 (0.5362)	Prec@1 83.594 (81.245)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.045)	BT: 0.005 (0.054)	Loss 0.6387 (0.5356)	Prec@1 79.688 (81.424)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.041)	BT: 0.004 (0.050)	Loss 0.5117 (0.5379)	Prec@1 83.594 (81.283)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.038)	BT: 0.008 (0.047)	Loss 0.5571 (0.5413)	Prec@1 78.906 (81.066)	
Total train loss: 0.5416
Avg Loading time: 0.0381 seconds
Avg Batch time: 0.0465 seconds

Train time: 18.36987805366516
 * Prec@1 81.320 Prec@5 99.200 Loss 0.5474
Avg Loading time: 0.0398 seconds
Avg Batch time: 0.0465 seconds

Best acc: 81.320
--------------------------------------------------------------------------------
Test time: 4.000736474990845

Epoch: [7][77/391]	LR: 0.1	DT: 0.030 (0.045)	BT: 0.038 (0.056)	Loss 0.6299 (0.5281)	Prec@1 76.562 (81.881)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.044)	BT: 0.004 (0.055)	Loss 0.4766 (0.5304)	Prec@1 85.938 (81.631)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.323 (0.044)	BT: 0.329 (0.054)	Loss 0.6938 (0.5329)	Prec@1 81.250 (81.691)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.040)	BT: 0.012 (0.051)	Loss 0.5513 (0.5336)	Prec@1 79.688 (81.658)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.039)	BT: 0.012 (0.050)	Loss 0.4968 (0.5371)	Prec@1 85.156 (81.504)	
Total train loss: 0.5370
Avg Loading time: 0.0390 seconds
Avg Batch time: 0.0494 seconds

Train time: 19.526768445968628
 * Prec@1 81.280 Prec@5 99.310 Loss 0.5513
Avg Loading time: 0.0420 seconds
Avg Batch time: 0.0499 seconds

Best acc: 81.320
--------------------------------------------------------------------------------
Test time: 4.210299015045166

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.045)	BT: 0.009 (0.056)	Loss 0.3501 (0.5445)	Prec@1 86.719 (80.719)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.032)	BT: 0.005 (0.042)	Loss 0.6191 (0.5362)	Prec@1 75.781 (81.375)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.270 (0.034)	BT: 0.277 (0.044)	Loss 0.6709 (0.5325)	Prec@1 76.562 (81.634)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.031)	BT: 0.004 (0.040)	Loss 0.4519 (0.5303)	Prec@1 87.500 (81.711)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.097 (0.032)	BT: 0.101 (0.040)	Loss 0.6221 (0.5321)	Prec@1 77.344 (81.647)	
Total train loss: 0.5323
Avg Loading time: 0.0316 seconds
Avg Batch time: 0.0403 seconds

Train time: 15.9881751537323
 * Prec@1 81.040 Prec@5 99.310 Loss 0.5537
Avg Loading time: 0.0453 seconds
Avg Batch time: 0.0521 seconds

Best acc: 81.320
--------------------------------------------------------------------------------
Test time: 4.374173164367676

Epoch: [9][77/391]	LR: 0.1	DT: 0.014 (0.044)	BT: 0.023 (0.055)	Loss 0.5522 (0.5266)	Prec@1 77.344 (82.041)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.015 (0.039)	BT: 0.021 (0.050)	Loss 0.4812 (0.5332)	Prec@1 85.938 (81.711)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.039)	BT: 0.011 (0.050)	Loss 0.4680 (0.5289)	Prec@1 86.719 (81.878)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.038)	BT: 0.020 (0.049)	Loss 0.5806 (0.5292)	Prec@1 82.031 (81.831)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.123 (0.038)	BT: 0.128 (0.048)	Loss 0.6113 (0.5279)	Prec@1 82.031 (81.857)	
Total train loss: 0.5282
Avg Loading time: 0.0378 seconds
Avg Batch time: 0.0483 seconds

Train time: 19.12832546234131
 * Prec@1 81.100 Prec@5 99.140 Loss 0.5552
Avg Loading time: 0.0349 seconds
Avg Batch time: 0.0393 seconds

Best acc: 81.320
--------------------------------------------------------------------------------
Test time: 3.27337908744812

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.041)	BT: 0.013 (0.051)	Loss 0.4111 (0.5101)	Prec@1 89.062 (82.412)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.132 (0.030)	BT: 0.142 (0.040)	Loss 0.4211 (0.5007)	Prec@1 85.938 (82.752)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.029)	BT: 0.005 (0.039)	Loss 0.4785 (0.5016)	Prec@1 85.156 (82.696)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.031)	BT: 0.010 (0.041)	Loss 0.4033 (0.5019)	Prec@1 84.375 (82.692)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.022 (0.031)	BT: 0.032 (0.041)	Loss 0.5566 (0.5002)	Prec@1 78.906 (82.808)	
Total train loss: 0.5002
Avg Loading time: 0.0307 seconds
Avg Batch time: 0.0405 seconds

Train time: 16.053077936172485
 * Prec@1 81.890 Prec@5 99.280 Loss 0.5322
Avg Loading time: 0.0499 seconds
Avg Batch time: 0.0565 seconds

Best acc: 81.890
--------------------------------------------------------------------------------
Test time: 4.701013565063477

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.013 (0.045)	BT: 0.017 (0.055)	Loss 0.5200 (0.4885)	Prec@1 83.594 (83.363)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.045)	BT: 0.012 (0.054)	Loss 0.5317 (0.4908)	Prec@1 82.812 (83.073)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.041)	BT: 0.009 (0.050)	Loss 0.5317 (0.4897)	Prec@1 80.469 (83.176)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.037)	BT: 0.003 (0.046)	Loss 0.5044 (0.4934)	Prec@1 83.594 (83.025)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.035)	BT: 0.005 (0.043)	Loss 0.5352 (0.4975)	Prec@1 80.469 (82.937)	
Total train loss: 0.4972
Avg Loading time: 0.0345 seconds
Avg Batch time: 0.0431 seconds

Train time: 17.042609930038452
 * Prec@1 81.870 Prec@5 99.330 Loss 0.5337
Avg Loading time: 0.0331 seconds
Avg Batch time: 0.0412 seconds

Best acc: 81.890
--------------------------------------------------------------------------------
Test time: 3.59989595413208

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.039)	BT: 0.008 (0.048)	Loss 0.4858 (0.4869)	Prec@1 84.375 (83.153)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.036)	BT: 0.009 (0.046)	Loss 0.6147 (0.4908)	Prec@1 78.906 (83.183)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.035)	BT: 0.011 (0.045)	Loss 0.3621 (0.4935)	Prec@1 85.938 (83.056)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.034)	BT: 0.010 (0.045)	Loss 0.3787 (0.4920)	Prec@1 85.938 (83.043)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.033)	BT: 0.004 (0.044)	Loss 0.4561 (0.4942)	Prec@1 84.375 (82.953)	
Total train loss: 0.4943
Avg Loading time: 0.0330 seconds
Avg Batch time: 0.0439 seconds

Train time: 17.405524492263794
 * Prec@1 81.830 Prec@5 99.290 Loss 0.5288
Avg Loading time: 0.0495 seconds
Avg Batch time: 0.0552 seconds

Best acc: 81.890
--------------------------------------------------------------------------------
Test time: 4.6124677658081055

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.048)	BT: 0.005 (0.057)	Loss 0.4917 (0.5013)	Prec@1 82.031 (82.762)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.036)	BT: 0.005 (0.045)	Loss 0.6211 (0.4946)	Prec@1 81.250 (82.988)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.180 (0.032)	BT: 0.189 (0.041)	Loss 0.5967 (0.4962)	Prec@1 79.688 (82.866)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.032)	BT: 0.004 (0.040)	Loss 0.5312 (0.4989)	Prec@1 83.594 (82.810)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.029)	BT: 0.006 (0.037)	Loss 0.4380 (0.4939)	Prec@1 84.375 (82.951)	
Total train loss: 0.4939
Avg Loading time: 0.0287 seconds
Avg Batch time: 0.0370 seconds

Train time: 14.66219687461853
 * Prec@1 82.060 Prec@5 99.280 Loss 0.5312
Avg Loading time: 0.0443 seconds
Avg Batch time: 0.0518 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.346057176589966

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.050)	BT: 0.005 (0.059)	Loss 0.4207 (0.4846)	Prec@1 85.938 (82.893)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.015 (0.043)	BT: 0.039 (0.053)	Loss 0.5347 (0.4934)	Prec@1 81.250 (82.848)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.034 (0.039)	BT: 0.048 (0.050)	Loss 0.5024 (0.4928)	Prec@1 82.031 (82.893)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.037)	BT: 0.017 (0.048)	Loss 0.4258 (0.4912)	Prec@1 86.719 (82.933)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.036)	BT: 0.012 (0.046)	Loss 0.5142 (0.4907)	Prec@1 82.031 (82.961)	
Total train loss: 0.4911
Avg Loading time: 0.0359 seconds
Avg Batch time: 0.0463 seconds

Train time: 18.350831270217896
 * Prec@1 81.960 Prec@5 99.260 Loss 0.5303
Avg Loading time: 0.0480 seconds
Avg Batch time: 0.0532 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.4275963306427

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.027 (0.030)	BT: 0.033 (0.036)	Loss 0.4094 (0.4889)	Prec@1 84.375 (83.303)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.123 (0.032)	BT: 0.151 (0.040)	Loss 0.5420 (0.4883)	Prec@1 82.031 (83.198)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.046 (0.029)	BT: 0.051 (0.036)	Loss 0.4949 (0.4907)	Prec@1 82.031 (83.076)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.028)	BT: 0.007 (0.035)	Loss 0.3936 (0.4902)	Prec@1 84.375 (83.078)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.017 (0.030)	BT: 0.022 (0.037)	Loss 0.4080 (0.4930)	Prec@1 83.594 (83.001)	
Total train loss: 0.4930
Avg Loading time: 0.0299 seconds
Avg Batch time: 0.0370 seconds

Train time: 14.720550537109375
 * Prec@1 81.910 Prec@5 99.380 Loss 0.5361
Avg Loading time: 0.0501 seconds
Avg Batch time: 0.0578 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.797616720199585

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.046)	BT: 0.006 (0.055)	Loss 0.5659 (0.4995)	Prec@1 79.688 (82.853)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.039)	BT: 0.007 (0.049)	Loss 0.5225 (0.5046)	Prec@1 80.469 (82.622)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.034)	BT: 0.004 (0.044)	Loss 0.5806 (0.5028)	Prec@1 80.469 (82.619)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.035)	BT: 0.026 (0.045)	Loss 0.4968 (0.4994)	Prec@1 78.906 (82.742)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.035)	BT: 0.004 (0.045)	Loss 0.5566 (0.4948)	Prec@1 82.031 (82.981)	
Total train loss: 0.4947
Avg Loading time: 0.0352 seconds
Avg Batch time: 0.0451 seconds

Train time: 17.869813680648804
 * Prec@1 81.840 Prec@5 99.230 Loss 0.5322
Avg Loading time: 0.0469 seconds
Avg Batch time: 0.0512 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.272220134735107

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.030)	BT: 0.005 (0.037)	Loss 0.5190 (0.4842)	Prec@1 87.500 (83.564)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.030)	BT: 0.008 (0.037)	Loss 0.5288 (0.4859)	Prec@1 80.469 (83.383)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.034)	BT: 0.004 (0.041)	Loss 0.4319 (0.4909)	Prec@1 85.156 (83.043)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.034)	BT: 0.007 (0.042)	Loss 0.4675 (0.4950)	Prec@1 85.156 (82.868)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.042 (0.033)	BT: 0.048 (0.042)	Loss 0.4949 (0.4954)	Prec@1 84.375 (82.871)	
Total train loss: 0.4954
Avg Loading time: 0.0332 seconds
Avg Batch time: 0.0417 seconds

Train time: 16.545056104660034
 * Prec@1 82.000 Prec@5 99.290 Loss 0.5312
Avg Loading time: 0.0460 seconds
Avg Batch time: 0.0538 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.4518141746521

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.149 (0.048)	BT: 0.160 (0.056)	Loss 0.4971 (0.4880)	Prec@1 81.250 (82.973)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.042)	BT: 0.006 (0.051)	Loss 0.5962 (0.4912)	Prec@1 80.469 (82.888)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.036)	BT: 0.006 (0.045)	Loss 0.4075 (0.4890)	Prec@1 89.062 (83.123)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.033)	BT: 0.007 (0.041)	Loss 0.6396 (0.4917)	Prec@1 77.344 (83.065)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.093 (0.033)	BT: 0.097 (0.041)	Loss 0.5840 (0.4924)	Prec@1 83.594 (83.023)	
Total train loss: 0.4922
Avg Loading time: 0.0326 seconds
Avg Batch time: 0.0410 seconds

Train time: 16.270628690719604
 * Prec@1 81.770 Prec@5 99.350 Loss 0.5317
Avg Loading time: 0.0318 seconds
Avg Batch time: 0.0357 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 3.0387489795684814

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.047)	BT: 0.005 (0.056)	Loss 0.5176 (0.4901)	Prec@1 79.688 (82.973)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.041)	BT: 0.009 (0.049)	Loss 0.4858 (0.4912)	Prec@1 78.906 (83.133)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.039)	BT: 0.007 (0.048)	Loss 0.4436 (0.4930)	Prec@1 82.031 (83.016)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.001 (0.037)	BT: 0.020 (0.046)	Loss 0.4514 (0.4936)	Prec@1 85.938 (82.955)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.036)	BT: 0.004 (0.045)	Loss 0.5244 (0.4921)	Prec@1 82.812 (82.959)	
Total train loss: 0.4925
Avg Loading time: 0.0363 seconds
Avg Batch time: 0.0452 seconds

Train time: 17.907719373703003
 * Prec@1 81.710 Prec@5 99.330 Loss 0.5327
Avg Loading time: 0.0590 seconds
Avg Batch time: 0.0663 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 5.457459211349487

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.041)	BT: 0.004 (0.048)	Loss 0.4973 (0.4906)	Prec@1 83.594 (83.253)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.033)	BT: 0.004 (0.040)	Loss 0.6929 (0.4864)	Prec@1 72.656 (83.263)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.101 (0.035)	BT: 0.117 (0.042)	Loss 0.4702 (0.4859)	Prec@1 82.812 (83.250)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.030)	BT: 0.004 (0.037)	Loss 0.4260 (0.4827)	Prec@1 84.375 (83.373)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.030)	BT: 0.005 (0.036)	Loss 0.5737 (0.4836)	Prec@1 78.125 (83.325)	
Total train loss: 0.4835
Avg Loading time: 0.0296 seconds
Avg Batch time: 0.0362 seconds

Train time: 14.408003330230713
 * Prec@1 81.980 Prec@5 99.360 Loss 0.5298
Avg Loading time: 0.0500 seconds
Avg Batch time: 0.0560 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.674943685531616

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.048)	BT: 0.008 (0.058)	Loss 0.3687 (0.4766)	Prec@1 87.500 (83.984)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.040)	BT: 0.004 (0.049)	Loss 0.4500 (0.4756)	Prec@1 81.250 (84.034)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.037)	BT: 0.008 (0.048)	Loss 0.5195 (0.4813)	Prec@1 83.594 (83.754)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.039 (0.034)	BT: 0.045 (0.045)	Loss 0.3748 (0.4807)	Prec@1 85.156 (83.669)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.034)	BT: 0.005 (0.044)	Loss 0.4983 (0.4829)	Prec@1 83.594 (83.566)	
Total train loss: 0.4831
Avg Loading time: 0.0338 seconds
Avg Batch time: 0.0443 seconds

Train time: 17.565762758255005
 * Prec@1 81.930 Prec@5 99.320 Loss 0.5303
Avg Loading time: 0.0405 seconds
Avg Batch time: 0.0463 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 3.8280386924743652

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.049)	BT: 0.017 (0.056)	Loss 0.3582 (0.4808)	Prec@1 89.844 (83.323)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.035)	BT: 0.004 (0.043)	Loss 0.4702 (0.4840)	Prec@1 84.375 (83.153)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.030)	BT: 0.004 (0.038)	Loss 0.4421 (0.4806)	Prec@1 82.812 (83.313)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.031)	BT: 0.010 (0.039)	Loss 0.5200 (0.4823)	Prec@1 84.375 (83.281)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.032)	BT: 0.009 (0.040)	Loss 0.5220 (0.4827)	Prec@1 82.812 (83.239)	
Total train loss: 0.4827
Avg Loading time: 0.0316 seconds
Avg Batch time: 0.0396 seconds

Train time: 15.70208215713501
 * Prec@1 81.900 Prec@5 99.290 Loss 0.5288
Avg Loading time: 0.0466 seconds
Avg Batch time: 0.0525 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.380312919616699

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.046)	BT: 0.020 (0.054)	Loss 0.3828 (0.4821)	Prec@1 85.938 (83.303)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.342 (0.041)	BT: 0.348 (0.050)	Loss 0.4790 (0.4773)	Prec@1 84.375 (83.413)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.037)	BT: 0.005 (0.047)	Loss 0.4619 (0.4782)	Prec@1 85.938 (83.247)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.038)	BT: 0.005 (0.047)	Loss 0.4170 (0.4790)	Prec@1 85.938 (83.261)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.034)	BT: 0.004 (0.043)	Loss 0.3833 (0.4807)	Prec@1 85.156 (83.291)	
Total train loss: 0.4810
Avg Loading time: 0.0338 seconds
Avg Batch time: 0.0426 seconds

Train time: 16.83956289291382
 * Prec@1 81.880 Prec@5 99.350 Loss 0.5288
Avg Loading time: 0.0474 seconds
Avg Batch time: 0.0536 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.431265115737915

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.053 (0.029)	BT: 0.057 (0.034)	Loss 0.4985 (0.4871)	Prec@1 83.594 (83.113)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.032)	BT: 0.025 (0.039)	Loss 0.5229 (0.4848)	Prec@1 82.031 (83.143)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.322 (0.033)	BT: 0.328 (0.041)	Loss 0.4194 (0.4897)	Prec@1 87.500 (83.056)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.001 (0.034)	BT: 0.014 (0.043)	Loss 0.4438 (0.4840)	Prec@1 85.156 (83.281)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.051 (0.035)	BT: 0.059 (0.043)	Loss 0.4177 (0.4827)	Prec@1 85.938 (83.397)	
Total train loss: 0.4825
Avg Loading time: 0.0346 seconds
Avg Batch time: 0.0429 seconds

Train time: 17.030758380889893
 * Prec@1 81.820 Prec@5 99.340 Loss 0.5298
Avg Loading time: 0.0495 seconds
Avg Batch time: 0.0561 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.6663453578948975

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.047)	BT: 0.009 (0.057)	Loss 0.5591 (0.4908)	Prec@1 79.688 (82.983)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.039)	BT: 0.012 (0.049)	Loss 0.4141 (0.4821)	Prec@1 85.938 (83.143)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.032)	BT: 0.005 (0.041)	Loss 0.5723 (0.4839)	Prec@1 78.906 (83.360)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.285 (0.033)	BT: 0.296 (0.042)	Loss 0.3647 (0.4826)	Prec@1 88.281 (83.293)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.030)	BT: 0.005 (0.039)	Loss 0.5586 (0.4825)	Prec@1 79.688 (83.365)	
Total train loss: 0.4823
Avg Loading time: 0.0303 seconds
Avg Batch time: 0.0389 seconds

Train time: 15.362440586090088
 * Prec@1 82.040 Prec@5 99.360 Loss 0.5298
Avg Loading time: 0.0472 seconds
Avg Batch time: 0.0527 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.407088994979858

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.014 (0.048)	BT: 0.024 (0.057)	Loss 0.3965 (0.4856)	Prec@1 86.719 (83.764)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.041)	BT: 0.007 (0.051)	Loss 0.2881 (0.4741)	Prec@1 91.406 (83.784)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.039)	BT: 0.017 (0.048)	Loss 0.5332 (0.4798)	Prec@1 82.031 (83.580)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.038)	BT: 0.030 (0.048)	Loss 0.3279 (0.4804)	Prec@1 89.844 (83.501)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.211 (0.037)	BT: 0.220 (0.047)	Loss 0.4019 (0.4807)	Prec@1 89.062 (83.476)	
Total train loss: 0.4807
Avg Loading time: 0.0368 seconds
Avg Batch time: 0.0469 seconds

Train time: 18.583714962005615
 * Prec@1 81.880 Prec@5 99.380 Loss 0.5278
Avg Loading time: 0.0493 seconds
Avg Batch time: 0.0548 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.562471151351929

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.032)	BT: 0.004 (0.038)	Loss 0.4993 (0.4709)	Prec@1 82.031 (83.444)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.035)	BT: 0.010 (0.043)	Loss 0.5830 (0.4771)	Prec@1 77.344 (83.288)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.031)	BT: 0.016 (0.038)	Loss 0.4983 (0.4812)	Prec@1 80.469 (83.247)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.033)	BT: 0.010 (0.041)	Loss 0.4563 (0.4819)	Prec@1 80.469 (83.261)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.033)	BT: 0.012 (0.041)	Loss 0.5469 (0.4823)	Prec@1 79.688 (83.273)	
Total train loss: 0.4825
Avg Loading time: 0.0329 seconds
Avg Batch time: 0.0410 seconds

Train time: 16.24931311607361
 * Prec@1 81.900 Prec@5 99.350 Loss 0.5293
Avg Loading time: 0.0465 seconds
Avg Batch time: 0.0541 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.523156642913818

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.004 (0.050)	BT: 0.009 (0.061)	Loss 0.4207 (0.4834)	Prec@1 85.156 (83.213)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.041)	BT: 0.005 (0.051)	Loss 0.4822 (0.4822)	Prec@1 85.938 (83.358)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.036)	BT: 0.014 (0.048)	Loss 0.2810 (0.4835)	Prec@1 90.625 (83.337)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.102 (0.036)	BT: 0.115 (0.047)	Loss 0.4775 (0.4833)	Prec@1 85.156 (83.323)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.034)	BT: 0.004 (0.045)	Loss 0.5913 (0.4810)	Prec@1 76.562 (83.353)	
Total train loss: 0.4810
Avg Loading time: 0.0344 seconds
Avg Batch time: 0.0445 seconds

Train time: 17.54918599128723
 * Prec@1 81.780 Prec@5 99.360 Loss 0.5298
Avg Loading time: 0.0507 seconds
Avg Batch time: 0.0574 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.78376579284668

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.029)	BT: 0.005 (0.035)	Loss 0.5059 (0.4833)	Prec@1 83.594 (83.213)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.103 (0.035)	BT: 0.118 (0.043)	Loss 0.4260 (0.4777)	Prec@1 86.719 (83.554)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.056 (0.036)	BT: 0.061 (0.045)	Loss 0.4556 (0.4769)	Prec@1 85.156 (83.544)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.035)	BT: 0.005 (0.045)	Loss 0.5566 (0.4799)	Prec@1 82.812 (83.481)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.035)	BT: 0.005 (0.044)	Loss 0.5308 (0.4807)	Prec@1 81.250 (83.431)	
Total train loss: 0.4806
Avg Loading time: 0.0348 seconds
Avg Batch time: 0.0442 seconds

Train time: 17.52063274383545
 * Prec@1 81.880 Prec@5 99.320 Loss 0.5288
Avg Loading time: 0.0450 seconds
Avg Batch time: 0.0531 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.4379563331604

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.045)	BT: 0.011 (0.055)	Loss 0.4438 (0.4806)	Prec@1 84.375 (83.403)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.039)	BT: 0.007 (0.051)	Loss 0.4104 (0.4885)	Prec@1 89.062 (82.978)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.032)	BT: 0.005 (0.043)	Loss 0.4778 (0.4852)	Prec@1 82.812 (83.116)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.216 (0.032)	BT: 0.222 (0.042)	Loss 0.5737 (0.4790)	Prec@1 81.250 (83.408)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.032)	BT: 0.004 (0.041)	Loss 0.5508 (0.4795)	Prec@1 82.812 (83.446)	
Total train loss: 0.4796
Avg Loading time: 0.0316 seconds
Avg Batch time: 0.0409 seconds

Train time: 16.126184701919556
 * Prec@1 81.830 Prec@5 99.370 Loss 0.5312
Avg Loading time: 0.0356 seconds
Avg Batch time: 0.0398 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 3.3878519535064697

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.048)	BT: 0.010 (0.057)	Loss 0.4761 (0.4836)	Prec@1 81.250 (83.153)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.043)	BT: 0.014 (0.052)	Loss 0.7808 (0.4809)	Prec@1 77.344 (83.403)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.154 (0.038)	BT: 0.159 (0.048)	Loss 0.5039 (0.4799)	Prec@1 83.594 (83.444)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.039)	BT: 0.007 (0.049)	Loss 0.4932 (0.4809)	Prec@1 86.719 (83.373)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.038)	BT: 0.007 (0.047)	Loss 0.4209 (0.4792)	Prec@1 87.500 (83.431)	
Total train loss: 0.4792
Avg Loading time: 0.0375 seconds
Avg Batch time: 0.0474 seconds

Train time: 18.7541446685791
 * Prec@1 81.910 Prec@5 99.360 Loss 0.5298
Avg Loading time: 0.0478 seconds
Avg Batch time: 0.0555 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.623300552368164

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.035)	BT: 0.004 (0.042)	Loss 0.4607 (0.4833)	Prec@1 83.594 (83.133)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.033)	BT: 0.007 (0.041)	Loss 0.4641 (0.4747)	Prec@1 87.500 (83.514)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.030)	BT: 0.005 (0.039)	Loss 0.5366 (0.4768)	Prec@1 79.688 (83.574)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.027)	BT: 0.009 (0.035)	Loss 0.5269 (0.4781)	Prec@1 83.594 (83.614)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.028)	BT: 0.004 (0.037)	Loss 0.5088 (0.4801)	Prec@1 81.250 (83.526)	
Total train loss: 0.4800
Avg Loading time: 0.0283 seconds
Avg Batch time: 0.0365 seconds

Train time: 14.453621864318848
 * Prec@1 81.850 Prec@5 99.370 Loss 0.5288
Avg Loading time: 0.0507 seconds
Avg Batch time: 0.0578 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.787997722625732

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.041)	BT: 0.007 (0.050)	Loss 0.4856 (0.4765)	Prec@1 81.250 (83.564)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.037)	BT: 0.012 (0.047)	Loss 0.3230 (0.4746)	Prec@1 90.625 (83.694)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.052 (0.036)	BT: 0.061 (0.046)	Loss 0.5054 (0.4753)	Prec@1 80.469 (83.757)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.036)	BT: 0.022 (0.046)	Loss 0.4258 (0.4751)	Prec@1 84.375 (83.686)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.116 (0.036)	BT: 0.121 (0.046)	Loss 0.6411 (0.4778)	Prec@1 78.125 (83.584)	
Total train loss: 0.4779
Avg Loading time: 0.0363 seconds
Avg Batch time: 0.0463 seconds

Train time: 18.305092334747314
 * Prec@1 81.870 Prec@5 99.310 Loss 0.5298
Avg Loading time: 0.0366 seconds
Avg Batch time: 0.0400 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 3.3864035606384277

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.045)	BT: 0.005 (0.052)	Loss 0.4937 (0.4627)	Prec@1 83.594 (83.794)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.033)	BT: 0.009 (0.039)	Loss 0.4417 (0.4687)	Prec@1 86.719 (83.769)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.036)	BT: 0.005 (0.043)	Loss 0.5488 (0.4722)	Prec@1 78.906 (83.701)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.035)	BT: 0.012 (0.043)	Loss 0.3320 (0.4774)	Prec@1 89.062 (83.561)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.033)	BT: 0.007 (0.041)	Loss 0.4822 (0.4777)	Prec@1 79.688 (83.502)	
Total train loss: 0.4780
Avg Loading time: 0.0325 seconds
Avg Batch time: 0.0411 seconds

Train time: 16.30780529975891
 * Prec@1 81.750 Prec@5 99.340 Loss 0.5293
Avg Loading time: 0.0446 seconds
Avg Batch time: 0.0523 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.3819780349731445

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.047)	BT: 0.006 (0.056)	Loss 0.4946 (0.4764)	Prec@1 82.031 (83.574)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.044)	BT: 0.005 (0.053)	Loss 0.3579 (0.4709)	Prec@1 89.844 (83.784)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.041)	BT: 0.029 (0.050)	Loss 0.4539 (0.4772)	Prec@1 82.812 (83.333)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.037)	BT: 0.004 (0.045)	Loss 0.4390 (0.4810)	Prec@1 81.250 (83.311)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.036)	BT: 0.010 (0.045)	Loss 0.4189 (0.4803)	Prec@1 87.500 (83.391)	
Total train loss: 0.4802
Avg Loading time: 0.0362 seconds
Avg Batch time: 0.0447 seconds

Train time: 17.696592807769775
 * Prec@1 81.930 Prec@5 99.380 Loss 0.5298
Avg Loading time: 0.0352 seconds
Avg Batch time: 0.0402 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 3.314342737197876

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.039)	BT: 0.011 (0.049)	Loss 0.3904 (0.4679)	Prec@1 85.156 (83.814)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.041)	BT: 0.014 (0.051)	Loss 0.4890 (0.4812)	Prec@1 84.375 (83.383)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.040)	BT: 0.010 (0.050)	Loss 0.4270 (0.4801)	Prec@1 86.719 (83.447)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.038)	BT: 0.008 (0.049)	Loss 0.5117 (0.4791)	Prec@1 79.688 (83.539)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.039)	BT: 0.006 (0.049)	Loss 0.3752 (0.4785)	Prec@1 88.281 (83.522)	
Total train loss: 0.4788
Avg Loading time: 0.0391 seconds
Avg Batch time: 0.0490 seconds

Train time: 19.381900310516357
 * Prec@1 81.870 Prec@5 99.400 Loss 0.5312
Avg Loading time: 0.0440 seconds
Avg Batch time: 0.0506 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.284240484237671

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.051)	BT: 0.008 (0.061)	Loss 0.5864 (0.4944)	Prec@1 78.125 (82.812)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.260 (0.037)	BT: 0.266 (0.045)	Loss 0.5249 (0.4932)	Prec@1 82.031 (83.018)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.035)	BT: 0.004 (0.043)	Loss 0.4744 (0.4835)	Prec@1 85.938 (83.313)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.032)	BT: 0.004 (0.039)	Loss 0.4639 (0.4815)	Prec@1 86.719 (83.386)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.031)	BT: 0.011 (0.039)	Loss 0.4500 (0.4805)	Prec@1 86.719 (83.409)	
Total train loss: 0.4805
Avg Loading time: 0.0312 seconds
Avg Batch time: 0.0392 seconds

Train time: 15.537079572677612
 * Prec@1 81.770 Prec@5 99.360 Loss 0.5293
Avg Loading time: 0.0519 seconds
Avg Batch time: 0.0584 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.849496364593506

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.043)	BT: 0.009 (0.052)	Loss 0.5044 (0.4830)	Prec@1 87.500 (83.484)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.042)	BT: 0.018 (0.052)	Loss 0.5117 (0.4866)	Prec@1 85.156 (83.273)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.209 (0.039)	BT: 0.218 (0.049)	Loss 0.4807 (0.4819)	Prec@1 85.156 (83.333)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.036)	BT: 0.007 (0.046)	Loss 0.5923 (0.4805)	Prec@1 76.562 (83.411)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.036)	BT: 0.004 (0.046)	Loss 0.2959 (0.4778)	Prec@1 88.281 (83.506)	
Total train loss: 0.4780
Avg Loading time: 0.0359 seconds
Avg Batch time: 0.0456 seconds

Train time: 18.095683336257935
 * Prec@1 81.910 Prec@5 99.370 Loss 0.5283
Avg Loading time: 0.0278 seconds
Avg Batch time: 0.0326 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 2.7467639446258545

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.049)	BT: 0.007 (0.058)	Loss 0.5645 (0.4842)	Prec@1 83.594 (83.023)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.034)	BT: 0.008 (0.042)	Loss 0.4553 (0.4817)	Prec@1 85.938 (83.193)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.287 (0.034)	BT: 0.292 (0.042)	Loss 0.4729 (0.4803)	Prec@1 81.250 (83.444)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.033)	BT: 0.006 (0.042)	Loss 0.4961 (0.4809)	Prec@1 80.469 (83.393)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.034)	BT: 0.014 (0.043)	Loss 0.4749 (0.4812)	Prec@1 81.250 (83.349)	
Total train loss: 0.4811
Avg Loading time: 0.0340 seconds
Avg Batch time: 0.0428 seconds

Train time: 16.968493461608887
 * Prec@1 81.890 Prec@5 99.380 Loss 0.5298
Avg Loading time: 0.0452 seconds
Avg Batch time: 0.0523 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.350248098373413

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.046)	BT: 0.006 (0.055)	Loss 0.5674 (0.4736)	Prec@1 81.250 (84.095)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.040)	BT: 0.015 (0.050)	Loss 0.4651 (0.4780)	Prec@1 81.250 (83.634)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.070 (0.039)	BT: 0.075 (0.049)	Loss 0.5171 (0.4779)	Prec@1 82.031 (83.570)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.034)	BT: 0.005 (0.043)	Loss 0.5342 (0.4787)	Prec@1 82.031 (83.576)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.033)	BT: 0.005 (0.042)	Loss 0.5752 (0.4785)	Prec@1 82.031 (83.604)	
Total train loss: 0.4785
Avg Loading time: 0.0331 seconds
Avg Batch time: 0.0418 seconds

Train time: 16.608014583587646
 * Prec@1 81.960 Prec@5 99.320 Loss 0.5293
Avg Loading time: 0.0338 seconds
Avg Batch time: 0.0379 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 3.188891649246216

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.044)	BT: 0.024 (0.053)	Loss 0.4614 (0.4717)	Prec@1 85.156 (83.734)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.039)	BT: 0.010 (0.049)	Loss 0.4299 (0.4715)	Prec@1 86.719 (83.574)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.183 (0.038)	BT: 0.190 (0.048)	Loss 0.7095 (0.4770)	Prec@1 79.688 (83.504)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.038)	BT: 0.007 (0.047)	Loss 0.5137 (0.4788)	Prec@1 83.594 (83.499)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.038)	BT: 0.007 (0.047)	Loss 0.6196 (0.4790)	Prec@1 77.344 (83.508)	
Total train loss: 0.4791
Avg Loading time: 0.0375 seconds
Avg Batch time: 0.0471 seconds

Train time: 18.634565830230713
 * Prec@1 81.890 Prec@5 99.350 Loss 0.5303
Avg Loading time: 0.0450 seconds
Avg Batch time: 0.0515 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.307276725769043

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.042)	BT: 0.005 (0.051)	Loss 0.5366 (0.4880)	Prec@1 81.250 (82.943)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.030)	BT: 0.004 (0.039)	Loss 0.4275 (0.4797)	Prec@1 83.594 (83.298)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.143 (0.032)	BT: 0.166 (0.040)	Loss 0.5962 (0.4825)	Prec@1 77.344 (83.293)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.134 (0.032)	BT: 0.141 (0.040)	Loss 0.6602 (0.4799)	Prec@1 74.219 (83.378)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.029)	BT: 0.004 (0.036)	Loss 0.5894 (0.4802)	Prec@1 78.125 (83.371)	
Total train loss: 0.4803
Avg Loading time: 0.0287 seconds
Avg Batch time: 0.0362 seconds

Train time: 14.403516054153442
 * Prec@1 81.790 Prec@5 99.360 Loss 0.5322
Avg Loading time: 0.0517 seconds
Avg Batch time: 0.0578 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.8276801109313965

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.053)	BT: 0.010 (0.062)	Loss 0.3972 (0.4733)	Prec@1 85.156 (83.664)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.046)	BT: 0.020 (0.055)	Loss 0.4717 (0.4774)	Prec@1 83.594 (83.674)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.041)	BT: 0.013 (0.050)	Loss 0.5073 (0.4794)	Prec@1 82.812 (83.617)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.041)	BT: 0.005 (0.050)	Loss 0.4905 (0.4794)	Prec@1 82.031 (83.616)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.039)	BT: 0.004 (0.048)	Loss 0.3098 (0.4786)	Prec@1 90.625 (83.650)	
Total train loss: 0.4786
Avg Loading time: 0.0386 seconds
Avg Batch time: 0.0479 seconds

Train time: 18.93241786956787
 * Prec@1 81.820 Prec@5 99.360 Loss 0.5283
Avg Loading time: 0.0414 seconds
Avg Batch time: 0.0485 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.030529737472534

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.036)	BT: 0.005 (0.043)	Loss 0.5098 (0.4611)	Prec@1 87.500 (84.135)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.032)	BT: 0.005 (0.041)	Loss 0.5054 (0.4832)	Prec@1 82.812 (83.348)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.081 (0.027)	BT: 0.086 (0.035)	Loss 0.4707 (0.4818)	Prec@1 85.156 (83.377)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.030)	BT: 0.006 (0.038)	Loss 0.4753 (0.4815)	Prec@1 84.375 (83.261)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.031)	BT: 0.008 (0.039)	Loss 0.4248 (0.4802)	Prec@1 83.594 (83.337)	
Total train loss: 0.4802
Avg Loading time: 0.0305 seconds
Avg Batch time: 0.0387 seconds

Train time: 15.384068727493286
 * Prec@1 81.810 Prec@5 99.340 Loss 0.5298
Avg Loading time: 0.0435 seconds
Avg Batch time: 0.0509 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.243540287017822

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.041)	BT: 0.012 (0.054)	Loss 0.3840 (0.4776)	Prec@1 86.719 (83.744)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.039)	BT: 0.007 (0.050)	Loss 0.5542 (0.4800)	Prec@1 81.250 (83.398)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.036)	BT: 0.020 (0.048)	Loss 0.4465 (0.4828)	Prec@1 83.594 (83.320)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.036)	BT: 0.008 (0.047)	Loss 0.5283 (0.4809)	Prec@1 82.031 (83.333)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.033)	BT: 0.004 (0.044)	Loss 0.4785 (0.4814)	Prec@1 85.156 (83.299)	
Total train loss: 0.4813
Avg Loading time: 0.0330 seconds
Avg Batch time: 0.0438 seconds

Train time: 17.31329870223999
 * Prec@1 81.990 Prec@5 99.320 Loss 0.5278
Avg Loading time: 0.0461 seconds
Avg Batch time: 0.0525 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.404949188232422

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.021 (0.028)	BT: 0.025 (0.034)	Loss 0.4680 (0.4811)	Prec@1 85.938 (83.654)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.031)	BT: 0.014 (0.038)	Loss 0.6196 (0.4812)	Prec@1 77.344 (83.454)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.033)	BT: 0.006 (0.041)	Loss 0.3916 (0.4777)	Prec@1 89.062 (83.554)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.034)	BT: 0.012 (0.042)	Loss 0.5571 (0.4813)	Prec@1 78.906 (83.464)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.033)	BT: 0.010 (0.042)	Loss 0.5156 (0.4769)	Prec@1 82.812 (83.586)	
Total train loss: 0.4775
Avg Loading time: 0.0333 seconds
Avg Batch time: 0.0419 seconds

Train time: 16.624804258346558
 * Prec@1 81.780 Prec@5 99.320 Loss 0.5312
Avg Loading time: 0.0463 seconds
Avg Batch time: 0.0516 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.335143089294434

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.049)	BT: 0.016 (0.059)	Loss 0.6465 (0.4710)	Prec@1 79.688 (83.544)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.046)	BT: 0.024 (0.056)	Loss 0.4292 (0.4719)	Prec@1 85.156 (83.679)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.129 (0.036)	BT: 0.135 (0.046)	Loss 0.4048 (0.4784)	Prec@1 86.719 (83.527)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.034)	BT: 0.007 (0.043)	Loss 0.4036 (0.4767)	Prec@1 84.375 (83.579)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.009 (0.034)	BT: 0.014 (0.043)	Loss 0.4846 (0.4753)	Prec@1 86.719 (83.680)	
Total train loss: 0.4754
Avg Loading time: 0.0341 seconds
Avg Batch time: 0.0431 seconds

Train time: 17.009321451187134
 * Prec@1 81.920 Prec@5 99.360 Loss 0.5288
Avg Loading time: 0.0365 seconds
Avg Batch time: 0.0415 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 3.525676727294922

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.050)	BT: 0.004 (0.059)	Loss 0.5356 (0.4810)	Prec@1 78.125 (83.474)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.043)	BT: 0.017 (0.054)	Loss 0.5142 (0.4771)	Prec@1 85.156 (83.729)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.040)	BT: 0.012 (0.050)	Loss 0.5547 (0.4778)	Prec@1 85.938 (83.647)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.038)	BT: 0.004 (0.048)	Loss 0.5645 (0.4804)	Prec@1 81.250 (83.579)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.035)	BT: 0.005 (0.046)	Loss 0.5874 (0.4799)	Prec@1 79.688 (83.570)	
Total train loss: 0.4799
Avg Loading time: 0.0354 seconds
Avg Batch time: 0.0460 seconds

Train time: 18.179266691207886
 * Prec@1 81.780 Prec@5 99.350 Loss 0.5303
Avg Loading time: 0.0465 seconds
Avg Batch time: 0.0532 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.450073003768921

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.026 (0.032)	BT: 0.032 (0.041)	Loss 0.3650 (0.4890)	Prec@1 88.281 (83.013)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.031)	BT: 0.012 (0.040)	Loss 0.4355 (0.4835)	Prec@1 89.062 (83.433)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.031)	BT: 0.005 (0.039)	Loss 0.5195 (0.4782)	Prec@1 81.250 (83.704)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.030)	BT: 0.005 (0.037)	Loss 0.4829 (0.4799)	Prec@1 85.156 (83.674)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.031)	BT: 0.012 (0.039)	Loss 0.5508 (0.4793)	Prec@1 78.906 (83.554)	
Total train loss: 0.4795
Avg Loading time: 0.0307 seconds
Avg Batch time: 0.0389 seconds

Train time: 15.452030897140503
 * Prec@1 82.050 Prec@5 99.380 Loss 0.5293
Avg Loading time: 0.0535 seconds
Avg Batch time: 0.0608 seconds

Best acc: 82.060
--------------------------------------------------------------------------------
Test time: 4.998628616333008

