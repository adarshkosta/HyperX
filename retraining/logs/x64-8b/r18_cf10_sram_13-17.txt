
      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 13
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/train/relu13
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/test/relu13
ResNet18(
  (conv14): QConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): QConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 12.140 Prec@5 49.630 Loss 2.3145
Avg Loading time: 4.5719 seconds
Avg Batch time: 4.5909 seconds

Pre-trained Prec@1 with 13 layers frozen: 12.139999389648438 	 Loss: 2.314453125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (5.850)	BT: 0.018 (5.875)	Loss 0.7549 (0.8023)	Prec@1 75.781 (74.850)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (5.820)	BT: 0.018 (5.844)	Loss 0.4988 (0.7133)	Prec@1 86.719 (76.773)	
Epoch: [0][233/391]	LR: 0.1	DT: 2.986 (5.854)	BT: 3.014 (5.878)	Loss 0.5874 (0.6655)	Prec@1 75.000 (78.125)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (5.766)	BT: 0.017 (5.790)	Loss 0.5640 (0.6240)	Prec@1 78.906 (79.309)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (5.832)	BT: 0.018 (5.856)	Loss 0.4663 (0.5931)	Prec@1 87.500 (80.222)	
Total train loss: 0.5928
Avg Loading time: 5.8169 seconds
Avg Batch time: 5.8410 seconds

Train time: 2283.8948419094086
 * Prec@1 63.920 Prec@5 94.530 Loss 1.3193
Avg Loading time: 3.4630 seconds
Avg Batch time: 3.4754 seconds

Best acc: 63.920
--------------------------------------------------------------------------------
Test time: 275.3859758377075

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (2.448)	BT: 0.018 (2.470)	Loss 0.3372 (0.4019)	Prec@1 87.500 (86.298)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (2.360)	BT: 0.018 (2.382)	Loss 0.4207 (0.4094)	Prec@1 86.719 (86.168)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (2.462)	BT: 0.021 (2.484)	Loss 0.4155 (0.4143)	Prec@1 84.375 (85.921)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (2.584)	BT: 0.018 (2.606)	Loss 0.4231 (0.4169)	Prec@1 85.156 (85.740)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (2.722)	BT: 0.018 (2.744)	Loss 0.4868 (0.4233)	Prec@1 84.375 (85.483)	
Total train loss: 0.4231
Avg Loading time: 2.7145 seconds
Avg Batch time: 2.7369 seconds

Train time: 1070.1950755119324
 * Prec@1 32.830 Prec@5 93.900 Loss inf
Avg Loading time: 3.1217 seconds
Avg Batch time: 3.1332 seconds

Best acc: 63.920
--------------------------------------------------------------------------------
Test time: 248.00933957099915

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (3.893)	BT: 0.019 (3.916)	Loss 0.2546 (0.3785)	Prec@1 90.625 (87.089)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (3.659)	BT: 0.024 (3.683)	Loss 0.3010 (0.3723)	Prec@1 92.188 (87.230)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (3.297)	BT: 0.020 (3.321)	Loss 0.4031 (0.3669)	Prec@1 85.938 (87.443)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (3.178)	BT: 0.018 (3.201)	Loss 0.5132 (0.3666)	Prec@1 81.250 (87.465)	
Epoch: [2][389/391]	LR: 0.1	DT: 2.056 (3.196)	BT: 2.083 (3.220)	Loss 0.4192 (0.3686)	Prec@1 85.938 (87.352)	
Total train loss: 0.3685
Avg Loading time: 3.1881 seconds
Avg Batch time: 3.2121 seconds

Train time: 1256.0253975391388
 * Prec@1 66.480 Prec@5 96.430 Loss 0.9863
Avg Loading time: 3.1916 seconds
Avg Batch time: 3.2046 seconds

Best acc: 66.480
--------------------------------------------------------------------------------
Test time: 254.03106689453125

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (3.345)	BT: 0.018 (3.369)	Loss 0.3718 (0.3239)	Prec@1 83.594 (88.882)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (3.298)	BT: 0.018 (3.322)	Loss 0.2671 (0.3218)	Prec@1 90.625 (88.987)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (3.264)	BT: 0.020 (3.288)	Loss 0.3020 (0.3254)	Prec@1 91.406 (88.792)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (3.208)	BT: 0.018 (3.231)	Loss 0.2893 (0.3260)	Prec@1 89.062 (88.852)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (3.219)	BT: 0.018 (3.242)	Loss 0.3970 (0.3267)	Prec@1 85.938 (88.860)	
Total train loss: 0.3267
Avg Loading time: 3.2111 seconds
Avg Batch time: 3.2340 seconds

Train time: 1264.565665960312
 * Prec@1 83.780 Prec@5 99.380 Loss 0.4663
Avg Loading time: 2.6924 seconds
Avg Batch time: 2.7041 seconds

Best acc: 83.780
--------------------------------------------------------------------------------
Test time: 214.48180270195007

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (2.417)	BT: 0.018 (2.440)	Loss 0.2615 (0.2846)	Prec@1 89.844 (90.345)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (2.175)	BT: 0.021 (2.198)	Loss 0.3984 (0.3059)	Prec@1 88.281 (89.543)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (2.118)	BT: 0.021 (2.140)	Loss 0.2842 (0.3082)	Prec@1 91.406 (89.360)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (2.334)	BT: 0.018 (2.356)	Loss 0.3069 (0.3105)	Prec@1 87.500 (89.313)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (2.479)	BT: 0.018 (2.501)	Loss 0.3860 (0.3117)	Prec@1 84.375 (89.221)	
Total train loss: 0.3120
Avg Loading time: 2.4723 seconds
Avg Batch time: 2.4945 seconds

Train time: 975.4273986816406
 * Prec@1 76.140 Prec@5 97.600 Loss 0.7266
Avg Loading time: 3.2561 seconds
Avg Batch time: 3.2682 seconds

Best acc: 83.780
--------------------------------------------------------------------------------
Test time: 258.6985969543457

Epoch: [5][77/391]	LR: 0.1	DT: 0.905 (3.110)	BT: 0.934 (3.136)	Loss 0.3455 (0.2658)	Prec@1 87.500 (90.735)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (2.973)	BT: 0.018 (2.998)	Loss 0.2537 (0.2667)	Prec@1 89.844 (90.815)	
Epoch: [5][233/391]	LR: 0.1	DT: 4.063 (3.151)	BT: 4.093 (3.176)	Loss 0.1506 (0.2755)	Prec@1 96.094 (90.511)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (3.130)	BT: 0.018 (3.156)	Loss 0.2729 (0.2787)	Prec@1 91.406 (90.405)	
Epoch: [5][389/391]	LR: 0.1	DT: 1.841 (3.164)	BT: 1.872 (3.189)	Loss 0.2549 (0.2789)	Prec@1 91.406 (90.433)	
Total train loss: 0.2790
Avg Loading time: 3.1556 seconds
Avg Batch time: 3.1810 seconds

Train time: 1243.8459300994873
 * Prec@1 10.040 Prec@5 66.650 Loss inf
Avg Loading time: 3.4521 seconds
Avg Batch time: 3.4643 seconds

Best acc: 83.780
--------------------------------------------------------------------------------
Test time: 274.17458510398865

Epoch: [6][77/391]	LR: 0.1	DT: 0.276 (3.295)	BT: 0.305 (3.322)	Loss 0.2788 (0.2606)	Prec@1 89.844 (91.076)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (3.340)	BT: 0.020 (3.367)	Loss 0.3105 (0.2586)	Prec@1 86.719 (91.041)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (3.283)	BT: 0.020 (3.309)	Loss 0.3416 (0.2588)	Prec@1 85.938 (91.032)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (3.128)	BT: 0.020 (3.154)	Loss 0.2238 (0.2742)	Prec@1 91.406 (90.545)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (3.020)	BT: 0.019 (3.045)	Loss 0.3887 (0.2794)	Prec@1 89.062 (90.375)	
Total train loss: 0.2796
Avg Loading time: 3.0122 seconds
Avg Batch time: 3.0374 seconds

Train time: 1187.6962661743164
 * Prec@1 13.330 Prec@5 61.240 Loss 3.1875
Avg Loading time: 1.9125 seconds
Avg Batch time: 1.9230 seconds

Best acc: 83.780
--------------------------------------------------------------------------------
Test time: 152.41125440597534

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (1.986)	BT: 0.019 (2.008)	Loss 0.2563 (0.2847)	Prec@1 89.844 (89.974)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (2.069)	BT: 0.019 (2.091)	Loss 0.2295 (0.2824)	Prec@1 93.750 (90.044)	
Epoch: [7][233/391]	LR: 0.1	DT: 5.035 (2.484)	BT: 5.065 (2.507)	Loss 0.3904 (0.2874)	Prec@1 83.594 (90.004)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (2.641)	BT: 0.019 (2.665)	Loss 0.2864 (0.2905)	Prec@1 89.844 (89.964)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (2.828)	BT: 0.019 (2.852)	Loss 0.1664 (0.2922)	Prec@1 93.750 (89.860)	
Total train loss: 0.2923
Avg Loading time: 2.8206 seconds
Avg Batch time: 2.8444 seconds

Train time: 1112.2453782558441
 * Prec@1 86.060 Prec@5 99.260 Loss 0.4331
Avg Loading time: 3.5876 seconds
Avg Batch time: 3.5997 seconds

Best acc: 86.060
--------------------------------------------------------------------------------
Test time: 285.2598764896393

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (3.671)	BT: 0.019 (3.697)	Loss 0.2440 (0.2698)	Prec@1 92.969 (91.206)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (3.990)	BT: 0.024 (4.017)	Loss 0.3088 (0.2782)	Prec@1 92.188 (90.615)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.353 (4.136)	BT: 0.383 (4.163)	Loss 0.3865 (0.2848)	Prec@1 84.375 (90.228)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (4.086)	BT: 0.020 (4.113)	Loss 0.3574 (0.2835)	Prec@1 88.281 (90.304)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (4.120)	BT: 0.019 (4.147)	Loss 0.1676 (0.2836)	Prec@1 92.969 (90.212)	
Total train loss: 0.2835
Avg Loading time: 4.1097 seconds
Avg Batch time: 4.1365 seconds

Train time: 1617.4833679199219
 * Prec@1 86.820 Prec@5 99.490 Loss 0.3936
Avg Loading time: 4.2574 seconds
Avg Batch time: 4.2693 seconds

Best acc: 86.820
--------------------------------------------------------------------------------
Test time: 338.18150901794434

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (4.366)	BT: 0.019 (4.390)	Loss 0.2399 (0.2564)	Prec@1 94.531 (91.206)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (4.366)	BT: 0.020 (4.390)	Loss 0.2837 (0.2606)	Prec@1 92.188 (91.011)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.387 (4.129)	BT: 0.414 (4.153)	Loss 0.3274 (0.2621)	Prec@1 89.062 (90.885)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (3.713)	BT: 0.019 (3.737)	Loss 0.3640 (0.2654)	Prec@1 85.938 (90.803)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (3.457)	BT: 0.019 (3.481)	Loss 0.1628 (0.2665)	Prec@1 93.750 (90.775)	
Total train loss: 0.2668
Avg Loading time: 3.4481 seconds
Avg Batch time: 3.4722 seconds

Train time: 1357.714866399765
 * Prec@1 61.130 Prec@5 95.740 Loss 1.1357
Avg Loading time: 3.3695 seconds
Avg Batch time: 3.3817 seconds

Best acc: 86.820
--------------------------------------------------------------------------------
Test time: 267.6716568470001

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (3.451)	BT: 0.019 (3.476)	Loss 0.1812 (0.2325)	Prec@1 95.312 (92.047)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (3.393)	BT: 0.019 (3.418)	Loss 0.1913 (0.2477)	Prec@1 92.969 (91.391)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.602 (3.168)	BT: 0.632 (3.192)	Loss 0.3042 (0.2594)	Prec@1 89.062 (90.899)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (2.953)	BT: 0.019 (2.977)	Loss 0.1621 (0.2549)	Prec@1 92.188 (91.088)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (2.849)	BT: 0.019 (2.872)	Loss 0.2476 (0.2533)	Prec@1 91.406 (91.228)	
Total train loss: 0.2531
Avg Loading time: 2.8413 seconds
Avg Batch time: 2.8651 seconds

Train time: 1120.3402285575867
 * Prec@1 86.580 Prec@5 99.430 Loss 0.4211
Avg Loading time: 3.0722 seconds
Avg Batch time: 3.0850 seconds

Best acc: 86.820
--------------------------------------------------------------------------------
Test time: 244.19693732261658

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.790 (2.957)	BT: 0.817 (2.983)	Loss 0.3167 (0.2260)	Prec@1 86.719 (92.418)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (2.967)	BT: 0.019 (2.994)	Loss 0.1772 (0.2212)	Prec@1 93.750 (92.398)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (3.025)	BT: 0.021 (3.052)	Loss 0.2581 (0.2235)	Prec@1 88.281 (92.348)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 1.572 (2.985)	BT: 1.599 (3.011)	Loss 0.2664 (0.2229)	Prec@1 85.938 (92.340)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (3.033)	BT: 0.019 (3.059)	Loss 0.1829 (0.2231)	Prec@1 93.750 (92.344)	
Total train loss: 0.2231
Avg Loading time: 3.0252 seconds
Avg Batch time: 3.0512 seconds

Train time: 1193.0921869277954
 * Prec@1 86.610 Prec@5 99.470 Loss 0.4077
Avg Loading time: 3.3280 seconds
Avg Batch time: 3.3406 seconds

Best acc: 86.820
--------------------------------------------------------------------------------
Test time: 264.40299677848816

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (3.461)	BT: 0.020 (3.487)	Loss 0.1724 (0.2230)	Prec@1 93.750 (92.208)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.480 (3.232)	BT: 0.509 (3.258)	Loss 0.2006 (0.2235)	Prec@1 94.531 (92.233)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 1.632 (2.937)	BT: 1.662 (2.963)	Loss 0.3289 (0.2240)	Prec@1 88.281 (92.238)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 2.417 (2.746)	BT: 2.443 (2.771)	Loss 0.2544 (0.2246)	Prec@1 92.188 (92.275)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (2.763)	BT: 0.018 (2.787)	Loss 0.3638 (0.2230)	Prec@1 85.938 (92.380)	
Total train loss: 0.2229
Avg Loading time: 2.7557 seconds
Avg Batch time: 2.7799 seconds

Train time: 1087.0190427303314
 * Prec@1 87.820 Prec@5 99.560 Loss 0.3784
Avg Loading time: 3.3875 seconds
Avg Batch time: 3.3993 seconds

Best acc: 87.820
--------------------------------------------------------------------------------
Test time: 269.42576575279236

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (3.282)	BT: 0.018 (3.307)	Loss 0.2040 (0.2255)	Prec@1 91.406 (92.218)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (3.201)	BT: 0.019 (3.225)	Loss 0.1951 (0.2279)	Prec@1 92.188 (92.177)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.217 (3.343)	BT: 0.244 (3.367)	Loss 0.2474 (0.2292)	Prec@1 92.188 (92.177)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (3.270)	BT: 0.018 (3.294)	Loss 0.1708 (0.2250)	Prec@1 92.188 (92.340)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (3.242)	BT: 0.018 (3.266)	Loss 0.3018 (0.2248)	Prec@1 90.625 (92.334)	
Total train loss: 0.2247
Avg Loading time: 3.2337 seconds
Avg Batch time: 3.2572 seconds

Train time: 1273.6312854290009
 * Prec@1 87.340 Prec@5 99.570 Loss 0.3884
Avg Loading time: 3.1751 seconds
Avg Batch time: 3.1886 seconds

Best acc: 87.820
--------------------------------------------------------------------------------
Test time: 252.53829073905945

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 1.474 (3.388)	BT: 1.502 (3.412)	Loss 0.2771 (0.2353)	Prec@1 91.406 (91.747)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (3.375)	BT: 0.033 (3.401)	Loss 0.1689 (0.2306)	Prec@1 92.969 (92.017)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 1.492 (3.390)	BT: 1.531 (3.419)	Loss 0.2153 (0.2277)	Prec@1 92.969 (92.171)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (3.397)	BT: 0.036 (3.428)	Loss 0.3096 (0.2248)	Prec@1 89.062 (92.280)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.978 (3.510)	BT: 1.015 (3.541)	Loss 0.2139 (0.2249)	Prec@1 93.750 (92.248)	
Total train loss: 0.2250
Avg Loading time: 3.5010 seconds
Avg Batch time: 3.5325 seconds

Train time: 1382.1321675777435
 * Prec@1 87.940 Prec@5 99.590 Loss 0.3701
Avg Loading time: 5.1168 seconds
Avg Batch time: 5.1312 seconds

Best acc: 87.940
--------------------------------------------------------------------------------
Test time: 408.6801710128784

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (3.336)	BT: 0.036 (3.369)	Loss 0.1992 (0.2237)	Prec@1 94.531 (92.268)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.802 (3.079)	BT: 0.840 (3.114)	Loss 0.2759 (0.2201)	Prec@1 89.844 (92.393)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (2.653)	BT: 0.016 (3.383)	Loss 0.1488 (0.2200)	Prec@1 97.656 (92.334)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 1.093 (2.996)	BT: 1.126 (3.615)	Loss 0.3794 (0.2237)	Prec@1 87.500 (92.278)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (3.359)	BT: 0.041 (4.001)	Loss 0.3862 (0.2227)	Prec@1 86.719 (92.336)	
Total train loss: 0.2227
Avg Loading time: 3.3503 seconds
Avg Batch time: 3.9903 seconds

Train time: 1560.2935616970062
 * Prec@1 88.090 Prec@5 99.570 Loss 0.3738
Avg Loading time: 4.1165 seconds
Avg Batch time: 5.7932 seconds

Best acc: 88.090
--------------------------------------------------------------------------------
Test time: 462.74551486968994

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (3.610)	BT: 0.018 (4.754)	Loss 0.2610 (0.2124)	Prec@1 92.188 (92.798)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (2.900)	BT: 0.028 (4.693)	Loss 0.2268 (0.2126)	Prec@1 89.844 (92.733)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (2.923)	BT: 0.017 (4.330)	Loss 0.2556 (0.2169)	Prec@1 90.625 (92.545)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (2.991)	BT: 0.041 (4.591)	Loss 0.3010 (0.2176)	Prec@1 88.281 (92.548)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (3.008)	BT: 0.018 (4.293)	Loss 0.2241 (0.2178)	Prec@1 92.969 (92.490)	
Total train loss: 0.2181
Avg Loading time: 3.0005 seconds
Avg Batch time: 4.2820 seconds

Train time: 1674.3438551425934
 * Prec@1 83.310 Prec@5 98.850 Loss 0.5098
Avg Loading time: 3.4454 seconds
Avg Batch time: 3.4565 seconds

Best acc: 88.090
--------------------------------------------------------------------------------
Test time: 273.5565252304077

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (3.285)	BT: 0.018 (3.317)	Loss 0.2571 (0.2202)	Prec@1 92.969 (92.358)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (3.134)	BT: 0.032 (3.165)	Loss 0.0801 (0.2178)	Prec@1 97.656 (92.348)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.970 (2.758)	BT: 0.999 (2.863)	Loss 0.1696 (0.2208)	Prec@1 94.531 (92.314)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (2.490)	BT: 0.019 (2.575)	Loss 0.1476 (0.2256)	Prec@1 93.750 (92.243)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 2.363 (2.381)	BT: 2.399 (2.454)	Loss 0.2085 (0.2255)	Prec@1 95.312 (92.278)	
Total train loss: 0.2254
Avg Loading time: 2.3764 seconds
Avg Batch time: 2.4493 seconds

Train time: 957.7409534454346
 * Prec@1 87.320 Prec@5 99.540 Loss 0.3809
Avg Loading time: 2.8890 seconds
Avg Batch time: 2.8998 seconds

Best acc: 88.090
--------------------------------------------------------------------------------
Test time: 229.58839392662048

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (3.333)	BT: 0.016 (3.360)	Loss 0.2290 (0.2261)	Prec@1 92.969 (92.448)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (3.380)	BT: 0.032 (3.404)	Loss 0.2939 (0.2205)	Prec@1 90.625 (92.503)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (3.410)	BT: 0.032 (3.435)	Loss 0.1998 (0.2238)	Prec@1 89.844 (92.348)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (3.166)	BT: 0.033 (3.382)	Loss 0.2104 (0.2231)	Prec@1 93.750 (92.438)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 1.095 (2.901)	BT: 1.123 (3.293)	Loss 0.1443 (0.2225)	Prec@1 93.750 (92.442)	
Total train loss: 0.2225
Avg Loading time: 2.8936 seconds
Avg Batch time: 3.2846 seconds

Train time: 1284.3596811294556
 * Prec@1 87.630 Prec@5 99.570 Loss 0.3826
Avg Loading time: 3.1345 seconds
Avg Batch time: 3.1468 seconds

Best acc: 88.090
--------------------------------------------------------------------------------
Test time: 249.0964629650116

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.500 (3.663)	BT: 0.538 (3.692)	Loss 0.2551 (0.2233)	Prec@1 92.188 (92.348)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.151 (3.133)	BT: 0.181 (3.655)	Loss 0.2065 (0.2166)	Prec@1 90.625 (92.498)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 4.205 (2.879)	BT: 4.241 (3.308)	Loss 0.1929 (0.2180)	Prec@1 92.188 (92.485)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (3.035)	BT: 0.032 (3.363)	Loss 0.1567 (0.2207)	Prec@1 93.750 (92.405)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (2.939)	BT: 0.019 (3.428)	Loss 0.2815 (0.2215)	Prec@1 89.844 (92.404)	
Total train loss: 0.2215
Avg Loading time: 2.9320 seconds
Avg Batch time: 3.4193 seconds

Train time: 1338.0375201702118
 * Prec@1 87.970 Prec@5 99.530 Loss 0.3721
Avg Loading time: 2.6140 seconds
Avg Batch time: 3.6736 seconds

Best acc: 88.090
--------------------------------------------------------------------------------
Test time: 290.68747997283936

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (3.931)	BT: 0.032 (3.964)	Loss 0.2664 (0.2153)	Prec@1 89.844 (92.748)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (3.332)	BT: 0.032 (3.364)	Loss 0.1506 (0.2192)	Prec@1 96.094 (92.698)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (3.023)	BT: 0.032 (3.054)	Loss 0.1875 (0.2182)	Prec@1 95.312 (92.622)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (2.918)	BT: 0.018 (2.949)	Loss 0.2047 (0.2176)	Prec@1 92.188 (92.563)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (2.984)	BT: 0.018 (3.154)	Loss 0.2908 (0.2184)	Prec@1 91.406 (92.518)	
Total train loss: 0.2186
Avg Loading time: 2.9764 seconds
Avg Batch time: 3.1460 seconds

Train time: 1230.1454772949219
 * Prec@1 88.070 Prec@5 99.560 Loss 0.3718
Avg Loading time: 2.6439 seconds
Avg Batch time: 3.5199 seconds

Best acc: 88.090
--------------------------------------------------------------------------------
Test time: 278.5675663948059

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (2.271)	BT: 0.031 (3.797)	Loss 0.2590 (0.2236)	Prec@1 90.625 (92.288)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (2.628)	BT: 0.032 (3.438)	Loss 0.2700 (0.2159)	Prec@1 89.062 (92.633)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 3.862 (2.762)	BT: 3.885 (3.311)	Loss 0.2661 (0.2163)	Prec@1 92.188 (92.662)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 2.057 (2.750)	BT: 2.093 (3.170)	Loss 0.2153 (0.2146)	Prec@1 92.969 (92.793)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (2.784)	BT: 0.017 (3.194)	Loss 0.2593 (0.2154)	Prec@1 90.625 (92.728)	
Total train loss: 0.2156
Avg Loading time: 2.7772 seconds
Avg Batch time: 3.1863 seconds

Train time: 1245.956260919571
 * Prec@1 88.070 Prec@5 99.580 Loss 0.3687
Avg Loading time: 2.3883 seconds
Avg Batch time: 2.7844 seconds

Best acc: 88.090
--------------------------------------------------------------------------------
Test time: 220.4594211578369

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (2.723)	BT: 0.032 (3.487)	Loss 0.1094 (0.2212)	Prec@1 96.875 (92.578)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 2.448 (3.155)	BT: 2.473 (3.552)	Loss 0.1934 (0.2169)	Prec@1 91.406 (92.648)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 6.607 (3.282)	BT: 6.643 (3.558)	Loss 0.2690 (0.2175)	Prec@1 90.625 (92.628)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (3.332)	BT: 0.032 (3.547)	Loss 0.2031 (0.2175)	Prec@1 94.531 (92.553)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (3.396)	BT: 0.018 (3.574)	Loss 0.2228 (0.2173)	Prec@1 92.188 (92.536)	
Total train loss: 0.2173
Avg Loading time: 3.3869 seconds
Avg Batch time: 3.5649 seconds

Train time: 1393.9463522434235
 * Prec@1 88.120 Prec@5 99.520 Loss 0.3691
Avg Loading time: 3.5124 seconds
Avg Batch time: 4.0265 seconds

Best acc: 88.120
--------------------------------------------------------------------------------
Test time: 318.9538130760193

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (1.698)	BT: 0.033 (2.685)	Loss 0.2008 (0.2200)	Prec@1 92.188 (92.147)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 2.836 (2.106)	BT: 2.875 (2.674)	Loss 0.2620 (0.2207)	Prec@1 92.969 (92.318)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (2.230)	BT: 0.034 (2.619)	Loss 0.1505 (0.2192)	Prec@1 94.531 (92.351)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 2.038 (2.582)	BT: 2.064 (2.882)	Loss 0.2217 (0.2166)	Prec@1 92.969 (92.415)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (2.734)	BT: 0.018 (2.978)	Loss 0.2842 (0.2160)	Prec@1 91.406 (92.422)	
Total train loss: 0.2160
Avg Loading time: 2.7268 seconds
Avg Batch time: 2.9706 seconds

Train time: 1161.5906691551208
 * Prec@1 88.120 Prec@5 99.580 Loss 0.3682
Avg Loading time: 3.4350 seconds
Avg Batch time: 3.5421 seconds

Best acc: 88.120
--------------------------------------------------------------------------------
Test time: 280.3405795097351

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (3.752)	BT: 0.018 (3.803)	Loss 0.1423 (0.2117)	Prec@1 96.094 (92.979)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (3.704)	BT: 0.018 (3.771)	Loss 0.1891 (0.2135)	Prec@1 92.188 (92.758)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.706 (3.510)	BT: 0.735 (3.610)	Loss 0.1530 (0.2121)	Prec@1 96.094 (92.752)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (3.322)	BT: 0.019 (3.404)	Loss 0.2290 (0.2140)	Prec@1 92.969 (92.638)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.865 (3.277)	BT: 0.895 (3.347)	Loss 0.1448 (0.2168)	Prec@1 94.531 (92.514)	
Total train loss: 0.2167
Avg Loading time: 3.2685 seconds
Avg Batch time: 3.3385 seconds

Train time: 1305.4044289588928
 * Prec@1 88.040 Prec@5 99.600 Loss 0.3718
Avg Loading time: 3.3444 seconds
Avg Batch time: 3.3559 seconds

Best acc: 88.120
--------------------------------------------------------------------------------
Test time: 265.6285548210144

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (3.246)	BT: 0.018 (3.364)	Loss 0.2981 (0.2187)	Prec@1 89.844 (92.688)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.623 (3.253)	BT: 0.653 (3.325)	Loss 0.2661 (0.2200)	Prec@1 90.625 (92.543)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (3.191)	BT: 0.020 (3.288)	Loss 0.3037 (0.2195)	Prec@1 87.500 (92.428)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (3.098)	BT: 0.018 (3.177)	Loss 0.1398 (0.2150)	Prec@1 96.094 (92.606)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (3.096)	BT: 0.019 (3.165)	Loss 0.2876 (0.2150)	Prec@1 89.844 (92.568)	
Total train loss: 0.2148
Avg Loading time: 3.0883 seconds
Avg Batch time: 3.1567 seconds

Train time: 1234.3236396312714
 * Prec@1 88.090 Prec@5 99.560 Loss 0.3704
Avg Loading time: 2.3718 seconds
Avg Batch time: 2.3839 seconds

Best acc: 88.120
--------------------------------------------------------------------------------
Test time: 188.82561111450195

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (2.077)	BT: 0.021 (2.229)	Loss 0.2002 (0.2098)	Prec@1 92.969 (92.798)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (2.144)	BT: 0.019 (2.231)	Loss 0.2433 (0.2165)	Prec@1 90.625 (92.438)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (2.442)	BT: 0.021 (2.544)	Loss 0.1586 (0.2138)	Prec@1 95.312 (92.531)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (2.538)	BT: 0.019 (2.621)	Loss 0.1390 (0.2120)	Prec@1 96.094 (92.616)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (2.670)	BT: 0.018 (2.741)	Loss 0.2295 (0.2119)	Prec@1 92.188 (92.594)	
Total train loss: 0.2123
Avg Loading time: 2.6634 seconds
Avg Batch time: 2.7344 seconds

Train time: 1069.2081654071808
 * Prec@1 88.070 Prec@5 99.610 Loss 0.3708
Avg Loading time: 3.1240 seconds
Avg Batch time: 3.1354 seconds

Best acc: 88.120
--------------------------------------------------------------------------------
Test time: 248.19800090789795

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (2.971)	BT: 0.018 (3.043)	Loss 0.2817 (0.2050)	Prec@1 89.844 (92.728)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (2.859)	BT: 0.018 (2.924)	Loss 0.2006 (0.2065)	Prec@1 92.969 (92.748)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.113 (2.840)	BT: 0.132 (2.917)	Loss 0.1892 (0.2107)	Prec@1 94.531 (92.688)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (2.872)	BT: 0.020 (2.937)	Loss 0.2009 (0.2124)	Prec@1 93.750 (92.713)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 1.255 (2.974)	BT: 1.283 (3.031)	Loss 0.2939 (0.2147)	Prec@1 89.062 (92.686)	
Total train loss: 0.2147
Avg Loading time: 2.9667 seconds
Avg Batch time: 3.0236 seconds

Train time: 1182.3172845840454
 * Prec@1 88.140 Prec@5 99.590 Loss 0.3689
Avg Loading time: 3.4785 seconds
Avg Batch time: 3.4903 seconds

Best acc: 88.140
--------------------------------------------------------------------------------
Test time: 276.6374008655548

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (3.273)	BT: 0.018 (3.298)	Loss 0.1921 (0.2119)	Prec@1 94.531 (92.698)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (3.159)	BT: 0.020 (3.203)	Loss 0.2988 (0.2212)	Prec@1 89.062 (92.463)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (3.161)	BT: 0.022 (3.214)	Loss 0.1846 (0.2208)	Prec@1 94.531 (92.485)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (3.038)	BT: 0.018 (3.129)	Loss 0.2388 (0.2164)	Prec@1 94.531 (92.636)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (2.927)	BT: 0.018 (3.004)	Loss 0.2329 (0.2162)	Prec@1 91.406 (92.658)	
Total train loss: 0.2163
Avg Loading time: 2.9199 seconds
Avg Batch time: 2.9966 seconds

Train time: 1171.7598567008972
 * Prec@1 88.170 Prec@5 99.610 Loss 0.3711
Avg Loading time: 1.9494 seconds
Avg Batch time: 1.9601 seconds

Best acc: 88.170
--------------------------------------------------------------------------------
Test time: 155.7437551021576

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (1.734)	BT: 0.023 (1.756)	Loss 0.1654 (0.2129)	Prec@1 94.531 (92.598)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (2.062)	BT: 0.019 (2.085)	Loss 0.2272 (0.2194)	Prec@1 93.750 (92.463)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (2.363)	BT: 0.021 (2.411)	Loss 0.1764 (0.2159)	Prec@1 95.312 (92.585)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (2.449)	BT: 0.018 (2.524)	Loss 0.3206 (0.2135)	Prec@1 86.719 (92.708)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (2.598)	BT: 0.018 (2.664)	Loss 0.2603 (0.2145)	Prec@1 89.844 (92.648)	
Total train loss: 0.2147
Avg Loading time: 2.5918 seconds
Avg Batch time: 2.6568 seconds

Train time: 1038.8744056224823
 * Prec@1 88.240 Prec@5 99.550 Loss 0.3684
Avg Loading time: 3.3852 seconds
Avg Batch time: 3.3967 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 269.2080068588257

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (2.793)	BT: 0.018 (2.817)	Loss 0.1829 (0.2178)	Prec@1 95.312 (92.458)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 2.279 (2.509)	BT: 2.304 (2.580)	Loss 0.1608 (0.2188)	Prec@1 96.875 (92.533)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (2.393)	BT: 0.021 (2.462)	Loss 0.1719 (0.2161)	Prec@1 96.094 (92.578)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (2.404)	BT: 0.018 (2.512)	Loss 0.2456 (0.2135)	Prec@1 92.188 (92.693)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (2.514)	BT: 0.020 (2.607)	Loss 0.1543 (0.2141)	Prec@1 96.094 (92.672)	
Total train loss: 0.2145
Avg Loading time: 2.5078 seconds
Avg Batch time: 2.6003 seconds

Train time: 1016.8337416648865
 * Prec@1 88.050 Prec@5 99.590 Loss 0.3706
Avg Loading time: 2.8647 seconds
Avg Batch time: 3.1925 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 252.68605971336365

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (3.250)	BT: 0.018 (3.538)	Loss 0.1448 (0.2125)	Prec@1 96.094 (92.728)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (3.200)	BT: 0.018 (3.356)	Loss 0.1729 (0.2129)	Prec@1 94.531 (92.668)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (3.184)	BT: 0.020 (3.305)	Loss 0.3350 (0.2178)	Prec@1 88.281 (92.571)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (3.083)	BT: 0.018 (3.179)	Loss 0.1376 (0.2160)	Prec@1 96.875 (92.623)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (3.005)	BT: 0.027 (3.114)	Loss 0.2051 (0.2148)	Prec@1 93.750 (92.624)	
Total train loss: 0.2148
Avg Loading time: 2.9976 seconds
Avg Batch time: 3.1064 seconds

Train time: 1214.696400642395
 * Prec@1 88.020 Prec@5 99.600 Loss 0.3701
Avg Loading time: 2.3050 seconds
Avg Batch time: 2.3156 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 183.4374659061432

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (2.325)	BT: 0.018 (2.349)	Loss 0.1558 (0.2150)	Prec@1 93.750 (92.778)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (2.509)	BT: 0.018 (2.554)	Loss 0.1719 (0.2165)	Prec@1 93.750 (92.663)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 4.850 (2.735)	BT: 4.876 (2.818)	Loss 0.1968 (0.2165)	Prec@1 95.312 (92.548)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 2.740 (2.786)	BT: 2.760 (2.854)	Loss 0.2332 (0.2132)	Prec@1 92.188 (92.703)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (2.874)	BT: 0.018 (2.933)	Loss 0.1700 (0.2148)	Prec@1 92.188 (92.652)	
Total train loss: 0.2148
Avg Loading time: 2.8670 seconds
Avg Batch time: 2.9256 seconds

Train time: 1143.996149301529
 * Prec@1 88.080 Prec@5 99.600 Loss 0.3708
Avg Loading time: 2.9518 seconds
Avg Batch time: 3.1474 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 249.15011286735535

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (3.213)	BT: 0.018 (3.357)	Loss 0.2139 (0.2227)	Prec@1 93.750 (92.167)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (3.068)	BT: 0.019 (3.171)	Loss 0.3215 (0.2204)	Prec@1 88.281 (92.393)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 3.018 (3.154)	BT: 3.045 (3.250)	Loss 0.2289 (0.2156)	Prec@1 93.750 (92.575)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (3.175)	BT: 0.018 (3.254)	Loss 0.1619 (0.2156)	Prec@1 95.312 (92.621)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.012 (3.177)	BT: 0.030 (3.294)	Loss 0.1980 (0.2165)	Prec@1 90.625 (92.610)	
Total train loss: 0.2167
Avg Loading time: 3.1693 seconds
Avg Batch time: 3.2854 seconds

Train time: 1284.6762764453888
 * Prec@1 88.110 Prec@5 99.600 Loss 0.3701
Avg Loading time: 3.7559 seconds
Avg Batch time: 3.7674 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 298.106880903244

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (3.614)	BT: 0.018 (3.639)	Loss 0.3447 (0.2196)	Prec@1 85.156 (92.448)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (3.590)	BT: 0.019 (3.636)	Loss 0.2747 (0.2178)	Prec@1 89.844 (92.558)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.715 (3.535)	BT: 0.746 (3.573)	Loss 0.2192 (0.2124)	Prec@1 93.750 (92.722)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (3.329)	BT: 0.019 (3.374)	Loss 0.1586 (0.2129)	Prec@1 92.969 (92.726)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (3.208)	BT: 0.018 (3.249)	Loss 0.1394 (0.2138)	Prec@1 97.656 (92.706)	
Total train loss: 0.2139
Avg Loading time: 3.1999 seconds
Avg Batch time: 3.2410 seconds

Train time: 1267.3059794902802
 * Prec@1 88.100 Prec@5 99.610 Loss 0.3694
Avg Loading time: 2.5258 seconds
Avg Batch time: 2.5369 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 200.91382145881653

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (3.048)	BT: 0.018 (3.080)	Loss 0.2480 (0.2187)	Prec@1 91.406 (92.418)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 2.728 (2.996)	BT: 2.760 (3.091)	Loss 0.1938 (0.2128)	Prec@1 92.969 (92.628)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (3.041)	BT: 0.022 (3.132)	Loss 0.1967 (0.2116)	Prec@1 92.188 (92.698)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (3.040)	BT: 0.018 (3.124)	Loss 0.2964 (0.2120)	Prec@1 89.062 (92.681)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 1.479 (3.106)	BT: 1.498 (3.201)	Loss 0.3254 (0.2122)	Prec@1 88.281 (92.652)	
Total train loss: 0.2123
Avg Loading time: 3.0981 seconds
Avg Batch time: 3.1931 seconds

Train time: 1248.5828738212585
 * Prec@1 88.080 Prec@5 99.550 Loss 0.3701
Avg Loading time: 3.9006 seconds
Avg Batch time: 3.9128 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 309.6181049346924

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (3.509)	BT: 0.018 (3.533)	Loss 0.1580 (0.2174)	Prec@1 94.531 (92.548)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (3.374)	BT: 0.019 (3.399)	Loss 0.2128 (0.2202)	Prec@1 89.844 (92.443)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.749 (3.263)	BT: 0.779 (3.287)	Loss 0.1833 (0.2207)	Prec@1 93.750 (92.455)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (3.172)	BT: 0.018 (3.208)	Loss 0.2317 (0.2190)	Prec@1 90.625 (92.523)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (3.197)	BT: 0.018 (3.239)	Loss 0.1437 (0.2168)	Prec@1 94.531 (92.608)	
Total train loss: 0.2170
Avg Loading time: 3.1891 seconds
Avg Batch time: 3.2307 seconds

Train time: 1263.2714064121246
 * Prec@1 87.980 Prec@5 99.590 Loss 0.3689
Avg Loading time: 3.4871 seconds
Avg Batch time: 3.4997 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 276.9936513900757

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 1.018 (3.413)	BT: 1.047 (3.438)	Loss 0.1786 (0.2184)	Prec@1 93.750 (92.478)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (3.255)	BT: 0.018 (3.280)	Loss 0.2590 (0.2103)	Prec@1 90.625 (92.733)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (2.893)	BT: 0.020 (2.916)	Loss 0.1661 (0.2111)	Prec@1 94.531 (92.692)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (2.680)	BT: 0.018 (2.703)	Loss 0.2260 (0.2128)	Prec@1 92.188 (92.621)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (2.605)	BT: 0.021 (2.628)	Loss 0.1862 (0.2126)	Prec@1 94.531 (92.700)	
Total train loss: 0.2125
Avg Loading time: 2.5982 seconds
Avg Batch time: 2.6213 seconds

Train time: 1025.0058763027191
 * Prec@1 88.120 Prec@5 99.570 Loss 0.3684
Avg Loading time: 3.1513 seconds
Avg Batch time: 3.1643 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 250.46974182128906

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (3.542)	BT: 0.019 (3.568)	Loss 0.2123 (0.2179)	Prec@1 92.188 (92.228)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (3.446)	BT: 0.018 (3.474)	Loss 0.1665 (0.2201)	Prec@1 96.094 (92.393)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.233 (3.334)	BT: 0.262 (3.361)	Loss 0.2656 (0.2181)	Prec@1 91.406 (92.431)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (3.225)	BT: 0.018 (3.251)	Loss 0.2202 (0.2163)	Prec@1 92.969 (92.521)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (3.161)	BT: 0.020 (3.221)	Loss 0.1769 (0.2144)	Prec@1 94.531 (92.564)	
Total train loss: 0.2143
Avg Loading time: 3.1529 seconds
Avg Batch time: 3.2123 seconds

Train time: 1256.1240303516388
 * Prec@1 88.190 Prec@5 99.580 Loss 0.3677
Avg Loading time: 2.6881 seconds
Avg Batch time: 2.8264 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 223.79924988746643

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (3.352)	BT: 0.018 (3.377)	Loss 0.2507 (0.2191)	Prec@1 91.406 (92.428)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (3.319)	BT: 0.019 (3.344)	Loss 0.1792 (0.2159)	Prec@1 91.406 (92.378)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 1.841 (3.193)	BT: 1.869 (3.223)	Loss 0.1360 (0.2151)	Prec@1 96.875 (92.545)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (3.076)	BT: 0.018 (3.139)	Loss 0.1936 (0.2148)	Prec@1 92.969 (92.556)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (3.055)	BT: 0.018 (3.170)	Loss 0.1598 (0.2146)	Prec@1 93.750 (92.626)	
Total train loss: 0.2149
Avg Loading time: 3.0467 seconds
Avg Batch time: 3.1621 seconds

Train time: 1236.4584002494812
 * Prec@1 88.160 Prec@5 99.590 Loss 0.3684
Avg Loading time: 3.4343 seconds
Avg Batch time: 3.4464 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 272.7668688297272

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (3.495)	BT: 0.021 (3.521)	Loss 0.1339 (0.2152)	Prec@1 95.312 (92.598)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (2.969)	BT: 0.021 (2.994)	Loss 0.2419 (0.2152)	Prec@1 94.531 (92.623)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (2.575)	BT: 0.024 (2.599)	Loss 0.1726 (0.2158)	Prec@1 95.312 (92.548)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (2.330)	BT: 0.021 (2.355)	Loss 0.2285 (0.2144)	Prec@1 92.969 (92.576)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (2.134)	BT: 0.018 (2.158)	Loss 0.1681 (0.2139)	Prec@1 94.531 (92.606)	
Total train loss: 0.2139
Avg Loading time: 2.1282 seconds
Avg Batch time: 2.1527 seconds

Train time: 841.8159346580505
 * Prec@1 87.950 Prec@5 99.600 Loss 0.3691
Avg Loading time: 3.1846 seconds
Avg Batch time: 3.1967 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 253.04202437400818

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (3.049)	BT: 0.019 (3.074)	Loss 0.2211 (0.2105)	Prec@1 89.844 (92.678)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (3.109)	BT: 0.020 (3.134)	Loss 0.1686 (0.2138)	Prec@1 95.312 (92.613)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (3.106)	BT: 0.021 (3.173)	Loss 0.2268 (0.2135)	Prec@1 92.188 (92.565)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (2.880)	BT: 0.019 (2.982)	Loss 0.2825 (0.2144)	Prec@1 91.406 (92.593)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (2.818)	BT: 0.018 (2.919)	Loss 0.2233 (0.2138)	Prec@1 92.188 (92.668)	
Total train loss: 0.2139
Avg Loading time: 2.8105 seconds
Avg Batch time: 2.9117 seconds

Train time: 1138.5571582317352
 * Prec@1 88.100 Prec@5 99.570 Loss 0.3682
Avg Loading time: 2.5268 seconds
Avg Batch time: 2.5859 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 204.81588339805603

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (3.008)	BT: 0.019 (3.041)	Loss 0.2441 (0.2147)	Prec@1 90.625 (93.009)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (2.951)	BT: 0.019 (3.104)	Loss 0.1759 (0.2130)	Prec@1 92.969 (92.864)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (3.050)	BT: 0.024 (3.174)	Loss 0.2673 (0.2159)	Prec@1 91.406 (92.778)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (3.037)	BT: 0.020 (3.136)	Loss 0.2805 (0.2174)	Prec@1 89.844 (92.706)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (3.070)	BT: 0.018 (3.174)	Loss 0.2184 (0.2168)	Prec@1 91.406 (92.746)	
Total train loss: 0.2168
Avg Loading time: 3.0620 seconds
Avg Batch time: 3.1662 seconds

Train time: 1238.0387473106384
 * Prec@1 88.050 Prec@5 99.540 Loss 0.3760
Avg Loading time: 3.3489 seconds
Avg Batch time: 3.3603 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 265.9488844871521

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (3.279)	BT: 0.018 (3.303)	Loss 0.2081 (0.2213)	Prec@1 91.406 (92.157)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (3.011)	BT: 0.019 (3.034)	Loss 0.2256 (0.2194)	Prec@1 92.188 (92.383)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.945 (2.744)	BT: 0.974 (2.768)	Loss 0.1444 (0.2182)	Prec@1 97.656 (92.491)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (2.537)	BT: 0.018 (2.563)	Loss 0.2377 (0.2171)	Prec@1 91.406 (92.528)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (2.526)	BT: 0.018 (2.591)	Loss 0.1086 (0.2154)	Prec@1 95.312 (92.580)	
Total train loss: 0.2155
Avg Loading time: 2.5199 seconds
Avg Batch time: 2.5846 seconds

Train time: 1010.6558752059937
 * Prec@1 88.070 Prec@5 99.610 Loss 0.3743
Avg Loading time: 3.3650 seconds
Avg Batch time: 3.3777 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 267.34646463394165

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (3.341)	BT: 0.019 (3.365)	Loss 0.2094 (0.2107)	Prec@1 93.750 (92.678)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 1.372 (3.209)	BT: 1.399 (3.232)	Loss 0.1998 (0.2154)	Prec@1 93.750 (92.613)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (3.106)	BT: 0.020 (3.191)	Loss 0.1669 (0.2141)	Prec@1 95.312 (92.748)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (3.023)	BT: 0.018 (3.093)	Loss 0.3027 (0.2165)	Prec@1 93.750 (92.628)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.042 (2.966)	BT: 0.060 (3.053)	Loss 0.1913 (0.2148)	Prec@1 93.750 (92.686)	
Total train loss: 0.2147
Avg Loading time: 2.9583 seconds
Avg Batch time: 3.0454 seconds

Train time: 1190.8074398040771
 * Prec@1 88.110 Prec@5 99.570 Loss 0.3701
Avg Loading time: 3.1301 seconds
Avg Batch time: 3.1783 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 251.5810136795044

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (3.358)	BT: 0.020 (3.383)	Loss 0.2754 (0.2148)	Prec@1 90.625 (92.648)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 1.473 (3.182)	BT: 1.503 (3.207)	Loss 0.2323 (0.2140)	Prec@1 95.312 (92.708)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (3.150)	BT: 0.021 (3.227)	Loss 0.2695 (0.2142)	Prec@1 89.844 (92.668)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (3.085)	BT: 0.018 (3.163)	Loss 0.2196 (0.2161)	Prec@1 92.188 (92.628)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (3.056)	BT: 0.019 (3.149)	Loss 0.2693 (0.2157)	Prec@1 89.844 (92.640)	
Total train loss: 0.2158
Avg Loading time: 3.0486 seconds
Avg Batch time: 3.1409 seconds

Train time: 1228.1887288093567
 * Prec@1 88.140 Prec@5 99.600 Loss 0.3711
Avg Loading time: 3.3007 seconds
Avg Batch time: 3.3569 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 265.6874804496765

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (3.239)	BT: 0.021 (3.266)	Loss 0.2549 (0.2108)	Prec@1 91.406 (92.839)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.485 (2.945)	BT: 0.512 (2.970)	Loss 0.3198 (0.2157)	Prec@1 89.062 (92.688)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (2.700)	BT: 0.027 (2.724)	Loss 0.2181 (0.2185)	Prec@1 92.969 (92.541)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (2.576)	BT: 0.018 (2.599)	Loss 0.2174 (0.2185)	Prec@1 91.406 (92.518)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (2.667)	BT: 0.018 (2.723)	Loss 0.2539 (0.2158)	Prec@1 91.406 (92.598)	
Total train loss: 0.2158
Avg Loading time: 2.6601 seconds
Avg Batch time: 2.7158 seconds

Train time: 1061.9710235595703
 * Prec@1 88.100 Prec@5 99.580 Loss 0.3684
Avg Loading time: 3.5836 seconds
Avg Batch time: 3.6795 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 291.18637561798096

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (4.000)	BT: 0.018 (4.101)	Loss 0.1855 (0.2061)	Prec@1 92.969 (92.618)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (3.919)	BT: 0.018 (4.079)	Loss 0.2076 (0.2147)	Prec@1 91.406 (92.338)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 2.041 (3.967)	BT: 2.066 (4.159)	Loss 0.3345 (0.2154)	Prec@1 88.281 (92.411)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (3.841)	BT: 0.018 (3.991)	Loss 0.1783 (0.2160)	Prec@1 93.750 (92.430)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (3.796)	BT: 0.023 (3.942)	Loss 0.1929 (0.2140)	Prec@1 92.969 (92.590)	
Total train loss: 0.2142
Avg Loading time: 3.7861 seconds
Avg Batch time: 3.9324 seconds

Train time: 1537.6260793209076
 * Prec@1 88.160 Prec@5 99.560 Loss 0.3699
Avg Loading time: 3.5610 seconds
Avg Batch time: 3.7302 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 295.1870710849762

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (4.113)	BT: 0.018 (4.136)	Loss 0.1879 (0.2328)	Prec@1 94.531 (92.047)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (4.130)	BT: 0.018 (4.155)	Loss 0.3191 (0.2250)	Prec@1 86.719 (92.403)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.784 (3.971)	BT: 0.814 (3.996)	Loss 0.1880 (0.2202)	Prec@1 92.969 (92.545)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (3.646)	BT: 0.022 (3.708)	Loss 0.1460 (0.2160)	Prec@1 94.531 (92.643)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.180 (3.410)	BT: 0.198 (3.465)	Loss 0.2422 (0.2138)	Prec@1 92.188 (92.718)	
Total train loss: 0.2141
Avg Loading time: 3.4017 seconds
Avg Batch time: 3.4558 seconds

Train time: 1351.2917091846466
 * Prec@1 88.010 Prec@5 99.590 Loss 0.3689
Avg Loading time: 1.7202 seconds
Avg Batch time: 1.7305 seconds

Best acc: 88.240
--------------------------------------------------------------------------------
Test time: 137.20223999023438

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (2.475)	BT: 0.018 (2.498)	Loss 0.2812 (0.2097)	Prec@1 89.844 (92.508)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.416 (2.574)	BT: 0.443 (2.651)	Loss 0.2556 (0.2110)	Prec@1 92.188 (92.643)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (2.798)	BT: 0.019 (2.857)	Loss 0.1874 (0.2129)	Prec@1 93.750 (92.642)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (2.876)	BT: 0.018 (2.926)	Loss 0.1611 (0.2122)	Prec@1 94.531 (92.766)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (2.918)	BT: 0.027 (2.966)	Loss 0.2166 (0.2126)	Prec@1 92.969 (92.732)	
Total train loss: 0.2127
Avg Loading time: 2.9107 seconds
Avg Batch time: 2.9589 seconds

Train time: 1157.0083956718445
 * Prec@1 88.250 Prec@5 99.540 Loss 0.3679
Avg Loading time: 2.8802 seconds
Avg Batch time: 3.0594 seconds

Best acc: 88.250
--------------------------------------------------------------------------------
Test time: 242.909193277359


      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 15
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/train/relu15
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/test/relu15
ResNet18(
  (conv16): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 14.610 Prec@5 49.780 Loss 2.3125
Avg Loading time: 5.4453 seconds
Avg Batch time: 5.4605 seconds

Pre-trained Prec@1 with 15 layers frozen: 14.609999656677246 	 Loss: 2.3125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (5.975)	BT: 0.009 (5.989)	Loss 0.5503 (0.8364)	Prec@1 81.250 (74.038)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.190 (5.716)	BT: 0.203 (6.077)	Loss 0.4692 (0.7013)	Prec@1 85.156 (77.464)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (5.911)	BT: 0.012 (6.303)	Loss 0.5117 (0.6424)	Prec@1 80.469 (78.986)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (5.360)	BT: 0.009 (6.182)	Loss 0.6660 (0.6063)	Prec@1 79.688 (79.885)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (5.144)	BT: 0.009 (5.857)	Loss 0.4524 (0.5952)	Prec@1 85.156 (80.138)	
Total train loss: 0.5951
Avg Loading time: 5.1307 seconds
Avg Batch time: 5.8416 seconds

Train time: 2284.1761951446533
 * Prec@1 78.570 Prec@5 98.820 Loss 0.6362
Avg Loading time: 1.5714 seconds
Avg Batch time: 1.5789 seconds

Best acc: 78.570
--------------------------------------------------------------------------------
Test time: 125.34571266174316

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (1.109)	BT: 0.010 (1.121)	Loss 0.6064 (0.4864)	Prec@1 79.688 (83.634)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (1.044)	BT: 0.012 (1.056)	Loss 0.5337 (0.4742)	Prec@1 81.250 (84.130)	
Epoch: [1][233/391]	LR: 0.1	DT: 3.179 (1.491)	BT: 3.196 (1.663)	Loss 0.3303 (0.4582)	Prec@1 89.844 (84.519)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (1.607)	BT: 0.012 (2.096)	Loss 0.3796 (0.4484)	Prec@1 88.281 (84.823)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.124 (1.734)	BT: 0.134 (2.314)	Loss 0.3674 (0.4462)	Prec@1 88.281 (84.876)	
Total train loss: 0.4462
Avg Loading time: 1.7300 seconds
Avg Batch time: 2.3076 seconds

Train time: 902.3831248283386
 * Prec@1 81.000 Prec@5 98.960 Loss 0.6074
Avg Loading time: 2.7184 seconds
Avg Batch time: 3.4682 seconds

Best acc: 81.000
--------------------------------------------------------------------------------
Test time: 274.5822069644928

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (2.321)	BT: 0.009 (3.855)	Loss 0.4775 (0.3790)	Prec@1 84.375 (86.919)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (2.231)	BT: 0.012 (4.027)	Loss 0.3252 (0.3837)	Prec@1 89.844 (86.634)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (1.919)	BT: 0.009 (3.665)	Loss 0.4988 (0.3892)	Prec@1 81.250 (86.592)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (1.964)	BT: 0.010 (3.856)	Loss 0.4883 (0.3960)	Prec@1 82.812 (86.346)	
Epoch: [2][389/391]	LR: 0.1	DT: 6.253 (2.082)	BT: 6.270 (3.709)	Loss 0.5576 (0.4009)	Prec@1 84.375 (86.274)	
Total train loss: 0.4010
Avg Loading time: 2.0766 seconds
Avg Batch time: 3.6991 seconds

Train time: 1446.4504642486572
 * Prec@1 62.800 Prec@5 89.370 Loss 2.7188
Avg Loading time: 2.6971 seconds
Avg Batch time: 4.0711 seconds

Best acc: 81.000
--------------------------------------------------------------------------------
Test time: 321.98643589019775

Epoch: [3][77/391]	LR: 0.1	DT: 0.091 (2.890)	BT: 0.103 (4.431)	Loss 0.4019 (0.4043)	Prec@1 85.938 (86.208)	
Epoch: [3][155/391]	LR: 0.1	DT: 2.154 (2.338)	BT: 2.176 (3.767)	Loss 0.3088 (0.4083)	Prec@1 89.062 (86.003)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (2.150)	BT: 0.010 (3.515)	Loss 0.3623 (0.4089)	Prec@1 89.062 (85.927)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (2.264)	BT: 0.010 (3.365)	Loss 0.2407 (0.3999)	Prec@1 92.969 (86.223)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (2.213)	BT: 0.013 (3.097)	Loss 0.4331 (0.3930)	Prec@1 85.156 (86.488)	
Total train loss: 0.3929
Avg Loading time: 2.2074 seconds
Avg Batch time: 3.0886 seconds

Train time: 1207.7636141777039
 * Prec@1 84.540 Prec@5 99.440 Loss 0.4612
Avg Loading time: 2.0542 seconds
Avg Batch time: 2.3220 seconds

Best acc: 84.540
--------------------------------------------------------------------------------
Test time: 184.0244677066803

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (2.833)	BT: 0.012 (3.701)	Loss 0.4077 (0.3364)	Prec@1 81.250 (88.071)	
Epoch: [4][155/391]	LR: 0.1	DT: 3.131 (3.013)	BT: 3.146 (3.455)	Loss 0.5073 (0.3722)	Prec@1 85.938 (86.974)	
Epoch: [4][233/391]	LR: 0.1	DT: 15.432 (2.863)	BT: 15.453 (3.257)	Loss 0.4612 (0.3728)	Prec@1 84.375 (87.009)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (2.673)	BT: 0.010 (3.228)	Loss 0.4104 (0.3637)	Prec@1 84.375 (87.377)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (2.646)	BT: 0.011 (3.162)	Loss 0.3596 (0.3583)	Prec@1 85.938 (87.570)	
Total train loss: 0.3584
Avg Loading time: 2.6390 seconds
Avg Batch time: 3.1539 seconds

Train time: 1233.3129262924194
 * Prec@1 56.610 Prec@5 94.850 Loss 3.5625
Avg Loading time: 3.0566 seconds
Avg Batch time: 3.6022 seconds

Best acc: 84.540
--------------------------------------------------------------------------------
Test time: 284.92381715774536

Epoch: [5][77/391]	LR: 0.1	DT: 0.293 (2.169)	BT: 0.310 (3.178)	Loss 0.2556 (0.3162)	Prec@1 92.188 (89.002)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (2.637)	BT: 0.010 (3.148)	Loss 0.3628 (0.3288)	Prec@1 88.281 (88.637)	
Epoch: [5][233/391]	LR: 0.1	DT: 24.880 (2.669)	BT: 48.852 (3.335)	Loss 0.3682 (0.3312)	Prec@1 86.719 (88.498)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (2.411)	BT: 0.009 (3.004)	Loss 0.3955 (0.3421)	Prec@1 89.062 (88.056)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (2.534)	BT: 0.009 (3.011)	Loss 0.2632 (0.3516)	Prec@1 93.750 (87.780)	
Total train loss: 0.3517
Avg Loading time: 2.5277 seconds
Avg Batch time: 3.0036 seconds

Train time: 1174.502390384674
 * Prec@1 85.540 Prec@5 99.550 Loss 0.4231
Avg Loading time: 2.6843 seconds
Avg Batch time: 3.2461 seconds

Best acc: 85.540
--------------------------------------------------------------------------------
Test time: 257.0480535030365

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (3.273)	BT: 0.009 (3.350)	Loss 0.5552 (0.3608)	Prec@1 82.812 (87.730)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.698 (3.177)	BT: 0.716 (3.223)	Loss 0.3840 (0.3505)	Prec@1 86.719 (87.831)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (3.078)	BT: 0.016 (3.165)	Loss 0.4658 (0.3435)	Prec@1 83.594 (88.014)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (2.740)	BT: 0.009 (2.877)	Loss 0.4285 (0.3401)	Prec@1 87.500 (88.166)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.615 (2.556)	BT: 0.636 (2.669)	Loss 0.2729 (0.3396)	Prec@1 88.281 (88.143)	
Total train loss: 0.3397
Avg Loading time: 2.5496 seconds
Avg Batch time: 2.6620 seconds

Train time: 1040.9769039154053
 * Prec@1 85.900 Prec@5 99.560 Loss 0.4224
Avg Loading time: 1.9843 seconds
Avg Batch time: 2.1368 seconds

Best acc: 85.900
--------------------------------------------------------------------------------
Test time: 169.37367510795593

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (1.773)	BT: 0.010 (3.194)	Loss 0.2966 (0.3727)	Prec@1 88.281 (86.939)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (1.702)	BT: 0.011 (3.173)	Loss 0.3726 (0.3582)	Prec@1 85.938 (87.485)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (1.667)	BT: 0.014 (3.084)	Loss 0.3813 (0.3515)	Prec@1 88.281 (87.851)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (1.674)	BT: 0.009 (3.221)	Loss 0.3779 (0.3562)	Prec@1 85.938 (87.630)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (1.648)	BT: 0.013 (3.029)	Loss 0.2712 (0.3586)	Prec@1 88.281 (87.524)	
Total train loss: 0.3587
Avg Loading time: 1.6434 seconds
Avg Batch time: 3.0215 seconds

Train time: 1181.5164840221405
 * Prec@1 84.090 Prec@5 99.330 Loss 0.4675
Avg Loading time: 2.0534 seconds
Avg Batch time: 3.2684 seconds

Best acc: 85.900
--------------------------------------------------------------------------------
Test time: 258.5449547767639

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (2.901)	BT: 0.010 (4.206)	Loss 0.2698 (0.3267)	Prec@1 89.844 (88.822)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.792 (2.694)	BT: 0.813 (3.764)	Loss 0.4160 (0.3470)	Prec@1 84.375 (88.026)	
Epoch: [8][233/391]	LR: 0.1	DT: 16.925 (2.736)	BT: 16.953 (3.497)	Loss 0.2423 (0.3479)	Prec@1 91.406 (87.897)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (2.615)	BT: 0.010 (3.244)	Loss 0.3877 (0.3540)	Prec@1 86.719 (87.663)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (2.697)	BT: 0.010 (3.203)	Loss 0.3374 (0.3492)	Prec@1 87.500 (87.911)	
Total train loss: 0.3493
Avg Loading time: 2.6905 seconds
Avg Batch time: 3.1947 seconds

Train time: 1249.2595872879028
 * Prec@1 86.130 Prec@5 99.500 Loss 0.4021
Avg Loading time: 3.1345 seconds
Avg Batch time: 3.1425 seconds

Best acc: 86.130
--------------------------------------------------------------------------------
Test time: 248.88315057754517

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (2.053)	BT: 0.009 (3.383)	Loss 0.2402 (0.3041)	Prec@1 92.969 (89.373)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (2.028)	BT: 0.019 (3.579)	Loss 0.3337 (0.3159)	Prec@1 87.500 (89.128)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (1.868)	BT: 0.012 (3.131)	Loss 0.3948 (0.3169)	Prec@1 85.938 (89.103)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (1.929)	BT: 0.010 (2.938)	Loss 0.2644 (0.3170)	Prec@1 92.188 (89.037)	
Epoch: [9][389/391]	LR: 0.1	DT: 5.132 (1.981)	BT: 5.151 (2.795)	Loss 0.2556 (0.3171)	Prec@1 89.844 (89.024)	
Total train loss: 0.3171
Avg Loading time: 1.9772 seconds
Avg Batch time: 2.7890 seconds

Train time: 1090.6232180595398
 * Prec@1 83.780 Prec@5 99.500 Loss 0.5176
Avg Loading time: 2.0890 seconds
Avg Batch time: 2.4881 seconds

Best acc: 86.130
--------------------------------------------------------------------------------
Test time: 196.94234371185303

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (2.752)	BT: 0.009 (3.307)	Loss 0.3970 (0.3148)	Prec@1 89.062 (89.153)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (2.060)	BT: 0.018 (2.604)	Loss 0.2197 (0.3043)	Prec@1 92.969 (89.478)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 6.230 (2.011)	BT: 6.240 (2.379)	Loss 0.2343 (0.3018)	Prec@1 92.188 (89.587)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (2.104)	BT: 0.009 (2.382)	Loss 0.2734 (0.3016)	Prec@1 92.969 (89.626)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (2.048)	BT: 0.009 (2.324)	Loss 0.3066 (0.3014)	Prec@1 91.406 (89.615)	
Total train loss: 0.3013
Avg Loading time: 2.0424 seconds
Avg Batch time: 2.3176 seconds

Train time: 906.3090887069702
 * Prec@1 86.990 Prec@5 99.740 Loss 0.3809
Avg Loading time: 2.2723 seconds
Avg Batch time: 2.2808 seconds

Best acc: 86.990
--------------------------------------------------------------------------------
Test time: 181.41674852371216

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (1.956)	BT: 0.010 (1.969)	Loss 0.2856 (0.2968)	Prec@1 91.406 (89.613)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (2.051)	BT: 0.009 (2.063)	Loss 0.3025 (0.3017)	Prec@1 88.281 (89.694)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 2.543 (2.093)	BT: 2.555 (2.106)	Loss 0.2908 (0.2969)	Prec@1 91.406 (89.797)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (1.989)	BT: 0.009 (2.039)	Loss 0.3281 (0.2981)	Prec@1 92.188 (89.764)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (1.954)	BT: 0.009 (1.996)	Loss 0.2260 (0.2961)	Prec@1 92.969 (89.832)	
Total train loss: 0.2962
Avg Loading time: 1.9487 seconds
Avg Batch time: 1.9911 seconds

Train time: 778.5906596183777
 * Prec@1 87.180 Prec@5 99.720 Loss 0.3735
Avg Loading time: 1.5524 seconds
Avg Batch time: 2.5336 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 200.75677800178528

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (1.978)	BT: 0.009 (2.372)	Loss 0.2937 (0.2893)	Prec@1 88.281 (90.244)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 2.894 (2.072)	BT: 2.914 (2.276)	Loss 0.2952 (0.2935)	Prec@1 88.281 (90.059)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 7.573 (2.212)	BT: 7.592 (2.352)	Loss 0.2996 (0.2939)	Prec@1 86.719 (90.027)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (1.976)	BT: 0.009 (2.084)	Loss 0.2847 (0.2943)	Prec@1 89.062 (89.976)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (1.774)	BT: 0.010 (1.863)	Loss 0.2888 (0.2939)	Prec@1 91.406 (90.046)	
Total train loss: 0.2941
Avg Loading time: 1.7690 seconds
Avg Batch time: 1.8578 seconds

Train time: 726.5049695968628
 * Prec@1 86.680 Prec@5 99.710 Loss 0.3818
Avg Loading time: 1.0833 seconds
Avg Batch time: 1.0894 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 86.50060963630676

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.486 (0.938)	BT: 0.507 (0.951)	Loss 0.2346 (0.3095)	Prec@1 92.188 (89.714)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.709)	BT: 0.011 (0.721)	Loss 0.3022 (0.3088)	Prec@1 87.500 (89.694)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.603)	BT: 0.009 (0.615)	Loss 0.1792 (0.3087)	Prec@1 95.312 (89.837)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.605)	BT: 0.010 (0.617)	Loss 0.2216 (0.3080)	Prec@1 92.188 (89.781)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.965)	BT: 0.009 (0.977)	Loss 0.2773 (0.3047)	Prec@1 92.188 (89.884)	
Total train loss: 0.3050
Avg Loading time: 0.9630 seconds
Avg Batch time: 0.9749 seconds

Train time: 381.32467818260193
 * Prec@1 86.710 Prec@5 99.690 Loss 0.3794
Avg Loading time: 1.9960 seconds
Avg Batch time: 2.0035 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 158.6400396823883

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (1.217)	BT: 0.009 (1.229)	Loss 0.2239 (0.2906)	Prec@1 94.531 (89.994)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (1.437)	BT: 0.010 (1.449)	Loss 0.2861 (0.2960)	Prec@1 87.500 (89.889)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 16.728 (1.565)	BT: 16.752 (1.682)	Loss 0.3804 (0.2982)	Prec@1 86.719 (89.840)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (1.618)	BT: 0.010 (1.708)	Loss 0.2485 (0.2990)	Prec@1 93.750 (89.921)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (1.651)	BT: 0.009 (1.781)	Loss 0.3435 (0.3025)	Prec@1 89.844 (89.832)	
Total train loss: 0.3026
Avg Loading time: 1.6464 seconds
Avg Batch time: 1.7762 seconds

Train time: 694.5997204780579
 * Prec@1 86.600 Prec@5 99.610 Loss 0.3835
Avg Loading time: 1.8954 seconds
Avg Batch time: 2.0918 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 165.60870265960693

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (1.940)	BT: 0.009 (2.224)	Loss 0.3811 (0.3231)	Prec@1 82.812 (89.153)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (2.074)	BT: 0.011 (2.223)	Loss 0.3193 (0.3180)	Prec@1 89.844 (89.418)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 7.117 (2.195)	BT: 7.135 (2.299)	Loss 0.2830 (0.3135)	Prec@1 91.406 (89.620)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (2.289)	BT: 0.010 (2.370)	Loss 0.1976 (0.3131)	Prec@1 95.312 (89.663)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.145 (2.336)	BT: 0.156 (2.404)	Loss 0.2766 (0.3108)	Prec@1 89.844 (89.730)	
Total train loss: 0.3109
Avg Loading time: 2.3301 seconds
Avg Batch time: 2.3975 seconds

Train time: 937.5527613162994
 * Prec@1 86.290 Prec@5 99.650 Loss 0.3936
Avg Loading time: 1.6378 seconds
Avg Batch time: 1.6456 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 130.40484642982483

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (1.100)	BT: 0.009 (1.112)	Loss 0.2617 (0.3047)	Prec@1 91.406 (89.934)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (1.020)	BT: 0.011 (1.033)	Loss 0.3406 (0.3102)	Prec@1 92.188 (89.829)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 1.090 (1.044)	BT: 1.108 (1.057)	Loss 0.4041 (0.3093)	Prec@1 85.938 (89.797)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.897)	BT: 0.010 (0.910)	Loss 0.3235 (0.3109)	Prec@1 91.406 (89.706)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.791)	BT: 0.009 (0.804)	Loss 0.3606 (0.3102)	Prec@1 89.844 (89.627)	
Total train loss: 0.3103
Avg Loading time: 0.7893 seconds
Avg Batch time: 0.8022 seconds

Train time: 313.78695940971375
 * Prec@1 86.450 Prec@5 99.630 Loss 0.3911
Avg Loading time: 1.5695 seconds
Avg Batch time: 1.5776 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 125.00378394126892

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (2.283)	BT: 0.009 (2.296)	Loss 0.3662 (0.3097)	Prec@1 88.281 (89.503)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (2.042)	BT: 0.009 (2.055)	Loss 0.3176 (0.3109)	Prec@1 89.844 (89.553)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (1.722)	BT: 0.009 (1.821)	Loss 0.3137 (0.3105)	Prec@1 90.625 (89.784)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (1.670)	BT: 0.010 (1.798)	Loss 0.2852 (0.3136)	Prec@1 89.062 (89.626)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (1.702)	BT: 0.012 (1.851)	Loss 0.2561 (0.3150)	Prec@1 93.750 (89.579)	
Total train loss: 0.3150
Avg Loading time: 1.6973 seconds
Avg Batch time: 1.8459 seconds

Train time: 721.8795640468597
 * Prec@1 86.370 Prec@5 99.650 Loss 0.3901
Avg Loading time: 1.8111 seconds
Avg Batch time: 2.2501 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 178.1209888458252

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (1.910)	BT: 0.010 (2.245)	Loss 0.2646 (0.3157)	Prec@1 93.750 (89.443)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 1.962 (1.993)	BT: 1.980 (2.171)	Loss 0.3413 (0.3192)	Prec@1 89.062 (89.418)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 4.903 (2.021)	BT: 4.913 (2.144)	Loss 0.3772 (0.3227)	Prec@1 86.719 (89.380)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.086 (2.034)	BT: 0.095 (2.130)	Loss 0.3809 (0.3203)	Prec@1 86.719 (89.360)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.580 (2.030)	BT: 0.597 (2.109)	Loss 0.4143 (0.3215)	Prec@1 87.500 (89.287)	
Total train loss: 0.3216
Avg Loading time: 2.0246 seconds
Avg Batch time: 2.1037 seconds

Train time: 822.6689131259918
 * Prec@1 86.280 Prec@5 99.580 Loss 0.3955
Avg Loading time: 2.1252 seconds
Avg Batch time: 2.2717 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 179.84451532363892

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (2.704)	BT: 0.009 (2.752)	Loss 0.4478 (0.3204)	Prec@1 86.719 (89.353)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (1.969)	BT: 0.010 (2.000)	Loss 0.3379 (0.3198)	Prec@1 85.156 (89.413)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 1.394 (1.643)	BT: 1.414 (1.667)	Loss 0.2891 (0.3224)	Prec@1 92.969 (89.286)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (1.450)	BT: 0.012 (1.471)	Loss 0.3000 (0.3233)	Prec@1 89.844 (89.255)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (1.360)	BT: 0.009 (1.379)	Loss 0.2595 (0.3252)	Prec@1 92.188 (89.235)	
Total train loss: 0.3250
Avg Loading time: 1.3560 seconds
Avg Batch time: 1.3755 seconds

Train time: 537.9515678882599
 * Prec@1 86.050 Prec@5 99.530 Loss 0.4023
Avg Loading time: 0.5989 seconds
Avg Batch time: 0.6045 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 48.19481587409973

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.282)	BT: 0.009 (0.294)	Loss 0.3352 (0.3307)	Prec@1 85.156 (88.792)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 12.082 (0.958)	BT: 12.100 (0.971)	Loss 0.2739 (0.3271)	Prec@1 91.406 (89.057)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 1.191 (1.357)	BT: 1.213 (1.371)	Loss 0.3545 (0.3286)	Prec@1 89.844 (89.059)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (1.502)	BT: 0.010 (1.515)	Loss 0.3462 (0.3276)	Prec@1 89.062 (89.040)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.684 (1.466)	BT: 0.699 (1.479)	Loss 0.4255 (0.3256)	Prec@1 88.281 (89.103)	
Total train loss: 0.3255
Avg Loading time: 1.4621 seconds
Avg Batch time: 1.4750 seconds

Train time: 576.8430256843567
 * Prec@1 86.080 Prec@5 99.570 Loss 0.3992
Avg Loading time: 1.9827 seconds
Avg Batch time: 1.9904 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 157.59565329551697

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (1.693)	BT: 0.013 (2.043)	Loss 0.3496 (0.3344)	Prec@1 92.188 (88.872)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 2.500 (1.622)	BT: 2.516 (2.329)	Loss 0.2856 (0.3288)	Prec@1 90.625 (89.203)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (1.729)	BT: 0.013 (2.272)	Loss 0.3230 (0.3263)	Prec@1 89.062 (89.186)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (1.843)	BT: 0.009 (2.253)	Loss 0.3059 (0.3256)	Prec@1 89.062 (89.220)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (1.926)	BT: 0.012 (2.257)	Loss 0.3228 (0.3241)	Prec@1 91.406 (89.229)	
Total train loss: 0.3241
Avg Loading time: 1.9212 seconds
Avg Batch time: 2.2516 seconds

Train time: 880.5136203765869
 * Prec@1 86.150 Prec@5 99.600 Loss 0.3982
Avg Loading time: 2.3757 seconds
Avg Batch time: 2.3836 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 188.66918921470642

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (2.653)	BT: 0.009 (3.353)	Loss 0.3779 (0.3293)	Prec@1 89.062 (89.062)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 4.215 (2.314)	BT: 4.233 (3.018)	Loss 0.2512 (0.3241)	Prec@1 91.406 (89.343)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (1.870)	BT: 0.012 (2.460)	Loss 0.2988 (0.3237)	Prec@1 89.062 (89.353)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (1.671)	BT: 0.010 (2.117)	Loss 0.2546 (0.3200)	Prec@1 89.062 (89.481)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (1.524)	BT: 0.011 (1.883)	Loss 0.2839 (0.3213)	Prec@1 88.281 (89.443)	
Total train loss: 0.3214
Avg Loading time: 1.5200 seconds
Avg Batch time: 1.8780 seconds

Train time: 734.4389324188232
 * Prec@1 86.130 Prec@5 99.600 Loss 0.3992
Avg Loading time: 1.1523 seconds
Avg Batch time: 1.1588 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 91.90086793899536

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.395)	BT: 0.016 (0.409)	Loss 0.4045 (0.3220)	Prec@1 89.062 (89.123)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.338)	BT: 0.011 (0.351)	Loss 0.2957 (0.3220)	Prec@1 90.625 (89.263)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.861)	BT: 0.015 (0.874)	Loss 0.3997 (0.3211)	Prec@1 87.500 (89.393)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 3.675 (1.245)	BT: 3.694 (1.258)	Loss 0.3706 (0.3235)	Prec@1 85.156 (89.248)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (1.329)	BT: 0.009 (1.342)	Loss 0.2260 (0.3244)	Prec@1 93.750 (89.203)	
Total train loss: 0.3243
Avg Loading time: 1.3253 seconds
Avg Batch time: 1.3387 seconds

Train time: 523.5712068080902
 * Prec@1 86.160 Prec@5 99.570 Loss 0.3982
Avg Loading time: 1.6262 seconds
Avg Batch time: 1.6335 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 129.4016146659851

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (2.111)	BT: 0.013 (2.403)	Loss 0.2607 (0.3170)	Prec@1 92.188 (89.774)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.536 (2.299)	BT: 0.554 (2.515)	Loss 0.3123 (0.3209)	Prec@1 91.406 (89.508)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 11.407 (2.569)	BT: 11.425 (2.718)	Loss 0.3555 (0.3193)	Prec@1 85.156 (89.490)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (2.482)	BT: 0.009 (2.723)	Loss 0.2769 (0.3187)	Prec@1 93.750 (89.518)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (2.357)	BT: 0.009 (2.745)	Loss 0.2776 (0.3216)	Prec@1 92.969 (89.393)	
Total train loss: 0.3218
Avg Loading time: 2.3509 seconds
Avg Batch time: 2.7381 seconds

Train time: 1070.7079899311066
 * Prec@1 86.120 Prec@5 99.590 Loss 0.3989
Avg Loading time: 2.4029 seconds
Avg Batch time: 2.4117 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 190.88176655769348

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (2.337)	BT: 0.010 (2.350)	Loss 0.3167 (0.3149)	Prec@1 88.281 (89.493)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (2.043)	BT: 0.013 (2.308)	Loss 0.3379 (0.3210)	Prec@1 89.844 (89.353)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 5.984 (1.819)	BT: 6.003 (2.000)	Loss 0.2944 (0.3240)	Prec@1 90.625 (89.166)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.085 (1.627)	BT: 0.093 (1.766)	Loss 0.3110 (0.3222)	Prec@1 89.844 (89.210)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (1.514)	BT: 0.010 (1.629)	Loss 0.2407 (0.3218)	Prec@1 92.969 (89.217)	
Total train loss: 0.3218
Avg Loading time: 1.5105 seconds
Avg Batch time: 1.6246 seconds

Train time: 635.342271566391
 * Prec@1 86.160 Prec@5 99.610 Loss 0.3977
Avg Loading time: 1.0344 seconds
Avg Batch time: 1.0411 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 82.5991702079773

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.459 (0.768)	BT: 0.476 (0.780)	Loss 0.1703 (0.3239)	Prec@1 95.312 (89.513)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.432)	BT: 0.011 (0.445)	Loss 0.3687 (0.3239)	Prec@1 88.281 (89.348)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.363 (0.353)	BT: 0.374 (0.366)	Loss 0.3992 (0.3256)	Prec@1 85.156 (89.203)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.821)	BT: 0.010 (0.834)	Loss 0.3196 (0.3254)	Prec@1 88.281 (89.138)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 3.253 (1.089)	BT: 3.264 (1.102)	Loss 0.2754 (0.3220)	Prec@1 88.281 (89.247)	
Total train loss: 0.3218
Avg Loading time: 1.0858 seconds
Avg Batch time: 1.0991 seconds

Train time: 429.87653374671936
 * Prec@1 86.330 Prec@5 99.570 Loss 0.3989
Avg Loading time: 1.4897 seconds
Avg Batch time: 1.6230 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 128.65994429588318

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (1.645)	BT: 0.009 (1.658)	Loss 0.3162 (0.3219)	Prec@1 89.062 (89.073)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (1.768)	BT: 0.012 (1.781)	Loss 0.3569 (0.3241)	Prec@1 88.281 (89.143)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 4.062 (1.809)	BT: 4.080 (1.822)	Loss 0.2854 (0.3223)	Prec@1 89.062 (89.189)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (1.818)	BT: 0.009 (1.830)	Loss 0.3325 (0.3186)	Prec@1 88.281 (89.370)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (1.833)	BT: 0.010 (1.846)	Loss 0.3330 (0.3208)	Prec@1 86.719 (89.351)	
Total train loss: 0.3207
Avg Loading time: 1.8285 seconds
Avg Batch time: 1.8411 seconds

Train time: 719.9766721725464
 * Prec@1 86.330 Prec@5 99.590 Loss 0.3992
Avg Loading time: 2.2233 seconds
Avg Batch time: 2.2320 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 176.69870328903198

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 4.062 (1.776)	BT: 4.083 (2.043)	Loss 0.3501 (0.3146)	Prec@1 86.719 (89.643)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (1.883)	BT: 0.010 (2.024)	Loss 0.3828 (0.3220)	Prec@1 85.938 (89.403)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 14.628 (1.953)	BT: 14.645 (2.051)	Loss 0.2642 (0.3235)	Prec@1 92.188 (89.216)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (2.031)	BT: 0.009 (2.108)	Loss 0.3206 (0.3208)	Prec@1 89.062 (89.325)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (2.097)	BT: 0.011 (2.162)	Loss 0.2725 (0.3214)	Prec@1 89.844 (89.285)	
Total train loss: 0.3212
Avg Loading time: 2.0921 seconds
Avg Batch time: 2.1563 seconds

Train time: 843.2475996017456
 * Prec@1 86.140 Prec@5 99.550 Loss 0.3989
Avg Loading time: 1.2195 seconds
Avg Batch time: 1.2261 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 97.2484769821167

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (1.007)	BT: 0.017 (1.021)	Loss 0.3630 (0.3297)	Prec@1 85.938 (88.902)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.266 (1.005)	BT: 0.284 (1.018)	Loss 0.4648 (0.3237)	Prec@1 82.031 (89.163)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.993)	BT: 0.012 (1.006)	Loss 0.3193 (0.3229)	Prec@1 86.719 (89.166)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.877)	BT: 0.017 (0.890)	Loss 0.3542 (0.3241)	Prec@1 85.938 (89.057)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.728)	BT: 0.009 (0.741)	Loss 0.3945 (0.3224)	Prec@1 87.500 (89.161)	
Total train loss: 0.3225
Avg Loading time: 0.7263 seconds
Avg Batch time: 0.7390 seconds

Train time: 289.12855982780457
 * Prec@1 86.110 Prec@5 99.570 Loss 0.3989
Avg Loading time: 2.3538 seconds
Avg Batch time: 2.3620 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 186.95455479621887

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (2.196)	BT: 0.009 (2.210)	Loss 0.2830 (0.3090)	Prec@1 90.625 (89.864)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (1.862)	BT: 0.009 (1.874)	Loss 0.3801 (0.3128)	Prec@1 82.031 (89.809)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 9.808 (1.736)	BT: 9.823 (1.749)	Loss 0.2764 (0.3196)	Prec@1 91.406 (89.557)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (1.718)	BT: 0.011 (1.730)	Loss 0.2976 (0.3190)	Prec@1 89.844 (89.476)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.273 (1.762)	BT: 0.283 (1.774)	Loss 0.2866 (0.3194)	Prec@1 90.625 (89.477)	
Total train loss: 0.3193
Avg Loading time: 1.7571 seconds
Avg Batch time: 1.7696 seconds

Train time: 692.0589466094971
 * Prec@1 86.150 Prec@5 99.590 Loss 0.3979
Avg Loading time: 1.5012 seconds
Avg Batch time: 2.0681 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 163.70198678970337

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (2.031)	BT: 0.009 (2.042)	Loss 0.3982 (0.3262)	Prec@1 87.500 (88.862)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (1.960)	BT: 0.010 (2.160)	Loss 0.3193 (0.3219)	Prec@1 89.844 (89.068)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (1.859)	BT: 0.009 (2.110)	Loss 0.3152 (0.3196)	Prec@1 92.188 (89.156)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (1.806)	BT: 0.009 (2.138)	Loss 0.3262 (0.3195)	Prec@1 89.062 (89.263)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.056 (1.839)	BT: 0.065 (2.107)	Loss 0.1863 (0.3197)	Prec@1 93.750 (89.277)	
Total train loss: 0.3197
Avg Loading time: 1.8341 seconds
Avg Batch time: 2.1014 seconds

Train time: 821.7396132946014
 * Prec@1 86.340 Prec@5 99.600 Loss 0.3972
Avg Loading time: 0.6891 seconds
Avg Batch time: 0.6957 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 55.33101963996887

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (1.097)	BT: 0.011 (1.110)	Loss 0.2284 (0.3106)	Prec@1 94.531 (89.714)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.571 (0.700)	BT: 0.582 (0.713)	Loss 0.2031 (0.3072)	Prec@1 94.531 (89.784)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.581 (0.675)	BT: 0.600 (0.688)	Loss 0.2644 (0.3165)	Prec@1 91.406 (89.416)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.696)	BT: 0.012 (0.710)	Loss 0.3455 (0.3197)	Prec@1 87.500 (89.350)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.016 (0.693)	BT: 0.026 (0.706)	Loss 0.2456 (0.3206)	Prec@1 92.188 (89.353)	
Total train loss: 0.3207
Avg Loading time: 0.6912 seconds
Avg Batch time: 0.7044 seconds

Train time: 275.52708554267883
 * Prec@1 86.110 Prec@5 99.580 Loss 0.3984
Avg Loading time: 0.7047 seconds
Avg Batch time: 0.7113 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 56.55411195755005

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.793)	BT: 0.014 (0.807)	Loss 0.4202 (0.3244)	Prec@1 82.812 (89.153)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (1.154)	BT: 0.010 (1.167)	Loss 0.2761 (0.3180)	Prec@1 91.406 (89.368)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.038 (1.566)	BT: 0.054 (1.692)	Loss 0.3276 (0.3128)	Prec@1 91.406 (89.650)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (2.007)	BT: 0.009 (2.256)	Loss 0.3123 (0.3174)	Prec@1 92.188 (89.478)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.294 (2.264)	BT: 0.313 (2.718)	Loss 0.2744 (0.3200)	Prec@1 93.750 (89.389)	
Total train loss: 0.3200
Avg Loading time: 2.2583 seconds
Avg Batch time: 2.7112 seconds

Train time: 1060.1725912094116
 * Prec@1 86.300 Prec@5 99.500 Loss 0.3987
Avg Loading time: 3.4504 seconds
Avg Batch time: 5.2293 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 413.5116002559662

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (3.471)	BT: 0.010 (4.809)	Loss 0.4172 (0.3279)	Prec@1 88.281 (89.353)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (3.823)	BT: 0.010 (4.773)	Loss 0.3140 (0.3244)	Prec@1 92.188 (89.408)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 1.109 (3.951)	BT: 1.130 (4.784)	Loss 0.3564 (0.3207)	Prec@1 89.844 (89.466)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (3.926)	BT: 0.009 (4.748)	Loss 0.3855 (0.3203)	Prec@1 85.156 (89.340)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (3.899)	BT: 0.009 (4.717)	Loss 0.3457 (0.3214)	Prec@1 89.062 (89.259)	
Total train loss: 0.3214
Avg Loading time: 3.8890 seconds
Avg Batch time: 4.7047 seconds

Train time: 1839.6323313713074
 * Prec@1 86.200 Prec@5 99.540 Loss 0.3972
Avg Loading time: 3.8752 seconds
Avg Batch time: 4.7186 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 373.1397235393524

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (4.517)	BT: 0.009 (5.829)	Loss 0.3325 (0.3239)	Prec@1 92.188 (89.303)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (3.583)	BT: 0.010 (4.654)	Loss 0.3008 (0.3226)	Prec@1 92.188 (89.408)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 1.870 (3.064)	BT: 1.885 (3.782)	Loss 0.2659 (0.3161)	Prec@1 89.844 (89.570)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (2.635)	BT: 0.009 (3.176)	Loss 0.3774 (0.3196)	Prec@1 88.281 (89.403)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (2.335)	BT: 0.009 (2.771)	Loss 0.3689 (0.3205)	Prec@1 88.281 (89.303)	
Total train loss: 0.3206
Avg Loading time: 2.3288 seconds
Avg Batch time: 2.7636 seconds

Train time: 1080.7461335659027
 * Prec@1 86.270 Prec@5 99.580 Loss 0.3977
Avg Loading time: 1.1003 seconds
Avg Batch time: 1.1072 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 87.87998223304749

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 3.776 (1.289)	BT: 3.795 (1.302)	Loss 0.3806 (0.3254)	Prec@1 87.500 (89.283)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 2.104 (1.539)	BT: 2.120 (1.553)	Loss 0.3462 (0.3263)	Prec@1 87.500 (89.273)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 9.493 (1.933)	BT: 9.506 (1.947)	Loss 0.4089 (0.3232)	Prec@1 88.281 (89.373)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (2.181)	BT: 0.010 (2.196)	Loss 0.3772 (0.3236)	Prec@1 82.812 (89.278)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 2.736 (2.260)	BT: 2.751 (2.406)	Loss 0.2886 (0.3213)	Prec@1 89.844 (89.399)	
Total train loss: 0.3214
Avg Loading time: 2.2546 seconds
Avg Batch time: 2.4001 seconds

Train time: 938.5674242973328
 * Prec@1 86.180 Prec@5 99.600 Loss 0.3987
Avg Loading time: 2.6807 seconds
Avg Batch time: 4.1778 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 330.4195945262909

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (1.803)	BT: 0.010 (3.458)	Loss 0.3813 (0.3285)	Prec@1 89.062 (88.772)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (2.210)	BT: 0.009 (3.678)	Loss 0.3184 (0.3286)	Prec@1 89.062 (88.992)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (2.370)	BT: 0.009 (3.926)	Loss 0.2710 (0.3234)	Prec@1 88.281 (89.126)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (3.271)	BT: 0.013 (4.724)	Loss 0.2656 (0.3219)	Prec@1 89.844 (89.235)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 19.206 (3.845)	BT: 19.237 (5.138)	Loss 0.3894 (0.3214)	Prec@1 87.500 (89.259)	
Total train loss: 0.3213
Avg Loading time: 3.8349 seconds
Avg Batch time: 5.1253 seconds

Train time: 2004.1133728027344
 * Prec@1 86.220 Prec@5 99.570 Loss 0.3997
Avg Loading time: 4.7248 seconds
Avg Batch time: 5.7112 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 451.539653301239

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (2.145)	BT: 0.009 (3.913)	Loss 0.3013 (0.3200)	Prec@1 89.844 (89.263)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (2.175)	BT: 0.016 (3.988)	Loss 0.4033 (0.3196)	Prec@1 87.500 (89.308)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.000 (1.981)	BT: 0.010 (3.385)	Loss 0.2576 (0.3226)	Prec@1 91.406 (89.216)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 1.495 (2.073)	BT: 1.514 (3.129)	Loss 0.3313 (0.3231)	Prec@1 87.500 (89.158)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.233 (1.937)	BT: 0.251 (2.785)	Loss 0.3984 (0.3220)	Prec@1 89.062 (89.263)	
Total train loss: 0.3218
Avg Loading time: 1.9324 seconds
Avg Batch time: 2.7783 seconds

Train time: 1086.4903452396393
 * Prec@1 86.100 Prec@5 99.560 Loss 0.3975
Avg Loading time: 1.5269 seconds
Avg Batch time: 1.5346 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 121.61102032661438

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (1.747)	BT: 0.009 (1.761)	Loss 0.3782 (0.3199)	Prec@1 87.500 (89.333)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (2.077)	BT: 0.010 (2.090)	Loss 0.3306 (0.3223)	Prec@1 91.406 (89.348)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 18.358 (2.064)	BT: 18.397 (2.336)	Loss 0.3271 (0.3213)	Prec@1 88.281 (89.426)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (2.124)	BT: 0.010 (2.667)	Loss 0.4321 (0.3198)	Prec@1 87.500 (89.488)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (2.347)	BT: 0.010 (2.876)	Loss 0.3806 (0.3196)	Prec@1 85.938 (89.493)	
Total train loss: 0.3196
Avg Loading time: 2.3406 seconds
Avg Batch time: 2.8691 seconds

Train time: 1121.901876449585
 * Prec@1 86.280 Prec@5 99.590 Loss 0.3982
Avg Loading time: 4.3733 seconds
Avg Batch time: 5.3340 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 421.7739794254303

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (3.374)	BT: 0.009 (4.086)	Loss 0.3245 (0.3264)	Prec@1 89.844 (89.213)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (2.981)	BT: 0.010 (3.802)	Loss 0.3572 (0.3194)	Prec@1 84.375 (89.353)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (3.109)	BT: 0.011 (3.662)	Loss 0.2800 (0.3165)	Prec@1 92.188 (89.497)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (2.938)	BT: 0.009 (3.625)	Loss 0.2056 (0.3178)	Prec@1 94.531 (89.323)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.968 (2.757)	BT: 0.986 (3.588)	Loss 0.3203 (0.3197)	Prec@1 89.844 (89.277)	
Total train loss: 0.3197
Avg Loading time: 2.7498 seconds
Avg Batch time: 3.5787 seconds

Train time: 1399.404098033905
 * Prec@1 86.170 Prec@5 99.570 Loss 0.3977
Avg Loading time: 2.4330 seconds
Avg Batch time: 3.3458 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 264.637220621109

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (2.679)	BT: 0.010 (3.562)	Loss 0.3445 (0.3138)	Prec@1 87.500 (89.764)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (2.613)	BT: 0.010 (3.715)	Loss 0.3645 (0.3151)	Prec@1 89.062 (89.588)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 10.332 (2.582)	BT: 10.350 (3.322)	Loss 0.2886 (0.3153)	Prec@1 90.625 (89.503)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (2.436)	BT: 0.009 (2.994)	Loss 0.3311 (0.3199)	Prec@1 91.406 (89.426)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.060 (2.358)	BT: 0.073 (2.807)	Loss 0.2632 (0.3188)	Prec@1 90.625 (89.437)	
Total train loss: 0.3186
Avg Loading time: 2.3521 seconds
Avg Batch time: 2.7998 seconds

Train time: 1094.8471145629883
 * Prec@1 86.250 Prec@5 99.570 Loss 0.3982
Avg Loading time: 1.4934 seconds
Avg Batch time: 1.5007 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 119.15422010421753

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (1.846)	BT: 0.012 (2.277)	Loss 0.3916 (0.3260)	Prec@1 84.375 (88.872)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 1.120 (2.167)	BT: 1.138 (2.389)	Loss 0.3342 (0.3187)	Prec@1 88.281 (89.283)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 19.345 (2.471)	BT: 40.359 (2.948)	Loss 0.3542 (0.3179)	Prec@1 86.719 (89.360)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 1.233 (2.484)	BT: 1.254 (2.929)	Loss 0.2771 (0.3209)	Prec@1 91.406 (89.200)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (2.669)	BT: 0.012 (3.027)	Loss 0.2458 (0.3193)	Prec@1 92.969 (89.329)	
Total train loss: 0.3191
Avg Loading time: 2.6617 seconds
Avg Batch time: 3.0193 seconds

Train time: 1180.6388399600983
 * Prec@1 86.240 Prec@5 99.580 Loss 0.3999
Avg Loading time: 2.5632 seconds
Avg Batch time: 3.5156 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 278.07785296440125

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (2.218)	BT: 0.009 (3.497)	Loss 0.3726 (0.3152)	Prec@1 86.719 (89.303)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.713 (2.142)	BT: 0.729 (3.574)	Loss 0.2544 (0.3216)	Prec@1 89.844 (89.118)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (2.027)	BT: 0.009 (3.535)	Loss 0.2489 (0.3214)	Prec@1 92.188 (89.153)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (2.126)	BT: 0.010 (3.499)	Loss 0.2876 (0.3208)	Prec@1 88.281 (89.203)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.102 (2.154)	BT: 0.115 (3.526)	Loss 0.2681 (0.3208)	Prec@1 91.406 (89.231)	
Total train loss: 0.3209
Avg Loading time: 2.1483 seconds
Avg Batch time: 3.5174 seconds

Train time: 1375.3938674926758
 * Prec@1 86.090 Prec@5 99.610 Loss 0.3977
Avg Loading time: 1.9395 seconds
Avg Batch time: 3.1791 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 251.52580332756042

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.752 (2.229)	BT: 0.767 (3.461)	Loss 0.2644 (0.3163)	Prec@1 92.188 (89.673)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 2.214 (2.776)	BT: 2.232 (4.017)	Loss 0.2074 (0.3192)	Prec@1 96.094 (89.533)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (2.568)	BT: 0.009 (3.762)	Loss 0.4258 (0.3171)	Prec@1 86.719 (89.560)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (2.524)	BT: 0.010 (3.423)	Loss 0.3469 (0.3180)	Prec@1 86.719 (89.483)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.158 (2.449)	BT: 0.169 (3.170)	Loss 0.3289 (0.3184)	Prec@1 88.281 (89.505)	
Total train loss: 0.3184
Avg Loading time: 2.4423 seconds
Avg Batch time: 3.1621 seconds

Train time: 1236.483784198761
 * Prec@1 86.200 Prec@5 99.590 Loss 0.3972
Avg Loading time: 1.7435 seconds
Avg Batch time: 1.7527 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 138.83793997764587

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (1.586)	BT: 0.012 (1.598)	Loss 0.3052 (0.3115)	Prec@1 90.625 (89.894)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.997 (1.735)	BT: 1.015 (1.748)	Loss 0.3340 (0.3184)	Prec@1 90.625 (89.699)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.347 (1.810)	BT: 0.363 (1.824)	Loss 0.2610 (0.3185)	Prec@1 92.188 (89.590)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (2.251)	BT: 0.012 (2.265)	Loss 0.2496 (0.3209)	Prec@1 92.969 (89.453)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (2.538)	BT: 0.012 (2.553)	Loss 0.3596 (0.3195)	Prec@1 89.844 (89.447)	
Total train loss: 0.3197
Avg Loading time: 2.5319 seconds
Avg Batch time: 2.5460 seconds

Train time: 995.6596310138702
 * Prec@1 86.190 Prec@5 99.550 Loss 0.3987
Avg Loading time: 3.1303 seconds
Avg Batch time: 4.7672 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 376.97725343704224

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (2.870)	BT: 0.009 (3.740)	Loss 0.2869 (0.3181)	Prec@1 90.625 (89.313)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (2.721)	BT: 0.011 (3.737)	Loss 0.2231 (0.3158)	Prec@1 93.750 (89.278)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 29.603 (2.487)	BT: 47.147 (3.504)	Loss 0.2593 (0.3174)	Prec@1 89.844 (89.330)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (2.436)	BT: 0.009 (3.391)	Loss 0.3159 (0.3197)	Prec@1 90.625 (89.283)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (2.528)	BT: 0.009 (3.573)	Loss 0.3701 (0.3189)	Prec@1 84.375 (89.353)	
Total train loss: 0.3188
Avg Loading time: 2.5213 seconds
Avg Batch time: 3.5634 seconds

Train time: 1393.3947677612305
 * Prec@1 86.300 Prec@5 99.570 Loss 0.3979
Avg Loading time: 3.2400 seconds
Avg Batch time: 4.2763 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 338.20293831825256

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (3.171)	BT: 0.009 (3.970)	Loss 0.2732 (0.3219)	Prec@1 90.625 (88.882)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.336 (3.023)	BT: 0.352 (3.531)	Loss 0.2395 (0.3212)	Prec@1 91.406 (89.178)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 3.719 (2.673)	BT: 3.735 (3.016)	Loss 0.3723 (0.3208)	Prec@1 88.281 (89.410)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 2.758 (2.563)	BT: 2.775 (2.824)	Loss 0.3706 (0.3215)	Prec@1 89.062 (89.298)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (2.591)	BT: 0.009 (2.802)	Loss 0.2937 (0.3203)	Prec@1 87.500 (89.361)	
Total train loss: 0.3202
Avg Loading time: 2.5848 seconds
Avg Batch time: 2.7951 seconds

Train time: 1092.9929847717285
 * Prec@1 86.170 Prec@5 99.580 Loss 0.3984
Avg Loading time: 2.9234 seconds
Avg Batch time: 2.9814 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 235.8848361968994

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (2.577)	BT: 0.009 (2.592)	Loss 0.3425 (0.3176)	Prec@1 86.719 (89.333)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (2.631)	BT: 0.012 (2.646)	Loss 0.2883 (0.3237)	Prec@1 89.844 (89.278)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (2.564)	BT: 0.009 (3.024)	Loss 0.3079 (0.3208)	Prec@1 87.500 (89.323)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (2.509)	BT: 0.009 (3.178)	Loss 0.4473 (0.3221)	Prec@1 88.281 (89.313)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (2.501)	BT: 0.011 (3.316)	Loss 0.2664 (0.3200)	Prec@1 92.188 (89.357)	
Total train loss: 0.3200
Avg Loading time: 2.4941 seconds
Avg Batch time: 3.3073 seconds

Train time: 1293.270580291748
 * Prec@1 86.030 Prec@5 99.610 Loss 0.4016
Avg Loading time: 3.3244 seconds
Avg Batch time: 4.9939 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 394.90812945365906

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (3.050)	BT: 0.009 (4.620)	Loss 0.2734 (0.3187)	Prec@1 92.188 (89.383)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (2.965)	BT: 0.010 (4.303)	Loss 0.2825 (0.3205)	Prec@1 91.406 (89.453)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (3.087)	BT: 0.013 (4.014)	Loss 0.2236 (0.3175)	Prec@1 92.969 (89.630)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.001 (2.792)	BT: 0.010 (3.780)	Loss 0.2991 (0.3189)	Prec@1 92.188 (89.446)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (2.582)	BT: 0.009 (3.570)	Loss 0.2766 (0.3195)	Prec@1 89.844 (89.421)	
Total train loss: 0.3196
Avg Loading time: 2.5751 seconds
Avg Batch time: 3.5613 seconds

Train time: 1392.5828680992126
 * Prec@1 86.040 Prec@5 99.580 Loss 0.3977
Avg Loading time: 2.2684 seconds
Avg Batch time: 3.1782 seconds

Best acc: 87.180
--------------------------------------------------------------------------------
Test time: 251.45214462280273


      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 17
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/train/relu17
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/test/relu17
ResNet18(
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 4.860 Prec@5 41.110 Loss 2.3613
Avg Loading time: 5.1191 seconds
Avg Batch time: 5.1636 seconds

Pre-trained Prec@1 with 17 layers frozen: 4.859999656677246 	 Loss: 2.361328125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (6.484)	BT: 0.006 (6.493)	Loss 0.6982 (0.9827)	Prec@1 80.469 (68.830)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (5.084)	BT: 0.008 (5.776)	Loss 0.5669 (0.8369)	Prec@1 77.344 (72.626)	
Epoch: [0][233/391]	LR: 0.1	DT: 20.167 (4.652)	BT: 29.967 (5.393)	Loss 0.7612 (0.7783)	Prec@1 70.312 (74.162)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (4.328)	BT: 0.005 (5.553)	Loss 0.4668 (0.7435)	Prec@1 84.375 (75.215)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.034 (4.330)	BT: 0.042 (5.773)	Loss 0.5635 (0.7169)	Prec@1 78.906 (75.956)	
Total train loss: 0.7168
Avg Loading time: 4.3192 seconds
Avg Batch time: 5.7587 seconds

Train time: 2251.769656419754
 * Prec@1 79.000 Prec@5 99.070 Loss 0.6089
Avg Loading time: 3.0094 seconds
Avg Batch time: 3.5881 seconds

Best acc: 79.000
--------------------------------------------------------------------------------
Test time: 283.5948555469513

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (2.280)	BT: 0.006 (3.231)	Loss 0.5908 (0.5975)	Prec@1 82.812 (79.387)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (2.361)	BT: 0.007 (3.155)	Loss 0.6421 (0.5916)	Prec@1 78.906 (79.828)	
Epoch: [1][233/391]	LR: 0.1	DT: 1.729 (2.549)	BT: 1.742 (3.213)	Loss 0.5190 (0.5900)	Prec@1 83.594 (79.841)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (2.586)	BT: 0.004 (3.221)	Loss 0.5776 (0.5881)	Prec@1 78.125 (79.880)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (2.526)	BT: 0.004 (3.292)	Loss 0.5825 (0.5868)	Prec@1 82.031 (79.872)	
Total train loss: 0.5867
Avg Loading time: 2.5193 seconds
Avg Batch time: 3.2840 seconds

Train time: 1284.1612300872803
 * Prec@1 79.870 Prec@5 99.190 Loss 0.5801
Avg Loading time: 1.9494 seconds
Avg Batch time: 2.5393 seconds

Best acc: 79.870
--------------------------------------------------------------------------------
Test time: 200.7484176158905

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (1.671)	BT: 0.005 (2.581)	Loss 0.5918 (0.5528)	Prec@1 78.125 (80.869)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.814 (2.145)	BT: 0.825 (2.674)	Loss 0.5332 (0.5679)	Prec@1 82.031 (80.564)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (2.143)	BT: 0.004 (2.584)	Loss 0.4929 (0.5644)	Prec@1 80.469 (80.529)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (2.288)	BT: 0.006 (2.621)	Loss 0.6143 (0.5645)	Prec@1 81.250 (80.571)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (2.204)	BT: 0.005 (2.543)	Loss 0.6694 (0.5652)	Prec@1 76.562 (80.585)	
Total train loss: 0.5654
Avg Loading time: 2.1981 seconds
Avg Batch time: 2.5367 seconds

Train time: 992.0113167762756
 * Prec@1 80.290 Prec@5 99.160 Loss 0.5698
Avg Loading time: 1.8475 seconds
Avg Batch time: 2.5900 seconds

Best acc: 80.290
--------------------------------------------------------------------------------
Test time: 204.73961782455444

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (1.436)	BT: 0.006 (2.198)	Loss 0.5093 (0.5335)	Prec@1 83.594 (81.671)	
Epoch: [3][155/391]	LR: 0.1	DT: 8.911 (1.659)	BT: 8.924 (2.043)	Loss 0.5181 (0.5415)	Prec@1 80.469 (81.586)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (1.945)	BT: 0.004 (2.204)	Loss 0.4685 (0.5448)	Prec@1 81.250 (81.400)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (2.189)	BT: 0.004 (2.385)	Loss 0.3423 (0.5520)	Prec@1 89.844 (81.057)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (2.331)	BT: 0.005 (2.489)	Loss 0.7051 (0.5540)	Prec@1 78.125 (81.008)	
Total train loss: 0.5540
Avg Loading time: 2.3253 seconds
Avg Batch time: 2.4829 seconds

Train time: 970.9193601608276
 * Prec@1 80.340 Prec@5 99.240 Loss 0.5698
Avg Loading time: 3.1776 seconds
Avg Batch time: 3.1851 seconds

Best acc: 80.340
--------------------------------------------------------------------------------
Test time: 251.75122809410095

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (2.574)	BT: 0.007 (3.521)	Loss 0.6597 (0.5543)	Prec@1 76.562 (80.839)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.001 (2.136)	BT: 0.016 (3.325)	Loss 0.4429 (0.5445)	Prec@1 82.812 (81.135)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (2.195)	BT: 0.013 (3.261)	Loss 0.6875 (0.5455)	Prec@1 78.906 (81.093)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (2.149)	BT: 0.005 (3.377)	Loss 0.5596 (0.5445)	Prec@1 82.812 (81.095)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (2.162)	BT: 0.006 (3.397)	Loss 0.6670 (0.5454)	Prec@1 79.688 (81.086)	
Total train loss: 0.5456
Avg Loading time: 2.1567 seconds
Avg Batch time: 3.3887 seconds

Train time: 1325.0999541282654
 * Prec@1 80.420 Prec@5 99.200 Loss 0.5649
Avg Loading time: 2.3134 seconds
Avg Batch time: 2.7094 seconds

Best acc: 80.420
--------------------------------------------------------------------------------
Test time: 214.23267030715942

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (2.403)	BT: 0.008 (2.412)	Loss 0.5791 (0.5288)	Prec@1 78.125 (81.861)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.007 (1.898)	BT: 0.017 (1.906)	Loss 0.5029 (0.5408)	Prec@1 78.125 (81.400)	
Epoch: [5][233/391]	LR: 0.1	DT: 1.466 (1.782)	BT: 1.476 (1.790)	Loss 0.4844 (0.5337)	Prec@1 82.031 (81.550)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.062 (1.672)	BT: 0.070 (1.680)	Loss 0.4893 (0.5361)	Prec@1 82.031 (81.458)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (1.614)	BT: 0.005 (1.622)	Loss 0.7100 (0.5375)	Prec@1 74.219 (81.456)	
Total train loss: 0.5375
Avg Loading time: 1.6097 seconds
Avg Batch time: 1.6177 seconds

Train time: 632.6406128406525
 * Prec@1 81.110 Prec@5 99.220 Loss 0.5527
Avg Loading time: 2.3843 seconds
Avg Batch time: 2.5322 seconds

Best acc: 81.110
--------------------------------------------------------------------------------
Test time: 200.26827692985535

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (2.813)	BT: 0.006 (2.821)	Loss 0.4272 (0.5298)	Prec@1 82.031 (81.560)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (2.272)	BT: 0.008 (2.280)	Loss 0.6001 (0.5312)	Prec@1 85.938 (81.545)	
Epoch: [6][233/391]	LR: 0.1	DT: 3.107 (2.010)	BT: 3.122 (2.018)	Loss 0.5967 (0.5300)	Prec@1 79.688 (81.704)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (1.910)	BT: 0.005 (1.918)	Loss 0.5386 (0.5328)	Prec@1 84.375 (81.663)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (1.882)	BT: 0.006 (1.890)	Loss 0.5405 (0.5363)	Prec@1 79.688 (81.492)	
Total train loss: 0.5366
Avg Loading time: 1.8774 seconds
Avg Batch time: 1.8853 seconds

Train time: 737.2640612125397
 * Prec@1 81.160 Prec@5 99.250 Loss 0.5498
Avg Loading time: 2.3272 seconds
Avg Batch time: 3.0724 seconds

Best acc: 81.160
--------------------------------------------------------------------------------
Test time: 242.83456015586853

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (2.419)	BT: 0.004 (3.039)	Loss 0.5874 (0.5224)	Prec@1 79.688 (82.151)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (2.423)	BT: 0.007 (3.029)	Loss 0.4722 (0.5231)	Prec@1 85.156 (82.031)	
Epoch: [7][233/391]	LR: 0.1	DT: 8.084 (2.444)	BT: 8.100 (3.306)	Loss 0.6694 (0.5244)	Prec@1 81.250 (82.068)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (2.276)	BT: 0.005 (3.271)	Loss 0.5386 (0.5259)	Prec@1 79.688 (81.984)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (2.150)	BT: 0.008 (3.195)	Loss 0.5249 (0.5309)	Prec@1 85.156 (81.833)	
Total train loss: 0.5308
Avg Loading time: 2.1447 seconds
Avg Batch time: 3.1870 seconds

Train time: 1246.2230458259583
 * Prec@1 81.090 Prec@5 99.270 Loss 0.5586
Avg Loading time: 2.3096 seconds
Avg Batch time: 3.1681 seconds

Best acc: 81.160
--------------------------------------------------------------------------------
Test time: 250.483540058136

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (3.716)	BT: 0.007 (3.725)	Loss 0.3777 (0.5432)	Prec@1 87.500 (80.809)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.473 (3.769)	BT: 0.485 (3.778)	Loss 0.6128 (0.5346)	Prec@1 76.562 (81.465)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (3.549)	BT: 0.007 (3.557)	Loss 0.6470 (0.5274)	Prec@1 78.125 (81.884)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (3.080)	BT: 0.004 (3.088)	Loss 0.4221 (0.5251)	Prec@1 86.719 (81.934)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (2.758)	BT: 0.006 (2.876)	Loss 0.6353 (0.5274)	Prec@1 75.781 (81.851)	
Total train loss: 0.5277
Avg Loading time: 2.7506 seconds
Avg Batch time: 2.8686 seconds

Train time: 1121.770387172699
 * Prec@1 80.750 Prec@5 99.260 Loss 0.5566
Avg Loading time: 1.1716 seconds
Avg Batch time: 1.5399 seconds

Best acc: 81.160
--------------------------------------------------------------------------------
Test time: 121.79378032684326

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (1.212)	BT: 0.004 (1.218)	Loss 0.5063 (0.5244)	Prec@1 79.688 (82.242)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (1.465)	BT: 0.005 (1.471)	Loss 0.5127 (0.5317)	Prec@1 84.375 (81.916)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (1.531)	BT: 0.006 (1.538)	Loss 0.4675 (0.5265)	Prec@1 84.375 (82.018)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (1.556)	BT: 0.005 (1.563)	Loss 0.5435 (0.5247)	Prec@1 82.031 (82.029)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (1.585)	BT: 0.007 (1.592)	Loss 0.5913 (0.5218)	Prec@1 83.594 (82.077)	
Total train loss: 0.5220
Avg Loading time: 1.5807 seconds
Avg Batch time: 1.5875 seconds

Train time: 620.8182001113892
 * Prec@1 81.190 Prec@5 99.230 Loss 0.5532
Avg Loading time: 1.2679 seconds
Avg Batch time: 1.2729 seconds

Best acc: 81.190
--------------------------------------------------------------------------------
Test time: 100.68725299835205

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (1.064)	BT: 0.006 (1.072)	Loss 0.4180 (0.5142)	Prec@1 87.500 (82.242)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (1.039)	BT: 0.012 (1.047)	Loss 0.4292 (0.5066)	Prec@1 83.594 (82.502)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 3.737 (1.023)	BT: 3.754 (1.030)	Loss 0.5420 (0.5144)	Prec@1 88.281 (82.262)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.988)	BT: 0.009 (0.996)	Loss 0.5112 (0.5291)	Prec@1 82.031 (82.014)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.148 (0.959)	BT: 0.156 (0.967)	Loss 0.6050 (0.5371)	Prec@1 80.469 (82.101)	
Total train loss: 0.5372
Avg Loading time: 0.9567 seconds
Avg Batch time: 0.9649 seconds

Train time: 377.3795599937439
 * Prec@1 81.090 Prec@5 99.270 Loss 0.5742
Avg Loading time: 0.9574 seconds
Avg Batch time: 0.9630 seconds

Best acc: 81.190
--------------------------------------------------------------------------------
Test time: 76.21710538864136

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (1.286)	BT: 0.005 (1.293)	Loss 0.5337 (0.5344)	Prec@1 81.250 (82.983)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (1.496)	BT: 0.006 (1.503)	Loss 0.5566 (0.5311)	Prec@1 80.469 (82.792)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 6.126 (1.558)	BT: 6.140 (1.565)	Loss 0.5283 (0.5283)	Prec@1 82.812 (82.846)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (1.563)	BT: 0.004 (1.570)	Loss 0.5171 (0.5276)	Prec@1 86.719 (82.690)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (1.575)	BT: 0.008 (1.582)	Loss 0.5537 (0.5278)	Prec@1 81.250 (82.648)	
Total train loss: 0.5276
Avg Loading time: 1.5705 seconds
Avg Batch time: 1.5777 seconds

Train time: 616.9818606376648
 * Prec@1 81.450 Prec@5 99.220 Loss 0.5420
Avg Loading time: 1.7047 seconds
Avg Batch time: 1.7101 seconds

Best acc: 81.450
--------------------------------------------------------------------------------
Test time: 135.22168254852295

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (1.963)	BT: 0.005 (1.970)	Loss 0.5127 (0.5050)	Prec@1 81.250 (82.933)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (1.977)	BT: 0.007 (1.985)	Loss 0.6133 (0.5088)	Prec@1 78.906 (83.003)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 2.087 (1.993)	BT: 2.099 (2.001)	Loss 0.4177 (0.5116)	Prec@1 86.719 (82.772)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.840 (1.956)	BT: 0.851 (1.964)	Loss 0.4412 (0.5134)	Prec@1 86.719 (82.810)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (1.905)	BT: 0.008 (1.914)	Loss 0.4431 (0.5141)	Prec@1 83.594 (82.867)	
Total train loss: 0.5143
Avg Loading time: 1.9000 seconds
Avg Batch time: 1.9088 seconds

Train time: 746.4635236263275
 * Prec@1 81.680 Prec@5 99.260 Loss 0.5454
Avg Loading time: 1.5266 seconds
Avg Batch time: 1.5325 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 121.178635597229

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.829 (1.625)	BT: 0.838 (1.632)	Loss 0.5327 (0.5215)	Prec@1 80.469 (82.422)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (1.651)	BT: 0.005 (1.658)	Loss 0.6514 (0.5212)	Prec@1 81.250 (82.732)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 1.168 (1.667)	BT: 1.179 (1.674)	Loss 0.5654 (0.5256)	Prec@1 85.156 (82.592)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (1.629)	BT: 0.004 (1.636)	Loss 0.6064 (0.5304)	Prec@1 82.812 (82.499)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (1.634)	BT: 0.004 (1.641)	Loss 0.4277 (0.5240)	Prec@1 83.594 (82.638)	
Total train loss: 0.5238
Avg Loading time: 1.6297 seconds
Avg Batch time: 1.6372 seconds

Train time: 640.2518360614777
 * Prec@1 81.420 Prec@5 99.270 Loss 0.5420
Avg Loading time: 1.5201 seconds
Avg Batch time: 1.5257 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 120.62709546089172

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.704 (1.214)	BT: 0.714 (1.222)	Loss 0.4797 (0.5071)	Prec@1 84.375 (82.672)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.044 (1.181)	BT: 0.048 (1.189)	Loss 0.5806 (0.5118)	Prec@1 79.688 (82.772)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 2.078 (1.196)	BT: 2.090 (1.204)	Loss 0.5615 (0.5150)	Prec@1 78.125 (82.756)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (1.184)	BT: 0.006 (1.192)	Loss 0.4539 (0.5136)	Prec@1 85.156 (82.757)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (1.192)	BT: 0.006 (1.200)	Loss 0.5508 (0.5133)	Prec@1 82.031 (82.798)	
Total train loss: 0.5136
Avg Loading time: 1.1887 seconds
Avg Batch time: 1.1973 seconds

Train time: 468.27422857284546
 * Prec@1 81.680 Prec@5 99.250 Loss 0.5513
Avg Loading time: 2.0048 seconds
Avg Batch time: 2.0105 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 158.97050023078918

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.875 (2.139)	BT: 0.885 (2.146)	Loss 0.4399 (0.5258)	Prec@1 89.844 (82.662)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (2.060)	BT: 0.007 (2.068)	Loss 0.5718 (0.5267)	Prec@1 82.812 (82.828)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (1.923)	BT: 0.009 (1.931)	Loss 0.5518 (0.5262)	Prec@1 79.688 (82.706)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (1.830)	BT: 0.004 (1.838)	Loss 0.4053 (0.5217)	Prec@1 85.156 (82.760)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (1.708)	BT: 0.005 (1.716)	Loss 0.4006 (0.5206)	Prec@1 85.938 (82.718)	
Total train loss: 0.5206
Avg Loading time: 1.7041 seconds
Avg Batch time: 1.7119 seconds

Train time: 669.4794158935547
 * Prec@1 81.620 Prec@5 99.270 Loss 0.5420
Avg Loading time: 1.0831 seconds
Avg Batch time: 1.0887 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 86.15088605880737

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (1.067)	BT: 0.010 (1.075)	Loss 0.5889 (0.5224)	Prec@1 79.688 (82.482)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (1.012)	BT: 0.005 (1.020)	Loss 0.5337 (0.5273)	Prec@1 81.250 (82.327)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (1.035)	BT: 0.007 (1.042)	Loss 0.5815 (0.5296)	Prec@1 79.688 (82.395)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.823 (1.055)	BT: 0.834 (1.063)	Loss 0.5562 (0.5252)	Prec@1 76.562 (82.532)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 1.037 (1.129)	BT: 1.048 (1.137)	Loss 0.5947 (0.5228)	Prec@1 82.031 (82.706)	
Total train loss: 0.5226
Avg Loading time: 1.1257 seconds
Avg Batch time: 1.1337 seconds

Train time: 443.3812401294708
 * Prec@1 81.510 Prec@5 99.230 Loss 0.5547
Avg Loading time: 2.0621 seconds
Avg Batch time: 2.0673 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 163.46152257919312

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (2.117)	BT: 0.006 (2.125)	Loss 0.5898 (0.5176)	Prec@1 82.812 (82.792)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 1.718 (1.994)	BT: 1.729 (2.002)	Loss 0.5532 (0.5140)	Prec@1 81.250 (82.702)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 1.205 (1.851)	BT: 1.217 (1.859)	Loss 0.4604 (0.5210)	Prec@1 84.375 (82.399)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.869 (1.746)	BT: 0.879 (1.754)	Loss 0.4551 (0.5214)	Prec@1 85.938 (82.342)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (1.720)	BT: 0.007 (1.728)	Loss 0.5225 (0.5231)	Prec@1 82.031 (82.412)	
Total train loss: 0.5232
Avg Loading time: 1.7157 seconds
Avg Batch time: 1.7239 seconds

Train time: 674.1628830432892
 * Prec@1 81.310 Prec@5 99.260 Loss 0.5566
Avg Loading time: 1.6317 seconds
Avg Batch time: 1.6369 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 129.43857741355896

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (1.724)	BT: 0.009 (1.731)	Loss 0.5322 (0.5204)	Prec@1 79.688 (82.522)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (1.718)	BT: 0.005 (1.726)	Loss 0.6084 (0.5333)	Prec@1 81.250 (82.362)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (1.730)	BT: 0.008 (1.737)	Loss 0.4463 (0.5321)	Prec@1 88.281 (82.485)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (1.698)	BT: 0.004 (1.705)	Loss 0.6714 (0.5312)	Prec@1 75.781 (82.467)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (1.705)	BT: 0.004 (1.711)	Loss 0.5908 (0.5291)	Prec@1 81.250 (82.494)	
Total train loss: 0.5290
Avg Loading time: 1.7003 seconds
Avg Batch time: 1.7068 seconds

Train time: 667.4987971782684
 * Prec@1 81.380 Prec@5 99.220 Loss 0.5508
Avg Loading time: 1.7882 seconds
Avg Batch time: 1.7936 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 141.821546792984

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (2.062)	BT: 0.006 (2.070)	Loss 0.5454 (0.5229)	Prec@1 82.812 (82.632)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 2.273 (2.135)	BT: 2.285 (2.143)	Loss 0.5117 (0.5262)	Prec@1 82.812 (82.687)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (2.041)	BT: 0.009 (2.049)	Loss 0.4856 (0.5248)	Prec@1 82.031 (82.632)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (1.809)	BT: 0.004 (1.817)	Loss 0.4854 (0.5264)	Prec@1 85.156 (82.605)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (1.667)	BT: 0.005 (1.675)	Loss 0.5889 (0.5252)	Prec@1 81.250 (82.614)	
Total train loss: 0.5255
Avg Loading time: 1.6627 seconds
Avg Batch time: 1.6702 seconds

Train time: 653.1757600307465
 * Prec@1 81.290 Prec@5 99.300 Loss 0.5698
Avg Loading time: 1.1193 seconds
Avg Batch time: 1.1249 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 89.01023840904236

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.315 (1.220)	BT: 0.326 (1.228)	Loss 0.5386 (0.5476)	Prec@1 85.938 (82.402)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.144 (1.221)	BT: 0.148 (1.229)	Loss 0.7100 (0.5439)	Prec@1 75.781 (82.397)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (1.233)	BT: 0.006 (1.241)	Loss 0.5586 (0.5445)	Prec@1 80.469 (82.422)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (1.330)	BT: 0.004 (1.338)	Loss 0.5010 (0.5410)	Prec@1 84.375 (82.590)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.007 (1.393)	BT: 0.011 (1.402)	Loss 0.6499 (0.5416)	Prec@1 80.469 (82.490)	
Total train loss: 0.5415
Avg Loading time: 1.3898 seconds
Avg Batch time: 1.3979 seconds

Train time: 546.7130529880524
 * Prec@1 81.350 Prec@5 99.270 Loss 0.5688
Avg Loading time: 1.9927 seconds
Avg Batch time: 1.9980 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 157.95750641822815

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (1.999)	BT: 0.005 (2.006)	Loss 0.5015 (0.5403)	Prec@1 85.156 (82.562)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (2.025)	BT: 0.004 (2.031)	Loss 0.5068 (0.5381)	Prec@1 86.719 (82.833)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.281 (1.868)	BT: 0.293 (1.874)	Loss 0.5796 (0.5409)	Prec@1 83.594 (82.612)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (1.644)	BT: 0.004 (1.651)	Loss 0.3857 (0.5396)	Prec@1 85.156 (82.697)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (1.501)	BT: 0.006 (1.507)	Loss 0.5752 (0.5413)	Prec@1 83.594 (82.680)	
Total train loss: 0.5414
Avg Loading time: 1.4972 seconds
Avg Batch time: 1.5036 seconds

Train time: 588.0563678741455
 * Prec@1 81.390 Prec@5 99.270 Loss 0.5698
Avg Loading time: 0.9759 seconds
Avg Batch time: 0.9820 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 77.6911826133728

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (1.050)	BT: 0.004 (1.056)	Loss 0.4587 (0.5408)	Prec@1 86.719 (82.422)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (1.058)	BT: 0.005 (1.064)	Loss 0.5166 (0.5431)	Prec@1 82.812 (82.412)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (1.072)	BT: 0.006 (1.078)	Loss 0.4912 (0.5409)	Prec@1 85.938 (82.439)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (1.122)	BT: 0.004 (1.128)	Loss 0.5488 (0.5411)	Prec@1 84.375 (82.492)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (1.227)	BT: 0.004 (1.233)	Loss 0.5664 (0.5408)	Prec@1 81.250 (82.482)	
Total train loss: 0.5407
Avg Loading time: 1.2241 seconds
Avg Batch time: 1.2302 seconds

Train time: 481.11376953125
 * Prec@1 81.200 Prec@5 99.260 Loss 0.5620
Avg Loading time: 1.7109 seconds
Avg Batch time: 1.7165 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 135.73102831840515

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (1.713)	BT: 0.006 (1.720)	Loss 0.4702 (0.5385)	Prec@1 82.812 (82.802)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (1.776)	BT: 0.006 (1.784)	Loss 0.5303 (0.5382)	Prec@1 86.719 (82.582)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 5.070 (1.839)	BT: 5.082 (1.847)	Loss 0.5498 (0.5382)	Prec@1 82.812 (82.499)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (1.868)	BT: 0.004 (1.875)	Loss 0.4827 (0.5380)	Prec@1 85.938 (82.424)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (1.927)	BT: 0.004 (1.934)	Loss 0.4578 (0.5387)	Prec@1 85.156 (82.480)	
Total train loss: 0.5390
Avg Loading time: 1.9217 seconds
Avg Batch time: 1.9290 seconds

Train time: 754.3722245693207
 * Prec@1 81.310 Prec@5 99.230 Loss 0.5674
Avg Loading time: 1.8701 seconds
Avg Batch time: 1.8762 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 148.34481596946716

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (1.713)	BT: 0.005 (1.721)	Loss 0.5264 (0.5502)	Prec@1 84.375 (81.921)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (1.762)	BT: 0.006 (1.770)	Loss 0.5547 (0.5437)	Prec@1 80.469 (82.237)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 3.127 (1.733)	BT: 3.139 (1.741)	Loss 0.4893 (0.5469)	Prec@1 84.375 (82.081)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (1.687)	BT: 0.004 (1.694)	Loss 0.5522 (0.5423)	Prec@1 82.031 (82.302)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (1.696)	BT: 0.005 (1.703)	Loss 0.4922 (0.5407)	Prec@1 84.375 (82.492)	
Total train loss: 0.5407
Avg Loading time: 1.6917 seconds
Avg Batch time: 1.6988 seconds

Train time: 664.3271808624268
 * Prec@1 81.160 Prec@5 99.250 Loss 0.5649
Avg Loading time: 1.7569 seconds
Avg Batch time: 1.7624 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 139.35883688926697

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (1.609)	BT: 0.004 (1.616)	Loss 0.5874 (0.5504)	Prec@1 80.469 (82.011)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.252 (1.373)	BT: 0.262 (1.381)	Loss 0.4609 (0.5425)	Prec@1 85.156 (82.257)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 2.545 (1.305)	BT: 2.558 (1.313)	Loss 0.6182 (0.5438)	Prec@1 76.562 (82.392)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (1.246)	BT: 0.004 (1.254)	Loss 0.4653 (0.5418)	Prec@1 87.500 (82.429)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (1.204)	BT: 0.005 (1.212)	Loss 0.6206 (0.5412)	Prec@1 81.250 (82.536)	
Total train loss: 0.5411
Avg Loading time: 1.2009 seconds
Avg Batch time: 1.2087 seconds

Train time: 472.6971387863159
 * Prec@1 81.310 Prec@5 99.280 Loss 0.5664
Avg Loading time: 1.2996 seconds
Avg Batch time: 1.3045 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 103.19574904441833

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 4.226 (0.977)	BT: 4.240 (0.984)	Loss 0.4868 (0.5424)	Prec@1 85.938 (83.003)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 1.543 (1.287)	BT: 1.554 (1.295)	Loss 0.3738 (0.5336)	Prec@1 89.844 (82.858)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.635 (1.383)	BT: 0.650 (1.392)	Loss 0.5654 (0.5363)	Prec@1 82.031 (82.672)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (1.418)	BT: 0.005 (1.426)	Loss 0.4580 (0.5374)	Prec@1 83.594 (82.527)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (1.456)	BT: 0.007 (1.465)	Loss 0.4675 (0.5383)	Prec@1 86.719 (82.442)	
Total train loss: 0.5383
Avg Loading time: 1.4521 seconds
Avg Batch time: 1.4608 seconds

Train time: 571.3004803657532
 * Prec@1 81.160 Prec@5 99.280 Loss 0.5649
Avg Loading time: 1.6679 seconds
Avg Batch time: 1.6742 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 132.4006793498993

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (1.745)	BT: 0.005 (1.752)	Loss 0.5942 (0.5348)	Prec@1 82.031 (82.352)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (1.733)	BT: 0.007 (1.741)	Loss 0.6050 (0.5377)	Prec@1 79.688 (82.467)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.983 (1.537)	BT: 0.995 (1.545)	Loss 0.5757 (0.5394)	Prec@1 78.906 (82.459)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.884 (1.380)	BT: 0.895 (1.388)	Loss 0.5210 (0.5396)	Prec@1 82.812 (82.505)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (1.323)	BT: 0.004 (1.331)	Loss 0.6343 (0.5400)	Prec@1 81.250 (82.466)	
Total train loss: 0.5402
Avg Loading time: 1.3198 seconds
Avg Batch time: 1.3276 seconds

Train time: 519.2327806949615
 * Prec@1 81.270 Prec@5 99.240 Loss 0.5698
Avg Loading time: 0.9244 seconds
Avg Batch time: 0.9305 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 73.65185499191284

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.907)	BT: 0.009 (0.915)	Loss 0.4944 (0.5402)	Prec@1 86.719 (82.322)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.890)	BT: 0.007 (0.898)	Loss 0.5415 (0.5406)	Prec@1 82.031 (82.502)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.203 (0.860)	BT: 0.208 (0.869)	Loss 0.3848 (0.5402)	Prec@1 89.062 (82.475)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (1.032)	BT: 0.006 (1.041)	Loss 0.5190 (0.5401)	Prec@1 80.469 (82.567)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 1.024 (1.137)	BT: 1.036 (1.146)	Loss 0.6240 (0.5391)	Prec@1 76.562 (82.528)	
Total train loss: 0.5391
Avg Loading time: 1.1337 seconds
Avg Batch time: 1.1428 seconds

Train time: 446.96709728240967
 * Prec@1 81.120 Prec@5 99.280 Loss 0.5649
Avg Loading time: 1.7751 seconds
Avg Batch time: 1.7815 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 140.86101984977722

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (1.750)	BT: 0.005 (1.758)	Loss 0.5923 (0.5418)	Prec@1 79.688 (82.742)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (1.751)	BT: 0.007 (1.759)	Loss 0.5483 (0.5373)	Prec@1 82.812 (82.717)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 3.191 (1.753)	BT: 3.204 (1.761)	Loss 0.5493 (0.5367)	Prec@1 82.031 (82.565)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (1.710)	BT: 0.008 (1.717)	Loss 0.5547 (0.5389)	Prec@1 85.156 (82.487)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.474 (1.713)	BT: 0.485 (1.722)	Loss 0.5596 (0.5378)	Prec@1 83.594 (82.478)	
Total train loss: 0.5378
Avg Loading time: 1.7091 seconds
Avg Batch time: 1.7171 seconds

Train time: 671.5113935470581
 * Prec@1 81.140 Prec@5 99.280 Loss 0.5674
Avg Loading time: 1.8243 seconds
Avg Batch time: 1.8303 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 144.70397806167603

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 1.080 (2.013)	BT: 1.089 (2.021)	Loss 0.4556 (0.5376)	Prec@1 86.719 (82.462)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (2.017)	BT: 0.006 (2.025)	Loss 0.4792 (0.5454)	Prec@1 84.375 (81.906)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.639 (2.031)	BT: 0.648 (2.039)	Loss 0.5220 (0.5432)	Prec@1 82.031 (82.045)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (1.988)	BT: 0.004 (1.996)	Loss 0.6162 (0.5390)	Prec@1 77.344 (82.334)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (1.946)	BT: 0.004 (1.953)	Loss 0.6323 (0.5400)	Prec@1 80.469 (82.352)	
Total train loss: 0.5402
Avg Loading time: 1.9409 seconds
Avg Batch time: 1.9485 seconds

Train time: 761.9634046554565
 * Prec@1 81.020 Prec@5 99.250 Loss 0.5664
Avg Loading time: 1.4281 seconds
Avg Batch time: 1.4335 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 113.38176774978638

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (1.180)	BT: 0.005 (1.186)	Loss 0.4983 (0.5433)	Prec@1 83.594 (81.821)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (1.199)	BT: 0.008 (1.205)	Loss 0.7354 (0.5396)	Prec@1 76.562 (82.207)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (1.185)	BT: 0.008 (1.191)	Loss 0.5835 (0.5388)	Prec@1 79.688 (82.308)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (1.148)	BT: 0.007 (1.155)	Loss 0.5254 (0.5398)	Prec@1 86.719 (82.312)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.974 (1.162)	BT: 0.985 (1.170)	Loss 0.5269 (0.5389)	Prec@1 83.594 (82.372)	
Total train loss: 0.5389
Avg Loading time: 1.1595 seconds
Avg Batch time: 1.1667 seconds

Train time: 456.3226704597473
 * Prec@1 81.180 Prec@5 99.230 Loss 0.5635
Avg Loading time: 1.8620 seconds
Avg Batch time: 2.2907 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 181.10454726219177

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (2.588)	BT: 0.006 (5.206)	Loss 0.5498 (0.5462)	Prec@1 85.156 (82.161)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 39.974 (2.560)	BT: 51.988 (4.743)	Loss 0.5376 (0.5356)	Prec@1 82.031 (82.412)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (2.397)	BT: 0.007 (4.436)	Loss 0.5928 (0.5366)	Prec@1 81.250 (82.525)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (2.377)	BT: 0.005 (4.221)	Loss 0.5396 (0.5380)	Prec@1 87.500 (82.437)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (2.272)	BT: 0.003 (4.085)	Loss 0.5859 (0.5399)	Prec@1 79.688 (82.336)	
Total train loss: 0.5398
Avg Loading time: 2.2664 seconds
Avg Batch time: 4.0741 seconds

Train time: 1593.0696158409119
 * Prec@1 81.160 Prec@5 99.230 Loss 0.5669
Avg Loading time: 1.0829 seconds
Avg Batch time: 1.0887 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 86.16414093971252

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (2.255)	BT: 0.005 (2.302)	Loss 0.5479 (0.5375)	Prec@1 81.250 (82.462)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (2.380)	BT: 0.006 (2.841)	Loss 0.3569 (0.5371)	Prec@1 91.406 (82.472)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.000 (2.352)	BT: 0.004 (3.421)	Loss 0.5366 (0.5373)	Prec@1 80.469 (82.686)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (2.438)	BT: 0.005 (3.545)	Loss 0.4976 (0.5367)	Prec@1 84.375 (82.700)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (2.562)	BT: 0.006 (3.733)	Loss 0.6685 (0.5381)	Prec@1 76.562 (82.564)	
Total train loss: 0.5381
Avg Loading time: 2.5554 seconds
Avg Batch time: 3.7233 seconds

Train time: 1455.913512468338
 * Prec@1 81.160 Prec@5 99.240 Loss 0.5645
Avg Loading time: 2.9420 seconds
Avg Batch time: 4.3274 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 342.0039813518524

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (2.396)	BT: 0.010 (3.040)	Loss 0.5752 (0.5269)	Prec@1 82.812 (83.023)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 12.971 (1.870)	BT: 12.985 (2.968)	Loss 0.5146 (0.5319)	Prec@1 85.156 (82.742)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (1.958)	BT: 0.007 (3.037)	Loss 0.5938 (0.5331)	Prec@1 78.125 (82.629)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 1.241 (2.188)	BT: 1.255 (2.999)	Loss 0.4355 (0.5380)	Prec@1 88.281 (82.424)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.429 (2.298)	BT: 0.437 (2.948)	Loss 0.5122 (0.5380)	Prec@1 82.812 (82.370)	
Total train loss: 0.5382
Avg Loading time: 2.2917 seconds
Avg Batch time: 2.9407 seconds

Train time: 1149.9428787231445
 * Prec@1 81.280 Prec@5 99.260 Loss 0.5679
Avg Loading time: 2.7007 seconds
Avg Batch time: 2.9337 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 231.91335725784302

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (3.358)	BT: 0.005 (3.678)	Loss 0.5601 (0.5409)	Prec@1 80.469 (82.482)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (3.010)	BT: 0.005 (3.860)	Loss 0.4692 (0.5335)	Prec@1 85.938 (82.818)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (2.719)	BT: 0.004 (3.706)	Loss 0.5088 (0.5372)	Prec@1 82.812 (82.616)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.021 (2.404)	BT: 0.028 (3.334)	Loss 0.5459 (0.5418)	Prec@1 78.906 (82.454)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (2.190)	BT: 0.005 (2.935)	Loss 0.4700 (0.5401)	Prec@1 83.594 (82.566)	
Total train loss: 0.5401
Avg Loading time: 2.1840 seconds
Avg Batch time: 2.9277 seconds

Train time: 1144.8656294345856
 * Prec@1 81.120 Prec@5 99.260 Loss 0.5659
Avg Loading time: 0.9718 seconds
Avg Batch time: 0.9779 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 77.36188101768494

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (1.153)	BT: 0.006 (1.161)	Loss 0.4875 (0.5308)	Prec@1 83.594 (83.023)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (1.200)	BT: 0.007 (1.208)	Loss 0.5396 (0.5402)	Prec@1 84.375 (82.577)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 2.262 (1.437)	BT: 2.274 (1.445)	Loss 0.4731 (0.5390)	Prec@1 88.281 (82.569)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (1.687)	BT: 0.004 (1.695)	Loss 0.5688 (0.5390)	Prec@1 83.594 (82.464)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (1.761)	BT: 0.005 (1.977)	Loss 0.4263 (0.5380)	Prec@1 89.844 (82.510)	
Total train loss: 0.5382
Avg Loading time: 1.7562 seconds
Avg Batch time: 1.9722 seconds

Train time: 771.2993133068085
 * Prec@1 81.300 Prec@5 99.260 Loss 0.5659
Avg Loading time: 2.1541 seconds
Avg Batch time: 2.8826 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 227.86764931678772

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (2.258)	BT: 0.005 (3.327)	Loss 0.6221 (0.5510)	Prec@1 79.688 (81.871)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (2.748)	BT: 0.005 (3.288)	Loss 0.5649 (0.5494)	Prec@1 83.594 (82.066)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 18.652 (2.903)	BT: 18.678 (3.266)	Loss 0.5464 (0.5407)	Prec@1 84.375 (82.385)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (2.894)	BT: 0.004 (3.169)	Loss 0.5312 (0.5397)	Prec@1 84.375 (82.369)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (2.867)	BT: 0.005 (3.204)	Loss 0.5283 (0.5395)	Prec@1 85.938 (82.424)	
Total train loss: 0.5394
Avg Loading time: 2.8598 seconds
Avg Batch time: 3.1956 seconds

Train time: 1249.6448237895966
 * Prec@1 81.160 Prec@5 99.280 Loss 0.5654
Avg Loading time: 2.5546 seconds
Avg Batch time: 3.5895 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 283.77026653289795

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (1.964)	BT: 0.004 (3.608)	Loss 0.5352 (0.5387)	Prec@1 87.500 (82.762)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 26.705 (2.239)	BT: 36.896 (3.674)	Loss 0.5586 (0.5449)	Prec@1 84.375 (82.462)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.099 (2.143)	BT: 0.104 (3.296)	Loss 0.5645 (0.5429)	Prec@1 82.812 (82.402)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (2.293)	BT: 0.009 (3.160)	Loss 0.6543 (0.5414)	Prec@1 75.781 (82.352)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (2.387)	BT: 0.008 (3.082)	Loss 0.3711 (0.5390)	Prec@1 89.062 (82.428)	
Total train loss: 0.5391
Avg Loading time: 2.3807 seconds
Avg Batch time: 3.0742 seconds

Train time: 1202.1483068466187
 * Prec@1 81.230 Prec@5 99.210 Loss 0.5649
Avg Loading time: 2.6038 seconds
Avg Batch time: 2.6104 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 206.3543827533722

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (1.363)	BT: 0.008 (1.372)	Loss 0.6045 (0.5431)	Prec@1 84.375 (82.482)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.289 (1.256)	BT: 0.300 (1.265)	Loss 0.5020 (0.5390)	Prec@1 86.719 (82.407)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 3.939 (1.221)	BT: 3.960 (1.230)	Loss 0.5176 (0.5392)	Prec@1 82.812 (82.469)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (1.233)	BT: 0.005 (1.242)	Loss 0.5713 (0.5402)	Prec@1 81.250 (82.454)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (1.251)	BT: 0.009 (1.259)	Loss 0.5342 (0.5394)	Prec@1 84.375 (82.450)	
Total train loss: 0.5394
Avg Loading time: 1.2474 seconds
Avg Batch time: 1.2562 seconds

Train time: 491.3274347782135
 * Prec@1 81.090 Prec@5 99.290 Loss 0.5684
Avg Loading time: 2.4863 seconds
Avg Batch time: 3.0872 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 244.0270335674286

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (2.528)	BT: 0.005 (3.110)	Loss 0.6089 (0.5336)	Prec@1 80.469 (82.502)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (2.288)	BT: 0.008 (3.444)	Loss 0.5186 (0.5391)	Prec@1 82.812 (82.242)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (2.263)	BT: 0.004 (3.393)	Loss 0.5361 (0.5404)	Prec@1 83.594 (82.171)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (2.295)	BT: 0.005 (3.413)	Loss 0.5723 (0.5389)	Prec@1 78.906 (82.339)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (2.386)	BT: 0.005 (3.403)	Loss 0.5854 (0.5387)	Prec@1 82.031 (82.394)	
Total train loss: 0.5387
Avg Loading time: 2.3802 seconds
Avg Batch time: 3.3946 seconds

Train time: 1327.3906497955322
 * Prec@1 81.240 Prec@5 99.250 Loss 0.5649
Avg Loading time: 3.6433 seconds
Avg Batch time: 3.6502 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 288.4742488861084

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (3.149)	BT: 0.005 (3.157)	Loss 0.5254 (0.5335)	Prec@1 82.812 (82.772)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (2.369)	BT: 0.006 (2.377)	Loss 0.5005 (0.5341)	Prec@1 86.719 (82.812)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (1.704)	BT: 0.008 (1.712)	Loss 0.7231 (0.5370)	Prec@1 77.344 (82.722)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (1.427)	BT: 0.004 (1.434)	Loss 0.5635 (0.5382)	Prec@1 83.594 (82.677)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (1.197)	BT: 0.004 (1.203)	Loss 0.6367 (0.5379)	Prec@1 82.031 (82.632)	
Total train loss: 0.5380
Avg Loading time: 1.1934 seconds
Avg Batch time: 1.2004 seconds

Train time: 469.46545934677124
 * Prec@1 81.280 Prec@5 99.280 Loss 0.5654
Avg Loading time: 0.8391 seconds
Avg Batch time: 0.8448 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 66.8733696937561

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.742)	BT: 0.005 (0.749)	Loss 0.5806 (0.5458)	Prec@1 79.688 (81.791)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.715)	BT: 0.005 (0.723)	Loss 0.4644 (0.5375)	Prec@1 84.375 (82.287)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.823)	BT: 0.009 (0.830)	Loss 0.6479 (0.5419)	Prec@1 77.344 (82.265)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (1.002)	BT: 0.004 (1.009)	Loss 0.7266 (0.5389)	Prec@1 72.656 (82.419)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (1.223)	BT: 0.005 (1.417)	Loss 0.6455 (0.5393)	Prec@1 75.000 (82.382)	
Total train loss: 0.5395
Avg Loading time: 1.2194 seconds
Avg Batch time: 1.4136 seconds

Train time: 552.8523316383362
 * Prec@1 81.120 Prec@5 99.210 Loss 0.5645
Avg Loading time: 1.8836 seconds
Avg Batch time: 2.6487 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 209.39789056777954

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (2.370)	BT: 0.006 (3.175)	Loss 0.4910 (0.5350)	Prec@1 84.375 (82.702)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (2.535)	BT: 0.006 (3.162)	Loss 0.5220 (0.5363)	Prec@1 83.594 (82.677)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (2.399)	BT: 0.005 (3.166)	Loss 0.5337 (0.5379)	Prec@1 80.469 (82.656)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.547 (2.330)	BT: 0.558 (3.093)	Loss 0.5269 (0.5378)	Prec@1 82.031 (82.620)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (2.325)	BT: 0.008 (3.013)	Loss 0.4114 (0.5376)	Prec@1 90.625 (82.622)	
Total train loss: 0.5376
Avg Loading time: 2.3193 seconds
Avg Batch time: 3.0057 seconds

Train time: 1175.387367963791
 * Prec@1 81.090 Prec@5 99.240 Loss 0.5679
Avg Loading time: 2.3260 seconds
Avg Batch time: 3.2820 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 259.432697057724

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.622 (2.708)	BT: 0.632 (3.082)	Loss 0.5156 (0.5190)	Prec@1 87.500 (83.524)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (3.031)	BT: 0.007 (3.223)	Loss 0.6084 (0.5377)	Prec@1 81.250 (82.622)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 10.703 (3.345)	BT: 10.714 (3.475)	Loss 0.5396 (0.5376)	Prec@1 82.031 (82.539)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (3.314)	BT: 0.004 (3.500)	Loss 0.5283 (0.5398)	Prec@1 81.250 (82.444)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (3.353)	BT: 0.005 (3.504)	Loss 0.4829 (0.5383)	Prec@1 86.719 (82.474)	
Total train loss: 0.5384
Avg Loading time: 3.3441 seconds
Avg Batch time: 3.4947 seconds

Train time: 1366.5244824886322
 * Prec@1 81.250 Prec@5 99.280 Loss 0.5664
Avg Loading time: 2.6172 seconds
Avg Batch time: 2.6237 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 207.41953301429749

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (1.790)	BT: 0.005 (1.797)	Loss 0.4324 (0.5379)	Prec@1 87.500 (82.802)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.650 (1.617)	BT: 0.655 (1.624)	Loss 0.6279 (0.5403)	Prec@1 79.688 (82.512)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (1.492)	BT: 0.009 (1.499)	Loss 0.4924 (0.5437)	Prec@1 82.031 (82.348)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (1.380)	BT: 0.006 (1.388)	Loss 0.5576 (0.5407)	Prec@1 81.250 (82.452)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (1.407)	BT: 0.006 (1.414)	Loss 0.5459 (0.5399)	Prec@1 82.812 (82.312)	
Total train loss: 0.5398
Avg Loading time: 1.4032 seconds
Avg Batch time: 1.4107 seconds

Train time: 551.7042734622955
 * Prec@1 81.150 Prec@5 99.240 Loss 0.5674
Avg Loading time: 1.8534 seconds
Avg Batch time: 1.8593 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 146.9927098751068

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.036 (2.368)	BT: 0.041 (2.377)	Loss 0.5205 (0.5405)	Prec@1 82.031 (82.482)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (2.551)	BT: 0.006 (2.665)	Loss 0.6211 (0.5421)	Prec@1 75.781 (82.257)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 11.255 (2.754)	BT: 11.265 (2.839)	Loss 0.4492 (0.5383)	Prec@1 89.062 (82.445)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (2.803)	BT: 0.006 (2.869)	Loss 0.6025 (0.5409)	Prec@1 75.781 (82.339)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (2.767)	BT: 0.009 (2.901)	Loss 0.6006 (0.5375)	Prec@1 81.250 (82.450)	
Total train loss: 0.5379
Avg Loading time: 2.7595 seconds
Avg Batch time: 2.8940 seconds

Train time: 1131.6718120574951
 * Prec@1 81.280 Prec@5 99.260 Loss 0.5645
Avg Loading time: 2.8112 seconds
Avg Batch time: 3.5423 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 279.9637362957001

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.316 (2.919)	BT: 0.327 (4.229)	Loss 0.7090 (0.5326)	Prec@1 81.250 (82.372)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (3.093)	BT: 0.007 (4.168)	Loss 0.5229 (0.5326)	Prec@1 85.938 (82.542)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 20.003 (2.803)	BT: 21.000 (3.896)	Loss 0.5376 (0.5373)	Prec@1 81.250 (82.402)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (2.485)	BT: 0.004 (3.572)	Loss 0.5225 (0.5360)	Prec@1 84.375 (82.520)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 1.258 (2.521)	BT: 1.270 (3.393)	Loss 0.5596 (0.5362)	Prec@1 83.594 (82.564)	
Total train loss: 0.5362
Avg Loading time: 2.5143 seconds
Avg Batch time: 3.3839 seconds

Train time: 1323.2111823558807
 * Prec@1 81.150 Prec@5 99.270 Loss 0.5654
Avg Loading time: 2.9417 seconds
Avg Batch time: 2.9486 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 233.07261061668396

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 1.879 (3.106)	BT: 1.893 (3.115)	Loss 0.6191 (0.5386)	Prec@1 76.562 (82.692)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (2.811)	BT: 0.005 (2.820)	Loss 0.6094 (0.5372)	Prec@1 82.812 (82.762)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (2.547)	BT: 0.008 (2.555)	Loss 0.5879 (0.5371)	Prec@1 84.375 (82.696)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (2.312)	BT: 0.005 (2.506)	Loss 0.5996 (0.5392)	Prec@1 81.250 (82.520)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.586 (2.088)	BT: 0.598 (2.245)	Loss 0.6333 (0.5394)	Prec@1 79.688 (82.406)	
Total train loss: 0.5394
Avg Loading time: 2.0828 seconds
Avg Batch time: 2.2390 seconds

Train time: 875.5590085983276
 * Prec@1 81.160 Prec@5 99.220 Loss 0.5664
Avg Loading time: 1.8143 seconds
Avg Batch time: 1.8196 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 143.88201332092285

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.678 (1.806)	BT: 0.688 (1.814)	Loss 0.4480 (0.5495)	Prec@1 85.156 (81.831)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (1.762)	BT: 0.010 (1.770)	Loss 0.4888 (0.5433)	Prec@1 87.500 (82.272)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (2.145)	BT: 0.009 (2.214)	Loss 0.5947 (0.5398)	Prec@1 78.906 (82.485)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 1.952 (2.224)	BT: 1.963 (2.556)	Loss 0.5146 (0.5408)	Prec@1 82.031 (82.414)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.017 (2.185)	BT: 0.021 (2.669)	Loss 0.5898 (0.5400)	Prec@1 79.688 (82.466)	
Total train loss: 0.5400
Avg Loading time: 2.1795 seconds
Avg Batch time: 2.6617 seconds

Train time: 1040.8343997001648
 * Prec@1 81.110 Prec@5 99.230 Loss 0.5659
Avg Loading time: 2.0490 seconds
Avg Batch time: 3.0108 seconds

Best acc: 81.680
--------------------------------------------------------------------------------
Test time: 237.98592019081116

