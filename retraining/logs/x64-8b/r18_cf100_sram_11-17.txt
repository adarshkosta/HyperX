
      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 0
          frozen_layers: 11
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar100/resnet18
DEVICE: cuda
GPU Id(s) being used: 0
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/train/relu11
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/test/relu11
ResNet18(
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=100, bias=False)
  (bn19): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 1.030 Prec@5 4.830 Loss 4.5859
Avg Loading time: 0.6163 seconds
Avg Batch time: 0.6323 seconds

Pre-trained Prec@1 with 11 layers frozen: 1.0299999713897705 	 Loss: 4.5859375

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (2.576)	BT: 0.025 (2.604)	Loss 1.8027 (2.3219)	Prec@1 50.781 (42.618)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (2.649)	BT: 0.026 (2.678)	Loss 1.5693 (2.0001)	Prec@1 55.469 (48.382)	
Epoch: [0][233/391]	LR: 0.1	DT: 3.982 (2.921)	BT: 4.019 (2.950)	Loss 1.3926 (1.8369)	Prec@1 64.062 (51.713)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (3.022)	BT: 0.025 (3.051)	Loss 1.4805 (1.7285)	Prec@1 59.375 (53.956)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (3.081)	BT: 0.025 (3.110)	Loss 1.3291 (1.6564)	Prec@1 65.625 (55.545)	
Total train loss: 1.6557
Avg Loading time: 3.0731 seconds
Avg Batch time: 3.1017 seconds

Train time: 1212.8538534641266
 * Prec@1 60.870 Prec@5 88.060 Loss 1.3994
Avg Loading time: 1.4371 seconds
Avg Batch time: 1.4473 seconds

Best acc: 60.870
--------------------------------------------------------------------------------
Test time: 115.28054285049438

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (1.374)	BT: 0.026 (1.402)	Loss 0.9985 (1.0067)	Prec@1 69.531 (71.254)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.347 (0.820)	BT: 0.384 (0.848)	Loss 0.9253 (1.0179)	Prec@1 77.344 (70.658)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.583)	BT: 0.023 (0.611)	Loss 0.9941 (1.0348)	Prec@1 70.312 (70.226)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.522 (0.465)	BT: 0.549 (0.494)	Loss 0.9932 (1.0352)	Prec@1 69.531 (70.242)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.393)	BT: 0.025 (0.421)	Loss 1.0820 (1.0338)	Prec@1 68.750 (70.224)	
Total train loss: 1.0344
Avg Loading time: 0.3919 seconds
Avg Batch time: 0.4200 seconds

Train time: 164.31967401504517
 * Prec@1 65.880 Prec@5 90.400 Loss 1.2285
Avg Loading time: 0.1054 seconds
Avg Batch time: 0.1163 seconds

Best acc: 65.880
--------------------------------------------------------------------------------
Test time: 10.160724878311157

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.120)	BT: 0.021 (0.147)	Loss 0.7480 (0.7157)	Prec@1 75.781 (78.335)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.120)	BT: 0.022 (0.146)	Loss 0.7363 (0.7330)	Prec@1 81.250 (77.990)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (0.115)	BT: 0.036 (0.141)	Loss 0.7554 (0.7425)	Prec@1 77.344 (77.711)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.109)	BT: 0.022 (0.135)	Loss 0.8945 (0.7567)	Prec@1 71.875 (77.191)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.104)	BT: 0.021 (0.130)	Loss 0.9639 (0.7750)	Prec@1 71.094 (76.775)	
Total train loss: 0.7755
Avg Loading time: 0.1038 seconds
Avg Batch time: 0.1299 seconds

Train time: 50.91729927062988
 * Prec@1 67.270 Prec@5 90.350 Loss 1.2100
Avg Loading time: 0.1023 seconds
Avg Batch time: 0.1130 seconds

Best acc: 67.270
--------------------------------------------------------------------------------
Test time: 10.587677240371704

Epoch: [3][77/391]	LR: 0.1	DT: 0.001 (0.130)	BT: 0.041 (0.156)	Loss 0.3867 (0.4970)	Prec@1 87.500 (85.437)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.116)	BT: 0.025 (0.141)	Loss 0.4778 (0.5218)	Prec@1 84.375 (84.195)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.114)	BT: 0.024 (0.140)	Loss 0.5483 (0.5460)	Prec@1 80.469 (83.467)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.110)	BT: 0.022 (0.136)	Loss 0.7129 (0.5696)	Prec@1 80.469 (82.592)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.108)	BT: 0.022 (0.134)	Loss 0.5830 (0.5860)	Prec@1 81.250 (82.029)	
Total train loss: 0.5863
Avg Loading time: 0.1080 seconds
Avg Batch time: 0.1342 seconds

Train time: 52.58956170082092
 * Prec@1 66.370 Prec@5 90.100 Loss 1.2412
Avg Loading time: 0.1318 seconds
Avg Batch time: 0.1418 seconds

Best acc: 67.270
--------------------------------------------------------------------------------
Test time: 11.790079355239868

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.097)	BT: 0.031 (0.123)	Loss 0.4807 (0.3736)	Prec@1 83.594 (88.792)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.096)	BT: 0.029 (0.121)	Loss 0.3210 (0.3739)	Prec@1 89.062 (88.677)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.089)	BT: 0.022 (0.114)	Loss 0.4470 (0.3962)	Prec@1 87.500 (87.841)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.088)	BT: 0.022 (0.113)	Loss 0.6416 (0.4148)	Prec@1 82.031 (87.275)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.088)	BT: 0.023 (0.113)	Loss 0.4792 (0.4294)	Prec@1 83.594 (86.771)	
Total train loss: 0.4300
Avg Loading time: 0.0879 seconds
Avg Batch time: 0.1132 seconds

Train time: 44.40281081199646
 * Prec@1 65.210 Prec@5 88.970 Loss 1.3721
Avg Loading time: 0.0896 seconds
Avg Batch time: 0.1006 seconds

Best acc: 67.270
--------------------------------------------------------------------------------
Test time: 8.557198286056519

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.091)	BT: 0.024 (0.116)	Loss 0.1936 (0.2638)	Prec@1 95.312 (92.508)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.090)	BT: 0.027 (0.116)	Loss 0.3049 (0.2801)	Prec@1 93.750 (91.707)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.289 (0.090)	BT: 0.318 (0.115)	Loss 0.3386 (0.2859)	Prec@1 89.844 (91.500)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.087)	BT: 0.032 (0.114)	Loss 0.4504 (0.2988)	Prec@1 85.156 (90.903)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.090)	BT: 0.021 (0.116)	Loss 0.3650 (0.3168)	Prec@1 88.281 (90.256)	
Total train loss: 0.3170
Avg Loading time: 0.0898 seconds
Avg Batch time: 0.1162 seconds

Train time: 45.526381731033325
 * Prec@1 65.800 Prec@5 88.800 Loss 1.3662
Avg Loading time: 0.1250 seconds
Avg Batch time: 0.1363 seconds

Best acc: 67.270
--------------------------------------------------------------------------------
Test time: 11.383478879928589

Epoch: [6][77/391]	LR: 0.1	DT: 0.001 (0.079)	BT: 0.032 (0.106)	Loss 0.2903 (0.2262)	Prec@1 92.188 (93.520)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.083)	BT: 0.029 (0.111)	Loss 0.2839 (0.2214)	Prec@1 92.188 (93.495)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.001 (0.083)	BT: 0.035 (0.109)	Loss 0.3081 (0.2269)	Prec@1 89.844 (93.172)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.082)	BT: 0.021 (0.108)	Loss 0.2324 (0.2380)	Prec@1 92.969 (92.884)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.085)	BT: 0.024 (0.112)	Loss 0.1682 (0.2475)	Prec@1 93.750 (92.540)	
Total train loss: 0.2476
Avg Loading time: 0.0852 seconds
Avg Batch time: 0.1115 seconds

Train time: 43.71457648277283
 * Prec@1 66.600 Prec@5 89.220 Loss 1.3887
Avg Loading time: 0.0929 seconds
Avg Batch time: 0.1034 seconds

Best acc: 67.270
--------------------------------------------------------------------------------
Test time: 8.723374366760254

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.096)	BT: 0.033 (0.123)	Loss 0.2100 (0.1772)	Prec@1 95.312 (94.982)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.091)	BT: 0.023 (0.118)	Loss 0.2407 (0.1678)	Prec@1 92.188 (95.252)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.084)	BT: 0.028 (0.110)	Loss 0.1782 (0.1748)	Prec@1 94.531 (94.975)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.090)	BT: 0.021 (0.116)	Loss 0.1566 (0.1846)	Prec@1 97.656 (94.649)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.092)	BT: 0.025 (0.118)	Loss 0.1238 (0.1982)	Prec@1 97.656 (94.151)	
Total train loss: 0.1984
Avg Loading time: 0.0914 seconds
Avg Batch time: 0.1174 seconds

Train time: 46.032814741134644
 * Prec@1 67.660 Prec@5 89.400 Loss 1.3779
Avg Loading time: 0.1295 seconds
Avg Batch time: 0.1404 seconds

Best acc: 67.660
--------------------------------------------------------------------------------
Test time: 12.058191061019897

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.102)	BT: 0.023 (0.128)	Loss 0.1323 (0.1412)	Prec@1 96.875 (95.994)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.101)	BT: 0.022 (0.127)	Loss 0.1120 (0.1430)	Prec@1 97.656 (96.029)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.099)	BT: 0.027 (0.126)	Loss 0.1677 (0.1489)	Prec@1 95.312 (95.837)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.099)	BT: 0.029 (0.126)	Loss 0.1247 (0.1530)	Prec@1 96.875 (95.688)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.098)	BT: 0.023 (0.124)	Loss 0.2539 (0.1623)	Prec@1 89.844 (95.343)	
Total train loss: 0.1624
Avg Loading time: 0.0973 seconds
Avg Batch time: 0.1238 seconds

Train time: 48.57219433784485
 * Prec@1 67.560 Prec@5 88.520 Loss 1.4463
Avg Loading time: 0.0979 seconds
Avg Batch time: 0.1088 seconds

Best acc: 67.660
--------------------------------------------------------------------------------
Test time: 9.205445528030396

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.090)	BT: 0.022 (0.115)	Loss 0.0811 (0.1312)	Prec@1 100.000 (96.384)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.185 (0.069)	BT: 0.210 (0.094)	Loss 0.0846 (0.1284)	Prec@1 96.875 (96.529)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.001 (0.076)	BT: 0.033 (0.103)	Loss 0.1157 (0.1322)	Prec@1 96.875 (96.304)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.080)	BT: 0.022 (0.107)	Loss 0.2244 (0.1365)	Prec@1 93.750 (96.101)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.084)	BT: 0.030 (0.110)	Loss 0.2344 (0.1401)	Prec@1 90.625 (95.996)	
Total train loss: 0.1402
Avg Loading time: 0.0835 seconds
Avg Batch time: 0.1098 seconds

Train time: 43.05257225036621
 * Prec@1 67.900 Prec@5 89.120 Loss 1.4355
Avg Loading time: 0.1026 seconds
Avg Batch time: 0.1138 seconds

Best acc: 67.900
--------------------------------------------------------------------------------
Test time: 10.024864196777344

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.104)	BT: 0.026 (0.130)	Loss 0.0370 (0.0852)	Prec@1 99.219 (97.867)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.092)	BT: 0.024 (0.118)	Loss 0.0388 (0.0747)	Prec@1 99.219 (98.157)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.088)	BT: 0.022 (0.114)	Loss 0.0375 (0.0667)	Prec@1 100.000 (98.397)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.085)	BT: 0.022 (0.111)	Loss 0.0324 (0.0618)	Prec@1 98.438 (98.545)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.089)	BT: 0.023 (0.114)	Loss 0.0245 (0.0587)	Prec@1 100.000 (98.628)	
Total train loss: 0.0588
Avg Loading time: 0.0887 seconds
Avg Batch time: 0.1139 seconds

Train time: 44.675616979599
 * Prec@1 73.860 Prec@5 91.870 Loss 1.1338
Avg Loading time: 0.0956 seconds
Avg Batch time: 0.1067 seconds

Best acc: 73.860
--------------------------------------------------------------------------------
Test time: 9.437592506408691

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.095)	BT: 0.025 (0.123)	Loss 0.0176 (0.0285)	Prec@1 100.000 (99.619)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.090)	BT: 0.036 (0.117)	Loss 0.0139 (0.0277)	Prec@1 100.000 (99.599)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.089)	BT: 0.024 (0.116)	Loss 0.0290 (0.0267)	Prec@1 100.000 (99.609)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.088)	BT: 0.023 (0.115)	Loss 0.0247 (0.0257)	Prec@1 100.000 (99.642)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.095)	BT: 0.042 (0.122)	Loss 0.0249 (0.0251)	Prec@1 100.000 (99.657)	
Total train loss: 0.0251
Avg Loading time: 0.0944 seconds
Avg Batch time: 0.1216 seconds

Train time: 47.68160319328308
 * Prec@1 73.890 Prec@5 91.780 Loss 1.1328
Avg Loading time: 0.1505 seconds
Avg Batch time: 0.1612 seconds

Best acc: 73.890
--------------------------------------------------------------------------------
Test time: 13.762620449066162

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.136)	BT: 0.022 (0.162)	Loss 0.0302 (0.0204)	Prec@1 99.219 (99.649)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.126)	BT: 0.022 (0.152)	Loss 0.0095 (0.0196)	Prec@1 100.000 (99.740)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.390 (0.125)	BT: 0.415 (0.151)	Loss 0.0263 (0.0194)	Prec@1 99.219 (99.766)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.124)	BT: 0.035 (0.150)	Loss 0.0134 (0.0191)	Prec@1 100.000 (99.782)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.126)	BT: 0.023 (0.152)	Loss 0.0290 (0.0194)	Prec@1 99.219 (99.772)	
Total train loss: 0.0193
Avg Loading time: 0.1254 seconds
Avg Batch time: 0.1514 seconds

Train time: 59.34976077079773
 * Prec@1 74.210 Prec@5 91.740 Loss 1.1211
Avg Loading time: 0.1790 seconds
Avg Batch time: 0.1899 seconds

Best acc: 74.210
--------------------------------------------------------------------------------
Test time: 16.021579027175903

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.113)	BT: 0.036 (0.139)	Loss 0.0107 (0.0162)	Prec@1 100.000 (99.870)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.128)	BT: 0.021 (0.154)	Loss 0.0103 (0.0156)	Prec@1 100.000 (99.890)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.307 (0.132)	BT: 0.340 (0.158)	Loss 0.0206 (0.0157)	Prec@1 99.219 (99.873)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.001 (0.127)	BT: 0.042 (0.154)	Loss 0.0060 (0.0156)	Prec@1 100.000 (99.867)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.123)	BT: 0.025 (0.149)	Loss 0.0404 (0.0159)	Prec@1 98.438 (99.856)	
Total train loss: 0.0159
Avg Loading time: 0.1230 seconds
Avg Batch time: 0.1491 seconds

Train time: 58.37775635719299
 * Prec@1 74.160 Prec@5 91.730 Loss 1.1348
Avg Loading time: 0.1855 seconds
Avg Batch time: 0.1968 seconds

Best acc: 74.210
--------------------------------------------------------------------------------
Test time: 16.129455089569092

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.122)	BT: 0.024 (0.148)	Loss 0.0082 (0.0155)	Prec@1 100.000 (99.890)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.107)	BT: 0.022 (0.132)	Loss 0.0099 (0.0149)	Prec@1 100.000 (99.860)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.100)	BT: 0.021 (0.126)	Loss 0.0074 (0.0148)	Prec@1 100.000 (99.863)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.097)	BT: 0.029 (0.123)	Loss 0.0097 (0.0147)	Prec@1 100.000 (99.870)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.102)	BT: 0.025 (0.128)	Loss 0.0104 (0.0146)	Prec@1 100.000 (99.876)	
Total train loss: 0.0146
Avg Loading time: 0.1019 seconds
Avg Batch time: 0.1276 seconds

Train time: 49.96220302581787
 * Prec@1 74.310 Prec@5 91.650 Loss 1.1367
Avg Loading time: 0.1454 seconds
Avg Batch time: 0.1568 seconds

Best acc: 74.310
--------------------------------------------------------------------------------
Test time: 13.3551766872406

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.095)	BT: 0.023 (0.121)	Loss 0.0102 (0.0124)	Prec@1 100.000 (99.880)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.082)	BT: 0.021 (0.109)	Loss 0.0113 (0.0123)	Prec@1 100.000 (99.895)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.084)	BT: 0.039 (0.111)	Loss 0.0082 (0.0123)	Prec@1 100.000 (99.893)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.081)	BT: 0.021 (0.108)	Loss 0.0162 (0.0123)	Prec@1 100.000 (99.900)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.167 (0.083)	BT: 0.193 (0.111)	Loss 0.0117 (0.0123)	Prec@1 100.000 (99.908)	
Total train loss: 0.0123
Avg Loading time: 0.0832 seconds
Avg Batch time: 0.1104 seconds

Train time: 43.238335847854614
 * Prec@1 73.990 Prec@5 91.800 Loss 1.1367
Avg Loading time: 0.0883 seconds
Avg Batch time: 0.0998 seconds

Best acc: 74.310
--------------------------------------------------------------------------------
Test time: 8.435399532318115

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.086)	BT: 0.034 (0.114)	Loss 0.0107 (0.0109)	Prec@1 100.000 (99.930)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.001 (0.081)	BT: 0.027 (0.109)	Loss 0.0193 (0.0120)	Prec@1 100.000 (99.900)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.770 (0.082)	BT: 0.793 (0.110)	Loss 0.0079 (0.0121)	Prec@1 100.000 (99.907)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.082)	BT: 0.021 (0.109)	Loss 0.0103 (0.0122)	Prec@1 100.000 (99.907)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.081)	BT: 0.021 (0.107)	Loss 0.0053 (0.0122)	Prec@1 100.000 (99.902)	
Total train loss: 0.0122
Avg Loading time: 0.0805 seconds
Avg Batch time: 0.1069 seconds

Train time: 41.94821310043335
 * Prec@1 74.150 Prec@5 91.480 Loss 1.1357
Avg Loading time: 0.1095 seconds
Avg Batch time: 0.1203 seconds

Best acc: 74.310
--------------------------------------------------------------------------------
Test time: 10.067871332168579

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.090)	BT: 0.022 (0.116)	Loss 0.0074 (0.0108)	Prec@1 100.000 (99.960)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.089)	BT: 0.026 (0.116)	Loss 0.0089 (0.0110)	Prec@1 100.000 (99.940)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.086)	BT: 0.022 (0.113)	Loss 0.0132 (0.0111)	Prec@1 99.219 (99.923)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.082)	BT: 0.022 (0.109)	Loss 0.0065 (0.0113)	Prec@1 100.000 (99.922)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.079)	BT: 0.022 (0.106)	Loss 0.0151 (0.0112)	Prec@1 99.219 (99.930)	
Total train loss: 0.0112
Avg Loading time: 0.0788 seconds
Avg Batch time: 0.1057 seconds

Train time: 41.42728304862976
 * Prec@1 74.330 Prec@5 91.690 Loss 1.1260
Avg Loading time: 0.0843 seconds
Avg Batch time: 0.0955 seconds

Best acc: 74.330
--------------------------------------------------------------------------------
Test time: 8.547516345977783

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.085)	BT: 0.026 (0.112)	Loss 0.0119 (0.0115)	Prec@1 100.000 (99.920)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.311 (0.074)	BT: 0.347 (0.101)	Loss 0.0155 (0.0107)	Prec@1 100.000 (99.950)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.074)	BT: 0.022 (0.100)	Loss 0.0103 (0.0106)	Prec@1 100.000 (99.943)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.072)	BT: 0.022 (0.098)	Loss 0.0072 (0.0106)	Prec@1 100.000 (99.932)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.074)	BT: 0.021 (0.100)	Loss 0.0109 (0.0103)	Prec@1 100.000 (99.940)	
Total train loss: 0.0103
Avg Loading time: 0.0734 seconds
Avg Batch time: 0.0996 seconds

Train time: 39.05699849128723
 * Prec@1 74.220 Prec@5 91.830 Loss 1.1318
Avg Loading time: 0.1018 seconds
Avg Batch time: 0.1121 seconds

Best acc: 74.330
--------------------------------------------------------------------------------
Test time: 9.4217369556427

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.088)	BT: 0.022 (0.115)	Loss 0.0075 (0.0092)	Prec@1 100.000 (99.960)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.082)	BT: 0.022 (0.109)	Loss 0.0038 (0.0097)	Prec@1 100.000 (99.940)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.080)	BT: 0.021 (0.107)	Loss 0.0068 (0.0102)	Prec@1 100.000 (99.930)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.080)	BT: 0.054 (0.107)	Loss 0.0051 (0.0099)	Prec@1 100.000 (99.930)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.042 (0.078)	BT: 0.065 (0.105)	Loss 0.0096 (0.0097)	Prec@1 100.000 (99.932)	
Total train loss: 0.0097
Avg Loading time: 0.0781 seconds
Avg Batch time: 0.1051 seconds

Train time: 41.17750859260559
 * Prec@1 74.440 Prec@5 91.660 Loss 1.1377
Avg Loading time: 0.0935 seconds
Avg Batch time: 0.1035 seconds

Best acc: 74.440
--------------------------------------------------------------------------------
Test time: 9.214447498321533

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.072)	BT: 0.021 (0.098)	Loss 0.0060 (0.0095)	Prec@1 100.000 (99.910)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.074)	BT: 0.026 (0.100)	Loss 0.0049 (0.0094)	Prec@1 100.000 (99.915)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.341 (0.080)	BT: 0.368 (0.105)	Loss 0.0089 (0.0092)	Prec@1 100.000 (99.933)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.001 (0.079)	BT: 0.035 (0.104)	Loss 0.0073 (0.0092)	Prec@1 100.000 (99.940)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.093 (0.082)	BT: 0.117 (0.107)	Loss 0.0039 (0.0091)	Prec@1 100.000 (99.942)	
Total train loss: 0.0091
Avg Loading time: 0.0816 seconds
Avg Batch time: 0.1072 seconds

Train time: 42.02221727371216
 * Prec@1 74.500 Prec@5 91.670 Loss 1.1396
Avg Loading time: 0.1074 seconds
Avg Batch time: 0.1187 seconds

Best acc: 74.500
--------------------------------------------------------------------------------
Test time: 10.34833312034607

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.076)	BT: 0.025 (0.103)	Loss 0.0082 (0.0087)	Prec@1 100.000 (99.950)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.073)	BT: 0.022 (0.101)	Loss 0.0040 (0.0088)	Prec@1 100.000 (99.950)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.067)	BT: 0.024 (0.095)	Loss 0.0096 (0.0089)	Prec@1 100.000 (99.950)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.072)	BT: 0.021 (0.099)	Loss 0.0079 (0.0088)	Prec@1 100.000 (99.955)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.082 (0.070)	BT: 0.102 (0.097)	Loss 0.0068 (0.0087)	Prec@1 100.000 (99.960)	
Total train loss: 0.0088
Avg Loading time: 0.0696 seconds
Avg Batch time: 0.0967 seconds

Train time: 37.9437530040741
 * Prec@1 74.300 Prec@5 91.770 Loss 1.1318
Avg Loading time: 0.0569 seconds
Avg Batch time: 0.0693 seconds

Best acc: 74.500
--------------------------------------------------------------------------------
Test time: 6.055430889129639

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.065)	BT: 0.042 (0.095)	Loss 0.0126 (0.0089)	Prec@1 100.000 (99.980)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.002 (0.062)	BT: 0.056 (0.092)	Loss 0.0069 (0.0092)	Prec@1 100.000 (99.970)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.053)	BT: 0.028 (0.082)	Loss 0.0050 (0.0093)	Prec@1 100.000 (99.957)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.043)	BT: 0.033 (0.074)	Loss 0.0093 (0.0092)	Prec@1 100.000 (99.957)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.050 (0.041)	BT: 0.076 (0.072)	Loss 0.0072 (0.0091)	Prec@1 100.000 (99.960)	
Total train loss: 0.0091
Avg Loading time: 0.0410 seconds
Avg Batch time: 0.0722 seconds

Train time: 28.34071183204651
 * Prec@1 74.430 Prec@5 91.670 Loss 1.1367
Avg Loading time: 0.0646 seconds
Avg Batch time: 0.0791 seconds

Best acc: 74.500
--------------------------------------------------------------------------------
Test time: 6.83668851852417

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.044)	BT: 0.034 (0.074)	Loss 0.0106 (0.0093)	Prec@1 100.000 (99.960)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.038)	BT: 0.021 (0.066)	Loss 0.0087 (0.0088)	Prec@1 100.000 (99.960)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.039)	BT: 0.024 (0.066)	Loss 0.0078 (0.0089)	Prec@1 100.000 (99.957)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.039)	BT: 0.024 (0.066)	Loss 0.0153 (0.0090)	Prec@1 100.000 (99.950)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.040)	BT: 0.037 (0.067)	Loss 0.0047 (0.0090)	Prec@1 100.000 (99.956)	
Total train loss: 0.0090
Avg Loading time: 0.0402 seconds
Avg Batch time: 0.0674 seconds

Train time: 26.416311979293823
 * Prec@1 74.520 Prec@5 91.730 Loss 1.1367
Avg Loading time: 0.0485 seconds
Avg Batch time: 0.0626 seconds

Best acc: 74.520
--------------------------------------------------------------------------------
Test time: 5.972269058227539

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.069)	BT: 0.027 (0.100)	Loss 0.0089 (0.0087)	Prec@1 100.000 (99.950)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.055)	BT: 0.028 (0.084)	Loss 0.0087 (0.0090)	Prec@1 100.000 (99.930)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.388 (0.049)	BT: 0.411 (0.079)	Loss 0.0067 (0.0091)	Prec@1 100.000 (99.943)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.046)	BT: 0.027 (0.076)	Loss 0.0039 (0.0091)	Prec@1 100.000 (99.942)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.047)	BT: 0.022 (0.077)	Loss 0.0077 (0.0093)	Prec@1 100.000 (99.940)	
Total train loss: 0.0093
Avg Loading time: 0.0469 seconds
Avg Batch time: 0.0772 seconds

Train time: 30.296356439590454
 * Prec@1 74.340 Prec@5 91.630 Loss 1.1357
Avg Loading time: 0.0655 seconds
Avg Batch time: 0.0780 seconds

Best acc: 74.520
--------------------------------------------------------------------------------
Test time: 6.7509753704071045

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.047)	BT: 0.022 (0.077)	Loss 0.0088 (0.0091)	Prec@1 100.000 (99.920)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.040)	BT: 0.022 (0.069)	Loss 0.0089 (0.0090)	Prec@1 100.000 (99.925)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.034)	BT: 0.043 (0.063)	Loss 0.0092 (0.0089)	Prec@1 100.000 (99.930)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.034)	BT: 0.029 (0.063)	Loss 0.0075 (0.0088)	Prec@1 100.000 (99.940)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.038)	BT: 0.052 (0.068)	Loss 0.0071 (0.0088)	Prec@1 100.000 (99.944)	
Total train loss: 0.0088
Avg Loading time: 0.0381 seconds
Avg Batch time: 0.0678 seconds

Train time: 26.643542766571045
 * Prec@1 74.260 Prec@5 91.780 Loss 1.1309
Avg Loading time: 0.0641 seconds
Avg Batch time: 0.0783 seconds

Best acc: 74.520
--------------------------------------------------------------------------------
Test time: 6.793659687042236

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.052)	BT: 0.071 (0.082)	Loss 0.0048 (0.0088)	Prec@1 100.000 (99.960)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.043)	BT: 0.043 (0.074)	Loss 0.0075 (0.0082)	Prec@1 100.000 (99.960)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.042)	BT: 0.022 (0.073)	Loss 0.0101 (0.0087)	Prec@1 100.000 (99.943)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.042)	BT: 0.031 (0.073)	Loss 0.0057 (0.0088)	Prec@1 100.000 (99.947)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.040)	BT: 0.028 (0.070)	Loss 0.0243 (0.0088)	Prec@1 99.219 (99.950)	
Total train loss: 0.0089
Avg Loading time: 0.0394 seconds
Avg Batch time: 0.0701 seconds

Train time: 27.516828298568726
 * Prec@1 74.320 Prec@5 91.660 Loss 1.1377
Avg Loading time: 0.0625 seconds
Avg Batch time: 0.0736 seconds

Best acc: 74.520
--------------------------------------------------------------------------------
Test time: 6.449359178543091

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.030 (0.058)	Loss 0.0032 (0.0090)	Prec@1 100.000 (99.950)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.017)	BT: 0.045 (0.046)	Loss 0.0066 (0.0088)	Prec@1 100.000 (99.950)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.018)	BT: 0.022 (0.048)	Loss 0.0091 (0.0088)	Prec@1 100.000 (99.947)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.027)	BT: 0.034 (0.057)	Loss 0.0073 (0.0087)	Prec@1 100.000 (99.950)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.036)	BT: 0.023 (0.066)	Loss 0.0056 (0.0087)	Prec@1 100.000 (99.952)	
Total train loss: 0.0087
Avg Loading time: 0.0363 seconds
Avg Batch time: 0.0657 seconds

Train time: 25.761123180389404
 * Prec@1 74.510 Prec@5 91.740 Loss 1.1338
Avg Loading time: 0.0850 seconds
Avg Batch time: 0.0964 seconds

Best acc: 74.520
--------------------------------------------------------------------------------
Test time: 8.209559917449951

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.105)	BT: 0.036 (0.134)	Loss 0.0093 (0.0083)	Prec@1 100.000 (99.960)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.094)	BT: 0.023 (0.123)	Loss 0.0064 (0.0084)	Prec@1 100.000 (99.950)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.094)	BT: 0.035 (0.122)	Loss 0.0070 (0.0088)	Prec@1 100.000 (99.950)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.089)	BT: 0.021 (0.117)	Loss 0.0142 (0.0089)	Prec@1 100.000 (99.947)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.313 (0.091)	BT: 0.336 (0.119)	Loss 0.0040 (0.0088)	Prec@1 100.000 (99.946)	
Total train loss: 0.0088
Avg Loading time: 0.0907 seconds
Avg Batch time: 0.1184 seconds

Train time: 46.42988586425781
 * Prec@1 74.030 Prec@5 91.690 Loss 1.1357
Avg Loading time: 0.0907 seconds
Avg Batch time: 0.1001 seconds

Best acc: 74.520
--------------------------------------------------------------------------------
Test time: 8.50877833366394

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.071)	BT: 0.038 (0.098)	Loss 0.0048 (0.0080)	Prec@1 100.000 (99.950)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.045)	BT: 0.038 (0.074)	Loss 0.0092 (0.0079)	Prec@1 100.000 (99.965)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.049)	BT: 0.027 (0.079)	Loss 0.0052 (0.0079)	Prec@1 100.000 (99.967)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.060)	BT: 0.027 (0.089)	Loss 0.0098 (0.0081)	Prec@1 100.000 (99.965)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.391 (0.064)	BT: 0.414 (0.093)	Loss 0.0071 (0.0082)	Prec@1 100.000 (99.966)	
Total train loss: 0.0082
Avg Loading time: 0.0643 seconds
Avg Batch time: 0.0931 seconds

Train time: 36.558542251586914
 * Prec@1 74.360 Prec@5 91.630 Loss 1.1406
Avg Loading time: 0.0775 seconds
Avg Batch time: 0.0889 seconds

Best acc: 74.520
--------------------------------------------------------------------------------
Test time: 7.6663291454315186

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.075)	BT: 0.028 (0.105)	Loss 0.0054 (0.0084)	Prec@1 100.000 (99.970)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.062)	BT: 0.023 (0.090)	Loss 0.0055 (0.0082)	Prec@1 100.000 (99.970)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.065)	BT: 0.026 (0.093)	Loss 0.0122 (0.0082)	Prec@1 100.000 (99.973)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.067)	BT: 0.022 (0.094)	Loss 0.0085 (0.0084)	Prec@1 100.000 (99.972)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.070)	BT: 0.021 (0.097)	Loss 0.0077 (0.0085)	Prec@1 100.000 (99.972)	
Total train loss: 0.0086
Avg Loading time: 0.0701 seconds
Avg Batch time: 0.0970 seconds

Train time: 38.015554904937744
 * Prec@1 74.390 Prec@5 91.650 Loss 1.1416
Avg Loading time: 0.0918 seconds
Avg Batch time: 0.1034 seconds

Best acc: 74.520
--------------------------------------------------------------------------------
Test time: 8.772215127944946

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.101)	BT: 0.025 (0.127)	Loss 0.0062 (0.0082)	Prec@1 100.000 (99.960)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.095)	BT: 0.031 (0.121)	Loss 0.0056 (0.0085)	Prec@1 100.000 (99.955)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.014 (0.092)	BT: 0.037 (0.118)	Loss 0.0080 (0.0086)	Prec@1 100.000 (99.950)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.090)	BT: 0.025 (0.117)	Loss 0.0058 (0.0088)	Prec@1 100.000 (99.945)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.091)	BT: 0.022 (0.117)	Loss 0.0135 (0.0089)	Prec@1 100.000 (99.936)	
Total train loss: 0.0089
Avg Loading time: 0.0909 seconds
Avg Batch time: 0.1169 seconds

Train time: 45.79726219177246
 * Prec@1 74.310 Prec@5 91.710 Loss 1.1348
Avg Loading time: 0.0971 seconds
Avg Batch time: 0.1085 seconds

Best acc: 74.520
--------------------------------------------------------------------------------
Test time: 9.11987566947937

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.083)	BT: 0.022 (0.108)	Loss 0.0050 (0.0090)	Prec@1 100.000 (99.950)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.086)	BT: 0.024 (0.112)	Loss 0.0048 (0.0086)	Prec@1 100.000 (99.955)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.528 (0.088)	BT: 0.561 (0.115)	Loss 0.0163 (0.0088)	Prec@1 99.219 (99.940)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.090)	BT: 0.033 (0.116)	Loss 0.0078 (0.0089)	Prec@1 100.000 (99.947)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.336 (0.091)	BT: 0.357 (0.118)	Loss 0.0065 (0.0088)	Prec@1 100.000 (99.942)	
Total train loss: 0.0088
Avg Loading time: 0.0911 seconds
Avg Batch time: 0.1179 seconds

Train time: 46.17315983772278
 * Prec@1 74.450 Prec@5 91.650 Loss 1.1328
Avg Loading time: 0.1196 seconds
Avg Batch time: 0.1303 seconds

Best acc: 74.520
--------------------------------------------------------------------------------
Test time: 10.896546602249146

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.094)	BT: 0.023 (0.120)	Loss 0.0037 (0.0078)	Prec@1 100.000 (99.990)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.099)	BT: 0.034 (0.124)	Loss 0.0107 (0.0084)	Prec@1 100.000 (99.955)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 1.025 (0.094)	BT: 1.058 (0.119)	Loss 0.0072 (0.0084)	Prec@1 100.000 (99.957)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.093)	BT: 0.021 (0.118)	Loss 0.0027 (0.0084)	Prec@1 100.000 (99.960)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.096)	BT: 0.025 (0.121)	Loss 0.0128 (0.0085)	Prec@1 100.000 (99.958)	
Total train loss: 0.0085
Avg Loading time: 0.0955 seconds
Avg Batch time: 0.1211 seconds

Train time: 47.41821098327637
 * Prec@1 74.840 Prec@5 91.660 Loss 1.1338
Avg Loading time: 0.0988 seconds
Avg Batch time: 0.1096 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 9.625726461410522

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.099)	BT: 0.037 (0.125)	Loss 0.0080 (0.0085)	Prec@1 100.000 (99.970)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.093)	BT: 0.023 (0.119)	Loss 0.0039 (0.0083)	Prec@1 100.000 (99.965)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.742 (0.091)	BT: 0.770 (0.116)	Loss 0.0082 (0.0083)	Prec@1 100.000 (99.973)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.092)	BT: 0.033 (0.118)	Loss 0.0042 (0.0083)	Prec@1 100.000 (99.970)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.090)	BT: 0.024 (0.117)	Loss 0.0065 (0.0083)	Prec@1 100.000 (99.970)	
Total train loss: 0.0083
Avg Loading time: 0.0900 seconds
Avg Batch time: 0.1164 seconds

Train time: 45.60819387435913
 * Prec@1 74.050 Prec@5 91.770 Loss 1.1367
Avg Loading time: 0.1472 seconds
Avg Batch time: 0.1574 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 12.987352848052979

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.089)	BT: 0.025 (0.114)	Loss 0.0122 (0.0094)	Prec@1 100.000 (99.970)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.084)	BT: 0.022 (0.109)	Loss 0.0291 (0.0089)	Prec@1 99.219 (99.960)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.087)	BT: 0.028 (0.112)	Loss 0.0086 (0.0088)	Prec@1 100.000 (99.947)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.088)	BT: 0.044 (0.114)	Loss 0.0079 (0.0085)	Prec@1 100.000 (99.955)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.091)	BT: 0.022 (0.117)	Loss 0.0209 (0.0085)	Prec@1 100.000 (99.958)	
Total train loss: 0.0085
Avg Loading time: 0.0909 seconds
Avg Batch time: 0.1168 seconds

Train time: 45.736154079437256
 * Prec@1 74.570 Prec@5 91.580 Loss 1.1318
Avg Loading time: 0.0852 seconds
Avg Batch time: 0.0950 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 8.053693771362305

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.112)	BT: 0.033 (0.139)	Loss 0.0058 (0.0077)	Prec@1 100.000 (99.970)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.379 (0.103)	BT: 0.412 (0.131)	Loss 0.0077 (0.0079)	Prec@1 100.000 (99.960)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.100)	BT: 0.021 (0.127)	Loss 0.0076 (0.0081)	Prec@1 100.000 (99.953)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.103)	BT: 0.045 (0.130)	Loss 0.0091 (0.0082)	Prec@1 100.000 (99.957)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.105)	BT: 0.022 (0.131)	Loss 0.0113 (0.0084)	Prec@1 100.000 (99.962)	
Total train loss: 0.0084
Avg Loading time: 0.1042 seconds
Avg Batch time: 0.1309 seconds

Train time: 51.26239585876465
 * Prec@1 74.430 Prec@5 91.590 Loss 1.1377
Avg Loading time: 0.1045 seconds
Avg Batch time: 0.1151 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 9.706126928329468

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.108)	BT: 0.027 (0.133)	Loss 0.0204 (0.0090)	Prec@1 99.219 (99.950)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.108)	BT: 0.025 (0.133)	Loss 0.0083 (0.0085)	Prec@1 100.000 (99.955)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.110)	BT: 0.030 (0.135)	Loss 0.0051 (0.0084)	Prec@1 100.000 (99.957)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.110)	BT: 0.024 (0.136)	Loss 0.0065 (0.0086)	Prec@1 100.000 (99.960)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.109)	BT: 0.034 (0.135)	Loss 0.0119 (0.0087)	Prec@1 99.219 (99.952)	
Total train loss: 0.0087
Avg Loading time: 0.1089 seconds
Avg Batch time: 0.1350 seconds

Train time: 52.88868284225464
 * Prec@1 74.520 Prec@5 91.650 Loss 1.1338
Avg Loading time: 0.1570 seconds
Avg Batch time: 0.1675 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 13.799575328826904

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.099)	BT: 0.022 (0.125)	Loss 0.0085 (0.0085)	Prec@1 100.000 (99.960)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.099)	BT: 0.022 (0.124)	Loss 0.0094 (0.0085)	Prec@1 100.000 (99.950)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.500 (0.097)	BT: 0.530 (0.122)	Loss 0.0097 (0.0083)	Prec@1 100.000 (99.960)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.098)	BT: 0.024 (0.124)	Loss 0.0080 (0.0084)	Prec@1 100.000 (99.952)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.103)	BT: 0.024 (0.129)	Loss 0.0041 (0.0083)	Prec@1 100.000 (99.958)	
Total train loss: 0.0084
Avg Loading time: 0.1028 seconds
Avg Batch time: 0.1285 seconds

Train time: 50.330729484558105
 * Prec@1 74.430 Prec@5 91.880 Loss 1.1348
Avg Loading time: 0.1498 seconds
Avg Batch time: 0.1615 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 13.375099182128906

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.116)	BT: 0.026 (0.142)	Loss 0.0103 (0.0085)	Prec@1 100.000 (99.950)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.115)	BT: 0.024 (0.141)	Loss 0.0123 (0.0083)	Prec@1 100.000 (99.955)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.114)	BT: 0.029 (0.139)	Loss 0.0028 (0.0083)	Prec@1 100.000 (99.950)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.108)	BT: 0.022 (0.134)	Loss 0.0162 (0.0084)	Prec@1 99.219 (99.947)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.227 (0.112)	BT: 0.260 (0.138)	Loss 0.0036 (0.0084)	Prec@1 100.000 (99.946)	
Total train loss: 0.0085
Avg Loading time: 0.1112 seconds
Avg Batch time: 0.1375 seconds

Train time: 53.85042715072632
 * Prec@1 74.340 Prec@5 91.570 Loss 1.1348
Avg Loading time: 0.1390 seconds
Avg Batch time: 0.1501 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 12.457298278808594

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.102)	BT: 0.026 (0.130)	Loss 0.0083 (0.0096)	Prec@1 100.000 (99.880)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.099)	BT: 0.058 (0.126)	Loss 0.0061 (0.0087)	Prec@1 100.000 (99.920)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.038 (0.100)	BT: 0.059 (0.126)	Loss 0.0082 (0.0086)	Prec@1 100.000 (99.933)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.100)	BT: 0.024 (0.127)	Loss 0.0098 (0.0087)	Prec@1 100.000 (99.930)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.099)	BT: 0.020 (0.126)	Loss 0.0141 (0.0086)	Prec@1 100.000 (99.944)	
Total train loss: 0.0086
Avg Loading time: 0.0991 seconds
Avg Batch time: 0.1256 seconds

Train time: 49.18545603752136
 * Prec@1 74.200 Prec@5 91.680 Loss 1.1387
Avg Loading time: 0.1564 seconds
Avg Batch time: 0.1670 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 13.75045371055603

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.090)	BT: 0.022 (0.115)	Loss 0.0038 (0.0086)	Prec@1 100.000 (99.980)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.092)	BT: 0.025 (0.117)	Loss 0.0182 (0.0086)	Prec@1 99.219 (99.960)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.093)	BT: 0.029 (0.118)	Loss 0.0079 (0.0089)	Prec@1 100.000 (99.943)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.095)	BT: 0.023 (0.121)	Loss 0.0119 (0.0086)	Prec@1 100.000 (99.955)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.101)	BT: 0.021 (0.127)	Loss 0.0184 (0.0088)	Prec@1 100.000 (99.954)	
Total train loss: 0.0088
Avg Loading time: 0.1007 seconds
Avg Batch time: 0.1268 seconds

Train time: 49.66278290748596
 * Prec@1 74.350 Prec@5 91.800 Loss 1.1436
Avg Loading time: 0.1462 seconds
Avg Batch time: 0.1566 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 12.980431079864502

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.100)	BT: 0.021 (0.127)	Loss 0.0058 (0.0088)	Prec@1 100.000 (99.940)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.102)	BT: 0.022 (0.128)	Loss 0.0030 (0.0086)	Prec@1 100.000 (99.950)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.429 (0.097)	BT: 0.462 (0.124)	Loss 0.0045 (0.0085)	Prec@1 100.000 (99.937)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.094)	BT: 0.026 (0.122)	Loss 0.0125 (0.0086)	Prec@1 100.000 (99.942)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.137 (0.094)	BT: 0.160 (0.122)	Loss 0.0093 (0.0086)	Prec@1 100.000 (99.948)	
Total train loss: 0.0086
Avg Loading time: 0.0942 seconds
Avg Batch time: 0.1218 seconds

Train time: 47.710200786590576
 * Prec@1 74.380 Prec@5 91.760 Loss 1.1387
Avg Loading time: 0.1340 seconds
Avg Batch time: 0.1441 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 11.958493947982788

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.101)	BT: 0.022 (0.128)	Loss 0.0078 (0.0084)	Prec@1 100.000 (99.960)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.096)	BT: 0.022 (0.123)	Loss 0.0107 (0.0088)	Prec@1 100.000 (99.965)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.094)	BT: 0.028 (0.121)	Loss 0.0271 (0.0087)	Prec@1 99.219 (99.960)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.094)	BT: 0.026 (0.121)	Loss 0.0089 (0.0088)	Prec@1 100.000 (99.955)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.093)	BT: 0.021 (0.120)	Loss 0.0407 (0.0089)	Prec@1 99.219 (99.948)	
Total train loss: 0.0089
Avg Loading time: 0.0928 seconds
Avg Batch time: 0.1194 seconds

Train time: 46.80539512634277
 * Prec@1 74.460 Prec@5 91.660 Loss 1.1426
Avg Loading time: 0.1038 seconds
Avg Batch time: 0.1152 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 9.724681615829468

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.088)	BT: 0.029 (0.114)	Loss 0.0106 (0.0093)	Prec@1 99.219 (99.890)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.088)	BT: 0.029 (0.114)	Loss 0.0058 (0.0087)	Prec@1 100.000 (99.935)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.088)	BT: 0.031 (0.114)	Loss 0.0142 (0.0089)	Prec@1 100.000 (99.940)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.090)	BT: 0.024 (0.116)	Loss 0.0054 (0.0088)	Prec@1 100.000 (99.945)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.093)	BT: 0.022 (0.119)	Loss 0.0077 (0.0087)	Prec@1 100.000 (99.952)	
Total train loss: 0.0087
Avg Loading time: 0.0928 seconds
Avg Batch time: 0.1191 seconds

Train time: 46.72192740440369
 * Prec@1 74.280 Prec@5 91.700 Loss 1.1387
Avg Loading time: 0.1054 seconds
Avg Batch time: 0.1157 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 9.736337900161743

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.092)	BT: 0.022 (0.119)	Loss 0.0043 (0.0087)	Prec@1 100.000 (99.940)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.089)	BT: 0.030 (0.115)	Loss 0.0030 (0.0083)	Prec@1 100.000 (99.950)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.085)	BT: 0.029 (0.112)	Loss 0.0130 (0.0084)	Prec@1 100.000 (99.943)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.083)	BT: 0.045 (0.110)	Loss 0.0079 (0.0084)	Prec@1 100.000 (99.947)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.082)	BT: 0.022 (0.108)	Loss 0.0064 (0.0085)	Prec@1 100.000 (99.948)	
Total train loss: 0.0085
Avg Loading time: 0.0814 seconds
Avg Batch time: 0.1080 seconds

Train time: 42.34216356277466
 * Prec@1 74.550 Prec@5 91.740 Loss 1.1396
Avg Loading time: 0.0929 seconds
Avg Batch time: 0.1031 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 8.70206618309021

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.090)	BT: 0.023 (0.115)	Loss 0.0061 (0.0086)	Prec@1 100.000 (99.950)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.092)	BT: 0.045 (0.118)	Loss 0.0050 (0.0087)	Prec@1 100.000 (99.945)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.673 (0.090)	BT: 0.704 (0.117)	Loss 0.0065 (0.0085)	Prec@1 100.000 (99.943)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.002 (0.094)	BT: 0.065 (0.120)	Loss 0.0060 (0.0087)	Prec@1 100.000 (99.942)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.091)	BT: 0.022 (0.118)	Loss 0.0046 (0.0087)	Prec@1 100.000 (99.942)	
Total train loss: 0.0087
Avg Loading time: 0.0909 seconds
Avg Batch time: 0.1175 seconds

Train time: 46.098712682724
 * Prec@1 74.270 Prec@5 91.710 Loss 1.1309
Avg Loading time: 0.1098 seconds
Avg Batch time: 0.1210 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 10.162192821502686

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.094)	BT: 0.022 (0.119)	Loss 0.0109 (0.0094)	Prec@1 100.000 (99.930)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.084)	BT: 0.022 (0.109)	Loss 0.0115 (0.0092)	Prec@1 100.000 (99.945)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.089)	BT: 0.027 (0.115)	Loss 0.0033 (0.0091)	Prec@1 100.000 (99.950)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.086)	BT: 0.024 (0.112)	Loss 0.0079 (0.0090)	Prec@1 100.000 (99.947)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.089)	BT: 0.022 (0.114)	Loss 0.0045 (0.0092)	Prec@1 100.000 (99.940)	
Total train loss: 0.0092
Avg Loading time: 0.0888 seconds
Avg Batch time: 0.1141 seconds

Train time: 44.7114577293396
 * Prec@1 74.300 Prec@5 91.730 Loss 1.1338
Avg Loading time: 0.0837 seconds
Avg Batch time: 0.0944 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 8.067490100860596

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.090)	BT: 0.025 (0.119)	Loss 0.0055 (0.0093)	Prec@1 100.000 (99.920)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.085)	BT: 0.023 (0.113)	Loss 0.0045 (0.0090)	Prec@1 100.000 (99.935)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.787 (0.084)	BT: 0.818 (0.111)	Loss 0.0056 (0.0090)	Prec@1 100.000 (99.940)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.084)	BT: 0.024 (0.111)	Loss 0.0071 (0.0089)	Prec@1 100.000 (99.940)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.085)	BT: 0.029 (0.111)	Loss 0.0101 (0.0087)	Prec@1 100.000 (99.936)	
Total train loss: 0.0088
Avg Loading time: 0.0844 seconds
Avg Batch time: 0.1112 seconds

Train time: 43.55904841423035
 * Prec@1 74.180 Prec@5 91.640 Loss 1.1445
Avg Loading time: 0.1207 seconds
Avg Batch time: 0.1312 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 10.942080736160278

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.081)	BT: 0.028 (0.107)	Loss 0.0086 (0.0089)	Prec@1 100.000 (99.910)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.083)	BT: 0.037 (0.110)	Loss 0.0075 (0.0087)	Prec@1 100.000 (99.930)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.084)	BT: 0.025 (0.111)	Loss 0.0076 (0.0086)	Prec@1 100.000 (99.930)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.084)	BT: 0.033 (0.112)	Loss 0.0075 (0.0086)	Prec@1 100.000 (99.940)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.084)	BT: 0.022 (0.111)	Loss 0.0069 (0.0088)	Prec@1 100.000 (99.938)	
Total train loss: 0.0089
Avg Loading time: 0.0839 seconds
Avg Batch time: 0.1111 seconds

Train time: 43.544766902923584
 * Prec@1 74.440 Prec@5 91.650 Loss 1.1377
Avg Loading time: 0.0912 seconds
Avg Batch time: 0.1018 seconds

Best acc: 74.840
--------------------------------------------------------------------------------
Test time: 8.665761470794678


      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 0
          frozen_layers: 13
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar100/resnet18
DEVICE: cuda
GPU Id(s) being used: 0
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/train/relu13
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/test/relu13
ResNet18(
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=100, bias=False)
  (bn19): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 0.760 Prec@5 4.540 Loss 4.6016
Avg Loading time: 1.1377 seconds
Avg Batch time: 1.1519 seconds

Pre-trained Prec@1 with 13 layers frozen: 0.7599999904632568 	 Loss: 4.6015625

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (0.986)	BT: 0.022 (1.008)	Loss 1.8955 (2.3011)	Prec@1 50.781 (44.381)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (0.884)	BT: 0.018 (0.906)	Loss 1.5771 (1.9577)	Prec@1 56.250 (50.351)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (0.851)	BT: 0.018 (0.872)	Loss 1.3740 (1.7941)	Prec@1 64.844 (53.322)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (0.806)	BT: 0.018 (0.827)	Loss 1.2520 (1.6942)	Prec@1 65.625 (55.243)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.800 (0.770)	BT: 0.819 (0.792)	Loss 1.2598 (1.6123)	Prec@1 61.719 (56.885)	
Total train loss: 1.6121
Avg Loading time: 0.7685 seconds
Avg Batch time: 0.7896 seconds

Train time: 308.85550832748413
 * Prec@1 64.080 Prec@5 90.370 Loss 1.2627
Avg Loading time: 0.0907 seconds
Avg Batch time: 0.0992 seconds

Best acc: 64.080
--------------------------------------------------------------------------------
Test time: 8.741756200790405

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.081)	BT: 0.018 (0.099)	Loss 1.1221 (0.9814)	Prec@1 64.844 (71.975)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.079)	BT: 0.015 (0.099)	Loss 0.9624 (0.9949)	Prec@1 69.531 (71.414)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.083)	BT: 0.018 (0.103)	Loss 0.8740 (0.9962)	Prec@1 76.562 (71.151)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.080)	BT: 0.016 (0.101)	Loss 0.9458 (1.0000)	Prec@1 77.344 (70.926)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.079)	BT: 0.036 (0.100)	Loss 1.1494 (1.0017)	Prec@1 67.969 (70.871)	
Total train loss: 1.0019
Avg Loading time: 0.0790 seconds
Avg Batch time: 0.0995 seconds

Train time: 39.04771900177002
 * Prec@1 67.350 Prec@5 90.900 Loss 1.1660
Avg Loading time: 0.0939 seconds
Avg Batch time: 0.1037 seconds

Best acc: 67.350
--------------------------------------------------------------------------------
Test time: 9.125753164291382

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.097)	BT: 0.017 (0.119)	Loss 0.5957 (0.6609)	Prec@1 82.031 (80.178)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.068 (0.078)	BT: 0.092 (0.098)	Loss 0.7070 (0.6798)	Prec@1 79.688 (79.612)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (0.080)	BT: 0.015 (0.099)	Loss 0.7705 (0.7029)	Prec@1 78.125 (79.077)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.077)	BT: 0.017 (0.096)	Loss 0.8623 (0.7164)	Prec@1 72.656 (78.576)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.077)	BT: 0.016 (0.097)	Loss 0.8188 (0.7363)	Prec@1 75.000 (78.073)	
Total train loss: 0.7365
Avg Loading time: 0.0771 seconds
Avg Batch time: 0.0965 seconds

Train time: 37.851226568222046
 * Prec@1 67.730 Prec@5 91.520 Loss 1.1533
Avg Loading time: 0.0789 seconds
Avg Batch time: 0.0892 seconds

Best acc: 67.730
--------------------------------------------------------------------------------
Test time: 7.936403036117554

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.090)	BT: 0.025 (0.113)	Loss 0.4199 (0.4813)	Prec@1 87.500 (85.577)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.085)	BT: 0.016 (0.108)	Loss 0.4434 (0.4900)	Prec@1 85.156 (85.086)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.563 (0.083)	BT: 0.592 (0.105)	Loss 0.5483 (0.5060)	Prec@1 80.469 (84.525)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.055 (0.084)	BT: 0.074 (0.106)	Loss 0.6108 (0.5242)	Prec@1 80.469 (83.932)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.081)	BT: 0.015 (0.103)	Loss 0.7705 (0.5390)	Prec@1 75.000 (83.375)	
Total train loss: 0.5392
Avg Loading time: 0.0810 seconds
Avg Batch time: 0.1030 seconds

Train time: 40.37970542907715
 * Prec@1 67.750 Prec@5 90.260 Loss 1.2109
Avg Loading time: 0.1024 seconds
Avg Batch time: 0.1108 seconds

Best acc: 67.750
--------------------------------------------------------------------------------
Test time: 9.639847040176392

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.058)	BT: 0.016 (0.078)	Loss 0.3469 (0.3304)	Prec@1 87.500 (90.264)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.061)	BT: 0.025 (0.082)	Loss 0.3279 (0.3440)	Prec@1 89.844 (89.528)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.064)	BT: 0.026 (0.086)	Loss 0.3813 (0.3588)	Prec@1 88.281 (89.006)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.068)	BT: 0.023 (0.089)	Loss 0.4182 (0.3763)	Prec@1 86.719 (88.359)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.068)	BT: 0.017 (0.090)	Loss 0.4475 (0.3926)	Prec@1 85.156 (87.837)	
Total train loss: 0.3925
Avg Loading time: 0.0679 seconds
Avg Batch time: 0.0897 seconds

Train time: 35.23025918006897
 * Prec@1 67.950 Prec@5 90.170 Loss 1.2939
Avg Loading time: 0.0868 seconds
Avg Batch time: 0.0957 seconds

Best acc: 67.950
--------------------------------------------------------------------------------
Test time: 8.45125150680542

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.080)	BT: 0.015 (0.100)	Loss 0.2979 (0.2434)	Prec@1 90.625 (93.109)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.075)	BT: 0.016 (0.095)	Loss 0.2206 (0.2485)	Prec@1 94.531 (92.834)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.000 (0.073)	BT: 0.020 (0.093)	Loss 0.2234 (0.2608)	Prec@1 94.531 (92.354)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.077)	BT: 0.016 (0.098)	Loss 0.3987 (0.2775)	Prec@1 84.375 (91.702)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.076)	BT: 0.019 (0.096)	Loss 0.5596 (0.2905)	Prec@1 78.125 (91.198)	
Total train loss: 0.2910
Avg Loading time: 0.0755 seconds
Avg Batch time: 0.0958 seconds

Train time: 37.55844283103943
 * Prec@1 67.500 Prec@5 89.580 Loss 1.3369
Avg Loading time: 0.0994 seconds
Avg Batch time: 0.1079 seconds

Best acc: 67.950
--------------------------------------------------------------------------------
Test time: 9.234256744384766

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.093)	BT: 0.015 (0.114)	Loss 0.2415 (0.1992)	Prec@1 92.969 (94.221)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.090)	BT: 0.018 (0.112)	Loss 0.1376 (0.1970)	Prec@1 96.094 (94.241)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.091)	BT: 0.020 (0.112)	Loss 0.1593 (0.2055)	Prec@1 96.094 (93.997)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.085)	BT: 0.032 (0.107)	Loss 0.1639 (0.2096)	Prec@1 92.969 (93.868)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.085)	BT: 0.017 (0.106)	Loss 0.2776 (0.2169)	Prec@1 91.406 (93.582)	
Total train loss: 0.2171
Avg Loading time: 0.0848 seconds
Avg Batch time: 0.1060 seconds

Train time: 41.56807041168213
 * Prec@1 68.240 Prec@5 89.970 Loss 1.3936
Avg Loading time: 0.1000 seconds
Avg Batch time: 0.1096 seconds

Best acc: 68.240
--------------------------------------------------------------------------------
Test time: 9.545029401779175

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.103)	BT: 0.026 (0.122)	Loss 0.1508 (0.1529)	Prec@1 95.312 (95.483)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.092)	BT: 0.017 (0.111)	Loss 0.1030 (0.1505)	Prec@1 97.656 (95.663)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.094)	BT: 0.027 (0.114)	Loss 0.1769 (0.1580)	Prec@1 94.531 (95.393)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.435 (0.091)	BT: 0.454 (0.111)	Loss 0.1824 (0.1656)	Prec@1 97.656 (95.137)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.090)	BT: 0.016 (0.111)	Loss 0.1799 (0.1746)	Prec@1 95.312 (94.812)	
Total train loss: 0.1746
Avg Loading time: 0.0897 seconds
Avg Batch time: 0.1107 seconds

Train time: 43.365710973739624
 * Prec@1 68.400 Prec@5 89.340 Loss 1.3828
Avg Loading time: 0.0987 seconds
Avg Batch time: 0.1090 seconds

Best acc: 68.400
--------------------------------------------------------------------------------
Test time: 9.489462852478027

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.095)	BT: 0.027 (0.116)	Loss 0.1348 (0.1326)	Prec@1 96.875 (96.144)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.096)	BT: 0.019 (0.117)	Loss 0.1898 (0.1388)	Prec@1 94.531 (96.059)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.097)	BT: 0.019 (0.119)	Loss 0.1917 (0.1414)	Prec@1 94.531 (95.923)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.094)	BT: 0.018 (0.116)	Loss 0.1357 (0.1463)	Prec@1 95.312 (95.773)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.099)	BT: 0.019 (0.120)	Loss 0.2499 (0.1497)	Prec@1 91.406 (95.653)	
Total train loss: 0.1498
Avg Loading time: 0.0989 seconds
Avg Batch time: 0.1202 seconds

Train time: 47.08994483947754
 * Prec@1 68.350 Prec@5 89.910 Loss 1.3828
Avg Loading time: 0.0992 seconds
Avg Batch time: 0.1091 seconds

Best acc: 68.400
--------------------------------------------------------------------------------
Test time: 9.266287803649902

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.101)	BT: 0.024 (0.123)	Loss 0.0387 (0.1090)	Prec@1 100.000 (97.025)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.010 (0.097)	BT: 0.034 (0.119)	Loss 0.1024 (0.1087)	Prec@1 97.656 (97.095)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.095)	BT: 0.024 (0.117)	Loss 0.1095 (0.1108)	Prec@1 97.656 (97.042)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.096)	BT: 0.018 (0.118)	Loss 0.0927 (0.1131)	Prec@1 96.875 (96.900)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.095)	BT: 0.019 (0.117)	Loss 0.2096 (0.1175)	Prec@1 92.969 (96.739)	
Total train loss: 0.1177
Avg Loading time: 0.0947 seconds
Avg Batch time: 0.1169 seconds

Train time: 45.805556535720825
 * Prec@1 68.330 Prec@5 89.100 Loss 1.3916
Avg Loading time: 0.1382 seconds
Avg Batch time: 0.1483 seconds

Best acc: 68.400
--------------------------------------------------------------------------------
Test time: 12.286020278930664

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.104)	BT: 0.021 (0.125)	Loss 0.0533 (0.0737)	Prec@1 98.438 (98.167)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.090)	BT: 0.020 (0.111)	Loss 0.0440 (0.0652)	Prec@1 100.000 (98.382)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.092)	BT: 0.018 (0.114)	Loss 0.0251 (0.0592)	Prec@1 99.219 (98.591)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.094)	BT: 0.019 (0.117)	Loss 0.0430 (0.0553)	Prec@1 99.219 (98.693)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.083 (0.097)	BT: 0.107 (0.119)	Loss 0.0242 (0.0517)	Prec@1 100.000 (98.822)	
Total train loss: 0.0518
Avg Loading time: 0.0967 seconds
Avg Batch time: 0.1192 seconds

Train time: 46.75117039680481
 * Prec@1 73.190 Prec@5 91.210 Loss 1.1582
Avg Loading time: 0.0930 seconds
Avg Batch time: 0.1023 seconds

Best acc: 73.190
--------------------------------------------------------------------------------
Test time: 8.985289335250854

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.101)	BT: 0.018 (0.121)	Loss 0.0345 (0.0254)	Prec@1 99.219 (99.619)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.092)	BT: 0.017 (0.112)	Loss 0.0354 (0.0252)	Prec@1 99.219 (99.644)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.351 (0.100)	BT: 0.371 (0.121)	Loss 0.0142 (0.0249)	Prec@1 100.000 (99.646)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.099)	BT: 0.019 (0.120)	Loss 0.0150 (0.0249)	Prec@1 100.000 (99.644)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.100)	BT: 0.017 (0.121)	Loss 0.0294 (0.0245)	Prec@1 99.219 (99.655)	
Total train loss: 0.0245
Avg Loading time: 0.0997 seconds
Avg Batch time: 0.1207 seconds

Train time: 47.32875990867615
 * Prec@1 73.630 Prec@5 91.070 Loss 1.1660
Avg Loading time: 0.0979 seconds
Avg Batch time: 0.1070 seconds

Best acc: 73.630
--------------------------------------------------------------------------------
Test time: 9.35410451889038

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.099)	BT: 0.021 (0.121)	Loss 0.0155 (0.0176)	Prec@1 100.000 (99.880)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.100)	BT: 0.021 (0.123)	Loss 0.0107 (0.0183)	Prec@1 100.000 (99.835)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.099)	BT: 0.026 (0.121)	Loss 0.0102 (0.0185)	Prec@1 100.000 (99.830)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.102)	BT: 0.029 (0.124)	Loss 0.0187 (0.0182)	Prec@1 100.000 (99.840)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.102)	BT: 0.016 (0.124)	Loss 0.0160 (0.0181)	Prec@1 100.000 (99.838)	
Total train loss: 0.0181
Avg Loading time: 0.1018 seconds
Avg Batch time: 0.1240 seconds

Train time: 48.56452131271362
 * Prec@1 73.920 Prec@5 91.350 Loss 1.1621
Avg Loading time: 0.1016 seconds
Avg Batch time: 0.1108 seconds

Best acc: 73.920
--------------------------------------------------------------------------------
Test time: 9.63657546043396

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.094)	BT: 0.017 (0.114)	Loss 0.0130 (0.0164)	Prec@1 100.000 (99.890)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.094)	BT: 0.029 (0.113)	Loss 0.0090 (0.0169)	Prec@1 100.000 (99.835)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.368 (0.092)	BT: 0.397 (0.112)	Loss 0.0208 (0.0162)	Prec@1 100.000 (99.833)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.100)	BT: 0.023 (0.120)	Loss 0.0188 (0.0162)	Prec@1 100.000 (99.832)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.102)	BT: 0.026 (0.123)	Loss 0.0268 (0.0164)	Prec@1 100.000 (99.828)	
Total train loss: 0.0164
Avg Loading time: 0.1018 seconds
Avg Batch time: 0.1224 seconds

Train time: 47.985127210617065
 * Prec@1 73.640 Prec@5 91.360 Loss 1.1611
Avg Loading time: 0.1156 seconds
Avg Batch time: 0.1247 seconds

Best acc: 73.920
--------------------------------------------------------------------------------
Test time: 10.414737462997437

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.092)	BT: 0.027 (0.115)	Loss 0.0083 (0.0127)	Prec@1 100.000 (99.890)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.093)	BT: 0.017 (0.115)	Loss 0.0098 (0.0135)	Prec@1 100.000 (99.865)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.094)	BT: 0.019 (0.116)	Loss 0.0115 (0.0136)	Prec@1 100.000 (99.850)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.096)	BT: 0.019 (0.118)	Loss 0.0109 (0.0141)	Prec@1 100.000 (99.835)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.095)	BT: 0.019 (0.117)	Loss 0.0180 (0.0139)	Prec@1 100.000 (99.846)	
Total train loss: 0.0141
Avg Loading time: 0.0948 seconds
Avg Batch time: 0.1164 seconds

Train time: 45.605143308639526
 * Prec@1 73.900 Prec@5 91.100 Loss 1.1699
Avg Loading time: 0.0927 seconds
Avg Batch time: 0.1017 seconds

Best acc: 73.920
--------------------------------------------------------------------------------
Test time: 8.529852390289307

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.105)	BT: 0.018 (0.128)	Loss 0.0070 (0.0118)	Prec@1 100.000 (99.940)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.095)	BT: 0.021 (0.117)	Loss 0.0054 (0.0115)	Prec@1 100.000 (99.945)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.507 (0.087)	BT: 0.526 (0.110)	Loss 0.0106 (0.0120)	Prec@1 100.000 (99.920)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.685 (0.088)	BT: 0.707 (0.111)	Loss 0.0449 (0.0122)	Prec@1 99.219 (99.912)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.091)	BT: 0.021 (0.114)	Loss 0.0107 (0.0121)	Prec@1 100.000 (99.912)	
Total train loss: 0.0121
Avg Loading time: 0.0911 seconds
Avg Batch time: 0.1136 seconds

Train time: 44.52285623550415
 * Prec@1 73.740 Prec@5 91.420 Loss 1.1709
Avg Loading time: 0.1025 seconds
Avg Batch time: 0.1119 seconds

Best acc: 73.920
--------------------------------------------------------------------------------
Test time: 9.366012811660767

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.035 (0.095)	BT: 0.052 (0.117)	Loss 0.0133 (0.0120)	Prec@1 99.219 (99.870)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.092)	BT: 0.019 (0.113)	Loss 0.0056 (0.0118)	Prec@1 100.000 (99.910)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.094)	BT: 0.027 (0.115)	Loss 0.0101 (0.0118)	Prec@1 100.000 (99.886)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.093)	BT: 0.015 (0.114)	Loss 0.0049 (0.0115)	Prec@1 100.000 (99.897)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.097)	BT: 0.019 (0.117)	Loss 0.0104 (0.0115)	Prec@1 100.000 (99.896)	
Total train loss: 0.0115
Avg Loading time: 0.0963 seconds
Avg Batch time: 0.1170 seconds

Train time: 45.85276436805725
 * Prec@1 73.970 Prec@5 91.020 Loss 1.1719
Avg Loading time: 0.0813 seconds
Avg Batch time: 0.0914 seconds

Best acc: 73.970
--------------------------------------------------------------------------------
Test time: 8.156843900680542

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.094)	BT: 0.015 (0.114)	Loss 0.0101 (0.0108)	Prec@1 100.000 (99.960)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.094)	BT: 0.018 (0.114)	Loss 0.0121 (0.0108)	Prec@1 100.000 (99.940)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.729 (0.097)	BT: 0.744 (0.118)	Loss 0.0069 (0.0105)	Prec@1 100.000 (99.930)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.093)	BT: 0.025 (0.113)	Loss 0.0161 (0.0106)	Prec@1 99.219 (99.930)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.093)	BT: 0.016 (0.113)	Loss 0.0101 (0.0109)	Prec@1 100.000 (99.926)	
Total train loss: 0.0109
Avg Loading time: 0.0925 seconds
Avg Batch time: 0.1128 seconds

Train time: 44.27211880683899
 * Prec@1 73.230 Prec@5 91.300 Loss 1.1709
Avg Loading time: 0.1316 seconds
Avg Batch time: 0.1400 seconds

Best acc: 73.970
--------------------------------------------------------------------------------
Test time: 11.619475364685059

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.094)	BT: 0.017 (0.114)	Loss 0.0067 (0.0092)	Prec@1 100.000 (99.960)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.242 (0.099)	BT: 0.267 (0.120)	Loss 0.0059 (0.0095)	Prec@1 100.000 (99.945)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.093)	BT: 0.019 (0.114)	Loss 0.0037 (0.0094)	Prec@1 100.000 (99.943)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.096)	BT: 0.023 (0.117)	Loss 0.0058 (0.0097)	Prec@1 100.000 (99.937)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.099)	BT: 0.027 (0.120)	Loss 0.0081 (0.0098)	Prec@1 100.000 (99.936)	
Total train loss: 0.0098
Avg Loading time: 0.0985 seconds
Avg Batch time: 0.1193 seconds

Train time: 46.79672574996948
 * Prec@1 73.850 Prec@5 91.160 Loss 1.1699
Avg Loading time: 0.0990 seconds
Avg Batch time: 0.1084 seconds

Best acc: 73.970
--------------------------------------------------------------------------------
Test time: 9.080992221832275

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.102)	BT: 0.017 (0.123)	Loss 0.0089 (0.0087)	Prec@1 100.000 (99.980)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.095)	BT: 0.017 (0.115)	Loss 0.0078 (0.0091)	Prec@1 100.000 (99.950)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.386 (0.088)	BT: 0.407 (0.108)	Loss 0.0092 (0.0095)	Prec@1 100.000 (99.953)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.087)	BT: 0.015 (0.106)	Loss 0.0088 (0.0092)	Prec@1 100.000 (99.962)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.090)	BT: 0.015 (0.109)	Loss 0.0437 (0.0093)	Prec@1 99.219 (99.956)	
Total train loss: 0.0093
Avg Loading time: 0.0894 seconds
Avg Batch time: 0.1088 seconds

Train time: 42.680168867111206
 * Prec@1 73.800 Prec@5 90.870 Loss 1.1719
Avg Loading time: 0.1142 seconds
Avg Batch time: 0.1236 seconds

Best acc: 73.970
--------------------------------------------------------------------------------
Test time: 10.313193559646606

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.103)	BT: 0.016 (0.123)	Loss 0.0039 (0.0093)	Prec@1 100.000 (99.920)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.092)	BT: 0.018 (0.112)	Loss 0.0089 (0.0092)	Prec@1 100.000 (99.920)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.096)	BT: 0.020 (0.116)	Loss 0.0121 (0.0092)	Prec@1 100.000 (99.923)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.093)	BT: 0.016 (0.113)	Loss 0.0067 (0.0089)	Prec@1 100.000 (99.922)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.093)	BT: 0.015 (0.113)	Loss 0.0109 (0.0088)	Prec@1 100.000 (99.932)	
Total train loss: 0.0088
Avg Loading time: 0.0929 seconds
Avg Batch time: 0.1130 seconds

Train time: 44.36851263046265
 * Prec@1 73.790 Prec@5 90.960 Loss 1.1729
Avg Loading time: 0.1090 seconds
Avg Batch time: 0.1168 seconds

Best acc: 73.970
--------------------------------------------------------------------------------
Test time: 9.755302667617798

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.093)	BT: 0.028 (0.114)	Loss 0.0038 (0.0100)	Prec@1 100.000 (99.920)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.633 (0.090)	BT: 0.664 (0.112)	Loss 0.0097 (0.0092)	Prec@1 100.000 (99.940)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.234 (0.091)	BT: 0.267 (0.112)	Loss 0.0107 (0.0088)	Prec@1 100.000 (99.953)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.089)	BT: 0.018 (0.110)	Loss 0.0075 (0.0088)	Prec@1 100.000 (99.947)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.094)	BT: 0.016 (0.115)	Loss 0.0072 (0.0089)	Prec@1 100.000 (99.954)	
Total train loss: 0.0089
Avg Loading time: 0.0935 seconds
Avg Batch time: 0.1148 seconds

Train time: 44.99017381668091
 * Prec@1 73.910 Prec@5 91.150 Loss 1.1699
Avg Loading time: 0.1138 seconds
Avg Batch time: 0.1227 seconds

Best acc: 73.970
--------------------------------------------------------------------------------
Test time: 10.262730836868286

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.274 (0.096)	BT: 0.294 (0.117)	Loss 0.0167 (0.0089)	Prec@1 99.219 (99.920)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.101)	BT: 0.029 (0.122)	Loss 0.0103 (0.0085)	Prec@1 100.000 (99.940)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.064 (0.094)	BT: 0.080 (0.114)	Loss 0.0103 (0.0084)	Prec@1 100.000 (99.947)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.095)	BT: 0.018 (0.116)	Loss 0.0034 (0.0084)	Prec@1 100.000 (99.955)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.094)	BT: 0.016 (0.115)	Loss 0.0049 (0.0086)	Prec@1 100.000 (99.958)	
Total train loss: 0.0086
Avg Loading time: 0.0935 seconds
Avg Batch time: 0.1144 seconds

Train time: 44.887720346450806
 * Prec@1 73.750 Prec@5 90.970 Loss 1.1709
Avg Loading time: 0.0821 seconds
Avg Batch time: 0.0918 seconds

Best acc: 73.970
--------------------------------------------------------------------------------
Test time: 7.822906255722046

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.098)	BT: 0.015 (0.117)	Loss 0.0111 (0.0075)	Prec@1 100.000 (99.990)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.088)	BT: 0.015 (0.107)	Loss 0.0069 (0.0085)	Prec@1 100.000 (99.965)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.092)	BT: 0.021 (0.111)	Loss 0.0030 (0.0085)	Prec@1 100.000 (99.963)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.089)	BT: 0.017 (0.110)	Loss 0.0107 (0.0085)	Prec@1 100.000 (99.960)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.092)	BT: 0.017 (0.112)	Loss 0.0083 (0.0086)	Prec@1 100.000 (99.950)	
Total train loss: 0.0086
Avg Loading time: 0.0913 seconds
Avg Batch time: 0.1119 seconds

Train time: 43.94246292114258
 * Prec@1 73.690 Prec@5 91.000 Loss 1.1631
Avg Loading time: 0.1461 seconds
Avg Batch time: 0.1545 seconds

Best acc: 73.970
--------------------------------------------------------------------------------
Test time: 12.77252745628357

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.094)	BT: 0.029 (0.115)	Loss 0.0079 (0.0086)	Prec@1 100.000 (99.960)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.084)	BT: 0.017 (0.104)	Loss 0.0112 (0.0086)	Prec@1 100.000 (99.955)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.081)	BT: 0.019 (0.102)	Loss 0.0050 (0.0084)	Prec@1 100.000 (99.953)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.081)	BT: 0.019 (0.103)	Loss 0.0035 (0.0087)	Prec@1 100.000 (99.945)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.080)	BT: 0.016 (0.101)	Loss 0.0062 (0.0087)	Prec@1 100.000 (99.948)	
Total train loss: 0.0087
Avg Loading time: 0.0796 seconds
Avg Batch time: 0.1012 seconds

Train time: 39.64808487892151
 * Prec@1 73.860 Prec@5 90.990 Loss 1.1699
Avg Loading time: 0.0681 seconds
Avg Batch time: 0.0790 seconds

Best acc: 73.970
--------------------------------------------------------------------------------
Test time: 6.797201871871948

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.051)	BT: 0.021 (0.072)	Loss 0.0066 (0.0100)	Prec@1 100.000 (99.910)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.040)	BT: 0.033 (0.064)	Loss 0.0106 (0.0093)	Prec@1 100.000 (99.930)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.032)	BT: 0.019 (0.057)	Loss 0.0078 (0.0088)	Prec@1 100.000 (99.943)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.035)	BT: 0.022 (0.060)	Loss 0.0058 (0.0087)	Prec@1 100.000 (99.950)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.050)	BT: 0.018 (0.074)	Loss 0.0029 (0.0087)	Prec@1 100.000 (99.946)	
Total train loss: 0.0087
Avg Loading time: 0.0494 seconds
Avg Batch time: 0.0734 seconds

Train time: 28.841220378875732
 * Prec@1 74.050 Prec@5 91.040 Loss 1.1680
Avg Loading time: 0.1223 seconds
Avg Batch time: 0.1309 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 11.266213178634644

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.086)	BT: 0.020 (0.104)	Loss 0.0072 (0.0086)	Prec@1 100.000 (99.950)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.114)	BT: 0.020 (0.133)	Loss 0.0077 (0.0089)	Prec@1 100.000 (99.930)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.682 (0.209)	BT: 0.707 (0.228)	Loss 0.0083 (0.0086)	Prec@1 100.000 (99.937)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.248)	BT: 0.018 (0.268)	Loss 0.0041 (0.0085)	Prec@1 100.000 (99.950)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.242)	BT: 0.017 (0.262)	Loss 0.0058 (0.0085)	Prec@1 100.000 (99.946)	
Total train loss: 0.0085
Avg Loading time: 0.2416 seconds
Avg Batch time: 0.2609 seconds

Train time: 102.11727929115295
 * Prec@1 73.710 Prec@5 91.160 Loss 1.1719
Avg Loading time: 0.1749 seconds
Avg Batch time: 0.1829 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 14.940065622329712

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.021 (0.269)	BT: 0.039 (0.290)	Loss 0.0033 (0.0096)	Prec@1 100.000 (99.930)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.340)	BT: 0.018 (0.361)	Loss 0.0244 (0.0093)	Prec@1 99.219 (99.925)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.955 (0.364)	BT: 0.980 (0.385)	Loss 0.0128 (0.0091)	Prec@1 100.000 (99.943)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.368)	BT: 0.017 (0.389)	Loss 0.0051 (0.0089)	Prec@1 100.000 (99.955)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.428)	BT: 0.017 (0.449)	Loss 0.0054 (0.0087)	Prec@1 100.000 (99.958)	
Total train loss: 0.0087
Avg Loading time: 0.4274 seconds
Avg Batch time: 0.4478 seconds

Train time: 175.1745743751526
 * Prec@1 73.620 Prec@5 91.000 Loss 1.1748
Avg Loading time: 0.7425 seconds
Avg Batch time: 0.7500 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 59.75274038314819

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.707)	BT: 0.021 (0.727)	Loss 0.0081 (0.0095)	Prec@1 100.000 (99.920)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.767 (0.730)	BT: 0.786 (0.751)	Loss 0.0067 (0.0088)	Prec@1 100.000 (99.945)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 1.124 (0.743)	BT: 1.149 (0.764)	Loss 0.0072 (0.0087)	Prec@1 100.000 (99.953)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.752)	BT: 0.017 (0.773)	Loss 0.0082 (0.0085)	Prec@1 100.000 (99.952)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.767)	BT: 0.017 (0.788)	Loss 0.0036 (0.0086)	Prec@1 100.000 (99.950)	
Total train loss: 0.0086
Avg Loading time: 0.7650 seconds
Avg Batch time: 0.7860 seconds

Train time: 307.47580313682556
 * Prec@1 73.700 Prec@5 91.170 Loss 1.1738
Avg Loading time: 0.5188 seconds
Avg Batch time: 0.5268 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 42.1853084564209

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.550 (0.124)	BT: 0.576 (0.145)	Loss 0.0109 (0.0088)	Prec@1 100.000 (99.960)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.125)	BT: 0.016 (0.145)	Loss 0.0085 (0.0086)	Prec@1 100.000 (99.960)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.120)	BT: 0.024 (0.140)	Loss 0.0037 (0.0088)	Prec@1 100.000 (99.960)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.116)	BT: 0.018 (0.136)	Loss 0.0211 (0.0087)	Prec@1 99.219 (99.960)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.262 (0.113)	BT: 0.286 (0.133)	Loss 0.0077 (0.0085)	Prec@1 100.000 (99.962)	
Total train loss: 0.0085
Avg Loading time: 0.1130 seconds
Avg Batch time: 0.1331 seconds

Train time: 52.187865018844604
 * Prec@1 73.960 Prec@5 90.940 Loss 1.1719
Avg Loading time: 0.1319 seconds
Avg Batch time: 0.1419 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 11.75825572013855

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.093)	BT: 0.024 (0.114)	Loss 0.0063 (0.0081)	Prec@1 100.000 (99.960)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.092)	BT: 0.024 (0.113)	Loss 0.0093 (0.0086)	Prec@1 100.000 (99.960)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.057 (0.094)	BT: 0.078 (0.115)	Loss 0.0066 (0.0085)	Prec@1 100.000 (99.967)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.100)	BT: 0.026 (0.120)	Loss 0.0053 (0.0084)	Prec@1 100.000 (99.967)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.101)	BT: 0.029 (0.122)	Loss 0.0073 (0.0085)	Prec@1 100.000 (99.964)	
Total train loss: 0.0085
Avg Loading time: 0.1012 seconds
Avg Batch time: 0.1213 seconds

Train time: 47.539154291152954
 * Prec@1 73.810 Prec@5 91.130 Loss 1.1689
Avg Loading time: 0.0938 seconds
Avg Batch time: 0.1030 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 8.6883225440979

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.107)	BT: 0.019 (0.126)	Loss 0.0078 (0.0084)	Prec@1 100.000 (99.950)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.097)	BT: 0.019 (0.118)	Loss 0.0086 (0.0085)	Prec@1 100.000 (99.950)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.095)	BT: 0.022 (0.116)	Loss 0.0120 (0.0085)	Prec@1 100.000 (99.960)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.094)	BT: 0.014 (0.114)	Loss 0.0028 (0.0087)	Prec@1 100.000 (99.952)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.100)	BT: 0.021 (0.120)	Loss 0.0067 (0.0086)	Prec@1 100.000 (99.954)	
Total train loss: 0.0086
Avg Loading time: 0.0995 seconds
Avg Batch time: 0.1196 seconds

Train time: 46.90415120124817
 * Prec@1 73.940 Prec@5 91.090 Loss 1.1748
Avg Loading time: 0.1166 seconds
Avg Batch time: 0.1251 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 10.404644966125488

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.108)	BT: 0.018 (0.130)	Loss 0.0091 (0.0080)	Prec@1 100.000 (99.990)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.105)	BT: 0.015 (0.125)	Loss 0.0160 (0.0084)	Prec@1 99.219 (99.955)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.102)	BT: 0.015 (0.122)	Loss 0.0115 (0.0081)	Prec@1 100.000 (99.963)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.103)	BT: 0.018 (0.123)	Loss 0.0112 (0.0081)	Prec@1 100.000 (99.965)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.102)	BT: 0.018 (0.122)	Loss 0.0073 (0.0082)	Prec@1 100.000 (99.964)	
Total train loss: 0.0082
Avg Loading time: 0.1017 seconds
Avg Batch time: 0.1214 seconds

Train time: 47.594058990478516
 * Prec@1 73.920 Prec@5 91.210 Loss 1.1660
Avg Loading time: 0.0928 seconds
Avg Batch time: 0.1016 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 8.587590456008911

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.108)	BT: 0.021 (0.128)	Loss 0.0048 (0.0088)	Prec@1 100.000 (99.950)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.107)	BT: 0.019 (0.127)	Loss 0.0033 (0.0086)	Prec@1 100.000 (99.945)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.485 (0.105)	BT: 0.505 (0.125)	Loss 0.0095 (0.0087)	Prec@1 100.000 (99.940)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.007 (0.102)	BT: 0.025 (0.122)	Loss 0.0051 (0.0085)	Prec@1 100.000 (99.945)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.099)	BT: 0.018 (0.119)	Loss 0.0139 (0.0086)	Prec@1 100.000 (99.940)	
Total train loss: 0.0086
Avg Loading time: 0.0989 seconds
Avg Batch time: 0.1185 seconds

Train time: 46.501275300979614
 * Prec@1 73.600 Prec@5 91.030 Loss 1.1729
Avg Loading time: 0.1226 seconds
Avg Batch time: 0.1306 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 10.875699758529663

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.103)	BT: 0.029 (0.123)	Loss 0.0052 (0.0082)	Prec@1 100.000 (99.950)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.102)	BT: 0.022 (0.123)	Loss 0.0045 (0.0082)	Prec@1 100.000 (99.955)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.822 (0.107)	BT: 0.851 (0.127)	Loss 0.0123 (0.0078)	Prec@1 100.000 (99.960)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.105)	BT: 0.014 (0.124)	Loss 0.0055 (0.0079)	Prec@1 100.000 (99.960)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.104)	BT: 0.014 (0.123)	Loss 0.0038 (0.0079)	Prec@1 100.000 (99.960)	
Total train loss: 0.0079
Avg Loading time: 0.1033 seconds
Avg Batch time: 0.1224 seconds

Train time: 47.9714469909668
 * Prec@1 73.930 Prec@5 91.130 Loss 1.1650
Avg Loading time: 0.0963 seconds
Avg Batch time: 0.1039 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 8.744860887527466

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.109)	BT: 0.018 (0.128)	Loss 0.0051 (0.0078)	Prec@1 100.000 (99.970)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.662 (0.105)	BT: 0.681 (0.125)	Loss 0.0029 (0.0085)	Prec@1 100.000 (99.960)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.100)	BT: 0.019 (0.120)	Loss 0.0219 (0.0084)	Prec@1 98.438 (99.953)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.104)	BT: 0.015 (0.123)	Loss 0.0065 (0.0084)	Prec@1 100.000 (99.957)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.103)	BT: 0.017 (0.122)	Loss 0.0079 (0.0084)	Prec@1 100.000 (99.954)	
Total train loss: 0.0084
Avg Loading time: 0.1025 seconds
Avg Batch time: 0.1221 seconds

Train time: 47.85490798950195
 * Prec@1 73.910 Prec@5 90.910 Loss 1.1719
Avg Loading time: 0.1144 seconds
Avg Batch time: 0.1219 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 10.195875883102417

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.125)	BT: 0.014 (0.145)	Loss 0.0127 (0.0092)	Prec@1 100.000 (99.950)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.113)	BT: 0.020 (0.132)	Loss 0.0038 (0.0087)	Prec@1 100.000 (99.955)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.112)	BT: 0.018 (0.132)	Loss 0.0042 (0.0087)	Prec@1 100.000 (99.947)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.117)	BT: 0.016 (0.136)	Loss 0.0072 (0.0086)	Prec@1 100.000 (99.950)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.115)	BT: 0.023 (0.134)	Loss 0.0061 (0.0086)	Prec@1 100.000 (99.946)	
Total train loss: 0.0086
Avg Loading time: 0.1144 seconds
Avg Batch time: 0.1342 seconds

Train time: 52.64052963256836
 * Prec@1 73.800 Prec@5 91.070 Loss 1.1797
Avg Loading time: 0.1379 seconds
Avg Batch time: 0.1464 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 12.07970643043518

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.089)	BT: 0.018 (0.109)	Loss 0.0158 (0.0086)	Prec@1 99.219 (99.950)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.084)	BT: 0.015 (0.103)	Loss 0.0325 (0.0088)	Prec@1 98.438 (99.940)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.089)	BT: 0.027 (0.108)	Loss 0.0072 (0.0085)	Prec@1 100.000 (99.953)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.089)	BT: 0.015 (0.109)	Loss 0.0150 (0.0088)	Prec@1 100.000 (99.942)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.094)	BT: 0.019 (0.114)	Loss 0.0064 (0.0086)	Prec@1 100.000 (99.944)	
Total train loss: 0.0086
Avg Loading time: 0.0938 seconds
Avg Batch time: 0.1138 seconds

Train time: 44.58360958099365
 * Prec@1 73.750 Prec@5 91.030 Loss 1.1699
Avg Loading time: 0.0842 seconds
Avg Batch time: 0.0919 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 7.819106817245483

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.102)	BT: 0.015 (0.122)	Loss 0.0115 (0.0082)	Prec@1 100.000 (99.970)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.088)	BT: 0.019 (0.109)	Loss 0.0059 (0.0083)	Prec@1 100.000 (99.955)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.243 (0.090)	BT: 0.265 (0.110)	Loss 0.0080 (0.0088)	Prec@1 100.000 (99.957)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.091)	BT: 0.021 (0.111)	Loss 0.0065 (0.0086)	Prec@1 100.000 (99.962)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.094)	BT: 0.020 (0.115)	Loss 0.0118 (0.0085)	Prec@1 100.000 (99.960)	
Total train loss: 0.0086
Avg Loading time: 0.0942 seconds
Avg Batch time: 0.1143 seconds

Train time: 44.86777949333191
 * Prec@1 73.950 Prec@5 90.910 Loss 1.1719
Avg Loading time: 0.1217 seconds
Avg Batch time: 0.1308 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 10.885239601135254

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.100)	BT: 0.030 (0.121)	Loss 0.0062 (0.0081)	Prec@1 100.000 (99.960)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.106)	BT: 0.033 (0.126)	Loss 0.0056 (0.0080)	Prec@1 100.000 (99.950)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.103)	BT: 0.018 (0.123)	Loss 0.0083 (0.0084)	Prec@1 100.000 (99.943)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.104)	BT: 0.027 (0.124)	Loss 0.0064 (0.0084)	Prec@1 100.000 (99.940)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.102)	BT: 0.022 (0.123)	Loss 0.0074 (0.0084)	Prec@1 100.000 (99.946)	
Total train loss: 0.0084
Avg Loading time: 0.1021 seconds
Avg Batch time: 0.1224 seconds

Train time: 48.00747632980347
 * Prec@1 73.960 Prec@5 90.940 Loss 1.1738
Avg Loading time: 0.0881 seconds
Avg Batch time: 0.0976 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 8.26192593574524

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.101)	BT: 0.025 (0.123)	Loss 0.0051 (0.0090)	Prec@1 100.000 (99.950)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.100)	BT: 0.016 (0.121)	Loss 0.0045 (0.0086)	Prec@1 100.000 (99.950)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.146 (0.101)	BT: 0.165 (0.122)	Loss 0.0080 (0.0086)	Prec@1 100.000 (99.950)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.101)	BT: 0.017 (0.122)	Loss 0.0055 (0.0084)	Prec@1 100.000 (99.952)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.099)	BT: 0.014 (0.119)	Loss 0.0069 (0.0081)	Prec@1 100.000 (99.956)	
Total train loss: 0.0081
Avg Loading time: 0.0988 seconds
Avg Batch time: 0.1189 seconds

Train time: 46.599101305007935
 * Prec@1 73.770 Prec@5 91.070 Loss 1.1660
Avg Loading time: 0.1149 seconds
Avg Batch time: 0.1224 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 10.202472686767578

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.116)	BT: 0.026 (0.138)	Loss 0.0374 (0.0093)	Prec@1 99.219 (99.910)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.115)	BT: 0.020 (0.136)	Loss 0.0240 (0.0087)	Prec@1 100.000 (99.940)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.439 (0.124)	BT: 0.458 (0.144)	Loss 0.0061 (0.0086)	Prec@1 100.000 (99.943)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.119)	BT: 0.018 (0.140)	Loss 0.0072 (0.0085)	Prec@1 100.000 (99.947)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.120)	BT: 0.020 (0.141)	Loss 0.0051 (0.0084)	Prec@1 100.000 (99.952)	
Total train loss: 0.0084
Avg Loading time: 0.1192 seconds
Avg Batch time: 0.1402 seconds

Train time: 55.00480270385742
 * Prec@1 73.800 Prec@5 91.010 Loss 1.1689
Avg Loading time: 0.1462 seconds
Avg Batch time: 0.1544 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 12.727434635162354

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.128)	BT: 0.018 (0.147)	Loss 0.0070 (0.0088)	Prec@1 100.000 (99.940)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.156 (0.111)	BT: 0.174 (0.131)	Loss 0.0073 (0.0084)	Prec@1 100.000 (99.955)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.174 (0.108)	BT: 0.190 (0.128)	Loss 0.0066 (0.0083)	Prec@1 100.000 (99.967)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.107)	BT: 0.017 (0.127)	Loss 0.0094 (0.0082)	Prec@1 100.000 (99.965)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.109)	BT: 0.020 (0.129)	Loss 0.0045 (0.0082)	Prec@1 100.000 (99.970)	
Total train loss: 0.0082
Avg Loading time: 0.1083 seconds
Avg Batch time: 0.1286 seconds

Train time: 50.42628264427185
 * Prec@1 73.640 Prec@5 90.870 Loss 1.1699
Avg Loading time: 0.1344 seconds
Avg Batch time: 0.1437 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 11.917446374893188

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.090)	BT: 0.015 (0.109)	Loss 0.0090 (0.0086)	Prec@1 100.000 (99.920)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.130 (0.098)	BT: 0.149 (0.118)	Loss 0.0072 (0.0084)	Prec@1 100.000 (99.945)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.096)	BT: 0.022 (0.117)	Loss 0.0123 (0.0084)	Prec@1 100.000 (99.943)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.095)	BT: 0.016 (0.116)	Loss 0.0046 (0.0082)	Prec@1 100.000 (99.947)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.093)	BT: 0.018 (0.114)	Loss 0.0073 (0.0082)	Prec@1 100.000 (99.948)	
Total train loss: 0.0082
Avg Loading time: 0.0929 seconds
Avg Batch time: 0.1137 seconds

Train time: 44.58463644981384
 * Prec@1 73.950 Prec@5 91.110 Loss 1.1631
Avg Loading time: 0.0928 seconds
Avg Batch time: 0.1021 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 8.580763816833496

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.102)	BT: 0.016 (0.120)	Loss 0.0053 (0.0084)	Prec@1 100.000 (99.950)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.087)	BT: 0.023 (0.105)	Loss 0.0114 (0.0081)	Prec@1 100.000 (99.965)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.074)	BT: 0.017 (0.094)	Loss 0.0075 (0.0083)	Prec@1 100.000 (99.963)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.067)	BT: 0.051 (0.088)	Loss 0.0049 (0.0082)	Prec@1 100.000 (99.965)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.064)	BT: 0.016 (0.086)	Loss 0.0100 (0.0083)	Prec@1 100.000 (99.964)	
Total train loss: 0.0083
Avg Loading time: 0.0636 seconds
Avg Batch time: 0.0861 seconds

Train time: 33.761228799819946
 * Prec@1 73.800 Prec@5 91.140 Loss 1.1699
Avg Loading time: 0.0582 seconds
Avg Batch time: 0.0686 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 5.978273868560791

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.036)	BT: 0.027 (0.065)	Loss 0.0075 (0.0077)	Prec@1 100.000 (99.980)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.043)	BT: 0.019 (0.068)	Loss 0.0127 (0.0081)	Prec@1 100.000 (99.965)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.649 (0.056)	BT: 0.676 (0.080)	Loss 0.0060 (0.0084)	Prec@1 100.000 (99.960)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.062)	BT: 0.017 (0.085)	Loss 0.0216 (0.0084)	Prec@1 100.000 (99.960)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.062)	BT: 0.015 (0.085)	Loss 0.0152 (0.0085)	Prec@1 100.000 (99.956)	
Total train loss: 0.0086
Avg Loading time: 0.0618 seconds
Avg Batch time: 0.0851 seconds

Train time: 33.44337058067322
 * Prec@1 73.640 Prec@5 91.050 Loss 1.1748
Avg Loading time: 0.0900 seconds
Avg Batch time: 0.0978 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 8.26180386543274

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.071)	BT: 0.018 (0.094)	Loss 0.0041 (0.0078)	Prec@1 100.000 (99.960)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.069)	BT: 0.018 (0.092)	Loss 0.0050 (0.0080)	Prec@1 100.000 (99.970)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.068)	BT: 0.023 (0.090)	Loss 0.0064 (0.0079)	Prec@1 100.000 (99.977)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.073)	BT: 0.018 (0.095)	Loss 0.0170 (0.0080)	Prec@1 99.219 (99.970)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.191 (0.079)	BT: 0.213 (0.100)	Loss 0.0092 (0.0081)	Prec@1 100.000 (99.968)	
Total train loss: 0.0081
Avg Loading time: 0.0784 seconds
Avg Batch time: 0.0999 seconds

Train time: 39.20835018157959
 * Prec@1 73.750 Prec@5 91.100 Loss 1.1738
Avg Loading time: 0.0892 seconds
Avg Batch time: 0.0976 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 8.26961636543274

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.080)	BT: 0.022 (0.102)	Loss 0.0066 (0.0091)	Prec@1 100.000 (99.910)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.084)	BT: 0.018 (0.106)	Loss 0.0079 (0.0081)	Prec@1 100.000 (99.945)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.251 (0.078)	BT: 0.281 (0.101)	Loss 0.0099 (0.0083)	Prec@1 100.000 (99.950)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.073)	BT: 0.030 (0.095)	Loss 0.0058 (0.0083)	Prec@1 100.000 (99.957)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.073)	BT: 0.019 (0.094)	Loss 0.0043 (0.0084)	Prec@1 100.000 (99.956)	
Total train loss: 0.0084
Avg Loading time: 0.0724 seconds
Avg Batch time: 0.0942 seconds

Train time: 36.911723375320435
 * Prec@1 73.800 Prec@5 91.150 Loss 1.1729
Avg Loading time: 0.0747 seconds
Avg Batch time: 0.0851 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 7.301758766174316

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.075)	BT: 0.025 (0.097)	Loss 0.0043 (0.0091)	Prec@1 100.000 (99.900)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.074)	BT: 0.034 (0.097)	Loss 0.0068 (0.0089)	Prec@1 100.000 (99.915)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.074)	BT: 0.018 (0.097)	Loss 0.0100 (0.0090)	Prec@1 100.000 (99.927)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.071)	BT: 0.019 (0.094)	Loss 0.0073 (0.0088)	Prec@1 100.000 (99.932)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.068)	BT: 0.017 (0.090)	Loss 0.0091 (0.0086)	Prec@1 100.000 (99.944)	
Total train loss: 0.0086
Avg Loading time: 0.0677 seconds
Avg Batch time: 0.0901 seconds

Train time: 35.364978075027466
 * Prec@1 73.730 Prec@5 91.120 Loss 1.1680
Avg Loading time: 0.0997 seconds
Avg Batch time: 0.1108 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 9.337403059005737

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.092)	BT: 0.021 (0.112)	Loss 0.0131 (0.0091)	Prec@1 99.219 (99.940)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.086)	BT: 0.020 (0.107)	Loss 0.0158 (0.0086)	Prec@1 99.219 (99.955)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.082)	BT: 0.022 (0.102)	Loss 0.0112 (0.0087)	Prec@1 100.000 (99.940)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.076)	BT: 0.021 (0.097)	Loss 0.0039 (0.0084)	Prec@1 100.000 (99.947)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.073)	BT: 0.015 (0.094)	Loss 0.0070 (0.0084)	Prec@1 100.000 (99.954)	
Total train loss: 0.0084
Avg Loading time: 0.0723 seconds
Avg Batch time: 0.0936 seconds

Train time: 36.75662398338318
 * Prec@1 73.980 Prec@5 90.990 Loss 1.1709
Avg Loading time: 0.0805 seconds
Avg Batch time: 0.0884 seconds

Best acc: 74.050
--------------------------------------------------------------------------------
Test time: 7.4879982471466064


      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 0
          frozen_layers: 15
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar100/resnet18
DEVICE: cuda
GPU Id(s) being used: 0
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/train/relu15
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/test/relu15
ResNet18(
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=100, bias=False)
  (bn19): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 0.970 Prec@5 5.120 Loss 4.5938
Avg Loading time: 0.7083 seconds
Avg Batch time: 0.7203 seconds

Pre-trained Prec@1 with 15 layers frozen: 0.9699999690055847 	 Loss: 4.59375

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.322 (1.221)	BT: 0.343 (1.233)	Loss 1.8359 (2.4690)	Prec@1 47.656 (39.994)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (1.204)	BT: 0.023 (1.217)	Loss 1.5381 (2.1113)	Prec@1 60.156 (46.710)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (1.254)	BT: 0.011 (1.266)	Loss 1.9014 (1.9427)	Prec@1 53.125 (49.836)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (1.228)	BT: 0.009 (1.240)	Loss 1.6123 (1.8354)	Prec@1 60.156 (51.888)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (1.249)	BT: 0.012 (1.261)	Loss 1.4414 (1.7617)	Prec@1 54.688 (53.365)	
Total train loss: 1.7611
Avg Loading time: 1.2461 seconds
Avg Batch time: 1.2582 seconds

Train time: 492.1178779602051
 * Prec@1 61.390 Prec@5 88.190 Loss 1.3740
Avg Loading time: 0.1446 seconds
Avg Batch time: 0.1494 seconds

Best acc: 61.390
--------------------------------------------------------------------------------
Test time: 12.354081153869629

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.155)	BT: 0.012 (0.166)	Loss 0.9600 (1.1582)	Prec@1 70.312 (66.847)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.148)	BT: 0.016 (0.159)	Loss 1.1143 (1.1721)	Prec@1 69.531 (66.456)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.078 (0.137)	BT: 0.087 (0.148)	Loss 1.3945 (1.1776)	Prec@1 62.500 (66.316)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.136)	BT: 0.018 (0.147)	Loss 1.2822 (1.1902)	Prec@1 62.500 (65.903)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.132)	BT: 0.012 (0.144)	Loss 1.1992 (1.1942)	Prec@1 67.188 (65.869)	
Total train loss: 1.1943
Avg Loading time: 0.1316 seconds
Avg Batch time: 0.1433 seconds

Train time: 56.16134452819824
 * Prec@1 64.580 Prec@5 89.740 Loss 1.2598
Avg Loading time: 0.1266 seconds
Avg Batch time: 0.1315 seconds

Best acc: 64.580
--------------------------------------------------------------------------------
Test time: 10.940233945846558

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.123)	BT: 0.009 (0.136)	Loss 0.8696 (0.8997)	Prec@1 75.000 (73.668)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.208 (0.136)	BT: 0.220 (0.149)	Loss 0.8203 (0.9185)	Prec@1 77.344 (73.112)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.181 (0.129)	BT: 0.191 (0.142)	Loss 0.7939 (0.9349)	Prec@1 77.344 (72.523)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.126)	BT: 0.009 (0.138)	Loss 1.0234 (0.9496)	Prec@1 65.625 (72.165)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.127)	BT: 0.009 (0.139)	Loss 1.0771 (0.9631)	Prec@1 67.188 (71.679)	
Total train loss: 0.9639
Avg Loading time: 0.1266 seconds
Avg Batch time: 0.1384 seconds

Train time: 54.22126269340515
 * Prec@1 64.490 Prec@5 89.520 Loss 1.2852
Avg Loading time: 0.1114 seconds
Avg Batch time: 0.1165 seconds

Best acc: 64.580
--------------------------------------------------------------------------------
Test time: 9.524227619171143

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.121)	BT: 0.012 (0.133)	Loss 0.9326 (0.7351)	Prec@1 74.219 (77.975)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.114)	BT: 0.017 (0.126)	Loss 0.8423 (0.7400)	Prec@1 73.438 (77.885)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.116)	BT: 0.015 (0.128)	Loss 0.6885 (0.7585)	Prec@1 78.906 (77.370)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.116)	BT: 0.010 (0.128)	Loss 0.8013 (0.7813)	Prec@1 76.562 (76.738)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.124)	BT: 0.015 (0.136)	Loss 0.7368 (0.7952)	Prec@1 79.688 (76.292)	
Total train loss: 0.7956
Avg Loading time: 0.1242 seconds
Avg Batch time: 0.1360 seconds

Train time: 53.32281446456909
 * Prec@1 65.130 Prec@5 89.890 Loss 1.2783
Avg Loading time: 0.1363 seconds
Avg Batch time: 0.1431 seconds

Best acc: 65.130
--------------------------------------------------------------------------------
Test time: 11.868582248687744

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.098)	BT: 0.010 (0.110)	Loss 0.4421 (0.5423)	Prec@1 85.938 (83.974)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.020 (0.102)	BT: 0.031 (0.114)	Loss 0.5742 (0.5651)	Prec@1 81.250 (83.198)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.216 (0.125)	BT: 0.240 (0.137)	Loss 0.6021 (0.5949)	Prec@1 84.375 (82.125)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.123)	BT: 0.009 (0.135)	Loss 0.7910 (0.6227)	Prec@1 75.781 (81.142)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.121)	BT: 0.017 (0.133)	Loss 0.7148 (0.6439)	Prec@1 78.906 (80.439)	
Total train loss: 0.6442
Avg Loading time: 0.1206 seconds
Avg Batch time: 0.1324 seconds

Train time: 51.91064429283142
 * Prec@1 65.790 Prec@5 89.710 Loss 1.2930
Avg Loading time: 0.1656 seconds
Avg Batch time: 0.1722 seconds

Best acc: 65.790
--------------------------------------------------------------------------------
Test time: 14.205329656600952

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.101)	BT: 0.015 (0.112)	Loss 0.3418 (0.4453)	Prec@1 89.844 (86.448)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.394 (0.098)	BT: 0.409 (0.109)	Loss 0.4653 (0.4473)	Prec@1 85.938 (86.243)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.303 (0.095)	BT: 0.313 (0.106)	Loss 0.5874 (0.4745)	Prec@1 86.719 (85.363)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.103)	BT: 0.009 (0.114)	Loss 0.5923 (0.4930)	Prec@1 82.031 (84.801)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.104)	BT: 0.009 (0.115)	Loss 0.5093 (0.5130)	Prec@1 85.938 (84.171)	
Total train loss: 0.5132
Avg Loading time: 0.1037 seconds
Avg Batch time: 0.1152 seconds

Train time: 45.192941427230835
 * Prec@1 64.670 Prec@5 88.540 Loss 1.3691
Avg Loading time: 0.1267 seconds
Avg Batch time: 0.1322 seconds

Best acc: 65.790
--------------------------------------------------------------------------------
Test time: 10.886502504348755

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.120)	BT: 0.021 (0.133)	Loss 0.2437 (0.3499)	Prec@1 92.969 (89.643)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.112)	BT: 0.013 (0.124)	Loss 0.3831 (0.3606)	Prec@1 87.500 (89.123)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.121 (0.110)	BT: 0.132 (0.122)	Loss 0.2810 (0.3741)	Prec@1 93.750 (88.522)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.106)	BT: 0.009 (0.118)	Loss 0.4775 (0.3903)	Prec@1 86.719 (87.968)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.105)	BT: 0.009 (0.117)	Loss 0.3789 (0.4048)	Prec@1 88.281 (87.504)	
Total train loss: 0.4052
Avg Loading time: 0.1052 seconds
Avg Batch time: 0.1166 seconds

Train time: 45.69974637031555
 * Prec@1 65.190 Prec@5 88.380 Loss 1.4209
Avg Loading time: 0.1123 seconds
Avg Batch time: 0.1175 seconds

Best acc: 65.790
--------------------------------------------------------------------------------
Test time: 9.631073713302612

Epoch: [7][77/391]	LR: 0.1	DT: 0.090 (0.120)	BT: 0.099 (0.131)	Loss 0.3484 (0.2687)	Prec@1 87.500 (91.907)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.113)	BT: 0.013 (0.124)	Loss 0.3289 (0.2785)	Prec@1 89.062 (91.672)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.008 (0.109)	BT: 0.021 (0.121)	Loss 0.3838 (0.2916)	Prec@1 86.719 (91.173)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.108)	BT: 0.009 (0.120)	Loss 0.3645 (0.3074)	Prec@1 87.500 (90.587)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.115)	BT: 0.009 (0.126)	Loss 0.4160 (0.3203)	Prec@1 83.594 (90.112)	
Total train loss: 0.3204
Avg Loading time: 0.1143 seconds
Avg Batch time: 0.1257 seconds

Train time: 49.24104189872742
 * Prec@1 64.420 Prec@5 87.660 Loss 1.4932
Avg Loading time: 0.0893 seconds
Avg Batch time: 0.0952 seconds

Best acc: 65.790
--------------------------------------------------------------------------------
Test time: 7.929550647735596

Epoch: [8][77/391]	LR: 0.1	DT: 0.070 (0.125)	BT: 0.079 (0.137)	Loss 0.2356 (0.2442)	Prec@1 90.625 (92.658)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.125)	BT: 0.015 (0.137)	Loss 0.1929 (0.2401)	Prec@1 92.969 (92.909)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.121)	BT: 0.009 (0.133)	Loss 0.3025 (0.2459)	Prec@1 91.406 (92.588)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.117)	BT: 0.009 (0.129)	Loss 0.2998 (0.2546)	Prec@1 90.625 (92.270)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.291 (0.114)	BT: 0.308 (0.126)	Loss 0.3186 (0.2652)	Prec@1 89.062 (91.927)	
Total train loss: 0.2653
Avg Loading time: 0.1134 seconds
Avg Batch time: 0.1256 seconds

Train time: 49.27044463157654
 * Prec@1 65.370 Prec@5 88.840 Loss 1.5596
Avg Loading time: 0.1282 seconds
Avg Batch time: 0.1331 seconds

Best acc: 65.790
--------------------------------------------------------------------------------
Test time: 10.858325719833374

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.109)	BT: 0.009 (0.120)	Loss 0.2407 (0.1989)	Prec@1 92.969 (94.181)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.107)	BT: 0.009 (0.118)	Loss 0.1927 (0.1936)	Prec@1 93.750 (94.356)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.728 (0.106)	BT: 0.740 (0.118)	Loss 0.1669 (0.1924)	Prec@1 94.531 (94.391)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.108)	BT: 0.009 (0.120)	Loss 0.2764 (0.2070)	Prec@1 89.844 (93.833)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.110)	BT: 0.014 (0.122)	Loss 0.1511 (0.2190)	Prec@1 95.312 (93.415)	
Total train loss: 0.2191
Avg Loading time: 0.1099 seconds
Avg Batch time: 0.1219 seconds

Train time: 47.82981634140015
 * Prec@1 65.870 Prec@5 87.850 Loss 1.5439
Avg Loading time: 0.0894 seconds
Avg Batch time: 0.0957 seconds

Best acc: 65.870
--------------------------------------------------------------------------------
Test time: 8.112490177154541

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.107)	BT: 0.009 (0.118)	Loss 0.0891 (0.1325)	Prec@1 99.219 (96.625)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.107)	BT: 0.009 (0.118)	Loss 0.0979 (0.1147)	Prec@1 96.875 (97.080)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.107)	BT: 0.012 (0.118)	Loss 0.0786 (0.1042)	Prec@1 98.438 (97.433)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.108)	BT: 0.009 (0.119)	Loss 0.0618 (0.0983)	Prec@1 97.656 (97.601)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.109)	BT: 0.010 (0.120)	Loss 0.1061 (0.0928)	Prec@1 97.656 (97.780)	
Total train loss: 0.0929
Avg Loading time: 0.1089 seconds
Avg Batch time: 0.1200 seconds

Train time: 47.02916216850281
 * Prec@1 69.950 Prec@5 90.730 Loss 1.2744
Avg Loading time: 0.1114 seconds
Avg Batch time: 0.1173 seconds

Best acc: 69.950
--------------------------------------------------------------------------------
Test time: 9.853973150253296

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.110)	BT: 0.010 (0.122)	Loss 0.0251 (0.0455)	Prec@1 100.000 (99.379)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.103)	BT: 0.012 (0.114)	Loss 0.0334 (0.0459)	Prec@1 100.000 (99.344)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.103)	BT: 0.015 (0.115)	Loss 0.0515 (0.0459)	Prec@1 100.000 (99.306)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.101)	BT: 0.009 (0.113)	Loss 0.0369 (0.0460)	Prec@1 100.000 (99.299)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.102)	BT: 0.009 (0.114)	Loss 0.0528 (0.0462)	Prec@1 99.219 (99.293)	
Total train loss: 0.0463
Avg Loading time: 0.1022 seconds
Avg Batch time: 0.1137 seconds

Train time: 44.59061527252197
 * Prec@1 70.410 Prec@5 90.320 Loss 1.2793
Avg Loading time: 0.0989 seconds
Avg Batch time: 0.1044 seconds

Best acc: 70.410
--------------------------------------------------------------------------------
Test time: 8.796138048171997

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.126)	BT: 0.009 (0.138)	Loss 0.0384 (0.0342)	Prec@1 98.438 (99.599)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.113)	BT: 0.013 (0.125)	Loss 0.0336 (0.0342)	Prec@1 100.000 (99.604)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.113)	BT: 0.009 (0.124)	Loss 0.0328 (0.0349)	Prec@1 100.000 (99.566)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.112)	BT: 0.011 (0.124)	Loss 0.0456 (0.0345)	Prec@1 99.219 (99.562)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.110)	BT: 0.012 (0.122)	Loss 0.0273 (0.0353)	Prec@1 100.000 (99.535)	
Total train loss: 0.0354
Avg Loading time: 0.1102 seconds
Avg Batch time: 0.1220 seconds

Train time: 47.83385682106018
 * Prec@1 70.550 Prec@5 90.140 Loss 1.2988
Avg Loading time: 0.1126 seconds
Avg Batch time: 0.1177 seconds

Best acc: 70.550
--------------------------------------------------------------------------------
Test time: 9.9046950340271

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.108)	BT: 0.009 (0.122)	Loss 0.0228 (0.0291)	Prec@1 100.000 (99.690)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.129 (0.118)	BT: 0.152 (0.130)	Loss 0.0539 (0.0293)	Prec@1 99.219 (99.684)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.117)	BT: 0.009 (0.129)	Loss 0.0225 (0.0292)	Prec@1 100.000 (99.696)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.118)	BT: 0.010 (0.131)	Loss 0.0299 (0.0292)	Prec@1 100.000 (99.710)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.117)	BT: 0.011 (0.129)	Loss 0.0265 (0.0290)	Prec@1 100.000 (99.720)	
Total train loss: 0.0290
Avg Loading time: 0.1166 seconds
Avg Batch time: 0.1289 seconds

Train time: 50.494937896728516
 * Prec@1 70.520 Prec@5 90.090 Loss 1.2998
Avg Loading time: 0.1106 seconds
Avg Batch time: 0.1161 seconds

Best acc: 70.550
--------------------------------------------------------------------------------
Test time: 9.515268087387085

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.162)	BT: 0.010 (0.173)	Loss 0.0156 (0.0253)	Prec@1 100.000 (99.830)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.134)	BT: 0.009 (0.146)	Loss 0.0269 (0.0249)	Prec@1 99.219 (99.810)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.128)	BT: 0.015 (0.139)	Loss 0.0165 (0.0249)	Prec@1 100.000 (99.810)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.125)	BT: 0.009 (0.137)	Loss 0.0387 (0.0251)	Prec@1 99.219 (99.797)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.130)	BT: 0.009 (0.142)	Loss 0.0214 (0.0252)	Prec@1 100.000 (99.796)	
Total train loss: 0.0252
Avg Loading time: 0.1299 seconds
Avg Batch time: 0.1412 seconds

Train time: 55.30925750732422
 * Prec@1 70.840 Prec@5 90.110 Loss 1.3096
Avg Loading time: 0.1346 seconds
Avg Batch time: 0.1395 seconds

Best acc: 70.840
--------------------------------------------------------------------------------
Test time: 11.572958946228027

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.086)	BT: 0.014 (0.098)	Loss 0.0243 (0.0221)	Prec@1 100.000 (99.840)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.101)	BT: 0.009 (0.112)	Loss 0.0176 (0.0224)	Prec@1 100.000 (99.830)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.188)	BT: 0.010 (0.199)	Loss 0.0182 (0.0225)	Prec@1 100.000 (99.830)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.169)	BT: 0.010 (0.180)	Loss 0.0353 (0.0227)	Prec@1 98.438 (99.820)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.153)	BT: 0.015 (0.164)	Loss 0.0116 (0.0228)	Prec@1 100.000 (99.830)	
Total train loss: 0.0228
Avg Loading time: 0.1522 seconds
Avg Batch time: 0.1635 seconds

Train time: 64.04529285430908
 * Prec@1 71.000 Prec@5 90.140 Loss 1.3135
Avg Loading time: 0.1596 seconds
Avg Batch time: 0.1656 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 13.679149866104126

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.075)	BT: 0.010 (0.086)	Loss 0.0127 (0.0205)	Prec@1 100.000 (99.860)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.075)	BT: 0.009 (0.086)	Loss 0.0134 (0.0209)	Prec@1 100.000 (99.820)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.074)	BT: 0.012 (0.085)	Loss 0.0232 (0.0205)	Prec@1 100.000 (99.806)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.066)	BT: 0.037 (0.077)	Loss 0.0197 (0.0205)	Prec@1 100.000 (99.810)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.060)	BT: 0.009 (0.072)	Loss 0.0300 (0.0209)	Prec@1 99.219 (99.808)	
Total train loss: 0.0209
Avg Loading time: 0.0595 seconds
Avg Batch time: 0.0717 seconds

Train time: 28.205168962478638
 * Prec@1 70.530 Prec@5 90.040 Loss 1.3096
Avg Loading time: 0.0676 seconds
Avg Batch time: 0.0734 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 6.171838283538818

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.082)	BT: 0.009 (0.094)	Loss 0.0125 (0.0180)	Prec@1 100.000 (99.880)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.077)	BT: 0.012 (0.089)	Loss 0.0140 (0.0186)	Prec@1 100.000 (99.850)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.047 (0.068)	BT: 0.061 (0.081)	Loss 0.0255 (0.0186)	Prec@1 100.000 (99.863)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.063)	BT: 0.010 (0.075)	Loss 0.0162 (0.0192)	Prec@1 100.000 (99.862)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.062)	BT: 0.009 (0.075)	Loss 0.0320 (0.0194)	Prec@1 100.000 (99.866)	
Total train loss: 0.0195
Avg Loading time: 0.0623 seconds
Avg Batch time: 0.0747 seconds

Train time: 29.27703070640564
 * Prec@1 70.500 Prec@5 90.030 Loss 1.3291
Avg Loading time: 0.0837 seconds
Avg Batch time: 0.0899 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 7.43873405456543

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.062)	BT: 0.012 (0.076)	Loss 0.0291 (0.0183)	Prec@1 99.219 (99.890)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.058)	BT: 0.017 (0.071)	Loss 0.0385 (0.0182)	Prec@1 99.219 (99.865)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.324 (0.057)	BT: 0.333 (0.071)	Loss 0.0161 (0.0186)	Prec@1 100.000 (99.863)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.059)	BT: 0.012 (0.072)	Loss 0.0109 (0.0183)	Prec@1 100.000 (99.872)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.058)	BT: 0.013 (0.071)	Loss 0.0133 (0.0186)	Prec@1 100.000 (99.866)	
Total train loss: 0.0186
Avg Loading time: 0.0582 seconds
Avg Batch time: 0.0712 seconds

Train time: 27.91757822036743
 * Prec@1 70.430 Prec@5 89.950 Loss 1.3252
Avg Loading time: 0.0456 seconds
Avg Batch time: 0.0506 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 4.366087436676025

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.068)	BT: 0.009 (0.081)	Loss 0.0126 (0.0175)	Prec@1 100.000 (99.910)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.063)	BT: 0.027 (0.076)	Loss 0.0248 (0.0176)	Prec@1 99.219 (99.910)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.064)	BT: 0.014 (0.077)	Loss 0.0112 (0.0181)	Prec@1 100.000 (99.883)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.001 (0.065)	BT: 0.017 (0.078)	Loss 0.0174 (0.0176)	Prec@1 100.000 (99.882)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.063)	BT: 0.009 (0.076)	Loss 0.0257 (0.0175)	Prec@1 100.000 (99.884)	
Total train loss: 0.0175
Avg Loading time: 0.0625 seconds
Avg Batch time: 0.0756 seconds

Train time: 29.735332250595093
 * Prec@1 70.650 Prec@5 89.920 Loss 1.3271
Avg Loading time: 0.0755 seconds
Avg Batch time: 0.0811 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 6.7877466678619385

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.053)	BT: 0.009 (0.065)	Loss 0.0140 (0.0147)	Prec@1 100.000 (99.930)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.059)	BT: 0.011 (0.071)	Loss 0.0192 (0.0152)	Prec@1 100.000 (99.935)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.536 (0.066)	BT: 0.547 (0.078)	Loss 0.0099 (0.0153)	Prec@1 100.000 (99.920)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.065)	BT: 0.029 (0.078)	Loss 0.0122 (0.0157)	Prec@1 100.000 (99.897)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.063)	BT: 0.014 (0.076)	Loss 0.0128 (0.0155)	Prec@1 100.000 (99.906)	
Total train loss: 0.0155
Avg Loading time: 0.0627 seconds
Avg Batch time: 0.0755 seconds

Train time: 29.685667753219604
 * Prec@1 70.520 Prec@5 89.780 Loss 1.3262
Avg Loading time: 0.0816 seconds
Avg Batch time: 0.0878 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 7.3350605964660645

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.056)	BT: 0.010 (0.068)	Loss 0.0115 (0.0150)	Prec@1 100.000 (99.960)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.137 (0.054)	BT: 0.147 (0.067)	Loss 0.0127 (0.0155)	Prec@1 100.000 (99.925)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.051)	BT: 0.018 (0.064)	Loss 0.0086 (0.0155)	Prec@1 100.000 (99.927)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.053)	BT: 0.027 (0.066)	Loss 0.0079 (0.0154)	Prec@1 100.000 (99.932)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.053)	BT: 0.010 (0.066)	Loss 0.0153 (0.0155)	Prec@1 100.000 (99.924)	
Total train loss: 0.0155
Avg Loading time: 0.0527 seconds
Avg Batch time: 0.0658 seconds

Train time: 25.896991729736328
 * Prec@1 70.590 Prec@5 89.710 Loss 1.3301
Avg Loading time: 0.0903 seconds
Avg Batch time: 0.0959 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 7.963377952575684

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.082)	BT: 0.016 (0.095)	Loss 0.0154 (0.0157)	Prec@1 100.000 (99.890)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.066)	BT: 0.009 (0.080)	Loss 0.0154 (0.0153)	Prec@1 100.000 (99.910)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.062)	BT: 0.011 (0.076)	Loss 0.0087 (0.0155)	Prec@1 100.000 (99.917)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.060)	BT: 0.013 (0.073)	Loss 0.0132 (0.0154)	Prec@1 100.000 (99.922)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.036 (0.058)	BT: 0.048 (0.071)	Loss 0.0304 (0.0155)	Prec@1 99.219 (99.918)	
Total train loss: 0.0155
Avg Loading time: 0.0574 seconds
Avg Batch time: 0.0708 seconds

Train time: 27.825684070587158
 * Prec@1 70.460 Prec@5 89.830 Loss 1.3281
Avg Loading time: 0.0596 seconds
Avg Batch time: 0.0666 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 5.6782753467559814

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.063)	BT: 0.026 (0.078)	Loss 0.0086 (0.0154)	Prec@1 100.000 (99.930)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.061)	BT: 0.009 (0.076)	Loss 0.0182 (0.0163)	Prec@1 100.000 (99.890)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.061)	BT: 0.016 (0.075)	Loss 0.0137 (0.0158)	Prec@1 100.000 (99.897)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.058)	BT: 0.009 (0.071)	Loss 0.0178 (0.0158)	Prec@1 100.000 (99.902)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.057)	BT: 0.009 (0.070)	Loss 0.0162 (0.0157)	Prec@1 100.000 (99.912)	
Total train loss: 0.0157
Avg Loading time: 0.0568 seconds
Avg Batch time: 0.0697 seconds

Train time: 27.370333909988403
 * Prec@1 70.590 Prec@5 89.810 Loss 1.3301
Avg Loading time: 0.0679 seconds
Avg Batch time: 0.0742 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 6.243862628936768

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.053)	BT: 0.013 (0.067)	Loss 0.0149 (0.0152)	Prec@1 100.000 (99.950)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.051)	BT: 0.013 (0.064)	Loss 0.0120 (0.0153)	Prec@1 100.000 (99.925)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.052)	BT: 0.013 (0.066)	Loss 0.0217 (0.0156)	Prec@1 100.000 (99.910)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.051)	BT: 0.010 (0.065)	Loss 0.0132 (0.0155)	Prec@1 100.000 (99.907)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.052)	BT: 0.009 (0.065)	Loss 0.0126 (0.0155)	Prec@1 100.000 (99.904)	
Total train loss: 0.0155
Avg Loading time: 0.0514 seconds
Avg Batch time: 0.0650 seconds

Train time: 25.56639814376831
 * Prec@1 70.470 Prec@5 89.900 Loss 1.3271
Avg Loading time: 0.0610 seconds
Avg Batch time: 0.0675 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 5.74558162689209

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.050)	BT: 0.012 (0.064)	Loss 0.0110 (0.0152)	Prec@1 100.000 (99.920)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.004 (0.039)	BT: 0.022 (0.054)	Loss 0.0278 (0.0158)	Prec@1 100.000 (99.900)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.038)	BT: 0.012 (0.053)	Loss 0.0137 (0.0154)	Prec@1 100.000 (99.917)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.041)	BT: 0.009 (0.056)	Loss 0.0109 (0.0156)	Prec@1 100.000 (99.915)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.044)	BT: 0.015 (0.059)	Loss 0.0267 (0.0155)	Prec@1 99.219 (99.910)	
Total train loss: 0.0155
Avg Loading time: 0.0440 seconds
Avg Batch time: 0.0584 seconds

Train time: 23.009904384613037
 * Prec@1 70.360 Prec@5 89.870 Loss 1.3301
Avg Loading time: 0.0958 seconds
Avg Batch time: 0.1024 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 8.500631332397461

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.061)	BT: 0.010 (0.072)	Loss 0.0267 (0.0155)	Prec@1 100.000 (99.960)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.053)	BT: 0.012 (0.065)	Loss 0.0129 (0.0155)	Prec@1 100.000 (99.935)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.055)	BT: 0.009 (0.067)	Loss 0.0140 (0.0154)	Prec@1 100.000 (99.933)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.058)	BT: 0.009 (0.070)	Loss 0.0180 (0.0153)	Prec@1 100.000 (99.930)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.059)	BT: 0.012 (0.072)	Loss 0.0164 (0.0152)	Prec@1 100.000 (99.924)	
Total train loss: 0.0152
Avg Loading time: 0.0591 seconds
Avg Batch time: 0.0716 seconds

Train time: 28.118751525878906
 * Prec@1 70.660 Prec@5 89.980 Loss 1.3291
Avg Loading time: 0.0742 seconds
Avg Batch time: 0.0799 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 6.686693429946899

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.083)	BT: 0.010 (0.096)	Loss 0.0176 (0.0156)	Prec@1 100.000 (99.980)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.076)	BT: 0.009 (0.089)	Loss 0.0154 (0.0151)	Prec@1 100.000 (99.970)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.071)	BT: 0.012 (0.084)	Loss 0.0123 (0.0153)	Prec@1 100.000 (99.953)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.070)	BT: 0.009 (0.083)	Loss 0.0144 (0.0153)	Prec@1 100.000 (99.947)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.071)	BT: 0.014 (0.084)	Loss 0.0099 (0.0150)	Prec@1 100.000 (99.950)	
Total train loss: 0.0151
Avg Loading time: 0.0710 seconds
Avg Batch time: 0.0837 seconds

Train time: 32.83682584762573
 * Prec@1 70.590 Prec@5 89.830 Loss 1.3311
Avg Loading time: 0.1230 seconds
Avg Batch time: 0.1295 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 10.60512900352478

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.301 (0.084)	BT: 0.312 (0.097)	Loss 0.0130 (0.0147)	Prec@1 100.000 (99.940)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.081)	BT: 0.009 (0.093)	Loss 0.0155 (0.0151)	Prec@1 99.219 (99.925)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.077)	BT: 0.010 (0.089)	Loss 0.0157 (0.0155)	Prec@1 100.000 (99.910)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.077)	BT: 0.009 (0.089)	Loss 0.0081 (0.0151)	Prec@1 100.000 (99.927)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.076)	BT: 0.014 (0.088)	Loss 0.0187 (0.0150)	Prec@1 100.000 (99.922)	
Total train loss: 0.0151
Avg Loading time: 0.0760 seconds
Avg Batch time: 0.0879 seconds

Train time: 34.4785680770874
 * Prec@1 70.460 Prec@5 89.880 Loss 1.3369
Avg Loading time: 0.0625 seconds
Avg Batch time: 0.0681 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 5.756551265716553

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.095)	BT: 0.024 (0.108)	Loss 0.0078 (0.0156)	Prec@1 100.000 (99.930)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.084)	BT: 0.019 (0.097)	Loss 0.0182 (0.0158)	Prec@1 100.000 (99.930)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.083)	BT: 0.028 (0.096)	Loss 0.0149 (0.0155)	Prec@1 100.000 (99.920)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.084)	BT: 0.014 (0.097)	Loss 0.0230 (0.0152)	Prec@1 100.000 (99.915)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.083)	BT: 0.019 (0.095)	Loss 0.0095 (0.0152)	Prec@1 100.000 (99.912)	
Total train loss: 0.0152
Avg Loading time: 0.0825 seconds
Avg Batch time: 0.0950 seconds

Train time: 37.261194705963135
 * Prec@1 70.580 Prec@5 89.800 Loss 1.3330
Avg Loading time: 0.0911 seconds
Avg Batch time: 0.0962 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 7.994822978973389

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.104)	BT: 0.009 (0.116)	Loss 0.0133 (0.0161)	Prec@1 100.000 (99.890)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.175 (0.103)	BT: 0.186 (0.114)	Loss 0.0127 (0.0154)	Prec@1 100.000 (99.905)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.357 (0.100)	BT: 0.366 (0.112)	Loss 0.0120 (0.0150)	Prec@1 100.000 (99.923)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.104)	BT: 0.009 (0.116)	Loss 0.0127 (0.0149)	Prec@1 100.000 (99.932)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.120)	BT: 0.011 (0.131)	Loss 0.0148 (0.0147)	Prec@1 100.000 (99.928)	
Total train loss: 0.0147
Avg Loading time: 0.1194 seconds
Avg Batch time: 0.1312 seconds

Train time: 51.399062156677246
 * Prec@1 70.680 Prec@5 89.800 Loss 1.3203
Avg Loading time: 0.0979 seconds
Avg Batch time: 0.1027 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 8.481402158737183

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.039 (0.092)	BT: 0.048 (0.104)	Loss 0.0190 (0.0153)	Prec@1 100.000 (99.960)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.099)	BT: 0.013 (0.111)	Loss 0.0145 (0.0148)	Prec@1 100.000 (99.950)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.001 (0.102)	BT: 0.011 (0.114)	Loss 0.0082 (0.0149)	Prec@1 100.000 (99.943)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.105)	BT: 0.010 (0.117)	Loss 0.0107 (0.0149)	Prec@1 100.000 (99.940)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.111)	BT: 0.011 (0.123)	Loss 0.0154 (0.0149)	Prec@1 100.000 (99.944)	
Total train loss: 0.0149
Avg Loading time: 0.1105 seconds
Avg Batch time: 0.1223 seconds

Train time: 47.9590744972229
 * Prec@1 70.680 Prec@5 89.790 Loss 1.3350
Avg Loading time: 0.1203 seconds
Avg Batch time: 0.1263 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 10.366972208023071

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.098)	BT: 0.011 (0.110)	Loss 0.0146 (0.0146)	Prec@1 100.000 (99.920)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.090)	BT: 0.010 (0.102)	Loss 0.0129 (0.0143)	Prec@1 100.000 (99.925)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.089)	BT: 0.009 (0.101)	Loss 0.0126 (0.0143)	Prec@1 100.000 (99.917)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.090)	BT: 0.009 (0.102)	Loss 0.0106 (0.0147)	Prec@1 100.000 (99.907)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.051 (0.092)	BT: 0.062 (0.105)	Loss 0.0119 (0.0147)	Prec@1 100.000 (99.920)	
Total train loss: 0.0147
Avg Loading time: 0.0922 seconds
Avg Batch time: 0.1045 seconds

Train time: 41.00412106513977
 * Prec@1 70.390 Prec@5 89.750 Loss 1.3369
Avg Loading time: 0.0804 seconds
Avg Batch time: 0.0860 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 7.178674221038818

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.112)	BT: 0.014 (0.125)	Loss 0.0125 (0.0153)	Prec@1 100.000 (99.900)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.452 (0.105)	BT: 0.462 (0.117)	Loss 0.0083 (0.0151)	Prec@1 100.000 (99.915)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.096)	BT: 0.011 (0.108)	Loss 0.0116 (0.0150)	Prec@1 100.000 (99.920)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.097)	BT: 0.010 (0.109)	Loss 0.0135 (0.0151)	Prec@1 100.000 (99.917)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.043 (0.097)	BT: 0.060 (0.109)	Loss 0.0342 (0.0149)	Prec@1 99.219 (99.916)	
Total train loss: 0.0149
Avg Loading time: 0.0971 seconds
Avg Batch time: 0.1089 seconds

Train time: 42.718600273132324
 * Prec@1 70.620 Prec@5 89.880 Loss 1.3252
Avg Loading time: 0.1221 seconds
Avg Batch time: 0.1276 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 10.477822542190552

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.098)	BT: 0.009 (0.111)	Loss 0.0216 (0.0144)	Prec@1 100.000 (99.920)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.097)	BT: 0.009 (0.110)	Loss 0.0139 (0.0142)	Prec@1 100.000 (99.955)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.099)	BT: 0.010 (0.111)	Loss 0.0070 (0.0149)	Prec@1 100.000 (99.920)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.001 (0.097)	BT: 0.010 (0.110)	Loss 0.0210 (0.0148)	Prec@1 100.000 (99.925)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.051 (0.096)	BT: 0.062 (0.108)	Loss 0.0187 (0.0146)	Prec@1 100.000 (99.932)	
Total train loss: 0.0147
Avg Loading time: 0.0962 seconds
Avg Batch time: 0.1080 seconds

Train time: 42.328805923461914
 * Prec@1 70.650 Prec@5 89.840 Loss 1.3262
Avg Loading time: 0.0702 seconds
Avg Batch time: 0.0744 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 6.196468830108643

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.074)	BT: 0.009 (0.085)	Loss 0.0223 (0.0147)	Prec@1 100.000 (99.970)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.255)	BT: 0.010 (0.266)	Loss 0.0206 (0.0149)	Prec@1 100.000 (99.960)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 2.071 (0.500)	BT: 2.087 (0.512)	Loss 0.0110 (0.0152)	Prec@1 100.000 (99.947)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.495)	BT: 0.009 (0.507)	Loss 0.0100 (0.0151)	Prec@1 100.000 (99.935)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.452)	BT: 0.009 (0.464)	Loss 0.0077 (0.0148)	Prec@1 100.000 (99.944)	
Total train loss: 0.0149
Avg Loading time: 0.4510 seconds
Avg Batch time: 0.4626 seconds

Train time: 180.97486209869385
 * Prec@1 70.820 Prec@5 89.850 Loss 1.3301
Avg Loading time: 0.8283 seconds
Avg Batch time: 0.8346 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 66.2715048789978

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.950)	BT: 0.009 (0.962)	Loss 0.0122 (0.0155)	Prec@1 100.000 (99.890)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (1.006)	BT: 0.011 (1.018)	Loss 0.0112 (0.0148)	Prec@1 100.000 (99.900)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (1.014)	BT: 0.011 (1.026)	Loss 0.0108 (0.0151)	Prec@1 100.000 (99.897)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.999)	BT: 0.009 (1.011)	Loss 0.0241 (0.0149)	Prec@1 100.000 (99.910)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (1.016)	BT: 0.009 (1.028)	Loss 0.0084 (0.0147)	Prec@1 100.000 (99.916)	
Total train loss: 0.0147
Avg Loading time: 1.0137 seconds
Avg Batch time: 1.0256 seconds

Train time: 401.10949087142944
 * Prec@1 70.600 Prec@5 89.870 Loss 1.3281
Avg Loading time: 1.2352 seconds
Avg Batch time: 1.2401 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 98.28678369522095

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (1.181)	BT: 0.011 (1.193)	Loss 0.0101 (0.0144)	Prec@1 100.000 (99.930)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (1.171)	BT: 0.011 (1.183)	Loss 0.0161 (0.0143)	Prec@1 100.000 (99.930)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.312 (1.171)	BT: 0.327 (1.183)	Loss 0.0209 (0.0143)	Prec@1 100.000 (99.930)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (1.116)	BT: 0.010 (1.128)	Loss 0.0146 (0.0147)	Prec@1 100.000 (99.907)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.923)	BT: 0.010 (0.935)	Loss 0.0290 (0.0147)	Prec@1 99.219 (99.908)	
Total train loss: 0.0147
Avg Loading time: 0.9202 seconds
Avg Batch time: 0.9324 seconds

Train time: 364.6719708442688
 * Prec@1 70.560 Prec@5 89.900 Loss 1.3271
Avg Loading time: 0.1259 seconds
Avg Batch time: 0.1305 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 10.656352281570435

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.128)	BT: 0.014 (0.140)	Loss 0.0240 (0.0150)	Prec@1 100.000 (99.930)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.512 (0.117)	BT: 0.523 (0.128)	Loss 0.0138 (0.0146)	Prec@1 100.000 (99.940)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.109)	BT: 0.009 (0.121)	Loss 0.0078 (0.0146)	Prec@1 100.000 (99.937)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.108)	BT: 0.009 (0.119)	Loss 0.0105 (0.0144)	Prec@1 100.000 (99.937)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.042 (0.108)	BT: 0.054 (0.120)	Loss 0.0198 (0.0146)	Prec@1 100.000 (99.934)	
Total train loss: 0.0146
Avg Loading time: 0.1082 seconds
Avg Batch time: 0.1198 seconds

Train time: 46.95384383201599
 * Prec@1 70.670 Prec@5 89.850 Loss 1.3301
Avg Loading time: 0.1053 seconds
Avg Batch time: 0.1100 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 9.062802076339722

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.146 (0.103)	BT: 0.165 (0.114)	Loss 0.0068 (0.0149)	Prec@1 100.000 (99.940)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.088)	BT: 0.009 (0.098)	Loss 0.0157 (0.0150)	Prec@1 100.000 (99.900)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.088 (0.089)	BT: 0.106 (0.100)	Loss 0.0105 (0.0146)	Prec@1 100.000 (99.920)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.092)	BT: 0.010 (0.104)	Loss 0.0092 (0.0147)	Prec@1 100.000 (99.922)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.091)	BT: 0.010 (0.103)	Loss 0.0197 (0.0149)	Prec@1 100.000 (99.920)	
Total train loss: 0.0149
Avg Loading time: 0.0912 seconds
Avg Batch time: 0.1029 seconds

Train time: 40.332014083862305
 * Prec@1 70.510 Prec@5 89.730 Loss 1.3252
Avg Loading time: 0.1019 seconds
Avg Batch time: 0.1079 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 8.854528427124023

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.087)	BT: 0.013 (0.098)	Loss 0.0151 (0.0147)	Prec@1 100.000 (99.910)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.085)	BT: 0.009 (0.096)	Loss 0.0151 (0.0147)	Prec@1 100.000 (99.900)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.251 (0.084)	BT: 0.268 (0.095)	Loss 0.0191 (0.0148)	Prec@1 100.000 (99.917)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.076)	BT: 0.011 (0.088)	Loss 0.0241 (0.0150)	Prec@1 100.000 (99.910)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.070)	BT: 0.014 (0.082)	Loss 0.0099 (0.0152)	Prec@1 100.000 (99.912)	
Total train loss: 0.0152
Avg Loading time: 0.0698 seconds
Avg Batch time: 0.0815 seconds

Train time: 32.02109360694885
 * Prec@1 70.430 Prec@5 89.880 Loss 1.3301
Avg Loading time: 0.0560 seconds
Avg Batch time: 0.0618 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 5.285666465759277

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.062)	BT: 0.009 (0.075)	Loss 0.0210 (0.0147)	Prec@1 100.000 (99.930)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.054)	BT: 0.015 (0.066)	Loss 0.0158 (0.0143)	Prec@1 100.000 (99.935)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.053)	BT: 0.019 (0.066)	Loss 0.0121 (0.0143)	Prec@1 100.000 (99.937)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.051)	BT: 0.012 (0.063)	Loss 0.0117 (0.0142)	Prec@1 100.000 (99.937)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.050)	BT: 0.014 (0.063)	Loss 0.0115 (0.0140)	Prec@1 100.000 (99.942)	
Total train loss: 0.0140
Avg Loading time: 0.0502 seconds
Avg Batch time: 0.0629 seconds

Train time: 24.692750930786133
 * Prec@1 70.540 Prec@5 89.820 Loss 1.3223
Avg Loading time: 0.0466 seconds
Avg Batch time: 0.0518 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 4.439630746841431

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.002 (0.047)	BT: 0.012 (0.059)	Loss 0.0199 (0.0148)	Prec@1 100.000 (99.910)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.047)	BT: 0.011 (0.060)	Loss 0.0184 (0.0157)	Prec@1 100.000 (99.905)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.483 (0.046)	BT: 0.493 (0.059)	Loss 0.0132 (0.0150)	Prec@1 100.000 (99.917)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.046)	BT: 0.010 (0.059)	Loss 0.0175 (0.0153)	Prec@1 100.000 (99.907)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.046)	BT: 0.009 (0.059)	Loss 0.0295 (0.0152)	Prec@1 99.219 (99.916)	
Total train loss: 0.0152
Avg Loading time: 0.0463 seconds
Avg Batch time: 0.0594 seconds

Train time: 23.38616418838501
 * Prec@1 70.670 Prec@5 89.890 Loss 1.3291
Avg Loading time: 0.0735 seconds
Avg Batch time: 0.0796 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 6.628374814987183

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.057)	BT: 0.013 (0.070)	Loss 0.0097 (0.0138)	Prec@1 100.000 (99.950)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.016 (0.047)	BT: 0.032 (0.060)	Loss 0.0095 (0.0141)	Prec@1 100.000 (99.930)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.215 (0.050)	BT: 0.228 (0.062)	Loss 0.0097 (0.0144)	Prec@1 100.000 (99.913)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.047)	BT: 0.019 (0.060)	Loss 0.0106 (0.0145)	Prec@1 100.000 (99.920)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.048)	BT: 0.016 (0.060)	Loss 0.0184 (0.0144)	Prec@1 100.000 (99.926)	
Total train loss: 0.0145
Avg Loading time: 0.0480 seconds
Avg Batch time: 0.0603 seconds

Train time: 23.722053289413452
 * Prec@1 70.610 Prec@5 89.920 Loss 1.3242
Avg Loading time: 0.0513 seconds
Avg Batch time: 0.0573 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 4.859828948974609

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.051)	BT: 0.010 (0.065)	Loss 0.0086 (0.0139)	Prec@1 100.000 (99.940)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.050)	BT: 0.009 (0.063)	Loss 0.0075 (0.0141)	Prec@1 100.000 (99.945)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.065 (0.047)	BT: 0.074 (0.060)	Loss 0.0135 (0.0145)	Prec@1 100.000 (99.927)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.047)	BT: 0.015 (0.060)	Loss 0.0227 (0.0143)	Prec@1 100.000 (99.927)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.046)	BT: 0.023 (0.059)	Loss 0.0098 (0.0148)	Prec@1 100.000 (99.908)	
Total train loss: 0.0149
Avg Loading time: 0.0462 seconds
Avg Batch time: 0.0592 seconds

Train time: 23.326963186264038
 * Prec@1 70.520 Prec@5 89.850 Loss 1.3271
Avg Loading time: 0.0515 seconds
Avg Batch time: 0.0570 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 4.887037515640259

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.058)	BT: 0.028 (0.072)	Loss 0.0201 (0.0153)	Prec@1 99.219 (99.930)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.052)	BT: 0.011 (0.066)	Loss 0.0067 (0.0148)	Prec@1 100.000 (99.950)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.052)	BT: 0.010 (0.066)	Loss 0.0151 (0.0149)	Prec@1 100.000 (99.933)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.051)	BT: 0.017 (0.064)	Loss 0.0151 (0.0147)	Prec@1 100.000 (99.940)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.051)	BT: 0.009 (0.065)	Loss 0.0119 (0.0147)	Prec@1 100.000 (99.944)	
Total train loss: 0.0147
Avg Loading time: 0.0513 seconds
Avg Batch time: 0.0649 seconds

Train time: 25.484317302703857
 * Prec@1 70.450 Prec@5 89.880 Loss 1.3350
Avg Loading time: 0.0528 seconds
Avg Batch time: 0.0599 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 5.054347038269043

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.061)	BT: 0.011 (0.075)	Loss 0.0167 (0.0140)	Prec@1 100.000 (99.930)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.049)	BT: 0.013 (0.062)	Loss 0.0111 (0.0144)	Prec@1 100.000 (99.940)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.200 (0.053)	BT: 0.211 (0.066)	Loss 0.0114 (0.0145)	Prec@1 100.000 (99.947)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.054)	BT: 0.009 (0.066)	Loss 0.0223 (0.0146)	Prec@1 100.000 (99.945)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.053)	BT: 0.011 (0.066)	Loss 0.0087 (0.0145)	Prec@1 100.000 (99.940)	
Total train loss: 0.0145
Avg Loading time: 0.0529 seconds
Avg Batch time: 0.0655 seconds

Train time: 25.716347694396973
 * Prec@1 70.470 Prec@5 89.830 Loss 1.3301
Avg Loading time: 0.0713 seconds
Avg Batch time: 0.0782 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 6.552459716796875

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.084 (0.057)	BT: 0.107 (0.069)	Loss 0.0166 (0.0145)	Prec@1 99.219 (99.950)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.052)	BT: 0.009 (0.065)	Loss 0.0130 (0.0149)	Prec@1 100.000 (99.930)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.240 (0.050)	BT: 0.250 (0.064)	Loss 0.0087 (0.0150)	Prec@1 100.000 (99.930)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.048)	BT: 0.009 (0.061)	Loss 0.0116 (0.0148)	Prec@1 100.000 (99.937)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.048)	BT: 0.010 (0.062)	Loss 0.0132 (0.0147)	Prec@1 100.000 (99.940)	
Total train loss: 0.0147
Avg Loading time: 0.0483 seconds
Avg Batch time: 0.0615 seconds

Train time: 24.182002544403076
 * Prec@1 70.460 Prec@5 89.800 Loss 1.3223
Avg Loading time: 0.0627 seconds
Avg Batch time: 0.0688 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 5.8195154666900635

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.050)	BT: 0.010 (0.063)	Loss 0.0158 (0.0143)	Prec@1 100.000 (99.920)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.048)	BT: 0.017 (0.062)	Loss 0.0087 (0.0144)	Prec@1 100.000 (99.925)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.049)	BT: 0.024 (0.063)	Loss 0.0110 (0.0144)	Prec@1 100.000 (99.927)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.048)	BT: 0.013 (0.062)	Loss 0.0184 (0.0144)	Prec@1 100.000 (99.930)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.045)	BT: 0.021 (0.059)	Loss 0.0116 (0.0145)	Prec@1 100.000 (99.930)	
Total train loss: 0.0147
Avg Loading time: 0.0446 seconds
Avg Batch time: 0.0587 seconds

Train time: 23.09334421157837
 * Prec@1 70.770 Prec@5 89.950 Loss 1.3320
Avg Loading time: 0.0413 seconds
Avg Batch time: 0.0474 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 4.30983567237854

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.045)	BT: 0.010 (0.058)	Loss 0.0219 (0.0148)	Prec@1 100.000 (99.920)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.187 (0.047)	BT: 0.198 (0.060)	Loss 0.0170 (0.0155)	Prec@1 100.000 (99.910)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.048)	BT: 0.009 (0.061)	Loss 0.0127 (0.0153)	Prec@1 100.000 (99.917)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.047)	BT: 0.015 (0.060)	Loss 0.0144 (0.0151)	Prec@1 100.000 (99.925)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.048)	BT: 0.009 (0.061)	Loss 0.0095 (0.0150)	Prec@1 100.000 (99.930)	
Total train loss: 0.0150
Avg Loading time: 0.0480 seconds
Avg Batch time: 0.0610 seconds

Train time: 23.93038058280945
 * Prec@1 70.700 Prec@5 89.810 Loss 1.3311
Avg Loading time: 0.0753 seconds
Avg Batch time: 0.0818 seconds

Best acc: 71.000
--------------------------------------------------------------------------------
Test time: 6.847910165786743


      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 0
          frozen_layers: 17
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar100/resnet18
DEVICE: cuda
GPU Id(s) being used: 0
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/train/relu17
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/test/relu17
ResNet18(
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=100, bias=False)
  (bn19): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 1.060 Prec@5 5.150 Loss 4.6055
Avg Loading time: 0.9316 seconds
Avg Batch time: 0.9431 seconds

Pre-trained Prec@1 with 17 layers frozen: 1.059999942779541 	 Loss: 4.60546875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (1.428)	BT: 0.004 (1.434)	Loss 2.2988 (2.7872)	Prec@1 42.969 (36.008)	
Epoch: [0][155/391]	LR: 0.1	DT: 1.587 (1.401)	BT: 1.599 (1.408)	Loss 1.9697 (2.4200)	Prec@1 50.000 (42.433)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (1.376)	BT: 0.008 (1.382)	Loss 1.8223 (2.2421)	Prec@1 52.344 (45.373)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (1.356)	BT: 0.008 (1.363)	Loss 1.7197 (2.1357)	Prec@1 56.250 (47.193)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (1.368)	BT: 0.006 (1.375)	Loss 1.6924 (2.0560)	Prec@1 59.375 (48.462)	
Total train loss: 2.0555
Avg Loading time: 1.3649 seconds
Avg Batch time: 1.3720 seconds

Train time: 536.5546591281891
 * Prec@1 57.400 Prec@5 84.000 Loss 1.6182
Avg Loading time: 0.1626 seconds
Avg Batch time: 0.1674 seconds

Best acc: 57.400
--------------------------------------------------------------------------------
Test time: 13.370325803756714

Epoch: [1][77/391]	LR: 0.1	DT: 0.281 (0.149)	BT: 0.290 (0.156)	Loss 1.6465 (1.5704)	Prec@1 52.344 (57.372)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.182 (0.135)	BT: 0.192 (0.142)	Loss 1.5000 (1.5534)	Prec@1 57.812 (58.098)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.649 (0.129)	BT: 0.659 (0.136)	Loss 1.4727 (1.5583)	Prec@1 59.375 (57.959)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.129)	BT: 0.005 (0.136)	Loss 1.4258 (1.5615)	Prec@1 62.500 (57.772)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.147)	BT: 0.007 (0.154)	Loss 1.6064 (1.5694)	Prec@1 56.250 (57.534)	
Total train loss: 1.5697
Avg Loading time: 0.1465 seconds
Avg Batch time: 0.1538 seconds

Train time: 60.19168257713318
 * Prec@1 58.970 Prec@5 85.280 Loss 1.5273
Avg Loading time: 0.2853 seconds
Avg Batch time: 0.2899 seconds

Best acc: 58.970
--------------------------------------------------------------------------------
Test time: 23.040297746658325

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.565)	BT: 0.004 (0.572)	Loss 1.5791 (1.3952)	Prec@1 56.250 (61.729)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.477)	BT: 0.006 (0.484)	Loss 1.5742 (1.4180)	Prec@1 57.812 (60.917)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (0.399)	BT: 0.009 (0.406)	Loss 1.3262 (1.4320)	Prec@1 67.969 (60.577)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.357)	BT: 0.005 (0.363)	Loss 1.5566 (1.4445)	Prec@1 61.719 (60.236)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.328)	BT: 0.004 (0.335)	Loss 1.3076 (1.4467)	Prec@1 62.500 (60.126)	
Total train loss: 1.4462
Avg Loading time: 0.3274 seconds
Avg Batch time: 0.3341 seconds

Train time: 130.77009320259094
 * Prec@1 59.470 Prec@5 85.770 Loss 1.4893
Avg Loading time: 0.2042 seconds
Avg Batch time: 0.2086 seconds

Best acc: 59.470
--------------------------------------------------------------------------------
Test time: 16.576401948928833

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.215)	BT: 0.005 (0.221)	Loss 1.1934 (1.3287)	Prec@1 65.625 (62.891)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.218)	BT: 0.006 (0.224)	Loss 1.5537 (1.3394)	Prec@1 52.344 (62.575)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.232)	BT: 0.008 (0.239)	Loss 1.6152 (1.3568)	Prec@1 62.500 (62.190)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.241)	BT: 0.004 (0.247)	Loss 1.4561 (1.3665)	Prec@1 59.375 (61.884)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.247)	BT: 0.005 (0.253)	Loss 1.4316 (1.3772)	Prec@1 59.375 (61.619)	
Total train loss: 1.3773
Avg Loading time: 0.2462 seconds
Avg Batch time: 0.2527 seconds

Train time: 98.89127039909363
 * Prec@1 60.140 Prec@5 86.250 Loss 1.4717
Avg Loading time: 0.2258 seconds
Avg Batch time: 0.2305 seconds

Best acc: 60.140
--------------------------------------------------------------------------------
Test time: 18.311043977737427

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.280)	BT: 0.008 (0.287)	Loss 1.4014 (1.2661)	Prec@1 62.500 (64.994)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.342 (0.269)	BT: 0.354 (0.277)	Loss 1.5117 (1.2914)	Prec@1 59.375 (64.002)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.254)	BT: 0.009 (0.261)	Loss 1.2148 (1.3040)	Prec@1 64.844 (63.618)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.233)	BT: 0.006 (0.241)	Loss 1.6240 (1.3229)	Prec@1 55.469 (63.126)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.219)	BT: 0.007 (0.226)	Loss 1.4414 (1.3321)	Prec@1 59.375 (62.782)	
Total train loss: 1.3323
Avg Loading time: 0.2180 seconds
Avg Batch time: 0.2256 seconds

Train time: 88.3219792842865
 * Prec@1 60.450 Prec@5 85.830 Loss 1.4717
Avg Loading time: 0.1523 seconds
Avg Batch time: 0.1568 seconds

Best acc: 60.450
--------------------------------------------------------------------------------
Test time: 12.48918890953064

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.135)	BT: 0.006 (0.141)	Loss 1.2539 (1.2399)	Prec@1 62.500 (65.455)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.148)	BT: 0.007 (0.155)	Loss 1.3232 (1.2695)	Prec@1 62.500 (64.438)	
Epoch: [5][233/391]	LR: 0.1	DT: 1.205 (0.153)	BT: 1.217 (0.160)	Loss 1.3496 (1.2730)	Prec@1 59.375 (64.269)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.151)	BT: 0.005 (0.158)	Loss 1.3662 (1.2882)	Prec@1 57.031 (63.805)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.150)	BT: 0.005 (0.157)	Loss 1.4033 (1.2981)	Prec@1 60.156 (63.522)	
Total train loss: 1.2984
Avg Loading time: 0.1499 seconds
Avg Batch time: 0.1570 seconds

Train time: 61.4791316986084
 * Prec@1 61.000 Prec@5 86.080 Loss 1.4521
Avg Loading time: 0.1893 seconds
Avg Batch time: 0.1933 seconds

Best acc: 61.000
--------------------------------------------------------------------------------
Test time: 15.41227674484253

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.134)	BT: 0.006 (0.141)	Loss 1.1240 (1.2237)	Prec@1 68.750 (65.194)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.083 (0.141)	BT: 0.089 (0.148)	Loss 1.1719 (1.2386)	Prec@1 62.500 (64.929)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.138)	BT: 0.005 (0.145)	Loss 1.5293 (1.2544)	Prec@1 59.375 (64.527)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.141)	BT: 0.005 (0.148)	Loss 1.4902 (1.2648)	Prec@1 61.719 (64.328)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.143)	BT: 0.004 (0.150)	Loss 1.2900 (1.2744)	Prec@1 61.719 (64.107)	
Total train loss: 1.2745
Avg Loading time: 0.1427 seconds
Avg Batch time: 0.1500 seconds

Train time: 58.78567147254944
 * Prec@1 59.920 Prec@5 86.160 Loss 1.4697
Avg Loading time: 0.1813 seconds
Avg Batch time: 0.1860 seconds

Best acc: 61.000
--------------------------------------------------------------------------------
Test time: 14.799678564071655

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.160)	BT: 0.009 (0.167)	Loss 1.2285 (1.1922)	Prec@1 63.281 (66.446)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.448 (0.154)	BT: 0.453 (0.161)	Loss 1.1582 (1.2181)	Prec@1 65.625 (65.595)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.151)	BT: 0.008 (0.157)	Loss 1.2490 (1.2259)	Prec@1 65.625 (65.338)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.154)	BT: 0.006 (0.161)	Loss 1.2246 (1.2362)	Prec@1 63.281 (65.127)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.154)	BT: 0.005 (0.161)	Loss 1.2119 (1.2505)	Prec@1 65.625 (64.645)	
Total train loss: 1.2506
Avg Loading time: 0.1539 seconds
Avg Batch time: 0.1606 seconds

Train time: 62.884214878082275
 * Prec@1 60.670 Prec@5 85.960 Loss 1.4639
Avg Loading time: 0.1958 seconds
Avg Batch time: 0.2007 seconds

Best acc: 61.000
--------------------------------------------------------------------------------
Test time: 15.981655597686768

Epoch: [8][77/391]	LR: 0.1	DT: 0.092 (0.155)	BT: 0.108 (0.162)	Loss 1.3525 (1.1870)	Prec@1 60.156 (65.615)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.159)	BT: 0.008 (0.166)	Loss 0.9165 (1.1953)	Prec@1 68.750 (65.845)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.156)	BT: 0.008 (0.163)	Loss 1.2861 (1.2157)	Prec@1 64.062 (65.171)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.151)	BT: 0.004 (0.158)	Loss 0.8706 (1.2262)	Prec@1 71.875 (65.019)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.154)	BT: 0.004 (0.161)	Loss 1.2607 (1.2385)	Prec@1 66.406 (64.698)	
Total train loss: 1.2387
Avg Loading time: 0.1534 seconds
Avg Batch time: 0.1605 seconds

Train time: 62.848450899124146
 * Prec@1 60.850 Prec@5 86.690 Loss 1.4492
Avg Loading time: 0.1818 seconds
Avg Batch time: 0.1862 seconds

Best acc: 61.000
--------------------------------------------------------------------------------
Test time: 14.801357984542847

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.147)	BT: 0.005 (0.153)	Loss 1.2598 (1.1732)	Prec@1 60.156 (66.937)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.161)	BT: 0.005 (0.168)	Loss 1.3750 (1.1872)	Prec@1 62.500 (66.261)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.791 (0.159)	BT: 0.800 (0.166)	Loss 1.2900 (1.1929)	Prec@1 62.500 (66.156)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.154)	BT: 0.005 (0.161)	Loss 1.3535 (1.2110)	Prec@1 69.531 (65.673)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.158)	BT: 0.004 (0.166)	Loss 1.2197 (1.2247)	Prec@1 64.062 (65.266)	
Total train loss: 1.2250
Avg Loading time: 0.1579 seconds
Avg Batch time: 0.1652 seconds

Train time: 64.67234396934509
 * Prec@1 60.590 Prec@5 85.850 Loss 1.4727
Avg Loading time: 0.1685 seconds
Avg Batch time: 0.1737 seconds

Best acc: 61.000
--------------------------------------------------------------------------------
Test time: 13.825864315032959

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.164)	BT: 0.005 (0.171)	Loss 1.1582 (1.0985)	Prec@1 64.062 (68.780)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.167)	BT: 0.006 (0.174)	Loss 1.2373 (1.0926)	Prec@1 63.281 (69.030)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 1.022 (0.167)	BT: 1.032 (0.174)	Loss 1.1318 (1.0889)	Prec@1 67.969 (69.047)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.166)	BT: 0.005 (0.173)	Loss 0.9849 (1.0865)	Prec@1 68.750 (69.103)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.077 (0.167)	BT: 0.082 (0.174)	Loss 0.8877 (1.0868)	Prec@1 72.656 (69.121)	
Total train loss: 1.0868
Avg Loading time: 0.1662 seconds
Avg Batch time: 0.1732 seconds

Train time: 67.78854656219482
 * Prec@1 62.410 Prec@5 86.730 Loss 1.4004
Avg Loading time: 0.2187 seconds
Avg Batch time: 0.2239 seconds

Best acc: 62.410
--------------------------------------------------------------------------------
Test time: 17.787872076034546

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.174)	BT: 0.004 (0.180)	Loss 1.1006 (1.0432)	Prec@1 70.312 (70.433)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.164)	BT: 0.006 (0.170)	Loss 1.0430 (1.0549)	Prec@1 70.312 (70.062)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.143)	BT: 0.006 (0.150)	Loss 1.2988 (1.0560)	Prec@1 60.156 (70.152)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.127)	BT: 0.005 (0.134)	Loss 1.0889 (1.0570)	Prec@1 68.750 (70.160)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.119)	BT: 0.004 (0.126)	Loss 1.0322 (1.0578)	Prec@1 64.844 (70.040)	
Total train loss: 1.0581
Avg Loading time: 0.1188 seconds
Avg Batch time: 0.1255 seconds

Train time: 49.166876554489136
 * Prec@1 62.270 Prec@5 86.940 Loss 1.4014
Avg Loading time: 0.1357 seconds
Avg Batch time: 0.1411 seconds

Best acc: 62.410
--------------------------------------------------------------------------------
Test time: 11.298309087753296

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.095)	BT: 0.004 (0.102)	Loss 1.0039 (1.0435)	Prec@1 72.656 (70.323)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.092)	BT: 0.007 (0.099)	Loss 0.9766 (1.0453)	Prec@1 76.562 (70.287)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.091)	BT: 0.005 (0.097)	Loss 1.1836 (1.0460)	Prec@1 68.750 (70.282)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.087)	BT: 0.004 (0.094)	Loss 1.1572 (1.0472)	Prec@1 67.188 (70.127)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.092)	BT: 0.008 (0.099)	Loss 0.9077 (1.0504)	Prec@1 75.000 (70.080)	
Total train loss: 1.0502
Avg Loading time: 0.0922 seconds
Avg Batch time: 0.0992 seconds

Train time: 38.89684724807739
 * Prec@1 62.830 Prec@5 86.930 Loss 1.4121
Avg Loading time: 0.0915 seconds
Avg Batch time: 0.0960 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 7.688554763793945

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.117)	BT: 0.005 (0.124)	Loss 1.0078 (1.0085)	Prec@1 71.094 (71.404)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.123)	BT: 0.014 (0.129)	Loss 1.0391 (1.0237)	Prec@1 72.656 (70.723)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.111)	BT: 0.012 (0.118)	Loss 1.1416 (1.0342)	Prec@1 67.969 (70.503)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.107)	BT: 0.005 (0.114)	Loss 1.2998 (1.0389)	Prec@1 60.938 (70.325)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.104)	BT: 0.004 (0.111)	Loss 1.1240 (1.0435)	Prec@1 69.531 (70.204)	
Total train loss: 1.0438
Avg Loading time: 0.1033 seconds
Avg Batch time: 0.1103 seconds

Train time: 43.23334980010986
 * Prec@1 62.290 Prec@5 86.710 Loss 1.4160
Avg Loading time: 0.0903 seconds
Avg Batch time: 0.0955 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 7.678610324859619

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.115)	BT: 0.005 (0.123)	Loss 1.0996 (1.0047)	Prec@1 64.844 (71.084)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.106)	BT: 0.004 (0.113)	Loss 1.1025 (1.0245)	Prec@1 69.531 (70.713)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.022 (0.113)	BT: 0.027 (0.120)	Loss 0.9985 (1.0349)	Prec@1 72.656 (70.596)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.112)	BT: 0.006 (0.119)	Loss 0.8896 (1.0398)	Prec@1 71.875 (70.323)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.085 (0.104)	BT: 0.092 (0.111)	Loss 0.9844 (1.0435)	Prec@1 69.531 (70.132)	
Total train loss: 1.0437
Avg Loading time: 0.1038 seconds
Avg Batch time: 0.1107 seconds

Train time: 43.39672040939331
 * Prec@1 62.050 Prec@5 86.800 Loss 1.4219
Avg Loading time: 0.0882 seconds
Avg Batch time: 0.0925 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 7.43184494972229

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.076)	BT: 0.005 (0.083)	Loss 1.0693 (1.0105)	Prec@1 69.531 (70.683)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.075)	BT: 0.007 (0.082)	Loss 0.9580 (1.0124)	Prec@1 74.219 (70.568)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.075)	BT: 0.005 (0.082)	Loss 1.1396 (1.0212)	Prec@1 67.188 (70.493)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.071)	BT: 0.005 (0.079)	Loss 0.8774 (1.0338)	Prec@1 71.875 (70.275)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.070)	BT: 0.004 (0.077)	Loss 0.9805 (1.0376)	Prec@1 69.531 (70.086)	
Total train loss: 1.0377
Avg Loading time: 0.0699 seconds
Avg Batch time: 0.0770 seconds

Train time: 30.266343116760254
 * Prec@1 61.940 Prec@5 86.620 Loss 1.4238
Avg Loading time: 0.0751 seconds
Avg Batch time: 0.0808 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 6.5171215534210205

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.069)	BT: 0.005 (0.075)	Loss 0.9253 (1.0165)	Prec@1 78.125 (71.224)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.059)	BT: 0.005 (0.066)	Loss 0.9463 (1.0179)	Prec@1 70.312 (70.878)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.058)	BT: 0.010 (0.064)	Loss 1.0752 (1.0250)	Prec@1 66.406 (70.593)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.013 (0.059)	BT: 0.018 (0.066)	Loss 1.0986 (1.0307)	Prec@1 63.281 (70.425)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.028 (0.059)	BT: 0.035 (0.066)	Loss 1.0908 (1.0315)	Prec@1 71.094 (70.417)	
Total train loss: 1.0318
Avg Loading time: 0.0588 seconds
Avg Batch time: 0.0659 seconds

Train time: 25.912733793258667
 * Prec@1 62.150 Prec@5 86.400 Loss 1.4268
Avg Loading time: 0.0812 seconds
Avg Batch time: 0.0873 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 7.00641393661499

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.075 (0.071)	BT: 0.087 (0.078)	Loss 1.0967 (0.9834)	Prec@1 69.531 (71.404)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.067)	BT: 0.004 (0.073)	Loss 0.9834 (1.0050)	Prec@1 74.219 (71.114)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.040 (0.068)	BT: 0.045 (0.075)	Loss 1.0732 (1.0154)	Prec@1 67.969 (71.007)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.064)	BT: 0.008 (0.071)	Loss 1.4189 (1.0258)	Prec@1 61.719 (70.681)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.186 (0.063)	BT: 0.193 (0.070)	Loss 0.9863 (1.0290)	Prec@1 70.312 (70.505)	
Total train loss: 1.0293
Avg Loading time: 0.0626 seconds
Avg Batch time: 0.0695 seconds

Train time: 27.267472743988037
 * Prec@1 62.230 Prec@5 86.880 Loss 1.4316
Avg Loading time: 0.0740 seconds
Avg Batch time: 0.0787 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 6.3215296268463135

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.070)	BT: 0.006 (0.077)	Loss 1.1113 (1.0283)	Prec@1 71.094 (70.473)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.061)	BT: 0.004 (0.069)	Loss 1.0459 (1.0215)	Prec@1 67.969 (70.518)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.063)	BT: 0.011 (0.071)	Loss 0.9961 (1.0226)	Prec@1 71.094 (70.433)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.071)	BT: 0.013 (0.079)	Loss 1.1709 (1.0266)	Prec@1 64.062 (70.430)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.079)	BT: 0.004 (0.087)	Loss 0.9565 (1.0255)	Prec@1 69.531 (70.459)	
Total train loss: 1.0257
Avg Loading time: 0.0788 seconds
Avg Batch time: 0.0865 seconds

Train time: 33.895273208618164
 * Prec@1 62.080 Prec@5 86.740 Loss 1.4287
Avg Loading time: 0.1095 seconds
Avg Batch time: 0.1153 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 9.191482782363892

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.105)	BT: 0.004 (0.112)	Loss 1.1582 (0.9931)	Prec@1 69.531 (71.565)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.105)	BT: 0.006 (0.112)	Loss 0.8994 (1.0045)	Prec@1 73.438 (71.154)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.102)	BT: 0.008 (0.110)	Loss 1.1318 (1.0170)	Prec@1 68.750 (70.820)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.767 (0.110)	BT: 0.776 (0.117)	Loss 0.9434 (1.0217)	Prec@1 72.656 (70.648)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.115)	BT: 0.004 (0.122)	Loss 1.0713 (1.0265)	Prec@1 71.094 (70.557)	
Total train loss: 1.0266
Avg Loading time: 0.1151 seconds
Avg Batch time: 0.1222 seconds

Train time: 47.87695646286011
 * Prec@1 61.970 Prec@5 86.450 Loss 1.4355
Avg Loading time: 0.1655 seconds
Avg Batch time: 0.1700 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 13.561659812927246

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.128)	BT: 0.004 (0.135)	Loss 1.0107 (0.9778)	Prec@1 70.312 (72.015)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.148)	BT: 0.005 (0.155)	Loss 0.8442 (0.9779)	Prec@1 70.312 (71.935)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.676 (0.151)	BT: 0.682 (0.158)	Loss 0.9473 (0.9813)	Prec@1 71.875 (71.731)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.150)	BT: 0.004 (0.157)	Loss 0.8711 (0.9807)	Prec@1 75.000 (71.785)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.146)	BT: 0.004 (0.153)	Loss 0.9727 (0.9818)	Prec@1 77.344 (71.793)	
Total train loss: 0.9820
Avg Loading time: 0.1455 seconds
Avg Batch time: 0.1526 seconds

Train time: 59.74171733856201
 * Prec@1 62.440 Prec@5 86.950 Loss 1.4248
Avg Loading time: 0.1289 seconds
Avg Batch time: 0.1340 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 10.732187747955322

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.121)	BT: 0.006 (0.127)	Loss 1.0234 (0.9803)	Prec@1 67.188 (71.524)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.119)	BT: 0.004 (0.125)	Loss 0.8618 (0.9707)	Prec@1 75.781 (71.985)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.327 (0.112)	BT: 0.333 (0.119)	Loss 0.9565 (0.9847)	Prec@1 75.000 (71.568)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.110)	BT: 0.005 (0.116)	Loss 0.8892 (0.9773)	Prec@1 75.781 (71.920)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.108)	BT: 0.003 (0.114)	Loss 1.0820 (0.9772)	Prec@1 65.625 (71.957)	
Total train loss: 0.9772
Avg Loading time: 0.1075 seconds
Avg Batch time: 0.1139 seconds

Train time: 44.6278874874115
 * Prec@1 62.490 Prec@5 86.850 Loss 1.4268
Avg Loading time: 0.0873 seconds
Avg Batch time: 0.0920 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 7.356440305709839

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.100)	BT: 0.007 (0.107)	Loss 1.0195 (0.9759)	Prec@1 72.656 (72.206)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.101)	BT: 0.007 (0.108)	Loss 0.9312 (0.9718)	Prec@1 71.094 (72.296)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.447 (0.101)	BT: 0.463 (0.109)	Loss 1.0039 (0.9728)	Prec@1 71.094 (72.239)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.125 (0.100)	BT: 0.131 (0.107)	Loss 1.0195 (0.9750)	Prec@1 69.531 (72.163)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.100)	BT: 0.004 (0.107)	Loss 0.7153 (0.9755)	Prec@1 78.906 (72.077)	
Total train loss: 0.9757
Avg Loading time: 0.0998 seconds
Avg Batch time: 0.1071 seconds

Train time: 41.991161584854126
 * Prec@1 62.360 Prec@5 86.670 Loss 1.4248
Avg Loading time: 0.1108 seconds
Avg Batch time: 0.1154 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 9.204771518707275

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.127)	BT: 0.005 (0.133)	Loss 0.9897 (0.9625)	Prec@1 71.875 (71.865)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.577 (0.127)	BT: 0.583 (0.133)	Loss 1.0586 (0.9578)	Prec@1 73.438 (72.085)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.122)	BT: 0.011 (0.128)	Loss 1.0391 (0.9604)	Prec@1 73.438 (72.319)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.120)	BT: 0.004 (0.127)	Loss 1.1426 (0.9677)	Prec@1 70.312 (72.155)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.120)	BT: 0.006 (0.127)	Loss 0.8174 (0.9722)	Prec@1 77.344 (72.073)	
Total train loss: 0.9722
Avg Loading time: 0.1196 seconds
Avg Batch time: 0.1264 seconds

Train time: 49.5021653175354
 * Prec@1 62.480 Prec@5 86.620 Loss 1.4268
Avg Loading time: 0.1200 seconds
Avg Batch time: 0.1249 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 9.99934697151184

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.102)	BT: 0.004 (0.109)	Loss 1.0586 (0.9606)	Prec@1 71.875 (72.646)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.100)	BT: 0.006 (0.107)	Loss 1.0098 (0.9641)	Prec@1 71.094 (72.316)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.103)	BT: 0.005 (0.110)	Loss 1.0605 (0.9655)	Prec@1 69.531 (72.369)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.105)	BT: 0.005 (0.112)	Loss 1.1641 (0.9674)	Prec@1 66.406 (72.206)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.106)	BT: 0.005 (0.113)	Loss 1.0166 (0.9717)	Prec@1 70.312 (72.093)	
Total train loss: 0.9722
Avg Loading time: 0.1061 seconds
Avg Batch time: 0.1132 seconds

Train time: 44.39907121658325
 * Prec@1 62.290 Prec@5 86.770 Loss 1.4307
Avg Loading time: 0.1228 seconds
Avg Batch time: 0.1273 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 10.194786787033081

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.132)	BT: 0.005 (0.138)	Loss 0.9556 (0.9740)	Prec@1 73.438 (72.135)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.120)	BT: 0.004 (0.126)	Loss 1.0811 (0.9730)	Prec@1 67.188 (72.140)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.195 (0.121)	BT: 0.200 (0.127)	Loss 1.1240 (0.9689)	Prec@1 65.625 (72.062)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.117)	BT: 0.008 (0.124)	Loss 0.9307 (0.9693)	Prec@1 75.000 (72.090)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.121)	BT: 0.006 (0.128)	Loss 1.0605 (0.9719)	Prec@1 65.625 (71.995)	
Total train loss: 0.9723
Avg Loading time: 0.1209 seconds
Avg Batch time: 0.1273 seconds

Train time: 49.92216873168945
 * Prec@1 62.660 Prec@5 86.910 Loss 1.4287
Avg Loading time: 0.1196 seconds
Avg Batch time: 0.1243 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 9.925886869430542

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.117)	BT: 0.013 (0.124)	Loss 1.0225 (0.9709)	Prec@1 71.875 (72.266)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.125)	BT: 0.013 (0.132)	Loss 0.9678 (0.9631)	Prec@1 77.344 (72.591)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.125)	BT: 0.014 (0.131)	Loss 1.0283 (0.9697)	Prec@1 70.312 (72.216)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.117)	BT: 0.005 (0.123)	Loss 1.1211 (0.9669)	Prec@1 68.750 (72.241)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.215 (0.119)	BT: 0.221 (0.125)	Loss 1.1592 (0.9701)	Prec@1 70.312 (72.177)	
Total train loss: 0.9703
Avg Loading time: 0.1183 seconds
Avg Batch time: 0.1248 seconds

Train time: 48.89957404136658
 * Prec@1 62.410 Prec@5 86.780 Loss 1.4336
Avg Loading time: 0.0903 seconds
Avg Batch time: 0.0947 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 7.588603496551514

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.009 (0.126)	BT: 0.013 (0.133)	Loss 0.8706 (0.9541)	Prec@1 73.438 (72.376)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.121)	BT: 0.006 (0.128)	Loss 0.9473 (0.9654)	Prec@1 73.438 (72.070)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.233 (0.126)	BT: 0.240 (0.132)	Loss 1.0244 (0.9584)	Prec@1 68.750 (72.523)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.127)	BT: 0.005 (0.135)	Loss 0.9194 (0.9652)	Prec@1 72.656 (72.316)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.127)	BT: 0.004 (0.134)	Loss 0.9072 (0.9696)	Prec@1 74.219 (72.119)	
Total train loss: 0.9696
Avg Loading time: 0.1265 seconds
Avg Batch time: 0.1335 seconds

Train time: 52.30406999588013
 * Prec@1 62.190 Prec@5 86.910 Loss 1.4297
Avg Loading time: 0.1618 seconds
Avg Batch time: 0.1669 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 13.365841150283813

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.126)	BT: 0.004 (0.133)	Loss 0.9922 (0.9739)	Prec@1 70.312 (72.065)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.131)	BT: 0.019 (0.138)	Loss 1.1230 (0.9698)	Prec@1 70.312 (71.890)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 1.170 (0.138)	BT: 1.182 (0.144)	Loss 1.0127 (0.9665)	Prec@1 69.531 (72.085)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.113 (0.132)	BT: 0.118 (0.139)	Loss 0.9927 (0.9669)	Prec@1 71.875 (72.088)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.134)	BT: 0.004 (0.141)	Loss 1.0264 (0.9664)	Prec@1 70.312 (72.206)	
Total train loss: 0.9662
Avg Loading time: 0.1335 seconds
Avg Batch time: 0.1402 seconds

Train time: 54.90947890281677
 * Prec@1 62.160 Prec@5 86.720 Loss 1.4316
Avg Loading time: 0.1775 seconds
Avg Batch time: 0.1826 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 14.559088230133057

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.169)	BT: 0.008 (0.177)	Loss 1.0830 (0.9510)	Prec@1 67.969 (72.446)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.080 (0.214)	BT: 0.088 (0.222)	Loss 0.8647 (0.9652)	Prec@1 74.219 (71.950)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.247)	BT: 0.010 (0.254)	Loss 1.1055 (0.9646)	Prec@1 65.625 (72.155)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.256)	BT: 0.005 (0.264)	Loss 0.8457 (0.9615)	Prec@1 73.438 (72.313)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.266)	BT: 0.008 (0.273)	Loss 1.1123 (0.9668)	Prec@1 70.312 (72.266)	
Total train loss: 0.9669
Avg Loading time: 0.2650 seconds
Avg Batch time: 0.2726 seconds

Train time: 106.67924761772156
 * Prec@1 62.370 Prec@5 86.600 Loss 1.4268
Avg Loading time: 0.3263 seconds
Avg Batch time: 0.3308 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 26.227107286453247

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.324)	BT: 0.005 (0.331)	Loss 1.0303 (0.9712)	Prec@1 70.312 (71.875)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.339)	BT: 0.005 (0.346)	Loss 0.9761 (0.9721)	Prec@1 75.000 (72.125)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 2.090 (0.331)	BT: 2.101 (0.338)	Loss 0.6987 (0.9618)	Prec@1 80.469 (72.379)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.319)	BT: 0.004 (0.326)	Loss 0.7964 (0.9596)	Prec@1 79.688 (72.498)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.325)	BT: 0.004 (0.332)	Loss 1.0322 (0.9602)	Prec@1 70.312 (72.480)	
Total train loss: 0.9604
Avg Loading time: 0.3241 seconds
Avg Batch time: 0.3313 seconds

Train time: 129.61199426651
 * Prec@1 62.590 Prec@5 86.690 Loss 1.4268
Avg Loading time: 0.2873 seconds
Avg Batch time: 0.2924 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 23.244640827178955

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.291)	BT: 0.005 (0.298)	Loss 0.8989 (0.9527)	Prec@1 72.656 (72.786)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.251 (0.276)	BT: 0.260 (0.283)	Loss 1.0830 (0.9588)	Prec@1 70.312 (72.431)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.286)	BT: 0.008 (0.293)	Loss 1.1543 (0.9614)	Prec@1 70.312 (72.396)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.276)	BT: 0.011 (0.283)	Loss 0.9688 (0.9634)	Prec@1 67.969 (72.333)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.274)	BT: 0.005 (0.281)	Loss 1.0674 (0.9629)	Prec@1 66.406 (72.282)	
Total train loss: 0.9627
Avg Loading time: 0.2735 seconds
Avg Batch time: 0.2806 seconds

Train time: 109.81604290008545
 * Prec@1 62.380 Prec@5 86.670 Loss 1.4346
Avg Loading time: 0.2304 seconds
Avg Batch time: 0.2364 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 18.79654836654663

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.267)	BT: 0.005 (0.273)	Loss 0.8955 (0.9567)	Prec@1 75.000 (73.317)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.261)	BT: 0.007 (0.267)	Loss 0.7534 (0.9660)	Prec@1 80.469 (72.601)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.255)	BT: 0.012 (0.261)	Loss 0.7876 (0.9563)	Prec@1 75.000 (72.900)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.250)	BT: 0.006 (0.257)	Loss 0.8037 (0.9607)	Prec@1 79.688 (72.749)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.244)	BT: 0.004 (0.251)	Loss 0.8018 (0.9602)	Prec@1 83.594 (72.682)	
Total train loss: 0.9601
Avg Loading time: 0.2436 seconds
Avg Batch time: 0.2505 seconds

Train time: 98.03002309799194
 * Prec@1 62.360 Prec@5 86.620 Loss 1.4297
Avg Loading time: 0.2263 seconds
Avg Batch time: 0.2309 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 18.349554538726807

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.250)	BT: 0.004 (0.256)	Loss 1.0586 (0.9593)	Prec@1 75.000 (72.386)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.255)	BT: 0.005 (0.261)	Loss 0.9419 (0.9668)	Prec@1 73.438 (71.990)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.149 (0.245)	BT: 0.162 (0.252)	Loss 0.8940 (0.9532)	Prec@1 74.219 (72.559)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.235)	BT: 0.007 (0.241)	Loss 0.8892 (0.9553)	Prec@1 75.781 (72.521)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.228)	BT: 0.004 (0.234)	Loss 1.0723 (0.9558)	Prec@1 67.969 (72.472)	
Total train loss: 0.9561
Avg Loading time: 0.2277 seconds
Avg Batch time: 0.2338 seconds

Train time: 91.50414752960205
 * Prec@1 62.290 Prec@5 86.760 Loss 1.4375
Avg Loading time: 0.2158 seconds
Avg Batch time: 0.2205 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 17.516107082366943

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.192)	BT: 0.004 (0.199)	Loss 1.0381 (0.9724)	Prec@1 69.531 (71.705)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.198)	BT: 0.006 (0.205)	Loss 0.7905 (0.9594)	Prec@1 78.906 (72.471)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.016 (0.212)	BT: 0.021 (0.219)	Loss 0.8389 (0.9587)	Prec@1 78.906 (72.429)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.239 (0.216)	BT: 0.250 (0.222)	Loss 1.0410 (0.9641)	Prec@1 71.875 (72.403)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.215)	BT: 0.005 (0.222)	Loss 0.8462 (0.9610)	Prec@1 77.344 (72.512)	
Total train loss: 0.9613
Avg Loading time: 0.2147 seconds
Avg Batch time: 0.2217 seconds

Train time: 86.8362877368927
 * Prec@1 62.330 Prec@5 86.720 Loss 1.4258
Avg Loading time: 0.2435 seconds
Avg Batch time: 0.2485 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 19.737309455871582

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.133 (0.189)	BT: 0.139 (0.197)	Loss 0.8438 (0.9563)	Prec@1 71.875 (72.326)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.066 (0.146)	BT: 0.071 (0.153)	Loss 1.1230 (0.9555)	Prec@1 64.844 (72.581)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.127)	BT: 0.008 (0.134)	Loss 1.0811 (0.9583)	Prec@1 69.531 (72.650)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.118)	BT: 0.005 (0.125)	Loss 0.8276 (0.9569)	Prec@1 72.656 (72.644)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.102 (0.109)	BT: 0.115 (0.117)	Loss 0.9512 (0.9573)	Prec@1 73.438 (72.674)	
Total train loss: 0.9577
Avg Loading time: 0.1088 seconds
Avg Batch time: 0.1164 seconds

Train time: 45.659130811691284
 * Prec@1 62.260 Prec@5 86.670 Loss 1.4355
Avg Loading time: 0.0546 seconds
Avg Batch time: 0.0601 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 4.869189739227295

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.100)	BT: 0.005 (0.108)	Loss 0.8140 (0.9761)	Prec@1 74.219 (72.246)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.104)	BT: 0.007 (0.111)	Loss 1.1895 (0.9707)	Prec@1 68.750 (72.065)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.102)	BT: 0.009 (0.109)	Loss 1.0410 (0.9679)	Prec@1 69.531 (72.065)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.104)	BT: 0.011 (0.111)	Loss 0.9072 (0.9636)	Prec@1 77.344 (72.241)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.110)	BT: 0.005 (0.117)	Loss 0.8237 (0.9596)	Prec@1 78.125 (72.396)	
Total train loss: 0.9598
Avg Loading time: 0.1099 seconds
Avg Batch time: 0.1166 seconds

Train time: 45.71275091171265
 * Prec@1 62.490 Prec@5 86.640 Loss 1.4287
Avg Loading time: 0.1162 seconds
Avg Batch time: 0.1204 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 9.631670713424683

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.118)	BT: 0.004 (0.126)	Loss 0.8706 (0.9711)	Prec@1 75.000 (72.306)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.115)	BT: 0.005 (0.122)	Loss 1.0820 (0.9714)	Prec@1 67.188 (72.251)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.249 (0.114)	BT: 0.257 (0.121)	Loss 0.9810 (0.9706)	Prec@1 74.219 (72.172)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.111)	BT: 0.004 (0.118)	Loss 0.8433 (0.9652)	Prec@1 79.688 (72.243)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.111)	BT: 0.004 (0.117)	Loss 1.0186 (0.9607)	Prec@1 71.094 (72.392)	
Total train loss: 0.9605
Avg Loading time: 0.1105 seconds
Avg Batch time: 0.1172 seconds

Train time: 45.902076959609985
 * Prec@1 62.190 Prec@5 86.980 Loss 1.4297
Avg Loading time: 0.1049 seconds
Avg Batch time: 0.1100 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 8.826539039611816

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.108)	BT: 0.007 (0.114)	Loss 0.8765 (0.9613)	Prec@1 77.344 (72.566)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.319 (0.105)	BT: 0.327 (0.111)	Loss 0.8501 (0.9609)	Prec@1 77.344 (72.581)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.106)	BT: 0.006 (0.112)	Loss 1.0166 (0.9587)	Prec@1 67.969 (72.496)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.095)	BT: 0.006 (0.101)	Loss 0.9521 (0.9602)	Prec@1 68.750 (72.541)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.394 (0.100)	BT: 0.399 (0.106)	Loss 0.7847 (0.9574)	Prec@1 76.562 (72.546)	
Total train loss: 0.9575
Avg Loading time: 0.0996 seconds
Avg Batch time: 0.1062 seconds

Train time: 41.63518929481506
 * Prec@1 62.420 Prec@5 86.650 Loss 1.4297
Avg Loading time: 0.0701 seconds
Avg Batch time: 0.0752 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 6.036749601364136

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.056)	BT: 0.006 (0.063)	Loss 0.9243 (0.9379)	Prec@1 71.094 (73.347)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.058)	BT: 0.006 (0.065)	Loss 0.7817 (0.9548)	Prec@1 78.906 (72.892)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.054)	BT: 0.013 (0.062)	Loss 0.8906 (0.9534)	Prec@1 74.219 (72.827)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.052)	BT: 0.006 (0.059)	Loss 0.9438 (0.9599)	Prec@1 73.438 (72.626)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.052)	BT: 0.005 (0.059)	Loss 1.0498 (0.9597)	Prec@1 66.406 (72.478)	
Total train loss: 0.9602
Avg Loading time: 0.0518 seconds
Avg Batch time: 0.0593 seconds

Train time: 23.31506848335266
 * Prec@1 61.990 Prec@5 86.630 Loss 1.4316
Avg Loading time: 0.0715 seconds
Avg Batch time: 0.0787 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 6.311114311218262

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.068)	BT: 0.005 (0.076)	Loss 0.8604 (0.9618)	Prec@1 75.781 (72.516)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.061)	BT: 0.032 (0.069)	Loss 0.7974 (0.9697)	Prec@1 76.562 (72.030)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.058)	BT: 0.005 (0.065)	Loss 0.9907 (0.9702)	Prec@1 72.656 (72.079)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.054)	BT: 0.004 (0.062)	Loss 1.0625 (0.9654)	Prec@1 68.750 (72.336)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.040 (0.052)	BT: 0.048 (0.060)	Loss 1.0342 (0.9588)	Prec@1 65.625 (72.532)	
Total train loss: 0.9587
Avg Loading time: 0.0516 seconds
Avg Batch time: 0.0597 seconds

Train time: 23.449281692504883
 * Prec@1 62.160 Prec@5 86.700 Loss 1.4316
Avg Loading time: 0.0415 seconds
Avg Batch time: 0.0459 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 3.761394739151001

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.050 (0.067)	BT: 0.055 (0.074)	Loss 0.9468 (0.9518)	Prec@1 73.438 (72.646)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.061)	BT: 0.005 (0.068)	Loss 1.1377 (0.9521)	Prec@1 67.969 (72.766)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.525 (0.058)	BT: 0.532 (0.065)	Loss 0.8174 (0.9528)	Prec@1 77.344 (72.733)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.057)	BT: 0.005 (0.064)	Loss 0.8501 (0.9527)	Prec@1 74.219 (72.819)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.056)	BT: 0.006 (0.064)	Loss 1.0889 (0.9577)	Prec@1 65.625 (72.584)	
Total train loss: 0.9574
Avg Loading time: 0.0558 seconds
Avg Batch time: 0.0635 seconds

Train time: 24.908881187438965
 * Prec@1 62.410 Prec@5 86.710 Loss 1.4316
Avg Loading time: 0.0770 seconds
Avg Batch time: 0.0818 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 6.561232328414917

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.048)	BT: 0.005 (0.055)	Loss 0.8862 (0.9784)	Prec@1 75.000 (71.825)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.085 (0.045)	BT: 0.094 (0.052)	Loss 0.9243 (0.9626)	Prec@1 75.000 (72.356)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.055)	BT: 0.004 (0.062)	Loss 0.9961 (0.9589)	Prec@1 69.531 (72.636)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.528 (0.060)	BT: 0.543 (0.067)	Loss 0.9922 (0.9563)	Prec@1 72.656 (72.671)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.062)	BT: 0.008 (0.069)	Loss 0.9150 (0.9578)	Prec@1 75.000 (72.616)	
Total train loss: 0.9577
Avg Loading time: 0.0620 seconds
Avg Batch time: 0.0687 seconds

Train time: 26.993834018707275
 * Prec@1 62.550 Prec@5 86.770 Loss 1.4268
Avg Loading time: 0.0880 seconds
Avg Batch time: 0.0925 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 7.437367677688599

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.090)	BT: 0.006 (0.097)	Loss 0.9448 (0.9543)	Prec@1 73.438 (72.606)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.088)	BT: 0.005 (0.095)	Loss 1.2227 (0.9562)	Prec@1 69.531 (72.586)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.083)	BT: 0.004 (0.090)	Loss 0.7842 (0.9560)	Prec@1 82.812 (72.636)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.084)	BT: 0.006 (0.091)	Loss 0.8203 (0.9535)	Prec@1 71.875 (72.656)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.082)	BT: 0.008 (0.089)	Loss 0.9282 (0.9551)	Prec@1 71.094 (72.686)	
Total train loss: 0.9550
Avg Loading time: 0.0819 seconds
Avg Batch time: 0.0887 seconds

Train time: 34.80610227584839
 * Prec@1 62.090 Prec@5 86.840 Loss 1.4268
Avg Loading time: 0.0869 seconds
Avg Batch time: 0.0918 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 7.352536678314209

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.086)	BT: 0.005 (0.093)	Loss 0.9531 (0.9639)	Prec@1 71.094 (72.105)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.062 (0.088)	BT: 0.070 (0.095)	Loss 1.0244 (0.9609)	Prec@1 71.094 (72.381)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.087)	BT: 0.011 (0.094)	Loss 0.9233 (0.9544)	Prec@1 70.312 (72.589)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.087)	BT: 0.009 (0.095)	Loss 1.0566 (0.9597)	Prec@1 65.625 (72.526)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.087)	BT: 0.004 (0.094)	Loss 1.0078 (0.9574)	Prec@1 69.531 (72.642)	
Total train loss: 0.9581
Avg Loading time: 0.0863 seconds
Avg Batch time: 0.0934 seconds

Train time: 36.640599727630615
 * Prec@1 62.570 Prec@5 86.630 Loss 1.4316
Avg Loading time: 0.0841 seconds
Avg Batch time: 0.0886 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 7.121572017669678

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.095)	BT: 0.005 (0.101)	Loss 1.0859 (0.9699)	Prec@1 62.500 (72.135)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.092)	BT: 0.007 (0.098)	Loss 0.8398 (0.9625)	Prec@1 74.219 (72.301)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.090)	BT: 0.011 (0.097)	Loss 0.9790 (0.9553)	Prec@1 74.219 (72.746)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.087)	BT: 0.004 (0.094)	Loss 0.9126 (0.9567)	Prec@1 76.562 (72.584)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.086)	BT: 0.006 (0.093)	Loss 1.0107 (0.9569)	Prec@1 67.188 (72.642)	
Total train loss: 0.9574
Avg Loading time: 0.0855 seconds
Avg Batch time: 0.0926 seconds

Train time: 36.34218192100525
 * Prec@1 62.060 Prec@5 86.650 Loss 1.4297
Avg Loading time: 0.1031 seconds
Avg Batch time: 0.1078 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 8.670859575271606

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.088)	BT: 0.004 (0.094)	Loss 0.9141 (0.9303)	Prec@1 74.219 (73.588)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.082)	BT: 0.005 (0.088)	Loss 0.8184 (0.9512)	Prec@1 75.781 (72.907)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.142 (0.081)	BT: 0.148 (0.088)	Loss 1.0742 (0.9558)	Prec@1 70.312 (72.796)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.081)	BT: 0.005 (0.088)	Loss 0.9868 (0.9551)	Prec@1 71.875 (72.651)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.084)	BT: 0.007 (0.091)	Loss 0.9624 (0.9529)	Prec@1 71.875 (72.708)	
Total train loss: 0.9535
Avg Loading time: 0.0841 seconds
Avg Batch time: 0.0906 seconds

Train time: 35.56424140930176
 * Prec@1 62.340 Prec@5 86.710 Loss 1.4307
Avg Loading time: 0.0678 seconds
Avg Batch time: 0.0726 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 5.8951873779296875

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.083)	BT: 0.004 (0.090)	Loss 1.0332 (0.9687)	Prec@1 75.000 (72.716)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.078)	BT: 0.006 (0.086)	Loss 1.0391 (0.9602)	Prec@1 70.312 (72.917)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.083)	BT: 0.008 (0.091)	Loss 0.8413 (0.9645)	Prec@1 72.656 (72.763)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.084)	BT: 0.019 (0.092)	Loss 0.9380 (0.9579)	Prec@1 71.875 (72.869)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.085)	BT: 0.006 (0.092)	Loss 0.8032 (0.9577)	Prec@1 75.781 (72.800)	
Total train loss: 0.9578
Avg Loading time: 0.0844 seconds
Avg Batch time: 0.0918 seconds

Train time: 36.027965784072876
 * Prec@1 62.470 Prec@5 86.860 Loss 1.4316
Avg Loading time: 0.0830 seconds
Avg Batch time: 0.0891 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 7.166704893112183

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.102)	BT: 0.005 (0.109)	Loss 0.9370 (0.9535)	Prec@1 72.656 (72.576)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.097)	BT: 0.006 (0.104)	Loss 0.8296 (0.9585)	Prec@1 78.125 (72.666)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.095)	BT: 0.011 (0.102)	Loss 0.9580 (0.9526)	Prec@1 76.562 (72.780)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.093)	BT: 0.006 (0.100)	Loss 0.7500 (0.9590)	Prec@1 76.562 (72.551)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.090)	BT: 0.004 (0.097)	Loss 0.9604 (0.9572)	Prec@1 71.875 (72.576)	
Total train loss: 0.9576
Avg Loading time: 0.0900 seconds
Avg Batch time: 0.0966 seconds

Train time: 37.84655237197876
 * Prec@1 62.090 Prec@5 86.780 Loss 1.4277
Avg Loading time: 0.0759 seconds
Avg Batch time: 0.0808 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 6.47189474105835

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.108)	BT: 0.004 (0.114)	Loss 1.0117 (0.9780)	Prec@1 68.750 (71.895)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.120 (0.082)	BT: 0.125 (0.089)	Loss 1.1201 (0.9734)	Prec@1 71.094 (72.125)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.073)	BT: 0.004 (0.079)	Loss 0.9033 (0.9653)	Prec@1 74.219 (72.269)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.067)	BT: 0.006 (0.073)	Loss 1.0635 (0.9629)	Prec@1 66.406 (72.333)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.063)	BT: 0.003 (0.069)	Loss 1.1025 (0.9621)	Prec@1 67.969 (72.416)	
Total train loss: 0.9621
Avg Loading time: 0.0629 seconds
Avg Batch time: 0.0689 seconds

Train time: 27.021665334701538
 * Prec@1 62.450 Prec@5 86.690 Loss 1.4316
Avg Loading time: 0.0711 seconds
Avg Batch time: 0.0755 seconds

Best acc: 62.830
--------------------------------------------------------------------------------
Test time: 6.068292856216431

