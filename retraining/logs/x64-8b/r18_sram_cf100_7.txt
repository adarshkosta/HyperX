
      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.005
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 7
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar100/resnet18
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/train/relu7
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar100/resnet18/test/relu7
ResNet18(
  (conv8): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): QConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): QConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): QConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): QConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=512, out_features=100, bias=False)
  (bn19): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 1.040 Prec@5 4.710 Loss 4.6055
Avg Loading time: 0.0513 seconds
Avg Batch time: 0.0926 seconds

Pre-trained Prec@1 with 7 layers frozen: 1.0399999618530273 	 Loss: 4.60546875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.005	DT: 0.000 (0.035)	BT: 0.051 (0.095)	Loss 2.7871 (3.5019)	Prec@1 32.812 (24.549)	
Epoch: [0][155/391]	LR: 0.005	DT: 0.001 (0.026)	BT: 0.065 (0.089)	Loss 2.2891 (2.9541)	Prec@1 54.688 (37.114)	
Epoch: [0][233/391]	LR: 0.005	DT: 0.000 (0.020)	BT: 0.060 (0.084)	Loss 2.1934 (2.7278)	Prec@1 58.594 (42.415)	
Epoch: [0][311/391]	LR: 0.005	DT: 0.038 (0.018)	BT: 0.079 (0.082)	Loss 2.2617 (2.6057)	Prec@1 54.688 (45.538)	
Epoch: [0][389/391]	LR: 0.005	DT: 0.000 (0.018)	BT: 0.053 (0.082)	Loss 2.2969 (2.5462)	Prec@1 59.375 (47.594)	
Total train loss: 2.5455
Avg Loading time: 0.0182 seconds
Avg Batch time: 0.0821 seconds

Train time: 32.23846793174744
 * Prec@1 56.080 Prec@5 85.170 Loss 2.1934
Avg Loading time: 0.0516 seconds
Avg Batch time: 0.0773 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 10.246554374694824

Epoch: [1][77/391]	LR: 0.005	DT: 0.000 (0.022)	BT: 0.047 (0.086)	Loss 2.0332 (2.2675)	Prec@1 60.938 (56.360)	
Epoch: [1][155/391]	LR: 0.005	DT: 0.048 (0.019)	BT: 0.117 (0.083)	Loss 1.9912 (2.2211)	Prec@1 65.625 (56.290)	
Epoch: [1][233/391]	LR: 0.005	DT: 0.115 (0.017)	BT: 0.168 (0.080)	Loss 2.1328 (2.1967)	Prec@1 56.250 (55.779)	
Epoch: [1][311/391]	LR: 0.005	DT: 0.000 (0.013)	BT: 0.042 (0.076)	Loss 1.8545 (2.1669)	Prec@1 62.500 (55.787)	
Epoch: [1][389/391]	LR: 0.005	DT: 0.000 (0.013)	BT: 0.086 (0.075)	Loss 2.2441 (2.1520)	Prec@1 51.562 (55.661)	
Total train loss: 2.1520
Avg Loading time: 0.0129 seconds
Avg Batch time: 0.0753 seconds

Train time: 29.587021350860596
 * Prec@1 52.320 Prec@5 80.690 Loss 1.9932
Avg Loading time: 0.0432 seconds
Avg Batch time: 0.0662 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 8.066093444824219

Epoch: [2][77/391]	LR: 0.005	DT: 0.000 (0.013)	BT: 0.053 (0.067)	Loss 1.9287 (2.0347)	Prec@1 55.469 (55.158)	
Epoch: [2][155/391]	LR: 0.005	DT: 0.000 (0.013)	BT: 0.089 (0.070)	Loss 2.5840 (2.0857)	Prec@1 53.125 (54.202)	
Epoch: [2][233/391]	LR: 0.005	DT: 0.000 (0.017)	BT: 0.080 (0.075)	Loss 2.3828 (2.1852)	Prec@1 50.781 (52.554)	
Epoch: [2][311/391]	LR: 0.005	DT: 0.057 (0.016)	BT: 0.115 (0.075)	Loss 2.2988 (2.1993)	Prec@1 49.219 (51.998)	
Epoch: [2][389/391]	LR: 0.005	DT: 0.040 (0.016)	BT: 0.079 (0.076)	Loss 1.9014 (2.1824)	Prec@1 58.594 (52.135)	
Total train loss: 2.1823
Avg Loading time: 0.0158 seconds
Avg Batch time: 0.0756 seconds

Train time: 29.662309408187866
 * Prec@1 53.850 Prec@5 83.430 Loss 2.0059
Avg Loading time: 0.0504 seconds
Avg Batch time: 0.0783 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 7.126008749008179

Epoch: [3][77/391]	LR: 0.005	DT: 0.000 (0.024)	BT: 0.078 (0.089)	Loss 1.8418 (2.0229)	Prec@1 64.062 (53.776)	
Epoch: [3][155/391]	LR: 0.005	DT: 0.418 (0.071)	BT: 0.469 (0.129)	Loss 2.0312 (2.0262)	Prec@1 54.688 (53.476)	
Epoch: [3][233/391]	LR: 0.005	DT: 0.041 (0.116)	BT: 0.083 (0.171)	Loss 1.9443 (2.0289)	Prec@1 58.594 (53.242)	
Epoch: [3][311/391]	LR: 0.005	DT: 0.245 (0.217)	BT: 0.290 (0.270)	Loss 1.9570 (2.0231)	Prec@1 54.688 (53.453)	
Epoch: [3][389/391]	LR: 0.005	DT: 0.000 (0.277)	BT: 0.045 (0.329)	Loss 2.0391 (2.0206)	Prec@1 51.562 (53.365)	
Total train loss: 2.0209
Avg Loading time: 0.2768 seconds
Avg Batch time: 0.3287 seconds

Train time: 128.6143343448639
 * Prec@1 53.980 Prec@5 83.550 Loss 1.9375
Avg Loading time: 0.7903 seconds
Avg Batch time: 0.8081 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 66.53994584083557

Epoch: [4][77/391]	LR: 0.005	DT: 0.000 (0.732)	BT: 0.038 (0.777)	Loss 1.9160 (1.9442)	Prec@1 53.906 (54.157)	
Epoch: [4][155/391]	LR: 0.005	DT: 0.000 (0.738)	BT: 0.051 (0.785)	Loss 1.9268 (1.9441)	Prec@1 54.688 (54.217)	
Epoch: [4][233/391]	LR: 0.005	DT: 0.758 (0.766)	BT: 0.814 (0.814)	Loss 1.8457 (1.9372)	Prec@1 56.250 (54.487)	
Epoch: [4][311/391]	LR: 0.005	DT: 0.000 (0.722)	BT: 0.041 (0.770)	Loss 1.6650 (1.9256)	Prec@1 58.594 (54.620)	
Epoch: [4][389/391]	LR: 0.005	DT: 0.000 (0.641)	BT: 0.038 (0.689)	Loss 1.7549 (1.9184)	Prec@1 56.250 (54.736)	
Total train loss: 1.9183
Avg Loading time: 0.6397 seconds
Avg Batch time: 0.6874 seconds

Train time: 268.8390882015228
 * Prec@1 55.670 Prec@5 84.900 Loss 1.8564
Avg Loading time: 0.0882 seconds
Avg Batch time: 0.1143 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 13.20024061203003

Epoch: [5][77/391]	LR: 0.005	DT: 0.000 (0.023)	BT: 0.086 (0.088)	Loss 1.9229 (1.8577)	Prec@1 54.688 (55.679)	
Epoch: [5][155/391]	LR: 0.005	DT: 0.072 (0.022)	BT: 0.120 (0.085)	Loss 1.9043 (1.8851)	Prec@1 63.281 (54.607)	
Epoch: [5][233/391]	LR: 0.005	DT: 0.000 (0.019)	BT: 0.053 (0.083)	Loss 2.2363 (1.9052)	Prec@1 49.219 (54.514)	
Epoch: [5][311/391]	LR: 0.005	DT: 0.005 (0.019)	BT: 0.061 (0.082)	Loss 1.8447 (1.9106)	Prec@1 58.594 (54.502)	
Epoch: [5][389/391]	LR: 0.005	DT: 0.000 (0.019)	BT: 0.039 (0.081)	Loss 1.9873 (1.9066)	Prec@1 55.469 (54.732)	
Total train loss: 1.9064
Avg Loading time: 0.0189 seconds
Avg Batch time: 0.0811 seconds

Train time: 31.832486867904663
 * Prec@1 54.900 Prec@5 84.410 Loss 1.8320
Avg Loading time: 0.0566 seconds
Avg Batch time: 0.0813 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 9.121299266815186

Epoch: [6][77/391]	LR: 0.005	DT: 0.012 (0.021)	BT: 0.077 (0.079)	Loss 3.4043 (2.0790)	Prec@1 29.688 (52.204)	
Epoch: [6][155/391]	LR: 0.005	DT: 0.000 (0.021)	BT: 0.072 (0.081)	Loss 3.4492 (2.8253)	Prec@1 20.312 (36.118)	
Epoch: [6][233/391]	LR: 0.005	DT: 0.000 (0.018)	BT: 0.039 (0.077)	Loss 3.0820 (2.9536)	Prec@1 22.656 (32.098)	
Epoch: [6][311/391]	LR: 0.005	DT: 0.000 (0.018)	BT: 0.097 (0.076)	Loss 2.9316 (2.9787)	Prec@1 25.781 (30.719)	
Epoch: [6][389/391]	LR: 0.005	DT: 0.022 (0.018)	BT: 0.062 (0.076)	Loss 2.9062 (2.9680)	Prec@1 29.688 (30.317)	
Total train loss: 2.9681
Avg Loading time: 0.0183 seconds
Avg Batch time: 0.0760 seconds

Train time: 29.904502630233765
 * Prec@1 6.040 Prec@5 17.200 Loss inf
Avg Loading time: 0.0614 seconds
Avg Batch time: 0.0882 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 7.728240728378296

Epoch: [7][77/391]	LR: 0.005	DT: 0.122 (0.024)	BT: 0.182 (0.091)	Loss 2.7266 (2.8522)	Prec@1 32.812 (31.230)	
Epoch: [7][155/391]	LR: 0.005	DT: 0.000 (0.021)	BT: 0.077 (0.086)	Loss 2.7520 (2.8277)	Prec@1 32.031 (31.545)	
Epoch: [7][233/391]	LR: 0.005	DT: 0.110 (0.021)	BT: 0.164 (0.084)	Loss 2.9199 (2.8341)	Prec@1 29.688 (31.347)	
Epoch: [7][311/391]	LR: 0.005	DT: 0.000 (0.019)	BT: 0.052 (0.082)	Loss 2.8496 (2.8210)	Prec@1 27.344 (31.515)	
Epoch: [7][389/391]	LR: 0.005	DT: 0.000 (0.019)	BT: 0.045 (0.080)	Loss 2.7559 (2.8026)	Prec@1 29.688 (31.715)	
Total train loss: 2.8023
Avg Loading time: 0.0186 seconds
Avg Batch time: 0.0804 seconds

Train time: 31.55037808418274
 * Prec@1 32.800 Prec@5 65.280 Loss 2.7188
Avg Loading time: 0.0539 seconds
Avg Batch time: 0.0776 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 6.783262014389038

Epoch: [8][77/391]	LR: 0.005	DT: 0.000 (0.022)	BT: 0.056 (0.080)	Loss 2.4961 (2.6830)	Prec@1 35.156 (33.514)	
Epoch: [8][155/391]	LR: 0.005	DT: 0.013 (0.020)	BT: 0.061 (0.078)	Loss 2.7070 (2.6848)	Prec@1 37.500 (33.739)	
Epoch: [8][233/391]	LR: 0.005	DT: 0.000 (0.016)	BT: 0.087 (0.074)	Loss 2.8379 (2.6790)	Prec@1 24.219 (33.871)	
Epoch: [8][311/391]	LR: 0.005	DT: 0.000 (0.015)	BT: 0.051 (0.073)	Loss 2.7109 (2.6691)	Prec@1 33.594 (34.287)	
Epoch: [8][389/391]	LR: 0.005	DT: 0.000 (0.015)	BT: 0.048 (0.073)	Loss 2.6484 (2.6586)	Prec@1 39.062 (34.704)	
Total train loss: 2.6588
Avg Loading time: 0.0150 seconds
Avg Batch time: 0.0734 seconds

Train time: 28.84214949607849
 * Prec@1 35.230 Prec@5 67.300 Loss 2.6465
Avg Loading time: 0.0589 seconds
Avg Batch time: 0.0835 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 7.948774099349976

Epoch: [9][77/391]	LR: 0.005	DT: 0.000 (0.025)	BT: 0.078 (0.086)	Loss 2.3418 (2.6199)	Prec@1 41.406 (35.146)	
Epoch: [9][155/391]	LR: 0.005	DT: 0.000 (0.023)	BT: 0.084 (0.084)	Loss 2.3984 (2.6059)	Prec@1 42.969 (35.727)	
Epoch: [9][233/391]	LR: 0.005	DT: 0.000 (0.020)	BT: 0.057 (0.082)	Loss 2.5840 (2.5817)	Prec@1 35.938 (36.141)	
Epoch: [9][311/391]	LR: 0.005	DT: 0.078 (0.020)	BT: 0.122 (0.081)	Loss 2.4238 (2.5641)	Prec@1 46.875 (36.458)	
Epoch: [9][389/391]	LR: 0.005	DT: 0.050 (0.019)	BT: 0.089 (0.079)	Loss 2.7539 (2.5526)	Prec@1 32.031 (36.731)	
Total train loss: 2.5523
Avg Loading time: 0.0191 seconds
Avg Batch time: 0.0792 seconds

Train time: 31.041898012161255
 * Prec@1 30.700 Prec@5 60.630 Loss 2.8379
Avg Loading time: 0.0504 seconds
Avg Batch time: 0.0744 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 6.627393484115601

Epoch: [10][77/391]	LR: 0.001	DT: 0.000 (0.023)	BT: 0.052 (0.083)	Loss 2.3926 (2.4800)	Prec@1 37.500 (38.722)	
Epoch: [10][155/391]	LR: 0.001	DT: 0.000 (0.015)	BT: 0.067 (0.075)	Loss 2.5879 (2.4809)	Prec@1 35.156 (38.897)	
Epoch: [10][233/391]	LR: 0.001	DT: 0.000 (0.014)	BT: 0.079 (0.075)	Loss 2.3379 (2.4849)	Prec@1 39.844 (38.618)	
Epoch: [10][311/391]	LR: 0.001	DT: 0.000 (0.014)	BT: 0.060 (0.076)	Loss 2.4824 (2.4892)	Prec@1 31.250 (38.271)	
Epoch: [10][389/391]	LR: 0.001	DT: 0.021 (0.014)	BT: 0.059 (0.076)	Loss 2.5371 (2.4867)	Prec@1 35.156 (38.223)	
Total train loss: 2.4865
Avg Loading time: 0.0137 seconds
Avg Batch time: 0.0756 seconds

Train time: 29.65522527694702
 * Prec@1 38.510 Prec@5 71.990 Loss 2.4609
Avg Loading time: 0.0573 seconds
Avg Batch time: 0.0816 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 8.87313461303711

Epoch: [11][77/391]	LR: 0.001	DT: 0.000 (0.028)	BT: 0.069 (0.093)	Loss 2.4551 (2.4972)	Prec@1 35.156 (38.752)	
Epoch: [11][155/391]	LR: 0.001	DT: 0.045 (0.024)	BT: 0.112 (0.088)	Loss 2.3164 (2.4888)	Prec@1 41.406 (38.592)	
Epoch: [11][233/391]	LR: 0.001	DT: 0.000 (0.022)	BT: 0.073 (0.085)	Loss 2.2969 (2.4796)	Prec@1 37.500 (38.635)	
Epoch: [11][311/391]	LR: 0.001	DT: 0.000 (0.020)	BT: 0.065 (0.084)	Loss 2.6074 (2.4729)	Prec@1 41.406 (38.544)	
Epoch: [11][389/391]	LR: 0.001	DT: 0.000 (0.018)	BT: 0.052 (0.080)	Loss 2.6406 (2.4714)	Prec@1 30.469 (38.602)	
Total train loss: 2.4715
Avg Loading time: 0.0179 seconds
Avg Batch time: 0.0797 seconds

Train time: 31.301723957061768
 * Prec@1 38.660 Prec@5 72.040 Loss 2.4629
Avg Loading time: 0.0479 seconds
Avg Batch time: 0.0721 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 8.61870813369751

Epoch: [12][77/391]	LR: 0.001	DT: 0.000 (0.024)	BT: 0.076 (0.085)	Loss 2.5039 (2.4658)	Prec@1 37.500 (38.371)	
Epoch: [12][155/391]	LR: 0.001	DT: 0.000 (0.019)	BT: 0.041 (0.081)	Loss 2.7051 (2.4635)	Prec@1 31.250 (38.602)	
Epoch: [12][233/391]	LR: 0.001	DT: 0.000 (0.019)	BT: 0.088 (0.081)	Loss 2.4414 (2.4638)	Prec@1 41.406 (38.602)	
Epoch: [12][311/391]	LR: 0.001	DT: 0.252 (0.020)	BT: 0.327 (0.082)	Loss 2.5859 (2.4670)	Prec@1 35.938 (38.564)	
Epoch: [12][389/391]	LR: 0.001	DT: 0.000 (0.018)	BT: 0.049 (0.081)	Loss 2.4023 (2.4652)	Prec@1 39.062 (38.520)	
Total train loss: 2.4651
Avg Loading time: 0.0183 seconds
Avg Batch time: 0.0806 seconds

Train time: 31.631966829299927
 * Prec@1 38.780 Prec@5 72.420 Loss 2.4551
Avg Loading time: 0.0578 seconds
Avg Batch time: 0.0818 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 7.531237840652466

Epoch: [13][77/391]	LR: 0.001	DT: 0.000 (0.017)	BT: 0.060 (0.085)	Loss 2.6328 (2.4607)	Prec@1 35.938 (38.692)	
Epoch: [13][155/391]	LR: 0.001	DT: 0.000 (0.017)	BT: 0.047 (0.082)	Loss 2.5625 (2.4560)	Prec@1 40.625 (38.782)	
Epoch: [13][233/391]	LR: 0.001	DT: 0.000 (0.017)	BT: 0.075 (0.080)	Loss 2.3965 (2.4553)	Prec@1 41.406 (38.645)	
Epoch: [13][311/391]	LR: 0.001	DT: 0.054 (0.014)	BT: 0.101 (0.076)	Loss 2.3066 (2.4602)	Prec@1 45.312 (38.474)	
Epoch: [13][389/391]	LR: 0.001	DT: 0.000 (0.013)	BT: 0.039 (0.076)	Loss 2.6211 (2.4565)	Prec@1 32.031 (38.622)	
Total train loss: 2.4566
Avg Loading time: 0.0132 seconds
Avg Batch time: 0.0758 seconds

Train time: 29.759056329727173
 * Prec@1 38.810 Prec@5 72.450 Loss 2.4473
Avg Loading time: 0.0483 seconds
Avg Batch time: 0.0660 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 10.242430448532104

Epoch: [14][77/391]	LR: 0.001	DT: 0.060 (0.028)	BT: 0.102 (0.089)	Loss 2.4375 (2.4605)	Prec@1 37.500 (38.492)	
Epoch: [14][155/391]	LR: 0.001	DT: 0.000 (0.022)	BT: 0.049 (0.083)	Loss 2.3262 (2.4568)	Prec@1 41.406 (38.557)	
Epoch: [14][233/391]	LR: 0.001	DT: 0.034 (0.020)	BT: 0.082 (0.082)	Loss 2.5273 (2.4509)	Prec@1 39.062 (38.942)	
Epoch: [14][311/391]	LR: 0.001	DT: 0.000 (0.018)	BT: 0.061 (0.081)	Loss 2.3906 (2.4543)	Prec@1 39.844 (38.739)	
Epoch: [14][389/391]	LR: 0.001	DT: 0.000 (0.017)	BT: 0.043 (0.080)	Loss 2.4512 (2.4501)	Prec@1 31.250 (38.866)	
Total train loss: 2.4506
Avg Loading time: 0.0169 seconds
Avg Batch time: 0.0795 seconds

Train time: 31.193854570388794
 * Prec@1 38.740 Prec@5 72.680 Loss 2.4414
Avg Loading time: 0.0539 seconds
Avg Batch time: 0.0800 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 7.2382941246032715

Epoch: [15][77/391]	LR: 0.001	DT: 0.000 (0.030)	BT: 0.040 (0.091)	Loss 2.4551 (2.4374)	Prec@1 35.156 (39.383)	
Epoch: [15][155/391]	LR: 0.001	DT: 0.156 (0.023)	BT: 0.216 (0.084)	Loss 2.3672 (2.4462)	Prec@1 39.062 (39.293)	
Epoch: [15][233/391]	LR: 0.001	DT: 0.054 (0.021)	BT: 0.097 (0.081)	Loss 2.5020 (2.4426)	Prec@1 38.281 (39.089)	
Epoch: [15][311/391]	LR: 0.001	DT: 0.000 (0.018)	BT: 0.059 (0.078)	Loss 2.3574 (2.4441)	Prec@1 39.062 (38.997)	
Epoch: [15][389/391]	LR: 0.001	DT: 0.000 (0.018)	BT: 0.041 (0.077)	Loss 2.6113 (2.4436)	Prec@1 40.625 (39.030)	
Total train loss: 2.4439
Avg Loading time: 0.0184 seconds
Avg Batch time: 0.0773 seconds

Train time: 30.343660354614258
 * Prec@1 39.110 Prec@5 72.820 Loss 2.4395
Avg Loading time: 0.0468 seconds
Avg Batch time: 0.0632 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 13.20658540725708

Epoch: [16][77/391]	LR: 0.001	DT: 0.000 (0.030)	BT: 0.065 (0.093)	Loss 2.4785 (2.4311)	Prec@1 38.281 (39.273)	
Epoch: [16][155/391]	LR: 0.001	DT: 0.006 (0.023)	BT: 0.076 (0.087)	Loss 2.2754 (2.4379)	Prec@1 43.750 (39.278)	
Epoch: [16][233/391]	LR: 0.001	DT: 0.036 (0.021)	BT: 0.093 (0.085)	Loss 2.2637 (2.4399)	Prec@1 44.531 (38.949)	
Epoch: [16][311/391]	LR: 0.001	DT: 0.000 (0.020)	BT: 0.058 (0.082)	Loss 2.6016 (2.4393)	Prec@1 33.594 (39.022)	
Epoch: [16][389/391]	LR: 0.001	DT: 0.045 (0.018)	BT: 0.097 (0.081)	Loss 2.0859 (2.4419)	Prec@1 50.781 (39.091)	
Total train loss: 2.4421
Avg Loading time: 0.0182 seconds
Avg Batch time: 0.0808 seconds

Train time: 31.729758262634277
 * Prec@1 39.140 Prec@5 73.010 Loss 2.4297
Avg Loading time: 0.0535 seconds
Avg Batch time: 0.0837 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 14.291659593582153

Epoch: [17][77/391]	LR: 0.001	DT: 0.073 (0.044)	BT: 0.128 (0.103)	Loss 2.3730 (2.4526)	Prec@1 38.281 (39.052)	
Epoch: [17][155/391]	LR: 0.001	DT: 0.000 (0.027)	BT: 0.064 (0.087)	Loss 2.2520 (2.4403)	Prec@1 43.750 (38.992)	
Epoch: [17][233/391]	LR: 0.001	DT: 0.000 (0.021)	BT: 0.054 (0.080)	Loss 2.5430 (2.4378)	Prec@1 35.156 (39.199)	
Epoch: [17][311/391]	LR: 0.001	DT: 0.000 (0.016)	BT: 0.046 (0.074)	Loss 2.4180 (2.4382)	Prec@1 42.969 (39.190)	
Epoch: [17][389/391]	LR: 0.001	DT: 0.000 (0.017)	BT: 0.045 (0.074)	Loss 2.4219 (2.4357)	Prec@1 42.969 (39.191)	
Total train loss: 2.4355
Avg Loading time: 0.0166 seconds
Avg Batch time: 0.0739 seconds

Train time: 29.04375696182251
 * Prec@1 39.140 Prec@5 73.030 Loss 2.4258
Avg Loading time: 0.0619 seconds
Avg Batch time: 0.0868 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 13.900579452514648

Epoch: [18][77/391]	LR: 0.001	DT: 0.000 (0.029)	BT: 0.053 (0.088)	Loss 2.4414 (2.4411)	Prec@1 39.844 (38.942)	
Epoch: [18][155/391]	LR: 0.001	DT: 0.000 (0.021)	BT: 0.056 (0.080)	Loss 2.5020 (2.4437)	Prec@1 36.719 (38.882)	
Epoch: [18][233/391]	LR: 0.001	DT: 0.000 (0.021)	BT: 0.040 (0.081)	Loss 2.4844 (2.4400)	Prec@1 46.875 (39.126)	
Epoch: [18][311/391]	LR: 0.001	DT: 0.000 (0.020)	BT: 0.071 (0.080)	Loss 2.5078 (2.4336)	Prec@1 35.156 (39.275)	
Epoch: [18][389/391]	LR: 0.001	DT: 0.000 (0.018)	BT: 0.050 (0.079)	Loss 2.3516 (2.4317)	Prec@1 34.375 (39.291)	
Total train loss: 2.4317
Avg Loading time: 0.0184 seconds
Avg Batch time: 0.0790 seconds

Train time: 31.039725065231323
 * Prec@1 39.200 Prec@5 73.000 Loss 2.4375
Avg Loading time: 0.0513 seconds
Avg Batch time: 0.0755 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 7.3533244132995605

Epoch: [19][77/391]	LR: 0.001	DT: 0.000 (0.023)	BT: 0.057 (0.083)	Loss 2.4238 (2.4245)	Prec@1 39.062 (38.662)	
Epoch: [19][155/391]	LR: 0.001	DT: 0.000 (0.014)	BT: 0.052 (0.071)	Loss 2.3223 (2.4283)	Prec@1 46.875 (38.957)	
Epoch: [19][233/391]	LR: 0.001	DT: 0.080 (0.015)	BT: 0.140 (0.070)	Loss 2.3770 (2.4245)	Prec@1 40.625 (39.206)	
Epoch: [19][311/391]	LR: 0.001	DT: 0.014 (0.016)	BT: 0.072 (0.072)	Loss 2.4395 (2.4297)	Prec@1 36.719 (39.268)	
Epoch: [19][389/391]	LR: 0.001	DT: 0.000 (0.017)	BT: 0.054 (0.073)	Loss 2.3340 (2.4259)	Prec@1 38.281 (39.385)	
Total train loss: 2.4258
Avg Loading time: 0.0173 seconds
Avg Batch time: 0.0735 seconds

Train time: 28.850545644760132
 * Prec@1 39.330 Prec@5 73.180 Loss 2.4297
Avg Loading time: 0.0463 seconds
Avg Batch time: 0.0747 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 13.437094926834106

Epoch: [20][77/391]	LR: 0.0002	DT: 0.000 (0.027)	BT: 0.078 (0.088)	Loss 2.2578 (2.4352)	Prec@1 43.750 (39.083)	
Epoch: [20][155/391]	LR: 0.0002	DT: 0.000 (0.021)	BT: 0.055 (0.082)	Loss 2.5195 (2.4275)	Prec@1 46.094 (39.458)	
Epoch: [20][233/391]	LR: 0.0002	DT: 0.000 (0.019)	BT: 0.082 (0.080)	Loss 2.5527 (2.4232)	Prec@1 34.375 (39.560)	
Epoch: [20][311/391]	LR: 0.0002	DT: 0.000 (0.019)	BT: 0.071 (0.080)	Loss 2.1992 (2.4211)	Prec@1 46.094 (39.578)	
Epoch: [20][389/391]	LR: 0.0002	DT: 0.000 (0.016)	BT: 0.039 (0.076)	Loss 2.5098 (2.4190)	Prec@1 30.469 (39.523)	
Total train loss: 2.4186
Avg Loading time: 0.0159 seconds
Avg Batch time: 0.0760 seconds

Train time: 29.856557846069336
 * Prec@1 39.530 Prec@5 73.270 Loss 2.4219
Avg Loading time: 0.0484 seconds
Avg Batch time: 0.0762 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 7.302125930786133

Epoch: [21][77/391]	LR: 0.0002	DT: 0.000 (0.014)	BT: 0.056 (0.067)	Loss 2.3789 (2.3979)	Prec@1 42.969 (39.924)	
Epoch: [21][155/391]	LR: 0.0002	DT: 0.042 (0.012)	BT: 0.099 (0.069)	Loss 2.5527 (2.4020)	Prec@1 34.375 (40.069)	
Epoch: [21][233/391]	LR: 0.0002	DT: 0.000 (0.015)	BT: 0.048 (0.073)	Loss 2.3262 (2.4084)	Prec@1 36.719 (39.897)	
Epoch: [21][311/391]	LR: 0.0002	DT: 0.000 (0.015)	BT: 0.055 (0.074)	Loss 2.4570 (2.4167)	Prec@1 36.719 (39.789)	
Epoch: [21][389/391]	LR: 0.0002	DT: 0.000 (0.015)	BT: 0.070 (0.073)	Loss 2.5312 (2.4163)	Prec@1 32.812 (39.688)	
Total train loss: 2.4161
Avg Loading time: 0.0146 seconds
Avg Batch time: 0.0732 seconds

Train time: 28.774590730667114
 * Prec@1 39.340 Prec@5 73.450 Loss 2.4121
Avg Loading time: 0.0505 seconds
Avg Batch time: 0.0774 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 10.368260145187378

Epoch: [22][77/391]	LR: 0.0002	DT: 0.046 (0.025)	BT: 0.091 (0.090)	Loss 2.2988 (2.4172)	Prec@1 39.062 (39.002)	
Epoch: [22][155/391]	LR: 0.0002	DT: 0.000 (0.024)	BT: 0.064 (0.086)	Loss 2.2559 (2.4164)	Prec@1 47.656 (39.248)	
Epoch: [22][233/391]	LR: 0.0002	DT: 0.000 (0.023)	BT: 0.060 (0.085)	Loss 2.4473 (2.4161)	Prec@1 35.156 (39.223)	
Epoch: [22][311/391]	LR: 0.0002	DT: 0.000 (0.019)	BT: 0.052 (0.081)	Loss 2.2344 (2.4196)	Prec@1 44.531 (39.258)	
Epoch: [22][389/391]	LR: 0.0002	DT: 0.000 (0.019)	BT: 0.047 (0.080)	Loss 2.3477 (2.4170)	Prec@1 45.312 (39.537)	
Total train loss: 2.4170
Avg Loading time: 0.0189 seconds
Avg Batch time: 0.0800 seconds

Train time: 31.448344945907593
 * Prec@1 39.190 Prec@5 73.070 Loss 2.4258
Avg Loading time: 0.0497 seconds
Avg Batch time: 0.0710 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 11.837957382202148

Epoch: [23][77/391]	LR: 0.0002	DT: 0.000 (0.026)	BT: 0.040 (0.085)	Loss 2.5293 (2.4199)	Prec@1 33.594 (39.934)	
Epoch: [23][155/391]	LR: 0.0002	DT: 0.000 (0.023)	BT: 0.094 (0.082)	Loss 2.4727 (2.4159)	Prec@1 40.625 (39.874)	
Epoch: [23][233/391]	LR: 0.0002	DT: 0.000 (0.022)	BT: 0.060 (0.081)	Loss 2.6309 (2.4155)	Prec@1 32.812 (39.844)	
Epoch: [23][311/391]	LR: 0.0002	DT: 0.000 (0.020)	BT: 0.090 (0.081)	Loss 2.5059 (2.4210)	Prec@1 35.938 (39.596)	
Epoch: [23][389/391]	LR: 0.0002	DT: 0.000 (0.020)	BT: 0.039 (0.080)	Loss 2.3945 (2.4183)	Prec@1 39.844 (39.447)	
Total train loss: 2.4182
Avg Loading time: 0.0199 seconds
Avg Batch time: 0.0799 seconds

Train time: 31.381260871887207
 * Prec@1 39.100 Prec@5 73.240 Loss 2.4199
Avg Loading time: 0.0534 seconds
Avg Batch time: 0.0789 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 13.387102603912354

Epoch: [24][77/391]	LR: 0.0002	DT: 0.000 (0.025)	BT: 0.073 (0.094)	Loss 2.2461 (2.4278)	Prec@1 41.406 (39.363)	
Epoch: [24][155/391]	LR: 0.0002	DT: 0.000 (0.019)	BT: 0.065 (0.082)	Loss 2.4062 (2.4221)	Prec@1 34.375 (39.588)	
Epoch: [24][233/391]	LR: 0.0002	DT: 0.000 (0.016)	BT: 0.072 (0.078)	Loss 2.5605 (2.4173)	Prec@1 36.719 (39.710)	
Epoch: [24][311/391]	LR: 0.0002	DT: 0.000 (0.015)	BT: 0.038 (0.076)	Loss 2.3594 (2.4157)	Prec@1 40.625 (39.673)	
Epoch: [24][389/391]	LR: 0.0002	DT: 0.000 (0.014)	BT: 0.040 (0.075)	Loss 2.5566 (2.4187)	Prec@1 28.906 (39.519)	
Total train loss: 2.4187
Avg Loading time: 0.0140 seconds
Avg Batch time: 0.0749 seconds

Train time: 29.425554275512695
 * Prec@1 39.330 Prec@5 73.170 Loss 2.4219
Avg Loading time: 0.0510 seconds
Avg Batch time: 0.0819 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 11.09239149093628

Epoch: [25][77/391]	LR: 0.0002	DT: 0.000 (0.024)	BT: 0.047 (0.088)	Loss 2.3945 (2.4169)	Prec@1 33.594 (39.463)	
Epoch: [25][155/391]	LR: 0.0002	DT: 0.000 (0.017)	BT: 0.051 (0.082)	Loss 2.1914 (2.4149)	Prec@1 46.875 (39.729)	
Epoch: [25][233/391]	LR: 0.0002	DT: 0.000 (0.015)	BT: 0.050 (0.079)	Loss 2.4531 (2.4181)	Prec@1 38.281 (39.647)	
Epoch: [25][311/391]	LR: 0.0002	DT: 0.000 (0.014)	BT: 0.071 (0.079)	Loss 2.5430 (2.4164)	Prec@1 40.625 (39.694)	
Epoch: [25][389/391]	LR: 0.0002	DT: 0.000 (0.014)	BT: 0.048 (0.078)	Loss 2.4238 (2.4171)	Prec@1 42.188 (39.613)	
Total train loss: 2.4172
Avg Loading time: 0.0140 seconds
Avg Batch time: 0.0783 seconds

Train time: 30.715779781341553
 * Prec@1 39.400 Prec@5 73.140 Loss 2.4199
Avg Loading time: 0.0579 seconds
Avg Batch time: 0.0877 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 11.112536907196045

Epoch: [26][77/391]	LR: 0.0002	DT: 0.000 (0.026)	BT: 0.039 (0.084)	Loss 2.4863 (2.4186)	Prec@1 36.719 (39.934)	
Epoch: [26][155/391]	LR: 0.0002	DT: 0.000 (0.015)	BT: 0.064 (0.074)	Loss 2.5781 (2.4219)	Prec@1 39.062 (39.834)	
Epoch: [26][233/391]	LR: 0.0002	DT: 0.000 (0.011)	BT: 0.055 (0.070)	Loss 2.3457 (2.4179)	Prec@1 45.312 (39.974)	
Epoch: [26][311/391]	LR: 0.0002	DT: 0.121 (0.012)	BT: 0.171 (0.071)	Loss 2.4258 (2.4169)	Prec@1 41.406 (39.804)	
Epoch: [26][389/391]	LR: 0.0002	DT: 0.000 (0.012)	BT: 0.039 (0.072)	Loss 2.5664 (2.4187)	Prec@1 30.469 (39.698)	
Total train loss: 2.4185
Avg Loading time: 0.0119 seconds
Avg Batch time: 0.0718 seconds

Train time: 28.203734636306763
 * Prec@1 39.120 Prec@5 73.240 Loss 2.4180
Avg Loading time: 0.0490 seconds
Avg Batch time: 0.0772 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 6.8358259201049805

Epoch: [27][77/391]	LR: 0.0002	DT: 0.000 (0.026)	BT: 0.076 (0.090)	Loss 2.4570 (2.4342)	Prec@1 36.719 (39.323)	
Epoch: [27][155/391]	LR: 0.0002	DT: 0.000 (0.021)	BT: 0.059 (0.086)	Loss 2.1523 (2.4197)	Prec@1 52.344 (39.538)	
Epoch: [27][233/391]	LR: 0.0002	DT: 0.000 (0.018)	BT: 0.066 (0.084)	Loss 2.3359 (2.4240)	Prec@1 40.625 (39.416)	
Epoch: [27][311/391]	LR: 0.0002	DT: 0.096 (0.019)	BT: 0.164 (0.083)	Loss 2.4160 (2.4231)	Prec@1 39.062 (39.386)	
Epoch: [27][389/391]	LR: 0.0002	DT: 0.000 (0.019)	BT: 0.039 (0.082)	Loss 2.5234 (2.4185)	Prec@1 38.281 (39.485)	
Total train loss: 2.4187
Avg Loading time: 0.0186 seconds
Avg Batch time: 0.0820 seconds

Train time: 32.1879448890686
 * Prec@1 39.370 Prec@5 73.310 Loss 2.4121
Avg Loading time: 0.0553 seconds
Avg Batch time: 0.0821 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 15.418893814086914

Epoch: [28][77/391]	LR: 0.0002	DT: 0.000 (0.012)	BT: 0.077 (0.064)	Loss 2.2676 (2.4103)	Prec@1 49.219 (40.455)	
Epoch: [28][155/391]	LR: 0.0002	DT: 0.146 (0.014)	BT: 0.242 (0.069)	Loss 2.3398 (2.4173)	Prec@1 42.188 (40.320)	
Epoch: [28][233/391]	LR: 0.0002	DT: 0.080 (0.013)	BT: 0.120 (0.070)	Loss 2.2441 (2.4197)	Prec@1 50.000 (40.007)	
Epoch: [28][311/391]	LR: 0.0002	DT: 0.000 (0.014)	BT: 0.102 (0.072)	Loss 2.3672 (2.4199)	Prec@1 39.062 (39.871)	
Epoch: [28][389/391]	LR: 0.0002	DT: 0.000 (0.015)	BT: 0.054 (0.073)	Loss 2.5938 (2.4180)	Prec@1 34.375 (39.796)	
Total train loss: 2.4181
Avg Loading time: 0.0148 seconds
Avg Batch time: 0.0729 seconds

Train time: 28.602985620498657
 * Prec@1 39.040 Prec@5 73.210 Loss 2.4199
Avg Loading time: 0.0482 seconds
Avg Batch time: 0.0770 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 10.30865740776062

Epoch: [29][77/391]	LR: 0.0002	DT: 0.101 (0.021)	BT: 0.177 (0.087)	Loss 2.4102 (2.4247)	Prec@1 34.375 (39.363)	
Epoch: [29][155/391]	LR: 0.0002	DT: 0.000 (0.018)	BT: 0.063 (0.083)	Loss 2.6445 (2.4262)	Prec@1 35.938 (39.533)	
Epoch: [29][233/391]	LR: 0.0002	DT: 0.000 (0.016)	BT: 0.065 (0.079)	Loss 2.4453 (2.4186)	Prec@1 35.938 (39.680)	
Epoch: [29][311/391]	LR: 0.0002	DT: 0.001 (0.017)	BT: 0.066 (0.079)	Loss 2.3379 (2.4196)	Prec@1 39.844 (39.673)	
Epoch: [29][389/391]	LR: 0.0002	DT: 0.000 (0.016)	BT: 0.039 (0.077)	Loss 2.4961 (2.4182)	Prec@1 40.625 (39.643)	
Total train loss: 2.4185
Avg Loading time: 0.0160 seconds
Avg Batch time: 0.0765 seconds

Train time: 30.053285360336304
 * Prec@1 39.310 Prec@5 73.300 Loss 2.4180
Avg Loading time: 0.0541 seconds
Avg Batch time: 0.0768 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 19.626608848571777

Epoch: [30][77/391]	LR: 4e-05	DT: 0.000 (0.018)	BT: 0.063 (0.083)	Loss 2.3457 (2.4155)	Prec@1 39.844 (39.073)	
Epoch: [30][155/391]	LR: 4e-05	DT: 0.032 (0.017)	BT: 0.100 (0.080)	Loss 2.3320 (2.4203)	Prec@1 42.188 (39.263)	
Epoch: [30][233/391]	LR: 4e-05	DT: 0.000 (0.015)	BT: 0.059 (0.079)	Loss 2.3457 (2.4112)	Prec@1 41.406 (39.513)	
Epoch: [30][311/391]	LR: 4e-05	DT: 0.103 (0.015)	BT: 0.153 (0.080)	Loss 2.3828 (2.4164)	Prec@1 40.625 (39.468)	
Epoch: [30][389/391]	LR: 4e-05	DT: 0.000 (0.015)	BT: 0.061 (0.079)	Loss 2.5234 (2.4178)	Prec@1 35.156 (39.535)	
Total train loss: 2.4182
Avg Loading time: 0.0152 seconds
Avg Batch time: 0.0792 seconds

Train time: 31.129411697387695
 * Prec@1 39.430 Prec@5 73.210 Loss 2.4180
Avg Loading time: 0.0516 seconds
Avg Batch time: 0.0779 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 7.922707796096802

Epoch: [31][77/391]	LR: 4e-05	DT: 0.000 (0.026)	BT: 0.058 (0.087)	Loss 2.3984 (2.4107)	Prec@1 36.719 (40.104)	
Epoch: [31][155/391]	LR: 4e-05	DT: 0.000 (0.024)	BT: 0.090 (0.083)	Loss 2.5508 (2.4132)	Prec@1 40.625 (39.749)	
Epoch: [31][233/391]	LR: 4e-05	DT: 0.023 (0.022)	BT: 0.062 (0.082)	Loss 2.4688 (2.4223)	Prec@1 37.500 (39.567)	
Epoch: [31][311/391]	LR: 4e-05	DT: 0.022 (0.021)	BT: 0.064 (0.079)	Loss 2.4824 (2.4226)	Prec@1 40.625 (39.393)	
Epoch: [31][389/391]	LR: 4e-05	DT: 0.048 (0.020)	BT: 0.087 (0.079)	Loss 2.4648 (2.4186)	Prec@1 38.281 (39.541)	
Total train loss: 2.4186
Avg Loading time: 0.0196 seconds
Avg Batch time: 0.0793 seconds

Train time: 31.097381830215454
 * Prec@1 39.320 Prec@5 73.170 Loss 2.4180
Avg Loading time: 0.0469 seconds
Avg Batch time: 0.0652 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 9.122199535369873

Epoch: [32][77/391]	LR: 4e-05	DT: 0.000 (0.029)	BT: 0.087 (0.092)	Loss 2.3359 (2.4108)	Prec@1 44.531 (40.415)	
Epoch: [32][155/391]	LR: 4e-05	DT: 0.072 (0.026)	BT: 0.143 (0.087)	Loss 2.6270 (2.4173)	Prec@1 32.031 (39.829)	
Epoch: [32][233/391]	LR: 4e-05	DT: 0.000 (0.027)	BT: 0.080 (0.088)	Loss 2.5273 (2.4148)	Prec@1 35.156 (39.757)	
Epoch: [32][311/391]	LR: 4e-05	DT: 0.000 (0.024)	BT: 0.046 (0.085)	Loss 2.3613 (2.4127)	Prec@1 42.969 (39.926)	
Epoch: [32][389/391]	LR: 4e-05	DT: 0.000 (0.024)	BT: 0.069 (0.084)	Loss 2.4277 (2.4143)	Prec@1 40.625 (39.790)	
Total train loss: 2.4144
Avg Loading time: 0.0237 seconds
Avg Batch time: 0.0839 seconds

Train time: 32.94649958610535
 * Prec@1 39.290 Prec@5 73.230 Loss 2.4082
Avg Loading time: 0.0533 seconds
Avg Batch time: 0.0785 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 10.22645616531372

Epoch: [33][77/391]	LR: 4e-05	DT: 0.000 (0.017)	BT: 0.043 (0.080)	Loss 2.4668 (2.4198)	Prec@1 35.938 (39.443)	
Epoch: [33][155/391]	LR: 4e-05	DT: 0.083 (0.020)	BT: 0.138 (0.080)	Loss 2.3750 (2.4204)	Prec@1 41.406 (39.568)	
Epoch: [33][233/391]	LR: 4e-05	DT: 0.000 (0.020)	BT: 0.061 (0.080)	Loss 2.5078 (2.4249)	Prec@1 36.719 (39.363)	
Epoch: [33][311/391]	LR: 4e-05	DT: 0.000 (0.018)	BT: 0.052 (0.077)	Loss 2.2129 (2.4212)	Prec@1 42.188 (39.348)	
Epoch: [33][389/391]	LR: 4e-05	DT: 0.000 (0.016)	BT: 0.095 (0.076)	Loss 2.5645 (2.4197)	Prec@1 37.500 (39.563)	
Total train loss: 2.4201
Avg Loading time: 0.0162 seconds
Avg Batch time: 0.0757 seconds

Train time: 29.73649501800537
 * Prec@1 39.210 Prec@5 73.120 Loss 2.4219
Avg Loading time: 0.0531 seconds
Avg Batch time: 0.0801 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 7.0195982456207275

Epoch: [34][77/391]	LR: 4e-05	DT: 0.000 (0.021)	BT: 0.061 (0.085)	Loss 2.6035 (2.4166)	Prec@1 35.938 (40.194)	
Epoch: [34][155/391]	LR: 4e-05	DT: 0.000 (0.018)	BT: 0.070 (0.080)	Loss 2.2031 (2.4127)	Prec@1 41.406 (40.074)	
Epoch: [34][233/391]	LR: 4e-05	DT: 0.000 (0.017)	BT: 0.074 (0.078)	Loss 2.5723 (2.4140)	Prec@1 32.812 (39.830)	
Epoch: [34][311/391]	LR: 4e-05	DT: 0.038 (0.015)	BT: 0.095 (0.077)	Loss 2.5547 (2.4137)	Prec@1 33.594 (39.844)	
Epoch: [34][389/391]	LR: 4e-05	DT: 0.069 (0.014)	BT: 0.117 (0.076)	Loss 2.2559 (2.4159)	Prec@1 48.438 (39.790)	
Total train loss: 2.4163
Avg Loading time: 0.0143 seconds
Avg Batch time: 0.0759 seconds

Train time: 29.805973291397095
 * Prec@1 39.280 Prec@5 73.090 Loss 2.4258
Avg Loading time: 0.0767 seconds
Avg Batch time: 0.1027 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 16.7813241481781

Epoch: [35][77/391]	LR: 4e-05	DT: 0.085 (0.021)	BT: 0.134 (0.072)	Loss 2.3320 (2.4052)	Prec@1 45.312 (39.824)	
Epoch: [35][155/391]	LR: 4e-05	DT: 0.000 (0.020)	BT: 0.059 (0.075)	Loss 2.3242 (2.4183)	Prec@1 40.625 (39.809)	
Epoch: [35][233/391]	LR: 4e-05	DT: 0.000 (0.020)	BT: 0.050 (0.077)	Loss 2.3457 (2.4172)	Prec@1 40.625 (39.690)	
Epoch: [35][311/391]	LR: 4e-05	DT: 0.000 (0.020)	BT: 0.063 (0.077)	Loss 2.5000 (2.4211)	Prec@1 31.250 (39.623)	
Epoch: [35][389/391]	LR: 4e-05	DT: 0.000 (0.019)	BT: 0.039 (0.077)	Loss 2.4258 (2.4191)	Prec@1 42.188 (39.587)	
Total train loss: 2.4192
Avg Loading time: 0.0193 seconds
Avg Batch time: 0.0769 seconds

Train time: 30.196810007095337
 * Prec@1 38.950 Prec@5 73.210 Loss 2.4160
Avg Loading time: 0.0505 seconds
Avg Batch time: 0.0768 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 10.209213018417358

Epoch: [36][77/391]	LR: 4e-05	DT: 0.000 (0.022)	BT: 0.039 (0.084)	Loss 2.4336 (2.4218)	Prec@1 36.719 (39.383)	
Epoch: [36][155/391]	LR: 4e-05	DT: 0.001 (0.017)	BT: 0.048 (0.080)	Loss 2.4141 (2.4223)	Prec@1 38.281 (39.393)	
Epoch: [36][233/391]	LR: 4e-05	DT: 0.128 (0.016)	BT: 0.184 (0.078)	Loss 2.5430 (2.4217)	Prec@1 35.938 (39.416)	
Epoch: [36][311/391]	LR: 4e-05	DT: 0.000 (0.014)	BT: 0.061 (0.074)	Loss 2.2910 (2.4196)	Prec@1 46.875 (39.473)	
Epoch: [36][389/391]	LR: 4e-05	DT: 0.054 (0.014)	BT: 0.093 (0.074)	Loss 2.4805 (2.4169)	Prec@1 37.500 (39.619)	
Total train loss: 2.4167
Avg Loading time: 0.0137 seconds
Avg Batch time: 0.0738 seconds

Train time: 29.01961088180542
 * Prec@1 39.210 Prec@5 73.100 Loss 2.4199
Avg Loading time: 0.0497 seconds
Avg Batch time: 0.0715 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 9.538919448852539

Epoch: [37][77/391]	LR: 4e-05	DT: 0.078 (0.034)	BT: 0.122 (0.092)	Loss 2.4375 (2.4219)	Prec@1 38.281 (39.573)	
Epoch: [37][155/391]	LR: 4e-05	DT: 0.000 (0.025)	BT: 0.059 (0.083)	Loss 2.1172 (2.4183)	Prec@1 50.781 (39.779)	
Epoch: [37][233/391]	LR: 4e-05	DT: 0.000 (0.020)	BT: 0.043 (0.079)	Loss 2.2090 (2.4165)	Prec@1 44.531 (39.770)	
Epoch: [37][311/391]	LR: 4e-05	DT: 0.000 (0.019)	BT: 0.051 (0.079)	Loss 2.2852 (2.4133)	Prec@1 44.531 (39.911)	
Epoch: [37][389/391]	LR: 4e-05	DT: 0.000 (0.018)	BT: 0.039 (0.079)	Loss 2.5254 (2.4179)	Prec@1 33.594 (39.772)	
Total train loss: 2.4180
Avg Loading time: 0.0183 seconds
Avg Batch time: 0.0784 seconds

Train time: 30.791553258895874
 * Prec@1 39.340 Prec@5 73.310 Loss 2.4238
Avg Loading time: 0.0542 seconds
Avg Batch time: 0.0799 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 9.95445728302002

Epoch: [38][77/391]	LR: 4e-05	DT: 0.000 (0.026)	BT: 0.069 (0.091)	Loss 2.4297 (2.4216)	Prec@1 41.406 (39.173)	
Epoch: [38][155/391]	LR: 4e-05	DT: 0.000 (0.020)	BT: 0.057 (0.080)	Loss 2.3301 (2.4106)	Prec@1 45.312 (39.608)	
Epoch: [38][233/391]	LR: 4e-05	DT: 0.000 (0.021)	BT: 0.062 (0.079)	Loss 2.1816 (2.4124)	Prec@1 43.750 (39.583)	
Epoch: [38][311/391]	LR: 4e-05	DT: 0.012 (0.019)	BT: 0.064 (0.077)	Loss 2.4258 (2.4127)	Prec@1 37.500 (39.651)	
Epoch: [38][389/391]	LR: 4e-05	DT: 0.000 (0.016)	BT: 0.069 (0.074)	Loss 2.5508 (2.4161)	Prec@1 36.719 (39.655)	
Total train loss: 2.4163
Avg Loading time: 0.0159 seconds
Avg Batch time: 0.0740 seconds

Train time: 29.052361488342285
 * Prec@1 39.270 Prec@5 73.190 Loss 2.4180
Avg Loading time: 0.0521 seconds
Avg Batch time: 0.0759 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 9.650432586669922

Epoch: [39][77/391]	LR: 4e-05	DT: 0.000 (0.022)	BT: 0.086 (0.090)	Loss 2.6680 (2.4235)	Prec@1 33.594 (39.603)	
Epoch: [39][155/391]	LR: 4e-05	DT: 0.136 (0.017)	BT: 0.189 (0.084)	Loss 2.4395 (2.4306)	Prec@1 36.719 (39.483)	
Epoch: [39][233/391]	LR: 4e-05	DT: 0.159 (0.017)	BT: 0.222 (0.082)	Loss 2.5918 (2.4218)	Prec@1 35.156 (39.423)	
Epoch: [39][311/391]	LR: 4e-05	DT: 0.000 (0.018)	BT: 0.054 (0.081)	Loss 2.3828 (2.4211)	Prec@1 39.844 (39.456)	
Epoch: [39][389/391]	LR: 4e-05	DT: 0.000 (0.017)	BT: 0.044 (0.081)	Loss 2.2910 (2.4179)	Prec@1 39.844 (39.457)	
Total train loss: 2.4178
Avg Loading time: 0.0171 seconds
Avg Batch time: 0.0805 seconds

Train time: 31.601593494415283
 * Prec@1 39.180 Prec@5 73.160 Loss 2.4141
Avg Loading time: 0.0536 seconds
Avg Batch time: 0.0804 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 8.852343320846558

Epoch: [40][77/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.016)	BT: 0.050 (0.078)	Loss 2.4727 (2.4352)	Prec@1 38.281 (39.423)	
Epoch: [40][155/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.015)	BT: 0.061 (0.076)	Loss 2.5020 (2.4244)	Prec@1 35.938 (39.683)	
Epoch: [40][233/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.011)	BT: 0.059 (0.071)	Loss 2.4746 (2.4176)	Prec@1 41.406 (39.640)	
Epoch: [40][311/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.010)	BT: 0.058 (0.071)	Loss 2.1660 (2.4138)	Prec@1 50.781 (39.551)	
Epoch: [40][389/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.011)	BT: 0.050 (0.071)	Loss 2.3633 (2.4150)	Prec@1 43.750 (39.605)	
Total train loss: 2.4150
Avg Loading time: 0.0108 seconds
Avg Batch time: 0.0706 seconds

Train time: 27.736953735351562
 * Prec@1 39.330 Prec@5 73.110 Loss 2.4219
Avg Loading time: 0.0536 seconds
Avg Batch time: 0.0811 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 11.912539005279541

Epoch: [41][77/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.025)	BT: 0.069 (0.086)	Loss 2.2031 (2.4242)	Prec@1 47.656 (39.303)	
Epoch: [41][155/391]	LR: 8.000000000000001e-06	DT: 0.162 (0.025)	BT: 0.233 (0.085)	Loss 2.4961 (2.4290)	Prec@1 32.812 (39.123)	
Epoch: [41][233/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.020)	BT: 0.056 (0.081)	Loss 2.5000 (2.4196)	Prec@1 35.938 (39.363)	
Epoch: [41][311/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.018)	BT: 0.050 (0.078)	Loss 2.6016 (2.4218)	Prec@1 39.062 (39.408)	
Epoch: [41][389/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.018)	BT: 0.040 (0.077)	Loss 2.5547 (2.4185)	Prec@1 37.500 (39.597)	
Total train loss: 2.4185
Avg Loading time: 0.0178 seconds
Avg Batch time: 0.0774 seconds

Train time: 30.396077632904053
 * Prec@1 39.140 Prec@5 73.260 Loss 2.4199
Avg Loading time: 0.0532 seconds
Avg Batch time: 0.0779 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 10.078428983688354

Epoch: [42][77/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.012)	BT: 0.054 (0.065)	Loss 2.2832 (2.4144)	Prec@1 42.969 (39.613)	
Epoch: [42][155/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.012)	BT: 0.045 (0.067)	Loss 2.4434 (2.4172)	Prec@1 42.188 (39.994)	
Epoch: [42][233/391]	LR: 8.000000000000001e-06	DT: 0.026 (0.011)	BT: 0.081 (0.070)	Loss 2.3965 (2.4210)	Prec@1 39.844 (39.607)	
Epoch: [42][311/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.012)	BT: 0.049 (0.071)	Loss 2.3809 (2.4186)	Prec@1 42.969 (39.533)	
Epoch: [42][389/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.014)	BT: 0.038 (0.072)	Loss 2.2676 (2.4185)	Prec@1 46.875 (39.539)	
Total train loss: 2.4186
Avg Loading time: 0.0141 seconds
Avg Batch time: 0.0721 seconds

Train time: 28.323917627334595
 * Prec@1 39.230 Prec@5 73.260 Loss 2.4102
Avg Loading time: 0.0555 seconds
Avg Batch time: 0.0813 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 9.353430032730103

Epoch: [43][77/391]	LR: 8.000000000000001e-06	DT: 0.052 (0.019)	BT: 0.112 (0.087)	Loss 2.3711 (2.4111)	Prec@1 42.188 (39.824)	
Epoch: [43][155/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.016)	BT: 0.050 (0.082)	Loss 2.3730 (2.4160)	Prec@1 40.625 (39.824)	
Epoch: [43][233/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.018)	BT: 0.046 (0.081)	Loss 2.5469 (2.4133)	Prec@1 32.812 (39.700)	
Epoch: [43][311/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.018)	BT: 0.069 (0.080)	Loss 2.3711 (2.4156)	Prec@1 42.969 (39.706)	
Epoch: [43][389/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.017)	BT: 0.039 (0.078)	Loss 2.4102 (2.4164)	Prec@1 42.969 (39.690)	
Total train loss: 2.4163
Avg Loading time: 0.0169 seconds
Avg Batch time: 0.0776 seconds

Train time: 30.483332633972168
 * Prec@1 39.100 Prec@5 73.010 Loss 2.4102
Avg Loading time: 0.0514 seconds
Avg Batch time: 0.0756 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 8.190539836883545

Epoch: [44][77/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.012)	BT: 0.039 (0.064)	Loss 2.4004 (2.4162)	Prec@1 35.156 (39.012)	
Epoch: [44][155/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.014)	BT: 0.079 (0.071)	Loss 2.3672 (2.4126)	Prec@1 42.188 (39.608)	
Epoch: [44][233/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.016)	BT: 0.069 (0.075)	Loss 2.3008 (2.4116)	Prec@1 46.094 (39.600)	
Epoch: [44][311/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.017)	BT: 0.070 (0.076)	Loss 2.3809 (2.4168)	Prec@1 46.094 (39.638)	
Epoch: [44][389/391]	LR: 8.000000000000001e-06	DT: 0.064 (0.017)	BT: 0.109 (0.075)	Loss 2.5176 (2.4154)	Prec@1 32.812 (39.742)	
Total train loss: 2.4154
Avg Loading time: 0.0168 seconds
Avg Batch time: 0.0752 seconds

Train time: 29.53308939933777
 * Prec@1 39.270 Prec@5 73.150 Loss 2.4141
Avg Loading time: 0.0566 seconds
Avg Batch time: 0.0824 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 9.211418390274048

Epoch: [45][77/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.022)	BT: 0.071 (0.084)	Loss 2.4492 (2.4158)	Prec@1 41.406 (39.673)	
Epoch: [45][155/391]	LR: 8.000000000000001e-06	DT: 0.045 (0.018)	BT: 0.131 (0.079)	Loss 2.4492 (2.4193)	Prec@1 40.625 (39.709)	
Epoch: [45][233/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.018)	BT: 0.086 (0.079)	Loss 2.5410 (2.4242)	Prec@1 32.812 (39.443)	
Epoch: [45][311/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.018)	BT: 0.062 (0.078)	Loss 2.4766 (2.4169)	Prec@1 42.969 (39.631)	
Epoch: [45][389/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.018)	BT: 0.070 (0.077)	Loss 2.6484 (2.4172)	Prec@1 38.281 (39.704)	
Total train loss: 2.4171
Avg Loading time: 0.0176 seconds
Avg Batch time: 0.0768 seconds

Train time: 30.161943912506104
 * Prec@1 39.380 Prec@5 73.170 Loss 2.4160
Avg Loading time: 0.0498 seconds
Avg Batch time: 0.0741 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 6.539039611816406

Epoch: [46][77/391]	LR: 8.000000000000001e-06	DT: 0.083 (0.019)	BT: 0.123 (0.085)	Loss 2.3809 (2.4100)	Prec@1 45.312 (39.874)	
Epoch: [46][155/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.017)	BT: 0.058 (0.080)	Loss 2.5430 (2.4105)	Prec@1 37.500 (39.774)	
Epoch: [46][233/391]	LR: 8.000000000000001e-06	DT: 0.039 (0.016)	BT: 0.092 (0.078)	Loss 2.5742 (2.4197)	Prec@1 39.844 (39.483)	
Epoch: [46][311/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.017)	BT: 0.053 (0.078)	Loss 2.4492 (2.4190)	Prec@1 42.969 (39.403)	
Epoch: [46][389/391]	LR: 8.000000000000001e-06	DT: 0.022 (0.017)	BT: 0.060 (0.077)	Loss 2.4375 (2.4145)	Prec@1 38.281 (39.549)	
Total train loss: 2.4142
Avg Loading time: 0.0169 seconds
Avg Batch time: 0.0769 seconds

Train time: 30.208752393722534
 * Prec@1 39.200 Prec@5 73.130 Loss 2.4219
Avg Loading time: 0.0565 seconds
Avg Batch time: 0.0810 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 7.098747968673706

Epoch: [47][77/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.031)	BT: 0.044 (0.095)	Loss 2.3867 (2.4254)	Prec@1 35.156 (39.423)	
Epoch: [47][155/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.024)	BT: 0.087 (0.086)	Loss 2.2754 (2.4172)	Prec@1 42.969 (39.709)	
Epoch: [47][233/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.021)	BT: 0.056 (0.083)	Loss 2.4824 (2.4168)	Prec@1 39.062 (39.493)	
Epoch: [47][311/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.019)	BT: 0.080 (0.080)	Loss 2.6113 (2.4228)	Prec@1 35.938 (39.486)	
Epoch: [47][389/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.019)	BT: 0.051 (0.079)	Loss 2.4766 (2.4176)	Prec@1 34.375 (39.621)	
Total train loss: 2.4181
Avg Loading time: 0.0186 seconds
Avg Batch time: 0.0788 seconds

Train time: 30.917459964752197
 * Prec@1 39.360 Prec@5 73.300 Loss 2.4121
Avg Loading time: 0.0490 seconds
Avg Batch time: 0.0708 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 6.27242374420166

Epoch: [48][77/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.021)	BT: 0.062 (0.088)	Loss 2.4043 (2.4188)	Prec@1 36.719 (39.884)	
Epoch: [48][155/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.020)	BT: 0.098 (0.086)	Loss 2.5352 (2.4137)	Prec@1 35.156 (40.074)	
Epoch: [48][233/391]	LR: 8.000000000000001e-06	DT: 0.446 (0.033)	BT: 0.491 (0.096)	Loss 2.2578 (2.4205)	Prec@1 43.750 (39.727)	
Epoch: [48][311/391]	LR: 8.000000000000001e-06	DT: 0.024 (0.044)	BT: 0.066 (0.103)	Loss 2.2285 (2.4178)	Prec@1 43.750 (39.741)	
Epoch: [48][389/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.059)	BT: 0.043 (0.116)	Loss 2.4609 (2.4161)	Prec@1 33.594 (39.696)	
Total train loss: 2.4165
Avg Loading time: 0.0586 seconds
Avg Batch time: 0.1154 seconds

Train time: 45.257465839385986
 * Prec@1 39.300 Prec@5 73.350 Loss 2.4160
Avg Loading time: 0.3708 seconds
Avg Batch time: 0.3886 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 31.32085871696472

Epoch: [49][77/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.513)	BT: 0.046 (0.562)	Loss 2.3828 (2.4329)	Prec@1 35.156 (39.032)	
Epoch: [49][155/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.522)	BT: 0.045 (0.570)	Loss 2.5039 (2.4185)	Prec@1 35.156 (39.804)	
Epoch: [49][233/391]	LR: 8.000000000000001e-06	DT: 1.984 (0.514)	BT: 2.035 (0.561)	Loss 2.2383 (2.4196)	Prec@1 45.312 (39.550)	
Epoch: [49][311/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.481)	BT: 0.043 (0.528)	Loss 2.2656 (2.4212)	Prec@1 41.406 (39.370)	
Epoch: [49][389/391]	LR: 8.000000000000001e-06	DT: 0.000 (0.439)	BT: 0.038 (0.487)	Loss 2.4277 (2.4161)	Prec@1 37.500 (39.619)	
Total train loss: 2.4163
Avg Loading time: 0.4377 seconds
Avg Batch time: 0.4863 seconds

Train time: 190.2276096343994
 * Prec@1 39.340 Prec@5 73.170 Loss 2.4199
Avg Loading time: 0.4552 seconds
Avg Batch time: 0.4736 seconds

Best acc: 56.080
--------------------------------------------------------------------------------
Test time: 39.13765478134155

