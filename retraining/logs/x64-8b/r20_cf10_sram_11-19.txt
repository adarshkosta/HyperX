
      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20fp_cifar10.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 30
          start_epoch: 0
          batch_size: 256
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          milestones: [8, 16, 24]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 11
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20fp_cifar10.pth.tar ...
Original model accuracy: 91.93
ResNet_cifar(
  (conv12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (conv18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu18): ReLU(inplace=True)
  (conv19): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu19): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (bn20): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=64, out_features=10, bias=False)
  (bn21): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 49.810 Prec@5 90.770 Loss 2.4062
Pre-trained Prec@1 with 11 layers frozen: 49.80999755859375 	 Loss: 2.40625

Starting training on SRAM layers...
Epoch: [0][38/196]	LR: 0.1	Loss 0.2358 (0.3423)	Prec@1 93.359 (88.582)	
Epoch: [0][77/196]	LR: 0.1	Loss 0.2468 (0.3063)	Prec@1 90.234 (89.694)	
Epoch: [0][116/196]	LR: 0.1	Loss 0.2754 (0.2908)	Prec@1 89.844 (90.061)	
Epoch: [0][155/196]	LR: 0.1	Loss 0.2029 (0.2814)	Prec@1 92.578 (90.330)	
Epoch: [0][194/196]	LR: 0.1	Loss 0.2439 (0.2763)	Prec@1 90.625 (90.443)	
Total train loss: 0.2762

Train time: 925.7795231342316
 * Prec@1 85.830 Prec@5 99.470 Loss 0.4468
Best acc: 85.830
--------------------------------------------------------------------------------
Test time: 955.2269515991211

Epoch: [1][38/196]	LR: 0.1	Loss 0.1000 (0.1597)	Prec@1 97.266 (94.431)	
Epoch: [1][77/196]	LR: 0.1	Loss 0.1719 (0.1582)	Prec@1 93.750 (94.516)	
Epoch: [1][116/196]	LR: 0.1	Loss 0.1186 (0.1601)	Prec@1 95.312 (94.444)	
Epoch: [1][155/196]	LR: 0.1	Loss 0.2039 (0.1662)	Prec@1 92.188 (94.168)	
Epoch: [1][194/196]	LR: 0.1	Loss 0.2219 (0.1691)	Prec@1 92.578 (94.111)	
Total train loss: 0.1691

Train time: 76.1319489479065
 * Prec@1 86.190 Prec@5 99.360 Loss 0.4617
Best acc: 86.190
--------------------------------------------------------------------------------
Test time: 82.55467772483826

Epoch: [2][38/196]	LR: 0.1	Loss 0.0742 (0.1192)	Prec@1 98.828 (96.114)	
Epoch: [2][77/196]	LR: 0.1	Loss 0.1412 (0.1160)	Prec@1 95.703 (96.134)	
Epoch: [2][116/196]	LR: 0.1	Loss 0.1440 (0.1195)	Prec@1 95.312 (95.960)	
Epoch: [2][155/196]	LR: 0.1	Loss 0.1049 (0.1225)	Prec@1 96.094 (95.788)	
Epoch: [2][194/196]	LR: 0.1	Loss 0.1312 (0.1253)	Prec@1 94.922 (95.701)	
Total train loss: 0.1253

Train time: 22.176064491271973
 * Prec@1 86.340 Prec@5 99.430 Loss 0.4731
Best acc: 86.340
--------------------------------------------------------------------------------
Test time: 26.997313976287842

Epoch: [3][38/196]	LR: 0.1	Loss 0.0610 (0.0816)	Prec@1 98.438 (97.436)	
Epoch: [3][77/196]	LR: 0.1	Loss 0.0771 (0.0854)	Prec@1 96.875 (97.236)	
Epoch: [3][116/196]	LR: 0.1	Loss 0.1023 (0.0911)	Prec@1 96.094 (96.928)	
Epoch: [3][155/196]	LR: 0.1	Loss 0.0921 (0.0936)	Prec@1 97.266 (96.817)	
Epoch: [3][194/196]	LR: 0.1	Loss 0.0623 (0.0972)	Prec@1 98.828 (96.625)	
Total train loss: 0.0972

Train time: 19.92675542831421
 * Prec@1 86.090 Prec@5 99.240 Loss 0.5059
Best acc: 86.340
--------------------------------------------------------------------------------
Test time: 23.096527814865112

Epoch: [4][38/196]	LR: 0.1	Loss 0.0617 (0.0810)	Prec@1 98.438 (97.426)	
Epoch: [4][77/196]	LR: 0.1	Loss 0.0814 (0.0761)	Prec@1 97.266 (97.581)	
Epoch: [4][116/196]	LR: 0.1	Loss 0.0776 (0.0780)	Prec@1 97.266 (97.513)	
Epoch: [4][155/196]	LR: 0.1	Loss 0.0923 (0.0788)	Prec@1 95.703 (97.473)	
Epoch: [4][194/196]	LR: 0.1	Loss 0.0947 (0.0823)	Prec@1 96.484 (97.338)	
Total train loss: 0.0823

Train time: 18.459800720214844
 * Prec@1 86.310 Prec@5 99.190 Loss 0.5298
Best acc: 86.340
--------------------------------------------------------------------------------
Test time: 22.931323766708374

Epoch: [5][38/196]	LR: 0.1	Loss 0.0936 (0.0638)	Prec@1 96.875 (97.987)	
Epoch: [5][77/196]	LR: 0.1	Loss 0.0663 (0.0625)	Prec@1 96.875 (98.012)	
Epoch: [5][116/196]	LR: 0.1	Loss 0.0782 (0.0631)	Prec@1 97.656 (97.960)	
Epoch: [5][155/196]	LR: 0.1	Loss 0.0700 (0.0635)	Prec@1 96.875 (97.959)	
Epoch: [5][194/196]	LR: 0.1	Loss 0.0807 (0.0671)	Prec@1 97.266 (97.831)	
Total train loss: 0.0672

Train time: 19.65765905380249
 * Prec@1 85.080 Prec@5 99.100 Loss 0.6182
Best acc: 86.340
--------------------------------------------------------------------------------
Test time: 24.075474739074707

Epoch: [6][38/196]	LR: 0.1	Loss 0.0506 (0.0576)	Prec@1 99.609 (98.087)	
Epoch: [6][77/196]	LR: 0.1	Loss 0.0485 (0.0549)	Prec@1 98.828 (98.292)	
Epoch: [6][116/196]	LR: 0.1	Loss 0.0638 (0.0544)	Prec@1 98.047 (98.311)	
Epoch: [6][155/196]	LR: 0.1	Loss 0.0573 (0.0548)	Prec@1 98.438 (98.322)	
Epoch: [6][194/196]	LR: 0.1	Loss 0.0540 (0.0566)	Prec@1 98.047 (98.219)	
Total train loss: 0.0566

Train time: 18.924687147140503
 * Prec@1 86.180 Prec@5 99.090 Loss 0.5845
Best acc: 86.340
--------------------------------------------------------------------------------
Test time: 22.544931888580322

Epoch: [7][38/196]	LR: 0.1	Loss 0.0626 (0.0498)	Prec@1 98.047 (98.598)	
Epoch: [7][77/196]	LR: 0.1	Loss 0.0619 (0.0476)	Prec@1 97.656 (98.628)	
Epoch: [7][116/196]	LR: 0.1	Loss 0.0524 (0.0466)	Prec@1 98.047 (98.631)	
Epoch: [7][155/196]	LR: 0.1	Loss 0.0767 (0.0484)	Prec@1 97.266 (98.545)	
Epoch: [7][194/196]	LR: 0.1	Loss 0.0540 (0.0512)	Prec@1 98.047 (98.415)	
Total train loss: 0.0512

Train time: 18.7533221244812
 * Prec@1 85.010 Prec@5 99.030 Loss 0.6118
Best acc: 86.340
--------------------------------------------------------------------------------
Test time: 23.183663606643677

Epoch: [8][38/196]	LR: 0.010000000000000002	Loss 0.0353 (0.0381)	Prec@1 98.828 (98.968)	
Epoch: [8][77/196]	LR: 0.010000000000000002	Loss 0.0227 (0.0326)	Prec@1 99.609 (99.184)	
Epoch: [8][116/196]	LR: 0.010000000000000002	Loss 0.0145 (0.0294)	Prec@1 100.000 (99.289)	
Epoch: [8][155/196]	LR: 0.010000000000000002	Loss 0.0179 (0.0266)	Prec@1 100.000 (99.404)	
Epoch: [8][194/196]	LR: 0.010000000000000002	Loss 0.0133 (0.0248)	Prec@1 100.000 (99.465)	
Total train loss: 0.0248

Train time: 19.118287086486816
 * Prec@1 88.000 Prec@5 99.410 Loss 0.4756
Best acc: 88.000
--------------------------------------------------------------------------------
Test time: 23.492353677749634

Epoch: [9][38/196]	LR: 0.010000000000000002	Loss 0.0123 (0.0131)	Prec@1 100.000 (99.860)	
Epoch: [9][77/196]	LR: 0.010000000000000002	Loss 0.0097 (0.0134)	Prec@1 100.000 (99.875)	
Epoch: [9][116/196]	LR: 0.010000000000000002	Loss 0.0201 (0.0138)	Prec@1 99.219 (99.873)	
Epoch: [9][155/196]	LR: 0.010000000000000002	Loss 0.0220 (0.0140)	Prec@1 99.609 (99.862)	
Epoch: [9][194/196]	LR: 0.010000000000000002	Loss 0.0206 (0.0141)	Prec@1 99.609 (99.860)	
Total train loss: 0.0142

Train time: 19.35922384262085
 * Prec@1 88.030 Prec@5 99.440 Loss 0.4785
Best acc: 88.030
--------------------------------------------------------------------------------
Test time: 23.006240844726562

Epoch: [10][38/196]	LR: 0.010000000000000002	Loss 0.0122 (0.0123)	Prec@1 99.609 (99.910)	
Epoch: [10][77/196]	LR: 0.010000000000000002	Loss 0.0073 (0.0118)	Prec@1 100.000 (99.920)	
Epoch: [10][116/196]	LR: 0.010000000000000002	Loss 0.0092 (0.0116)	Prec@1 100.000 (99.920)	
Epoch: [10][155/196]	LR: 0.010000000000000002	Loss 0.0068 (0.0116)	Prec@1 100.000 (99.925)	
Epoch: [10][194/196]	LR: 0.010000000000000002	Loss 0.0092 (0.0114)	Prec@1 100.000 (99.930)	
Total train loss: 0.0115

Train time: 19.326820373535156
 * Prec@1 88.210 Prec@5 99.410 Loss 0.4768
Best acc: 88.210
--------------------------------------------------------------------------------
Test time: 23.43011164665222

Epoch: [11][38/196]	LR: 0.010000000000000002	Loss 0.0110 (0.0112)	Prec@1 100.000 (99.920)	
Epoch: [11][77/196]	LR: 0.010000000000000002	Loss 0.0152 (0.0111)	Prec@1 99.609 (99.910)	
Epoch: [11][116/196]	LR: 0.010000000000000002	Loss 0.0041 (0.0106)	Prec@1 100.000 (99.920)	
Epoch: [11][155/196]	LR: 0.010000000000000002	Loss 0.0082 (0.0106)	Prec@1 99.609 (99.930)	
Epoch: [11][194/196]	LR: 0.010000000000000002	Loss 0.0080 (0.0106)	Prec@1 100.000 (99.930)	
Total train loss: 0.0106

Train time: 19.29799199104309
 * Prec@1 88.330 Prec@5 99.340 Loss 0.4775
Best acc: 88.330
--------------------------------------------------------------------------------
Test time: 23.38992214202881

Epoch: [12][38/196]	LR: 0.010000000000000002	Loss 0.0092 (0.0099)	Prec@1 100.000 (99.960)	
Epoch: [12][77/196]	LR: 0.010000000000000002	Loss 0.0064 (0.0098)	Prec@1 100.000 (99.965)	
Epoch: [12][116/196]	LR: 0.010000000000000002	Loss 0.0106 (0.0099)	Prec@1 100.000 (99.957)	
Epoch: [12][155/196]	LR: 0.010000000000000002	Loss 0.0078 (0.0099)	Prec@1 100.000 (99.955)	
Epoch: [12][194/196]	LR: 0.010000000000000002	Loss 0.0112 (0.0099)	Prec@1 100.000 (99.950)	
Total train loss: 0.0100

Train time: 18.511250972747803
 * Prec@1 88.310 Prec@5 99.330 Loss 0.4763
Best acc: 88.330
--------------------------------------------------------------------------------
Test time: 22.070108652114868

Epoch: [13][38/196]	LR: 0.010000000000000002	Loss 0.0071 (0.0098)	Prec@1 100.000 (99.950)	
Epoch: [13][77/196]	LR: 0.010000000000000002	Loss 0.0125 (0.0094)	Prec@1 100.000 (99.975)	
Epoch: [13][116/196]	LR: 0.010000000000000002	Loss 0.0093 (0.0094)	Prec@1 100.000 (99.970)	
Epoch: [13][155/196]	LR: 0.010000000000000002	Loss 0.0079 (0.0094)	Prec@1 100.000 (99.965)	
Epoch: [13][194/196]	LR: 0.010000000000000002	Loss 0.0065 (0.0095)	Prec@1 100.000 (99.962)	
Total train loss: 0.0095

Train time: 20.004465103149414
 * Prec@1 88.210 Prec@5 99.360 Loss 0.4807
Best acc: 88.330
--------------------------------------------------------------------------------
Test time: 24.15887212753296

Epoch: [14][38/196]	LR: 0.010000000000000002	Loss 0.0062 (0.0085)	Prec@1 100.000 (99.980)	
Epoch: [14][77/196]	LR: 0.010000000000000002	Loss 0.0103 (0.0085)	Prec@1 100.000 (99.985)	
Epoch: [14][116/196]	LR: 0.010000000000000002	Loss 0.0099 (0.0086)	Prec@1 100.000 (99.980)	
Epoch: [14][155/196]	LR: 0.010000000000000002	Loss 0.0067 (0.0087)	Prec@1 100.000 (99.970)	
Epoch: [14][194/196]	LR: 0.010000000000000002	Loss 0.0066 (0.0086)	Prec@1 100.000 (99.974)	
Total train loss: 0.0087

Train time: 19.309388637542725
 * Prec@1 88.280 Prec@5 99.390 Loss 0.4751
Best acc: 88.330
--------------------------------------------------------------------------------
Test time: 23.239336252212524

Epoch: [15][38/196]	LR: 0.010000000000000002	Loss 0.0063 (0.0071)	Prec@1 100.000 (99.990)	
Epoch: [15][77/196]	LR: 0.010000000000000002	Loss 0.0060 (0.0077)	Prec@1 100.000 (99.990)	
Epoch: [15][116/196]	LR: 0.010000000000000002	Loss 0.0049 (0.0077)	Prec@1 100.000 (99.987)	
Epoch: [15][155/196]	LR: 0.010000000000000002	Loss 0.0081 (0.0082)	Prec@1 100.000 (99.977)	
Epoch: [15][194/196]	LR: 0.010000000000000002	Loss 0.0053 (0.0082)	Prec@1 100.000 (99.982)	
Total train loss: 0.0082

Train time: 20.530211210250854
 * Prec@1 88.290 Prec@5 99.380 Loss 0.4788
Best acc: 88.330
--------------------------------------------------------------------------------
Test time: 23.61795139312744

Epoch: [16][38/196]	LR: 0.0010000000000000002	Loss 0.0069 (0.0077)	Prec@1 100.000 (99.980)	
Epoch: [16][77/196]	LR: 0.0010000000000000002	Loss 0.0071 (0.0081)	Prec@1 100.000 (99.970)	
Epoch: [16][116/196]	LR: 0.0010000000000000002	Loss 0.0046 (0.0080)	Prec@1 100.000 (99.977)	
Epoch: [16][155/196]	LR: 0.0010000000000000002	Loss 0.0089 (0.0080)	Prec@1 100.000 (99.977)	
Epoch: [16][194/196]	LR: 0.0010000000000000002	Loss 0.0070 (0.0080)	Prec@1 100.000 (99.982)	
Total train loss: 0.0080

Train time: 19.557984113693237
 * Prec@1 88.150 Prec@5 99.380 Loss 0.4768
Best acc: 88.330
--------------------------------------------------------------------------------
Test time: 23.234525442123413

Epoch: [17][38/196]	LR: 0.0010000000000000002	Loss 0.0056 (0.0082)	Prec@1 100.000 (99.990)	
Epoch: [17][77/196]	LR: 0.0010000000000000002	Loss 0.0135 (0.0079)	Prec@1 100.000 (99.995)	
Epoch: [17][116/196]	LR: 0.0010000000000000002	Loss 0.0071 (0.0081)	Prec@1 100.000 (99.983)	
Epoch: [17][155/196]	LR: 0.0010000000000000002	Loss 0.0242 (0.0079)	Prec@1 99.219 (99.982)	
Epoch: [17][194/196]	LR: 0.0010000000000000002	Loss 0.0126 (0.0079)	Prec@1 99.609 (99.976)	
Total train loss: 0.0080

Train time: 18.635281085968018
 * Prec@1 88.350 Prec@5 99.370 Loss 0.4805
Best acc: 88.350
--------------------------------------------------------------------------------
Test time: 22.54885482788086

Epoch: [18][38/196]	LR: 0.0010000000000000002	Loss 0.0108 (0.0076)	Prec@1 100.000 (99.990)	
Epoch: [18][77/196]	LR: 0.0010000000000000002	Loss 0.0072 (0.0076)	Prec@1 100.000 (99.990)	
Epoch: [18][116/196]	LR: 0.0010000000000000002	Loss 0.0063 (0.0075)	Prec@1 100.000 (99.990)	
Epoch: [18][155/196]	LR: 0.0010000000000000002	Loss 0.0059 (0.0076)	Prec@1 100.000 (99.990)	
Epoch: [18][194/196]	LR: 0.0010000000000000002	Loss 0.0051 (0.0076)	Prec@1 100.000 (99.992)	
Total train loss: 0.0076

Train time: 19.426513671875
 * Prec@1 88.120 Prec@5 99.370 Loss 0.4812
Best acc: 88.350
--------------------------------------------------------------------------------
Test time: 22.489479541778564

Epoch: [19][38/196]	LR: 0.0010000000000000002	Loss 0.0103 (0.0078)	Prec@1 100.000 (99.980)	
Epoch: [19][77/196]	LR: 0.0010000000000000002	Loss 0.0062 (0.0080)	Prec@1 100.000 (99.975)	
Epoch: [19][116/196]	LR: 0.0010000000000000002	Loss 0.0050 (0.0078)	Prec@1 100.000 (99.980)	
Epoch: [19][155/196]	LR: 0.0010000000000000002	Loss 0.0063 (0.0077)	Prec@1 100.000 (99.982)	
Epoch: [19][194/196]	LR: 0.0010000000000000002	Loss 0.0106 (0.0077)	Prec@1 100.000 (99.984)	
Total train loss: 0.0077

Train time: 19.10552668571472
 * Prec@1 88.320 Prec@5 99.370 Loss 0.4788
Best acc: 88.350
--------------------------------------------------------------------------------
Test time: 23.01946234703064

Epoch: [20][38/196]	LR: 0.0010000000000000002	Loss 0.0065 (0.0078)	Prec@1 100.000 (99.990)	
Epoch: [20][77/196]	LR: 0.0010000000000000002	Loss 0.0069 (0.0080)	Prec@1 100.000 (99.985)	
Epoch: [20][116/196]	LR: 0.0010000000000000002	Loss 0.0070 (0.0079)	Prec@1 100.000 (99.983)	
Epoch: [20][155/196]	LR: 0.0010000000000000002	Loss 0.0079 (0.0081)	Prec@1 100.000 (99.980)	
Epoch: [20][194/196]	LR: 0.0010000000000000002	Loss 0.0140 (0.0080)	Prec@1 99.609 (99.978)	
Total train loss: 0.0080

Train time: 20.10619330406189
 * Prec@1 88.110 Prec@5 99.370 Loss 0.4817
Best acc: 88.350
--------------------------------------------------------------------------------
Test time: 23.677359580993652

Epoch: [21][38/196]	LR: 0.0010000000000000002	Loss 0.0058 (0.0080)	Prec@1 100.000 (99.970)	
Epoch: [21][77/196]	LR: 0.0010000000000000002	Loss 0.0071 (0.0079)	Prec@1 100.000 (99.975)	
Epoch: [21][116/196]	LR: 0.0010000000000000002	Loss 0.0084 (0.0080)	Prec@1 100.000 (99.977)	
Epoch: [21][155/196]	LR: 0.0010000000000000002	Loss 0.0104 (0.0080)	Prec@1 100.000 (99.977)	
Epoch: [21][194/196]	LR: 0.0010000000000000002	Loss 0.0041 (0.0079)	Prec@1 100.000 (99.978)	
Total train loss: 0.0079

Train time: 19.683940649032593
 * Prec@1 88.160 Prec@5 99.350 Loss 0.4817
Best acc: 88.350
--------------------------------------------------------------------------------
Test time: 23.02868628501892

Epoch: [22][38/196]	LR: 0.0010000000000000002	Loss 0.0054 (0.0081)	Prec@1 100.000 (99.980)	
Epoch: [22][77/196]	LR: 0.0010000000000000002	Loss 0.0069 (0.0077)	Prec@1 100.000 (99.990)	
Epoch: [22][116/196]	LR: 0.0010000000000000002	Loss 0.0175 (0.0077)	Prec@1 100.000 (99.987)	
Epoch: [22][155/196]	LR: 0.0010000000000000002	Loss 0.0052 (0.0077)	Prec@1 100.000 (99.987)	
Epoch: [22][194/196]	LR: 0.0010000000000000002	Loss 0.0085 (0.0078)	Prec@1 100.000 (99.990)	
Total train loss: 0.0078

Train time: 21.13654375076294
 * Prec@1 88.130 Prec@5 99.350 Loss 0.4807
Best acc: 88.350
--------------------------------------------------------------------------------
Test time: 24.778045177459717

Epoch: [23][38/196]	LR: 0.0010000000000000002	Loss 0.0083 (0.0078)	Prec@1 100.000 (99.970)	
Epoch: [23][77/196]	LR: 0.0010000000000000002	Loss 0.0081 (0.0077)	Prec@1 100.000 (99.975)	
Epoch: [23][116/196]	LR: 0.0010000000000000002	Loss 0.0070 (0.0082)	Prec@1 100.000 (99.970)	
Epoch: [23][155/196]	LR: 0.0010000000000000002	Loss 0.0066 (0.0082)	Prec@1 100.000 (99.970)	
Epoch: [23][194/196]	LR: 0.0010000000000000002	Loss 0.0109 (0.0082)	Prec@1 100.000 (99.970)	
Total train loss: 0.0082

Train time: 18.596986532211304
 * Prec@1 88.230 Prec@5 99.380 Loss 0.4805
Best acc: 88.350
--------------------------------------------------------------------------------
Test time: 22.2334623336792

Epoch: [24][38/196]	LR: 0.00010000000000000003	Loss 0.0077 (0.0074)	Prec@1 100.000 (99.980)	
Epoch: [24][77/196]	LR: 0.00010000000000000003	Loss 0.0094 (0.0072)	Prec@1 100.000 (99.990)	
Epoch: [24][116/196]	LR: 0.00010000000000000003	Loss 0.0059 (0.0074)	Prec@1 100.000 (99.987)	
Epoch: [24][155/196]	LR: 0.00010000000000000003	Loss 0.0068 (0.0074)	Prec@1 100.000 (99.990)	
Epoch: [24][194/196]	LR: 0.00010000000000000003	Loss 0.0128 (0.0077)	Prec@1 100.000 (99.984)	
Total train loss: 0.0077

Train time: 19.283347606658936
 * Prec@1 88.180 Prec@5 99.370 Loss 0.4812
Best acc: 88.350
--------------------------------------------------------------------------------
Test time: 22.280763387680054

Epoch: [25][38/196]	LR: 0.00010000000000000003	Loss 0.0117 (0.0085)	Prec@1 100.000 (99.940)	
Epoch: [25][77/196]	LR: 0.00010000000000000003	Loss 0.0115 (0.0081)	Prec@1 100.000 (99.955)	
Epoch: [25][116/196]	LR: 0.00010000000000000003	Loss 0.0073 (0.0081)	Prec@1 100.000 (99.963)	
Epoch: [25][155/196]	LR: 0.00010000000000000003	Loss 0.0081 (0.0079)	Prec@1 100.000 (99.972)	
Epoch: [25][194/196]	LR: 0.00010000000000000003	Loss 0.0067 (0.0078)	Prec@1 100.000 (99.978)	
Total train loss: 0.0078

Train time: 19.561702489852905
 * Prec@1 88.230 Prec@5 99.360 Loss 0.4792
Best acc: 88.350
--------------------------------------------------------------------------------
Test time: 23.252806425094604

Epoch: [26][38/196]	LR: 0.00010000000000000003	Loss 0.0062 (0.0073)	Prec@1 100.000 (100.000)	
Epoch: [26][77/196]	LR: 0.00010000000000000003	Loss 0.0099 (0.0075)	Prec@1 100.000 (99.990)	
Epoch: [26][116/196]	LR: 0.00010000000000000003	Loss 0.0094 (0.0077)	Prec@1 100.000 (99.987)	
Epoch: [26][155/196]	LR: 0.00010000000000000003	Loss 0.0084 (0.0078)	Prec@1 100.000 (99.987)	
Epoch: [26][194/196]	LR: 0.00010000000000000003	Loss 0.0121 (0.0080)	Prec@1 100.000 (99.984)	
Total train loss: 0.0080

Train time: 20.056268215179443
 * Prec@1 88.130 Prec@5 99.340 Loss 0.4812
Best acc: 88.350
--------------------------------------------------------------------------------
Test time: 23.892984628677368

Epoch: [27][38/196]	LR: 0.00010000000000000003	Loss 0.0091 (0.0078)	Prec@1 99.609 (99.990)	
Epoch: [27][77/196]	LR: 0.00010000000000000003	Loss 0.0035 (0.0078)	Prec@1 100.000 (99.995)	
Epoch: [27][116/196]	LR: 0.00010000000000000003	Loss 0.0092 (0.0079)	Prec@1 100.000 (99.993)	
Epoch: [27][155/196]	LR: 0.00010000000000000003	Loss 0.0089 (0.0077)	Prec@1 100.000 (99.995)	
Epoch: [27][194/196]	LR: 0.00010000000000000003	Loss 0.0070 (0.0077)	Prec@1 100.000 (99.992)	
Total train loss: 0.0077

Train time: 19.648728609085083
 * Prec@1 88.200 Prec@5 99.320 Loss 0.4824
Best acc: 88.350
--------------------------------------------------------------------------------
Test time: 22.871081590652466

Epoch: [28][38/196]	LR: 0.00010000000000000003	Loss 0.0089 (0.0082)	Prec@1 100.000 (100.000)	
Epoch: [28][77/196]	LR: 0.00010000000000000003	Loss 0.0066 (0.0081)	Prec@1 100.000 (99.990)	
Epoch: [28][116/196]	LR: 0.00010000000000000003	Loss 0.0104 (0.0081)	Prec@1 100.000 (99.980)	
Epoch: [28][155/196]	LR: 0.00010000000000000003	Loss 0.0060 (0.0081)	Prec@1 100.000 (99.977)	
Epoch: [28][194/196]	LR: 0.00010000000000000003	Loss 0.0073 (0.0080)	Prec@1 100.000 (99.978)	
Total train loss: 0.0081

Train time: 19.85148811340332
 * Prec@1 88.270 Prec@5 99.370 Loss 0.4788
Best acc: 88.350
--------------------------------------------------------------------------------
Test time: 23.48397922515869

Epoch: [29][38/196]	LR: 0.00010000000000000003	Loss 0.0077 (0.0079)	Prec@1 100.000 (99.980)	
Epoch: [29][77/196]	LR: 0.00010000000000000003	Loss 0.0067 (0.0078)	Prec@1 100.000 (99.985)	
Epoch: [29][116/196]	LR: 0.00010000000000000003	Loss 0.0076 (0.0077)	Prec@1 100.000 (99.990)	
Epoch: [29][155/196]	LR: 0.00010000000000000003	Loss 0.0070 (0.0077)	Prec@1 100.000 (99.992)	
Epoch: [29][194/196]	LR: 0.00010000000000000003	Loss 0.0063 (0.0077)	Prec@1 100.000 (99.994)	
Total train loss: 0.0077

Train time: 13.161633729934692
 * Prec@1 88.100 Prec@5 99.370 Loss 0.4812
Best acc: 88.350
--------------------------------------------------------------------------------
Test time: 16.351040363311768


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20fp_cifar10.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 30
          start_epoch: 0
          batch_size: 256
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          milestones: [8, 16, 24]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 13
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20fp_cifar10.pth.tar ...
Original model accuracy: 91.93
ResNet_cifar(
  (conv14): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (conv18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu18): ReLU(inplace=True)
  (conv19): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu19): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (bn20): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=64, out_features=10, bias=False)
  (bn21): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 44.860 Prec@5 88.580 Loss 2.7422
Pre-trained Prec@1 with 13 layers frozen: 44.86000061035156 	 Loss: 2.7421875

Starting training on SRAM layers...
Epoch: [0][38/196]	LR: 0.1	Loss 0.3237 (0.3837)	Prec@1 86.719 (87.630)	
Epoch: [0][77/196]	LR: 0.1	Loss 0.2805 (0.3470)	Prec@1 89.062 (88.276)	
Epoch: [0][116/196]	LR: 0.1	Loss 0.3257 (0.3250)	Prec@1 89.062 (88.949)	
Epoch: [0][155/196]	LR: 0.1	Loss 0.3184 (0.3128)	Prec@1 88.281 (89.318)	
Epoch: [0][194/196]	LR: 0.1	Loss 0.2058 (0.3043)	Prec@1 92.578 (89.565)	
Total train loss: 0.3042

Train time: 157.23091435432434
 * Prec@1 86.700 Prec@5 99.470 Loss 0.4197
Best acc: 86.700
--------------------------------------------------------------------------------
Test time: 161.84546566009521

Epoch: [1][38/196]	LR: 0.1	Loss 0.1803 (0.1784)	Prec@1 94.141 (93.800)	
Epoch: [1][77/196]	LR: 0.1	Loss 0.2399 (0.1748)	Prec@1 92.188 (94.005)	
Epoch: [1][116/196]	LR: 0.1	Loss 0.1772 (0.1787)	Prec@1 91.797 (93.780)	
Epoch: [1][155/196]	LR: 0.1	Loss 0.2443 (0.1800)	Prec@1 92.578 (93.790)	
Epoch: [1][194/196]	LR: 0.1	Loss 0.2244 (0.1835)	Prec@1 91.406 (93.638)	
Total train loss: 0.1835

Train time: 21.488986492156982
 * Prec@1 86.840 Prec@5 99.480 Loss 0.4275
Best acc: 86.840
--------------------------------------------------------------------------------
Test time: 25.433128833770752

Epoch: [2][38/196]	LR: 0.1	Loss 0.1115 (0.1240)	Prec@1 96.484 (95.733)	
Epoch: [2][77/196]	LR: 0.1	Loss 0.1497 (0.1283)	Prec@1 94.531 (95.618)	
Epoch: [2][116/196]	LR: 0.1	Loss 0.1964 (0.1306)	Prec@1 93.750 (95.570)	
Epoch: [2][155/196]	LR: 0.1	Loss 0.1694 (0.1365)	Prec@1 94.922 (95.360)	
Epoch: [2][194/196]	LR: 0.1	Loss 0.1436 (0.1415)	Prec@1 94.141 (95.128)	
Total train loss: 0.1415

Train time: 19.87605094909668
 * Prec@1 84.890 Prec@5 99.190 Loss 0.5566
Best acc: 86.840
--------------------------------------------------------------------------------
Test time: 23.466970682144165

Epoch: [3][38/196]	LR: 0.1	Loss 0.0561 (0.1003)	Prec@1 99.219 (96.735)	
Epoch: [3][77/196]	LR: 0.1	Loss 0.0684 (0.1007)	Prec@1 97.656 (96.705)	
Epoch: [3][116/196]	LR: 0.1	Loss 0.0965 (0.1014)	Prec@1 96.094 (96.641)	
Epoch: [3][155/196]	LR: 0.1	Loss 0.1696 (0.1071)	Prec@1 94.531 (96.384)	
Epoch: [3][194/196]	LR: 0.1	Loss 0.1296 (0.1112)	Prec@1 94.922 (96.194)	
Total train loss: 0.1113

Train time: 18.53209924697876
 * Prec@1 84.420 Prec@5 98.910 Loss 0.6147
Best acc: 86.840
--------------------------------------------------------------------------------
Test time: 23.185735940933228

Epoch: [4][38/196]	LR: 0.1	Loss 0.1006 (0.0929)	Prec@1 96.484 (96.725)	
Epoch: [4][77/196]	LR: 0.1	Loss 0.0860 (0.0871)	Prec@1 97.266 (96.960)	
Epoch: [4][116/196]	LR: 0.1	Loss 0.1083 (0.0855)	Prec@1 95.703 (97.052)	
Epoch: [4][155/196]	LR: 0.1	Loss 0.1071 (0.0887)	Prec@1 96.094 (96.985)	
Epoch: [4][194/196]	LR: 0.1	Loss 0.1237 (0.0931)	Prec@1 95.703 (96.855)	
Total train loss: 0.0932

Train time: 20.28743004798889
 * Prec@1 86.140 Prec@5 99.230 Loss 0.5273
Best acc: 86.840
--------------------------------------------------------------------------------
Test time: 23.48533821105957

Epoch: [5][38/196]	LR: 0.1	Loss 0.0641 (0.0688)	Prec@1 98.047 (97.817)	
Epoch: [5][77/196]	LR: 0.1	Loss 0.0940 (0.0643)	Prec@1 96.875 (98.007)	
Epoch: [5][116/196]	LR: 0.1	Loss 0.0517 (0.0664)	Prec@1 98.828 (97.927)	
Epoch: [5][155/196]	LR: 0.1	Loss 0.1214 (0.0723)	Prec@1 96.484 (97.699)	
Epoch: [5][194/196]	LR: 0.1	Loss 0.0786 (0.0753)	Prec@1 97.266 (97.582)	
Total train loss: 0.0753

Train time: 19.20026683807373
 * Prec@1 85.930 Prec@5 99.100 Loss 0.5679
Best acc: 86.840
--------------------------------------------------------------------------------
Test time: 22.921366691589355

Epoch: [6][38/196]	LR: 0.1	Loss 0.0534 (0.0587)	Prec@1 98.438 (98.187)	
Epoch: [6][77/196]	LR: 0.1	Loss 0.0917 (0.0559)	Prec@1 96.094 (98.292)	
Epoch: [6][116/196]	LR: 0.1	Loss 0.0765 (0.0582)	Prec@1 98.047 (98.190)	
Epoch: [6][155/196]	LR: 0.1	Loss 0.0659 (0.0594)	Prec@1 96.484 (98.130)	
Epoch: [6][194/196]	LR: 0.1	Loss 0.0742 (0.0615)	Prec@1 98.047 (98.035)	
Total train loss: 0.0615

Train time: 18.096851348876953
 * Prec@1 85.020 Prec@5 99.080 Loss 0.6074
Best acc: 86.840
--------------------------------------------------------------------------------
Test time: 22.73549199104309

Epoch: [7][38/196]	LR: 0.1	Loss 0.0292 (0.0538)	Prec@1 99.609 (98.277)	
Epoch: [7][77/196]	LR: 0.1	Loss 0.0418 (0.0533)	Prec@1 99.609 (98.327)	
Epoch: [7][116/196]	LR: 0.1	Loss 0.0447 (0.0525)	Prec@1 99.219 (98.357)	
Epoch: [7][155/196]	LR: 0.1	Loss 0.0600 (0.0550)	Prec@1 98.047 (98.270)	
Epoch: [7][194/196]	LR: 0.1	Loss 0.0927 (0.0567)	Prec@1 96.484 (98.227)	
Total train loss: 0.0567

Train time: 18.749465465545654
 * Prec@1 84.510 Prec@5 99.150 Loss 0.6484
Best acc: 86.840
--------------------------------------------------------------------------------
Test time: 22.015535593032837

Epoch: [8][38/196]	LR: 0.010000000000000002	Loss 0.0274 (0.0395)	Prec@1 99.609 (98.988)	
Epoch: [8][77/196]	LR: 0.010000000000000002	Loss 0.0216 (0.0336)	Prec@1 99.609 (99.164)	
Epoch: [8][116/196]	LR: 0.010000000000000002	Loss 0.0674 (0.0309)	Prec@1 98.047 (99.265)	
Epoch: [8][155/196]	LR: 0.010000000000000002	Loss 0.0226 (0.0284)	Prec@1 99.609 (99.366)	
Epoch: [8][194/196]	LR: 0.010000000000000002	Loss 0.0183 (0.0269)	Prec@1 99.609 (99.419)	
Total train loss: 0.0269

Train time: 17.81957221031189
 * Prec@1 87.630 Prec@5 99.350 Loss 0.5010
Best acc: 87.630
--------------------------------------------------------------------------------
Test time: 21.40157675743103

Epoch: [9][38/196]	LR: 0.010000000000000002	Loss 0.0286 (0.0167)	Prec@1 99.609 (99.820)	
Epoch: [9][77/196]	LR: 0.010000000000000002	Loss 0.0157 (0.0165)	Prec@1 99.609 (99.825)	
Epoch: [9][116/196]	LR: 0.010000000000000002	Loss 0.0081 (0.0163)	Prec@1 100.000 (99.813)	
Epoch: [9][155/196]	LR: 0.010000000000000002	Loss 0.0141 (0.0162)	Prec@1 100.000 (99.810)	
Epoch: [9][194/196]	LR: 0.010000000000000002	Loss 0.0128 (0.0156)	Prec@1 100.000 (99.832)	
Total train loss: 0.0156

Train time: 19.50908899307251
 * Prec@1 87.600 Prec@5 99.350 Loss 0.4995
Best acc: 87.630
--------------------------------------------------------------------------------
Test time: 23.917853355407715

Epoch: [10][38/196]	LR: 0.010000000000000002	Loss 0.0115 (0.0138)	Prec@1 100.000 (99.920)	
Epoch: [10][77/196]	LR: 0.010000000000000002	Loss 0.0096 (0.0124)	Prec@1 100.000 (99.945)	
Epoch: [10][116/196]	LR: 0.010000000000000002	Loss 0.0078 (0.0123)	Prec@1 100.000 (99.943)	
Epoch: [10][155/196]	LR: 0.010000000000000002	Loss 0.0092 (0.0125)	Prec@1 100.000 (99.930)	
Epoch: [10][194/196]	LR: 0.010000000000000002	Loss 0.0209 (0.0125)	Prec@1 99.609 (99.928)	
Total train loss: 0.0126

Train time: 20.09580135345459
 * Prec@1 87.730 Prec@5 99.390 Loss 0.4995
Best acc: 87.730
--------------------------------------------------------------------------------
Test time: 23.55015802383423

Epoch: [11][38/196]	LR: 0.010000000000000002	Loss 0.0071 (0.0114)	Prec@1 100.000 (99.920)	
Epoch: [11][77/196]	LR: 0.010000000000000002	Loss 0.0083 (0.0115)	Prec@1 100.000 (99.920)	
Epoch: [11][116/196]	LR: 0.010000000000000002	Loss 0.0120 (0.0113)	Prec@1 100.000 (99.940)	
Epoch: [11][155/196]	LR: 0.010000000000000002	Loss 0.0199 (0.0117)	Prec@1 100.000 (99.922)	
Epoch: [11][194/196]	LR: 0.010000000000000002	Loss 0.0085 (0.0117)	Prec@1 100.000 (99.920)	
Total train loss: 0.0117

Train time: 19.15102529525757
 * Prec@1 87.670 Prec@5 99.350 Loss 0.5020
Best acc: 87.730
--------------------------------------------------------------------------------
Test time: 22.623283624649048

Epoch: [12][38/196]	LR: 0.010000000000000002	Loss 0.0122 (0.0105)	Prec@1 100.000 (99.980)	
Epoch: [12][77/196]	LR: 0.010000000000000002	Loss 0.0075 (0.0105)	Prec@1 100.000 (99.975)	
Epoch: [12][116/196]	LR: 0.010000000000000002	Loss 0.0155 (0.0106)	Prec@1 100.000 (99.977)	
Epoch: [12][155/196]	LR: 0.010000000000000002	Loss 0.0176 (0.0107)	Prec@1 100.000 (99.967)	
Epoch: [12][194/196]	LR: 0.010000000000000002	Loss 0.0133 (0.0106)	Prec@1 100.000 (99.970)	
Total train loss: 0.0106

Train time: 18.727505445480347
 * Prec@1 87.800 Prec@5 99.370 Loss 0.4993
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 22.919300079345703

Epoch: [13][38/196]	LR: 0.010000000000000002	Loss 0.0071 (0.0094)	Prec@1 100.000 (99.970)	
Epoch: [13][77/196]	LR: 0.010000000000000002	Loss 0.0110 (0.0096)	Prec@1 100.000 (99.965)	
Epoch: [13][116/196]	LR: 0.010000000000000002	Loss 0.0083 (0.0096)	Prec@1 100.000 (99.973)	
Epoch: [13][155/196]	LR: 0.010000000000000002	Loss 0.0089 (0.0099)	Prec@1 100.000 (99.972)	
Epoch: [13][194/196]	LR: 0.010000000000000002	Loss 0.0122 (0.0099)	Prec@1 100.000 (99.966)	
Total train loss: 0.0100

Train time: 19.384036540985107
 * Prec@1 87.580 Prec@5 99.290 Loss 0.5034
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 23.455090522766113

Epoch: [14][38/196]	LR: 0.010000000000000002	Loss 0.0083 (0.0093)	Prec@1 100.000 (99.990)	
Epoch: [14][77/196]	LR: 0.010000000000000002	Loss 0.0135 (0.0093)	Prec@1 100.000 (99.975)	
Epoch: [14][116/196]	LR: 0.010000000000000002	Loss 0.0143 (0.0093)	Prec@1 100.000 (99.980)	
Epoch: [14][155/196]	LR: 0.010000000000000002	Loss 0.0067 (0.0094)	Prec@1 100.000 (99.982)	
Epoch: [14][194/196]	LR: 0.010000000000000002	Loss 0.0063 (0.0093)	Prec@1 100.000 (99.982)	
Total train loss: 0.0094

Train time: 19.149818658828735
 * Prec@1 87.580 Prec@5 99.330 Loss 0.5010
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 22.57259178161621

Epoch: [15][38/196]	LR: 0.010000000000000002	Loss 0.0132 (0.0090)	Prec@1 100.000 (99.960)	
Epoch: [15][77/196]	LR: 0.010000000000000002	Loss 0.0071 (0.0085)	Prec@1 100.000 (99.970)	
Epoch: [15][116/196]	LR: 0.010000000000000002	Loss 0.0093 (0.0086)	Prec@1 100.000 (99.977)	
Epoch: [15][155/196]	LR: 0.010000000000000002	Loss 0.0080 (0.0087)	Prec@1 100.000 (99.977)	
Epoch: [15][194/196]	LR: 0.010000000000000002	Loss 0.0093 (0.0087)	Prec@1 100.000 (99.982)	
Total train loss: 0.0087

Train time: 19.49121332168579
 * Prec@1 87.560 Prec@5 99.300 Loss 0.5034
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 24.262377977371216

Epoch: [16][38/196]	LR: 0.0010000000000000002	Loss 0.0116 (0.0083)	Prec@1 100.000 (100.000)	
Epoch: [16][77/196]	LR: 0.0010000000000000002	Loss 0.0077 (0.0083)	Prec@1 100.000 (99.995)	
Epoch: [16][116/196]	LR: 0.0010000000000000002	Loss 0.0071 (0.0083)	Prec@1 100.000 (99.987)	
Epoch: [16][155/196]	LR: 0.0010000000000000002	Loss 0.0076 (0.0081)	Prec@1 100.000 (99.990)	
Epoch: [16][194/196]	LR: 0.0010000000000000002	Loss 0.0067 (0.0083)	Prec@1 100.000 (99.988)	
Total train loss: 0.0083

Train time: 18.979777097702026
 * Prec@1 87.640 Prec@5 99.290 Loss 0.5039
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 22.81928014755249

Epoch: [17][38/196]	LR: 0.0010000000000000002	Loss 0.0051 (0.0085)	Prec@1 100.000 (99.990)	
Epoch: [17][77/196]	LR: 0.0010000000000000002	Loss 0.0052 (0.0086)	Prec@1 100.000 (99.990)	
Epoch: [17][116/196]	LR: 0.0010000000000000002	Loss 0.0084 (0.0086)	Prec@1 100.000 (99.990)	
Epoch: [17][155/196]	LR: 0.0010000000000000002	Loss 0.0063 (0.0088)	Prec@1 100.000 (99.985)	
Epoch: [17][194/196]	LR: 0.0010000000000000002	Loss 0.0053 (0.0087)	Prec@1 100.000 (99.988)	
Total train loss: 0.0087

Train time: 18.704753637313843
 * Prec@1 87.770 Prec@5 99.300 Loss 0.5015
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 21.952308654785156

Epoch: [18][38/196]	LR: 0.0010000000000000002	Loss 0.0074 (0.0087)	Prec@1 100.000 (99.990)	
Epoch: [18][77/196]	LR: 0.0010000000000000002	Loss 0.0156 (0.0088)	Prec@1 100.000 (99.990)	
Epoch: [18][116/196]	LR: 0.0010000000000000002	Loss 0.0051 (0.0086)	Prec@1 100.000 (99.990)	
Epoch: [18][155/196]	LR: 0.0010000000000000002	Loss 0.0062 (0.0087)	Prec@1 100.000 (99.985)	
Epoch: [18][194/196]	LR: 0.0010000000000000002	Loss 0.0061 (0.0085)	Prec@1 100.000 (99.984)	
Total train loss: 0.0086

Train time: 18.85226273536682
 * Prec@1 87.670 Prec@5 99.300 Loss 0.5020
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 23.204252004623413

Epoch: [19][38/196]	LR: 0.0010000000000000002	Loss 0.0075 (0.0083)	Prec@1 100.000 (99.990)	
Epoch: [19][77/196]	LR: 0.0010000000000000002	Loss 0.0062 (0.0086)	Prec@1 100.000 (99.985)	
Epoch: [19][116/196]	LR: 0.0010000000000000002	Loss 0.0079 (0.0086)	Prec@1 100.000 (99.980)	
Epoch: [19][155/196]	LR: 0.0010000000000000002	Loss 0.0076 (0.0084)	Prec@1 100.000 (99.985)	
Epoch: [19][194/196]	LR: 0.0010000000000000002	Loss 0.0080 (0.0086)	Prec@1 100.000 (99.982)	
Total train loss: 0.0086

Train time: 19.337652921676636
 * Prec@1 87.560 Prec@5 99.310 Loss 0.5044
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 22.81065344810486

Epoch: [20][38/196]	LR: 0.0010000000000000002	Loss 0.0078 (0.0084)	Prec@1 100.000 (100.000)	
Epoch: [20][77/196]	LR: 0.0010000000000000002	Loss 0.0097 (0.0087)	Prec@1 100.000 (99.990)	
Epoch: [20][116/196]	LR: 0.0010000000000000002	Loss 0.0137 (0.0086)	Prec@1 100.000 (99.993)	
Epoch: [20][155/196]	LR: 0.0010000000000000002	Loss 0.0062 (0.0086)	Prec@1 100.000 (99.992)	
Epoch: [20][194/196]	LR: 0.0010000000000000002	Loss 0.0138 (0.0085)	Prec@1 100.000 (99.992)	
Total train loss: 0.0086

Train time: 18.505173683166504
 * Prec@1 87.760 Prec@5 99.320 Loss 0.5049
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 22.305293321609497

Epoch: [21][38/196]	LR: 0.0010000000000000002	Loss 0.0081 (0.0088)	Prec@1 100.000 (99.990)	
Epoch: [21][77/196]	LR: 0.0010000000000000002	Loss 0.0121 (0.0085)	Prec@1 100.000 (99.990)	
Epoch: [21][116/196]	LR: 0.0010000000000000002	Loss 0.0095 (0.0088)	Prec@1 100.000 (99.973)	
Epoch: [21][155/196]	LR: 0.0010000000000000002	Loss 0.0109 (0.0087)	Prec@1 100.000 (99.975)	
Epoch: [21][194/196]	LR: 0.0010000000000000002	Loss 0.0132 (0.0087)	Prec@1 100.000 (99.978)	
Total train loss: 0.0087

Train time: 18.91248106956482
 * Prec@1 87.510 Prec@5 99.270 Loss 0.5073
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 22.885474681854248

Epoch: [22][38/196]	LR: 0.0010000000000000002	Loss 0.0085 (0.0083)	Prec@1 100.000 (99.980)	
Epoch: [22][77/196]	LR: 0.0010000000000000002	Loss 0.0114 (0.0085)	Prec@1 99.609 (99.975)	
Epoch: [22][116/196]	LR: 0.0010000000000000002	Loss 0.0052 (0.0084)	Prec@1 100.000 (99.973)	
Epoch: [22][155/196]	LR: 0.0010000000000000002	Loss 0.0085 (0.0084)	Prec@1 100.000 (99.977)	
Epoch: [22][194/196]	LR: 0.0010000000000000002	Loss 0.0088 (0.0086)	Prec@1 100.000 (99.974)	
Total train loss: 0.0086

Train time: 20.762128114700317
 * Prec@1 87.640 Prec@5 99.310 Loss 0.5054
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 24.09134840965271

Epoch: [23][38/196]	LR: 0.0010000000000000002	Loss 0.0074 (0.0083)	Prec@1 100.000 (99.990)	
Epoch: [23][77/196]	LR: 0.0010000000000000002	Loss 0.0126 (0.0085)	Prec@1 100.000 (99.985)	
Epoch: [23][116/196]	LR: 0.0010000000000000002	Loss 0.0067 (0.0084)	Prec@1 100.000 (99.990)	
Epoch: [23][155/196]	LR: 0.0010000000000000002	Loss 0.0065 (0.0086)	Prec@1 100.000 (99.982)	
Epoch: [23][194/196]	LR: 0.0010000000000000002	Loss 0.0116 (0.0087)	Prec@1 100.000 (99.980)	
Total train loss: 0.0087

Train time: 18.165650367736816
 * Prec@1 87.650 Prec@5 99.290 Loss 0.5024
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 21.457239389419556

Epoch: [24][38/196]	LR: 0.00010000000000000003	Loss 0.0114 (0.0085)	Prec@1 100.000 (99.990)	
Epoch: [24][77/196]	LR: 0.00010000000000000003	Loss 0.0061 (0.0085)	Prec@1 100.000 (99.995)	
Epoch: [24][116/196]	LR: 0.00010000000000000003	Loss 0.0093 (0.0087)	Prec@1 100.000 (99.990)	
Epoch: [24][155/196]	LR: 0.00010000000000000003	Loss 0.0078 (0.0087)	Prec@1 100.000 (99.987)	
Epoch: [24][194/196]	LR: 0.00010000000000000003	Loss 0.0064 (0.0086)	Prec@1 100.000 (99.984)	
Total train loss: 0.0086

Train time: 18.909397840499878
 * Prec@1 87.650 Prec@5 99.290 Loss 0.5049
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 23.746368646621704

Epoch: [25][38/196]	LR: 0.00010000000000000003	Loss 0.0099 (0.0088)	Prec@1 100.000 (99.970)	
Epoch: [25][77/196]	LR: 0.00010000000000000003	Loss 0.0075 (0.0086)	Prec@1 100.000 (99.980)	
Epoch: [25][116/196]	LR: 0.00010000000000000003	Loss 0.0065 (0.0086)	Prec@1 100.000 (99.977)	
Epoch: [25][155/196]	LR: 0.00010000000000000003	Loss 0.0093 (0.0086)	Prec@1 100.000 (99.977)	
Epoch: [25][194/196]	LR: 0.00010000000000000003	Loss 0.0086 (0.0085)	Prec@1 100.000 (99.980)	
Total train loss: 0.0085

Train time: 18.517848014831543
 * Prec@1 87.710 Prec@5 99.270 Loss 0.5015
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 21.79813861846924

Epoch: [26][38/196]	LR: 0.00010000000000000003	Loss 0.0079 (0.0099)	Prec@1 100.000 (99.920)	
Epoch: [26][77/196]	LR: 0.00010000000000000003	Loss 0.0081 (0.0096)	Prec@1 100.000 (99.955)	
Epoch: [26][116/196]	LR: 0.00010000000000000003	Loss 0.0138 (0.0092)	Prec@1 100.000 (99.967)	
Epoch: [26][155/196]	LR: 0.00010000000000000003	Loss 0.0134 (0.0091)	Prec@1 100.000 (99.972)	
Epoch: [26][194/196]	LR: 0.00010000000000000003	Loss 0.0041 (0.0090)	Prec@1 100.000 (99.976)	
Total train loss: 0.0090

Train time: 19.185407876968384
 * Prec@1 87.630 Prec@5 99.330 Loss 0.5054
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 22.85684585571289

Epoch: [27][38/196]	LR: 0.00010000000000000003	Loss 0.0069 (0.0087)	Prec@1 100.000 (99.980)	
Epoch: [27][77/196]	LR: 0.00010000000000000003	Loss 0.0066 (0.0086)	Prec@1 100.000 (99.975)	
Epoch: [27][116/196]	LR: 0.00010000000000000003	Loss 0.0108 (0.0088)	Prec@1 100.000 (99.983)	
Epoch: [27][155/196]	LR: 0.00010000000000000003	Loss 0.0065 (0.0086)	Prec@1 100.000 (99.982)	
Epoch: [27][194/196]	LR: 0.00010000000000000003	Loss 0.0079 (0.0086)	Prec@1 100.000 (99.982)	
Total train loss: 0.0086

Train time: 18.41326332092285
 * Prec@1 87.630 Prec@5 99.240 Loss 0.5078
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 22.819544315338135

Epoch: [28][38/196]	LR: 0.00010000000000000003	Loss 0.0090 (0.0091)	Prec@1 100.000 (99.990)	
Epoch: [28][77/196]	LR: 0.00010000000000000003	Loss 0.0071 (0.0090)	Prec@1 100.000 (99.985)	
Epoch: [28][116/196]	LR: 0.00010000000000000003	Loss 0.0074 (0.0089)	Prec@1 100.000 (99.990)	
Epoch: [28][155/196]	LR: 0.00010000000000000003	Loss 0.0094 (0.0087)	Prec@1 100.000 (99.990)	
Epoch: [28][194/196]	LR: 0.00010000000000000003	Loss 0.0114 (0.0087)	Prec@1 100.000 (99.988)	
Total train loss: 0.0087

Train time: 13.385486602783203
 * Prec@1 87.650 Prec@5 99.310 Loss 0.5020
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 16.10254430770874

Epoch: [29][38/196]	LR: 0.00010000000000000003	Loss 0.0143 (0.0088)	Prec@1 100.000 (99.990)	
Epoch: [29][77/196]	LR: 0.00010000000000000003	Loss 0.0072 (0.0090)	Prec@1 100.000 (99.995)	
Epoch: [29][116/196]	LR: 0.00010000000000000003	Loss 0.0077 (0.0091)	Prec@1 100.000 (99.993)	
Epoch: [29][155/196]	LR: 0.00010000000000000003	Loss 0.0082 (0.0089)	Prec@1 100.000 (99.987)	
Epoch: [29][194/196]	LR: 0.00010000000000000003	Loss 0.0068 (0.0087)	Prec@1 100.000 (99.988)	
Total train loss: 0.0087

Train time: 10.828354597091675
 * Prec@1 87.670 Prec@5 99.280 Loss 0.5020
Best acc: 87.800
--------------------------------------------------------------------------------
Test time: 12.777562618255615


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20fp_cifar10.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 30
          start_epoch: 0
          batch_size: 256
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          milestones: [8, 16, 24]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 15
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20fp_cifar10.pth.tar ...
Original model accuracy: 91.93
ResNet_cifar(
  (conv16): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (conv18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu18): ReLU(inplace=True)
  (conv19): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu19): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (bn20): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=64, out_features=10, bias=False)
  (bn21): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 35.290 Prec@5 85.340 Loss 3.0410
Pre-trained Prec@1 with 15 layers frozen: 35.290000915527344 	 Loss: 3.041015625

Starting training on SRAM layers...
Epoch: [0][38/196]	LR: 0.1	Loss 0.5474 (0.7737)	Prec@1 81.250 (76.893)	
Epoch: [0][77/196]	LR: 0.1	Loss 0.3552 (0.6462)	Prec@1 87.109 (79.512)	
Epoch: [0][116/196]	LR: 0.1	Loss 0.3501 (0.5843)	Prec@1 88.672 (80.973)	
Epoch: [0][155/196]	LR: 0.1	Loss 0.3477 (0.5452)	Prec@1 87.500 (82.051)	
Epoch: [0][194/196]	LR: 0.1	Loss 0.4834 (0.5238)	Prec@1 82.812 (82.604)	
Total train loss: 0.5236

Train time: 191.51865196228027
 * Prec@1 83.430 Prec@5 99.100 Loss 0.5063
Best acc: 83.430
--------------------------------------------------------------------------------
Test time: 195.59353375434875

Epoch: [1][38/196]	LR: 0.1	Loss 0.3655 (0.3400)	Prec@1 87.891 (88.442)	
Epoch: [1][77/196]	LR: 0.1	Loss 0.3938 (0.3443)	Prec@1 85.547 (88.136)	
Epoch: [1][116/196]	LR: 0.1	Loss 0.3870 (0.3432)	Prec@1 87.500 (88.084)	
Epoch: [1][155/196]	LR: 0.1	Loss 0.3782 (0.3477)	Prec@1 87.891 (87.926)	
Epoch: [1][194/196]	LR: 0.1	Loss 0.3440 (0.3513)	Prec@1 84.766 (87.817)	
Total train loss: 0.3513

Train time: 18.773784160614014
 * Prec@1 83.860 Prec@5 99.140 Loss 0.4993
Best acc: 83.860
--------------------------------------------------------------------------------
Test time: 22.306039094924927

Epoch: [2][38/196]	LR: 0.1	Loss 0.2844 (0.2705)	Prec@1 91.016 (90.515)	
Epoch: [2][77/196]	LR: 0.1	Loss 0.2803 (0.2760)	Prec@1 91.016 (90.294)	
Epoch: [2][116/196]	LR: 0.1	Loss 0.2610 (0.2839)	Prec@1 90.234 (90.001)	
Epoch: [2][155/196]	LR: 0.1	Loss 0.2876 (0.2896)	Prec@1 89.453 (89.804)	
Epoch: [2][194/196]	LR: 0.1	Loss 0.3293 (0.2963)	Prec@1 87.500 (89.573)	
Total train loss: 0.2963

Train time: 18.800914525985718
 * Prec@1 84.210 Prec@5 98.930 Loss 0.5059
Best acc: 84.210
--------------------------------------------------------------------------------
Test time: 21.764183521270752

Epoch: [3][38/196]	LR: 0.1	Loss 0.2101 (0.2220)	Prec@1 91.016 (92.117)	
Epoch: [3][77/196]	LR: 0.1	Loss 0.2590 (0.2335)	Prec@1 87.891 (91.752)	
Epoch: [3][116/196]	LR: 0.1	Loss 0.2600 (0.2430)	Prec@1 92.578 (91.446)	
Epoch: [3][155/196]	LR: 0.1	Loss 0.3530 (0.2482)	Prec@1 87.500 (91.314)	
Epoch: [3][194/196]	LR: 0.1	Loss 0.3315 (0.2559)	Prec@1 89.453 (91.020)	
Total train loss: 0.2561

Train time: 15.838157415390015
 * Prec@1 83.340 Prec@5 99.180 Loss 0.5366
Best acc: 84.210
--------------------------------------------------------------------------------
Test time: 19.814820766448975

Epoch: [4][38/196]	LR: 0.1	Loss 0.2542 (0.1938)	Prec@1 93.359 (93.289)	
Epoch: [4][77/196]	LR: 0.1	Loss 0.1613 (0.2001)	Prec@1 95.312 (92.999)	
Epoch: [4][116/196]	LR: 0.1	Loss 0.2622 (0.2097)	Prec@1 90.234 (92.642)	
Epoch: [4][155/196]	LR: 0.1	Loss 0.2908 (0.2155)	Prec@1 91.406 (92.508)	
Epoch: [4][194/196]	LR: 0.1	Loss 0.1699 (0.2199)	Prec@1 95.312 (92.340)	
Total train loss: 0.2200

Train time: 18.962212085723877
 * Prec@1 83.650 Prec@5 99.050 Loss 0.5703
Best acc: 84.210
--------------------------------------------------------------------------------
Test time: 22.048601388931274

Epoch: [5][38/196]	LR: 0.1	Loss 0.1664 (0.1743)	Prec@1 93.359 (93.990)	
Epoch: [5][77/196]	LR: 0.1	Loss 0.2078 (0.1729)	Prec@1 92.578 (94.035)	
Epoch: [5][116/196]	LR: 0.1	Loss 0.2095 (0.1749)	Prec@1 91.406 (93.910)	
Epoch: [5][155/196]	LR: 0.1	Loss 0.1854 (0.1829)	Prec@1 91.797 (93.562)	
Epoch: [5][194/196]	LR: 0.1	Loss 0.2423 (0.1917)	Prec@1 92.188 (93.227)	
Total train loss: 0.1918

Train time: 17.65828514099121
 * Prec@1 81.440 Prec@5 99.010 Loss 0.7051
Best acc: 84.210
--------------------------------------------------------------------------------
Test time: 21.43237066268921

Epoch: [6][38/196]	LR: 0.1	Loss 0.1682 (0.1542)	Prec@1 93.750 (94.892)	
Epoch: [6][77/196]	LR: 0.1	Loss 0.1190 (0.1495)	Prec@1 95.703 (94.907)	
Epoch: [6][116/196]	LR: 0.1	Loss 0.1506 (0.1579)	Prec@1 93.359 (94.545)	
Epoch: [6][155/196]	LR: 0.1	Loss 0.1781 (0.1596)	Prec@1 94.141 (94.461)	
Epoch: [6][194/196]	LR: 0.1	Loss 0.2201 (0.1682)	Prec@1 92.188 (94.129)	
Total train loss: 0.1683

Train time: 17.722805976867676
 * Prec@1 82.100 Prec@5 99.000 Loss 0.6470
Best acc: 84.210
--------------------------------------------------------------------------------
Test time: 21.452082872390747

Epoch: [7][38/196]	LR: 0.1	Loss 0.1345 (0.1420)	Prec@1 96.094 (95.333)	
Epoch: [7][77/196]	LR: 0.1	Loss 0.1080 (0.1344)	Prec@1 96.094 (95.443)	
Epoch: [7][116/196]	LR: 0.1	Loss 0.0843 (0.1411)	Prec@1 96.875 (95.142)	
Epoch: [7][155/196]	LR: 0.1	Loss 0.2131 (0.1463)	Prec@1 92.969 (94.914)	
Epoch: [7][194/196]	LR: 0.1	Loss 0.1722 (0.1515)	Prec@1 94.531 (94.750)	
Total train loss: 0.1522

Train time: 19.021946668624878
 * Prec@1 82.470 Prec@5 99.030 Loss 0.6772
Best acc: 84.210
--------------------------------------------------------------------------------
Test time: 22.64820408821106

Epoch: [8][38/196]	LR: 0.010000000000000002	Loss 0.1036 (0.1025)	Prec@1 97.266 (96.765)	
Epoch: [8][77/196]	LR: 0.010000000000000002	Loss 0.0620 (0.0889)	Prec@1 98.438 (97.371)	
Epoch: [8][116/196]	LR: 0.010000000000000002	Loss 0.0790 (0.0839)	Prec@1 98.047 (97.539)	
Epoch: [8][155/196]	LR: 0.010000000000000002	Loss 0.0540 (0.0794)	Prec@1 98.828 (97.759)	
Epoch: [8][194/196]	LR: 0.010000000000000002	Loss 0.0703 (0.0764)	Prec@1 97.656 (97.859)	
Total train loss: 0.0764

Train time: 18.18763041496277
 * Prec@1 84.900 Prec@5 99.180 Loss 0.5654
Best acc: 84.900
--------------------------------------------------------------------------------
Test time: 21.305866718292236

Epoch: [9][38/196]	LR: 0.010000000000000002	Loss 0.0541 (0.0522)	Prec@1 98.828 (98.868)	
Epoch: [9][77/196]	LR: 0.010000000000000002	Loss 0.0353 (0.0508)	Prec@1 99.219 (98.963)	
Epoch: [9][116/196]	LR: 0.010000000000000002	Loss 0.0547 (0.0515)	Prec@1 98.438 (98.935)	
Epoch: [9][155/196]	LR: 0.010000000000000002	Loss 0.0584 (0.0512)	Prec@1 99.219 (98.951)	
Epoch: [9][194/196]	LR: 0.010000000000000002	Loss 0.0725 (0.0504)	Prec@1 97.266 (98.968)	
Total train loss: 0.0504

Train time: 17.329103231430054
 * Prec@1 84.940 Prec@5 99.060 Loss 0.5791
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 21.422226905822754

Epoch: [10][38/196]	LR: 0.010000000000000002	Loss 0.0470 (0.0440)	Prec@1 99.219 (99.299)	
Epoch: [10][77/196]	LR: 0.010000000000000002	Loss 0.0252 (0.0433)	Prec@1 99.609 (99.264)	
Epoch: [10][116/196]	LR: 0.010000000000000002	Loss 0.0497 (0.0431)	Prec@1 99.609 (99.272)	
Epoch: [10][155/196]	LR: 0.010000000000000002	Loss 0.0410 (0.0423)	Prec@1 99.609 (99.309)	
Epoch: [10][194/196]	LR: 0.010000000000000002	Loss 0.0413 (0.0426)	Prec@1 99.219 (99.293)	
Total train loss: 0.0427

Train time: 18.319348573684692
 * Prec@1 84.880 Prec@5 99.100 Loss 0.5801
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 21.563475608825684

Epoch: [11][38/196]	LR: 0.010000000000000002	Loss 0.0558 (0.0351)	Prec@1 98.828 (99.579)	
Epoch: [11][77/196]	LR: 0.010000000000000002	Loss 0.0318 (0.0361)	Prec@1 99.219 (99.589)	
Epoch: [11][116/196]	LR: 0.010000000000000002	Loss 0.0422 (0.0363)	Prec@1 99.609 (99.569)	
Epoch: [11][155/196]	LR: 0.010000000000000002	Loss 0.0321 (0.0360)	Prec@1 100.000 (99.567)	
Epoch: [11][194/196]	LR: 0.010000000000000002	Loss 0.0337 (0.0364)	Prec@1 99.609 (99.537)	
Total train loss: 0.0364

Train time: 18.52628469467163
 * Prec@1 84.860 Prec@5 99.120 Loss 0.5913
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 21.75057888031006

Epoch: [12][38/196]	LR: 0.010000000000000002	Loss 0.0172 (0.0328)	Prec@1 100.000 (99.679)	
Epoch: [12][77/196]	LR: 0.010000000000000002	Loss 0.0328 (0.0322)	Prec@1 100.000 (99.684)	
Epoch: [12][116/196]	LR: 0.010000000000000002	Loss 0.0359 (0.0327)	Prec@1 100.000 (99.666)	
Epoch: [12][155/196]	LR: 0.010000000000000002	Loss 0.0428 (0.0331)	Prec@1 99.219 (99.687)	
Epoch: [12][194/196]	LR: 0.010000000000000002	Loss 0.0282 (0.0333)	Prec@1 99.609 (99.665)	
Total train loss: 0.0333

Train time: 18.26819086074829
 * Prec@1 84.640 Prec@5 99.060 Loss 0.5991
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 22.01951837539673

Epoch: [13][38/196]	LR: 0.010000000000000002	Loss 0.0259 (0.0295)	Prec@1 100.000 (99.750)	
Epoch: [13][77/196]	LR: 0.010000000000000002	Loss 0.0294 (0.0310)	Prec@1 100.000 (99.735)	
Epoch: [13][116/196]	LR: 0.010000000000000002	Loss 0.0379 (0.0317)	Prec@1 99.609 (99.710)	
Epoch: [13][155/196]	LR: 0.010000000000000002	Loss 0.0352 (0.0317)	Prec@1 99.609 (99.700)	
Epoch: [13][194/196]	LR: 0.010000000000000002	Loss 0.0334 (0.0316)	Prec@1 100.000 (99.706)	
Total train loss: 0.0317

Train time: 17.398440837860107
 * Prec@1 84.670 Prec@5 99.030 Loss 0.6006
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 20.964812755584717

Epoch: [14][38/196]	LR: 0.010000000000000002	Loss 0.0205 (0.0278)	Prec@1 100.000 (99.790)	
Epoch: [14][77/196]	LR: 0.010000000000000002	Loss 0.0297 (0.0284)	Prec@1 99.219 (99.785)	
Epoch: [14][116/196]	LR: 0.010000000000000002	Loss 0.0351 (0.0280)	Prec@1 99.219 (99.816)	
Epoch: [14][155/196]	LR: 0.010000000000000002	Loss 0.0318 (0.0286)	Prec@1 99.609 (99.795)	
Epoch: [14][194/196]	LR: 0.010000000000000002	Loss 0.0358 (0.0289)	Prec@1 99.219 (99.766)	
Total train loss: 0.0289

Train time: 18.638065814971924
 * Prec@1 84.530 Prec@5 99.020 Loss 0.6074
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 21.801000595092773

Epoch: [15][38/196]	LR: 0.010000000000000002	Loss 0.0341 (0.0280)	Prec@1 100.000 (99.750)	
Epoch: [15][77/196]	LR: 0.010000000000000002	Loss 0.0406 (0.0275)	Prec@1 99.609 (99.815)	
Epoch: [15][116/196]	LR: 0.010000000000000002	Loss 0.0248 (0.0271)	Prec@1 100.000 (99.830)	
Epoch: [15][155/196]	LR: 0.010000000000000002	Loss 0.0301 (0.0271)	Prec@1 100.000 (99.835)	
Epoch: [15][194/196]	LR: 0.010000000000000002	Loss 0.0243 (0.0273)	Prec@1 100.000 (99.838)	
Total train loss: 0.0273

Train time: 18.679733753204346
 * Prec@1 84.630 Prec@5 98.990 Loss 0.6138
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 22.582968950271606

Epoch: [16][38/196]	LR: 0.0010000000000000002	Loss 0.0186 (0.0255)	Prec@1 100.000 (99.840)	
Epoch: [16][77/196]	LR: 0.0010000000000000002	Loss 0.0192 (0.0262)	Prec@1 100.000 (99.840)	
Epoch: [16][116/196]	LR: 0.0010000000000000002	Loss 0.0208 (0.0258)	Prec@1 99.609 (99.843)	
Epoch: [16][155/196]	LR: 0.0010000000000000002	Loss 0.0212 (0.0254)	Prec@1 100.000 (99.862)	
Epoch: [16][194/196]	LR: 0.0010000000000000002	Loss 0.0189 (0.0255)	Prec@1 100.000 (99.856)	
Total train loss: 0.0255

Train time: 17.582246780395508
 * Prec@1 84.650 Prec@5 98.980 Loss 0.6128
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 20.645145416259766

Epoch: [17][38/196]	LR: 0.0010000000000000002	Loss 0.0280 (0.0250)	Prec@1 100.000 (99.830)	
Epoch: [17][77/196]	LR: 0.0010000000000000002	Loss 0.0273 (0.0248)	Prec@1 99.609 (99.865)	
Epoch: [17][116/196]	LR: 0.0010000000000000002	Loss 0.0380 (0.0255)	Prec@1 99.609 (99.836)	
Epoch: [17][155/196]	LR: 0.0010000000000000002	Loss 0.0263 (0.0253)	Prec@1 99.609 (99.850)	
Epoch: [17][194/196]	LR: 0.0010000000000000002	Loss 0.0222 (0.0256)	Prec@1 100.000 (99.850)	
Total train loss: 0.0256

Train time: 18.535639762878418
 * Prec@1 84.590 Prec@5 99.010 Loss 0.6138
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 21.78066658973694

Epoch: [18][38/196]	LR: 0.0010000000000000002	Loss 0.0185 (0.0256)	Prec@1 100.000 (99.840)	
Epoch: [18][77/196]	LR: 0.0010000000000000002	Loss 0.0346 (0.0258)	Prec@1 99.609 (99.850)	
Epoch: [18][116/196]	LR: 0.0010000000000000002	Loss 0.0266 (0.0261)	Prec@1 100.000 (99.840)	
Epoch: [18][155/196]	LR: 0.0010000000000000002	Loss 0.0189 (0.0252)	Prec@1 100.000 (99.862)	
Epoch: [18][194/196]	LR: 0.0010000000000000002	Loss 0.0185 (0.0253)	Prec@1 100.000 (99.852)	
Total train loss: 0.0254

Train time: 18.957128763198853
 * Prec@1 84.600 Prec@5 98.980 Loss 0.6172
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 22.426314115524292

Epoch: [19][38/196]	LR: 0.0010000000000000002	Loss 0.0451 (0.0255)	Prec@1 98.828 (99.840)	
Epoch: [19][77/196]	LR: 0.0010000000000000002	Loss 0.0161 (0.0255)	Prec@1 100.000 (99.870)	
Epoch: [19][116/196]	LR: 0.0010000000000000002	Loss 0.0257 (0.0254)	Prec@1 100.000 (99.866)	
Epoch: [19][155/196]	LR: 0.0010000000000000002	Loss 0.0306 (0.0254)	Prec@1 99.609 (99.867)	
Epoch: [19][194/196]	LR: 0.0010000000000000002	Loss 0.0158 (0.0249)	Prec@1 100.000 (99.876)	
Total train loss: 0.0249

Train time: 17.2455952167511
 * Prec@1 84.720 Prec@5 98.990 Loss 0.6118
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 20.849360466003418

Epoch: [20][38/196]	LR: 0.0010000000000000002	Loss 0.0346 (0.0260)	Prec@1 99.219 (99.880)	
Epoch: [20][77/196]	LR: 0.0010000000000000002	Loss 0.0276 (0.0256)	Prec@1 99.609 (99.850)	
Epoch: [20][116/196]	LR: 0.0010000000000000002	Loss 0.0253 (0.0253)	Prec@1 100.000 (99.830)	
Epoch: [20][155/196]	LR: 0.0010000000000000002	Loss 0.0224 (0.0251)	Prec@1 100.000 (99.837)	
Epoch: [20][194/196]	LR: 0.0010000000000000002	Loss 0.0251 (0.0253)	Prec@1 100.000 (99.852)	
Total train loss: 0.0253

Train time: 17.28473711013794
 * Prec@1 84.640 Prec@5 98.960 Loss 0.6152
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 20.2929744720459

Epoch: [21][38/196]	LR: 0.0010000000000000002	Loss 0.0220 (0.0265)	Prec@1 100.000 (99.830)	
Epoch: [21][77/196]	LR: 0.0010000000000000002	Loss 0.0253 (0.0254)	Prec@1 100.000 (99.840)	
Epoch: [21][116/196]	LR: 0.0010000000000000002	Loss 0.0235 (0.0257)	Prec@1 100.000 (99.836)	
Epoch: [21][155/196]	LR: 0.0010000000000000002	Loss 0.0232 (0.0255)	Prec@1 100.000 (99.857)	
Epoch: [21][194/196]	LR: 0.0010000000000000002	Loss 0.0240 (0.0254)	Prec@1 100.000 (99.852)	
Total train loss: 0.0255

Train time: 17.404831409454346
 * Prec@1 84.570 Prec@5 98.990 Loss 0.6206
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 21.480870962142944

Epoch: [22][38/196]	LR: 0.0010000000000000002	Loss 0.0169 (0.0263)	Prec@1 100.000 (99.790)	
Epoch: [22][77/196]	LR: 0.0010000000000000002	Loss 0.0211 (0.0257)	Prec@1 100.000 (99.790)	
Epoch: [22][116/196]	LR: 0.0010000000000000002	Loss 0.0252 (0.0255)	Prec@1 99.609 (99.820)	
Epoch: [22][155/196]	LR: 0.0010000000000000002	Loss 0.0197 (0.0249)	Prec@1 100.000 (99.850)	
Epoch: [22][194/196]	LR: 0.0010000000000000002	Loss 0.0247 (0.0249)	Prec@1 100.000 (99.850)	
Total train loss: 0.0250

Train time: 18.831047534942627
 * Prec@1 84.740 Prec@5 98.960 Loss 0.6162
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 21.97741675376892

Epoch: [23][38/196]	LR: 0.0010000000000000002	Loss 0.0283 (0.0261)	Prec@1 100.000 (99.840)	
Epoch: [23][77/196]	LR: 0.0010000000000000002	Loss 0.0274 (0.0261)	Prec@1 100.000 (99.800)	
Epoch: [23][116/196]	LR: 0.0010000000000000002	Loss 0.0224 (0.0254)	Prec@1 100.000 (99.823)	
Epoch: [23][155/196]	LR: 0.0010000000000000002	Loss 0.0247 (0.0251)	Prec@1 100.000 (99.832)	
Epoch: [23][194/196]	LR: 0.0010000000000000002	Loss 0.0313 (0.0252)	Prec@1 100.000 (99.846)	
Total train loss: 0.0252

Train time: 18.70952868461609
 * Prec@1 84.620 Prec@5 99.000 Loss 0.6187
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 21.842633962631226

Epoch: [24][38/196]	LR: 0.00010000000000000003	Loss 0.0201 (0.0239)	Prec@1 99.609 (99.910)	
Epoch: [24][77/196]	LR: 0.00010000000000000003	Loss 0.0284 (0.0241)	Prec@1 100.000 (99.915)	
Epoch: [24][116/196]	LR: 0.00010000000000000003	Loss 0.0198 (0.0245)	Prec@1 100.000 (99.886)	
Epoch: [24][155/196]	LR: 0.00010000000000000003	Loss 0.0247 (0.0246)	Prec@1 100.000 (99.877)	
Epoch: [24][194/196]	LR: 0.00010000000000000003	Loss 0.0188 (0.0248)	Prec@1 100.000 (99.870)	
Total train loss: 0.0249

Train time: 18.576224327087402
 * Prec@1 84.550 Prec@5 98.950 Loss 0.6123
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 22.167760133743286

Epoch: [25][38/196]	LR: 0.00010000000000000003	Loss 0.0201 (0.0243)	Prec@1 100.000 (99.860)	
Epoch: [25][77/196]	LR: 0.00010000000000000003	Loss 0.0201 (0.0242)	Prec@1 100.000 (99.875)	
Epoch: [25][116/196]	LR: 0.00010000000000000003	Loss 0.0251 (0.0250)	Prec@1 100.000 (99.843)	
Epoch: [25][155/196]	LR: 0.00010000000000000003	Loss 0.0183 (0.0250)	Prec@1 100.000 (99.842)	
Epoch: [25][194/196]	LR: 0.00010000000000000003	Loss 0.0267 (0.0250)	Prec@1 100.000 (99.848)	
Total train loss: 0.0251

Train time: 18.41258406639099
 * Prec@1 84.620 Prec@5 99.010 Loss 0.6138
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 21.964324235916138

Epoch: [26][38/196]	LR: 0.00010000000000000003	Loss 0.0293 (0.0246)	Prec@1 99.219 (99.810)	
Epoch: [26][77/196]	LR: 0.00010000000000000003	Loss 0.0221 (0.0247)	Prec@1 100.000 (99.820)	
Epoch: [26][116/196]	LR: 0.00010000000000000003	Loss 0.0302 (0.0247)	Prec@1 99.609 (99.820)	
Epoch: [26][155/196]	LR: 0.00010000000000000003	Loss 0.0424 (0.0251)	Prec@1 99.609 (99.822)	
Epoch: [26][194/196]	LR: 0.00010000000000000003	Loss 0.0269 (0.0251)	Prec@1 100.000 (99.832)	
Total train loss: 0.0252

Train time: 18.10863733291626
 * Prec@1 84.670 Prec@5 99.000 Loss 0.6147
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 20.974520206451416

Epoch: [27][38/196]	LR: 0.00010000000000000003	Loss 0.0182 (0.0262)	Prec@1 100.000 (99.820)	
Epoch: [27][77/196]	LR: 0.00010000000000000003	Loss 0.0194 (0.0250)	Prec@1 100.000 (99.865)	
Epoch: [27][116/196]	LR: 0.00010000000000000003	Loss 0.0229 (0.0253)	Prec@1 100.000 (99.856)	
Epoch: [27][155/196]	LR: 0.00010000000000000003	Loss 0.0180 (0.0248)	Prec@1 100.000 (99.870)	
Epoch: [27][194/196]	LR: 0.00010000000000000003	Loss 0.0196 (0.0247)	Prec@1 100.000 (99.872)	
Total train loss: 0.0247

Train time: 17.034013032913208
 * Prec@1 84.530 Prec@5 99.000 Loss 0.6099
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 21.12485122680664

Epoch: [28][38/196]	LR: 0.00010000000000000003	Loss 0.0259 (0.0242)	Prec@1 100.000 (99.940)	
Epoch: [28][77/196]	LR: 0.00010000000000000003	Loss 0.0286 (0.0241)	Prec@1 100.000 (99.930)	
Epoch: [28][116/196]	LR: 0.00010000000000000003	Loss 0.0282 (0.0241)	Prec@1 100.000 (99.923)	
Epoch: [28][155/196]	LR: 0.00010000000000000003	Loss 0.0279 (0.0243)	Prec@1 99.609 (99.910)	
Epoch: [28][194/196]	LR: 0.00010000000000000003	Loss 0.0289 (0.0246)	Prec@1 99.609 (99.894)	
Total train loss: 0.0247

Train time: 12.844864130020142
 * Prec@1 84.600 Prec@5 98.950 Loss 0.6118
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 15.52218770980835

Epoch: [29][38/196]	LR: 0.00010000000000000003	Loss 0.0258 (0.0255)	Prec@1 100.000 (99.860)	
Epoch: [29][77/196]	LR: 0.00010000000000000003	Loss 0.0219 (0.0253)	Prec@1 100.000 (99.850)	
Epoch: [29][116/196]	LR: 0.00010000000000000003	Loss 0.0191 (0.0252)	Prec@1 100.000 (99.866)	
Epoch: [29][155/196]	LR: 0.00010000000000000003	Loss 0.0293 (0.0248)	Prec@1 100.000 (99.880)	
Epoch: [29][194/196]	LR: 0.00010000000000000003	Loss 0.0558 (0.0251)	Prec@1 99.609 (99.870)	
Total train loss: 0.0250

Train time: 9.643216609954834
 * Prec@1 84.700 Prec@5 98.960 Loss 0.6094
Best acc: 84.940
--------------------------------------------------------------------------------
Test time: 11.89478874206543


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20fp_cifar10.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 30
          start_epoch: 0
          batch_size: 256
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          milestones: [8, 16, 24]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 17
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20fp_cifar10.pth.tar ...
Original model accuracy: 91.93
ResNet_cifar(
  (conv18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu18): ReLU(inplace=True)
  (conv19): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu19): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (bn20): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=64, out_features=10, bias=False)
  (bn21): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 34.750 Prec@5 84.940 Loss 3.0625
Pre-trained Prec@1 with 17 layers frozen: 34.75 	 Loss: 3.0625

Starting training on SRAM layers...
Epoch: [0][38/196]	LR: 0.1	Loss 0.7144 (0.9175)	Prec@1 76.172 (72.346)	
Epoch: [0][77/196]	LR: 0.1	Loss 0.4973 (0.7725)	Prec@1 82.031 (75.396)	
Epoch: [0][116/196]	LR: 0.1	Loss 0.5229 (0.7147)	Prec@1 78.516 (76.729)	
Epoch: [0][155/196]	LR: 0.1	Loss 0.5225 (0.6763)	Prec@1 82.812 (77.714)	
Epoch: [0][194/196]	LR: 0.1	Loss 0.5737 (0.6493)	Prec@1 80.469 (78.429)	
Total train loss: 0.6489

Train time: 158.82952618598938
 * Prec@1 80.570 Prec@5 98.720 Loss 0.5952
Best acc: 80.570
--------------------------------------------------------------------------------
Test time: 163.21229720115662

Epoch: [1][38/196]	LR: 0.1	Loss 0.4268 (0.4785)	Prec@1 83.594 (83.193)	
Epoch: [1][77/196]	LR: 0.1	Loss 0.4404 (0.4861)	Prec@1 85.547 (83.033)	
Epoch: [1][116/196]	LR: 0.1	Loss 0.5254 (0.4813)	Prec@1 83.203 (83.280)	
Epoch: [1][155/196]	LR: 0.1	Loss 0.4875 (0.4842)	Prec@1 82.031 (83.186)	
Epoch: [1][194/196]	LR: 0.1	Loss 0.5620 (0.4835)	Prec@1 79.297 (83.275)	
Total train loss: 0.4834

Train time: 19.037092208862305
 * Prec@1 80.790 Prec@5 98.850 Loss 0.5737
Best acc: 80.790
--------------------------------------------------------------------------------
Test time: 22.593188285827637

Epoch: [2][38/196]	LR: 0.1	Loss 0.4263 (0.4402)	Prec@1 85.547 (84.505)	
Epoch: [2][77/196]	LR: 0.1	Loss 0.3389 (0.4358)	Prec@1 89.062 (84.791)	
Epoch: [2][116/196]	LR: 0.1	Loss 0.4995 (0.4368)	Prec@1 80.078 (84.669)	
Epoch: [2][155/196]	LR: 0.1	Loss 0.4187 (0.4386)	Prec@1 82.812 (84.635)	
Epoch: [2][194/196]	LR: 0.1	Loss 0.5059 (0.4393)	Prec@1 80.859 (84.631)	
Total train loss: 0.4395

Train time: 18.34533166885376
 * Prec@1 81.860 Prec@5 99.070 Loss 0.5479
Best acc: 81.860
--------------------------------------------------------------------------------
Test time: 21.106175899505615

Epoch: [3][38/196]	LR: 0.1	Loss 0.3386 (0.3902)	Prec@1 88.281 (86.368)	
Epoch: [3][77/196]	LR: 0.1	Loss 0.4756 (0.3901)	Prec@1 82.422 (86.468)	
Epoch: [3][116/196]	LR: 0.1	Loss 0.4478 (0.3938)	Prec@1 85.156 (86.285)	
Epoch: [3][155/196]	LR: 0.1	Loss 0.3892 (0.3956)	Prec@1 87.891 (86.215)	
Epoch: [3][194/196]	LR: 0.1	Loss 0.3938 (0.4016)	Prec@1 84.766 (85.958)	
Total train loss: 0.4016

Train time: 17.69060707092285
 * Prec@1 82.980 Prec@5 98.930 Loss 0.5337
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 21.564961433410645

Epoch: [4][38/196]	LR: 0.1	Loss 0.3772 (0.3564)	Prec@1 86.719 (87.520)	
Epoch: [4][77/196]	LR: 0.1	Loss 0.3247 (0.3628)	Prec@1 88.281 (87.099)	
Epoch: [4][116/196]	LR: 0.1	Loss 0.4648 (0.3645)	Prec@1 84.375 (87.066)	
Epoch: [4][155/196]	LR: 0.1	Loss 0.3513 (0.3691)	Prec@1 88.281 (87.032)	
Epoch: [4][194/196]	LR: 0.1	Loss 0.4238 (0.3722)	Prec@1 85.938 (86.907)	
Total train loss: 0.3721

Train time: 19.215482711791992
 * Prec@1 81.920 Prec@5 99.000 Loss 0.5571
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 22.38983678817749

Epoch: [5][38/196]	LR: 0.1	Loss 0.3191 (0.3213)	Prec@1 87.500 (88.912)	
Epoch: [5][77/196]	LR: 0.1	Loss 0.4299 (0.3290)	Prec@1 84.375 (88.622)	
Epoch: [5][116/196]	LR: 0.1	Loss 0.3694 (0.3419)	Prec@1 87.109 (88.211)	
Epoch: [5][155/196]	LR: 0.1	Loss 0.3752 (0.3495)	Prec@1 85.547 (87.848)	
Epoch: [5][194/196]	LR: 0.1	Loss 0.4248 (0.3504)	Prec@1 85.547 (87.762)	
Total train loss: 0.3506

Train time: 19.036860942840576
 * Prec@1 81.570 Prec@5 98.760 Loss 0.5918
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 22.24026870727539

Epoch: [6][38/196]	LR: 0.1	Loss 0.3030 (0.3075)	Prec@1 90.234 (89.243)	
Epoch: [6][77/196]	LR: 0.1	Loss 0.3342 (0.3060)	Prec@1 87.109 (89.293)	
Epoch: [6][116/196]	LR: 0.1	Loss 0.3042 (0.3116)	Prec@1 89.453 (89.066)	
Epoch: [6][155/196]	LR: 0.1	Loss 0.3621 (0.3154)	Prec@1 87.891 (88.947)	
Epoch: [6][194/196]	LR: 0.1	Loss 0.3828 (0.3215)	Prec@1 87.891 (88.726)	
Total train loss: 0.3214

Train time: 17.0899338722229
 * Prec@1 80.540 Prec@5 98.710 Loss 0.6582
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 20.62940764427185

Epoch: [7][38/196]	LR: 0.1	Loss 0.1903 (0.2681)	Prec@1 94.922 (90.966)	
Epoch: [7][77/196]	LR: 0.1	Loss 0.2496 (0.2831)	Prec@1 91.406 (90.360)	
Epoch: [7][116/196]	LR: 0.1	Loss 0.3062 (0.2911)	Prec@1 90.625 (90.071)	
Epoch: [7][155/196]	LR: 0.1	Loss 0.2878 (0.2976)	Prec@1 88.672 (89.626)	
Epoch: [7][194/196]	LR: 0.1	Loss 0.3657 (0.3004)	Prec@1 87.500 (89.503)	
Total train loss: 0.3003

Train time: 19.437681913375854
 * Prec@1 80.100 Prec@5 98.540 Loss 0.6963
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 22.995988845825195

Epoch: [8][38/196]	LR: 0.010000000000000002	Loss 0.2173 (0.2454)	Prec@1 93.359 (91.717)	
Epoch: [8][77/196]	LR: 0.010000000000000002	Loss 0.1827 (0.2298)	Prec@1 93.750 (92.368)	
Epoch: [8][116/196]	LR: 0.010000000000000002	Loss 0.1947 (0.2199)	Prec@1 93.359 (92.765)	
Epoch: [8][155/196]	LR: 0.010000000000000002	Loss 0.1888 (0.2154)	Prec@1 93.750 (92.924)	
Epoch: [8][194/196]	LR: 0.010000000000000002	Loss 0.1937 (0.2117)	Prec@1 95.312 (93.023)	
Total train loss: 0.2117

Train time: 18.411494255065918
 * Prec@1 82.830 Prec@5 98.830 Loss 0.5674
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 21.52940821647644

Epoch: [9][38/196]	LR: 0.010000000000000002	Loss 0.2141 (0.1776)	Prec@1 92.188 (94.471)	
Epoch: [9][77/196]	LR: 0.010000000000000002	Loss 0.1899 (0.1814)	Prec@1 92.969 (94.356)	
Epoch: [9][116/196]	LR: 0.010000000000000002	Loss 0.1580 (0.1806)	Prec@1 95.703 (94.354)	
Epoch: [9][155/196]	LR: 0.010000000000000002	Loss 0.1770 (0.1791)	Prec@1 94.141 (94.386)	
Epoch: [9][194/196]	LR: 0.010000000000000002	Loss 0.2351 (0.1819)	Prec@1 92.188 (94.287)	
Total train loss: 0.1820

Train time: 17.521930932998657
 * Prec@1 82.890 Prec@5 98.830 Loss 0.5820
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 21.645899772644043

Epoch: [10][38/196]	LR: 0.010000000000000002	Loss 0.1661 (0.1652)	Prec@1 95.703 (95.373)	
Epoch: [10][77/196]	LR: 0.010000000000000002	Loss 0.1560 (0.1694)	Prec@1 94.922 (94.902)	
Epoch: [10][116/196]	LR: 0.010000000000000002	Loss 0.1670 (0.1708)	Prec@1 94.531 (94.822)	
Epoch: [10][155/196]	LR: 0.010000000000000002	Loss 0.1942 (0.1697)	Prec@1 93.359 (94.857)	
Epoch: [10][194/196]	LR: 0.010000000000000002	Loss 0.2096 (0.1701)	Prec@1 92.578 (94.794)	
Total train loss: 0.1701

Train time: 16.691123723983765
 * Prec@1 82.650 Prec@5 98.810 Loss 0.5942
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 19.92940378189087

Epoch: [11][38/196]	LR: 0.010000000000000002	Loss 0.1517 (0.1508)	Prec@1 96.094 (95.913)	
Epoch: [11][77/196]	LR: 0.010000000000000002	Loss 0.1470 (0.1557)	Prec@1 95.703 (95.568)	
Epoch: [11][116/196]	LR: 0.010000000000000002	Loss 0.1655 (0.1564)	Prec@1 95.312 (95.573)	
Epoch: [11][155/196]	LR: 0.010000000000000002	Loss 0.2064 (0.1583)	Prec@1 94.922 (95.443)	
Epoch: [11][194/196]	LR: 0.010000000000000002	Loss 0.1473 (0.1596)	Prec@1 96.094 (95.331)	
Total train loss: 0.1598

Train time: 17.538657665252686
 * Prec@1 82.390 Prec@5 98.760 Loss 0.6050
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 21.099101066589355

Epoch: [12][38/196]	LR: 0.010000000000000002	Loss 0.1185 (0.1436)	Prec@1 98.047 (95.913)	
Epoch: [12][77/196]	LR: 0.010000000000000002	Loss 0.1855 (0.1498)	Prec@1 95.312 (95.723)	
Epoch: [12][116/196]	LR: 0.010000000000000002	Loss 0.1422 (0.1531)	Prec@1 97.266 (95.580)	
Epoch: [12][155/196]	LR: 0.010000000000000002	Loss 0.1520 (0.1548)	Prec@1 95.703 (95.508)	
Epoch: [12][194/196]	LR: 0.010000000000000002	Loss 0.1672 (0.1538)	Prec@1 96.875 (95.557)	
Total train loss: 0.1539

Train time: 17.832988262176514
 * Prec@1 82.310 Prec@5 98.700 Loss 0.6172
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 21.411504983901978

Epoch: [13][38/196]	LR: 0.010000000000000002	Loss 0.1705 (0.1414)	Prec@1 94.141 (96.044)	
Epoch: [13][77/196]	LR: 0.010000000000000002	Loss 0.1350 (0.1466)	Prec@1 96.484 (95.808)	
Epoch: [13][116/196]	LR: 0.010000000000000002	Loss 0.1163 (0.1469)	Prec@1 97.656 (95.803)	
Epoch: [13][155/196]	LR: 0.010000000000000002	Loss 0.1602 (0.1473)	Prec@1 94.531 (95.796)	
Epoch: [13][194/196]	LR: 0.010000000000000002	Loss 0.1152 (0.1476)	Prec@1 97.266 (95.751)	
Total train loss: 0.1476

Train time: 17.719910383224487
 * Prec@1 82.430 Prec@5 98.690 Loss 0.6182
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 21.25806188583374

Epoch: [14][38/196]	LR: 0.010000000000000002	Loss 0.1078 (0.1387)	Prec@1 97.656 (96.134)	
Epoch: [14][77/196]	LR: 0.010000000000000002	Loss 0.1206 (0.1400)	Prec@1 97.266 (96.054)	
Epoch: [14][116/196]	LR: 0.010000000000000002	Loss 0.1162 (0.1414)	Prec@1 96.094 (96.057)	
Epoch: [14][155/196]	LR: 0.010000000000000002	Loss 0.1992 (0.1420)	Prec@1 94.141 (96.029)	
Epoch: [14][194/196]	LR: 0.010000000000000002	Loss 0.1495 (0.1413)	Prec@1 96.094 (96.044)	
Total train loss: 0.1413

Train time: 18.211575031280518
 * Prec@1 82.190 Prec@5 98.570 Loss 0.6274
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 20.829821825027466

Epoch: [15][38/196]	LR: 0.010000000000000002	Loss 0.1121 (0.1349)	Prec@1 96.484 (96.504)	
Epoch: [15][77/196]	LR: 0.010000000000000002	Loss 0.1125 (0.1311)	Prec@1 96.484 (96.600)	
Epoch: [15][116/196]	LR: 0.010000000000000002	Loss 0.1576 (0.1324)	Prec@1 94.922 (96.514)	
Epoch: [15][155/196]	LR: 0.010000000000000002	Loss 0.1906 (0.1351)	Prec@1 93.359 (96.359)	
Epoch: [15][194/196]	LR: 0.010000000000000002	Loss 0.1333 (0.1349)	Prec@1 96.094 (96.392)	
Total train loss: 0.1350

Train time: 17.548930168151855
 * Prec@1 82.020 Prec@5 98.590 Loss 0.6416
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 21.862293481826782

Epoch: [16][38/196]	LR: 0.0010000000000000002	Loss 0.1202 (0.1207)	Prec@1 96.875 (97.005)	
Epoch: [16][77/196]	LR: 0.0010000000000000002	Loss 0.1049 (0.1204)	Prec@1 97.656 (97.110)	
Epoch: [16][116/196]	LR: 0.0010000000000000002	Loss 0.1556 (0.1224)	Prec@1 96.484 (96.995)	
Epoch: [16][155/196]	LR: 0.0010000000000000002	Loss 0.0963 (0.1233)	Prec@1 98.438 (96.958)	
Epoch: [16][194/196]	LR: 0.0010000000000000002	Loss 0.1506 (0.1244)	Prec@1 96.094 (96.899)	
Total train loss: 0.1246

Train time: 17.296555042266846
 * Prec@1 82.170 Prec@5 98.670 Loss 0.6406
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 20.383360862731934

Epoch: [17][38/196]	LR: 0.0010000000000000002	Loss 0.1371 (0.1180)	Prec@1 95.312 (97.376)	
Epoch: [17][77/196]	LR: 0.0010000000000000002	Loss 0.1121 (0.1185)	Prec@1 96.875 (97.216)	
Epoch: [17][116/196]	LR: 0.0010000000000000002	Loss 0.0868 (0.1192)	Prec@1 98.828 (97.119)	
Epoch: [17][155/196]	LR: 0.0010000000000000002	Loss 0.1033 (0.1207)	Prec@1 98.047 (97.098)	
Epoch: [17][194/196]	LR: 0.0010000000000000002	Loss 0.1172 (0.1223)	Prec@1 96.484 (97.039)	
Total train loss: 0.1223

Train time: 17.074251174926758
 * Prec@1 82.170 Prec@5 98.660 Loss 0.6426
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 20.658681631088257

Epoch: [18][38/196]	LR: 0.0010000000000000002	Loss 0.1100 (0.1197)	Prec@1 96.484 (97.115)	
Epoch: [18][77/196]	LR: 0.0010000000000000002	Loss 0.1179 (0.1224)	Prec@1 96.875 (96.920)	
Epoch: [18][116/196]	LR: 0.0010000000000000002	Loss 0.1127 (0.1209)	Prec@1 96.484 (97.022)	
Epoch: [18][155/196]	LR: 0.0010000000000000002	Loss 0.1414 (0.1215)	Prec@1 96.094 (97.005)	
Epoch: [18][194/196]	LR: 0.0010000000000000002	Loss 0.0921 (0.1221)	Prec@1 98.047 (96.995)	
Total train loss: 0.1221

Train time: 18.132980823516846
 * Prec@1 82.110 Prec@5 98.610 Loss 0.6416
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 22.425904035568237

Epoch: [19][38/196]	LR: 0.0010000000000000002	Loss 0.1071 (0.1237)	Prec@1 96.484 (96.835)	
Epoch: [19][77/196]	LR: 0.0010000000000000002	Loss 0.1766 (0.1229)	Prec@1 93.750 (96.975)	
Epoch: [19][116/196]	LR: 0.0010000000000000002	Loss 0.1515 (0.1213)	Prec@1 96.484 (97.079)	
Epoch: [19][155/196]	LR: 0.0010000000000000002	Loss 0.1371 (0.1227)	Prec@1 96.094 (97.025)	
Epoch: [19][194/196]	LR: 0.0010000000000000002	Loss 0.1171 (0.1216)	Prec@1 96.875 (97.095)	
Total train loss: 0.1217

Train time: 17.73943257331848
 * Prec@1 82.200 Prec@5 98.630 Loss 0.6426
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 21.624255418777466

Epoch: [20][38/196]	LR: 0.0010000000000000002	Loss 0.1221 (0.1238)	Prec@1 97.266 (97.085)	
Epoch: [20][77/196]	LR: 0.0010000000000000002	Loss 0.1232 (0.1223)	Prec@1 97.656 (97.090)	
Epoch: [20][116/196]	LR: 0.0010000000000000002	Loss 0.1169 (0.1214)	Prec@1 97.656 (97.132)	
Epoch: [20][155/196]	LR: 0.0010000000000000002	Loss 0.1072 (0.1206)	Prec@1 97.656 (97.145)	
Epoch: [20][194/196]	LR: 0.0010000000000000002	Loss 0.0847 (0.1202)	Prec@1 97.656 (97.163)	
Total train loss: 0.1204

Train time: 17.52255129814148
 * Prec@1 82.100 Prec@5 98.640 Loss 0.6382
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 20.503663063049316

Epoch: [21][38/196]	LR: 0.0010000000000000002	Loss 0.1274 (0.1257)	Prec@1 96.875 (96.945)	
Epoch: [21][77/196]	LR: 0.0010000000000000002	Loss 0.1220 (0.1206)	Prec@1 96.875 (97.160)	
Epoch: [21][116/196]	LR: 0.0010000000000000002	Loss 0.1028 (0.1204)	Prec@1 98.438 (97.142)	
Epoch: [21][155/196]	LR: 0.0010000000000000002	Loss 0.1119 (0.1206)	Prec@1 97.656 (97.118)	
Epoch: [21][194/196]	LR: 0.0010000000000000002	Loss 0.1481 (0.1212)	Prec@1 96.484 (97.043)	
Total train loss: 0.1212

Train time: 16.017105102539062
 * Prec@1 82.250 Prec@5 98.620 Loss 0.6362
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 20.066166162490845

Epoch: [22][38/196]	LR: 0.0010000000000000002	Loss 0.1493 (0.1212)	Prec@1 96.484 (97.055)	
Epoch: [22][77/196]	LR: 0.0010000000000000002	Loss 0.1841 (0.1216)	Prec@1 95.312 (96.985)	
Epoch: [22][116/196]	LR: 0.0010000000000000002	Loss 0.1772 (0.1214)	Prec@1 94.922 (96.999)	
Epoch: [22][155/196]	LR: 0.0010000000000000002	Loss 0.1110 (0.1217)	Prec@1 97.266 (96.993)	
Epoch: [22][194/196]	LR: 0.0010000000000000002	Loss 0.0881 (0.1218)	Prec@1 98.047 (96.987)	
Total train loss: 0.1219

Train time: 18.05891466140747
 * Prec@1 82.160 Prec@5 98.600 Loss 0.6396
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 21.545279026031494

Epoch: [23][38/196]	LR: 0.0010000000000000002	Loss 0.0896 (0.1198)	Prec@1 98.047 (97.155)	
Epoch: [23][77/196]	LR: 0.0010000000000000002	Loss 0.1305 (0.1216)	Prec@1 96.094 (97.090)	
Epoch: [23][116/196]	LR: 0.0010000000000000002	Loss 0.1202 (0.1208)	Prec@1 96.094 (97.095)	
Epoch: [23][155/196]	LR: 0.0010000000000000002	Loss 0.1259 (0.1200)	Prec@1 96.484 (97.135)	
Epoch: [23][194/196]	LR: 0.0010000000000000002	Loss 0.1216 (0.1201)	Prec@1 96.094 (97.115)	
Total train loss: 0.1203

Train time: 18.2675724029541
 * Prec@1 82.180 Prec@5 98.590 Loss 0.6440
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 22.36739230155945

Epoch: [24][38/196]	LR: 0.00010000000000000003	Loss 0.1667 (0.1183)	Prec@1 93.750 (97.196)	
Epoch: [24][77/196]	LR: 0.00010000000000000003	Loss 0.1479 (0.1195)	Prec@1 95.312 (97.165)	
Epoch: [24][116/196]	LR: 0.00010000000000000003	Loss 0.1162 (0.1204)	Prec@1 98.047 (97.129)	
Epoch: [24][155/196]	LR: 0.00010000000000000003	Loss 0.1141 (0.1211)	Prec@1 97.656 (97.075)	
Epoch: [24][194/196]	LR: 0.00010000000000000003	Loss 0.1150 (0.1211)	Prec@1 97.656 (97.065)	
Total train loss: 0.1211

Train time: 16.498398780822754
 * Prec@1 82.160 Prec@5 98.620 Loss 0.6387
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 20.307055711746216

Epoch: [25][38/196]	LR: 0.00010000000000000003	Loss 0.1478 (0.1189)	Prec@1 96.094 (97.015)	
Epoch: [25][77/196]	LR: 0.00010000000000000003	Loss 0.1381 (0.1186)	Prec@1 95.703 (97.175)	
Epoch: [25][116/196]	LR: 0.00010000000000000003	Loss 0.1052 (0.1193)	Prec@1 97.656 (97.139)	
Epoch: [25][155/196]	LR: 0.00010000000000000003	Loss 0.1295 (0.1199)	Prec@1 96.484 (97.155)	
Epoch: [25][194/196]	LR: 0.00010000000000000003	Loss 0.1638 (0.1203)	Prec@1 95.703 (97.119)	
Total train loss: 0.1204

Train time: 16.761840105056763
 * Prec@1 82.310 Prec@5 98.620 Loss 0.6406
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 20.32602095603943

Epoch: [26][38/196]	LR: 0.00010000000000000003	Loss 0.0842 (0.1205)	Prec@1 98.828 (97.206)	
Epoch: [26][77/196]	LR: 0.00010000000000000003	Loss 0.1142 (0.1207)	Prec@1 96.875 (97.185)	
Epoch: [26][116/196]	LR: 0.00010000000000000003	Loss 0.1322 (0.1197)	Prec@1 97.266 (97.216)	
Epoch: [26][155/196]	LR: 0.00010000000000000003	Loss 0.1606 (0.1205)	Prec@1 96.484 (97.163)	
Epoch: [26][194/196]	LR: 0.00010000000000000003	Loss 0.1108 (0.1204)	Prec@1 97.266 (97.141)	
Total train loss: 0.1204

Train time: 17.128113746643066
 * Prec@1 82.170 Prec@5 98.630 Loss 0.6436
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 20.21151375770569

Epoch: [27][38/196]	LR: 0.00010000000000000003	Loss 0.1094 (0.1226)	Prec@1 97.266 (97.005)	
Epoch: [27][77/196]	LR: 0.00010000000000000003	Loss 0.1312 (0.1196)	Prec@1 98.047 (97.110)	
Epoch: [27][116/196]	LR: 0.00010000000000000003	Loss 0.1101 (0.1171)	Prec@1 97.266 (97.272)	
Epoch: [27][155/196]	LR: 0.00010000000000000003	Loss 0.1229 (0.1188)	Prec@1 96.875 (97.193)	
Epoch: [27][194/196]	LR: 0.00010000000000000003	Loss 0.1093 (0.1184)	Prec@1 96.484 (97.173)	
Total train loss: 0.1184

Train time: 16.823432683944702
 * Prec@1 82.150 Prec@5 98.620 Loss 0.6396
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 21.162862062454224

Epoch: [28][38/196]	LR: 0.00010000000000000003	Loss 0.1384 (0.1240)	Prec@1 95.703 (96.975)	
Epoch: [28][77/196]	LR: 0.00010000000000000003	Loss 0.1394 (0.1225)	Prec@1 96.484 (97.070)	
Epoch: [28][116/196]	LR: 0.00010000000000000003	Loss 0.1462 (0.1205)	Prec@1 95.312 (97.139)	
Epoch: [28][155/196]	LR: 0.00010000000000000003	Loss 0.0999 (0.1206)	Prec@1 98.047 (97.105)	
Epoch: [28][194/196]	LR: 0.00010000000000000003	Loss 0.1426 (0.1196)	Prec@1 96.484 (97.165)	
Total train loss: 0.1195

Train time: 12.513786554336548
 * Prec@1 82.260 Prec@5 98.630 Loss 0.6382
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 14.777356386184692

Epoch: [29][38/196]	LR: 0.00010000000000000003	Loss 0.1624 (0.1192)	Prec@1 96.094 (97.196)	
Epoch: [29][77/196]	LR: 0.00010000000000000003	Loss 0.1321 (0.1191)	Prec@1 97.266 (97.140)	
Epoch: [29][116/196]	LR: 0.00010000000000000003	Loss 0.1417 (0.1194)	Prec@1 95.312 (97.159)	
Epoch: [29][155/196]	LR: 0.00010000000000000003	Loss 0.1357 (0.1203)	Prec@1 96.875 (97.148)	
Epoch: [29][194/196]	LR: 0.00010000000000000003	Loss 0.1241 (0.1216)	Prec@1 96.094 (97.085)	
Total train loss: 0.1217

Train time: 9.853520154953003
 * Prec@1 82.270 Prec@5 98.620 Loss 0.6411
Best acc: 82.980
--------------------------------------------------------------------------------
Test time: 12.124861478805542


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20fp_cifar10.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 30
          start_epoch: 0
          batch_size: 256
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          milestones: [8, 16, 24]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 19
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20fp_cifar10.pth.tar ...
Original model accuracy: 91.93
ResNet_cifar(
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (bn20): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=64, out_features=10, bias=False)
  (bn21): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 31.930 Prec@5 85.120 Loss 3.1152
Pre-trained Prec@1 with 19 layers frozen: 31.92999839782715 	 Loss: 3.115234375

Starting training on SRAM layers...
Epoch: [0][38/196]	LR: 0.1	Loss 0.8022 (1.1233)	Prec@1 75.781 (68.399)	
Epoch: [0][77/196]	LR: 0.1	Loss 0.8418 (0.9864)	Prec@1 70.312 (69.727)	
Epoch: [0][116/196]	LR: 0.1	Loss 0.7983 (0.9227)	Prec@1 71.484 (70.954)	
Epoch: [0][155/196]	LR: 0.1	Loss 0.7017 (0.8907)	Prec@1 76.172 (71.537)	
Epoch: [0][194/196]	LR: 0.1	Loss 0.8945 (0.8714)	Prec@1 71.094 (71.835)	
Total train loss: 0.8716

Train time: 86.10748505592346
 * Prec@1 75.020 Prec@5 97.770 Loss 0.7646
Best acc: 75.020
--------------------------------------------------------------------------------
Test time: 89.31359124183655

Epoch: [1][38/196]	LR: 0.1	Loss 0.7568 (0.7415)	Prec@1 72.656 (74.890)	
Epoch: [1][77/196]	LR: 0.1	Loss 0.7627 (0.7634)	Prec@1 74.219 (74.053)	
Epoch: [1][116/196]	LR: 0.1	Loss 0.7900 (0.7650)	Prec@1 73.438 (74.018)	
Epoch: [1][155/196]	LR: 0.1	Loss 0.8916 (0.7727)	Prec@1 70.703 (73.781)	
Epoch: [1][194/196]	LR: 0.1	Loss 0.7651 (0.7731)	Prec@1 73.438 (73.756)	
Total train loss: 0.7738

Train time: 13.9187593460083
 * Prec@1 75.310 Prec@5 97.940 Loss 0.7554
Best acc: 75.310
--------------------------------------------------------------------------------
Test time: 16.867443799972534

Epoch: [2][38/196]	LR: 0.1	Loss 0.7246 (0.7714)	Prec@1 74.219 (73.928)	
Epoch: [2][77/196]	LR: 0.1	Loss 0.7456 (0.7613)	Prec@1 74.609 (73.993)	
Epoch: [2][116/196]	LR: 0.1	Loss 0.8193 (0.7643)	Prec@1 69.531 (74.025)	
Epoch: [2][155/196]	LR: 0.1	Loss 0.5752 (0.7651)	Prec@1 79.297 (74.026)	
Epoch: [2][194/196]	LR: 0.1	Loss 0.8125 (0.7657)	Prec@1 74.609 (74.095)	
Total train loss: 0.7662

Train time: 13.106082677841187
 * Prec@1 75.380 Prec@5 97.830 Loss 0.7588
Best acc: 75.380
--------------------------------------------------------------------------------
Test time: 15.481255769729614

Epoch: [3][38/196]	LR: 0.1	Loss 0.8105 (0.7703)	Prec@1 72.266 (73.968)	
Epoch: [3][77/196]	LR: 0.1	Loss 0.7471 (0.7656)	Prec@1 73.047 (74.269)	
Epoch: [3][116/196]	LR: 0.1	Loss 0.8687 (0.7659)	Prec@1 73.047 (74.192)	
Epoch: [3][155/196]	LR: 0.1	Loss 0.7236 (0.7660)	Prec@1 73.438 (74.129)	
Epoch: [3][194/196]	LR: 0.1	Loss 0.8535 (0.7655)	Prec@1 70.703 (74.131)	
Total train loss: 0.7653

Train time: 11.565420389175415
 * Prec@1 75.460 Prec@5 97.880 Loss 0.7485
Best acc: 75.460
--------------------------------------------------------------------------------
Test time: 14.534346580505371

Epoch: [4][38/196]	LR: 0.1	Loss 0.7856 (0.7723)	Prec@1 70.703 (73.608)	
Epoch: [4][77/196]	LR: 0.1	Loss 0.7603 (0.7723)	Prec@1 75.391 (73.853)	
Epoch: [4][116/196]	LR: 0.1	Loss 0.7856 (0.7653)	Prec@1 75.781 (74.042)	
Epoch: [4][155/196]	LR: 0.1	Loss 0.7344 (0.7662)	Prec@1 75.000 (74.028)	
Epoch: [4][194/196]	LR: 0.1	Loss 0.8047 (0.7611)	Prec@1 73.047 (74.219)	
Total train loss: 0.7614

Train time: 12.861879348754883
 * Prec@1 75.720 Prec@5 97.910 Loss 0.7466
Best acc: 75.720
--------------------------------------------------------------------------------
Test time: 15.746222257614136

Epoch: [5][38/196]	LR: 0.1	Loss 0.8662 (0.7622)	Prec@1 68.750 (74.309)	
Epoch: [5][77/196]	LR: 0.1	Loss 0.7266 (0.7666)	Prec@1 76.172 (74.058)	
Epoch: [5][116/196]	LR: 0.1	Loss 0.7559 (0.7636)	Prec@1 76.953 (74.139)	
Epoch: [5][155/196]	LR: 0.1	Loss 0.8018 (0.7588)	Prec@1 73.438 (74.414)	
Epoch: [5][194/196]	LR: 0.1	Loss 0.7524 (0.7601)	Prec@1 74.609 (74.375)	
Total train loss: 0.7602

Train time: 12.117945671081543
 * Prec@1 75.630 Prec@5 97.980 Loss 0.7446
Best acc: 75.720
--------------------------------------------------------------------------------
Test time: 15.133524417877197

Epoch: [6][38/196]	LR: 0.1	Loss 0.8315 (0.7436)	Prec@1 71.094 (74.669)	
Epoch: [6][77/196]	LR: 0.1	Loss 0.7007 (0.7616)	Prec@1 75.781 (74.174)	
Epoch: [6][116/196]	LR: 0.1	Loss 0.8154 (0.7618)	Prec@1 72.656 (74.042)	
Epoch: [6][155/196]	LR: 0.1	Loss 0.8335 (0.7577)	Prec@1 73.828 (74.226)	
Epoch: [6][194/196]	LR: 0.1	Loss 0.7588 (0.7621)	Prec@1 75.391 (74.157)	
Total train loss: 0.7621

Train time: 12.881738185882568
 * Prec@1 75.570 Prec@5 97.840 Loss 0.7437
Best acc: 75.720
--------------------------------------------------------------------------------
Test time: 15.36653470993042

Epoch: [7][38/196]	LR: 0.1	Loss 0.6904 (0.7528)	Prec@1 76.953 (74.700)	
Epoch: [7][77/196]	LR: 0.1	Loss 0.7217 (0.7497)	Prec@1 75.000 (74.770)	
Epoch: [7][116/196]	LR: 0.1	Loss 0.8257 (0.7559)	Prec@1 68.359 (74.596)	
Epoch: [7][155/196]	LR: 0.1	Loss 0.7764 (0.7611)	Prec@1 72.266 (74.346)	
Epoch: [7][194/196]	LR: 0.1	Loss 0.7373 (0.7591)	Prec@1 75.781 (74.385)	
Total train loss: 0.7590

Train time: 11.88283896446228
 * Prec@1 75.460 Prec@5 97.870 Loss 0.7505
Best acc: 75.720
--------------------------------------------------------------------------------
Test time: 14.918155431747437

Epoch: [8][38/196]	LR: 0.010000000000000002	Loss 0.7173 (0.7444)	Prec@1 77.734 (75.030)	
Epoch: [8][77/196]	LR: 0.010000000000000002	Loss 0.6885 (0.7429)	Prec@1 76.562 (74.845)	
Epoch: [8][116/196]	LR: 0.010000000000000002	Loss 0.7002 (0.7423)	Prec@1 73.047 (74.716)	
Epoch: [8][155/196]	LR: 0.010000000000000002	Loss 0.7129 (0.7470)	Prec@1 75.000 (74.617)	
Epoch: [8][194/196]	LR: 0.010000000000000002	Loss 0.7998 (0.7509)	Prec@1 71.875 (74.493)	
Total train loss: 0.7510

Train time: 12.624049425125122
 * Prec@1 75.970 Prec@5 97.950 Loss 0.7407
Best acc: 75.970
--------------------------------------------------------------------------------
Test time: 15.56767463684082

Epoch: [9][38/196]	LR: 0.010000000000000002	Loss 0.6772 (0.7349)	Prec@1 74.609 (74.870)	
Epoch: [9][77/196]	LR: 0.010000000000000002	Loss 0.8726 (0.7356)	Prec@1 69.922 (74.980)	
Epoch: [9][116/196]	LR: 0.010000000000000002	Loss 0.8311 (0.7440)	Prec@1 70.703 (74.786)	
Epoch: [9][155/196]	LR: 0.010000000000000002	Loss 0.7812 (0.7499)	Prec@1 75.000 (74.642)	
Epoch: [9][194/196]	LR: 0.010000000000000002	Loss 0.8403 (0.7473)	Prec@1 70.703 (74.706)	
Total train loss: 0.7472

Train time: 12.245189666748047
 * Prec@1 76.110 Prec@5 97.960 Loss 0.7393
Best acc: 76.110
--------------------------------------------------------------------------------
Test time: 15.266935348510742

Epoch: [10][38/196]	LR: 0.010000000000000002	Loss 0.7031 (0.7490)	Prec@1 75.000 (74.349)	
Epoch: [10][77/196]	LR: 0.010000000000000002	Loss 0.7319 (0.7478)	Prec@1 74.219 (74.424)	
Epoch: [10][116/196]	LR: 0.010000000000000002	Loss 0.9619 (0.7466)	Prec@1 69.141 (74.496)	
Epoch: [10][155/196]	LR: 0.010000000000000002	Loss 0.7559 (0.7445)	Prec@1 74.219 (74.637)	
Epoch: [10][194/196]	LR: 0.010000000000000002	Loss 0.8438 (0.7468)	Prec@1 73.828 (74.712)	
Total train loss: 0.7469

Train time: 12.547886848449707
 * Prec@1 76.000 Prec@5 97.950 Loss 0.7397
Best acc: 76.110
--------------------------------------------------------------------------------
Test time: 15.032670497894287

Epoch: [11][38/196]	LR: 0.010000000000000002	Loss 0.7637 (0.7342)	Prec@1 74.219 (74.720)	
Epoch: [11][77/196]	LR: 0.010000000000000002	Loss 0.7476 (0.7393)	Prec@1 74.219 (74.755)	
Epoch: [11][116/196]	LR: 0.010000000000000002	Loss 0.7495 (0.7393)	Prec@1 76.562 (74.803)	
Epoch: [11][155/196]	LR: 0.010000000000000002	Loss 0.9312 (0.7453)	Prec@1 68.359 (74.674)	
Epoch: [11][194/196]	LR: 0.010000000000000002	Loss 0.9375 (0.7469)	Prec@1 69.922 (74.617)	
Total train loss: 0.7470

Train time: 12.427650690078735
 * Prec@1 75.890 Prec@5 97.970 Loss 0.7388
Best acc: 76.110
--------------------------------------------------------------------------------
Test time: 15.434525489807129

Epoch: [12][38/196]	LR: 0.010000000000000002	Loss 0.7886 (0.7356)	Prec@1 72.656 (74.649)	
Epoch: [12][77/196]	LR: 0.010000000000000002	Loss 0.6826 (0.7410)	Prec@1 76.562 (74.654)	
Epoch: [12][116/196]	LR: 0.010000000000000002	Loss 0.9297 (0.7440)	Prec@1 66.797 (74.713)	
Epoch: [12][155/196]	LR: 0.010000000000000002	Loss 0.7754 (0.7470)	Prec@1 77.734 (74.740)	
Epoch: [12][194/196]	LR: 0.010000000000000002	Loss 0.7280 (0.7459)	Prec@1 74.609 (74.756)	
Total train loss: 0.7459

Train time: 12.422743320465088
 * Prec@1 76.100 Prec@5 97.960 Loss 0.7358
Best acc: 76.110
--------------------------------------------------------------------------------
Test time: 15.403188943862915

Epoch: [13][38/196]	LR: 0.010000000000000002	Loss 0.6597 (0.7411)	Prec@1 77.344 (74.820)	
Epoch: [13][77/196]	LR: 0.010000000000000002	Loss 0.8364 (0.7451)	Prec@1 73.828 (74.674)	
Epoch: [13][116/196]	LR: 0.010000000000000002	Loss 0.7080 (0.7431)	Prec@1 73.438 (74.756)	
Epoch: [13][155/196]	LR: 0.010000000000000002	Loss 0.7100 (0.7496)	Prec@1 75.391 (74.602)	
Epoch: [13][194/196]	LR: 0.010000000000000002	Loss 0.6230 (0.7458)	Prec@1 77.344 (74.710)	
Total train loss: 0.7460

Train time: 12.25447416305542
 * Prec@1 76.020 Prec@5 97.930 Loss 0.7368
Best acc: 76.110
--------------------------------------------------------------------------------
Test time: 15.245197534561157

Epoch: [14][38/196]	LR: 0.010000000000000002	Loss 0.8481 (0.7487)	Prec@1 73.047 (74.750)	
Epoch: [14][77/196]	LR: 0.010000000000000002	Loss 0.7598 (0.7367)	Prec@1 71.484 (75.055)	
Epoch: [14][116/196]	LR: 0.010000000000000002	Loss 0.7437 (0.7410)	Prec@1 76.562 (74.833)	
Epoch: [14][155/196]	LR: 0.010000000000000002	Loss 0.7944 (0.7437)	Prec@1 72.656 (74.747)	
Epoch: [14][194/196]	LR: 0.010000000000000002	Loss 0.8091 (0.7453)	Prec@1 72.266 (74.671)	
Total train loss: 0.7454

Train time: 12.268221378326416
 * Prec@1 76.050 Prec@5 97.960 Loss 0.7388
Best acc: 76.110
--------------------------------------------------------------------------------
Test time: 14.647255897521973

Epoch: [15][38/196]	LR: 0.010000000000000002	Loss 0.6377 (0.7351)	Prec@1 79.688 (74.820)	
Epoch: [15][77/196]	LR: 0.010000000000000002	Loss 0.8008 (0.7424)	Prec@1 73.047 (74.624)	
Epoch: [15][116/196]	LR: 0.010000000000000002	Loss 0.7227 (0.7472)	Prec@1 75.781 (74.436)	
Epoch: [15][155/196]	LR: 0.010000000000000002	Loss 0.7314 (0.7471)	Prec@1 77.344 (74.604)	
Epoch: [15][194/196]	LR: 0.010000000000000002	Loss 0.8311 (0.7475)	Prec@1 69.922 (74.690)	
Total train loss: 0.7475

Train time: 14.006164073944092
 * Prec@1 76.100 Prec@5 97.950 Loss 0.7378
Best acc: 76.110
--------------------------------------------------------------------------------
Test time: 16.892510414123535

Epoch: [16][38/196]	LR: 0.0010000000000000002	Loss 0.6929 (0.7509)	Prec@1 75.781 (74.519)	
Epoch: [16][77/196]	LR: 0.0010000000000000002	Loss 0.7593 (0.7453)	Prec@1 78.516 (74.980)	
Epoch: [16][116/196]	LR: 0.0010000000000000002	Loss 0.7266 (0.7473)	Prec@1 76.562 (74.917)	
Epoch: [16][155/196]	LR: 0.0010000000000000002	Loss 0.7407 (0.7474)	Prec@1 75.391 (74.855)	
Epoch: [16][194/196]	LR: 0.0010000000000000002	Loss 0.6924 (0.7455)	Prec@1 75.391 (74.854)	
Total train loss: 0.7456

Train time: 12.089371681213379
 * Prec@1 76.130 Prec@5 98.030 Loss 0.7368
Best acc: 76.130
--------------------------------------------------------------------------------
Test time: 14.960812091827393

Epoch: [17][38/196]	LR: 0.0010000000000000002	Loss 0.6655 (0.7613)	Prec@1 76.953 (74.058)	
Epoch: [17][77/196]	LR: 0.0010000000000000002	Loss 0.7524 (0.7487)	Prec@1 74.609 (74.329)	
Epoch: [17][116/196]	LR: 0.0010000000000000002	Loss 0.6138 (0.7494)	Prec@1 76.562 (74.389)	
Epoch: [17][155/196]	LR: 0.0010000000000000002	Loss 0.8677 (0.7479)	Prec@1 75.391 (74.482)	
Epoch: [17][194/196]	LR: 0.0010000000000000002	Loss 0.7729 (0.7457)	Prec@1 75.391 (74.649)	
Total train loss: 0.7458

Train time: 12.005542993545532
 * Prec@1 76.130 Prec@5 97.950 Loss 0.7349
Best acc: 76.130
--------------------------------------------------------------------------------
Test time: 14.862275838851929

Epoch: [18][38/196]	LR: 0.0010000000000000002	Loss 0.7407 (0.7366)	Prec@1 77.344 (74.700)	
Epoch: [18][77/196]	LR: 0.0010000000000000002	Loss 0.6562 (0.7329)	Prec@1 80.469 (74.865)	
Epoch: [18][116/196]	LR: 0.0010000000000000002	Loss 0.6958 (0.7391)	Prec@1 78.125 (74.790)	
Epoch: [18][155/196]	LR: 0.0010000000000000002	Loss 0.7661 (0.7467)	Prec@1 74.609 (74.677)	
Epoch: [18][194/196]	LR: 0.0010000000000000002	Loss 0.8003 (0.7444)	Prec@1 71.875 (74.834)	
Total train loss: 0.7445

Train time: 11.955992221832275
 * Prec@1 76.000 Prec@5 97.970 Loss 0.7378
Best acc: 76.130
--------------------------------------------------------------------------------
Test time: 14.304130554199219

Epoch: [19][38/196]	LR: 0.0010000000000000002	Loss 0.8306 (0.7387)	Prec@1 70.703 (75.090)	
Epoch: [19][77/196]	LR: 0.0010000000000000002	Loss 0.7759 (0.7469)	Prec@1 71.484 (74.935)	
Epoch: [19][116/196]	LR: 0.0010000000000000002	Loss 0.9214 (0.7505)	Prec@1 68.359 (74.636)	
Epoch: [19][155/196]	LR: 0.0010000000000000002	Loss 0.7148 (0.7455)	Prec@1 73.828 (74.717)	
Epoch: [19][194/196]	LR: 0.0010000000000000002	Loss 0.8105 (0.7462)	Prec@1 71.484 (74.838)	
Total train loss: 0.7462

Train time: 12.092040777206421
 * Prec@1 76.150 Prec@5 98.000 Loss 0.7358
Best acc: 76.150
--------------------------------------------------------------------------------
Test time: 14.982308149337769

Epoch: [20][38/196]	LR: 0.0010000000000000002	Loss 0.6641 (0.7443)	Prec@1 78.125 (74.980)	
Epoch: [20][77/196]	LR: 0.0010000000000000002	Loss 0.7163 (0.7395)	Prec@1 75.391 (74.945)	
Epoch: [20][116/196]	LR: 0.0010000000000000002	Loss 0.7388 (0.7419)	Prec@1 76.562 (74.790)	
Epoch: [20][155/196]	LR: 0.0010000000000000002	Loss 0.8159 (0.7432)	Prec@1 71.094 (74.727)	
Epoch: [20][194/196]	LR: 0.0010000000000000002	Loss 0.8647 (0.7449)	Prec@1 72.266 (74.750)	
Total train loss: 0.7451

Train time: 11.874413967132568
 * Prec@1 76.080 Prec@5 97.920 Loss 0.7349
Best acc: 76.150
--------------------------------------------------------------------------------
Test time: 14.21315622329712

Epoch: [21][38/196]	LR: 0.0010000000000000002	Loss 0.8716 (0.7518)	Prec@1 69.922 (74.389)	
Epoch: [21][77/196]	LR: 0.0010000000000000002	Loss 0.7793 (0.7460)	Prec@1 70.312 (74.594)	
Epoch: [21][116/196]	LR: 0.0010000000000000002	Loss 0.6670 (0.7398)	Prec@1 76.562 (74.813)	
Epoch: [21][155/196]	LR: 0.0010000000000000002	Loss 0.7578 (0.7438)	Prec@1 73.828 (74.732)	
Epoch: [21][194/196]	LR: 0.0010000000000000002	Loss 0.8154 (0.7440)	Prec@1 69.922 (74.688)	
Total train loss: 0.7439

Train time: 12.046648740768433
 * Prec@1 76.200 Prec@5 97.940 Loss 0.7373
Best acc: 76.200
--------------------------------------------------------------------------------
Test time: 15.44896650314331

Epoch: [22][38/196]	LR: 0.0010000000000000002	Loss 0.7251 (0.7495)	Prec@1 76.172 (74.720)	
Epoch: [22][77/196]	LR: 0.0010000000000000002	Loss 0.7773 (0.7511)	Prec@1 73.438 (74.815)	
Epoch: [22][116/196]	LR: 0.0010000000000000002	Loss 0.6768 (0.7464)	Prec@1 75.781 (74.963)	
Epoch: [22][155/196]	LR: 0.0010000000000000002	Loss 0.7515 (0.7445)	Prec@1 73.828 (74.932)	
Epoch: [22][194/196]	LR: 0.0010000000000000002	Loss 0.8662 (0.7472)	Prec@1 71.875 (74.770)	
Total train loss: 0.7476

Train time: 11.993106126785278
 * Prec@1 76.120 Prec@5 97.980 Loss 0.7373
Best acc: 76.200
--------------------------------------------------------------------------------
Test time: 14.340711116790771

Epoch: [23][38/196]	LR: 0.0010000000000000002	Loss 0.6514 (0.7253)	Prec@1 78.516 (75.160)	
Epoch: [23][77/196]	LR: 0.0010000000000000002	Loss 0.7139 (0.7315)	Prec@1 75.781 (74.935)	
Epoch: [23][116/196]	LR: 0.0010000000000000002	Loss 0.6401 (0.7382)	Prec@1 78.906 (74.826)	
Epoch: [23][155/196]	LR: 0.0010000000000000002	Loss 0.8750 (0.7392)	Prec@1 69.531 (74.827)	
Epoch: [23][194/196]	LR: 0.0010000000000000002	Loss 0.8579 (0.7453)	Prec@1 71.094 (74.663)	
Total train loss: 0.7450

Train time: 12.080084800720215
 * Prec@1 75.900 Prec@5 97.940 Loss 0.7397
Best acc: 76.200
--------------------------------------------------------------------------------
Test time: 15.211389064788818

Epoch: [24][38/196]	LR: 0.00010000000000000003	Loss 0.6528 (0.7588)	Prec@1 76.953 (74.750)	
Epoch: [24][77/196]	LR: 0.00010000000000000003	Loss 0.6309 (0.7483)	Prec@1 78.125 (75.085)	
Epoch: [24][116/196]	LR: 0.00010000000000000003	Loss 0.7515 (0.7490)	Prec@1 74.219 (74.816)	
Epoch: [24][155/196]	LR: 0.00010000000000000003	Loss 0.7690 (0.7498)	Prec@1 72.656 (74.832)	
Epoch: [24][194/196]	LR: 0.00010000000000000003	Loss 0.7012 (0.7465)	Prec@1 74.609 (74.836)	
Total train loss: 0.7465

Train time: 12.025427341461182
 * Prec@1 76.020 Prec@5 97.930 Loss 0.7358
Best acc: 76.200
--------------------------------------------------------------------------------
Test time: 14.433943748474121

Epoch: [25][38/196]	LR: 0.00010000000000000003	Loss 0.6909 (0.7296)	Prec@1 74.609 (75.511)	
Epoch: [25][77/196]	LR: 0.00010000000000000003	Loss 0.8066 (0.7372)	Prec@1 73.828 (75.170)	
Epoch: [25][116/196]	LR: 0.00010000000000000003	Loss 0.6113 (0.7414)	Prec@1 78.906 (74.970)	
Epoch: [25][155/196]	LR: 0.00010000000000000003	Loss 0.6587 (0.7415)	Prec@1 76.172 (74.960)	
Epoch: [25][194/196]	LR: 0.00010000000000000003	Loss 0.7266 (0.7446)	Prec@1 75.391 (74.814)	
Total train loss: 0.7445

Train time: 12.343588829040527
 * Prec@1 76.090 Prec@5 97.940 Loss 0.7397
Best acc: 76.200
--------------------------------------------------------------------------------
Test time: 15.292566776275635

Epoch: [26][38/196]	LR: 0.00010000000000000003	Loss 0.8120 (0.7429)	Prec@1 73.828 (74.509)	
Epoch: [26][77/196]	LR: 0.00010000000000000003	Loss 0.7583 (0.7482)	Prec@1 75.781 (74.695)	
Epoch: [26][116/196]	LR: 0.00010000000000000003	Loss 0.7754 (0.7462)	Prec@1 71.484 (74.623)	
Epoch: [26][155/196]	LR: 0.00010000000000000003	Loss 0.6963 (0.7408)	Prec@1 76.172 (74.882)	
Epoch: [26][194/196]	LR: 0.00010000000000000003	Loss 0.7275 (0.7453)	Prec@1 73.047 (74.696)	
Total train loss: 0.7450

Train time: 12.264196872711182
 * Prec@1 76.140 Prec@5 97.940 Loss 0.7368
Best acc: 76.200
--------------------------------------------------------------------------------
Test time: 15.212266206741333

Epoch: [27][38/196]	LR: 0.00010000000000000003	Loss 0.7993 (0.7384)	Prec@1 73.438 (75.010)	
Epoch: [27][77/196]	LR: 0.00010000000000000003	Loss 0.8848 (0.7429)	Prec@1 70.312 (74.730)	
Epoch: [27][116/196]	LR: 0.00010000000000000003	Loss 0.8540 (0.7473)	Prec@1 67.969 (74.646)	
Epoch: [27][155/196]	LR: 0.00010000000000000003	Loss 0.5957 (0.7452)	Prec@1 80.859 (74.712)	
Epoch: [27][194/196]	LR: 0.00010000000000000003	Loss 0.7056 (0.7447)	Prec@1 78.906 (74.675)	
Total train loss: 0.7448

Train time: 12.663094758987427
 * Prec@1 76.010 Prec@5 97.960 Loss 0.7368
Best acc: 76.200
--------------------------------------------------------------------------------
Test time: 15.623045206069946

Epoch: [28][38/196]	LR: 0.00010000000000000003	Loss 0.7310 (0.7443)	Prec@1 76.172 (74.700)	
Epoch: [28][77/196]	LR: 0.00010000000000000003	Loss 0.7236 (0.7481)	Prec@1 74.609 (74.474)	
Epoch: [28][116/196]	LR: 0.00010000000000000003	Loss 0.7896 (0.7486)	Prec@1 71.875 (74.563)	
Epoch: [28][155/196]	LR: 0.00010000000000000003	Loss 0.6616 (0.7459)	Prec@1 74.609 (74.562)	
Epoch: [28][194/196]	LR: 0.00010000000000000003	Loss 0.6079 (0.7448)	Prec@1 78.516 (74.764)	
Total train loss: 0.7449

Train time: 11.781490087509155
 * Prec@1 76.000 Prec@5 97.910 Loss 0.7349
Best acc: 76.200
--------------------------------------------------------------------------------
Test time: 13.364573001861572

Epoch: [29][38/196]	LR: 0.00010000000000000003	Loss 0.7109 (0.7461)	Prec@1 76.562 (74.679)	
Epoch: [29][77/196]	LR: 0.00010000000000000003	Loss 0.6245 (0.7415)	Prec@1 80.469 (74.790)	
Epoch: [29][116/196]	LR: 0.00010000000000000003	Loss 0.7495 (0.7424)	Prec@1 73.047 (74.833)	
Epoch: [29][155/196]	LR: 0.00010000000000000003	Loss 0.7686 (0.7452)	Prec@1 75.391 (74.742)	
Epoch: [29][194/196]	LR: 0.00010000000000000003	Loss 0.8472 (0.7441)	Prec@1 71.094 (74.880)	
Total train loss: 0.7439

Train time: 8.140769958496094
 * Prec@1 76.120 Prec@5 97.910 Loss 0.7354
Best acc: 76.200
--------------------------------------------------------------------------------
Test time: 9.96326231956482

