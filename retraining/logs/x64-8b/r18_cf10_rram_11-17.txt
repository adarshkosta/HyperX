
      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 11
Savedir:  ../pretrained_models/frozen/x64-8b/rram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/train/relu11
Test path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/test/relu11
ResNet18(
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 12.600 Prec@5 49.830 Loss 2.3145
Avg Loading time: 0.0177 seconds
Avg Batch time: 0.0519 seconds

Pre-trained Prec@1 with 11 layers frozen: 12.59999942779541 	 Loss: 2.314453125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (0.012)	BT: 0.052 (0.063)	Loss 0.4214 (0.6749)	Prec@1 88.281 (79.177)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (0.083)	BT: 0.054 (0.135)	Loss 0.5342 (0.5555)	Prec@1 80.469 (82.141)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (0.176)	BT: 0.055 (0.229)	Loss 0.2617 (0.4969)	Prec@1 92.188 (83.837)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (0.393)	BT: 0.055 (0.446)	Loss 0.3843 (0.4617)	Prec@1 88.281 (84.851)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.020 (0.600)	BT: 0.076 (0.653)	Loss 0.3101 (0.4355)	Prec@1 90.625 (85.645)	
Total train loss: 0.4353
Avg Loading time: 0.5984 seconds
Avg Batch time: 0.6519 seconds

Train time: 255.0252742767334
 * Prec@1 89.160 Prec@5 99.600 Loss 0.3296
Avg Loading time: 0.2911 seconds
Avg Batch time: 0.3038 seconds

Best acc: 89.160
--------------------------------------------------------------------------------
Test time: 25.037530183792114

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.378)	BT: 0.047 (0.412)	Loss 0.1597 (0.1892)	Prec@1 94.531 (93.890)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.318)	BT: 0.023 (0.359)	Loss 0.1674 (0.1911)	Prec@1 93.750 (93.625)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.306)	BT: 0.023 (0.345)	Loss 0.1755 (0.1960)	Prec@1 93.750 (93.379)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.290)	BT: 0.052 (0.331)	Loss 0.1965 (0.1992)	Prec@1 94.531 (93.302)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.291)	BT: 0.052 (0.334)	Loss 0.2043 (0.2034)	Prec@1 91.406 (93.147)	
Total train loss: 0.2035
Avg Loading time: 0.2902 seconds
Avg Batch time: 0.3328 seconds

Train time: 130.2677185535431
 * Prec@1 88.660 Prec@5 99.690 Loss 0.3418
Avg Loading time: 0.2802 seconds
Avg Batch time: 0.2972 seconds

Best acc: 89.160
--------------------------------------------------------------------------------
Test time: 24.117541551589966

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.264)	BT: 0.028 (0.316)	Loss 0.0615 (0.1046)	Prec@1 99.219 (96.585)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.262)	BT: 0.057 (0.313)	Loss 0.1670 (0.1079)	Prec@1 94.531 (96.509)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (0.253)	BT: 0.055 (0.304)	Loss 0.1403 (0.1169)	Prec@1 96.875 (96.104)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.243)	BT: 0.055 (0.295)	Loss 0.1492 (0.1215)	Prec@1 94.531 (95.908)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.012 (0.241)	BT: 0.067 (0.294)	Loss 0.1120 (0.1233)	Prec@1 97.656 (95.831)	
Total train loss: 0.1232
Avg Loading time: 0.2409 seconds
Avg Batch time: 0.2932 seconds

Train time: 114.79609155654907
 * Prec@1 89.760 Prec@5 99.660 Loss 0.3213
Avg Loading time: 0.2995 seconds
Avg Batch time: 0.3166 seconds

Best acc: 89.760
--------------------------------------------------------------------------------
Test time: 26.058709144592285

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.111)	BT: 0.061 (0.166)	Loss 0.0378 (0.0710)	Prec@1 99.219 (97.726)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.071)	BT: 0.057 (0.125)	Loss 0.0555 (0.0705)	Prec@1 99.219 (97.676)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.047)	BT: 0.059 (0.103)	Loss 0.0367 (0.0722)	Prec@1 99.219 (97.643)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.036)	BT: 0.074 (0.093)	Loss 0.1508 (0.0771)	Prec@1 95.312 (97.471)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.029)	BT: 0.055 (0.087)	Loss 0.1523 (0.0805)	Prec@1 95.312 (97.342)	
Total train loss: 0.0806
Avg Loading time: 0.0285 seconds
Avg Batch time: 0.0866 seconds

Train time: 34.06483840942383
 * Prec@1 89.060 Prec@5 99.630 Loss 0.3574
Avg Loading time: 0.0264 seconds
Avg Batch time: 0.0436 seconds

Best acc: 89.760
--------------------------------------------------------------------------------
Test time: 4.070540189743042

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.019)	BT: 0.086 (0.070)	Loss 0.1075 (0.0570)	Prec@1 95.312 (98.127)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.009)	BT: 0.056 (0.067)	Loss 0.0229 (0.0538)	Prec@1 100.000 (98.277)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.056 (0.066)	Loss 0.0739 (0.0557)	Prec@1 96.875 (98.234)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.062 (0.065)	Loss 0.0614 (0.0584)	Prec@1 98.438 (98.140)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.061 (0.064)	Loss 0.0824 (0.0617)	Prec@1 98.438 (98.027)	
Total train loss: 0.0618
Avg Loading time: 0.0040 seconds
Avg Batch time: 0.0641 seconds

Train time: 25.241474866867065
 * Prec@1 89.540 Prec@5 99.560 Loss 0.3669
Avg Loading time: 0.0476 seconds
Avg Batch time: 0.0638 seconds

Best acc: 89.760
--------------------------------------------------------------------------------
Test time: 5.711572647094727

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.053 (0.070)	Loss 0.0544 (0.0539)	Prec@1 97.656 (98.327)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.005 (0.017)	BT: 0.064 (0.069)	Loss 0.0955 (0.0524)	Prec@1 96.875 (98.307)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.001 (0.013)	BT: 0.064 (0.069)	Loss 0.0546 (0.0531)	Prec@1 98.438 (98.241)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.011)	BT: 0.056 (0.069)	Loss 0.0959 (0.0544)	Prec@1 96.875 (98.212)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.009)	BT: 0.062 (0.068)	Loss 0.0380 (0.0550)	Prec@1 99.219 (98.213)	
Total train loss: 0.0550
Avg Loading time: 0.0090 seconds
Avg Batch time: 0.0677 seconds

Train time: 26.669419288635254
 * Prec@1 90.420 Prec@5 99.520 Loss 0.3362
Avg Loading time: 0.0333 seconds
Avg Batch time: 0.0580 seconds

Best acc: 90.420
--------------------------------------------------------------------------------
Test time: 5.663729190826416

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.054 (0.075)	Loss 0.0242 (0.0299)	Prec@1 99.219 (99.149)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.057 (0.068)	Loss 0.0109 (0.0304)	Prec@1 100.000 (99.094)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.060 (0.066)	Loss 0.0188 (0.0317)	Prec@1 100.000 (99.042)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.032 (0.063)	Loss 0.0131 (0.0339)	Prec@1 100.000 (98.993)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.059 (0.062)	Loss 0.0463 (0.0376)	Prec@1 99.219 (98.862)	
Total train loss: 0.0377
Avg Loading time: 0.0036 seconds
Avg Batch time: 0.0622 seconds

Train time: 24.5223069190979
 * Prec@1 90.060 Prec@5 99.560 Loss 0.3450
Avg Loading time: 0.0536 seconds
Avg Batch time: 0.0732 seconds

Best acc: 90.420
--------------------------------------------------------------------------------
Test time: 6.479802131652832

Epoch: [7][77/391]	LR: 0.1	DT: 0.001 (0.017)	BT: 0.058 (0.082)	Loss 0.0223 (0.0325)	Prec@1 99.219 (98.998)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.009)	BT: 0.073 (0.073)	Loss 0.0271 (0.0314)	Prec@1 99.219 (99.109)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.009)	BT: 0.081 (0.073)	Loss 0.0162 (0.0319)	Prec@1 100.000 (99.062)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.081 (0.072)	Loss 0.0444 (0.0335)	Prec@1 97.656 (98.953)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.068 (0.071)	Loss 0.0144 (0.0347)	Prec@1 100.000 (98.942)	
Total train loss: 0.0347
Avg Loading time: 0.0066 seconds
Avg Batch time: 0.0710 seconds

Train time: 27.954908847808838
 * Prec@1 90.940 Prec@5 99.570 Loss 0.3257
Avg Loading time: 0.0362 seconds
Avg Batch time: 0.0576 seconds

Best acc: 90.940
--------------------------------------------------------------------------------
Test time: 5.699719667434692

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.021)	BT: 0.055 (0.079)	Loss 0.0121 (0.0237)	Prec@1 100.000 (99.359)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.016)	BT: 0.077 (0.076)	Loss 0.0375 (0.0243)	Prec@1 99.219 (99.334)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.011)	BT: 0.054 (0.072)	Loss 0.0050 (0.0242)	Prec@1 100.000 (99.332)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.052 (0.070)	Loss 0.0500 (0.0249)	Prec@1 97.656 (99.294)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.063 (0.068)	Loss 0.0216 (0.0256)	Prec@1 100.000 (99.267)	
Total train loss: 0.0257
Avg Loading time: 0.0065 seconds
Avg Batch time: 0.0683 seconds

Train time: 26.91153907775879
 * Prec@1 90.440 Prec@5 99.510 Loss 0.3481
Avg Loading time: 0.0420 seconds
Avg Batch time: 0.0625 seconds

Best acc: 90.940
--------------------------------------------------------------------------------
Test time: 5.653953313827515

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.016)	BT: 0.078 (0.079)	Loss 0.0168 (0.0200)	Prec@1 100.000 (99.449)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.054 (0.072)	Loss 0.0097 (0.0200)	Prec@1 100.000 (99.484)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.054 (0.068)	Loss 0.0807 (0.0231)	Prec@1 96.875 (99.366)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.071 (0.068)	Loss 0.0192 (0.0236)	Prec@1 99.219 (99.346)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.057 (0.068)	Loss 0.0503 (0.0256)	Prec@1 97.656 (99.251)	
Total train loss: 0.0257
Avg Loading time: 0.0061 seconds
Avg Batch time: 0.0677 seconds

Train time: 26.674567461013794
 * Prec@1 91.030 Prec@5 99.530 Loss 0.3308
Avg Loading time: 0.0344 seconds
Avg Batch time: 0.0591 seconds

Best acc: 91.030
--------------------------------------------------------------------------------
Test time: 5.80653190612793

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.002 (0.015)	BT: 0.039 (0.077)	Loss 0.0147 (0.0153)	Prec@1 99.219 (99.629)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.015)	BT: 0.053 (0.071)	Loss 0.0048 (0.0126)	Prec@1 100.000 (99.720)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.011)	BT: 0.059 (0.070)	Loss 0.0050 (0.0110)	Prec@1 100.000 (99.763)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.054 (0.069)	Loss 0.0024 (0.0102)	Prec@1 100.000 (99.797)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.065 (0.069)	Loss 0.0026 (0.0093)	Prec@1 100.000 (99.822)	
Total train loss: 0.0093
Avg Loading time: 0.0070 seconds
Avg Batch time: 0.0690 seconds

Train time: 27.181164741516113
 * Prec@1 93.320 Prec@5 99.720 Loss 0.2458
Avg Loading time: 0.0460 seconds
Avg Batch time: 0.0674 seconds

Best acc: 93.320
--------------------------------------------------------------------------------
Test time: 6.469326019287109

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.015)	BT: 0.056 (0.075)	Loss 0.0101 (0.0040)	Prec@1 99.219 (99.970)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.090 (0.069)	Loss 0.0021 (0.0040)	Prec@1 100.000 (99.980)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.067 (0.068)	Loss 0.0037 (0.0038)	Prec@1 100.000 (99.980)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.044 (0.065)	Loss 0.0020 (0.0039)	Prec@1 100.000 (99.975)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.060 (0.064)	Loss 0.0052 (0.0038)	Prec@1 100.000 (99.974)	
Total train loss: 0.0038
Avg Loading time: 0.0038 seconds
Avg Batch time: 0.0642 seconds

Train time: 25.319060564041138
 * Prec@1 93.160 Prec@5 99.700 Loss 0.2441
Avg Loading time: 0.0324 seconds
Avg Batch time: 0.0549 seconds

Best acc: 93.320
--------------------------------------------------------------------------------
Test time: 5.022156476974487

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.001 (0.014)	BT: 0.065 (0.079)	Loss 0.0040 (0.0034)	Prec@1 100.000 (99.970)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.058 (0.073)	Loss 0.0061 (0.0034)	Prec@1 100.000 (99.980)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.092 (0.070)	Loss 0.0022 (0.0035)	Prec@1 100.000 (99.973)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.067 (0.069)	Loss 0.0016 (0.0033)	Prec@1 100.000 (99.980)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.003)	BT: 0.054 (0.068)	Loss 0.0031 (0.0033)	Prec@1 100.000 (99.980)	
Total train loss: 0.0033
Avg Loading time: 0.0031 seconds
Avg Batch time: 0.0675 seconds

Train time: 26.59693455696106
 * Prec@1 93.360 Prec@5 99.700 Loss 0.2419
Avg Loading time: 0.0437 seconds
Avg Batch time: 0.0649 seconds

Best acc: 93.360
--------------------------------------------------------------------------------
Test time: 6.2576892375946045

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.016)	BT: 0.069 (0.081)	Loss 0.0015 (0.0025)	Prec@1 100.000 (100.000)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.054 (0.071)	Loss 0.0022 (0.0026)	Prec@1 100.000 (99.995)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.061 (0.068)	Loss 0.0024 (0.0027)	Prec@1 100.000 (99.997)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.057 (0.067)	Loss 0.0011 (0.0028)	Prec@1 100.000 (99.992)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.054 (0.065)	Loss 0.0027 (0.0028)	Prec@1 100.000 (99.994)	
Total train loss: 0.0028
Avg Loading time: 0.0035 seconds
Avg Batch time: 0.0650 seconds

Train time: 25.61246633529663
 * Prec@1 93.560 Prec@5 99.710 Loss 0.2428
Avg Loading time: 0.0269 seconds
Avg Batch time: 0.0477 seconds

Best acc: 93.560
--------------------------------------------------------------------------------
Test time: 4.875162124633789

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.017)	BT: 0.059 (0.076)	Loss 0.0042 (0.0025)	Prec@1 100.000 (100.000)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.059 (0.069)	Loss 0.0035 (0.0027)	Prec@1 100.000 (99.990)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.025 (0.077)	Loss 0.0084 (0.0027)	Prec@1 100.000 (99.993)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.036 (0.033)	BT: 0.064 (0.081)	Loss 0.0020 (0.0027)	Prec@1 100.000 (99.995)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.029)	BT: 0.052 (0.078)	Loss 0.0018 (0.0026)	Prec@1 100.000 (99.996)	
Total train loss: 0.0026
Avg Loading time: 0.0289 seconds
Avg Batch time: 0.0783 seconds

Train time: 30.8411066532135
 * Prec@1 93.480 Prec@5 99.730 Loss 0.2380
Avg Loading time: 0.0446 seconds
Avg Batch time: 0.0665 seconds

Best acc: 93.560
--------------------------------------------------------------------------------
Test time: 5.932950735092163

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.066 (0.081)	Loss 0.0066 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.051 (0.071)	Loss 0.0016 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.056 (0.069)	Loss 0.0028 (0.0023)	Prec@1 100.000 (99.997)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.057 (0.068)	Loss 0.0028 (0.0023)	Prec@1 100.000 (99.997)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.066 (0.068)	Loss 0.0023 (0.0023)	Prec@1 100.000 (99.998)	
Total train loss: 0.0023
Avg Loading time: 0.0039 seconds
Avg Batch time: 0.0680 seconds

Train time: 26.797889471054077
 * Prec@1 93.450 Prec@5 99.710 Loss 0.2397
Avg Loading time: 0.0439 seconds
Avg Batch time: 0.0609 seconds

Best acc: 93.560
--------------------------------------------------------------------------------
Test time: 5.489603281021118

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.011)	BT: 0.062 (0.067)	Loss 0.0008 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.054 (0.065)	Loss 0.0020 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.047 (0.059)	Loss 0.0029 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.039 (0.053)	Loss 0.0038 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.026 (0.051)	Loss 0.0016 (0.0021)	Prec@1 100.000 (99.998)	
Total train loss: 0.0021
Avg Loading time: 0.0064 seconds
Avg Batch time: 0.0514 seconds

Train time: 20.294867753982544
 * Prec@1 93.610 Prec@5 99.720 Loss 0.2393
Avg Loading time: 0.0399 seconds
Avg Batch time: 0.0616 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 6.046730995178223

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.016)	BT: 0.062 (0.079)	Loss 0.0012 (0.0022)	Prec@1 100.000 (99.980)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.058 (0.072)	Loss 0.0090 (0.0024)	Prec@1 99.219 (99.965)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.056 (0.070)	Loss 0.0023 (0.0023)	Prec@1 100.000 (99.973)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.052 (0.069)	Loss 0.0047 (0.0023)	Prec@1 100.000 (99.980)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.003)	BT: 0.054 (0.068)	Loss 0.0020 (0.0023)	Prec@1 100.000 (99.984)	
Total train loss: 0.0023
Avg Loading time: 0.0034 seconds
Avg Batch time: 0.0677 seconds

Train time: 26.65047550201416
 * Prec@1 93.490 Prec@5 99.700 Loss 0.2408
Avg Loading time: 0.0438 seconds
Avg Batch time: 0.0658 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.903398513793945

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.015)	BT: 0.060 (0.081)	Loss 0.0020 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.075 (0.073)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.063 (0.071)	Loss 0.0014 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.056 (0.071)	Loss 0.0010 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.054 (0.069)	Loss 0.0064 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0048 seconds
Avg Batch time: 0.0690 seconds

Train time: 27.16615891456604
 * Prec@1 93.540 Prec@5 99.690 Loss 0.2396
Avg Loading time: 0.0319 seconds
Avg Batch time: 0.0558 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.080234527587891

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.060 (0.074)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.048 (0.065)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.010)	BT: 0.077 (0.063)	Loss 0.0034 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.062 (0.064)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.054 (0.064)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0063 seconds
Avg Batch time: 0.0636 seconds

Train time: 25.071929454803467
 * Prec@1 93.430 Prec@5 99.720 Loss 0.2408
Avg Loading time: 0.0462 seconds
Avg Batch time: 0.0697 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 6.189671754837036

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.056 (0.083)	Loss 0.0013 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.052 (0.074)	Loss 0.0007 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.069 (0.070)	Loss 0.0047 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.033 (0.068)	Loss 0.0010 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.054 (0.067)	Loss 0.0014 (0.0018)	Prec@1 100.000 (99.996)	
Total train loss: 0.0018
Avg Loading time: 0.0062 seconds
Avg Batch time: 0.0671 seconds

Train time: 26.4613778591156
 * Prec@1 93.480 Prec@5 99.710 Loss 0.2388
Avg Loading time: 0.0397 seconds
Avg Batch time: 0.0620 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.5841064453125

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.016)	BT: 0.063 (0.080)	Loss 0.0025 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.010)	BT: 0.056 (0.071)	Loss 0.0008 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.077 (0.068)	Loss 0.0011 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.064 (0.068)	Loss 0.0023 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.056 (0.066)	Loss 0.0009 (0.0018)	Prec@1 100.000 (99.996)	
Total train loss: 0.0018
Avg Loading time: 0.0046 seconds
Avg Batch time: 0.0655 seconds

Train time: 25.793681859970093
 * Prec@1 93.500 Prec@5 99.710 Loss 0.2406
Avg Loading time: 0.0527 seconds
Avg Batch time: 0.0711 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 6.359273910522461

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.016)	BT: 0.084 (0.082)	Loss 0.0020 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.064 (0.074)	Loss 0.0044 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.083 (0.070)	Loss 0.0071 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.001 (0.004)	BT: 0.079 (0.069)	Loss 0.0027 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.024 (0.066)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0055 seconds
Avg Batch time: 0.0658 seconds

Train time: 25.95909357070923
 * Prec@1 93.560 Prec@5 99.710 Loss 0.2394
Avg Loading time: 0.0360 seconds
Avg Batch time: 0.0601 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.497020483016968

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.018)	BT: 0.057 (0.082)	Loss 0.0023 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.009)	BT: 0.056 (0.073)	Loss 0.0017 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.054 (0.070)	Loss 0.0021 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.054 (0.068)	Loss 0.0015 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.054 (0.067)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0040 seconds
Avg Batch time: 0.0668 seconds

Train time: 26.336252212524414
 * Prec@1 93.480 Prec@5 99.720 Loss 0.2375
Avg Loading time: 0.0454 seconds
Avg Batch time: 0.0644 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.770812034606934

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.017)	BT: 0.056 (0.073)	Loss 0.0019 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.077 (0.066)	Loss 0.0030 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.054 (0.066)	Loss 0.0055 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.001 (0.005)	BT: 0.060 (0.065)	Loss 0.0013 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.051 (0.066)	Loss 0.0014 (0.0017)	Prec@1 100.000 (100.000)	
Total train loss: 0.0017
Avg Loading time: 0.0046 seconds
Avg Batch time: 0.0658 seconds

Train time: 25.913085222244263
 * Prec@1 93.440 Prec@5 99.700 Loss 0.2416
Avg Loading time: 0.0361 seconds
Avg Batch time: 0.0613 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.565855979919434

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.017)	BT: 0.066 (0.082)	Loss 0.0019 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.009)	BT: 0.026 (0.072)	Loss 0.0011 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.010)	BT: 0.070 (0.070)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.058 (0.068)	Loss 0.0015 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.054 (0.069)	Loss 0.0023 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0084 seconds
Avg Batch time: 0.0692 seconds

Train time: 27.28333044052124
 * Prec@1 93.490 Prec@5 99.680 Loss 0.2402
Avg Loading time: 0.0456 seconds
Avg Batch time: 0.0676 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 6.069723844528198

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.092 (0.080)	Loss 0.0036 (0.0021)	Prec@1 100.000 (99.980)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.052 (0.071)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.058 (0.067)	Loss 0.0014 (0.0018)	Prec@1 100.000 (99.993)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.027 (0.065)	Loss 0.0009 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.051 (0.064)	Loss 0.0005 (0.0018)	Prec@1 100.000 (99.994)	
Total train loss: 0.0018
Avg Loading time: 0.0043 seconds
Avg Batch time: 0.0639 seconds

Train time: 25.113372564315796
 * Prec@1 93.450 Prec@5 99.710 Loss 0.2384
Avg Loading time: 0.0332 seconds
Avg Batch time: 0.0542 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.0056703090667725

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.062 (0.075)	Loss 0.0028 (0.0019)	Prec@1 100.000 (99.980)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.003 (0.008)	BT: 0.060 (0.070)	Loss 0.0011 (0.0018)	Prec@1 100.000 (99.990)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.047 (0.067)	Loss 0.0029 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.063 (0.065)	Loss 0.0038 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.031 (0.063)	Loss 0.0007 (0.0018)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0080 seconds
Avg Batch time: 0.0626 seconds

Train time: 24.707281589508057
 * Prec@1 93.470 Prec@5 99.700 Loss 0.2412
Avg Loading time: 0.0540 seconds
Avg Batch time: 0.0731 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 6.45939040184021

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.078 (0.078)	Loss 0.0008 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.053 (0.071)	Loss 0.0030 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.058 (0.068)	Loss 0.0008 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.066 (0.067)	Loss 0.0017 (0.0017)	Prec@1 100.000 (99.997)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.052 (0.067)	Loss 0.0015 (0.0017)	Prec@1 100.000 (99.998)	
Total train loss: 0.0017
Avg Loading time: 0.0035 seconds
Avg Batch time: 0.0671 seconds

Train time: 26.398255109786987
 * Prec@1 93.500 Prec@5 99.710 Loss 0.2406
Avg Loading time: 0.0320 seconds
Avg Batch time: 0.0549 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.044828414916992

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.013)	BT: 0.060 (0.075)	Loss 0.0026 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.009)	BT: 0.055 (0.066)	Loss 0.0010 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.057 (0.065)	Loss 0.0034 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.059 (0.064)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.054 (0.064)	Loss 0.0020 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0045 seconds
Avg Batch time: 0.0642 seconds

Train time: 25.316625118255615
 * Prec@1 93.430 Prec@5 99.720 Loss 0.2390
Avg Loading time: 0.0459 seconds
Avg Batch time: 0.0673 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 6.001850366592407

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.001 (0.017)	BT: 0.060 (0.083)	Loss 0.0010 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.054 (0.073)	Loss 0.0006 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.077 (0.071)	Loss 0.0033 (0.0018)	Prec@1 100.000 (99.993)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.075 (0.069)	Loss 0.0027 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.052 (0.068)	Loss 0.0061 (0.0018)	Prec@1 100.000 (99.996)	
Total train loss: 0.0018
Avg Loading time: 0.0051 seconds
Avg Batch time: 0.0679 seconds

Train time: 26.7606360912323
 * Prec@1 93.560 Prec@5 99.700 Loss 0.2384
Avg Loading time: 0.0332 seconds
Avg Batch time: 0.0563 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.150278568267822

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.060 (0.080)	Loss 0.0022 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.058 (0.074)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.067 (0.072)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.058 (0.069)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.054 (0.068)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.0050 seconds
Avg Batch time: 0.0677 seconds

Train time: 26.679017543792725
 * Prec@1 93.590 Prec@5 99.690 Loss 0.2382
Avg Loading time: 0.0391 seconds
Avg Batch time: 0.0586 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.390539646148682

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.014)	BT: 0.057 (0.072)	Loss 0.0018 (0.0018)	Prec@1 100.000 (99.990)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.054 (0.064)	Loss 0.0018 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.059 (0.063)	Loss 0.0024 (0.0018)	Prec@1 100.000 (99.993)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.065 (0.063)	Loss 0.0011 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.052 (0.063)	Loss 0.0010 (0.0018)	Prec@1 100.000 (99.996)	
Total train loss: 0.0018
Avg Loading time: 0.0032 seconds
Avg Batch time: 0.0632 seconds

Train time: 24.935294151306152
 * Prec@1 93.470 Prec@5 99.720 Loss 0.2390
Avg Loading time: 0.0305 seconds
Avg Batch time: 0.0540 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 4.959338426589966

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.065 (0.074)	Loss 0.0011 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.074 (0.070)	Loss 0.0020 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.004 (0.005)	BT: 0.075 (0.067)	Loss 0.0014 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.056 (0.066)	Loss 0.0009 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.053 (0.066)	Loss 0.0014 (0.0018)	Prec@1 100.000 (99.996)	
Total train loss: 0.0018
Avg Loading time: 0.0035 seconds
Avg Batch time: 0.0654 seconds

Train time: 25.772276639938354
 * Prec@1 93.490 Prec@5 99.710 Loss 0.2384
Avg Loading time: 0.0509 seconds
Avg Batch time: 0.0732 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 6.497623920440674

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.089 (0.081)	Loss 0.0011 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.054 (0.071)	Loss 0.0018 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.053 (0.066)	Loss 0.0014 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.054 (0.065)	Loss 0.0008 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.054 (0.063)	Loss 0.0011 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0032 seconds
Avg Batch time: 0.0632 seconds

Train time: 24.924175024032593
 * Prec@1 93.470 Prec@5 99.710 Loss 0.2404
Avg Loading time: 0.0381 seconds
Avg Batch time: 0.0580 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.259993314743042

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.014)	BT: 0.052 (0.080)	Loss 0.0025 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.052 (0.071)	Loss 0.0015 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.054 (0.069)	Loss 0.0011 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.058 (0.067)	Loss 0.0015 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.075 (0.067)	Loss 0.0064 (0.0017)	Prec@1 100.000 (100.000)	
Total train loss: 0.0017
Avg Loading time: 0.0036 seconds
Avg Batch time: 0.0668 seconds

Train time: 26.344661235809326
 * Prec@1 93.460 Prec@5 99.700 Loss 0.2416
Avg Loading time: 0.0413 seconds
Avg Batch time: 0.0624 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.601855754852295

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.058 (0.077)	Loss 0.0010 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.058 (0.069)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.068 (0.067)	Loss 0.0042 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.073 (0.066)	Loss 0.0022 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.054 (0.065)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0027 seconds
Avg Batch time: 0.0649 seconds

Train time: 25.577670097351074
 * Prec@1 93.480 Prec@5 99.700 Loss 0.2438
Avg Loading time: 0.0244 seconds
Avg Batch time: 0.0422 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 4.01647162437439

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.060 (0.077)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.046 (0.065)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.045)	BT: 0.027 (0.092)	Loss 0.0017 (0.0020)	Prec@1 100.000 (99.987)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.002 (0.035)	BT: 0.075 (0.085)	Loss 0.0018 (0.0020)	Prec@1 100.000 (99.987)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.028)	BT: 0.051 (0.081)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.990)	
Total train loss: 0.0019
Avg Loading time: 0.0281 seconds
Avg Batch time: 0.0810 seconds

Train time: 31.84866189956665
 * Prec@1 93.380 Prec@5 99.720 Loss 0.2386
Avg Loading time: 0.0459 seconds
Avg Batch time: 0.0671 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 6.049052953720093

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.018)	BT: 0.069 (0.083)	Loss 0.0009 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.054 (0.073)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.067 (0.070)	Loss 0.0022 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.034 (0.066)	Loss 0.0007 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.035 (0.064)	Loss 0.0021 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0065 seconds
Avg Batch time: 0.0640 seconds

Train time: 25.19376850128174
 * Prec@1 93.540 Prec@5 99.720 Loss 0.2380
Avg Loading time: 0.0402 seconds
Avg Batch time: 0.0548 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.026879072189331

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.064 (0.080)	Loss 0.0041 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.053 (0.071)	Loss 0.0009 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.032 (0.060)	Loss 0.0007 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.032 (0.054)	Loss 0.0021 (0.0017)	Prec@1 100.000 (99.997)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.025 (0.053)	Loss 0.0011 (0.0017)	Prec@1 100.000 (99.998)	
Total train loss: 0.0017
Avg Loading time: 0.0069 seconds
Avg Batch time: 0.0529 seconds

Train time: 20.93307590484619
 * Prec@1 93.450 Prec@5 99.700 Loss 0.2415
Avg Loading time: 0.0343 seconds
Avg Batch time: 0.0521 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 4.74835467338562

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.013)	BT: 0.055 (0.073)	Loss 0.0013 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.077 (0.068)	Loss 0.0010 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.053 (0.067)	Loss 0.0014 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.066 (0.067)	Loss 0.0021 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.054 (0.066)	Loss 0.0005 (0.0019)	Prec@1 100.000 (99.994)	
Total train loss: 0.0019
Avg Loading time: 0.0029 seconds
Avg Batch time: 0.0659 seconds

Train time: 25.93403196334839
 * Prec@1 93.470 Prec@5 99.710 Loss 0.2408
Avg Loading time: 0.0425 seconds
Avg Batch time: 0.0638 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.737382650375366

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.029)	BT: 0.060 (0.073)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.015)	BT: 0.058 (0.070)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.053 (0.067)	Loss 0.0007 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.065 (0.066)	Loss 0.0056 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.053 (0.065)	Loss 0.0024 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0062 seconds
Avg Batch time: 0.0654 seconds

Train time: 25.75759530067444
 * Prec@1 93.280 Prec@5 99.700 Loss 0.2410
Avg Loading time: 0.0431 seconds
Avg Batch time: 0.0637 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.750558137893677

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.001 (0.017)	BT: 0.065 (0.083)	Loss 0.0014 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.064 (0.072)	Loss 0.0029 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.073 (0.010)	BT: 0.099 (0.067)	Loss 0.0021 (0.0017)	Prec@1 100.000 (99.997)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.053 (0.066)	Loss 0.0032 (0.0017)	Prec@1 100.000 (99.997)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.052 (0.064)	Loss 0.0011 (0.0017)	Prec@1 100.000 (99.998)	
Total train loss: 0.0017
Avg Loading time: 0.0070 seconds
Avg Batch time: 0.0642 seconds

Train time: 25.29416847229004
 * Prec@1 93.520 Prec@5 99.720 Loss 0.2410
Avg Loading time: 0.0396 seconds
Avg Batch time: 0.0620 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.602626323699951

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.015)	BT: 0.054 (0.081)	Loss 0.0031 (0.0018)	Prec@1 100.000 (99.990)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.054 (0.074)	Loss 0.0013 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.076 (0.071)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.067 (0.071)	Loss 0.0007 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.031 (0.067)	Loss 0.0007 (0.0018)	Prec@1 100.000 (99.996)	
Total train loss: 0.0018
Avg Loading time: 0.0057 seconds
Avg Batch time: 0.0671 seconds

Train time: 26.459025382995605
 * Prec@1 93.370 Prec@5 99.710 Loss 0.2380
Avg Loading time: 0.0439 seconds
Avg Batch time: 0.0645 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.941108226776123

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.016)	BT: 0.054 (0.081)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.075 (0.073)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.061 (0.070)	Loss 0.0014 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.054 (0.068)	Loss 0.0015 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.069 (0.067)	Loss 0.0044 (0.0018)	Prec@1 100.000 (99.996)	
Total train loss: 0.0018
Avg Loading time: 0.0035 seconds
Avg Batch time: 0.0670 seconds

Train time: 26.34145760536194
 * Prec@1 93.510 Prec@5 99.710 Loss 0.2400
Avg Loading time: 0.0444 seconds
Avg Batch time: 0.0645 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.835489988327026

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.017)	BT: 0.054 (0.074)	Loss 0.0008 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.062 (0.066)	Loss 0.0023 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.077 (0.065)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.059 (0.065)	Loss 0.0014 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.052 (0.064)	Loss 0.0019 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0037 seconds
Avg Batch time: 0.0642 seconds

Train time: 25.28959083557129
 * Prec@1 93.530 Prec@5 99.710 Loss 0.2394
Avg Loading time: 0.0339 seconds
Avg Batch time: 0.0553 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.038393974304199

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.016)	BT: 0.072 (0.080)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.051 (0.072)	Loss 0.0009 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.067 (0.069)	Loss 0.0010 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.053 (0.069)	Loss 0.0023 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.054 (0.068)	Loss 0.0022 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0047 seconds
Avg Batch time: 0.0681 seconds

Train time: 26.827166318893433
 * Prec@1 93.460 Prec@5 99.700 Loss 0.2416
Avg Loading time: 0.0486 seconds
Avg Batch time: 0.0712 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 6.323708772659302

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.060 (0.074)	Loss 0.0034 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.012)	BT: 0.058 (0.070)	Loss 0.0008 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.053 (0.066)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.057 (0.065)	Loss 0.0015 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.051 (0.064)	Loss 0.0020 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0048 seconds
Avg Batch time: 0.0638 seconds

Train time: 25.132367610931396
 * Prec@1 93.420 Prec@5 99.690 Loss 0.2416
Avg Loading time: 0.0240 seconds
Avg Batch time: 0.0419 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 3.9295907020568848

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.017)	BT: 0.053 (0.081)	Loss 0.0014 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.054 (0.074)	Loss 0.0011 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.054 (0.070)	Loss 0.0017 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.054 (0.066)	Loss 0.0013 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.064 (0.065)	Loss 0.0014 (0.0017)	Prec@1 100.000 (100.000)	
Total train loss: 0.0017
Avg Loading time: 0.0051 seconds
Avg Batch time: 0.0653 seconds

Train time: 25.757769107818604
 * Prec@1 93.540 Prec@5 99.690 Loss 0.2397
Avg Loading time: 0.0497 seconds
Avg Batch time: 0.0709 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 6.324674129486084

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.018)	BT: 0.066 (0.082)	Loss 0.0028 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.058 (0.073)	Loss 0.0011 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.062 (0.070)	Loss 0.0064 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.063 (0.069)	Loss 0.0018 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.058 (0.068)	Loss 0.0019 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0038 seconds
Avg Batch time: 0.0678 seconds

Train time: 26.716081857681274
 * Prec@1 93.430 Prec@5 99.690 Loss 0.2397
Avg Loading time: 0.0419 seconds
Avg Batch time: 0.0580 seconds

Best acc: 93.610
--------------------------------------------------------------------------------
Test time: 5.241297960281372


      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 13
Savedir:  ../pretrained_models/frozen/x64-8b/rram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/train/relu13
Test path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/test/relu13
ResNet18(
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 9.950 Prec@5 55.750 Loss 2.2988
Avg Loading time: 0.0700 seconds
Avg Batch time: 0.0930 seconds

Pre-trained Prec@1 with 13 layers frozen: 9.949999809265137 	 Loss: 2.298828125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (0.495)	BT: 0.040 (0.538)	Loss 0.5430 (0.6669)	Prec@1 82.031 (79.497)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (0.411)	BT: 0.042 (0.454)	Loss 0.3706 (0.5543)	Prec@1 85.938 (82.267)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.726 (0.376)	BT: 0.768 (0.421)	Loss 0.4346 (0.4992)	Prec@1 84.375 (83.931)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (0.358)	BT: 0.042 (0.401)	Loss 0.3345 (0.4629)	Prec@1 86.719 (84.993)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.743 (0.345)	BT: 0.793 (0.389)	Loss 0.3391 (0.4366)	Prec@1 88.281 (85.691)	
Total train loss: 0.4364
Avg Loading time: 0.3444 seconds
Avg Batch time: 0.3879 seconds

Train time: 151.91734743118286
 * Prec@1 88.830 Prec@5 99.620 Loss 0.3274
Avg Loading time: 0.0449 seconds
Avg Batch time: 0.0632 seconds

Best acc: 88.830
--------------------------------------------------------------------------------
Test time: 5.979292869567871

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.017)	BT: 0.040 (0.070)	Loss 0.1296 (0.1784)	Prec@1 95.312 (94.291)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.015)	BT: 0.040 (0.067)	Loss 0.1886 (0.1852)	Prec@1 94.531 (93.855)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.013)	BT: 0.054 (0.064)	Loss 0.2458 (0.1914)	Prec@1 91.406 (93.633)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.023 (0.012)	BT: 0.063 (0.063)	Loss 0.3423 (0.1936)	Prec@1 85.938 (93.510)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.013)	BT: 0.040 (0.063)	Loss 0.2900 (0.2003)	Prec@1 89.062 (93.221)	
Total train loss: 0.2002
Avg Loading time: 0.0132 seconds
Avg Batch time: 0.0633 seconds

Train time: 24.984198093414307
 * Prec@1 89.020 Prec@5 99.650 Loss 0.3210
Avg Loading time: 0.0415 seconds
Avg Batch time: 0.0626 seconds

Best acc: 89.020
--------------------------------------------------------------------------------
Test time: 5.9932074546813965

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.020)	BT: 0.065 (0.070)	Loss 0.1206 (0.1049)	Prec@1 95.312 (96.835)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.012)	BT: 0.040 (0.062)	Loss 0.1100 (0.1018)	Prec@1 97.656 (96.830)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.047 (0.056)	Loss 0.0935 (0.1025)	Prec@1 96.875 (96.721)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.011)	BT: 0.052 (0.059)	Loss 0.1317 (0.1063)	Prec@1 93.750 (96.504)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.010)	BT: 0.048 (0.058)	Loss 0.0915 (0.1116)	Prec@1 96.875 (96.302)	
Total train loss: 0.1117
Avg Loading time: 0.0101 seconds
Avg Batch time: 0.0574 seconds

Train time: 22.59984016418457
 * Prec@1 88.040 Prec@5 99.540 Loss 0.3809
Avg Loading time: 0.0271 seconds
Avg Batch time: 0.0427 seconds

Best acc: 89.020
--------------------------------------------------------------------------------
Test time: 4.012050151824951

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.019)	BT: 0.051 (0.072)	Loss 0.0625 (0.0638)	Prec@1 97.656 (98.107)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.108 (0.013)	BT: 0.149 (0.065)	Loss 0.0326 (0.0596)	Prec@1 99.219 (98.177)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.013)	BT: 0.033 (0.062)	Loss 0.0662 (0.0634)	Prec@1 98.438 (98.010)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.097 (0.017)	BT: 0.122 (0.061)	Loss 0.0172 (0.0674)	Prec@1 100.000 (97.827)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.034 (0.019)	BT: 0.053 (0.059)	Loss 0.0804 (0.0713)	Prec@1 96.875 (97.688)	
Total train loss: 0.0713
Avg Loading time: 0.0187 seconds
Avg Batch time: 0.0591 seconds

Train time: 23.363546133041382
 * Prec@1 89.720 Prec@5 99.580 Loss 0.3416
Avg Loading time: 0.0476 seconds
Avg Batch time: 0.0617 seconds

Best acc: 89.720
--------------------------------------------------------------------------------
Test time: 5.938116550445557

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.038)	BT: 0.043 (0.065)	Loss 0.0174 (0.0448)	Prec@1 100.000 (98.728)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.030)	BT: 0.033 (0.057)	Loss 0.0817 (0.0470)	Prec@1 97.656 (98.578)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.044 (0.056)	Loss 0.0490 (0.0497)	Prec@1 97.656 (98.481)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.046)	BT: 0.021 (0.073)	Loss 0.0152 (0.0513)	Prec@1 100.000 (98.443)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.044)	BT: 0.035 (0.074)	Loss 0.0670 (0.0536)	Prec@1 98.438 (98.339)	
Total train loss: 0.0536
Avg Loading time: 0.0442 seconds
Avg Batch time: 0.0735 seconds

Train time: 28.946662187576294
 * Prec@1 89.720 Prec@5 99.570 Loss 0.3484
Avg Loading time: 0.0427 seconds
Avg Batch time: 0.0595 seconds

Best acc: 89.720
--------------------------------------------------------------------------------
Test time: 5.355432510375977

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.019)	BT: 0.038 (0.061)	Loss 0.0427 (0.0337)	Prec@1 98.438 (99.038)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.005 (0.020)	BT: 0.082 (0.065)	Loss 0.0163 (0.0322)	Prec@1 99.219 (99.104)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.000 (0.018)	BT: 0.047 (0.064)	Loss 0.0145 (0.0321)	Prec@1 100.000 (99.129)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.039 (0.059)	Loss 0.0197 (0.0352)	Prec@1 100.000 (99.001)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.013)	BT: 0.039 (0.058)	Loss 0.0349 (0.0385)	Prec@1 99.219 (98.864)	
Total train loss: 0.0386
Avg Loading time: 0.0128 seconds
Avg Batch time: 0.0584 seconds

Train time: 23.073267698287964
 * Prec@1 89.460 Prec@5 99.500 Loss 0.3706
Avg Loading time: 0.0443 seconds
Avg Batch time: 0.0643 seconds

Best acc: 89.720
--------------------------------------------------------------------------------
Test time: 5.739310264587402

Epoch: [6][77/391]	LR: 0.1	DT: 0.014 (0.026)	BT: 0.031 (0.067)	Loss 0.0264 (0.0341)	Prec@1 99.219 (98.928)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.048 (0.065)	Loss 0.0186 (0.0339)	Prec@1 99.219 (98.963)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.020)	BT: 0.018 (0.060)	Loss 0.0667 (0.0335)	Prec@1 97.656 (98.985)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.045 (0.058)	Loss 0.0294 (0.0336)	Prec@1 99.219 (98.996)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.017 (0.057)	Loss 0.0408 (0.0343)	Prec@1 98.438 (98.966)	
Total train loss: 0.0343
Avg Loading time: 0.0220 seconds
Avg Batch time: 0.0565 seconds

Train time: 22.327877283096313
 * Prec@1 87.490 Prec@5 99.300 Loss 0.4800
Avg Loading time: 0.0378 seconds
Avg Batch time: 0.0566 seconds

Best acc: 89.720
--------------------------------------------------------------------------------
Test time: 5.128909349441528

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.066 (0.078)	Loss 0.0204 (0.0251)	Prec@1 100.000 (99.339)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.018)	BT: 0.040 (0.067)	Loss 0.0259 (0.0254)	Prec@1 98.438 (99.314)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.012)	BT: 0.044 (0.063)	Loss 0.0461 (0.0260)	Prec@1 97.656 (99.272)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.011)	BT: 0.061 (0.062)	Loss 0.0558 (0.0287)	Prec@1 98.438 (99.124)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.010)	BT: 0.040 (0.061)	Loss 0.0410 (0.0326)	Prec@1 98.438 (99.002)	
Total train loss: 0.0326
Avg Loading time: 0.0103 seconds
Avg Batch time: 0.0611 seconds

Train time: 24.127629041671753
 * Prec@1 89.640 Prec@5 99.350 Loss 0.3801
Avg Loading time: 0.0398 seconds
Avg Batch time: 0.0584 seconds

Best acc: 89.720
--------------------------------------------------------------------------------
Test time: 5.163117408752441

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.067 (0.065)	Loss 0.0316 (0.0365)	Prec@1 99.219 (98.848)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.013)	BT: 0.061 (0.059)	Loss 0.0516 (0.0317)	Prec@1 97.656 (99.033)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.010)	BT: 0.038 (0.056)	Loss 0.0492 (0.0311)	Prec@1 98.438 (99.035)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.072 (0.053)	Loss 0.0199 (0.0314)	Prec@1 100.000 (99.006)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.048 (0.054)	Loss 0.0504 (0.0336)	Prec@1 99.219 (98.930)	
Total train loss: 0.0336
Avg Loading time: 0.0075 seconds
Avg Batch time: 0.0537 seconds

Train time: 21.24105930328369
 * Prec@1 89.230 Prec@5 99.360 Loss 0.3943
Avg Loading time: 0.0420 seconds
Avg Batch time: 0.0619 seconds

Best acc: 89.720
--------------------------------------------------------------------------------
Test time: 5.543367147445679

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.057 (0.079)	Loss 0.0200 (0.0241)	Prec@1 99.219 (99.369)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.057 (0.069)	Loss 0.0290 (0.0231)	Prec@1 99.219 (99.419)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.018)	BT: 0.044 (0.066)	Loss 0.0057 (0.0222)	Prec@1 100.000 (99.422)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.016)	BT: 0.063 (0.065)	Loss 0.0255 (0.0226)	Prec@1 99.219 (99.387)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.040 (0.063)	Loss 0.0291 (0.0228)	Prec@1 98.438 (99.391)	
Total train loss: 0.0228
Avg Loading time: 0.0144 seconds
Avg Batch time: 0.0628 seconds

Train time: 24.80290937423706
 * Prec@1 91.260 Prec@5 99.580 Loss 0.3279
Avg Loading time: 0.0531 seconds
Avg Batch time: 0.0714 seconds

Best acc: 91.260
--------------------------------------------------------------------------------
Test time: 6.700682640075684

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.024)	BT: 0.064 (0.075)	Loss 0.0055 (0.0110)	Prec@1 100.000 (99.830)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.055 (0.065)	Loss 0.0093 (0.0099)	Prec@1 100.000 (99.845)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.044 (0.064)	Loss 0.0049 (0.0091)	Prec@1 100.000 (99.846)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.010)	BT: 0.037 (0.061)	Loss 0.0020 (0.0086)	Prec@1 100.000 (99.860)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.012)	BT: 0.037 (0.059)	Loss 0.0024 (0.0080)	Prec@1 100.000 (99.876)	
Total train loss: 0.0080
Avg Loading time: 0.0123 seconds
Avg Batch time: 0.0590 seconds

Train time: 23.281486988067627
 * Prec@1 92.380 Prec@5 99.620 Loss 0.2732
Avg Loading time: 0.0416 seconds
Avg Batch time: 0.0609 seconds

Best acc: 92.380
--------------------------------------------------------------------------------
Test time: 5.825087070465088

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.051 (0.076)	Loss 0.0074 (0.0040)	Prec@1 100.000 (99.980)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.012)	BT: 0.040 (0.061)	Loss 0.0010 (0.0040)	Prec@1 100.000 (99.970)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.005 (0.010)	BT: 0.051 (0.059)	Loss 0.0019 (0.0039)	Prec@1 100.000 (99.980)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.010)	BT: 0.042 (0.059)	Loss 0.0031 (0.0038)	Prec@1 100.000 (99.982)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.040 (0.058)	Loss 0.0129 (0.0039)	Prec@1 99.219 (99.972)	
Total train loss: 0.0039
Avg Loading time: 0.0088 seconds
Avg Batch time: 0.0582 seconds

Train time: 23.010008573532104
 * Prec@1 92.350 Prec@5 99.630 Loss 0.2766
Avg Loading time: 0.0392 seconds
Avg Batch time: 0.0585 seconds

Best acc: 92.380
--------------------------------------------------------------------------------
Test time: 5.279374361038208

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.028)	BT: 0.046 (0.066)	Loss 0.0030 (0.0032)	Prec@1 100.000 (99.970)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.015)	BT: 0.044 (0.059)	Loss 0.0014 (0.0032)	Prec@1 100.000 (99.975)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.012)	BT: 0.040 (0.059)	Loss 0.0045 (0.0033)	Prec@1 100.000 (99.983)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.049 (0.057)	Loss 0.0013 (0.0032)	Prec@1 100.000 (99.985)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.038 (0.056)	Loss 0.0037 (0.0031)	Prec@1 100.000 (99.988)	
Total train loss: 0.0031
Avg Loading time: 0.0078 seconds
Avg Batch time: 0.0559 seconds

Train time: 22.067774534225464
 * Prec@1 92.500 Prec@5 99.620 Loss 0.2715
Avg Loading time: 0.0410 seconds
Avg Batch time: 0.0580 seconds

Best acc: 92.500
--------------------------------------------------------------------------------
Test time: 5.6015541553497314

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.163 (0.020)	BT: 0.237 (0.072)	Loss 0.0103 (0.0035)	Prec@1 100.000 (99.970)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.011)	BT: 0.056 (0.062)	Loss 0.0017 (0.0032)	Prec@1 100.000 (99.980)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.050 (0.059)	Loss 0.0020 (0.0031)	Prec@1 100.000 (99.987)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.040 (0.058)	Loss 0.0012 (0.0030)	Prec@1 100.000 (99.985)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.040 (0.057)	Loss 0.0024 (0.0029)	Prec@1 100.000 (99.988)	
Total train loss: 0.0029
Avg Loading time: 0.0058 seconds
Avg Batch time: 0.0567 seconds

Train time: 22.393935680389404
 * Prec@1 92.580 Prec@5 99.650 Loss 0.2705
Avg Loading time: 0.0409 seconds
Avg Batch time: 0.0577 seconds

Best acc: 92.580
--------------------------------------------------------------------------------
Test time: 5.6035685539245605

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.047 (0.065)	Loss 0.0029 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.018 (0.056)	Loss 0.0028 (0.0027)	Prec@1 100.000 (99.990)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.057 (0.053)	Loss 0.0024 (0.0027)	Prec@1 100.000 (99.987)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.005 (0.008)	BT: 0.059 (0.055)	Loss 0.0037 (0.0027)	Prec@1 100.000 (99.985)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.046 (0.056)	Loss 0.0015 (0.0027)	Prec@1 100.000 (99.988)	
Total train loss: 0.0027
Avg Loading time: 0.0080 seconds
Avg Batch time: 0.0555 seconds

Train time: 21.96848726272583
 * Prec@1 92.560 Prec@5 99.620 Loss 0.2715
Avg Loading time: 0.0446 seconds
Avg Batch time: 0.0612 seconds

Best acc: 92.580
--------------------------------------------------------------------------------
Test time: 5.495706796646118

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.063 (0.069)	Loss 0.0014 (0.0026)	Prec@1 100.000 (99.980)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.016)	BT: 0.043 (0.066)	Loss 0.0022 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.050 (0.064)	Loss 0.0026 (0.0024)	Prec@1 100.000 (99.987)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.011)	BT: 0.041 (0.061)	Loss 0.0031 (0.0024)	Prec@1 100.000 (99.987)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.012)	BT: 0.042 (0.060)	Loss 0.0014 (0.0024)	Prec@1 100.000 (99.990)	
Total train loss: 0.0024
Avg Loading time: 0.0121 seconds
Avg Batch time: 0.0597 seconds

Train time: 23.55965518951416
 * Prec@1 92.510 Prec@5 99.630 Loss 0.2683
Avg Loading time: 0.0426 seconds
Avg Batch time: 0.0606 seconds

Best acc: 92.580
--------------------------------------------------------------------------------
Test time: 5.447903156280518

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.040 (0.071)	Loss 0.0045 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.016)	BT: 0.053 (0.066)	Loss 0.0015 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.067 (0.016)	BT: 0.105 (0.066)	Loss 0.0010 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.039 (0.064)	Loss 0.0022 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.011)	BT: 0.042 (0.060)	Loss 0.0009 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0114 seconds
Avg Batch time: 0.0601 seconds

Train time: 23.69668412208557
 * Prec@1 92.660 Prec@5 99.600 Loss 0.2676
Avg Loading time: 0.0434 seconds
Avg Batch time: 0.0584 seconds

Best acc: 92.660
--------------------------------------------------------------------------------
Test time: 5.659212112426758

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.016)	BT: 0.042 (0.064)	Loss 0.0012 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.042 (0.053)	Loss 0.0009 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.053 (0.055)	Loss 0.0008 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.010)	BT: 0.040 (0.057)	Loss 0.0010 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.011)	BT: 0.044 (0.058)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.998)	
Total train loss: 0.0021
Avg Loading time: 0.0112 seconds
Avg Batch time: 0.0579 seconds

Train time: 22.866018772125244
 * Prec@1 92.660 Prec@5 99.620 Loss 0.2664
Avg Loading time: 0.0532 seconds
Avg Batch time: 0.0654 seconds

Best acc: 92.660
--------------------------------------------------------------------------------
Test time: 5.806401252746582

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.036)	BT: 0.048 (0.073)	Loss 0.0009 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.061 (0.066)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.017)	BT: 0.043 (0.062)	Loss 0.0023 (0.0021)	Prec@1 100.000 (99.993)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.016)	BT: 0.046 (0.062)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.117 (0.017)	BT: 0.155 (0.063)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0167 seconds
Avg Batch time: 0.0631 seconds

Train time: 24.89663076400757
 * Prec@1 92.550 Prec@5 99.660 Loss 0.2695
Avg Loading time: 0.0400 seconds
Avg Batch time: 0.0607 seconds

Best acc: 92.660
--------------------------------------------------------------------------------
Test time: 5.467601776123047

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.026)	BT: 0.063 (0.076)	Loss 0.0023 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.021)	BT: 0.069 (0.072)	Loss 0.0013 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.017)	BT: 0.038 (0.065)	Loss 0.0014 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.040 (0.060)	Loss 0.0007 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.015)	BT: 0.040 (0.061)	Loss 0.0214 (0.0019)	Prec@1 98.438 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0150 seconds
Avg Batch time: 0.0611 seconds

Train time: 24.136298656463623
 * Prec@1 92.640 Prec@5 99.590 Loss 0.2683
Avg Loading time: 0.0348 seconds
Avg Batch time: 0.0518 seconds

Best acc: 92.660
--------------------------------------------------------------------------------
Test time: 4.8488850593566895

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.019)	BT: 0.050 (0.065)	Loss 0.0017 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.014)	BT: 0.067 (0.062)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.001 (0.012)	BT: 0.065 (0.061)	Loss 0.0007 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.002 (0.009)	BT: 0.057 (0.059)	Loss 0.0033 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.051 (0.059)	Loss 0.0032 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0084 seconds
Avg Batch time: 0.0588 seconds

Train time: 23.22610330581665
 * Prec@1 92.690 Prec@5 99.560 Loss 0.2683
Avg Loading time: 0.0453 seconds
Avg Batch time: 0.0619 seconds

Best acc: 92.690
--------------------------------------------------------------------------------
Test time: 5.901983261108398

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.034)	BT: 0.075 (0.080)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.020)	BT: 0.038 (0.068)	Loss 0.0046 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.020)	BT: 0.044 (0.067)	Loss 0.0008 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.018)	BT: 0.045 (0.066)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.048 (0.064)	Loss 0.0030 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0152 seconds
Avg Batch time: 0.0638 seconds

Train time: 25.15673327445984
 * Prec@1 92.690 Prec@5 99.600 Loss 0.2671
Avg Loading time: 0.0524 seconds
Avg Batch time: 0.0713 seconds

Best acc: 92.690
--------------------------------------------------------------------------------
Test time: 6.296243906021118

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.001 (0.020)	BT: 0.073 (0.071)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.011)	BT: 0.059 (0.059)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.002 (0.010)	BT: 0.050 (0.056)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.009)	BT: 0.067 (0.055)	Loss 0.0007 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.050 (0.054)	Loss 0.0022 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0073 seconds
Avg Batch time: 0.0543 seconds

Train time: 21.42513418197632
 * Prec@1 92.590 Prec@5 99.590 Loss 0.2676
Avg Loading time: 0.0274 seconds
Avg Batch time: 0.0433 seconds

Best acc: 92.690
--------------------------------------------------------------------------------
Test time: 4.067318916320801

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.142 (0.016)	BT: 0.208 (0.067)	Loss 0.0020 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.014)	BT: 0.071 (0.062)	Loss 0.0017 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.005 (0.012)	BT: 0.080 (0.061)	Loss 0.0014 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.011)	BT: 0.044 (0.061)	Loss 0.0014 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.011)	BT: 0.046 (0.061)	Loss 0.0058 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0108 seconds
Avg Batch time: 0.0608 seconds

Train time: 24.02463674545288
 * Prec@1 92.690 Prec@5 99.620 Loss 0.2644
Avg Loading time: 0.0383 seconds
Avg Batch time: 0.0587 seconds

Best acc: 92.690
--------------------------------------------------------------------------------
Test time: 5.294104337692261

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.042 (0.068)	Loss 0.0012 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.056 (0.061)	Loss 0.0010 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.072 (0.059)	Loss 0.0011 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.040 (0.058)	Loss 0.0010 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.038 (0.058)	Loss 0.0010 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.0063 seconds
Avg Batch time: 0.0577 seconds

Train time: 22.7731351852417
 * Prec@1 92.700 Prec@5 99.570 Loss 0.2693
Avg Loading time: 0.0444 seconds
Avg Batch time: 0.0633 seconds

Best acc: 92.700
--------------------------------------------------------------------------------
Test time: 6.071054697036743

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.018)	BT: 0.044 (0.071)	Loss 0.0010 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.009)	BT: 0.039 (0.060)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.049 (0.057)	Loss 0.0040 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.007 (0.007)	BT: 0.062 (0.056)	Loss 0.0016 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.039 (0.054)	Loss 0.0029 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0053 seconds
Avg Batch time: 0.0539 seconds

Train time: 21.239809274673462
 * Prec@1 92.780 Prec@5 99.620 Loss 0.2651
Avg Loading time: 0.0380 seconds
Avg Batch time: 0.0546 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 5.328940153121948

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.025)	BT: 0.050 (0.069)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.017)	BT: 0.038 (0.064)	Loss 0.0011 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.011)	BT: 0.048 (0.060)	Loss 0.0024 (0.0017)	Prec@1 100.000 (99.997)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.010)	BT: 0.063 (0.059)	Loss 0.0017 (0.0017)	Prec@1 100.000 (99.997)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.009)	BT: 0.039 (0.058)	Loss 0.0012 (0.0017)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0090 seconds
Avg Batch time: 0.0583 seconds

Train time: 23.030828714370728
 * Prec@1 92.780 Prec@5 99.610 Loss 0.2666
Avg Loading time: 0.0405 seconds
Avg Batch time: 0.0586 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 5.30250883102417

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.019)	BT: 0.046 (0.072)	Loss 0.0014 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.012)	BT: 0.051 (0.063)	Loss 0.0017 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.072 (0.010)	BT: 0.092 (0.059)	Loss 0.0020 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.027 (0.016)	BT: 0.069 (0.060)	Loss 0.0042 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.025)	BT: 0.016 (0.066)	Loss 0.0042 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0251 seconds
Avg Batch time: 0.0656 seconds

Train time: 25.897830724716187
 * Prec@1 92.730 Prec@5 99.640 Loss 0.2644
Avg Loading time: 0.0868 seconds
Avg Batch time: 0.0990 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 8.478545427322388

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.016)	BT: 0.042 (0.062)	Loss 0.0018 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.010)	BT: 0.037 (0.056)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.054 (0.055)	Loss 0.0021 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.058 (0.052)	Loss 0.0008 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.043 (0.053)	Loss 0.0057 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0068 seconds
Avg Batch time: 0.0531 seconds

Train time: 20.953011512756348
 * Prec@1 92.710 Prec@5 99.610 Loss 0.2673
Avg Loading time: 0.0448 seconds
Avg Batch time: 0.0615 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 5.542243480682373

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.019)	BT: 0.041 (0.071)	Loss 0.0008 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.010)	BT: 0.042 (0.061)	Loss 0.0042 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.086 (0.014)	BT: 0.126 (0.063)	Loss 0.0009 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.039 (0.062)	Loss 0.0032 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.026 (0.060)	Loss 0.0018 (0.0018)	Prec@1 100.000 (99.998)	
Total train loss: 0.0018
Avg Loading time: 0.0148 seconds
Avg Batch time: 0.0595 seconds

Train time: 23.464648246765137
 * Prec@1 92.760 Prec@5 99.610 Loss 0.2661
Avg Loading time: 0.0443 seconds
Avg Batch time: 0.0569 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 5.153617858886719

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.039 (0.071)	Loss 0.0014 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.001 (0.017)	BT: 0.056 (0.065)	Loss 0.0014 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.043 (0.063)	Loss 0.0021 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.013)	BT: 0.050 (0.062)	Loss 0.0030 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.044 (0.060)	Loss 0.0005 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0115 seconds
Avg Batch time: 0.0602 seconds

Train time: 23.77234172821045
 * Prec@1 92.620 Prec@5 99.590 Loss 0.2690
Avg Loading time: 0.0274 seconds
Avg Batch time: 0.0436 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 4.09613037109375

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.019)	BT: 0.047 (0.068)	Loss 0.0011 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.012 (0.014)	BT: 0.039 (0.061)	Loss 0.0008 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.013)	BT: 0.037 (0.053)	Loss 0.0012 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.047 (0.053)	Loss 0.0013 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.042 (0.053)	Loss 0.0008 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0090 seconds
Avg Batch time: 0.0529 seconds

Train time: 20.88614797592163
 * Prec@1 92.670 Prec@5 99.620 Loss 0.2683
Avg Loading time: 0.0547 seconds
Avg Batch time: 0.0720 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 6.329852104187012

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.042 (0.072)	Loss 0.0007 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.049 (0.065)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.010)	BT: 0.051 (0.061)	Loss 0.0010 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.055 (0.060)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.023 (0.058)	Loss 0.0033 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0089 seconds
Avg Batch time: 0.0574 seconds

Train time: 22.704851627349854
 * Prec@1 92.580 Prec@5 99.610 Loss 0.2698
Avg Loading time: 0.0354 seconds
Avg Batch time: 0.0530 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 4.852683782577515

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.040 (0.070)	Loss 0.0006 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.040 (0.060)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.010)	BT: 0.040 (0.058)	Loss 0.0010 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.010)	BT: 0.048 (0.059)	Loss 0.0008 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.010)	BT: 0.038 (0.058)	Loss 0.0010 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0100 seconds
Avg Batch time: 0.0583 seconds

Train time: 23.030784130096436
 * Prec@1 92.660 Prec@5 99.600 Loss 0.2673
Avg Loading time: 0.0362 seconds
Avg Batch time: 0.0524 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 4.773995637893677

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.033)	BT: 0.038 (0.068)	Loss 0.0021 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.024 (0.022)	BT: 0.075 (0.061)	Loss 0.0013 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.046 (0.056)	Loss 0.0023 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.014)	BT: 0.042 (0.056)	Loss 0.0017 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.013)	BT: 0.040 (0.057)	Loss 0.0018 (0.0018)	Prec@1 100.000 (99.996)	
Total train loss: 0.0018
Avg Loading time: 0.0129 seconds
Avg Batch time: 0.0567 seconds

Train time: 22.405604362487793
 * Prec@1 92.630 Prec@5 99.610 Loss 0.2649
Avg Loading time: 0.0466 seconds
Avg Batch time: 0.0662 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 5.868650436401367

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.019)	BT: 0.053 (0.071)	Loss 0.0008 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.038 (0.063)	Loss 0.0025 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.022 (0.061)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.090 (0.016)	BT: 0.129 (0.060)	Loss 0.0022 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.014)	BT: 0.039 (0.060)	Loss 0.0027 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0143 seconds
Avg Batch time: 0.0597 seconds

Train time: 23.57553458213806
 * Prec@1 92.600 Prec@5 99.600 Loss 0.2693
Avg Loading time: 0.0441 seconds
Avg Batch time: 0.0652 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 5.799604177474976

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.018)	BT: 0.042 (0.068)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.018 (0.061)	Loss 0.0018 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.040 (0.059)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.047 (0.058)	Loss 0.0015 (0.0019)	Prec@1 100.000 (99.992)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.040 (0.058)	Loss 0.0035 (0.0020)	Prec@1 100.000 (99.992)	
Total train loss: 0.0020
Avg Loading time: 0.0082 seconds
Avg Batch time: 0.0575 seconds

Train time: 22.6754469871521
 * Prec@1 92.640 Prec@5 99.630 Loss 0.2664
Avg Loading time: 0.0398 seconds
Avg Batch time: 0.0566 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 5.162978410720825

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.021)	BT: 0.080 (0.073)	Loss 0.0024 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.040 (0.061)	Loss 0.0029 (0.0019)	Prec@1 100.000 (99.985)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.040 (0.009)	BT: 0.086 (0.058)	Loss 0.0011 (0.0018)	Prec@1 100.000 (99.990)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.065 (0.058)	Loss 0.0017 (0.0018)	Prec@1 100.000 (99.990)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.040 (0.058)	Loss 0.0017 (0.0018)	Prec@1 100.000 (99.992)	
Total train loss: 0.0018
Avg Loading time: 0.0107 seconds
Avg Batch time: 0.0575 seconds

Train time: 22.690550327301025
 * Prec@1 92.750 Prec@5 99.600 Loss 0.2659
Avg Loading time: 0.0446 seconds
Avg Batch time: 0.0636 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 5.710494518280029

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.050 (0.072)	Loss 0.0008 (0.0023)	Prec@1 100.000 (99.980)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.076 (0.064)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.052 (0.061)	Loss 0.0041 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.001 (0.008)	BT: 0.064 (0.061)	Loss 0.0030 (0.0019)	Prec@1 100.000 (99.992)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.040 (0.061)	Loss 0.0006 (0.0019)	Prec@1 100.000 (99.994)	
Total train loss: 0.0019
Avg Loading time: 0.0088 seconds
Avg Batch time: 0.0607 seconds

Train time: 23.953985929489136
 * Prec@1 92.650 Prec@5 99.620 Loss 0.2661
Avg Loading time: 0.0405 seconds
Avg Batch time: 0.0580 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 5.238642454147339

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.019)	BT: 0.040 (0.071)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.010)	BT: 0.074 (0.062)	Loss 0.0038 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.001 (0.009)	BT: 0.080 (0.060)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.001 (0.009)	BT: 0.059 (0.060)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.040 (0.057)	Loss 0.0010 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0073 seconds
Avg Batch time: 0.0572 seconds

Train time: 22.534487009048462
 * Prec@1 92.740 Prec@5 99.650 Loss 0.2666
Avg Loading time: 0.0421 seconds
Avg Batch time: 0.0600 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 5.409868955612183

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.017)	BT: 0.062 (0.067)	Loss 0.0013 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.044 (0.054)	Loss 0.0010 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.010 (0.011)	BT: 0.034 (0.051)	Loss 0.0009 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.013)	BT: 0.041 (0.055)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.012)	BT: 0.059 (0.056)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0122 seconds
Avg Batch time: 0.0556 seconds

Train time: 21.995875120162964
 * Prec@1 92.720 Prec@5 99.620 Loss 0.2671
Avg Loading time: 0.0453 seconds
Avg Batch time: 0.0624 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 5.578264951705933

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.018)	BT: 0.054 (0.068)	Loss 0.0014 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.019)	BT: 0.046 (0.064)	Loss 0.0009 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.020)	BT: 0.036 (0.062)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.020)	BT: 0.039 (0.060)	Loss 0.0034 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.019)	BT: 0.037 (0.061)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0190 seconds
Avg Batch time: 0.0609 seconds

Train time: 24.038453340530396
 * Prec@1 92.680 Prec@5 99.620 Loss 0.2627
Avg Loading time: 0.0394 seconds
Avg Batch time: 0.0592 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 5.372909784317017

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.033)	BT: 0.056 (0.080)	Loss 0.0017 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.024)	BT: 0.040 (0.073)	Loss 0.0030 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.020)	BT: 0.038 (0.068)	Loss 0.0010 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.015)	BT: 0.046 (0.062)	Loss 0.0016 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.015)	BT: 0.063 (0.062)	Loss 0.0026 (0.0019)	Prec@1 100.000 (99.994)	
Total train loss: 0.0019
Avg Loading time: 0.0148 seconds
Avg Batch time: 0.0619 seconds

Train time: 24.427573442459106
 * Prec@1 92.690 Prec@5 99.580 Loss 0.2690
Avg Loading time: 0.0352 seconds
Avg Batch time: 0.0523 seconds

Best acc: 92.780
--------------------------------------------------------------------------------
Test time: 4.746568202972412

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.013)	BT: 0.065 (0.060)	Loss 0.0017 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.066 (0.060)	Loss 0.0027 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.012)	BT: 0.046 (0.061)	Loss 0.0018 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.039 (0.061)	Loss 0.0043 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.044 (0.059)	Loss 0.0018 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0095 seconds
Avg Batch time: 0.0593 seconds

Train time: 23.402064085006714
 * Prec@1 92.790 Prec@5 99.650 Loss 0.2659
Avg Loading time: 0.0437 seconds
Avg Batch time: 0.0631 seconds

Best acc: 92.790
--------------------------------------------------------------------------------
Test time: 6.011224985122681

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.016)	BT: 0.059 (0.069)	Loss 0.0034 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.057 (0.062)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.063 (0.062)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.987)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.012)	BT: 0.041 (0.061)	Loss 0.0024 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.014)	BT: 0.042 (0.062)	Loss 0.0017 (0.0020)	Prec@1 100.000 (99.992)	
Total train loss: 0.0020
Avg Loading time: 0.0135 seconds
Avg Batch time: 0.0622 seconds

Train time: 24.517158031463623
 * Prec@1 92.710 Prec@5 99.620 Loss 0.2649
Avg Loading time: 0.0426 seconds
Avg Batch time: 0.0599 seconds

Best acc: 92.790
--------------------------------------------------------------------------------
Test time: 5.37968111038208

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.026)	BT: 0.048 (0.073)	Loss 0.0032 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.016)	BT: 0.040 (0.064)	Loss 0.0014 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.055 (0.057)	Loss 0.0015 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.020 (0.056)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.040 (0.056)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0095 seconds
Avg Batch time: 0.0561 seconds

Train time: 22.1575345993042
 * Prec@1 92.710 Prec@5 99.610 Loss 0.2673
Avg Loading time: 0.0302 seconds
Avg Batch time: 0.0435 seconds

Best acc: 92.790
--------------------------------------------------------------------------------
Test time: 4.018000841140747

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.021)	BT: 0.045 (0.075)	Loss 0.0017 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.013)	BT: 0.062 (0.065)	Loss 0.0031 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.038 (0.062)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.085 (0.010)	BT: 0.128 (0.060)	Loss 0.0016 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.038 (0.058)	Loss 0.0018 (0.0020)	Prec@1 100.000 (99.992)	
Total train loss: 0.0020
Avg Loading time: 0.0085 seconds
Avg Batch time: 0.0578 seconds

Train time: 22.83256459236145
 * Prec@1 92.600 Prec@5 99.620 Loss 0.2661
Avg Loading time: 0.0364 seconds
Avg Batch time: 0.0563 seconds

Best acc: 92.790
--------------------------------------------------------------------------------
Test time: 5.132790565490723

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.019)	BT: 0.047 (0.071)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.056 (0.063)	Loss 0.0018 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.057 (0.063)	Loss 0.0038 (0.0020)	Prec@1 100.000 (99.987)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.072 (0.061)	Loss 0.0023 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.038 (0.059)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.992)	
Total train loss: 0.0019
Avg Loading time: 0.0065 seconds
Avg Batch time: 0.0590 seconds

Train time: 23.272221565246582
 * Prec@1 92.630 Prec@5 99.610 Loss 0.2661
Avg Loading time: 0.0429 seconds
Avg Batch time: 0.0632 seconds

Best acc: 92.790
--------------------------------------------------------------------------------
Test time: 5.642343282699585

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.021)	BT: 0.061 (0.069)	Loss 0.0009 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.046 (0.060)	Loss 0.0017 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.048 (0.056)	Loss 0.0045 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.050 (0.056)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.039 (0.055)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.0056 seconds
Avg Batch time: 0.0548 seconds

Train time: 21.65649676322937
 * Prec@1 92.530 Prec@5 99.620 Loss 0.2695
Avg Loading time: 0.0330 seconds
Avg Batch time: 0.0456 seconds

Best acc: 92.790
--------------------------------------------------------------------------------
Test time: 4.197027683258057

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.019)	BT: 0.080 (0.070)	Loss 0.0025 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.012)	BT: 0.049 (0.063)	Loss 0.0010 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.043 (0.060)	Loss 0.0052 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.049 (0.058)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.038 (0.058)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.0076 seconds
Avg Batch time: 0.0578 seconds

Train time: 22.8094162940979
 * Prec@1 92.700 Prec@5 99.610 Loss 0.2659
Avg Loading time: 0.0407 seconds
Avg Batch time: 0.0613 seconds

Best acc: 92.790
--------------------------------------------------------------------------------
Test time: 5.4678955078125


      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 15
Savedir:  ../pretrained_models/frozen/x64-8b/rram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/train/relu15
Test path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/test/relu15
ResNet18(
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 10.110 Prec@5 49.260 Loss 2.3262
Avg Loading time: 0.0566 seconds
Avg Batch time: 0.0833 seconds

Pre-trained Prec@1 with 15 layers frozen: 10.109999656677246 	 Loss: 2.326171875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.003 (0.389)	BT: 0.028 (0.404)	Loss 0.4307 (0.7374)	Prec@1 85.156 (76.653)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (0.300)	BT: 0.020 (0.319)	Loss 0.4893 (0.6119)	Prec@1 83.594 (80.233)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (0.270)	BT: 0.013 (0.292)	Loss 0.4773 (0.5551)	Prec@1 84.375 (81.804)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (0.254)	BT: 0.022 (0.274)	Loss 0.4641 (0.5215)	Prec@1 82.812 (82.792)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (0.243)	BT: 0.029 (0.265)	Loss 0.3423 (0.4978)	Prec@1 86.719 (83.496)	
Total train loss: 0.4976
Avg Loading time: 0.2427 seconds
Avg Batch time: 0.2641 seconds

Train time: 103.49018716812134
 * Prec@1 86.600 Prec@5 99.560 Loss 0.3882
Avg Loading time: 0.0477 seconds
Avg Batch time: 0.0592 seconds

Best acc: 86.600
--------------------------------------------------------------------------------
Test time: 5.364243984222412

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.044)	BT: 0.036 (0.064)	Loss 0.2881 (0.2717)	Prec@1 93.750 (91.056)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.034)	BT: 0.040 (0.059)	Loss 0.2544 (0.2698)	Prec@1 89.844 (90.981)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.030)	BT: 0.024 (0.057)	Loss 0.2225 (0.2716)	Prec@1 90.625 (90.799)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.028 (0.056)	Loss 0.3132 (0.2732)	Prec@1 90.625 (90.728)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.025)	BT: 0.034 (0.054)	Loss 0.2515 (0.2767)	Prec@1 92.969 (90.569)	
Total train loss: 0.2769
Avg Loading time: 0.0254 seconds
Avg Batch time: 0.0543 seconds

Train time: 21.469151973724365
 * Prec@1 87.300 Prec@5 99.680 Loss 0.3650
Avg Loading time: 0.0472 seconds
Avg Batch time: 0.0588 seconds

Best acc: 87.300
--------------------------------------------------------------------------------
Test time: 5.340484619140625

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.027)	BT: 0.028 (0.059)	Loss 0.2361 (0.1592)	Prec@1 92.969 (94.862)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.021)	BT: 0.032 (0.053)	Loss 0.1171 (0.1640)	Prec@1 96.094 (94.616)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (0.025)	BT: 0.017 (0.053)	Loss 0.2008 (0.1708)	Prec@1 92.969 (94.308)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.031 (0.052)	Loss 0.2037 (0.1743)	Prec@1 91.406 (94.166)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.020)	BT: 0.023 (0.049)	Loss 0.2181 (0.1797)	Prec@1 93.750 (93.968)	
Total train loss: 0.1797
Avg Loading time: 0.0195 seconds
Avg Batch time: 0.0484 seconds

Train time: 19.156175136566162
 * Prec@1 87.810 Prec@5 99.610 Loss 0.3650
Avg Loading time: 0.0389 seconds
Avg Batch time: 0.0488 seconds

Best acc: 87.810
--------------------------------------------------------------------------------
Test time: 4.488799333572388

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.028 (0.052)	Loss 0.1230 (0.1066)	Prec@1 96.875 (96.524)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.020)	BT: 0.023 (0.050)	Loss 0.0536 (0.1071)	Prec@1 99.219 (96.439)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.023 (0.043)	Loss 0.0989 (0.1138)	Prec@1 97.656 (96.117)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.012)	BT: 0.025 (0.040)	Loss 0.0738 (0.1163)	Prec@1 97.656 (96.076)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.012)	BT: 0.025 (0.040)	Loss 0.1731 (0.1220)	Prec@1 94.531 (95.849)	
Total train loss: 0.1220
Avg Loading time: 0.0116 seconds
Avg Batch time: 0.0398 seconds

Train time: 15.756312370300293
 * Prec@1 87.520 Prec@5 99.410 Loss 0.3865
Avg Loading time: 0.0442 seconds
Avg Batch time: 0.0561 seconds

Best acc: 87.810
--------------------------------------------------------------------------------
Test time: 4.909367322921753

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.035)	BT: 0.023 (0.063)	Loss 0.0922 (0.0673)	Prec@1 96.875 (97.997)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.032)	BT: 0.026 (0.061)	Loss 0.0646 (0.0689)	Prec@1 97.656 (97.897)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.025)	BT: 0.041 (0.055)	Loss 0.1219 (0.0715)	Prec@1 97.656 (97.837)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.030 (0.053)	Loss 0.1228 (0.0773)	Prec@1 94.531 (97.599)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.021)	BT: 0.021 (0.052)	Loss 0.1567 (0.0833)	Prec@1 96.094 (97.368)	
Total train loss: 0.0834
Avg Loading time: 0.0213 seconds
Avg Batch time: 0.0519 seconds

Train time: 20.542131185531616
 * Prec@1 88.090 Prec@5 99.480 Loss 0.3914
Avg Loading time: 0.0341 seconds
Avg Batch time: 0.0476 seconds

Best acc: 88.090
--------------------------------------------------------------------------------
Test time: 4.432270288467407

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.038)	BT: 0.025 (0.058)	Loss 0.0488 (0.0599)	Prec@1 98.438 (98.337)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.027)	BT: 0.032 (0.054)	Loss 0.1115 (0.0586)	Prec@1 97.656 (98.262)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.048 (0.025)	BT: 0.067 (0.051)	Loss 0.0419 (0.0615)	Prec@1 99.219 (98.067)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.026)	BT: 0.040 (0.052)	Loss 0.0568 (0.0616)	Prec@1 98.438 (98.067)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.025)	BT: 0.031 (0.052)	Loss 0.0609 (0.0641)	Prec@1 97.656 (97.981)	
Total train loss: 0.0642
Avg Loading time: 0.0245 seconds
Avg Batch time: 0.0517 seconds

Train time: 20.433412790298462
 * Prec@1 88.630 Prec@5 99.330 Loss 0.3892
Avg Loading time: 0.0581 seconds
Avg Batch time: 0.0686 seconds

Best acc: 88.630
--------------------------------------------------------------------------------
Test time: 6.118600606918335

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.017)	BT: 0.023 (0.048)	Loss 0.0375 (0.0451)	Prec@1 99.219 (98.668)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.015)	BT: 0.023 (0.039)	Loss 0.0193 (0.0418)	Prec@1 99.219 (98.803)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.001 (0.017)	BT: 0.030 (0.042)	Loss 0.0267 (0.0407)	Prec@1 99.219 (98.821)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.016)	BT: 0.031 (0.043)	Loss 0.0597 (0.0410)	Prec@1 98.438 (98.816)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.016)	BT: 0.029 (0.043)	Loss 0.0340 (0.0419)	Prec@1 99.219 (98.776)	
Total train loss: 0.0419
Avg Loading time: 0.0157 seconds
Avg Batch time: 0.0426 seconds

Train time: 16.893165111541748
 * Prec@1 88.890 Prec@5 99.280 Loss 0.3855
Avg Loading time: 0.0212 seconds
Avg Batch time: 0.0308 seconds

Best acc: 88.890
--------------------------------------------------------------------------------
Test time: 3.077393054962158

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.023 (0.058)	Loss 0.0363 (0.0316)	Prec@1 98.438 (99.028)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.027)	BT: 0.041 (0.057)	Loss 0.0652 (0.0301)	Prec@1 98.438 (99.139)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.025)	BT: 0.023 (0.055)	Loss 0.0547 (0.0318)	Prec@1 98.438 (99.089)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.028 (0.053)	Loss 0.0512 (0.0334)	Prec@1 99.219 (99.016)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.023 (0.050)	Loss 0.0286 (0.0341)	Prec@1 99.219 (99.008)	
Total train loss: 0.0341
Avg Loading time: 0.0217 seconds
Avg Batch time: 0.0504 seconds

Train time: 19.94779658317566
 * Prec@1 89.290 Prec@5 99.400 Loss 0.3909
Avg Loading time: 0.0420 seconds
Avg Batch time: 0.0538 seconds

Best acc: 89.290
--------------------------------------------------------------------------------
Test time: 4.959015846252441

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.040)	BT: 0.023 (0.069)	Loss 0.0122 (0.0246)	Prec@1 100.000 (99.399)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.029)	BT: 0.036 (0.059)	Loss 0.0311 (0.0254)	Prec@1 99.219 (99.354)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.023 (0.054)	Loss 0.0079 (0.0258)	Prec@1 100.000 (99.342)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.021)	BT: 0.023 (0.052)	Loss 0.0205 (0.0260)	Prec@1 100.000 (99.324)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.020)	BT: 0.042 (0.051)	Loss 0.0517 (0.0274)	Prec@1 97.656 (99.249)	
Total train loss: 0.0274
Avg Loading time: 0.0204 seconds
Avg Batch time: 0.0507 seconds

Train time: 20.0591082572937
 * Prec@1 88.330 Prec@5 99.270 Loss 0.4243
Avg Loading time: 0.0515 seconds
Avg Batch time: 0.0625 seconds

Best acc: 89.290
--------------------------------------------------------------------------------
Test time: 5.43752384185791

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.033)	BT: 0.025 (0.059)	Loss 0.0282 (0.0253)	Prec@1 98.438 (99.379)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.057 (0.053)	Loss 0.0246 (0.0270)	Prec@1 99.219 (99.289)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.049 (0.023)	BT: 0.073 (0.051)	Loss 0.0235 (0.0277)	Prec@1 99.219 (99.249)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.018)	BT: 0.023 (0.047)	Loss 0.0133 (0.0275)	Prec@1 100.000 (99.254)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.017)	BT: 0.021 (0.045)	Loss 0.0117 (0.0281)	Prec@1 100.000 (99.235)	
Total train loss: 0.0281
Avg Loading time: 0.0172 seconds
Avg Batch time: 0.0450 seconds

Train time: 17.80768871307373
 * Prec@1 88.950 Prec@5 99.210 Loss 0.4065
Avg Loading time: 0.0447 seconds
Avg Batch time: 0.0566 seconds

Best acc: 89.290
--------------------------------------------------------------------------------
Test time: 4.991256475448608

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.023)	BT: 0.023 (0.051)	Loss 0.0275 (0.0149)	Prec@1 98.438 (99.710)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.021 (0.040)	Loss 0.0135 (0.0127)	Prec@1 99.219 (99.785)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.021 (0.013)	BT: 0.044 (0.039)	Loss 0.0098 (0.0113)	Prec@1 100.000 (99.826)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.198 (0.014)	BT: 0.209 (0.041)	Loss 0.0026 (0.0105)	Prec@1 100.000 (99.847)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.015)	BT: 0.033 (0.042)	Loss 0.0059 (0.0098)	Prec@1 100.000 (99.864)	
Total train loss: 0.0098
Avg Loading time: 0.0154 seconds
Avg Batch time: 0.0419 seconds

Train time: 16.623412132263184
 * Prec@1 90.210 Prec@5 99.400 Loss 0.3435
Avg Loading time: 0.0416 seconds
Avg Batch time: 0.0518 seconds

Best acc: 90.210
--------------------------------------------------------------------------------
Test time: 4.8222620487213135

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.028)	BT: 0.027 (0.058)	Loss 0.0070 (0.0053)	Prec@1 100.000 (99.960)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.113 (0.030)	BT: 0.134 (0.059)	Loss 0.0026 (0.0054)	Prec@1 100.000 (99.955)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.026)	BT: 0.031 (0.055)	Loss 0.0055 (0.0053)	Prec@1 100.000 (99.967)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.019 (0.052)	Loss 0.0074 (0.0052)	Prec@1 100.000 (99.967)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.014 (0.051)	Loss 0.0045 (0.0052)	Prec@1 100.000 (99.964)	
Total train loss: 0.0052
Avg Loading time: 0.0250 seconds
Avg Batch time: 0.0508 seconds

Train time: 20.094597101211548
 * Prec@1 90.600 Prec@5 99.430 Loss 0.3362
Avg Loading time: 0.0486 seconds
Avg Batch time: 0.0597 seconds

Best acc: 90.600
--------------------------------------------------------------------------------
Test time: 5.66412878036499

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.036)	BT: 0.030 (0.067)	Loss 0.0043 (0.0038)	Prec@1 100.000 (99.980)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.029)	BT: 0.033 (0.061)	Loss 0.0044 (0.0041)	Prec@1 100.000 (99.975)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.039 (0.025)	BT: 0.076 (0.056)	Loss 0.0134 (0.0043)	Prec@1 99.219 (99.977)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.027)	BT: 0.027 (0.056)	Loss 0.0018 (0.0042)	Prec@1 100.000 (99.977)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.026)	BT: 0.030 (0.055)	Loss 0.0047 (0.0041)	Prec@1 100.000 (99.980)	
Total train loss: 0.0042
Avg Loading time: 0.0264 seconds
Avg Batch time: 0.0553 seconds

Train time: 21.818599224090576
 * Prec@1 90.600 Prec@5 99.440 Loss 0.3396
Avg Loading time: 0.0307 seconds
Avg Batch time: 0.0405 seconds

Best acc: 90.600
--------------------------------------------------------------------------------
Test time: 3.599252939224243

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.027)	BT: 0.023 (0.055)	Loss 0.0024 (0.0035)	Prec@1 100.000 (99.980)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.020)	BT: 0.023 (0.049)	Loss 0.0061 (0.0035)	Prec@1 100.000 (99.985)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.019)	BT: 0.014 (0.046)	Loss 0.0014 (0.0036)	Prec@1 100.000 (99.980)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.017)	BT: 0.021 (0.044)	Loss 0.0054 (0.0036)	Prec@1 100.000 (99.980)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.015)	BT: 0.023 (0.042)	Loss 0.0040 (0.0035)	Prec@1 100.000 (99.982)	
Total train loss: 0.0035
Avg Loading time: 0.0151 seconds
Avg Batch time: 0.0416 seconds

Train time: 16.454277753829956
 * Prec@1 90.550 Prec@5 99.420 Loss 0.3413
Avg Loading time: 0.0440 seconds
Avg Batch time: 0.0563 seconds

Best acc: 90.600
--------------------------------------------------------------------------------
Test time: 4.88628077507019

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.034 (0.027)	BT: 0.060 (0.057)	Loss 0.0048 (0.0031)	Prec@1 100.000 (99.980)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.026)	BT: 0.016 (0.057)	Loss 0.0012 (0.0032)	Prec@1 100.000 (99.990)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.023)	BT: 0.023 (0.054)	Loss 0.0034 (0.0033)	Prec@1 100.000 (99.990)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.040 (0.053)	Loss 0.0022 (0.0032)	Prec@1 100.000 (99.992)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.027 (0.053)	Loss 0.0038 (0.0032)	Prec@1 100.000 (99.990)	
Total train loss: 0.0032
Avg Loading time: 0.0222 seconds
Avg Batch time: 0.0527 seconds

Train time: 20.779903411865234
 * Prec@1 90.740 Prec@5 99.430 Loss 0.3403
Avg Loading time: 0.0503 seconds
Avg Batch time: 0.0610 seconds

Best acc: 90.740
--------------------------------------------------------------------------------
Test time: 5.5348474979400635

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.027)	BT: 0.028 (0.059)	Loss 0.0027 (0.0031)	Prec@1 100.000 (100.000)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.028 (0.053)	Loss 0.0039 (0.0034)	Prec@1 100.000 (99.985)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.032 (0.050)	Loss 0.0026 (0.0033)	Prec@1 100.000 (99.990)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.017 (0.049)	Loss 0.0028 (0.0032)	Prec@1 100.000 (99.992)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.034 (0.048)	Loss 0.0027 (0.0031)	Prec@1 100.000 (99.994)	
Total train loss: 0.0031
Avg Loading time: 0.0182 seconds
Avg Batch time: 0.0483 seconds

Train time: 19.135642766952515
 * Prec@1 90.890 Prec@5 99.390 Loss 0.3354
Avg Loading time: 0.0387 seconds
Avg Batch time: 0.0502 seconds

Best acc: 90.890
--------------------------------------------------------------------------------
Test time: 4.6009135246276855

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.039)	BT: 0.028 (0.069)	Loss 0.0013 (0.0027)	Prec@1 100.000 (100.000)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.023 (0.055)	Loss 0.0021 (0.0029)	Prec@1 100.000 (99.995)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.017)	BT: 0.023 (0.046)	Loss 0.0029 (0.0030)	Prec@1 100.000 (99.997)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.023 (0.046)	Loss 0.0025 (0.0029)	Prec@1 100.000 (99.997)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.023 (0.046)	Loss 0.0028 (0.0029)	Prec@1 100.000 (99.998)	
Total train loss: 0.0029
Avg Loading time: 0.0181 seconds
Avg Batch time: 0.0459 seconds

Train time: 18.118833780288696
 * Prec@1 90.830 Prec@5 99.420 Loss 0.3381
Avg Loading time: 0.0341 seconds
Avg Batch time: 0.0448 seconds

Best acc: 90.890
--------------------------------------------------------------------------------
Test time: 3.973740577697754

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.040 (0.017)	BT: 0.063 (0.040)	Loss 0.0059 (0.0027)	Prec@1 100.000 (99.990)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.038 (0.041)	Loss 0.0027 (0.0026)	Prec@1 100.000 (99.990)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.016)	BT: 0.027 (0.045)	Loss 0.0016 (0.0026)	Prec@1 100.000 (99.993)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.005 (0.019)	BT: 0.028 (0.046)	Loss 0.0020 (0.0026)	Prec@1 100.000 (99.995)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.023 (0.046)	Loss 0.0028 (0.0026)	Prec@1 100.000 (99.996)	
Total train loss: 0.0026
Avg Loading time: 0.0181 seconds
Avg Batch time: 0.0457 seconds

Train time: 18.102351665496826
 * Prec@1 90.760 Prec@5 99.400 Loss 0.3401
Avg Loading time: 0.0471 seconds
Avg Batch time: 0.0582 seconds

Best acc: 90.890
--------------------------------------------------------------------------------
Test time: 5.099769353866577

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.030)	BT: 0.027 (0.062)	Loss 0.0018 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.038 (0.057)	Loss 0.0017 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.214 (0.024)	BT: 0.248 (0.056)	Loss 0.0029 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.025 (0.053)	Loss 0.0051 (0.0024)	Prec@1 100.000 (99.997)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.031 (0.020)	BT: 0.052 (0.051)	Loss 0.0053 (0.0025)	Prec@1 100.000 (99.996)	
Total train loss: 0.0025
Avg Loading time: 0.0196 seconds
Avg Batch time: 0.0508 seconds

Train time: 20.086313486099243
 * Prec@1 90.800 Prec@5 99.400 Loss 0.3384
Avg Loading time: 0.0400 seconds
Avg Batch time: 0.0518 seconds

Best acc: 90.890
--------------------------------------------------------------------------------
Test time: 4.5624470710754395

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.031)	BT: 0.023 (0.060)	Loss 0.0031 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.002 (0.022)	BT: 0.040 (0.053)	Loss 0.0011 (0.0023)	Prec@1 100.000 (99.995)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.023)	BT: 0.025 (0.053)	Loss 0.0016 (0.0024)	Prec@1 100.000 (99.997)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.023)	BT: 0.023 (0.054)	Loss 0.0011 (0.0024)	Prec@1 100.000 (99.997)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.021)	BT: 0.031 (0.051)	Loss 0.0029 (0.0024)	Prec@1 100.000 (99.996)	
Total train loss: 0.0024
Avg Loading time: 0.0208 seconds
Avg Batch time: 0.0511 seconds

Train time: 20.220360040664673
 * Prec@1 90.880 Prec@5 99.440 Loss 0.3379
Avg Loading time: 0.0349 seconds
Avg Batch time: 0.0454 seconds

Best acc: 90.890
--------------------------------------------------------------------------------
Test time: 4.071889638900757

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.029 (0.055)	Loss 0.0015 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.023 (0.052)	Loss 0.0020 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.023 (0.044)	Loss 0.0024 (0.0023)	Prec@1 100.000 (99.997)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.012)	BT: 0.031 (0.041)	Loss 0.0028 (0.0023)	Prec@1 100.000 (99.997)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.013)	BT: 0.023 (0.041)	Loss 0.0016 (0.0023)	Prec@1 100.000 (99.998)	
Total train loss: 0.0023
Avg Loading time: 0.0130 seconds
Avg Batch time: 0.0411 seconds

Train time: 16.294394731521606
 * Prec@1 90.920 Prec@5 99.420 Loss 0.3381
Avg Loading time: 0.0428 seconds
Avg Batch time: 0.0546 seconds

Best acc: 90.920
--------------------------------------------------------------------------------
Test time: 5.023532390594482

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.023)	BT: 0.023 (0.053)	Loss 0.0012 (0.0026)	Prec@1 100.000 (99.990)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.016)	BT: 0.023 (0.047)	Loss 0.0013 (0.0026)	Prec@1 100.000 (99.990)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.110 (0.015)	BT: 0.136 (0.046)	Loss 0.0013 (0.0025)	Prec@1 100.000 (99.993)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.014)	BT: 0.033 (0.046)	Loss 0.0015 (0.0025)	Prec@1 100.000 (99.995)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.014)	BT: 0.021 (0.046)	Loss 0.0028 (0.0025)	Prec@1 100.000 (99.996)	
Total train loss: 0.0025
Avg Loading time: 0.0142 seconds
Avg Batch time: 0.0461 seconds

Train time: 18.226418495178223
 * Prec@1 90.620 Prec@5 99.410 Loss 0.3386
Avg Loading time: 0.0372 seconds
Avg Batch time: 0.0496 seconds

Best acc: 90.920
--------------------------------------------------------------------------------
Test time: 4.389062404632568

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.025)	BT: 0.018 (0.051)	Loss 0.0016 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.013 (0.027)	BT: 0.023 (0.048)	Loss 0.0017 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.030)	BT: 0.011 (0.050)	Loss 0.0020 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.030)	BT: 0.013 (0.049)	Loss 0.0015 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.029)	BT: 0.011 (0.047)	Loss 0.0023 (0.0023)	Prec@1 100.000 (100.000)	
Total train loss: 0.0023
Avg Loading time: 0.0285 seconds
Avg Batch time: 0.0471 seconds

Train time: 18.645040035247803
 * Prec@1 90.830 Prec@5 99.410 Loss 0.3347
Avg Loading time: 0.0451 seconds
Avg Batch time: 0.0529 seconds

Best acc: 90.920
--------------------------------------------------------------------------------
Test time: 4.624879598617554

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.036)	BT: 0.036 (0.053)	Loss 0.0014 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.032)	BT: 0.037 (0.048)	Loss 0.0027 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.014 (0.042)	Loss 0.0021 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.023 (0.039)	Loss 0.0024 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.012 (0.039)	Loss 0.0016 (0.0024)	Prec@1 100.000 (99.998)	
Total train loss: 0.0024
Avg Loading time: 0.0241 seconds
Avg Batch time: 0.0394 seconds

Train time: 15.63662338256836
 * Prec@1 90.830 Prec@5 99.370 Loss 0.3381
Avg Loading time: 0.0412 seconds
Avg Batch time: 0.0502 seconds

Best acc: 90.920
--------------------------------------------------------------------------------
Test time: 4.43764066696167

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.027)	BT: 0.010 (0.040)	Loss 0.0012 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.005 (0.022)	BT: 0.017 (0.034)	Loss 0.0026 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.049 (0.022)	BT: 0.062 (0.035)	Loss 0.0011 (0.0023)	Prec@1 100.000 (99.993)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.018 (0.036)	Loss 0.0021 (0.0023)	Prec@1 100.000 (99.995)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.014 (0.037)	Loss 0.0013 (0.0023)	Prec@1 100.000 (99.996)	
Total train loss: 0.0023
Avg Loading time: 0.0221 seconds
Avg Batch time: 0.0369 seconds

Train time: 14.674888372421265
 * Prec@1 90.810 Prec@5 99.400 Loss 0.3364
Avg Loading time: 0.0388 seconds
Avg Batch time: 0.0475 seconds

Best acc: 90.920
--------------------------------------------------------------------------------
Test time: 4.237399578094482

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.259 (0.038)	BT: 0.277 (0.053)	Loss 0.0052 (0.0027)	Prec@1 100.000 (99.980)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.029)	BT: 0.029 (0.046)	Loss 0.0016 (0.0025)	Prec@1 100.000 (99.985)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.002 (0.028)	BT: 0.012 (0.045)	Loss 0.0015 (0.0024)	Prec@1 100.000 (99.990)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.029)	BT: 0.012 (0.046)	Loss 0.0019 (0.0024)	Prec@1 100.000 (99.992)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.027)	BT: 0.012 (0.044)	Loss 0.0029 (0.0024)	Prec@1 100.000 (99.994)	
Total train loss: 0.0024
Avg Loading time: 0.0268 seconds
Avg Batch time: 0.0443 seconds

Train time: 17.527036428451538
 * Prec@1 90.790 Prec@5 99.370 Loss 0.3391
Avg Loading time: 0.0432 seconds
Avg Batch time: 0.0524 seconds

Best acc: 90.920
--------------------------------------------------------------------------------
Test time: 4.655165195465088

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.118)	BT: 0.010 (0.132)	Loss 0.0017 (0.0026)	Prec@1 100.000 (99.980)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.084)	BT: 0.035 (0.101)	Loss 0.0013 (0.0025)	Prec@1 100.000 (99.990)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.063)	BT: 0.022 (0.084)	Loss 0.0013 (0.0025)	Prec@1 100.000 (99.993)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.051)	BT: 0.037 (0.074)	Loss 0.0020 (0.0025)	Prec@1 100.000 (99.992)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.043)	BT: 0.020 (0.067)	Loss 0.0013 (0.0024)	Prec@1 100.000 (99.994)	
Total train loss: 0.0024
Avg Loading time: 0.0433 seconds
Avg Batch time: 0.0670 seconds

Train time: 26.399054765701294
 * Prec@1 90.810 Prec@5 99.380 Loss 0.3364
Avg Loading time: 0.0365 seconds
Avg Batch time: 0.0474 seconds

Best acc: 90.920
--------------------------------------------------------------------------------
Test time: 4.239570379257202

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.027)	BT: 0.020 (0.051)	Loss 0.0038 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.008 (0.023)	BT: 0.035 (0.048)	Loss 0.0014 (0.0024)	Prec@1 100.000 (99.995)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.131 (0.023)	BT: 0.150 (0.048)	Loss 0.0016 (0.0023)	Prec@1 100.000 (99.997)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.011 (0.019)	BT: 0.030 (0.045)	Loss 0.0060 (0.0023)	Prec@1 100.000 (99.997)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.016)	BT: 0.020 (0.041)	Loss 0.0015 (0.0023)	Prec@1 100.000 (99.996)	
Total train loss: 0.0023
Avg Loading time: 0.0164 seconds
Avg Batch time: 0.0411 seconds

Train time: 16.23462963104248
 * Prec@1 90.930 Prec@5 99.410 Loss 0.3372
Avg Loading time: 0.0371 seconds
Avg Batch time: 0.0497 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 4.62986946105957

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.038)	BT: 0.015 (0.056)	Loss 0.0037 (0.0025)	Prec@1 100.000 (99.980)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.037)	BT: 0.016 (0.053)	Loss 0.0049 (0.0024)	Prec@1 100.000 (99.990)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.121 (0.032)	BT: 0.136 (0.049)	Loss 0.0026 (0.0024)	Prec@1 100.000 (99.990)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.030)	BT: 0.018 (0.047)	Loss 0.0019 (0.0024)	Prec@1 100.000 (99.992)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.029)	BT: 0.008 (0.045)	Loss 0.0017 (0.0024)	Prec@1 100.000 (99.992)	
Total train loss: 0.0024
Avg Loading time: 0.0284 seconds
Avg Batch time: 0.0450 seconds

Train time: 17.821481227874756
 * Prec@1 90.780 Prec@5 99.380 Loss 0.3369
Avg Loading time: 0.0343 seconds
Avg Batch time: 0.0458 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 4.058186292648315

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.005 (0.037)	BT: 0.037 (0.063)	Loss 0.0013 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.028)	BT: 0.024 (0.055)	Loss 0.0026 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.028)	BT: 0.020 (0.055)	Loss 0.0016 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.025)	BT: 0.048 (0.053)	Loss 0.0052 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.023 (0.051)	Loss 0.0018 (0.0023)	Prec@1 100.000 (100.000)	
Total train loss: 0.0023
Avg Loading time: 0.0220 seconds
Avg Batch time: 0.0512 seconds

Train time: 20.25234293937683
 * Prec@1 90.810 Prec@5 99.410 Loss 0.3369
Avg Loading time: 0.0429 seconds
Avg Batch time: 0.0542 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 4.770325660705566

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.042)	BT: 0.029 (0.063)	Loss 0.0040 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.030)	BT: 0.023 (0.056)	Loss 0.0019 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.022 (0.050)	Loss 0.0014 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.038 (0.046)	Loss 0.0023 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.019)	BT: 0.023 (0.045)	Loss 0.0023 (0.0022)	Prec@1 100.000 (99.998)	
Total train loss: 0.0022
Avg Loading time: 0.0190 seconds
Avg Batch time: 0.0453 seconds

Train time: 17.90324640274048
 * Prec@1 90.880 Prec@5 99.380 Loss 0.3347
Avg Loading time: 0.0422 seconds
Avg Batch time: 0.0532 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 4.694929838180542

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.023 (0.043)	Loss 0.0017 (0.0025)	Prec@1 100.000 (100.000)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.018 (0.011)	BT: 0.046 (0.037)	Loss 0.0016 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.040 (0.042)	Loss 0.0029 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.025 (0.043)	Loss 0.0015 (0.0023)	Prec@1 100.000 (99.997)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.025 (0.043)	Loss 0.0014 (0.0023)	Prec@1 100.000 (99.998)	
Total train loss: 0.0023
Avg Loading time: 0.0168 seconds
Avg Batch time: 0.0428 seconds

Train time: 16.981096506118774
 * Prec@1 90.870 Prec@5 99.390 Loss 0.3369
Avg Loading time: 0.0344 seconds
Avg Batch time: 0.0476 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 4.245099782943726

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.022)	BT: 0.028 (0.051)	Loss 0.0034 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.035 (0.049)	Loss 0.0012 (0.0027)	Prec@1 100.000 (99.985)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.016)	BT: 0.034 (0.047)	Loss 0.0035 (0.0026)	Prec@1 100.000 (99.990)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.018)	BT: 0.031 (0.048)	Loss 0.0026 (0.0026)	Prec@1 100.000 (99.992)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.038 (0.048)	Loss 0.0015 (0.0025)	Prec@1 100.000 (99.994)	
Total train loss: 0.0025
Avg Loading time: 0.0166 seconds
Avg Batch time: 0.0475 seconds

Train time: 18.790791749954224
 * Prec@1 90.780 Prec@5 99.360 Loss 0.3384
Avg Loading time: 0.0415 seconds
Avg Batch time: 0.0531 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 4.679354190826416

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.039)	BT: 0.027 (0.059)	Loss 0.0014 (0.0026)	Prec@1 100.000 (99.990)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.028)	BT: 0.025 (0.053)	Loss 0.0013 (0.0023)	Prec@1 100.000 (99.995)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.026)	BT: 0.027 (0.053)	Loss 0.0034 (0.0024)	Prec@1 100.000 (99.993)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.023)	BT: 0.044 (0.051)	Loss 0.0015 (0.0024)	Prec@1 100.000 (99.995)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.023)	BT: 0.023 (0.050)	Loss 0.0024 (0.0024)	Prec@1 100.000 (99.994)	
Total train loss: 0.0024
Avg Loading time: 0.0225 seconds
Avg Batch time: 0.0503 seconds

Train time: 19.898709058761597
 * Prec@1 90.840 Prec@5 99.420 Loss 0.3347
Avg Loading time: 0.0353 seconds
Avg Batch time: 0.0488 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 4.302819728851318

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.017)	BT: 0.023 (0.041)	Loss 0.0015 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.040 (0.019)	BT: 0.063 (0.044)	Loss 0.0013 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.093 (0.016)	BT: 0.116 (0.043)	Loss 0.0019 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.009 (0.041)	Loss 0.0020 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.015)	BT: 0.021 (0.040)	Loss 0.0031 (0.0023)	Prec@1 100.000 (100.000)	
Total train loss: 0.0023
Avg Loading time: 0.0150 seconds
Avg Batch time: 0.0395 seconds

Train time: 15.59015440940857
 * Prec@1 90.760 Prec@5 99.390 Loss 0.3398
Avg Loading time: 0.0185 seconds
Avg Batch time: 0.0272 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 2.532897472381592

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.027 (0.032)	Loss 0.0014 (0.0028)	Prec@1 100.000 (99.970)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.023 (0.028)	Loss 0.0024 (0.0026)	Prec@1 100.000 (99.985)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.010 (0.026)	Loss 0.0012 (0.0024)	Prec@1 100.000 (99.990)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.026 (0.025)	Loss 0.0025 (0.0024)	Prec@1 100.000 (99.992)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.023 (0.025)	Loss 0.0019 (0.0024)	Prec@1 100.000 (99.994)	
Total train loss: 0.0024
Avg Loading time: 0.0042 seconds
Avg Batch time: 0.0247 seconds

Train time: 9.797363996505737
 * Prec@1 90.770 Prec@5 99.390 Loss 0.3391
Avg Loading time: 0.0211 seconds
Avg Batch time: 0.0305 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 2.8093149662017822

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.044 (0.016)	BT: 0.054 (0.033)	Loss 0.0014 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.010)	BT: 0.031 (0.030)	Loss 0.0019 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.001 (0.012)	BT: 0.024 (0.033)	Loss 0.0017 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.026 (0.036)	Loss 0.0012 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.010)	BT: 0.023 (0.034)	Loss 0.0012 (0.0023)	Prec@1 100.000 (100.000)	
Total train loss: 0.0023
Avg Loading time: 0.0100 seconds
Avg Batch time: 0.0335 seconds

Train time: 13.25084137916565
 * Prec@1 90.860 Prec@5 99.380 Loss 0.3386
Avg Loading time: 0.0485 seconds
Avg Batch time: 0.0578 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 4.975694894790649

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.049)	BT: 0.023 (0.071)	Loss 0.0015 (0.0027)	Prec@1 100.000 (99.980)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.164 (0.051)	BT: 0.187 (0.074)	Loss 0.0012 (0.0025)	Prec@1 100.000 (99.990)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.060)	BT: 0.026 (0.083)	Loss 0.0037 (0.0025)	Prec@1 100.000 (99.993)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.070)	BT: 0.023 (0.092)	Loss 0.0022 (0.0025)	Prec@1 100.000 (99.995)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.080)	BT: 0.023 (0.102)	Loss 0.0045 (0.0024)	Prec@1 100.000 (99.996)	
Total train loss: 0.0024
Avg Loading time: 0.0795 seconds
Avg Batch time: 0.1021 seconds

Train time: 40.11155557632446
 * Prec@1 90.910 Prec@5 99.380 Loss 0.3398
Avg Loading time: 0.1294 seconds
Avg Batch time: 0.1387 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 11.408506631851196

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.133)	BT: 0.033 (0.156)	Loss 0.0020 (0.0025)	Prec@1 100.000 (100.000)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.123)	BT: 0.023 (0.146)	Loss 0.0017 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.367 (0.123)	BT: 0.380 (0.145)	Loss 0.0027 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.123)	BT: 0.023 (0.145)	Loss 0.0039 (0.0025)	Prec@1 100.000 (99.997)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.128)	BT: 0.023 (0.150)	Loss 0.0081 (0.0025)	Prec@1 100.000 (99.994)	
Total train loss: 0.0025
Avg Loading time: 0.1286 seconds
Avg Batch time: 0.1506 seconds

Train time: 59.06312966346741
 * Prec@1 90.820 Prec@5 99.390 Loss 0.3379
Avg Loading time: 0.1840 seconds
Avg Batch time: 0.1936 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 15.719948291778564

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.125)	BT: 0.023 (0.149)	Loss 0.0056 (0.0025)	Prec@1 100.000 (99.990)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.136)	BT: 0.023 (0.159)	Loss 0.0010 (0.0023)	Prec@1 100.000 (99.995)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.014 (0.130)	BT: 0.036 (0.152)	Loss 0.0020 (0.0024)	Prec@1 100.000 (99.997)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.129)	BT: 0.023 (0.152)	Loss 0.0021 (0.0023)	Prec@1 100.000 (99.997)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.131)	BT: 0.023 (0.153)	Loss 0.0022 (0.0024)	Prec@1 100.000 (99.992)	
Total train loss: 0.0024
Avg Loading time: 0.1304 seconds
Avg Batch time: 0.1530 seconds

Train time: 60.010241985321045
 * Prec@1 90.880 Prec@5 99.400 Loss 0.3362
Avg Loading time: 0.1706 seconds
Avg Batch time: 0.1799 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 14.631714105606079

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.117)	BT: 0.021 (0.140)	Loss 0.0018 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.114)	BT: 0.021 (0.137)	Loss 0.0021 (0.0024)	Prec@1 100.000 (99.995)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.105 (0.118)	BT: 0.120 (0.141)	Loss 0.0019 (0.0023)	Prec@1 100.000 (99.993)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.118)	BT: 0.021 (0.141)	Loss 0.0015 (0.0023)	Prec@1 100.000 (99.995)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.119)	BT: 0.021 (0.142)	Loss 0.0018 (0.0024)	Prec@1 100.000 (99.996)	
Total train loss: 0.0024
Avg Loading time: 0.1186 seconds
Avg Batch time: 0.1417 seconds

Train time: 55.5389940738678
 * Prec@1 90.760 Prec@5 99.390 Loss 0.3369
Avg Loading time: 0.0470 seconds
Avg Batch time: 0.0561 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 4.85954737663269

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.018)	BT: 0.032 (0.051)	Loss 0.0025 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.015)	BT: 0.027 (0.046)	Loss 0.0016 (0.0025)	Prec@1 100.000 (99.990)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.023 (0.039)	Loss 0.0032 (0.0024)	Prec@1 100.000 (99.993)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.016)	BT: 0.023 (0.044)	Loss 0.0016 (0.0024)	Prec@1 100.000 (99.995)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.018)	BT: 0.038 (0.047)	Loss 0.0029 (0.0024)	Prec@1 100.000 (99.996)	
Total train loss: 0.0024
Avg Loading time: 0.0180 seconds
Avg Batch time: 0.0472 seconds

Train time: 18.698763132095337
 * Prec@1 90.830 Prec@5 99.430 Loss 0.3364
Avg Loading time: 0.0399 seconds
Avg Batch time: 0.0523 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 4.605484247207642

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.001 (0.032)	BT: 0.032 (0.064)	Loss 0.0015 (0.0025)	Prec@1 100.000 (100.000)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.024)	BT: 0.057 (0.056)	Loss 0.0043 (0.0025)	Prec@1 100.000 (100.000)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.024)	BT: 0.027 (0.055)	Loss 0.0016 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.031 (0.055)	Loss 0.0010 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.024)	BT: 0.023 (0.055)	Loss 0.0011 (0.0023)	Prec@1 100.000 (100.000)	
Total train loss: 0.0023
Avg Loading time: 0.0238 seconds
Avg Batch time: 0.0553 seconds

Train time: 21.861176013946533
 * Prec@1 90.860 Prec@5 99.400 Loss 0.3347
Avg Loading time: 0.0398 seconds
Avg Batch time: 0.0528 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 4.624531984329224

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.030)	BT: 0.023 (0.057)	Loss 0.0011 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.025)	BT: 0.023 (0.052)	Loss 0.0031 (0.0024)	Prec@1 100.000 (99.985)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.015 (0.019)	BT: 0.038 (0.046)	Loss 0.0022 (0.0024)	Prec@1 100.000 (99.990)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.020)	BT: 0.045 (0.047)	Loss 0.0023 (0.0024)	Prec@1 100.000 (99.992)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.018)	BT: 0.034 (0.046)	Loss 0.0012 (0.0025)	Prec@1 100.000 (99.990)	
Total train loss: 0.0025
Avg Loading time: 0.0176 seconds
Avg Batch time: 0.0464 seconds

Train time: 18.39131736755371
 * Prec@1 90.710 Prec@5 99.400 Loss 0.3391
Avg Loading time: 0.0514 seconds
Avg Batch time: 0.0599 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 5.229545831680298

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.033)	BT: 0.021 (0.049)	Loss 0.0014 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.029)	BT: 0.012 (0.044)	Loss 0.0012 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.048)	BT: 0.010 (0.063)	Loss 0.0041 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.026 (0.055)	BT: 0.045 (0.071)	Loss 0.0018 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.050)	BT: 0.020 (0.069)	Loss 0.0012 (0.0022)	Prec@1 100.000 (99.998)	
Total train loss: 0.0022
Avg Loading time: 0.0503 seconds
Avg Batch time: 0.0684 seconds

Train time: 26.996874809265137
 * Prec@1 90.920 Prec@5 99.370 Loss 0.3379
Avg Loading time: 0.0343 seconds
Avg Batch time: 0.0478 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 4.256686210632324

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.017)	BT: 0.020 (0.039)	Loss 0.0012 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.162 (0.024)	BT: 0.192 (0.046)	Loss 0.0010 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.020)	BT: 0.020 (0.044)	Loss 0.0024 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.018)	BT: 0.033 (0.041)	Loss 0.0015 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.020)	BT: 0.031 (0.045)	Loss 0.0018 (0.0023)	Prec@1 100.000 (99.996)	
Total train loss: 0.0023
Avg Loading time: 0.0200 seconds
Avg Batch time: 0.0445 seconds

Train time: 17.62113642692566
 * Prec@1 90.830 Prec@5 99.370 Loss 0.3376
Avg Loading time: 0.0491 seconds
Avg Batch time: 0.0609 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 5.267390966415405

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.035 (0.039)	BT: 0.046 (0.066)	Loss 0.0015 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.048 (0.037)	BT: 0.065 (0.058)	Loss 0.0039 (0.0027)	Prec@1 100.000 (99.975)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.104 (0.035)	BT: 0.115 (0.055)	Loss 0.0019 (0.0027)	Prec@1 100.000 (99.980)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.032)	BT: 0.009 (0.053)	Loss 0.0017 (0.0026)	Prec@1 100.000 (99.980)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.034)	BT: 0.009 (0.054)	Loss 0.0034 (0.0026)	Prec@1 100.000 (99.982)	
Total train loss: 0.0026
Avg Loading time: 0.0344 seconds
Avg Batch time: 0.0537 seconds

Train time: 21.22161340713501
 * Prec@1 90.830 Prec@5 99.410 Loss 0.3398
Avg Loading time: 0.0462 seconds
Avg Batch time: 0.0563 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 4.891512632369995

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.035)	BT: 0.029 (0.062)	Loss 0.0015 (0.0026)	Prec@1 100.000 (99.990)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.023 (0.048)	Loss 0.0047 (0.0025)	Prec@1 100.000 (99.990)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.022)	BT: 0.027 (0.048)	Loss 0.0013 (0.0025)	Prec@1 100.000 (99.993)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.020)	BT: 0.050 (0.048)	Loss 0.0082 (0.0025)	Prec@1 100.000 (99.995)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.019)	BT: 0.029 (0.047)	Loss 0.0011 (0.0025)	Prec@1 100.000 (99.996)	
Total train loss: 0.0025
Avg Loading time: 0.0187 seconds
Avg Batch time: 0.0465 seconds

Train time: 18.40866994857788
 * Prec@1 90.750 Prec@5 99.410 Loss 0.3386
Avg Loading time: 0.0332 seconds
Avg Batch time: 0.0463 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 4.09743595123291

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.037)	BT: 0.028 (0.068)	Loss 0.0058 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.030)	BT: 0.023 (0.056)	Loss 0.0016 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.029)	BT: 0.034 (0.056)	Loss 0.0019 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.026)	BT: 0.027 (0.054)	Loss 0.0009 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.026)	BT: 0.023 (0.054)	Loss 0.0012 (0.0023)	Prec@1 100.000 (100.000)	
Total train loss: 0.0023
Avg Loading time: 0.0260 seconds
Avg Batch time: 0.0542 seconds

Train time: 21.434592247009277
 * Prec@1 90.830 Prec@5 99.390 Loss 0.3394
Avg Loading time: 0.0369 seconds
Avg Batch time: 0.0499 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 4.358785390853882

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.032)	BT: 0.034 (0.061)	Loss 0.0018 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.027 (0.051)	Loss 0.0014 (0.0023)	Prec@1 100.000 (99.995)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.228 (0.022)	BT: 0.250 (0.050)	Loss 0.0018 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.009 (0.050)	Loss 0.0015 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.021)	BT: 0.034 (0.048)	Loss 0.0023 (0.0022)	Prec@1 100.000 (99.998)	
Total train loss: 0.0022
Avg Loading time: 0.0205 seconds
Avg Batch time: 0.0478 seconds

Train time: 18.920912981033325
 * Prec@1 90.930 Prec@5 99.400 Loss 0.3379
Avg Loading time: 0.0480 seconds
Avg Batch time: 0.0606 seconds

Best acc: 90.930
--------------------------------------------------------------------------------
Test time: 5.260753154754639


      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 17
Savedir:  ../pretrained_models/frozen/x64-8b/rram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/train/relu17
Test path:  /home/nano01/a/esoufler/activations/x64-8b/rram/one_batch/cifar10/resnet18/test/relu17
ResNet18(
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 9.400 Prec@5 45.240 Loss 2.3301
Avg Loading time: 0.0577 seconds
Avg Batch time: 0.0786 seconds

Pre-trained Prec@1 with 17 layers frozen: 9.399999618530273 	 Loss: 2.330078125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (0.316)	BT: 0.016 (0.332)	Loss 0.7954 (0.9218)	Prec@1 75.781 (70.713)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.195 (0.261)	BT: 0.213 (0.276)	Loss 0.5713 (0.8090)	Prec@1 81.250 (73.377)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.291 (0.241)	BT: 0.303 (0.256)	Loss 0.7197 (0.7620)	Prec@1 71.875 (74.543)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (0.229)	BT: 0.014 (0.244)	Loss 0.5757 (0.7367)	Prec@1 79.688 (75.253)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (0.231)	BT: 0.014 (0.246)	Loss 0.5674 (0.7163)	Prec@1 82.031 (75.843)	
Total train loss: 0.7162
Avg Loading time: 0.2304 seconds
Avg Batch time: 0.2449 seconds

Train time: 95.9920928478241
 * Prec@1 77.760 Prec@5 98.870 Loss 0.6274
Avg Loading time: 0.0298 seconds
Avg Batch time: 0.0366 seconds

Best acc: 77.760
--------------------------------------------------------------------------------
Test time: 3.0561773777008057

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.051)	BT: 0.010 (0.069)	Loss 0.5400 (0.6060)	Prec@1 82.812 (78.886)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.044)	BT: 0.014 (0.061)	Loss 0.7471 (0.6073)	Prec@1 75.000 (78.866)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.041)	BT: 0.010 (0.058)	Loss 0.5679 (0.6136)	Prec@1 83.594 (78.606)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.040)	BT: 0.014 (0.056)	Loss 0.6309 (0.6110)	Prec@1 82.812 (78.764)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.040)	BT: 0.014 (0.056)	Loss 0.6538 (0.6129)	Prec@1 78.125 (78.678)	
Total train loss: 0.6130
Avg Loading time: 0.0401 seconds
Avg Batch time: 0.0559 seconds

Train time: 22.10075855255127
 * Prec@1 78.840 Prec@5 98.840 Loss 0.6040
Avg Loading time: 0.0539 seconds
Avg Batch time: 0.0636 seconds

Best acc: 78.840
--------------------------------------------------------------------------------
Test time: 5.263426303863525

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.041)	BT: 0.014 (0.058)	Loss 0.5347 (0.5754)	Prec@1 82.812 (80.329)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.040)	BT: 0.014 (0.057)	Loss 0.6196 (0.5869)	Prec@1 77.344 (79.642)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.138 (0.037)	BT: 0.153 (0.054)	Loss 0.4707 (0.5908)	Prec@1 83.594 (79.494)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.032)	BT: 0.012 (0.048)	Loss 0.5430 (0.5968)	Prec@1 82.031 (79.294)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.035)	BT: 0.008 (0.050)	Loss 0.7036 (0.5989)	Prec@1 76.562 (79.313)	
Total train loss: 0.5991
Avg Loading time: 0.0345 seconds
Avg Batch time: 0.0497 seconds

Train time: 19.644524097442627
 * Prec@1 78.490 Prec@5 99.090 Loss 0.6069
Avg Loading time: 0.0281 seconds
Avg Batch time: 0.0332 seconds

Best acc: 78.840
--------------------------------------------------------------------------------
Test time: 2.830925464630127

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.038)	BT: 0.018 (0.056)	Loss 0.6685 (0.5715)	Prec@1 75.781 (80.108)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.034)	BT: 0.018 (0.053)	Loss 0.5308 (0.5751)	Prec@1 79.688 (79.923)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.032)	BT: 0.018 (0.051)	Loss 0.5527 (0.5800)	Prec@1 84.375 (79.644)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.034)	BT: 0.013 (0.052)	Loss 0.4956 (0.5879)	Prec@1 82.031 (79.400)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.037)	BT: 0.018 (0.054)	Loss 0.7773 (0.5905)	Prec@1 71.094 (79.329)	
Total train loss: 0.5905
Avg Loading time: 0.0374 seconds
Avg Batch time: 0.0535 seconds

Train time: 21.133482456207275
 * Prec@1 79.160 Prec@5 99.110 Loss 0.5977
Avg Loading time: 0.0454 seconds
Avg Batch time: 0.0539 seconds

Best acc: 79.160
--------------------------------------------------------------------------------
Test time: 4.471439838409424

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.045)	BT: 0.010 (0.063)	Loss 0.5435 (0.5765)	Prec@1 79.688 (80.028)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.225 (0.041)	BT: 0.240 (0.059)	Loss 0.4880 (0.5751)	Prec@1 79.688 (80.173)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.035)	BT: 0.019 (0.052)	Loss 0.7554 (0.5790)	Prec@1 71.094 (80.028)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.031)	BT: 0.012 (0.048)	Loss 0.6362 (0.5815)	Prec@1 78.125 (79.888)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.030)	BT: 0.010 (0.046)	Loss 0.7100 (0.5852)	Prec@1 75.781 (79.637)	
Total train loss: 0.5853
Avg Loading time: 0.0300 seconds
Avg Batch time: 0.0465 seconds

Train time: 18.339383125305176
 * Prec@1 79.120 Prec@5 99.180 Loss 0.5952
Avg Loading time: 0.0353 seconds
Avg Batch time: 0.0435 seconds

Best acc: 79.160
--------------------------------------------------------------------------------
Test time: 3.5989766120910645

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.038)	BT: 0.016 (0.055)	Loss 0.6543 (0.5632)	Prec@1 78.906 (80.529)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.170 (0.034)	BT: 0.186 (0.051)	Loss 0.5337 (0.5816)	Prec@1 81.250 (79.883)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.000 (0.033)	BT: 0.010 (0.050)	Loss 0.4470 (0.5753)	Prec@1 85.938 (79.978)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.035)	BT: 0.010 (0.052)	Loss 0.5107 (0.5786)	Prec@1 79.688 (79.778)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.034)	BT: 0.016 (0.052)	Loss 0.8125 (0.5796)	Prec@1 72.656 (79.734)	
Total train loss: 0.5798
Avg Loading time: 0.0344 seconds
Avg Batch time: 0.0515 seconds

Train time: 20.36665678024292
 * Prec@1 78.770 Prec@5 99.090 Loss 0.5991
Avg Loading time: 0.0394 seconds
Avg Batch time: 0.0490 seconds

Best acc: 79.160
--------------------------------------------------------------------------------
Test time: 4.111926794052124

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.053)	BT: 0.014 (0.069)	Loss 0.4321 (0.5610)	Prec@1 81.250 (80.519)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.044)	BT: 0.018 (0.060)	Loss 0.5879 (0.5698)	Prec@1 83.594 (80.349)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.173 (0.041)	BT: 0.186 (0.057)	Loss 0.7388 (0.5725)	Prec@1 74.219 (80.285)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.038)	BT: 0.010 (0.054)	Loss 0.5840 (0.5789)	Prec@1 79.688 (79.888)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.035)	BT: 0.022 (0.050)	Loss 0.6548 (0.5815)	Prec@1 76.562 (79.726)	
Total train loss: 0.5820
Avg Loading time: 0.0353 seconds
Avg Batch time: 0.0500 seconds

Train time: 19.76408076286316
 * Prec@1 79.100 Prec@5 99.010 Loss 0.5933
Avg Loading time: 0.0448 seconds
Avg Batch time: 0.0535 seconds

Best acc: 79.160
--------------------------------------------------------------------------------
Test time: 4.636744499206543

Epoch: [7][77/391]	LR: 0.1	DT: 0.033 (0.045)	BT: 0.047 (0.060)	Loss 0.6074 (0.5689)	Prec@1 77.344 (80.439)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.152 (0.045)	BT: 0.169 (0.061)	Loss 0.6025 (0.5679)	Prec@1 81.250 (80.379)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.137 (0.044)	BT: 0.151 (0.060)	Loss 0.7207 (0.5696)	Prec@1 75.781 (80.175)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.044)	BT: 0.010 (0.060)	Loss 0.6133 (0.5718)	Prec@1 76.562 (80.103)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.043)	BT: 0.006 (0.059)	Loss 0.6489 (0.5764)	Prec@1 78.906 (80.006)	
Total train loss: 0.5763
Avg Loading time: 0.0429 seconds
Avg Batch time: 0.0591 seconds

Train time: 23.336591720581055
 * Prec@1 78.910 Prec@5 99.090 Loss 0.5967
Avg Loading time: 0.0484 seconds
Avg Batch time: 0.0577 seconds

Best acc: 79.160
--------------------------------------------------------------------------------
Test time: 4.789407730102539

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.044)	BT: 0.018 (0.061)	Loss 0.3992 (0.5733)	Prec@1 83.594 (79.657)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.035)	BT: 0.023 (0.053)	Loss 0.6470 (0.5751)	Prec@1 77.344 (79.703)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.012 (0.047)	Loss 0.5659 (0.5715)	Prec@1 83.594 (79.915)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.157 (0.026)	BT: 0.182 (0.042)	Loss 0.4431 (0.5694)	Prec@1 87.500 (80.013)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.027)	BT: 0.019 (0.044)	Loss 0.5918 (0.5719)	Prec@1 77.344 (80.026)	
Total train loss: 0.5723
Avg Loading time: 0.0269 seconds
Avg Batch time: 0.0437 seconds

Train time: 17.249682188034058
 * Prec@1 79.190 Prec@5 99.230 Loss 0.5913
Avg Loading time: 0.0303 seconds
Avg Batch time: 0.0357 seconds

Best acc: 79.190
--------------------------------------------------------------------------------
Test time: 3.0469188690185547

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.043)	BT: 0.019 (0.059)	Loss 0.4685 (0.5563)	Prec@1 82.812 (80.689)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.021 (0.037)	BT: 0.037 (0.055)	Loss 0.5771 (0.5630)	Prec@1 77.344 (80.374)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.132 (0.035)	BT: 0.155 (0.054)	Loss 0.5303 (0.5599)	Prec@1 85.156 (80.609)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.001 (0.033)	BT: 0.025 (0.051)	Loss 0.5664 (0.5630)	Prec@1 78.906 (80.516)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.035)	BT: 0.008 (0.053)	Loss 0.7036 (0.5675)	Prec@1 76.562 (80.294)	
Total train loss: 0.5678
Avg Loading time: 0.0346 seconds
Avg Batch time: 0.0527 seconds

Train time: 20.8502254486084
 * Prec@1 79.330 Prec@5 99.190 Loss 0.5938
Avg Loading time: 0.0540 seconds
Avg Batch time: 0.0653 seconds

Best acc: 79.330
--------------------------------------------------------------------------------
Test time: 5.412705421447754

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.022 (0.051)	BT: 0.033 (0.068)	Loss 0.4802 (0.5470)	Prec@1 84.375 (80.980)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.040)	BT: 0.022 (0.058)	Loss 0.5010 (0.5418)	Prec@1 82.031 (81.005)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.041)	BT: 0.027 (0.058)	Loss 0.5322 (0.5456)	Prec@1 78.906 (80.950)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.035)	BT: 0.012 (0.051)	Loss 0.4758 (0.5447)	Prec@1 83.594 (80.997)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.053 (0.036)	BT: 0.064 (0.051)	Loss 0.6035 (0.5444)	Prec@1 81.250 (81.004)	
Total train loss: 0.5443
Avg Loading time: 0.0357 seconds
Avg Batch time: 0.0512 seconds

Train time: 20.19659996032715
 * Prec@1 79.610 Prec@5 99.210 Loss 0.5791
Avg Loading time: 0.0327 seconds
Avg Batch time: 0.0394 seconds

Best acc: 79.610
--------------------------------------------------------------------------------
Test time: 3.3048622608184814

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.040)	BT: 0.010 (0.058)	Loss 0.5205 (0.5286)	Prec@1 83.594 (81.631)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.043 (0.035)	BT: 0.060 (0.053)	Loss 0.4490 (0.5295)	Prec@1 83.594 (81.636)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.038)	BT: 0.016 (0.055)	Loss 0.5527 (0.5310)	Prec@1 80.469 (81.427)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.002 (0.036)	BT: 0.028 (0.054)	Loss 0.5259 (0.5354)	Prec@1 82.812 (81.290)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.033)	BT: 0.012 (0.052)	Loss 0.5732 (0.5419)	Prec@1 78.906 (81.102)	
Total train loss: 0.5420
Avg Loading time: 0.0334 seconds
Avg Batch time: 0.0514 seconds

Train time: 20.3192298412323
 * Prec@1 79.940 Prec@5 99.190 Loss 0.5796
Avg Loading time: 0.0465 seconds
Avg Batch time: 0.0587 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.866744756698608

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.004 (0.036)	BT: 0.018 (0.053)	Loss 0.5386 (0.5425)	Prec@1 82.031 (81.340)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.034)	BT: 0.023 (0.051)	Loss 0.5356 (0.5440)	Prec@1 81.250 (81.260)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.004 (0.032)	BT: 0.027 (0.050)	Loss 0.4473 (0.5429)	Prec@1 84.375 (81.163)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.030)	BT: 0.025 (0.047)	Loss 0.4500 (0.5398)	Prec@1 84.375 (81.335)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.027)	BT: 0.010 (0.043)	Loss 0.4648 (0.5406)	Prec@1 78.906 (81.314)	
Total train loss: 0.5405
Avg Loading time: 0.0266 seconds
Avg Batch time: 0.0432 seconds

Train time: 17.109918117523193
 * Prec@1 79.260 Prec@5 99.180 Loss 0.5854
Avg Loading time: 0.0504 seconds
Avg Batch time: 0.0580 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.8274078369140625

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.033)	BT: 0.007 (0.040)	Loss 0.4590 (0.5475)	Prec@1 82.812 (80.719)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.198 (0.033)	BT: 0.210 (0.042)	Loss 0.7334 (0.5361)	Prec@1 77.344 (81.505)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.031)	BT: 0.010 (0.041)	Loss 0.5811 (0.5396)	Prec@1 77.344 (81.237)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.032)	BT: 0.006 (0.042)	Loss 0.6587 (0.5410)	Prec@1 75.000 (81.140)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.031)	BT: 0.012 (0.041)	Loss 0.4629 (0.5392)	Prec@1 82.031 (81.184)	
Total train loss: 0.5391
Avg Loading time: 0.0308 seconds
Avg Batch time: 0.0407 seconds

Train time: 16.140162229537964
 * Prec@1 79.670 Prec@5 99.190 Loss 0.5786
Avg Loading time: 0.0492 seconds
Avg Batch time: 0.0564 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.693569183349609

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.049)	BT: 0.005 (0.060)	Loss 0.4900 (0.5382)	Prec@1 88.281 (81.140)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.040)	BT: 0.016 (0.050)	Loss 0.5405 (0.5345)	Prec@1 79.688 (81.385)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.039)	BT: 0.005 (0.049)	Loss 0.7104 (0.5347)	Prec@1 81.250 (81.460)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.037)	BT: 0.012 (0.048)	Loss 0.4985 (0.5358)	Prec@1 75.781 (81.320)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.036)	BT: 0.008 (0.047)	Loss 0.5244 (0.5351)	Prec@1 85.156 (81.404)	
Total train loss: 0.5354
Avg Loading time: 0.0364 seconds
Avg Batch time: 0.0466 seconds

Train time: 18.45366597175598
 * Prec@1 79.820 Prec@5 99.140 Loss 0.5811
Avg Loading time: 0.0291 seconds
Avg Batch time: 0.0358 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 2.9760994911193848

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.046)	BT: 0.013 (0.055)	Loss 0.4780 (0.5326)	Prec@1 83.594 (81.530)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.036)	BT: 0.007 (0.045)	Loss 0.5854 (0.5332)	Prec@1 79.688 (81.560)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.031)	BT: 0.018 (0.039)	Loss 0.4973 (0.5354)	Prec@1 83.594 (81.497)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.030)	BT: 0.015 (0.039)	Loss 0.5317 (0.5366)	Prec@1 82.812 (81.438)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.031)	BT: 0.009 (0.040)	Loss 0.4678 (0.5383)	Prec@1 80.469 (81.338)	
Total train loss: 0.5385
Avg Loading time: 0.0305 seconds
Avg Batch time: 0.0397 seconds

Train time: 15.757171154022217
 * Prec@1 79.490 Prec@5 99.150 Loss 0.5820
Avg Loading time: 0.0382 seconds
Avg Batch time: 0.0477 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 3.984128475189209

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.043)	BT: 0.011 (0.054)	Loss 0.6953 (0.5430)	Prec@1 75.781 (81.591)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.035)	BT: 0.010 (0.047)	Loss 0.5259 (0.5467)	Prec@1 82.031 (81.150)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.033)	BT: 0.028 (0.045)	Loss 0.5664 (0.5441)	Prec@1 80.469 (81.076)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.034)	BT: 0.007 (0.045)	Loss 0.6362 (0.5429)	Prec@1 73.438 (81.127)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.033)	BT: 0.005 (0.044)	Loss 0.5400 (0.5385)	Prec@1 85.156 (81.316)	
Total train loss: 0.5384
Avg Loading time: 0.0330 seconds
Avg Batch time: 0.0438 seconds

Train time: 17.39183807373047
 * Prec@1 79.660 Prec@5 99.070 Loss 0.5811
Avg Loading time: 0.0516 seconds
Avg Batch time: 0.0597 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.927334547042847

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.049)	BT: 0.023 (0.059)	Loss 0.5234 (0.5276)	Prec@1 84.375 (81.741)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.033)	BT: 0.005 (0.043)	Loss 0.4307 (0.5297)	Prec@1 85.156 (81.370)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.001 (0.031)	BT: 0.020 (0.040)	Loss 0.5278 (0.5408)	Prec@1 80.469 (81.113)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.031)	BT: 0.015 (0.041)	Loss 0.4878 (0.5417)	Prec@1 86.719 (81.087)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.029)	BT: 0.006 (0.038)	Loss 0.5103 (0.5402)	Prec@1 80.469 (81.170)	
Total train loss: 0.5401
Avg Loading time: 0.0287 seconds
Avg Batch time: 0.0379 seconds

Train time: 14.983732461929321
 * Prec@1 79.710 Prec@5 99.130 Loss 0.5830
Avg Loading time: 0.0441 seconds
Avg Batch time: 0.0521 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.361542701721191

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.050)	BT: 0.010 (0.062)	Loss 0.4775 (0.5312)	Prec@1 83.594 (81.691)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.042)	BT: 0.013 (0.053)	Loss 0.5801 (0.5308)	Prec@1 77.344 (81.606)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.039)	BT: 0.020 (0.049)	Loss 0.5815 (0.5308)	Prec@1 79.688 (81.631)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.038)	BT: 0.009 (0.048)	Loss 0.6211 (0.5382)	Prec@1 80.469 (81.355)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.094 (0.037)	BT: 0.101 (0.047)	Loss 0.6411 (0.5381)	Prec@1 81.250 (81.312)	
Total train loss: 0.5379
Avg Loading time: 0.0364 seconds
Avg Batch time: 0.0466 seconds

Train time: 18.46009874343872
 * Prec@1 79.760 Prec@5 99.160 Loss 0.5830
Avg Loading time: 0.0454 seconds
Avg Batch time: 0.0541 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.5089545249938965

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.047)	BT: 0.013 (0.059)	Loss 0.5693 (0.5271)	Prec@1 77.344 (81.470)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.170 (0.038)	BT: 0.176 (0.048)	Loss 0.5137 (0.5367)	Prec@1 82.031 (81.180)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.035)	BT: 0.009 (0.046)	Loss 0.5439 (0.5344)	Prec@1 82.812 (81.500)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.031)	BT: 0.010 (0.041)	Loss 0.4614 (0.5361)	Prec@1 85.156 (81.353)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.031)	BT: 0.007 (0.041)	Loss 0.5107 (0.5382)	Prec@1 81.250 (81.244)	
Total train loss: 0.5384
Avg Loading time: 0.0311 seconds
Avg Batch time: 0.0410 seconds

Train time: 16.255683660507202
 * Prec@1 79.600 Prec@5 99.110 Loss 0.5806
Avg Loading time: 0.0418 seconds
Avg Batch time: 0.0474 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.017338037490845

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.038)	BT: 0.021 (0.048)	Loss 0.5303 (0.5384)	Prec@1 81.250 (81.400)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.038)	BT: 0.005 (0.048)	Loss 0.6250 (0.5359)	Prec@1 78.125 (81.310)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.037)	BT: 0.008 (0.048)	Loss 0.5562 (0.5320)	Prec@1 79.688 (81.510)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.034)	BT: 0.022 (0.046)	Loss 0.5796 (0.5281)	Prec@1 80.469 (81.658)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.034)	BT: 0.007 (0.046)	Loss 0.5977 (0.5291)	Prec@1 84.375 (81.595)	
Total train loss: 0.5290
Avg Loading time: 0.0341 seconds
Avg Batch time: 0.0456 seconds

Train time: 18.07580852508545
 * Prec@1 79.500 Prec@5 99.100 Loss 0.5811
Avg Loading time: 0.0410 seconds
Avg Batch time: 0.0488 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.074341058731079

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.042)	BT: 0.007 (0.053)	Loss 0.4062 (0.5270)	Prec@1 85.156 (81.821)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.038)	BT: 0.011 (0.049)	Loss 0.5801 (0.5210)	Prec@1 82.031 (81.921)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.346 (0.037)	BT: 0.353 (0.048)	Loss 0.5972 (0.5288)	Prec@1 77.344 (81.767)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.752 (0.047)	BT: 0.763 (0.057)	Loss 0.4167 (0.5289)	Prec@1 83.594 (81.728)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.055)	BT: 0.018 (0.065)	Loss 0.5786 (0.5297)	Prec@1 81.250 (81.713)	
Total train loss: 0.5298
Avg Loading time: 0.0544 seconds
Avg Batch time: 0.0647 seconds

Train time: 25.52894139289856
 * Prec@1 79.740 Prec@5 99.170 Loss 0.5806
Avg Loading time: 0.0480 seconds
Avg Batch time: 0.0570 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.776262044906616

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.042)	BT: 0.012 (0.057)	Loss 0.4561 (0.5417)	Prec@1 85.156 (81.290)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.038)	BT: 0.014 (0.054)	Loss 0.5103 (0.5366)	Prec@1 85.156 (81.365)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.035)	BT: 0.016 (0.052)	Loss 0.4351 (0.5304)	Prec@1 82.812 (81.604)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.034)	BT: 0.023 (0.050)	Loss 0.4702 (0.5306)	Prec@1 80.469 (81.563)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.025 (0.034)	BT: 0.054 (0.051)	Loss 0.5928 (0.5296)	Prec@1 82.812 (81.621)	
Total train loss: 0.5295
Avg Loading time: 0.0344 seconds
Avg Batch time: 0.0513 seconds

Train time: 20.26484227180481
 * Prec@1 79.720 Prec@5 99.120 Loss 0.5806
Avg Loading time: 0.0520 seconds
Avg Batch time: 0.0607 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 5.02667760848999

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.041)	BT: 0.007 (0.057)	Loss 0.4014 (0.5256)	Prec@1 87.500 (81.781)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.010 (0.045)	BT: 0.017 (0.058)	Loss 0.5649 (0.5267)	Prec@1 81.250 (81.696)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.068 (0.046)	BT: 0.078 (0.058)	Loss 0.4287 (0.5265)	Prec@1 85.938 (81.587)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.039)	BT: 0.006 (0.050)	Loss 0.4482 (0.5254)	Prec@1 82.031 (81.806)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.038)	BT: 0.012 (0.050)	Loss 0.4211 (0.5265)	Prec@1 83.594 (81.759)	
Total train loss: 0.5267
Avg Loading time: 0.0374 seconds
Avg Batch time: 0.0494 seconds

Train time: 19.535041093826294
 * Prec@1 79.780 Prec@5 99.100 Loss 0.5781
Avg Loading time: 0.0327 seconds
Avg Batch time: 0.0395 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 3.257389545440674

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.037)	BT: 0.018 (0.053)	Loss 0.4912 (0.5331)	Prec@1 85.156 (80.909)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.238 (0.040)	BT: 0.251 (0.055)	Loss 0.6035 (0.5303)	Prec@1 79.688 (81.235)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.046 (0.038)	BT: 0.062 (0.054)	Loss 0.5127 (0.5356)	Prec@1 83.594 (81.173)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.120 (0.037)	BT: 0.131 (0.053)	Loss 0.4211 (0.5292)	Prec@1 87.500 (81.458)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.035)	BT: 0.016 (0.051)	Loss 0.4846 (0.5283)	Prec@1 84.375 (81.567)	
Total train loss: 0.5282
Avg Loading time: 0.0349 seconds
Avg Batch time: 0.0510 seconds

Train time: 20.184640884399414
 * Prec@1 79.580 Prec@5 99.210 Loss 0.5806
Avg Loading time: 0.0441 seconds
Avg Batch time: 0.0536 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.47743034362793

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.048)	BT: 0.012 (0.065)	Loss 0.7383 (0.5419)	Prec@1 75.781 (81.500)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.041)	BT: 0.018 (0.058)	Loss 0.4456 (0.5336)	Prec@1 85.938 (81.671)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.098 (0.040)	BT: 0.117 (0.057)	Loss 0.5479 (0.5316)	Prec@1 79.688 (81.808)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.033)	BT: 0.009 (0.050)	Loss 0.3694 (0.5284)	Prec@1 85.156 (81.836)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.032)	BT: 0.019 (0.048)	Loss 0.5327 (0.5277)	Prec@1 79.688 (81.761)	
Total train loss: 0.5280
Avg Loading time: 0.0318 seconds
Avg Batch time: 0.0481 seconds

Train time: 19.04963779449463
 * Prec@1 79.710 Prec@5 99.160 Loss 0.5796
Avg Loading time: 0.0346 seconds
Avg Batch time: 0.0435 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 3.8805062770843506

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.001 (0.040)	BT: 0.015 (0.052)	Loss 0.5234 (0.5264)	Prec@1 85.156 (81.971)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.037)	BT: 0.011 (0.051)	Loss 0.3691 (0.5173)	Prec@1 86.719 (82.131)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.034)	BT: 0.021 (0.050)	Loss 0.5410 (0.5244)	Prec@1 84.375 (81.821)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.034)	BT: 0.033 (0.050)	Loss 0.4343 (0.5276)	Prec@1 85.156 (81.686)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.033)	BT: 0.018 (0.049)	Loss 0.4695 (0.5297)	Prec@1 86.719 (81.629)	
Total train loss: 0.5297
Avg Loading time: 0.0330 seconds
Avg Batch time: 0.0493 seconds

Train time: 19.496498346328735
 * Prec@1 79.520 Prec@5 99.170 Loss 0.5791
Avg Loading time: 0.0492 seconds
Avg Batch time: 0.0587 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.855797052383423

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.050)	BT: 0.016 (0.066)	Loss 0.4619 (0.5184)	Prec@1 82.812 (82.021)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.189 (0.046)	BT: 0.195 (0.061)	Loss 0.6787 (0.5223)	Prec@1 79.688 (81.831)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.042)	BT: 0.012 (0.058)	Loss 0.6201 (0.5266)	Prec@1 77.344 (81.694)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.091 (0.038)	BT: 0.100 (0.053)	Loss 0.4775 (0.5275)	Prec@1 81.250 (81.653)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.033)	BT: 0.015 (0.048)	Loss 0.5703 (0.5308)	Prec@1 79.688 (81.484)	
Total train loss: 0.5311
Avg Loading time: 0.0331 seconds
Avg Batch time: 0.0482 seconds

Train time: 19.079193592071533
 * Prec@1 79.590 Prec@5 99.180 Loss 0.5806
Avg Loading time: 0.0522 seconds
Avg Batch time: 0.0605 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 5.039345979690552

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.028)	BT: 0.020 (0.042)	Loss 0.5410 (0.5324)	Prec@1 82.031 (81.500)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.031)	BT: 0.018 (0.046)	Loss 0.4287 (0.5285)	Prec@1 82.812 (81.475)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.237 (0.030)	BT: 0.247 (0.047)	Loss 0.2991 (0.5264)	Prec@1 92.969 (81.510)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.029)	BT: 0.012 (0.046)	Loss 0.4866 (0.5271)	Prec@1 87.500 (81.450)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.030)	BT: 0.012 (0.047)	Loss 0.5767 (0.5269)	Prec@1 78.125 (81.583)	
Total train loss: 0.5269
Avg Loading time: 0.0303 seconds
Avg Batch time: 0.0466 seconds

Train time: 18.49860906600952
 * Prec@1 79.600 Prec@5 99.200 Loss 0.5786
Avg Loading time: 0.0507 seconds
Avg Batch time: 0.0596 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.9822611808776855

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.051)	BT: 0.010 (0.067)	Loss 0.6011 (0.5299)	Prec@1 79.688 (81.711)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.041)	BT: 0.027 (0.058)	Loss 0.4883 (0.5273)	Prec@1 84.375 (81.656)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.025 (0.037)	BT: 0.039 (0.053)	Loss 0.5405 (0.5250)	Prec@1 78.125 (81.614)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.037)	BT: 0.018 (0.053)	Loss 0.7036 (0.5277)	Prec@1 78.125 (81.566)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.032)	BT: 0.012 (0.048)	Loss 0.5366 (0.5278)	Prec@1 81.250 (81.611)	
Total train loss: 0.5277
Avg Loading time: 0.0321 seconds
Avg Batch time: 0.0481 seconds

Train time: 18.9644033908844
 * Prec@1 79.470 Prec@5 99.180 Loss 0.5806
Avg Loading time: 0.0542 seconds
Avg Batch time: 0.0619 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 5.110623121261597

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.012 (0.037)	Loss 0.4106 (0.5385)	Prec@1 90.625 (81.060)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.030)	BT: 0.031 (0.045)	Loss 0.4600 (0.5374)	Prec@1 82.031 (81.320)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.030)	BT: 0.016 (0.046)	Loss 0.4680 (0.5342)	Prec@1 84.375 (81.507)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.030)	BT: 0.023 (0.047)	Loss 0.5645 (0.5263)	Prec@1 76.562 (81.758)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.031)	BT: 0.007 (0.048)	Loss 0.6338 (0.5277)	Prec@1 76.562 (81.673)	
Total train loss: 0.5278
Avg Loading time: 0.0308 seconds
Avg Batch time: 0.0477 seconds

Train time: 18.86189317703247
 * Prec@1 79.420 Prec@5 99.200 Loss 0.5820
Avg Loading time: 0.0459 seconds
Avg Batch time: 0.0555 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.634060382843018

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.043)	BT: 0.020 (0.057)	Loss 0.5386 (0.5266)	Prec@1 83.594 (81.791)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.041)	BT: 0.023 (0.056)	Loss 0.6313 (0.5276)	Prec@1 75.000 (81.671)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.041)	BT: 0.023 (0.057)	Loss 0.4570 (0.5265)	Prec@1 82.812 (81.717)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.038)	BT: 0.010 (0.054)	Loss 0.3916 (0.5278)	Prec@1 83.594 (81.540)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.034)	BT: 0.014 (0.050)	Loss 0.4568 (0.5277)	Prec@1 84.375 (81.633)	
Total train loss: 0.5279
Avg Loading time: 0.0343 seconds
Avg Batch time: 0.0498 seconds

Train time: 19.64979839324951
 * Prec@1 79.520 Prec@5 99.200 Loss 0.5796
Avg Loading time: 0.0576 seconds
Avg Batch time: 0.0667 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 5.508184909820557

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.028)	BT: 0.043 (0.042)	Loss 0.4465 (0.5296)	Prec@1 78.906 (81.460)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.033)	BT: 0.013 (0.050)	Loss 0.4988 (0.5258)	Prec@1 82.812 (81.611)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.032)	BT: 0.014 (0.050)	Loss 0.5957 (0.5293)	Prec@1 78.906 (81.641)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.030)	BT: 0.014 (0.049)	Loss 0.5913 (0.5295)	Prec@1 79.688 (81.701)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.030)	BT: 0.016 (0.049)	Loss 0.4978 (0.5280)	Prec@1 83.594 (81.723)	
Total train loss: 0.5280
Avg Loading time: 0.0300 seconds
Avg Batch time: 0.0487 seconds

Train time: 19.309770584106445
 * Prec@1 79.700 Prec@5 99.200 Loss 0.5786
Avg Loading time: 0.0364 seconds
Avg Batch time: 0.0460 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 3.8915793895721436

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.052)	BT: 0.018 (0.068)	Loss 0.4949 (0.5200)	Prec@1 83.594 (82.081)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.042)	BT: 0.018 (0.058)	Loss 0.4868 (0.5243)	Prec@1 82.031 (81.836)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.037 (0.037)	BT: 0.054 (0.053)	Loss 0.5635 (0.5233)	Prec@1 81.250 (81.894)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.034)	BT: 0.010 (0.051)	Loss 0.5723 (0.5220)	Prec@1 83.594 (82.026)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.033)	BT: 0.007 (0.049)	Loss 0.6880 (0.5239)	Prec@1 77.344 (81.949)	
Total train loss: 0.5241
Avg Loading time: 0.0331 seconds
Avg Batch time: 0.0493 seconds

Train time: 19.500593423843384
 * Prec@1 79.600 Prec@5 99.150 Loss 0.5815
Avg Loading time: 0.0460 seconds
Avg Batch time: 0.0532 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.427813291549683

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.031)	BT: 0.009 (0.043)	Loss 0.6455 (0.5149)	Prec@1 80.469 (81.701)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.029)	BT: 0.010 (0.040)	Loss 0.4983 (0.5228)	Prec@1 85.938 (81.576)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.029)	BT: 0.019 (0.041)	Loss 0.7524 (0.5257)	Prec@1 75.781 (81.574)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.030)	BT: 0.034 (0.042)	Loss 0.4307 (0.5286)	Prec@1 85.156 (81.571)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.030)	BT: 0.016 (0.043)	Loss 0.5205 (0.5264)	Prec@1 83.594 (81.721)	
Total train loss: 0.5266
Avg Loading time: 0.0301 seconds
Avg Batch time: 0.0429 seconds

Train time: 17.013087034225464
 * Prec@1 79.690 Prec@5 99.130 Loss 0.5806
Avg Loading time: 0.0561 seconds
Avg Batch time: 0.0651 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 5.383302211761475

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.167 (0.043)	BT: 0.180 (0.059)	Loss 0.5688 (0.5269)	Prec@1 80.469 (81.951)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.038)	BT: 0.023 (0.055)	Loss 0.4216 (0.5222)	Prec@1 88.281 (82.247)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.035)	BT: 0.015 (0.053)	Loss 0.5010 (0.5257)	Prec@1 81.250 (81.978)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.032)	BT: 0.027 (0.050)	Loss 0.4150 (0.5307)	Prec@1 85.938 (81.721)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.068 (0.032)	BT: 0.088 (0.050)	Loss 0.4675 (0.5283)	Prec@1 86.719 (81.759)	
Total train loss: 0.5283
Avg Loading time: 0.0318 seconds
Avg Batch time: 0.0501 seconds

Train time: 19.806045055389404
 * Prec@1 79.620 Prec@5 99.160 Loss 0.5806
Avg Loading time: 0.0372 seconds
Avg Batch time: 0.0435 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 3.597738265991211

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.043)	BT: 0.010 (0.058)	Loss 0.4087 (0.5079)	Prec@1 84.375 (82.462)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.034)	BT: 0.013 (0.048)	Loss 0.5308 (0.5256)	Prec@1 84.375 (82.061)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.028)	BT: 0.012 (0.042)	Loss 0.4565 (0.5246)	Prec@1 84.375 (82.001)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.029)	BT: 0.031 (0.043)	Loss 0.4810 (0.5254)	Prec@1 87.500 (81.851)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.030)	BT: 0.008 (0.045)	Loss 0.4851 (0.5259)	Prec@1 82.812 (81.763)	
Total train loss: 0.5259
Avg Loading time: 0.0304 seconds
Avg Batch time: 0.0452 seconds

Train time: 17.946608066558838
 * Prec@1 79.740 Prec@5 99.160 Loss 0.5811
Avg Loading time: 0.0454 seconds
Avg Batch time: 0.0544 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.524332523345947

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.052)	BT: 0.012 (0.068)	Loss 0.6606 (0.5464)	Prec@1 76.562 (80.950)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.040)	BT: 0.027 (0.058)	Loss 0.6821 (0.5453)	Prec@1 77.344 (81.115)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.039)	BT: 0.027 (0.055)	Loss 0.4910 (0.5333)	Prec@1 80.469 (81.487)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.036)	BT: 0.020 (0.053)	Loss 0.4407 (0.5303)	Prec@1 87.500 (81.568)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.036)	BT: 0.009 (0.052)	Loss 0.4497 (0.5277)	Prec@1 89.062 (81.657)	
Total train loss: 0.5277
Avg Loading time: 0.0363 seconds
Avg Batch time: 0.0523 seconds

Train time: 20.716756343841553
 * Prec@1 79.530 Prec@5 99.160 Loss 0.5811
Avg Loading time: 0.0542 seconds
Avg Batch time: 0.0624 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 5.136329174041748

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.038)	BT: 0.015 (0.051)	Loss 0.4697 (0.5242)	Prec@1 85.156 (81.901)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.036)	BT: 0.012 (0.050)	Loss 0.5225 (0.5323)	Prec@1 81.250 (81.606)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.052 (0.031)	BT: 0.068 (0.044)	Loss 0.4924 (0.5298)	Prec@1 81.250 (81.611)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.001 (0.032)	BT: 0.031 (0.047)	Loss 0.6001 (0.5281)	Prec@1 79.688 (81.666)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.033 (0.034)	BT: 0.056 (0.049)	Loss 0.4773 (0.5263)	Prec@1 82.812 (81.727)	
Total train loss: 0.5264
Avg Loading time: 0.0338 seconds
Avg Batch time: 0.0492 seconds

Train time: 19.478675603866577
 * Prec@1 79.670 Prec@5 99.170 Loss 0.5801
Avg Loading time: 0.0528 seconds
Avg Batch time: 0.0620 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 5.154198408126831

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.052)	BT: 0.016 (0.071)	Loss 0.5923 (0.5283)	Prec@1 82.031 (82.021)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.045)	BT: 0.024 (0.063)	Loss 0.4978 (0.5258)	Prec@1 79.688 (81.856)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.038)	BT: 0.013 (0.056)	Loss 0.5107 (0.5267)	Prec@1 82.031 (81.851)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.040)	BT: 0.031 (0.057)	Loss 0.6362 (0.5270)	Prec@1 78.906 (81.771)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.037)	BT: 0.007 (0.055)	Loss 0.5518 (0.5283)	Prec@1 75.000 (81.645)	
Total train loss: 0.5280
Avg Loading time: 0.0373 seconds
Avg Batch time: 0.0549 seconds

Train time: 21.689875602722168
 * Prec@1 79.560 Prec@5 99.180 Loss 0.5796
Avg Loading time: 0.0517 seconds
Avg Batch time: 0.0596 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.93442702293396

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.025)	BT: 0.010 (0.039)	Loss 0.5962 (0.5320)	Prec@1 79.688 (81.440)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.001 (0.026)	BT: 0.026 (0.040)	Loss 0.7153 (0.5283)	Prec@1 76.562 (81.545)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.028)	BT: 0.021 (0.044)	Loss 0.4885 (0.5300)	Prec@1 82.031 (81.427)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.030)	BT: 0.020 (0.046)	Loss 0.5776 (0.5299)	Prec@1 80.469 (81.510)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.030)	BT: 0.012 (0.047)	Loss 0.6104 (0.5288)	Prec@1 81.250 (81.567)	
Total train loss: 0.5287
Avg Loading time: 0.0304 seconds
Avg Batch time: 0.0466 seconds

Train time: 18.464327096939087
 * Prec@1 79.690 Prec@5 99.200 Loss 0.5801
Avg Loading time: 0.0541 seconds
Avg Batch time: 0.0627 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 5.176192760467529

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.048)	BT: 0.010 (0.065)	Loss 0.4844 (0.5267)	Prec@1 85.156 (81.701)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.043)	BT: 0.016 (0.061)	Loss 0.3723 (0.5241)	Prec@1 89.844 (81.921)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.042)	BT: 0.010 (0.060)	Loss 0.7534 (0.5238)	Prec@1 72.656 (81.808)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.038)	BT: 0.020 (0.055)	Loss 0.5898 (0.5259)	Prec@1 78.125 (81.718)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.035)	BT: 0.007 (0.052)	Loss 0.7100 (0.5257)	Prec@1 75.000 (81.755)	
Total train loss: 0.5260
Avg Loading time: 0.0347 seconds
Avg Batch time: 0.0523 seconds

Train time: 20.634108781814575
 * Prec@1 79.770 Prec@5 99.130 Loss 0.5801
Avg Loading time: 0.0558 seconds
Avg Batch time: 0.0643 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 5.29337477684021

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.026)	BT: 0.006 (0.038)	Loss 0.5410 (0.5363)	Prec@1 78.125 (81.571)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.029)	BT: 0.014 (0.043)	Loss 0.4768 (0.5304)	Prec@1 83.594 (81.636)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.031)	BT: 0.008 (0.045)	Loss 0.6191 (0.5320)	Prec@1 79.688 (81.530)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.106 (0.031)	BT: 0.121 (0.047)	Loss 0.7432 (0.5286)	Prec@1 77.344 (81.648)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.033)	BT: 0.014 (0.049)	Loss 0.5767 (0.5279)	Prec@1 81.250 (81.667)	
Total train loss: 0.5279
Avg Loading time: 0.0329 seconds
Avg Batch time: 0.0485 seconds

Train time: 19.177018404006958
 * Prec@1 79.530 Prec@5 99.200 Loss 0.5806
Avg Loading time: 0.0504 seconds
Avg Batch time: 0.0600 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.989670753479004

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.044)	BT: 0.014 (0.063)	Loss 0.4814 (0.5208)	Prec@1 82.812 (81.641)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.038)	BT: 0.015 (0.055)	Loss 0.5264 (0.5256)	Prec@1 78.906 (81.560)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.039)	BT: 0.013 (0.053)	Loss 0.4512 (0.5244)	Prec@1 80.469 (81.734)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.037)	BT: 0.006 (0.050)	Loss 0.4485 (0.5249)	Prec@1 83.594 (81.763)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.036)	BT: 0.004 (0.048)	Loss 0.3918 (0.5262)	Prec@1 89.844 (81.737)	
Total train loss: 0.5264
Avg Loading time: 0.0354 seconds
Avg Batch time: 0.0480 seconds

Train time: 18.92637324333191
 * Prec@1 79.600 Prec@5 99.160 Loss 0.5811
Avg Loading time: 0.0499 seconds
Avg Batch time: 0.0567 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.698462963104248

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.052 (0.031)	BT: 0.058 (0.039)	Loss 0.5640 (0.5130)	Prec@1 79.688 (81.751)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.026)	BT: 0.005 (0.033)	Loss 0.5259 (0.5252)	Prec@1 82.812 (81.490)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.025)	BT: 0.006 (0.034)	Loss 0.5454 (0.5282)	Prec@1 80.469 (81.454)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.027)	BT: 0.006 (0.036)	Loss 0.5400 (0.5288)	Prec@1 80.469 (81.525)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.028)	BT: 0.005 (0.038)	Loss 0.4414 (0.5267)	Prec@1 85.938 (81.629)	
Total train loss: 0.5267
Avg Loading time: 0.0279 seconds
Avg Batch time: 0.0375 seconds

Train time: 14.889687061309814
 * Prec@1 79.430 Prec@5 99.180 Loss 0.5806
Avg Loading time: 0.0418 seconds
Avg Batch time: 0.0493 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.123509883880615

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.051)	BT: 0.009 (0.062)	Loss 0.5093 (0.5306)	Prec@1 81.250 (81.390)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.042)	BT: 0.013 (0.053)	Loss 0.5693 (0.5294)	Prec@1 83.594 (81.475)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.040)	BT: 0.006 (0.051)	Loss 0.5498 (0.5340)	Prec@1 82.031 (81.263)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.038)	BT: 0.005 (0.049)	Loss 0.5068 (0.5321)	Prec@1 81.250 (81.325)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.036)	BT: 0.006 (0.047)	Loss 0.5332 (0.5289)	Prec@1 80.469 (81.490)	
Total train loss: 0.5287
Avg Loading time: 0.0360 seconds
Avg Batch time: 0.0471 seconds

Train time: 18.62914776802063
 * Prec@1 79.640 Prec@5 99.150 Loss 0.5806
Avg Loading time: 0.0407 seconds
Avg Batch time: 0.0477 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.006890535354614

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.084 (0.039)	BT: 0.091 (0.049)	Loss 0.5298 (0.5266)	Prec@1 82.812 (81.751)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.031)	BT: 0.008 (0.039)	Loss 0.6274 (0.5238)	Prec@1 79.688 (81.791)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.033)	BT: 0.018 (0.042)	Loss 0.4976 (0.5237)	Prec@1 81.250 (81.714)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.030)	BT: 0.010 (0.039)	Loss 0.6587 (0.5250)	Prec@1 78.906 (81.728)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.141 (0.029)	BT: 0.154 (0.038)	Loss 0.6309 (0.5238)	Prec@1 78.125 (81.723)	
Total train loss: 0.5247
Avg Loading time: 0.0291 seconds
Avg Batch time: 0.0380 seconds

Train time: 15.08971881866455
 * Prec@1 79.470 Prec@5 99.130 Loss 0.5830
Avg Loading time: 0.0467 seconds
Avg Batch time: 0.0531 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.4200825691223145

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.049)	BT: 0.019 (0.061)	Loss 0.6870 (0.5133)	Prec@1 78.125 (81.651)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.042)	BT: 0.005 (0.055)	Loss 0.3818 (0.5174)	Prec@1 91.406 (81.761)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.247 (0.040)	BT: 0.260 (0.051)	Loss 0.4812 (0.5242)	Prec@1 79.688 (81.617)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.037)	BT: 0.007 (0.049)	Loss 0.5239 (0.5245)	Prec@1 81.250 (81.691)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.036)	BT: 0.014 (0.048)	Loss 0.4463 (0.5259)	Prec@1 84.375 (81.737)	
Total train loss: 0.5258
Avg Loading time: 0.0364 seconds
Avg Batch time: 0.0484 seconds

Train time: 19.134297370910645
 * Prec@1 79.390 Prec@5 99.160 Loss 0.5820
Avg Loading time: 0.0441 seconds
Avg Batch time: 0.0523 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.338073253631592

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.046)	BT: 0.016 (0.057)	Loss 0.5396 (0.5328)	Prec@1 79.688 (81.621)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.039)	BT: 0.005 (0.051)	Loss 0.6128 (0.5231)	Prec@1 78.125 (81.926)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.112 (0.033)	BT: 0.117 (0.044)	Loss 0.6216 (0.5262)	Prec@1 77.344 (81.747)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.021 (0.033)	BT: 0.026 (0.043)	Loss 0.6392 (0.5275)	Prec@1 79.688 (81.686)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.033)	BT: 0.012 (0.043)	Loss 0.6440 (0.5266)	Prec@1 78.125 (81.645)	
Total train loss: 0.5265
Avg Loading time: 0.0333 seconds
Avg Batch time: 0.0431 seconds

Train time: 16.984752416610718
 * Prec@1 79.590 Prec@5 99.160 Loss 0.5815
Avg Loading time: 0.0351 seconds
Avg Batch time: 0.0414 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 3.502741813659668

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.044)	BT: 0.028 (0.056)	Loss 0.3867 (0.5331)	Prec@1 85.938 (82.021)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.036)	BT: 0.013 (0.048)	Loss 0.4856 (0.5354)	Prec@1 81.250 (81.701)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.039)	BT: 0.010 (0.050)	Loss 0.5020 (0.5272)	Prec@1 81.250 (81.911)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.024 (0.037)	BT: 0.038 (0.049)	Loss 0.4500 (0.5275)	Prec@1 84.375 (81.843)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.035)	BT: 0.005 (0.047)	Loss 0.5811 (0.5264)	Prec@1 79.688 (81.841)	
Total train loss: 0.5268
Avg Loading time: 0.0348 seconds
Avg Batch time: 0.0466 seconds

Train time: 18.443342924118042
 * Prec@1 79.670 Prec@5 99.170 Loss 0.5791
Avg Loading time: 0.0448 seconds
Avg Batch time: 0.0520 seconds

Best acc: 79.940
--------------------------------------------------------------------------------
Test time: 4.353760004043579

