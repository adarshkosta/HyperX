
      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 3
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/train/relu3
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/test/relu3
ResNet18(
  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu4): ReLU(inplace=True)
  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu5): ReLU(inplace=True)
  (conv6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv1): Sequential(
    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu6): ReLU(inplace=True)
  (conv7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu7): ReLU(inplace=True)
  (conv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 9.660 Prec@5 49.980 Loss 2.3047
Avg Loading time: 4.5698 seconds
Avg Batch time: 4.6190 seconds

Pre-trained Prec@1 with 3 layers frozen: 9.65999984741211 	 Loss: 2.3046875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.01	DT: 0.000 (4.783)	BT: 0.093 (4.882)	Loss 0.5410 (0.8424)	Prec@1 83.594 (77.885)	
Epoch: [0][155/391]	LR: 0.01	DT: 0.000 (4.714)	BT: 0.080 (4.810)	Loss 0.3894 (0.6428)	Prec@1 89.844 (83.373)	
Epoch: [0][233/391]	LR: 0.01	DT: 4.382 (4.464)	BT: 4.486 (4.559)	Loss 0.4304 (0.5422)	Prec@1 85.938 (85.821)	
Epoch: [0][311/391]	LR: 0.01	DT: 0.000 (4.132)	BT: 0.081 (4.227)	Loss 0.3279 (0.4818)	Prec@1 90.625 (87.300)	
Epoch: [0][389/391]	LR: 0.01	DT: 0.000 (3.992)	BT: 0.087 (4.087)	Loss 0.2649 (0.4426)	Prec@1 92.969 (88.191)	
Total train loss: 0.4424
Avg Loading time: 3.9818 seconds
Avg Batch time: 4.0771 seconds

Train time: 1594.2760498523712
 * Prec@1 92.570 Prec@5 99.810 Loss 0.2583
Avg Loading time: 3.3925 seconds
Avg Batch time: 3.4283 seconds

Best acc: 92.570
--------------------------------------------------------------------------------
Test time: 272.9957435131073

Epoch: [1][77/391]	LR: 0.01	DT: 0.292 (1.756)	BT: 0.380 (1.844)	Loss 0.1208 (0.1627)	Prec@1 96.875 (96.164)	
Epoch: [1][155/391]	LR: 0.01	DT: 0.000 (1.768)	BT: 0.077 (1.856)	Loss 0.1598 (0.1574)	Prec@1 96.875 (96.239)	
Epoch: [1][233/391]	LR: 0.01	DT: 0.043 (1.373)	BT: 0.124 (1.463)	Loss 0.1689 (0.1574)	Prec@1 92.188 (96.107)	
Epoch: [1][311/391]	LR: 0.01	DT: 0.000 (1.530)	BT: 0.088 (1.621)	Loss 0.1600 (0.1571)	Prec@1 94.531 (96.036)	
Epoch: [1][389/391]	LR: 0.01	DT: 0.000 (1.420)	BT: 0.075 (1.512)	Loss 0.1854 (0.1573)	Prec@1 96.094 (95.899)	
Total train loss: 0.1573
Avg Loading time: 1.4164 seconds
Avg Batch time: 1.5082 seconds

Train time: 589.8529274463654
 * Prec@1 93.210 Prec@5 99.830 Loss 0.2192
Avg Loading time: 0.9018 seconds
Avg Batch time: 0.9376 seconds

Best acc: 93.210
--------------------------------------------------------------------------------
Test time: 75.2821946144104

Epoch: [2][77/391]	LR: 0.01	DT: 1.715 (0.838)	BT: 1.819 (0.928)	Loss 0.1174 (0.0836)	Prec@1 97.656 (98.397)	
Epoch: [2][155/391]	LR: 0.01	DT: 0.000 (0.893)	BT: 0.081 (0.984)	Loss 0.0531 (0.0782)	Prec@1 100.000 (98.558)	
Epoch: [2][233/391]	LR: 0.01	DT: 2.144 (0.976)	BT: 2.248 (1.068)	Loss 0.0622 (0.0763)	Prec@1 99.219 (98.608)	
Epoch: [2][311/391]	LR: 0.01	DT: 0.000 (1.082)	BT: 0.079 (1.175)	Loss 0.0502 (0.0754)	Prec@1 98.438 (98.603)	
Epoch: [2][389/391]	LR: 0.01	DT: 2.260 (1.236)	BT: 2.364 (1.328)	Loss 0.0535 (0.0759)	Prec@1 99.219 (98.566)	
Total train loss: 0.0759
Avg Loading time: 1.2326 seconds
Avg Batch time: 1.3249 seconds

Train time: 518.1710007190704
 * Prec@1 93.820 Prec@5 99.810 Loss 0.2006
Avg Loading time: 2.0572 seconds
Avg Batch time: 2.0936 seconds

Best acc: 93.820
--------------------------------------------------------------------------------
Test time: 166.6376829147339

Epoch: [3][77/391]	LR: 0.01	DT: 1.029 (1.494)	BT: 1.115 (1.587)	Loss 0.0464 (0.0445)	Prec@1 99.219 (99.569)	
Epoch: [3][155/391]	LR: 0.01	DT: 0.000 (1.627)	BT: 0.090 (1.717)	Loss 0.0757 (0.0442)	Prec@1 98.438 (99.554)	
Epoch: [3][233/391]	LR: 0.01	DT: 7.065 (1.783)	BT: 7.163 (1.872)	Loss 0.0585 (0.0434)	Prec@1 99.219 (99.579)	
Epoch: [3][311/391]	LR: 0.01	DT: 0.000 (1.736)	BT: 0.082 (1.825)	Loss 0.0600 (0.0424)	Prec@1 99.219 (99.577)	
Epoch: [3][389/391]	LR: 0.01	DT: 0.000 (1.799)	BT: 0.079 (1.889)	Loss 0.0340 (0.0421)	Prec@1 100.000 (99.567)	
Total train loss: 0.0421
Avg Loading time: 1.7947 seconds
Avg Batch time: 1.8840 seconds

Train time: 736.7989764213562
 * Prec@1 94.610 Prec@5 99.750 Loss 0.1862
Avg Loading time: 0.7387 seconds
Avg Batch time: 0.7809 seconds

Best acc: 94.610
--------------------------------------------------------------------------------
Test time: 62.90159893035889

Epoch: [4][77/391]	LR: 0.01	DT: 0.000 (0.551)	BT: 0.079 (0.645)	Loss 0.0228 (0.0289)	Prec@1 100.000 (99.920)	
Epoch: [4][155/391]	LR: 0.01	DT: 0.000 (0.585)	BT: 0.100 (0.678)	Loss 0.0212 (0.0286)	Prec@1 100.000 (99.910)	
Epoch: [4][233/391]	LR: 0.01	DT: 0.000 (0.659)	BT: 0.127 (0.751)	Loss 0.0264 (0.0292)	Prec@1 100.000 (99.876)	
Epoch: [4][311/391]	LR: 0.01	DT: 0.000 (0.743)	BT: 0.082 (0.834)	Loss 0.0274 (0.0285)	Prec@1 100.000 (99.890)	
Epoch: [4][389/391]	LR: 0.01	DT: 0.000 (0.881)	BT: 0.076 (0.971)	Loss 0.0214 (0.0285)	Prec@1 100.000 (99.898)	
Total train loss: 0.0285
Avg Loading time: 0.8786 seconds
Avg Batch time: 0.9685 seconds

Train time: 378.83151936531067
 * Prec@1 94.870 Prec@5 99.780 Loss 0.1747
Avg Loading time: 1.5692 seconds
Avg Batch time: 1.6077 seconds

Best acc: 94.870
--------------------------------------------------------------------------------
Test time: 128.39771175384521

Epoch: [5][77/391]	LR: 0.01	DT: 0.000 (1.391)	BT: 0.081 (1.480)	Loss 0.0292 (0.0238)	Prec@1 100.000 (99.970)	
Epoch: [5][155/391]	LR: 0.01	DT: 0.000 (1.427)	BT: 0.083 (1.516)	Loss 0.0206 (0.0229)	Prec@1 100.000 (99.975)	
Epoch: [5][233/391]	LR: 0.01	DT: 2.132 (1.555)	BT: 2.244 (1.644)	Loss 0.0267 (0.0225)	Prec@1 100.000 (99.970)	
Epoch: [5][311/391]	LR: 0.01	DT: 0.000 (1.606)	BT: 0.079 (1.695)	Loss 0.0312 (0.0225)	Prec@1 100.000 (99.967)	
Epoch: [5][389/391]	LR: 0.01	DT: 0.000 (1.756)	BT: 0.080 (1.846)	Loss 0.0182 (0.0230)	Prec@1 100.000 (99.950)	
Total train loss: 0.0230
Avg Loading time: 1.7519 seconds
Avg Batch time: 1.8415 seconds

Train time: 720.1853046417236
 * Prec@1 94.960 Prec@5 99.800 Loss 0.1714
Avg Loading time: 1.2457 seconds
Avg Batch time: 1.2846 seconds

Best acc: 94.960
--------------------------------------------------------------------------------
Test time: 102.64609599113464

Epoch: [6][77/391]	LR: 0.01	DT: 0.000 (1.531)	BT: 0.091 (1.622)	Loss 0.0140 (0.0211)	Prec@1 100.000 (99.970)	
Epoch: [6][155/391]	LR: 0.01	DT: 0.000 (1.455)	BT: 0.076 (1.548)	Loss 0.0164 (0.0204)	Prec@1 100.000 (99.980)	
Epoch: [6][233/391]	LR: 0.01	DT: 0.000 (1.381)	BT: 0.090 (1.474)	Loss 0.0214 (0.0208)	Prec@1 100.000 (99.967)	
Epoch: [6][311/391]	LR: 0.01	DT: 0.000 (1.489)	BT: 0.084 (1.582)	Loss 0.0262 (0.0210)	Prec@1 100.000 (99.957)	
Epoch: [6][389/391]	LR: 0.01	DT: 0.000 (1.647)	BT: 0.087 (1.741)	Loss 0.0191 (0.0208)	Prec@1 100.000 (99.964)	
Total train loss: 0.0208
Avg Loading time: 1.6433 seconds
Avg Batch time: 1.7363 seconds

Train time: 679.008636713028
 * Prec@1 95.170 Prec@5 99.820 Loss 0.1696
Avg Loading time: 1.8005 seconds
Avg Batch time: 1.8398 seconds

Best acc: 95.170
--------------------------------------------------------------------------------
Test time: 146.66254210472107

Epoch: [7][77/391]	LR: 0.01	DT: 0.000 (1.379)	BT: 0.081 (1.468)	Loss 0.0324 (0.0201)	Prec@1 99.219 (99.960)	
Epoch: [7][155/391]	LR: 0.01	DT: 0.000 (1.433)	BT: 0.082 (1.522)	Loss 0.0150 (0.0191)	Prec@1 100.000 (99.975)	
Epoch: [7][233/391]	LR: 0.01	DT: 0.000 (1.544)	BT: 0.091 (1.633)	Loss 0.0349 (0.0190)	Prec@1 99.219 (99.977)	
Epoch: [7][311/391]	LR: 0.01	DT: 0.000 (1.611)	BT: 0.081 (1.700)	Loss 0.0203 (0.0192)	Prec@1 100.000 (99.972)	
Epoch: [7][389/391]	LR: 0.01	DT: 0.000 (1.785)	BT: 0.087 (1.873)	Loss 0.0141 (0.0192)	Prec@1 100.000 (99.972)	
Total train loss: 0.0192
Avg Loading time: 1.7802 seconds
Avg Batch time: 1.8688 seconds

Train time: 730.8613982200623
 * Prec@1 95.090 Prec@5 99.800 Loss 0.1708
Avg Loading time: 1.0932 seconds
Avg Batch time: 1.1369 seconds

Best acc: 95.170
--------------------------------------------------------------------------------
Test time: 90.50314211845398

Epoch: [8][77/391]	LR: 0.01	DT: 0.000 (1.694)	BT: 0.083 (1.786)	Loss 0.0205 (0.0181)	Prec@1 100.000 (99.990)	
Epoch: [8][155/391]	LR: 0.01	DT: 0.000 (1.453)	BT: 0.085 (1.543)	Loss 0.0219 (0.0178)	Prec@1 100.000 (99.995)	
Epoch: [8][233/391]	LR: 0.01	DT: 0.000 (1.360)	BT: 0.094 (1.450)	Loss 0.0145 (0.0178)	Prec@1 100.000 (99.993)	
Epoch: [8][311/391]	LR: 0.01	DT: 0.000 (1.449)	BT: 0.081 (1.538)	Loss 0.0138 (0.0177)	Prec@1 100.000 (99.992)	
Epoch: [8][389/391]	LR: 0.01	DT: 0.000 (1.637)	BT: 0.080 (1.726)	Loss 0.0165 (0.0176)	Prec@1 100.000 (99.994)	
Total train loss: 0.0176
Avg Loading time: 1.6333 seconds
Avg Batch time: 1.7222 seconds

Train time: 673.4865202903748
 * Prec@1 95.120 Prec@5 99.810 Loss 0.1700
Avg Loading time: 2.1021 seconds
Avg Batch time: 2.1413 seconds

Best acc: 95.170
--------------------------------------------------------------------------------
Test time: 169.8597674369812

Epoch: [9][77/391]	LR: 0.01	DT: 0.484 (1.427)	BT: 0.575 (1.521)	Loss 0.0122 (0.0168)	Prec@1 100.000 (100.000)	
Epoch: [9][155/391]	LR: 0.01	DT: 0.000 (1.499)	BT: 0.095 (1.594)	Loss 0.0167 (0.0161)	Prec@1 100.000 (100.000)	
Epoch: [9][233/391]	LR: 0.01	DT: 14.667 (1.610)	BT: 14.766 (1.703)	Loss 0.0251 (0.0163)	Prec@1 100.000 (100.000)	
Epoch: [9][311/391]	LR: 0.01	DT: 0.000 (1.722)	BT: 0.082 (1.814)	Loss 0.0119 (0.0163)	Prec@1 100.000 (99.997)	
Epoch: [9][389/391]	LR: 0.01	DT: 0.000 (1.921)	BT: 0.081 (2.013)	Loss 0.0166 (0.0162)	Prec@1 100.000 (99.996)	
Total train loss: 0.0162
Avg Loading time: 1.9162 seconds
Avg Batch time: 2.0082 seconds

Train time: 785.3452534675598
 * Prec@1 95.070 Prec@5 99.800 Loss 0.1715
Avg Loading time: 1.3094 seconds
Avg Batch time: 1.3477 seconds

Best acc: 95.170
--------------------------------------------------------------------------------
Test time: 107.17643189430237

Epoch: [10][77/391]	LR: 0.002	DT: 0.000 (2.607)	BT: 0.085 (2.698)	Loss 0.0132 (0.0156)	Prec@1 100.000 (99.990)	
Epoch: [10][155/391]	LR: 0.002	DT: 0.113 (1.918)	BT: 0.203 (2.009)	Loss 0.0127 (0.0155)	Prec@1 100.000 (99.995)	
Epoch: [10][233/391]	LR: 0.002	DT: 0.798 (1.668)	BT: 0.901 (1.760)	Loss 0.0178 (0.0159)	Prec@1 100.000 (99.993)	
Epoch: [10][311/391]	LR: 0.002	DT: 0.000 (1.664)	BT: 0.081 (1.755)	Loss 0.0151 (0.0158)	Prec@1 100.000 (99.995)	
Epoch: [10][389/391]	LR: 0.002	DT: 0.000 (1.796)	BT: 0.081 (1.886)	Loss 0.0132 (0.0157)	Prec@1 100.000 (99.994)	
Total train loss: 0.0157
Avg Loading time: 1.7911 seconds
Avg Batch time: 1.8818 seconds

Train time: 735.9435791969299
 * Prec@1 95.030 Prec@5 99.770 Loss 0.1715
Avg Loading time: 2.2852 seconds
Avg Batch time: 2.3264 seconds

Best acc: 95.170
--------------------------------------------------------------------------------
Test time: 184.52041673660278

Epoch: [11][77/391]	LR: 0.002	DT: 0.000 (2.247)	BT: 0.076 (2.337)	Loss 0.0118 (0.0155)	Prec@1 100.000 (100.000)	
Epoch: [11][155/391]	LR: 0.002	DT: 1.915 (2.405)	BT: 2.014 (2.495)	Loss 0.0132 (0.0158)	Prec@1 100.000 (99.995)	
Epoch: [11][233/391]	LR: 0.002	DT: 0.000 (2.615)	BT: 0.092 (2.706)	Loss 0.0120 (0.0159)	Prec@1 100.000 (99.990)	
Epoch: [11][311/391]	LR: 0.002	DT: 0.000 (2.736)	BT: 0.076 (2.827)	Loss 0.0139 (0.0159)	Prec@1 100.000 (99.992)	
Epoch: [11][389/391]	LR: 0.002	DT: 0.000 (2.716)	BT: 0.074 (2.806)	Loss 0.0110 (0.0160)	Prec@1 100.000 (99.990)	
Total train loss: 0.0160
Avg Loading time: 2.7086 seconds
Avg Batch time: 2.7992 seconds

Train time: 1094.638842344284
 * Prec@1 95.070 Prec@5 99.800 Loss 0.1691
Avg Loading time: 3.0239 seconds
Avg Batch time: 3.0608 seconds

Best acc: 95.170
--------------------------------------------------------------------------------
Test time: 242.61914539337158

Epoch: [12][77/391]	LR: 0.002	DT: 0.000 (1.179)	BT: 0.085 (1.269)	Loss 0.0128 (0.0157)	Prec@1 100.000 (99.990)	
Epoch: [12][155/391]	LR: 0.002	DT: 0.000 (1.406)	BT: 0.095 (1.497)	Loss 0.0235 (0.0158)	Prec@1 100.000 (99.985)	
Epoch: [12][233/391]	LR: 0.002	DT: 8.040 (1.690)	BT: 8.143 (1.782)	Loss 0.0114 (0.0158)	Prec@1 100.000 (99.987)	
Epoch: [12][311/391]	LR: 0.002	DT: 0.000 (1.857)	BT: 0.082 (1.950)	Loss 0.0097 (0.0159)	Prec@1 100.000 (99.990)	
Epoch: [12][389/391]	LR: 0.002	DT: 0.000 (2.007)	BT: 0.086 (2.101)	Loss 0.0171 (0.0156)	Prec@1 100.000 (99.992)	
Total train loss: 0.0156
Avg Loading time: 2.0018 seconds
Avg Batch time: 2.0954 seconds

Train time: 819.4440312385559
 * Prec@1 95.100 Prec@5 99.790 Loss 0.1702
Avg Loading time: 3.1734 seconds
Avg Batch time: 3.2120 seconds

Best acc: 95.170
--------------------------------------------------------------------------------
Test time: 254.5018265247345

Epoch: [13][77/391]	LR: 0.002	DT: 0.000 (1.820)	BT: 0.080 (1.914)	Loss 0.0153 (0.0155)	Prec@1 100.000 (99.990)	
Epoch: [13][155/391]	LR: 0.002	DT: 0.000 (1.942)	BT: 0.081 (2.035)	Loss 0.0144 (0.0153)	Prec@1 100.000 (99.995)	
Epoch: [13][233/391]	LR: 0.002	DT: 6.965 (2.091)	BT: 7.072 (2.183)	Loss 0.0110 (0.0151)	Prec@1 100.000 (99.997)	
Epoch: [13][311/391]	LR: 0.002	DT: 0.000 (2.047)	BT: 0.082 (2.139)	Loss 0.0127 (0.0151)	Prec@1 100.000 (99.995)	
Epoch: [13][389/391]	LR: 0.002	DT: 0.000 (2.164)	BT: 0.079 (2.255)	Loss 0.0137 (0.0152)	Prec@1 100.000 (99.996)	
Total train loss: 0.0152
Avg Loading time: 2.1583 seconds
Avg Batch time: 2.2498 seconds

Train time: 879.8391754627228
 * Prec@1 95.050 Prec@5 99.790 Loss 0.1709
Avg Loading time: 1.7707 seconds
Avg Batch time: 1.8097 seconds

Best acc: 95.170
--------------------------------------------------------------------------------
Test time: 143.72826027870178

Epoch: [14][77/391]	LR: 0.002	DT: 0.000 (1.060)	BT: 0.083 (1.149)	Loss 0.0121 (0.0146)	Prec@1 100.000 (100.000)	
Epoch: [14][155/391]	LR: 0.002	DT: 0.000 (1.182)	BT: 0.096 (1.271)	Loss 0.0148 (0.0146)	Prec@1 100.000 (100.000)	
Epoch: [14][233/391]	LR: 0.002	DT: 0.000 (1.329)	BT: 0.096 (1.419)	Loss 0.0117 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [14][311/391]	LR: 0.002	DT: 0.000 (1.445)	BT: 0.076 (1.534)	Loss 0.0118 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [14][389/391]	LR: 0.002	DT: 0.000 (1.620)	BT: 0.076 (1.709)	Loss 0.0129 (0.0149)	Prec@1 100.000 (100.000)	
Total train loss: 0.0149
Avg Loading time: 1.6156 seconds
Avg Batch time: 1.7043 seconds

Train time: 666.5300328731537
 * Prec@1 95.130 Prec@5 99.810 Loss 0.1703
Avg Loading time: 2.3053 seconds
Avg Batch time: 2.3412 seconds

Best acc: 95.170
--------------------------------------------------------------------------------
Test time: 185.71090364456177

Epoch: [15][77/391]	LR: 0.002	DT: 0.774 (1.763)	BT: 0.864 (1.849)	Loss 0.0125 (0.0142)	Prec@1 100.000 (99.990)	
Epoch: [15][155/391]	LR: 0.002	DT: 0.000 (1.879)	BT: 0.086 (1.966)	Loss 0.0144 (0.0148)	Prec@1 100.000 (99.990)	
Epoch: [15][233/391]	LR: 0.002	DT: 4.623 (1.731)	BT: 4.725 (1.818)	Loss 0.0173 (0.0149)	Prec@1 100.000 (99.993)	
Epoch: [15][311/391]	LR: 0.002	DT: 0.000 (1.814)	BT: 0.083 (1.902)	Loss 0.0128 (0.0148)	Prec@1 100.000 (99.995)	
Epoch: [15][389/391]	LR: 0.002	DT: 0.000 (1.823)	BT: 0.087 (1.912)	Loss 0.0159 (0.0149)	Prec@1 100.000 (99.996)	
Total train loss: 0.0149
Avg Loading time: 1.8180 seconds
Avg Batch time: 1.9070 seconds

Train time: 745.79177069664
 * Prec@1 95.090 Prec@5 99.790 Loss 0.1718
Avg Loading time: 1.1474 seconds
Avg Batch time: 1.1857 seconds

Best acc: 95.170
--------------------------------------------------------------------------------
Test time: 94.34869718551636

Epoch: [16][77/391]	LR: 0.002	DT: 0.000 (1.000)	BT: 0.079 (1.090)	Loss 0.0113 (0.0147)	Prec@1 100.000 (100.000)	
Epoch: [16][155/391]	LR: 0.002	DT: 0.000 (1.056)	BT: 0.082 (1.145)	Loss 0.0128 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [16][233/391]	LR: 0.002	DT: 0.000 (1.162)	BT: 0.090 (1.250)	Loss 0.0261 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [16][311/391]	LR: 0.002	DT: 0.000 (1.249)	BT: 0.081 (1.337)	Loss 0.0164 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [16][389/391]	LR: 0.002	DT: 0.000 (1.364)	BT: 0.080 (1.452)	Loss 0.0124 (0.0152)	Prec@1 100.000 (100.000)	
Total train loss: 0.0152
Avg Loading time: 1.3606 seconds
Avg Batch time: 1.4483 seconds

Train time: 566.4148168563843
 * Prec@1 95.040 Prec@5 99.780 Loss 0.1699
Avg Loading time: 1.8421 seconds
Avg Batch time: 1.8807 seconds

Best acc: 95.170
--------------------------------------------------------------------------------
Test time: 149.3776445388794

Epoch: [17][77/391]	LR: 0.002	DT: 0.000 (1.626)	BT: 0.081 (1.719)	Loss 0.0144 (0.0148)	Prec@1 100.000 (100.000)	
Epoch: [17][155/391]	LR: 0.002	DT: 3.413 (1.646)	BT: 3.518 (1.740)	Loss 0.0101 (0.0152)	Prec@1 100.000 (99.995)	
Epoch: [17][233/391]	LR: 0.002	DT: 5.634 (1.758)	BT: 5.745 (1.853)	Loss 0.0128 (0.0154)	Prec@1 100.000 (99.993)	
Epoch: [17][311/391]	LR: 0.002	DT: 3.429 (1.995)	BT: 3.536 (2.090)	Loss 0.0196 (0.0155)	Prec@1 100.000 (99.992)	
Epoch: [17][389/391]	LR: 0.002	DT: 0.000 (2.220)	BT: 0.087 (2.315)	Loss 0.0159 (0.0153)	Prec@1 100.000 (99.994)	
Total train loss: 0.0153
Avg Loading time: 2.2139 seconds
Avg Batch time: 2.3087 seconds

Train time: 902.8387427330017
 * Prec@1 95.030 Prec@5 99.790 Loss 0.1711
Avg Loading time: 3.2484 seconds
Avg Batch time: 3.2866 seconds

Best acc: 95.170
--------------------------------------------------------------------------------
Test time: 260.3020439147949

Epoch: [18][77/391]	LR: 0.002	DT: 0.000 (2.841)	BT: 0.081 (2.931)	Loss 0.0113 (0.0155)	Prec@1 100.000 (99.980)	
Epoch: [18][155/391]	LR: 0.002	DT: 3.795 (3.102)	BT: 3.905 (3.194)	Loss 0.0129 (0.0152)	Prec@1 100.000 (99.990)	
Epoch: [18][233/391]	LR: 0.002	DT: 0.000 (3.058)	BT: 0.096 (3.153)	Loss 0.0102 (0.0153)	Prec@1 100.000 (99.987)	
Epoch: [18][311/391]	LR: 0.002	DT: 0.000 (2.818)	BT: 0.076 (2.912)	Loss 0.0183 (0.0155)	Prec@1 100.000 (99.987)	
Epoch: [18][389/391]	LR: 0.002	DT: 0.000 (2.764)	BT: 0.082 (2.858)	Loss 0.0175 (0.0154)	Prec@1 100.000 (99.988)	
Total train loss: 0.0154
Avg Loading time: 2.7570 seconds
Avg Batch time: 2.8510 seconds

Train time: 1114.9279906749725
 * Prec@1 95.120 Prec@5 99.810 Loss 0.1711
Avg Loading time: 3.4213 seconds
Avg Batch time: 3.4606 seconds

Best acc: 95.170
--------------------------------------------------------------------------------
Test time: 274.1414566040039

Epoch: [19][77/391]	LR: 0.002	DT: 0.000 (0.644)	BT: 0.082 (0.734)	Loss 0.0123 (0.0152)	Prec@1 100.000 (99.990)	
Epoch: [19][155/391]	LR: 0.002	DT: 0.000 (1.240)	BT: 0.084 (1.331)	Loss 0.0185 (0.0151)	Prec@1 100.000 (99.990)	
Epoch: [19][233/391]	LR: 0.002	DT: 0.000 (1.275)	BT: 0.088 (1.365)	Loss 0.0220 (0.0153)	Prec@1 100.000 (99.987)	
Epoch: [19][311/391]	LR: 0.002	DT: 0.000 (1.309)	BT: 0.073 (1.397)	Loss 0.0158 (0.0155)	Prec@1 100.000 (99.977)	
Epoch: [19][389/391]	LR: 0.002	DT: 0.000 (1.450)	BT: 0.076 (1.537)	Loss 0.0132 (0.0153)	Prec@1 100.000 (99.980)	
Total train loss: 0.0154
Avg Loading time: 1.4459 seconds
Avg Batch time: 1.5330 seconds

Train time: 599.5426819324493
 * Prec@1 95.100 Prec@5 99.790 Loss 0.1707
Avg Loading time: 1.5870 seconds
Avg Batch time: 1.6243 seconds

Best acc: 95.170
--------------------------------------------------------------------------------
Test time: 129.0447359085083

Epoch: [20][77/391]	LR: 0.0004	DT: 0.000 (1.359)	BT: 0.081 (1.449)	Loss 0.0139 (0.0148)	Prec@1 100.000 (100.000)	
Epoch: [20][155/391]	LR: 0.0004	DT: 0.039 (1.410)	BT: 0.120 (1.500)	Loss 0.0214 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [20][233/391]	LR: 0.0004	DT: 0.000 (1.524)	BT: 0.095 (1.612)	Loss 0.0112 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [20][311/391]	LR: 0.0004	DT: 0.000 (1.602)	BT: 0.082 (1.691)	Loss 0.0230 (0.0151)	Prec@1 100.000 (99.992)	
Epoch: [20][389/391]	LR: 0.0004	DT: 0.000 (1.766)	BT: 0.084 (1.855)	Loss 0.0134 (0.0151)	Prec@1 100.000 (99.994)	
Total train loss: 0.0151
Avg Loading time: 1.7615 seconds
Avg Batch time: 1.8503 seconds

Train time: 723.7411668300629
 * Prec@1 95.160 Prec@5 99.800 Loss 0.1704
Avg Loading time: 3.1461 seconds
Avg Batch time: 3.1862 seconds

Best acc: 95.170
--------------------------------------------------------------------------------
Test time: 252.52433609962463

Epoch: [21][77/391]	LR: 0.0004	DT: 0.906 (0.227)	BT: 1.012 (0.329)	Loss 0.0135 (0.0154)	Prec@1 100.000 (100.000)	
Epoch: [21][155/391]	LR: 0.0004	DT: 0.000 (0.711)	BT: 0.081 (0.811)	Loss 0.0138 (0.0150)	Prec@1 100.000 (99.995)	
Epoch: [21][233/391]	LR: 0.0004	DT: 0.000 (0.860)	BT: 0.088 (0.958)	Loss 0.0129 (0.0152)	Prec@1 100.000 (99.997)	
Epoch: [21][311/391]	LR: 0.0004	DT: 0.000 (0.976)	BT: 0.093 (1.073)	Loss 0.0109 (0.0151)	Prec@1 100.000 (99.995)	
Epoch: [21][389/391]	LR: 0.0004	DT: 0.175 (1.154)	BT: 0.269 (1.252)	Loss 0.0216 (0.0151)	Prec@1 100.000 (99.996)	
Total train loss: 0.0151
Avg Loading time: 1.1656 seconds
Avg Batch time: 1.2626 seconds

Train time: 493.81385803222656
 * Prec@1 95.160 Prec@5 99.780 Loss 0.1700
Avg Loading time: 1.9775 seconds
Avg Batch time: 2.0177 seconds

Best acc: 95.170
--------------------------------------------------------------------------------
Test time: 160.1197109222412

Epoch: [22][77/391]	LR: 0.0004	DT: 0.000 (1.541)	BT: 0.078 (1.632)	Loss 0.0156 (0.0148)	Prec@1 100.000 (99.990)	
Epoch: [22][155/391]	LR: 0.0004	DT: 0.000 (1.593)	BT: 0.096 (1.686)	Loss 0.0155 (0.0151)	Prec@1 100.000 (99.995)	
Epoch: [22][233/391]	LR: 0.0004	DT: 0.000 (1.585)	BT: 0.093 (1.677)	Loss 0.0159 (0.0153)	Prec@1 100.000 (99.990)	
Epoch: [22][311/391]	LR: 0.0004	DT: 0.000 (1.649)	BT: 0.079 (1.741)	Loss 0.0156 (0.0154)	Prec@1 100.000 (99.987)	
Epoch: [22][389/391]	LR: 0.0004	DT: 0.000 (1.794)	BT: 0.083 (1.886)	Loss 0.0110 (0.0152)	Prec@1 100.000 (99.990)	
Total train loss: 0.0152
Avg Loading time: 1.7895 seconds
Avg Batch time: 1.8811 seconds

Train time: 735.6062180995941
 * Prec@1 95.180 Prec@5 99.780 Loss 0.1699
Avg Loading time: 2.1790 seconds
Avg Batch time: 2.2200 seconds

Best acc: 95.180
--------------------------------------------------------------------------------
Test time: 176.6280038356781

Epoch: [23][77/391]	LR: 0.0004	DT: 0.000 (0.591)	BT: 0.117 (0.693)	Loss 0.0142 (0.0156)	Prec@1 100.000 (100.000)	
Epoch: [23][155/391]	LR: 0.0004	DT: 3.071 (0.904)	BT: 3.178 (1.001)	Loss 0.0137 (0.0157)	Prec@1 100.000 (100.000)	
Epoch: [23][233/391]	LR: 0.0004	DT: 0.000 (1.075)	BT: 0.093 (1.172)	Loss 0.0161 (0.0156)	Prec@1 100.000 (100.000)	
Epoch: [23][311/391]	LR: 0.0004	DT: 0.000 (1.134)	BT: 0.081 (1.231)	Loss 0.0209 (0.0154)	Prec@1 100.000 (100.000)	
Epoch: [23][389/391]	LR: 0.0004	DT: 0.000 (1.265)	BT: 0.096 (1.363)	Loss 0.0099 (0.0152)	Prec@1 100.000 (100.000)	
Total train loss: 0.0152
Avg Loading time: 1.2622 seconds
Avg Batch time: 1.3595 seconds

Train time: 531.7184338569641
 * Prec@1 95.120 Prec@5 99.810 Loss 0.1698
Avg Loading time: 1.5385 seconds
Avg Batch time: 1.5780 seconds

Best acc: 95.180
--------------------------------------------------------------------------------
Test time: 125.36478471755981

Epoch: [24][77/391]	LR: 0.0004	DT: 0.000 (1.478)	BT: 0.096 (1.572)	Loss 0.0171 (0.0147)	Prec@1 100.000 (99.990)	
Epoch: [24][155/391]	LR: 0.0004	DT: 5.075 (1.618)	BT: 5.182 (1.712)	Loss 0.0165 (0.0151)	Prec@1 100.000 (99.990)	
Epoch: [24][233/391]	LR: 0.0004	DT: 0.000 (1.704)	BT: 0.094 (1.799)	Loss 0.0156 (0.0152)	Prec@1 100.000 (99.990)	
Epoch: [24][311/391]	LR: 0.0004	DT: 0.000 (1.857)	BT: 0.076 (1.950)	Loss 0.0153 (0.0154)	Prec@1 100.000 (99.992)	
Epoch: [24][389/391]	LR: 0.0004	DT: 0.000 (1.982)	BT: 0.090 (2.075)	Loss 0.0153 (0.0154)	Prec@1 100.000 (99.992)	
Total train loss: 0.0154
Avg Loading time: 1.9769 seconds
Avg Batch time: 2.0700 seconds

Train time: 809.506105184555
 * Prec@1 95.160 Prec@5 99.780 Loss 0.1708
Avg Loading time: 2.1656 seconds
Avg Batch time: 2.2052 seconds

Best acc: 95.180
--------------------------------------------------------------------------------
Test time: 174.9360888004303

Epoch: [25][77/391]	LR: 0.0004	DT: 2.431 (0.449)	BT: 2.534 (0.544)	Loss 0.0157 (0.0156)	Prec@1 100.000 (100.000)	
Epoch: [25][155/391]	LR: 0.0004	DT: 0.000 (0.901)	BT: 0.083 (0.996)	Loss 0.0159 (0.0155)	Prec@1 100.000 (99.995)	
Epoch: [25][233/391]	LR: 0.0004	DT: 0.000 (1.021)	BT: 0.090 (1.116)	Loss 0.0196 (0.0156)	Prec@1 100.000 (99.997)	
Epoch: [25][311/391]	LR: 0.0004	DT: 0.000 (1.125)	BT: 0.081 (1.219)	Loss 0.0111 (0.0154)	Prec@1 100.000 (99.992)	
Epoch: [25][389/391]	LR: 0.0004	DT: 0.363 (1.280)	BT: 0.452 (1.374)	Loss 0.0133 (0.0152)	Prec@1 100.000 (99.994)	
Total train loss: 0.0152
Avg Loading time: 1.2767 seconds
Avg Batch time: 1.3702 seconds

Train time: 535.8996450901031
 * Prec@1 95.080 Prec@5 99.780 Loss 0.1705
Avg Loading time: 1.4950 seconds
Avg Batch time: 1.5352 seconds

Best acc: 95.180
--------------------------------------------------------------------------------
Test time: 121.99501323699951

Epoch: [26][77/391]	LR: 0.0004	DT: 0.000 (1.295)	BT: 0.081 (1.388)	Loss 0.0158 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [26][155/391]	LR: 0.0004	DT: 0.000 (1.409)	BT: 0.082 (1.499)	Loss 0.0119 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [26][233/391]	LR: 0.0004	DT: 0.000 (1.669)	BT: 0.093 (1.758)	Loss 0.0113 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [26][311/391]	LR: 0.0004	DT: 0.000 (1.801)	BT: 0.083 (1.891)	Loss 0.0141 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [26][389/391]	LR: 0.0004	DT: 0.000 (1.948)	BT: 0.080 (2.039)	Loss 0.0154 (0.0152)	Prec@1 100.000 (99.998)	
Total train loss: 0.0152
Avg Loading time: 1.9430 seconds
Avg Batch time: 2.0339 seconds

Train time: 795.3654131889343
 * Prec@1 95.160 Prec@5 99.800 Loss 0.1704
Avg Loading time: 2.7826 seconds
Avg Batch time: 2.8215 seconds

Best acc: 95.180
--------------------------------------------------------------------------------
Test time: 223.69171047210693

Epoch: [27][77/391]	LR: 0.0004	DT: 0.000 (1.447)	BT: 0.110 (1.542)	Loss 0.0146 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [27][155/391]	LR: 0.0004	DT: 0.000 (1.293)	BT: 0.081 (1.388)	Loss 0.0147 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [27][233/391]	LR: 0.0004	DT: 0.000 (1.318)	BT: 0.093 (1.412)	Loss 0.0126 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [27][311/391]	LR: 0.0004	DT: 0.000 (1.412)	BT: 0.084 (1.506)	Loss 0.0260 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [27][389/391]	LR: 0.0004	DT: 0.000 (1.568)	BT: 0.088 (1.662)	Loss 0.0126 (0.0149)	Prec@1 100.000 (100.000)	
Total train loss: 0.0149
Avg Loading time: 1.5638 seconds
Avg Batch time: 1.6582 seconds

Train time: 648.5020906925201
 * Prec@1 95.060 Prec@5 99.790 Loss 0.1710
Avg Loading time: 1.8029 seconds
Avg Batch time: 1.8441 seconds

Best acc: 95.180
--------------------------------------------------------------------------------
Test time: 146.51738381385803

Epoch: [28][77/391]	LR: 0.0004	DT: 0.000 (1.440)	BT: 0.083 (1.529)	Loss 0.0146 (0.0153)	Prec@1 100.000 (99.990)	
Epoch: [28][155/391]	LR: 0.0004	DT: 0.000 (1.519)	BT: 0.079 (1.609)	Loss 0.0142 (0.0154)	Prec@1 100.000 (99.995)	
Epoch: [28][233/391]	LR: 0.0004	DT: 0.000 (1.633)	BT: 0.093 (1.722)	Loss 0.0121 (0.0153)	Prec@1 100.000 (99.993)	
Epoch: [28][311/391]	LR: 0.0004	DT: 0.000 (1.754)	BT: 0.098 (1.843)	Loss 0.0122 (0.0152)	Prec@1 100.000 (99.995)	
Epoch: [28][389/391]	LR: 0.0004	DT: 0.000 (1.988)	BT: 0.075 (2.076)	Loss 0.0142 (0.0151)	Prec@1 100.000 (99.996)	
Total train loss: 0.0151
Avg Loading time: 1.9826 seconds
Avg Batch time: 2.0713 seconds

Train time: 810.0018656253815
 * Prec@1 95.120 Prec@5 99.790 Loss 0.1707
Avg Loading time: 3.3343 seconds
Avg Batch time: 3.3741 seconds

Best acc: 95.180
--------------------------------------------------------------------------------
Test time: 267.274799823761

Epoch: [29][77/391]	LR: 0.0004	DT: 0.000 (0.938)	BT: 0.092 (1.036)	Loss 0.0179 (0.0146)	Prec@1 100.000 (100.000)	
Epoch: [29][155/391]	LR: 0.0004	DT: 0.000 (1.000)	BT: 0.081 (1.093)	Loss 0.0162 (0.0144)	Prec@1 100.000 (100.000)	
Epoch: [29][233/391]	LR: 0.0004	DT: 0.000 (1.140)	BT: 0.094 (1.231)	Loss 0.0121 (0.0146)	Prec@1 100.000 (99.997)	
Epoch: [29][311/391]	LR: 0.0004	DT: 0.000 (1.273)	BT: 0.083 (1.364)	Loss 0.0186 (0.0147)	Prec@1 100.000 (99.997)	
Epoch: [29][389/391]	LR: 0.0004	DT: 0.000 (1.474)	BT: 0.080 (1.565)	Loss 0.0198 (0.0147)	Prec@1 100.000 (99.998)	
Total train loss: 0.0147
Avg Loading time: 1.4701 seconds
Avg Batch time: 1.5609 seconds

Train time: 610.4881181716919
 * Prec@1 95.000 Prec@5 99.800 Loss 0.1715
Avg Loading time: 2.4203 seconds
Avg Batch time: 2.4601 seconds

Best acc: 95.180
--------------------------------------------------------------------------------
Test time: 195.1182770729065

Epoch: [30][77/391]	LR: 8e-05	DT: 0.000 (1.840)	BT: 0.081 (1.930)	Loss 0.0170 (0.0144)	Prec@1 100.000 (100.000)	
Epoch: [30][155/391]	LR: 8e-05	DT: 0.000 (1.857)	BT: 0.081 (1.947)	Loss 0.0151 (0.0152)	Prec@1 100.000 (99.995)	
Epoch: [30][233/391]	LR: 8e-05	DT: 0.000 (1.964)	BT: 0.094 (2.054)	Loss 0.0175 (0.0152)	Prec@1 100.000 (99.997)	
Epoch: [30][311/391]	LR: 8e-05	DT: 2.390 (1.936)	BT: 2.494 (2.027)	Loss 0.0102 (0.0150)	Prec@1 100.000 (99.997)	
Epoch: [30][389/391]	LR: 8e-05	DT: 0.000 (2.057)	BT: 0.080 (2.147)	Loss 0.0230 (0.0150)	Prec@1 100.000 (99.998)	
Total train loss: 0.0150
Avg Loading time: 2.0513 seconds
Avg Batch time: 2.1417 seconds

Train time: 837.5543880462646
 * Prec@1 95.180 Prec@5 99.770 Loss 0.1713
Avg Loading time: 2.3638 seconds
Avg Batch time: 2.4029 seconds

Best acc: 95.180
--------------------------------------------------------------------------------
Test time: 190.97662949562073

Epoch: [31][77/391]	LR: 8e-05	DT: 0.000 (1.024)	BT: 0.081 (1.115)	Loss 0.0129 (0.0155)	Prec@1 100.000 (100.000)	
Epoch: [31][155/391]	LR: 8e-05	DT: 0.000 (1.159)	BT: 0.082 (1.249)	Loss 0.0129 (0.0155)	Prec@1 100.000 (100.000)	
Epoch: [31][233/391]	LR: 8e-05	DT: 0.000 (1.336)	BT: 0.090 (1.425)	Loss 0.0172 (0.0156)	Prec@1 100.000 (100.000)	
Epoch: [31][311/391]	LR: 8e-05	DT: 0.000 (1.456)	BT: 0.082 (1.545)	Loss 0.0138 (0.0155)	Prec@1 100.000 (100.000)	
Epoch: [31][389/391]	LR: 8e-05	DT: 0.000 (1.617)	BT: 0.077 (1.706)	Loss 0.0164 (0.0153)	Prec@1 100.000 (100.000)	
Total train loss: 0.0153
Avg Loading time: 1.6129 seconds
Avg Batch time: 1.7021 seconds

Train time: 665.653092622757
 * Prec@1 95.140 Prec@5 99.790 Loss 0.1707
Avg Loading time: 2.3191 seconds
Avg Batch time: 2.3576 seconds

Best acc: 95.180
--------------------------------------------------------------------------------
Test time: 187.01739478111267

Epoch: [32][77/391]	LR: 8e-05	DT: 0.000 (1.707)	BT: 0.075 (1.800)	Loss 0.0138 (0.0142)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 8e-05	DT: 1.741 (1.819)	BT: 1.830 (1.912)	Loss 0.0161 (0.0144)	Prec@1 100.000 (100.000)	
Epoch: [32][233/391]	LR: 8e-05	DT: 4.312 (1.673)	BT: 4.418 (1.767)	Loss 0.0124 (0.0146)	Prec@1 100.000 (100.000)	
Epoch: [32][311/391]	LR: 8e-05	DT: 0.000 (1.717)	BT: 0.082 (1.812)	Loss 0.0135 (0.0145)	Prec@1 100.000 (99.997)	
Epoch: [32][389/391]	LR: 8e-05	DT: 0.210 (1.763)	BT: 0.304 (1.858)	Loss 0.0140 (0.0147)	Prec@1 100.000 (99.996)	
Total train loss: 0.0147
Avg Loading time: 1.7585 seconds
Avg Batch time: 1.8537 seconds

Train time: 724.9300303459167
