
      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: sram
          mode_test: sram
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 3
Savedir:  ../pretrained_models/frozen/x64-8b/sram/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/train/relu3
Test path:  /home/nano01/a/esoufler/activations/x64-8b/sram/one_batch/cifar10/resnet18/test/relu3
ResNet18(
  (conv4): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu4): ReLU(inplace=True)
  (conv5): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu5): ReLU(inplace=True)
  (conv6): QConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv1): Sequential(
    (0): QConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu6): ReLU(inplace=True)
  (conv7): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu7): ReLU(inplace=True)
  (conv8): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): QConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): QConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): QConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): QConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 9.600 Prec@5 49.950 Loss 2.3066
Avg Loading time: 7.3057 seconds
Avg Batch time: 7.3640 seconds

Pre-trained Prec@1 with 3 layers frozen: 9.59999942779541 	 Loss: 2.306640625

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.01	DT: 0.000 (11.186)	BT: 0.169 (11.365)	Loss 0.6567 (1.0137)	Prec@1 82.812 (72.506)	
Epoch: [0][155/391]	LR: 0.01	DT: 0.000 (11.118)	BT: 0.169 (11.299)	Loss 0.5581 (0.7963)	Prec@1 82.031 (78.516)	
Epoch: [0][233/391]	LR: 0.01	DT: 0.604 (10.701)	BT: 0.791 (10.884)	Loss 0.4329 (0.6845)	Prec@1 85.938 (81.377)	
Epoch: [0][311/391]	LR: 0.01	DT: 0.000 (10.168)	BT: 0.170 (10.351)	Loss 0.4495 (0.6177)	Prec@1 87.500 (83.023)	
Epoch: [0][389/391]	LR: 0.01	DT: 1.074 (9.603)	BT: 1.250 (9.785)	Loss 0.4370 (0.5792)	Prec@1 87.500 (83.798)	
Total train loss: 0.5790
Avg Loading time: 9.5786 seconds
Avg Batch time: 9.7604 seconds

Train time: 3816.3623926639557
 * Prec@1 87.700 Prec@5 99.630 Loss 0.4016
Avg Loading time: 6.3003 seconds
Avg Batch time: 6.3669 seconds

Best acc: 87.700
--------------------------------------------------------------------------------
Test time: 504.4230442047119

Epoch: [1][77/391]	LR: 0.01	DT: 0.000 (5.334)	BT: 0.168 (5.511)	Loss 0.2356 (0.3556)	Prec@1 93.750 (89.143)	
Epoch: [1][155/391]	LR: 0.01	DT: 0.000 (5.858)	BT: 0.167 (6.037)	Loss 0.3752 (0.3554)	Prec@1 92.188 (88.887)	
Epoch: [1][233/391]	LR: 0.01	DT: 0.000 (6.421)	BT: 0.185 (6.600)	Loss 0.3203 (0.3533)	Prec@1 89.844 (88.919)	
Epoch: [1][311/391]	LR: 0.01	DT: 0.000 (6.550)	BT: 0.172 (6.730)	Loss 0.4426 (0.3481)	Prec@1 83.594 (89.088)	
Epoch: [1][389/391]	LR: 0.01	DT: 0.000 (6.701)	BT: 0.168 (6.881)	Loss 0.3611 (0.3457)	Prec@1 85.156 (89.099)	
Total train loss: 0.3457
Avg Loading time: 6.6840 seconds
Avg Batch time: 6.8639 seconds

Train time: 2684.094652891159
 * Prec@1 82.100 Prec@5 99.160 Loss 0.5454
Avg Loading time: 6.4087 seconds
Avg Batch time: 6.4673 seconds

Best acc: 87.700
--------------------------------------------------------------------------------
Test time: 513.270414352417

Epoch: [2][77/391]	LR: 0.01	DT: 0.000 (6.656)	BT: 0.167 (6.835)	Loss 0.3655 (0.3238)	Prec@1 91.406 (89.553)	
Epoch: [2][155/391]	LR: 0.01	DT: 0.000 (6.309)	BT: 0.169 (6.488)	Loss 0.3220 (0.3274)	Prec@1 89.062 (89.403)	
Epoch: [2][233/391]	LR: 0.01	DT: 0.000 (6.184)	BT: 0.183 (6.363)	Loss 0.3057 (0.3285)	Prec@1 89.062 (89.263)	
Epoch: [2][311/391]	LR: 0.01	DT: 0.000 (6.368)	BT: 0.170 (6.546)	Loss 0.3357 (0.3282)	Prec@1 89.062 (89.325)	
Epoch: [2][389/391]	LR: 0.01	DT: 0.000 (6.598)	BT: 0.167 (6.776)	Loss 0.3220 (0.3279)	Prec@1 85.938 (89.323)	
Total train loss: 0.3279
Avg Loading time: 6.5811 seconds
Avg Batch time: 6.7593 seconds

Train time: 2642.944055557251
 * Prec@1 89.810 Prec@5 99.630 Loss 0.3367
Avg Loading time: 6.3860 seconds
Avg Batch time: 6.4416 seconds

Best acc: 89.810
--------------------------------------------------------------------------------
Test time: 510.0298104286194

Epoch: [3][77/391]	LR: 0.01	DT: 0.000 (6.681)	BT: 0.171 (6.862)	Loss 0.4355 (0.3440)	Prec@1 85.156 (88.672)	
Epoch: [3][155/391]	LR: 0.01	DT: 7.832 (6.966)	BT: 8.006 (7.148)	Loss 0.4829 (0.3355)	Prec@1 85.938 (88.897)	
Epoch: [3][233/391]	LR: 0.01	DT: 15.319 (7.120)	BT: 15.524 (7.302)	Loss 0.3313 (0.3350)	Prec@1 89.844 (89.066)	
Epoch: [3][311/391]	LR: 0.01	DT: 0.000 (6.702)	BT: 0.175 (6.885)	Loss 0.3516 (0.3333)	Prec@1 88.281 (89.015)	
Epoch: [3][389/391]	LR: 0.01	DT: 0.000 (6.831)	BT: 0.172 (7.014)	Loss 0.3198 (0.3329)	Prec@1 87.500 (89.022)	
Total train loss: 0.3330
Avg Loading time: 6.8135 seconds
Avg Batch time: 6.9964 seconds

Train time: 2735.632467508316
 * Prec@1 75.050 Prec@5 98.610 Loss 0.7227
Avg Loading time: 7.2748 seconds
Avg Batch time: 7.3348 seconds

Best acc: 89.810
--------------------------------------------------------------------------------
Test time: 579.980865240097

Epoch: [4][77/391]	LR: 0.01	DT: 0.000 (7.187)	BT: 0.171 (7.370)	Loss 0.3770 (0.3093)	Prec@1 86.719 (89.934)	
Epoch: [4][155/391]	LR: 0.01	DT: 0.515 (7.342)	BT: 0.699 (7.525)	Loss 0.3042 (0.3259)	Prec@1 89.062 (89.188)	
Epoch: [4][233/391]	LR: 0.01	DT: 11.599 (7.527)	BT: 11.778 (7.709)	Loss 0.2966 (0.3326)	Prec@1 89.062 (88.952)	
Epoch: [4][311/391]	LR: 0.01	DT: 0.000 (7.406)	BT: 0.173 (7.587)	Loss 0.3499 (0.3252)	Prec@1 87.500 (89.273)	
Epoch: [4][389/391]	LR: 0.01	DT: 0.000 (7.271)	BT: 0.173 (7.452)	Loss 0.3240 (0.3235)	Prec@1 89.062 (89.315)	
Total train loss: 0.3234
Avg Loading time: 7.2519 seconds
Avg Batch time: 7.4335 seconds

Train time: 2906.5389256477356
 * Prec@1 88.470 Prec@5 99.700 Loss 0.3423
Avg Loading time: 5.1553 seconds
Avg Batch time: 5.2141 seconds

Best acc: 89.810
--------------------------------------------------------------------------------
Test time: 412.50342178344727

Epoch: [5][77/391]	LR: 0.01	DT: 0.000 (6.500)	BT: 0.170 (6.684)	Loss 0.3313 (0.2885)	Prec@1 87.500 (90.455)	
Epoch: [5][155/391]	LR: 0.01	DT: 0.000 (6.977)	BT: 0.174 (7.159)	Loss 0.2693 (0.2977)	Prec@1 91.406 (90.024)	
Epoch: [5][233/391]	LR: 0.01	DT: 13.921 (7.310)	BT: 14.131 (7.494)	Loss 0.3943 (0.2974)	Prec@1 88.281 (90.178)	
Epoch: [5][311/391]	LR: 0.01	DT: 0.000 (7.237)	BT: 0.172 (7.420)	Loss 0.2399 (0.2997)	Prec@1 90.625 (90.107)	
Epoch: [5][389/391]	LR: 0.01	DT: 1.666 (7.361)	BT: 1.851 (7.544)	Loss 0.4048 (0.3110)	Prec@1 82.812 (89.669)	
Total train loss: 0.3112
Avg Loading time: 7.3417 seconds
Avg Batch time: 7.5250 seconds

Train time: 2942.514794111252
 * Prec@1 33.430 Prec@5 83.750 Loss 1.8164
Avg Loading time: 6.8426 seconds
Avg Batch time: 6.9107 seconds

Best acc: 89.810
--------------------------------------------------------------------------------
Test time: 546.7630753517151

Epoch: [6][77/391]	LR: 0.01	DT: 0.265 (5.723)	BT: 0.437 (5.905)	Loss 0.2000 (0.3005)	Prec@1 93.750 (89.774)	
Epoch: [6][155/391]	LR: 0.01	DT: 0.000 (5.976)	BT: 0.173 (6.159)	Loss 0.2798 (0.2967)	Prec@1 92.188 (90.204)	
Epoch: [6][233/391]	LR: 0.01	DT: 19.416 (6.725)	BT: 19.615 (6.910)	Loss 0.2869 (0.3028)	Prec@1 88.281 (90.001)	
Epoch: [6][311/391]	LR: 0.01	DT: 0.000 (6.873)	BT: 0.170 (7.058)	Loss 0.4448 (0.3107)	Prec@1 84.375 (89.694)	
Epoch: [6][389/391]	LR: 0.01	DT: 0.000 (7.083)	BT: 0.168 (7.268)	Loss 0.2605 (0.3126)	Prec@1 92.188 (89.653)	
Total train loss: 0.3128
Avg Loading time: 7.0647 seconds
Avg Batch time: 7.2494 seconds

Train time: 2834.815582752228
 * Prec@1 88.340 Prec@5 99.660 Loss 0.3523
Avg Loading time: 6.7538 seconds
Avg Batch time: 6.8188 seconds

Best acc: 89.810
--------------------------------------------------------------------------------
Test time: 541.0865988731384

Epoch: [7][77/391]	LR: 0.01	DT: 0.000 (7.036)	BT: 0.178 (7.221)	Loss 0.4138 (0.3270)	Prec@1 82.812 (88.852)	
Epoch: [7][155/391]	LR: 0.01	DT: 0.000 (6.838)	BT: 0.181 (7.023)	Loss 0.2751 (0.3085)	Prec@1 92.188 (89.683)	
Epoch: [7][233/391]	LR: 0.01	DT: 13.630 (6.759)	BT: 13.821 (6.942)	Loss 0.2986 (0.3089)	Prec@1 89.844 (89.770)	
Epoch: [7][311/391]	LR: 0.01	DT: 0.000 (6.711)	BT: 0.171 (6.895)	Loss 0.2578 (0.3128)	Prec@1 92.969 (89.638)	
Epoch: [7][389/391]	LR: 0.01	DT: 0.000 (6.863)	BT: 0.169 (7.046)	Loss 0.3406 (0.3135)	Prec@1 86.719 (89.653)	
Total train loss: 0.3134
Avg Loading time: 6.8455 seconds
Avg Batch time: 7.0286 seconds

Train time: 2748.2899582386017
 * Prec@1 89.200 Prec@5 99.730 Loss 0.3193
Avg Loading time: 6.4256 seconds
Avg Batch time: 6.4809 seconds

Best acc: 89.810
--------------------------------------------------------------------------------
Test time: 512.6407988071442

Epoch: [8][77/391]	LR: 0.01	DT: 0.000 (6.578)	BT: 0.169 (6.761)	Loss 0.2732 (0.2848)	Prec@1 92.969 (90.835)	
Epoch: [8][155/391]	LR: 0.01	DT: 0.000 (6.782)	BT: 0.164 (6.965)	Loss 0.3242 (0.2899)	Prec@1 86.719 (90.345)	
Epoch: [8][233/391]	LR: 0.01	DT: 3.256 (6.919)	BT: 3.454 (7.102)	Loss 0.3477 (0.2938)	Prec@1 87.500 (90.248)	
Epoch: [8][311/391]	LR: 0.01	DT: 0.000 (6.576)	BT: 0.172 (6.758)	Loss 0.2496 (0.2949)	Prec@1 89.844 (90.199)	
Epoch: [8][389/391]	LR: 0.01	DT: 0.000 (6.495)	BT: 0.173 (6.678)	Loss 0.2585 (0.2996)	Prec@1 91.406 (90.062)	
Total train loss: 0.2997
Avg Loading time: 6.4784 seconds
Avg Batch time: 6.6609 seconds

Train time: 2604.462781906128
 * Prec@1 76.400 Prec@5 97.630 Loss 0.7231
Avg Loading time: 5.9433 seconds
Avg Batch time: 6.0057 seconds

Best acc: 89.810
--------------------------------------------------------------------------------
Test time: 474.99758744239807

Epoch: [9][77/391]	LR: 0.01	DT: 0.000 (6.579)	BT: 0.172 (6.762)	Loss 0.2466 (0.2919)	Prec@1 92.969 (90.605)	
Epoch: [9][155/391]	LR: 0.01	DT: 0.000 (6.794)	BT: 0.168 (6.975)	Loss 0.2654 (0.2803)	Prec@1 92.188 (90.860)	
Epoch: [9][233/391]	LR: 0.01	DT: 0.000 (7.012)	BT: 0.187 (7.193)	Loss 0.2861 (0.2829)	Prec@1 89.844 (90.672)	
Epoch: [9][311/391]	LR: 0.01	DT: 0.000 (6.957)	BT: 0.171 (7.138)	Loss 0.2299 (0.2879)	Prec@1 94.531 (90.452)	
Epoch: [9][389/391]	LR: 0.01	DT: 0.000 (6.903)	BT: 0.174 (7.084)	Loss 0.3521 (0.2891)	Prec@1 85.156 (90.407)	
Total train loss: 0.2892
Avg Loading time: 6.8850 seconds
Avg Batch time: 7.0658 seconds

Train time: 2762.765984773636
 * Prec@1 89.050 Prec@5 99.720 Loss 0.3203
Avg Loading time: 5.1709 seconds
Avg Batch time: 5.2291 seconds

Best acc: 89.810
--------------------------------------------------------------------------------
Test time: 413.6449227333069

Epoch: [10][77/391]	LR: 0.002	DT: 0.000 (5.882)	BT: 0.176 (6.066)	Loss 0.2375 (0.2697)	Prec@1 91.406 (91.296)	
Epoch: [10][155/391]	LR: 0.002	DT: 0.000 (6.435)	BT: 0.170 (6.617)	Loss 0.2903 (0.2602)	Prec@1 92.188 (91.556)	
Epoch: [10][233/391]	LR: 0.002	DT: 0.000 (6.798)	BT: 0.181 (6.979)	Loss 0.2469 (0.2622)	Prec@1 90.625 (91.460)	
Epoch: [10][311/391]	LR: 0.002	DT: 0.000 (6.779)	BT: 0.175 (6.960)	Loss 0.2681 (0.2645)	Prec@1 89.062 (91.301)	
Epoch: [10][389/391]	LR: 0.002	DT: 0.000 (6.891)	BT: 0.172 (7.073)	Loss 0.3123 (0.2648)	Prec@1 88.281 (91.284)	
Total train loss: 0.2646
Avg Loading time: 6.8736 seconds
Avg Batch time: 7.0548 seconds

Train time: 2758.628935813904
 * Prec@1 89.880 Prec@5 99.730 Loss 0.2971
Avg Loading time: 6.4169 seconds
Avg Batch time: 6.4867 seconds

Best acc: 89.880
--------------------------------------------------------------------------------
Test time: 514.2778124809265

Epoch: [11][77/391]	LR: 0.002	DT: 0.000 (5.722)	BT: 0.176 (5.906)	Loss 0.3318 (0.2567)	Prec@1 89.062 (91.406)	
Epoch: [11][155/391]	LR: 0.002	DT: 7.731 (6.250)	BT: 7.923 (6.434)	Loss 0.2732 (0.2545)	Prec@1 89.062 (91.511)	
Epoch: [11][233/391]	LR: 0.002	DT: 5.847 (6.462)	BT: 6.039 (6.647)	Loss 0.2485 (0.2572)	Prec@1 91.406 (91.510)	
Epoch: [11][311/391]	LR: 0.002	DT: 0.845 (6.647)	BT: 1.033 (6.832)	Loss 0.2812 (0.2595)	Prec@1 91.406 (91.474)	
Epoch: [11][389/391]	LR: 0.002	DT: 0.000 (6.841)	BT: 0.173 (7.027)	Loss 0.2386 (0.2580)	Prec@1 91.406 (91.516)	
Total train loss: 0.2580
Avg Loading time: 6.8234 seconds
Avg Batch time: 7.0088 seconds

Train time: 2740.5584106445312
 * Prec@1 89.970 Prec@5 99.730 Loss 0.2954
Avg Loading time: 6.7118 seconds
Avg Batch time: 6.7739 seconds

Best acc: 89.970
--------------------------------------------------------------------------------
Test time: 537.9255874156952

Epoch: [12][77/391]	LR: 0.002	DT: 0.000 (6.891)	BT: 0.176 (7.077)	Loss 0.2595 (0.2601)	Prec@1 90.625 (91.256)	
Epoch: [12][155/391]	LR: 0.002	DT: 0.000 (6.649)	BT: 0.173 (6.833)	Loss 0.2178 (0.2536)	Prec@1 92.188 (91.587)	
Epoch: [12][233/391]	LR: 0.002	DT: 16.320 (6.667)	BT: 16.515 (6.850)	Loss 0.2395 (0.2533)	Prec@1 92.969 (91.687)	
Epoch: [12][311/391]	LR: 0.002	DT: 0.000 (6.497)	BT: 0.171 (6.680)	Loss 0.2042 (0.2558)	Prec@1 91.406 (91.529)	
Epoch: [12][389/391]	LR: 0.002	DT: 0.000 (6.626)	BT: 0.176 (6.809)	Loss 0.2822 (0.2548)	Prec@1 90.625 (91.506)	
Total train loss: 0.2549
Avg Loading time: 6.6086 seconds
Avg Batch time: 6.7919 seconds

Train time: 2655.7913494110107
 * Prec@1 89.970 Prec@5 99.750 Loss 0.2952
Avg Loading time: 6.3977 seconds
Avg Batch time: 6.4591 seconds

Best acc: 89.970
--------------------------------------------------------------------------------
Test time: 510.9160499572754

Epoch: [13][77/391]	LR: 0.002	DT: 0.000 (6.511)	BT: 0.171 (6.695)	Loss 0.2927 (0.2594)	Prec@1 90.625 (91.126)	
Epoch: [13][155/391]	LR: 0.002	DT: 0.000 (6.791)	BT: 0.172 (6.975)	Loss 0.2678 (0.2577)	Prec@1 92.188 (91.401)	
Epoch: [13][233/391]	LR: 0.002	DT: 0.000 (6.870)	BT: 0.188 (7.054)	Loss 0.1747 (0.2564)	Prec@1 94.531 (91.376)	
Epoch: [13][311/391]	LR: 0.002	DT: 1.980 (6.552)	BT: 2.158 (6.736)	Loss 0.2239 (0.2528)	Prec@1 91.406 (91.539)	
Epoch: [13][389/391]	LR: 0.002	DT: 0.140 (6.573)	BT: 0.313 (6.758)	Loss 0.2380 (0.2527)	Prec@1 93.750 (91.550)	
Total train loss: 0.2530
Avg Loading time: 6.5566 seconds
Avg Batch time: 6.7410 seconds

Train time: 2635.767007112503
 * Prec@1 89.960 Prec@5 99.720 Loss 0.2939
Avg Loading time: 6.1422 seconds
Avg Batch time: 6.2059 seconds

Best acc: 89.970
--------------------------------------------------------------------------------
Test time: 490.84415078163147

Epoch: [14][77/391]	LR: 0.002	DT: 0.000 (6.510)	BT: 0.175 (6.694)	Loss 0.2323 (0.2371)	Prec@1 89.844 (92.278)	
Epoch: [14][155/391]	LR: 0.002	DT: 6.172 (6.793)	BT: 6.352 (6.978)	Loss 0.2437 (0.2423)	Prec@1 93.750 (92.127)	
Epoch: [14][233/391]	LR: 0.002	DT: 0.000 (6.988)	BT: 0.179 (7.173)	Loss 0.2070 (0.2452)	Prec@1 92.969 (91.924)	
Epoch: [14][311/391]	LR: 0.002	DT: 0.000 (6.948)	BT: 0.172 (7.132)	Loss 0.1881 (0.2461)	Prec@1 92.188 (91.877)	
Epoch: [14][389/391]	LR: 0.002	DT: 0.000 (6.837)	BT: 0.174 (7.021)	Loss 0.2174 (0.2478)	Prec@1 91.406 (91.867)	
Total train loss: 0.2477
Avg Loading time: 6.8193 seconds
Avg Batch time: 7.0030 seconds

Train time: 2738.1953732967377
 * Prec@1 90.050 Prec@5 99.720 Loss 0.2932
Avg Loading time: 4.9116 seconds
Avg Batch time: 4.9668 seconds

Best acc: 90.050
--------------------------------------------------------------------------------
Test time: 393.4115858078003

Epoch: [15][77/391]	LR: 0.002	DT: 0.000 (6.147)	BT: 0.171 (6.329)	Loss 0.2112 (0.2470)	Prec@1 92.188 (91.777)	
Epoch: [15][155/391]	LR: 0.002	DT: 0.000 (6.420)	BT: 0.176 (6.602)	Loss 0.2467 (0.2434)	Prec@1 90.625 (92.007)	
Epoch: [15][233/391]	LR: 0.002	DT: 0.000 (6.796)	BT: 0.190 (6.977)	Loss 0.1615 (0.2456)	Prec@1 96.875 (91.804)	
Epoch: [15][311/391]	LR: 0.002	DT: 0.000 (6.767)	BT: 0.176 (6.948)	Loss 0.3123 (0.2482)	Prec@1 89.062 (91.769)	
Epoch: [15][389/391]	LR: 0.002	DT: 0.000 (6.871)	BT: 0.170 (7.052)	Loss 0.2905 (0.2479)	Prec@1 87.500 (91.741)	
Total train loss: 0.2478
Avg Loading time: 6.8531 seconds
Avg Batch time: 7.0341 seconds

Train time: 2750.6265766620636
 * Prec@1 89.970 Prec@5 99.730 Loss 0.2944
Avg Loading time: 6.2977 seconds
Avg Batch time: 6.3656 seconds

Best acc: 90.050
--------------------------------------------------------------------------------
Test time: 503.6268627643585

Epoch: [16][77/391]	LR: 0.002	DT: 1.668 (5.774)	BT: 1.867 (5.957)	Loss 0.2078 (0.2488)	Prec@1 92.969 (91.597)	
Epoch: [16][155/391]	LR: 0.002	DT: 0.000 (6.372)	BT: 0.173 (6.555)	Loss 0.2610 (0.2468)	Prec@1 91.406 (91.667)	
Epoch: [16][233/391]	LR: 0.002	DT: 0.000 (6.385)	BT: 0.190 (6.568)	Loss 0.2715 (0.2451)	Prec@1 90.625 (91.814)	
Epoch: [16][311/391]	LR: 0.002	DT: 0.000 (6.502)	BT: 0.172 (6.686)	Loss 0.2112 (0.2476)	Prec@1 93.750 (91.754)	
Epoch: [16][389/391]	LR: 0.002	DT: 0.000 (6.669)	BT: 0.172 (6.853)	Loss 0.3003 (0.2490)	Prec@1 87.500 (91.767)	
Total train loss: 0.2489
Avg Loading time: 6.6523 seconds
Avg Batch time: 6.8359 seconds

Train time: 2673.080070734024
 * Prec@1 90.120 Prec@5 99.750 Loss 0.2927
Avg Loading time: 6.4421 seconds
Avg Batch time: 6.5060 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 515.9144244194031

Epoch: [17][77/391]	LR: 0.002	DT: 0.000 (6.608)	BT: 0.170 (6.795)	Loss 0.2698 (0.2447)	Prec@1 92.188 (91.737)	
Epoch: [17][155/391]	LR: 0.002	DT: 0.000 (6.350)	BT: 0.176 (6.536)	Loss 0.2465 (0.2463)	Prec@1 92.969 (91.822)	
Epoch: [17][233/391]	LR: 0.002	DT: 3.713 (6.558)	BT: 3.906 (6.743)	Loss 0.2617 (0.2492)	Prec@1 90.625 (91.757)	
Epoch: [17][311/391]	LR: 0.002	DT: 0.000 (6.463)	BT: 0.170 (6.647)	Loss 0.3086 (0.2488)	Prec@1 89.062 (91.744)	
Epoch: [17][389/391]	LR: 0.002	DT: 0.000 (6.474)	BT: 0.172 (6.658)	Loss 0.2194 (0.2482)	Prec@1 90.625 (91.839)	
Total train loss: 0.2481
Avg Loading time: 6.4576 seconds
Avg Batch time: 6.6410 seconds

Train time: 2596.725708246231
 * Prec@1 89.990 Prec@5 99.700 Loss 0.2915
Avg Loading time: 6.4361 seconds
Avg Batch time: 6.4982 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 513.9442451000214

Epoch: [18][77/391]	LR: 0.002	DT: 0.000 (6.597)	BT: 0.175 (6.781)	Loss 0.2366 (0.2388)	Prec@1 92.969 (92.137)	
Epoch: [18][155/391]	LR: 0.002	DT: 0.000 (6.848)	BT: 0.168 (7.031)	Loss 0.2776 (0.2411)	Prec@1 89.062 (91.922)	
Epoch: [18][233/391]	LR: 0.002	DT: 6.363 (6.871)	BT: 6.547 (7.054)	Loss 0.1703 (0.2466)	Prec@1 94.531 (91.787)	
Epoch: [18][311/391]	LR: 0.002	DT: 0.000 (6.511)	BT: 0.167 (6.694)	Loss 0.3337 (0.2475)	Prec@1 91.406 (91.767)	
Epoch: [18][389/391]	LR: 0.002	DT: 0.000 (6.683)	BT: 0.173 (6.866)	Loss 0.3225 (0.2483)	Prec@1 91.406 (91.809)	
Total train loss: 0.2485
Avg Loading time: 6.6660 seconds
Avg Batch time: 6.8485 seconds

Train time: 2677.7863805294037
 * Prec@1 89.910 Prec@5 99.720 Loss 0.2935
Avg Loading time: 6.8022 seconds
Avg Batch time: 6.8623 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 542.6982836723328

Epoch: [19][77/391]	LR: 0.002	DT: 5.436 (6.716)	BT: 5.612 (6.899)	Loss 0.2664 (0.2470)	Prec@1 92.969 (91.847)	
Epoch: [19][155/391]	LR: 0.002	DT: 0.000 (6.827)	BT: 0.171 (7.011)	Loss 0.1968 (0.2473)	Prec@1 95.312 (91.827)	
Epoch: [19][233/391]	LR: 0.002	DT: 3.581 (7.015)	BT: 3.772 (7.199)	Loss 0.2703 (0.2473)	Prec@1 89.062 (91.760)	
Epoch: [19][311/391]	LR: 0.002	DT: 13.703 (6.991)	BT: 13.891 (7.176)	Loss 0.2426 (0.2459)	Prec@1 92.188 (91.822)	
Epoch: [19][389/391]	LR: 0.002	DT: 0.000 (6.833)	BT: 0.175 (7.018)	Loss 0.2922 (0.2468)	Prec@1 89.062 (91.807)	
Total train loss: 0.2469
Avg Loading time: 6.8158 seconds
Avg Batch time: 7.0003 seconds

Train time: 2737.1701068878174
 * Prec@1 89.990 Prec@5 99.730 Loss 0.2920
Avg Loading time: 5.2673 seconds
Avg Batch time: 5.3241 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 421.1828832626343

Epoch: [20][77/391]	LR: 0.0004	DT: 0.000 (6.545)	BT: 0.172 (6.727)	Loss 0.2578 (0.2417)	Prec@1 92.969 (91.907)	
Epoch: [20][155/391]	LR: 0.0004	DT: 0.000 (6.533)	BT: 0.174 (6.717)	Loss 0.2239 (0.2423)	Prec@1 91.406 (91.922)	
Epoch: [20][233/391]	LR: 0.0004	DT: 6.085 (6.830)	BT: 6.266 (7.014)	Loss 0.2822 (0.2401)	Prec@1 89.844 (92.137)	
Epoch: [20][311/391]	LR: 0.0004	DT: 0.000 (6.825)	BT: 0.172 (7.009)	Loss 0.2742 (0.2421)	Prec@1 89.844 (92.117)	
Epoch: [20][389/391]	LR: 0.0004	DT: 0.000 (6.928)	BT: 0.177 (7.113)	Loss 0.1826 (0.2422)	Prec@1 95.312 (92.157)	
Total train loss: 0.2422
Avg Loading time: 6.9103 seconds
Avg Batch time: 7.0948 seconds

Train time: 2774.3164768218994
 * Prec@1 90.060 Prec@5 99.740 Loss 0.2922
Avg Loading time: 6.2937 seconds
Avg Batch time: 6.3613 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 503.4788055419922

Epoch: [21][77/391]	LR: 0.0004	DT: 0.000 (6.175)	BT: 0.174 (6.357)	Loss 0.2610 (0.2464)	Prec@1 89.062 (91.917)	
Epoch: [21][155/391]	LR: 0.0004	DT: 0.000 (6.894)	BT: 0.172 (7.078)	Loss 0.2539 (0.2433)	Prec@1 92.188 (91.982)	
Epoch: [21][233/391]	LR: 0.0004	DT: 2.522 (7.112)	BT: 2.704 (7.295)	Loss 0.2410 (0.2446)	Prec@1 92.188 (91.937)	
Epoch: [21][311/391]	LR: 0.0004	DT: 0.000 (7.172)	BT: 0.169 (7.355)	Loss 0.1754 (0.2437)	Prec@1 94.531 (92.057)	
Epoch: [21][389/391]	LR: 0.0004	DT: 0.000 (7.384)	BT: 0.176 (7.568)	Loss 0.3059 (0.2431)	Prec@1 88.281 (92.025)	
Total train loss: 0.2431
Avg Loading time: 7.3649 seconds
Avg Batch time: 7.5489 seconds

Train time: 2951.673143863678
 * Prec@1 90.040 Prec@5 99.720 Loss 0.2908
Avg Loading time: 7.6339 seconds
Avg Batch time: 7.6969 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 609.7074780464172

Epoch: [22][77/391]	LR: 0.0004	DT: 0.000 (7.235)	BT: 0.172 (7.420)	Loss 0.2646 (0.2330)	Prec@1 92.188 (92.528)	
Epoch: [22][155/391]	LR: 0.0004	DT: 0.000 (6.560)	BT: 0.178 (6.744)	Loss 0.2111 (0.2377)	Prec@1 92.188 (92.373)	
Epoch: [22][233/391]	LR: 0.0004	DT: 6.813 (6.811)	BT: 7.013 (6.995)	Loss 0.2343 (0.2407)	Prec@1 92.188 (92.228)	
Epoch: [22][311/391]	LR: 0.0004	DT: 0.000 (6.690)	BT: 0.173 (6.874)	Loss 0.3433 (0.2425)	Prec@1 88.281 (92.135)	
Epoch: [22][389/391]	LR: 0.0004	DT: 0.000 (6.828)	BT: 0.173 (7.012)	Loss 0.2578 (0.2419)	Prec@1 89.844 (92.139)	
Total train loss: 0.2421
Avg Loading time: 6.8100 seconds
Avg Batch time: 6.9946 seconds

Train time: 2734.9686291217804
 * Prec@1 90.040 Prec@5 99.730 Loss 0.2922
Avg Loading time: 8.3290 seconds
Avg Batch time: 8.3925 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 663.6944868564606

Epoch: [23][77/391]	LR: 0.0004	DT: 1.249 (7.875)	BT: 1.424 (8.059)	Loss 0.2690 (0.2471)	Prec@1 90.625 (91.737)	
Epoch: [23][155/391]	LR: 0.0004	DT: 0.000 (8.229)	BT: 0.176 (8.415)	Loss 0.2291 (0.2479)	Prec@1 91.406 (91.832)	
Epoch: [23][233/391]	LR: 0.0004	DT: 6.889 (7.779)	BT: 7.074 (7.965)	Loss 0.2146 (0.2455)	Prec@1 92.969 (91.924)	
Epoch: [23][311/391]	LR: 0.0004	DT: 0.000 (7.397)	BT: 0.178 (7.582)	Loss 0.3191 (0.2446)	Prec@1 86.719 (91.897)	
Epoch: [23][389/391]	LR: 0.0004	DT: 0.000 (7.392)	BT: 0.173 (7.578)	Loss 0.1948 (0.2433)	Prec@1 93.750 (92.007)	
Total train loss: 0.2433
Avg Loading time: 7.3730 seconds
Avg Batch time: 7.5590 seconds

Train time: 2955.60528588295
 * Prec@1 90.020 Prec@5 99.720 Loss 0.2905
Avg Loading time: 6.9778 seconds
Avg Batch time: 7.0397 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 556.8732118606567

Epoch: [24][77/391]	LR: 0.0004	DT: 1.443 (6.794)	BT: 1.624 (6.982)	Loss 0.2439 (0.2355)	Prec@1 91.406 (92.198)	
Epoch: [24][155/391]	LR: 0.0004	DT: 0.000 (6.992)	BT: 0.174 (7.180)	Loss 0.2764 (0.2372)	Prec@1 90.625 (92.193)	
Epoch: [24][233/391]	LR: 0.0004	DT: 2.342 (7.206)	BT: 2.536 (7.394)	Loss 0.1802 (0.2396)	Prec@1 94.531 (92.057)	
Epoch: [24][311/391]	LR: 0.0004	DT: 0.000 (7.044)	BT: 0.166 (7.231)	Loss 0.1559 (0.2455)	Prec@1 95.312 (91.824)	
Epoch: [24][389/391]	LR: 0.0004	DT: 0.000 (6.891)	BT: 0.176 (7.078)	Loss 0.2377 (0.2435)	Prec@1 93.750 (91.963)	
Total train loss: 0.2435
Avg Loading time: 6.8731 seconds
Avg Batch time: 7.0603 seconds

Train time: 2760.6295251846313
 * Prec@1 90.020 Prec@5 99.730 Loss 0.2917
Avg Loading time: 5.7615 seconds
Avg Batch time: 5.8253 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 460.76899790763855

Epoch: [25][77/391]	LR: 0.0004	DT: 0.000 (6.880)	BT: 0.176 (7.066)	Loss 0.2539 (0.2396)	Prec@1 91.406 (91.987)	
Epoch: [25][155/391]	LR: 0.0004	DT: 0.000 (6.799)	BT: 0.176 (6.986)	Loss 0.2783 (0.2384)	Prec@1 90.625 (92.067)	
Epoch: [25][233/391]	LR: 0.0004	DT: 0.000 (7.060)	BT: 0.180 (7.246)	Loss 0.1801 (0.2401)	Prec@1 96.094 (92.071)	
Epoch: [25][311/391]	LR: 0.0004	DT: 0.000 (6.995)	BT: 0.175 (7.180)	Loss 0.2140 (0.2421)	Prec@1 92.188 (92.082)	
Epoch: [25][389/391]	LR: 0.0004	DT: 0.000 (7.080)	BT: 0.177 (7.265)	Loss 0.2280 (0.2422)	Prec@1 94.531 (92.083)	
Total train loss: 0.2424
Avg Loading time: 7.0614 seconds
Avg Batch time: 7.2466 seconds

Train time: 2833.625632762909
 * Prec@1 90.070 Prec@5 99.760 Loss 0.2908
Avg Loading time: 6.1435 seconds
Avg Batch time: 6.2145 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 494.4206852912903

Epoch: [26][77/391]	LR: 0.0004	DT: 0.000 (6.863)	BT: 0.173 (7.050)	Loss 0.1716 (0.2424)	Prec@1 94.531 (91.917)	
Epoch: [26][155/391]	LR: 0.0004	DT: 0.000 (7.273)	BT: 0.175 (7.459)	Loss 0.2739 (0.2401)	Prec@1 89.062 (92.022)	
Epoch: [26][233/391]	LR: 0.0004	DT: 0.000 (7.156)	BT: 0.187 (7.343)	Loss 0.1672 (0.2394)	Prec@1 96.094 (92.071)	
Epoch: [26][311/391]	LR: 0.0004	DT: 0.000 (7.323)	BT: 0.178 (7.510)	Loss 0.2040 (0.2416)	Prec@1 92.969 (92.002)	
Epoch: [26][389/391]	LR: 0.0004	DT: 0.000 (7.456)	BT: 0.180 (7.643)	Loss 0.2830 (0.2427)	Prec@1 91.406 (91.995)	
Total train loss: 0.2426
Avg Loading time: 7.4373 seconds
Avg Batch time: 7.6241 seconds

Train time: 2981.201618909836
 * Prec@1 89.920 Prec@5 99.750 Loss 0.2930
Avg Loading time: 8.0449 seconds
Avg Batch time: 8.1130 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 641.6643197536469

Epoch: [27][77/391]	LR: 0.0004	DT: 0.000 (7.330)	BT: 0.174 (7.516)	Loss 0.2333 (0.2506)	Prec@1 92.969 (91.907)	
Epoch: [27][155/391]	LR: 0.0004	DT: 0.000 (6.846)	BT: 0.176 (7.031)	Loss 0.1748 (0.2413)	Prec@1 93.750 (92.147)	
Epoch: [27][233/391]	LR: 0.0004	DT: 0.000 (7.203)	BT: 0.188 (7.387)	Loss 0.2927 (0.2451)	Prec@1 89.062 (92.047)	
Epoch: [27][311/391]	LR: 0.0004	DT: 0.000 (6.906)	BT: 0.175 (7.090)	Loss 0.2954 (0.2437)	Prec@1 90.625 (92.092)	
Epoch: [27][389/391]	LR: 0.0004	DT: 0.000 (6.858)	BT: 0.173 (7.042)	Loss 0.2443 (0.2419)	Prec@1 92.188 (92.117)	
Total train loss: 0.2419
Avg Loading time: 6.8404 seconds
Avg Batch time: 7.0247 seconds

Train time: 2746.7655613422394
 * Prec@1 89.960 Prec@5 99.720 Loss 0.2920
Avg Loading time: 6.7018 seconds
Avg Batch time: 6.7656 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 536.9574704170227

Epoch: [28][77/391]	LR: 0.0004	DT: 2.074 (6.935)	BT: 2.252 (7.123)	Loss 0.2810 (0.2476)	Prec@1 92.188 (92.047)	
Epoch: [28][155/391]	LR: 0.0004	DT: 0.000 (7.155)	BT: 0.175 (7.343)	Loss 0.2178 (0.2465)	Prec@1 92.969 (92.122)	
Epoch: [28][233/391]	LR: 0.0004	DT: 14.813 (6.911)	BT: 15.009 (7.099)	Loss 0.2487 (0.2448)	Prec@1 92.188 (92.064)	
Epoch: [28][311/391]	LR: 0.0004	DT: 0.000 (6.789)	BT: 0.178 (6.976)	Loss 0.2396 (0.2436)	Prec@1 89.844 (92.045)	
Epoch: [28][389/391]	LR: 0.0004	DT: 1.456 (6.859)	BT: 1.641 (7.046)	Loss 0.2273 (0.2419)	Prec@1 93.750 (92.151)	
Total train loss: 0.2417
Avg Loading time: 6.8414 seconds
Avg Batch time: 7.0287 seconds

Train time: 2748.2728099823
 * Prec@1 90.010 Prec@5 99.730 Loss 0.2920
Avg Loading time: 6.8028 seconds
Avg Batch time: 6.8644 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 543.1386661529541

Epoch: [29][77/391]	LR: 0.0004	DT: 0.000 (6.895)	BT: 0.172 (7.080)	Loss 0.2169 (0.2339)	Prec@1 93.750 (92.328)	
Epoch: [29][155/391]	LR: 0.0004	DT: 0.000 (7.118)	BT: 0.178 (7.302)	Loss 0.1870 (0.2367)	Prec@1 96.094 (92.323)	
Epoch: [29][233/391]	LR: 0.0004	DT: 16.645 (7.277)	BT: 16.849 (7.463)	Loss 0.2600 (0.2361)	Prec@1 91.406 (92.324)	
Epoch: [29][311/391]	LR: 0.0004	DT: 0.000 (7.109)	BT: 0.172 (7.294)	Loss 0.1787 (0.2380)	Prec@1 92.969 (92.253)	
Epoch: [29][389/391]	LR: 0.0004	DT: 0.000 (7.009)	BT: 0.178 (7.195)	Loss 0.2411 (0.2396)	Prec@1 91.406 (92.161)	
Total train loss: 0.2396
Avg Loading time: 6.9914 seconds
Avg Batch time: 7.1767 seconds

Train time: 2806.139232158661
 * Prec@1 89.970 Prec@5 99.740 Loss 0.2932
Avg Loading time: 6.6136 seconds
Avg Batch time: 6.6977 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 535.2879285812378

Epoch: [30][77/391]	LR: 8e-05	DT: 0.000 (8.414)	BT: 0.171 (8.602)	Loss 0.3057 (0.2348)	Prec@1 87.500 (92.127)	
Epoch: [30][155/391]	LR: 8e-05	DT: 0.000 (8.525)	BT: 0.176 (8.713)	Loss 0.2051 (0.2423)	Prec@1 91.406 (92.062)	
Epoch: [30][233/391]	LR: 8e-05	DT: 2.106 (8.382)	BT: 2.295 (8.569)	Loss 0.2036 (0.2379)	Prec@1 92.188 (92.167)	
Epoch: [30][311/391]	LR: 8e-05	DT: 0.000 (8.109)	BT: 0.174 (8.296)	Loss 0.2269 (0.2398)	Prec@1 90.625 (92.100)	
Epoch: [30][389/391]	LR: 8e-05	DT: 0.483 (7.978)	BT: 0.659 (8.165)	Loss 0.2263 (0.2399)	Prec@1 93.750 (92.087)	
Total train loss: 0.2400
Avg Loading time: 7.9577 seconds
Avg Batch time: 8.1443 seconds

Train time: 3184.6824717521667
 * Prec@1 89.950 Prec@5 99.760 Loss 0.2915
Avg Loading time: 6.2984 seconds
Avg Batch time: 6.3635 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 505.69083547592163

Epoch: [31][77/391]	LR: 8e-05	DT: 0.000 (7.215)	BT: 0.175 (7.402)	Loss 0.2120 (0.2427)	Prec@1 92.969 (92.248)	
Epoch: [31][155/391]	LR: 8e-05	DT: 0.000 (7.377)	BT: 0.171 (7.564)	Loss 0.2378 (0.2477)	Prec@1 93.750 (91.927)	
Epoch: [31][233/391]	LR: 8e-05	DT: 0.000 (7.229)	BT: 0.188 (7.414)	Loss 0.2710 (0.2444)	Prec@1 92.969 (92.021)	
Epoch: [31][311/391]	LR: 8e-05	DT: 0.000 (7.171)	BT: 0.176 (7.355)	Loss 0.1968 (0.2440)	Prec@1 94.531 (91.992)	
Epoch: [31][389/391]	LR: 8e-05	DT: 0.000 (7.237)	BT: 0.172 (7.421)	Loss 0.2542 (0.2434)	Prec@1 91.406 (91.997)	
Total train loss: 0.2435
Avg Loading time: 7.2185 seconds
Avg Batch time: 7.4026 seconds

Train time: 2894.633902311325
 * Prec@1 89.990 Prec@5 99.740 Loss 0.2915
Avg Loading time: 7.3747 seconds
Avg Batch time: 7.4379 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 588.3285641670227

Epoch: [32][77/391]	LR: 8e-05	DT: 0.782 (6.861)	BT: 0.954 (7.045)	Loss 0.2355 (0.2443)	Prec@1 93.750 (91.947)	
Epoch: [32][155/391]	LR: 8e-05	DT: 0.000 (6.772)	BT: 0.172 (6.957)	Loss 0.2729 (0.2410)	Prec@1 90.625 (92.102)	
Epoch: [32][233/391]	LR: 8e-05	DT: 0.000 (7.357)	BT: 0.180 (7.542)	Loss 0.2253 (0.2398)	Prec@1 92.188 (92.188)	
Epoch: [32][311/391]	LR: 8e-05	DT: 0.000 (7.155)	BT: 0.182 (7.340)	Loss 0.2438 (0.2418)	Prec@1 90.625 (92.075)	
Epoch: [32][389/391]	LR: 8e-05	DT: 0.000 (7.144)	BT: 0.173 (7.329)	Loss 0.2710 (0.2415)	Prec@1 92.188 (92.027)	
Total train loss: 0.2414
Avg Loading time: 7.1254 seconds
Avg Batch time: 7.3102 seconds

Train time: 2858.3821296691895
 * Prec@1 89.970 Prec@5 99.750 Loss 0.2915
Avg Loading time: 7.3942 seconds
Avg Batch time: 7.4608 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 591.9260020256042

Epoch: [33][77/391]	LR: 8e-05	DT: 0.000 (7.569)	BT: 0.176 (7.756)	Loss 0.3083 (0.2529)	Prec@1 90.625 (91.777)	
Epoch: [33][155/391]	LR: 8e-05	DT: 13.142 (7.788)	BT: 13.324 (7.975)	Loss 0.2500 (0.2454)	Prec@1 91.406 (91.937)	
Epoch: [33][233/391]	LR: 8e-05	DT: 0.000 (7.328)	BT: 0.188 (7.516)	Loss 0.2330 (0.2415)	Prec@1 93.750 (92.067)	
Epoch: [33][311/391]	LR: 8e-05	DT: 0.000 (7.279)	BT: 0.173 (7.467)	Loss 0.2275 (0.2418)	Prec@1 92.188 (92.065)	
Epoch: [33][389/391]	LR: 8e-05	DT: 0.000 (7.350)	BT: 0.178 (7.538)	Loss 0.1884 (0.2408)	Prec@1 94.531 (92.065)	
Total train loss: 0.2408
Avg Loading time: 7.3314 seconds
Avg Batch time: 7.5190 seconds

Train time: 2940.004260778427
 * Prec@1 89.970 Prec@5 99.750 Loss 0.2920
Avg Loading time: 7.0607 seconds
Avg Batch time: 7.1228 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 563.2905130386353

Epoch: [34][77/391]	LR: 8e-05	DT: 0.000 (6.889)	BT: 0.173 (7.075)	Loss 0.3062 (0.2330)	Prec@1 89.062 (92.508)	
Epoch: [34][155/391]	LR: 8e-05	DT: 0.000 (7.108)	BT: 0.176 (7.294)	Loss 0.2231 (0.2381)	Prec@1 95.312 (92.142)	
Epoch: [34][233/391]	LR: 8e-05	DT: 0.000 (7.221)	BT: 0.177 (7.407)	Loss 0.2443 (0.2389)	Prec@1 91.406 (92.091)	
Epoch: [34][311/391]	LR: 8e-05	DT: 0.000 (6.933)	BT: 0.176 (7.119)	Loss 0.3005 (0.2426)	Prec@1 89.844 (91.987)	
Epoch: [34][389/391]	LR: 8e-05	DT: 0.000 (6.807)	BT: 0.171 (6.992)	Loss 0.2094 (0.2423)	Prec@1 93.750 (92.055)	
Total train loss: 0.2424
Avg Loading time: 6.7896 seconds
Avg Batch time: 6.9746 seconds

Train time: 2727.1072232723236
 * Prec@1 89.870 Prec@5 99.710 Loss 0.2915
Avg Loading time: 6.4356 seconds
Avg Batch time: 6.4966 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 513.8258881568909

Epoch: [35][77/391]	LR: 8e-05	DT: 0.000 (6.535)	BT: 0.175 (6.718)	Loss 0.1941 (0.2311)	Prec@1 94.531 (92.548)	
Epoch: [35][155/391]	LR: 8e-05	DT: 0.000 (6.519)	BT: 0.177 (6.703)	Loss 0.2413 (0.2409)	Prec@1 90.625 (92.107)	
Epoch: [35][233/391]	LR: 8e-05	DT: 2.285 (6.888)	BT: 2.489 (7.072)	Loss 0.1906 (0.2406)	Prec@1 93.750 (92.204)	
Epoch: [35][311/391]	LR: 8e-05	DT: 0.000 (6.856)	BT: 0.172 (7.040)	Loss 0.3613 (0.2420)	Prec@1 87.500 (92.177)	
Epoch: [35][389/391]	LR: 8e-05	DT: 0.000 (6.949)	BT: 0.174 (7.133)	Loss 0.3303 (0.2421)	Prec@1 89.844 (92.181)	
Total train loss: 0.2420
Avg Loading time: 6.9311 seconds
Avg Batch time: 7.1146 seconds

Train time: 2782.1934509277344
 * Prec@1 90.010 Prec@5 99.720 Loss 0.2932
Avg Loading time: 5.8771 seconds
Avg Batch time: 5.9468 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 470.715784072876

Epoch: [36][77/391]	LR: 8e-05	DT: 0.000 (7.230)	BT: 0.180 (7.418)	Loss 0.2057 (0.2457)	Prec@1 93.750 (91.997)	
Epoch: [36][155/391]	LR: 8e-05	DT: 0.000 (7.259)	BT: 0.173 (7.446)	Loss 0.1996 (0.2440)	Prec@1 94.531 (91.862)	
Epoch: [36][233/391]	LR: 8e-05	DT: 0.000 (6.898)	BT: 0.183 (7.085)	Loss 0.2136 (0.2414)	Prec@1 91.406 (91.904)	
Epoch: [36][311/391]	LR: 8e-05	DT: 0.000 (6.808)	BT: 0.171 (6.994)	Loss 0.2084 (0.2414)	Prec@1 92.969 (91.987)	
Epoch: [36][389/391]	LR: 8e-05	DT: 0.000 (6.915)	BT: 0.172 (7.100)	Loss 0.1938 (0.2419)	Prec@1 94.531 (91.961)	
Total train loss: 0.2419
Avg Loading time: 6.8971 seconds
Avg Batch time: 7.0823 seconds

Train time: 2769.238229751587
 * Prec@1 89.950 Prec@5 99.730 Loss 0.2913
Avg Loading time: 6.9996 seconds
Avg Batch time: 7.0705 seconds

Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 560.7935998439789

Epoch: [37][77/391]	LR: 8e-05	DT: 0.000 (6.142)	BT: 0.181 (6.328)	Loss 0.2629 (0.2421)	Prec@1 92.969 (92.137)	
Epoch: [37][155/391]	LR: 8e-05	DT: 0.000 (6.461)	BT: 0.175 (6.648)	Loss 0.2166 (0.2396)	Prec@1 93.750 (92.117)	
Epoch: [37][233/391]	LR: 8e-05	DT: 7.509 (6.870)	BT: 7.706 (7.058)	Loss 0.2391 (0.2409)	Prec@1 92.969 (92.114)	
Epoch: [37][311/391]	LR: 8e-05	DT: 2.871 (6.711)	BT: 3.055 (6.898)	Loss 0.1443 (0.2409)	Prec@1 95.312 (92.172)	
Epoch: [37][389/391]	LR: 8e-05	DT: 0.000 (6.765)	BT: 0.177 (6.952)	Loss 0.2727 (0.2414)	Prec@1 89.062 (92.129)	
Total train loss: 0.2414
Avg Loading time: 6.7473 seconds
Avg Batch time: 6.9345 seconds

Train time: 2711.437326192856
 * Prec@1 90.140 Prec@5 99.720 Loss 0.2915
Avg Loading time: 7.3465 seconds
Avg Batch time: 7.4142 seconds

Best acc: 90.140
--------------------------------------------------------------------------------
Test time: 587.890468120575

Epoch: [38][77/391]	LR: 8e-05	DT: 0.000 (7.284)	BT: 0.173 (7.471)	Loss 0.2236 (0.2412)	Prec@1 90.625 (92.077)	
Epoch: [38][155/391]	LR: 8e-05	DT: 0.000 (7.195)	BT: 0.171 (7.381)	Loss 0.3110 (0.2407)	Prec@1 87.500 (92.092)	
Epoch: [38][233/391]	LR: 8e-05	DT: 0.000 (6.939)	BT: 0.180 (7.125)	Loss 0.2593 (0.2419)	Prec@1 91.406 (92.084)	
Epoch: [38][311/391]	LR: 8e-05	DT: 0.000 (6.960)	BT: 0.174 (7.145)	Loss 0.2583 (0.2402)	Prec@1 92.188 (92.152)	
Epoch: [38][389/391]	LR: 8e-05	DT: 0.000 (7.017)	BT: 0.176 (7.201)	Loss 0.3027 (0.2400)	Prec@1 87.500 (92.169)	
Total train loss: 0.2401
Avg Loading time: 6.9986 seconds
Avg Batch time: 7.1830 seconds

Train time: 2808.6082952022552
 * Prec@1 90.080 Prec@5 99.740 Loss 0.2903
Avg Loading time: 7.5365 seconds
Avg Batch time: 7.5986 seconds

Best acc: 90.140
--------------------------------------------------------------------------------
Test time: 600.9181365966797

Epoch: [39][77/391]	LR: 8e-05	DT: 0.197 (6.796)	BT: 0.385 (6.981)	Loss 0.2047 (0.2402)	Prec@1 93.750 (91.877)	
Epoch: [39][155/391]	LR: 8e-05	DT: 0.000 (7.070)	BT: 0.177 (7.256)	Loss 0.1716 (0.2435)	Prec@1 96.094 (91.927)	
Epoch: [39][233/391]	LR: 8e-05	DT: 0.000 (7.187)	BT: 0.202 (7.372)	Loss 0.2111 (0.2440)	Prec@1 96.094 (91.981)	
Epoch: [39][311/391]	LR: 8e-05	DT: 0.000 (6.788)	BT: 0.174 (6.973)	Loss 0.2133 (0.2424)	Prec@1 92.969 (92.050)	
Epoch: [39][389/391]	LR: 8e-05	DT: 6.948 (6.823)	BT: 7.133 (7.009)	Loss 0.2269 (0.2412)	Prec@1 92.188 (92.095)	
Total train loss: 0.2412
Avg Loading time: 6.8056 seconds
Avg Batch time: 6.9911 seconds

Train time: 2733.5805189609528
 * Prec@1 90.050 Prec@5 99.750 Loss 0.2922
Avg Loading time: 6.6205 seconds
Avg Batch time: 6.6789 seconds

Best acc: 90.140
--------------------------------------------------------------------------------
Test time: 528.1924653053284

Epoch: [40][77/391]	LR: 1.6000000000000003e-05	DT: 0.281 (6.456)	BT: 0.470 (6.643)	Loss 0.2070 (0.2409)	Prec@1 96.094 (92.518)	
Epoch: [40][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.572)	BT: 0.176 (6.759)	Loss 0.1831 (0.2388)	Prec@1 95.312 (92.368)	
Epoch: [40][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.781)	BT: 0.191 (6.968)	Loss 0.1805 (0.2388)	Prec@1 94.531 (92.284)	
Epoch: [40][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.808)	BT: 0.172 (6.994)	Loss 0.2605 (0.2404)	Prec@1 93.750 (92.180)	
Epoch: [40][389/391]	LR: 1.6000000000000003e-05	DT: 0.113 (6.800)	BT: 0.289 (6.986)	Loss 0.3247 (0.2415)	Prec@1 90.625 (92.200)	
Total train loss: 0.2415
Avg Loading time: 6.7824 seconds
Avg Batch time: 6.9685 seconds

Train time: 2724.7425763607025
 * Prec@1 89.980 Prec@5 99.750 Loss 0.2910
Avg Loading time: 5.3317 seconds
Avg Batch time: 5.3950 seconds

Best acc: 90.140
--------------------------------------------------------------------------------
Test time: 427.3422281742096

Epoch: [41][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (7.215)	BT: 0.177 (7.402)	Loss 0.1753 (0.2426)	Prec@1 94.531 (92.188)	
Epoch: [41][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (7.172)	BT: 0.176 (7.358)	Loss 0.1586 (0.2456)	Prec@1 96.094 (92.027)	
Epoch: [41][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.858)	BT: 0.189 (7.045)	Loss 0.2319 (0.2452)	Prec@1 91.406 (91.977)	
Epoch: [41][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.854)	BT: 0.175 (7.041)	Loss 0.2495 (0.2431)	Prec@1 91.406 (92.077)	
Epoch: [41][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.967)	BT: 0.177 (7.154)	Loss 0.2166 (0.2433)	Prec@1 93.750 (92.025)	
Total train loss: 0.2433
Avg Loading time: 6.9495 seconds
Avg Batch time: 7.1358 seconds

Train time: 2790.1618065834045
 * Prec@1 89.990 Prec@5 99.730 Loss 0.2920
Avg Loading time: 7.0342 seconds
Avg Batch time: 7.1019 seconds

Best acc: 90.140
--------------------------------------------------------------------------------
Test time: 563.0313687324524

Epoch: [42][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.919)	BT: 0.177 (6.103)	Loss 0.1962 (0.2429)	Prec@1 96.094 (91.967)	
Epoch: [42][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.468)	BT: 0.172 (6.652)	Loss 0.1730 (0.2406)	Prec@1 94.531 (92.137)	
Epoch: [42][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.802)	BT: 0.191 (6.986)	Loss 0.2032 (0.2429)	Prec@1 93.750 (92.097)	
Epoch: [42][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.611)	BT: 0.170 (6.795)	Loss 0.2101 (0.2434)	Prec@1 94.531 (92.017)	
Epoch: [42][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.667)	BT: 0.176 (6.851)	Loss 0.2542 (0.2416)	Prec@1 92.969 (92.087)	
Total train loss: 0.2417
Avg Loading time: 6.6495 seconds
Avg Batch time: 6.8334 seconds

Train time: 2671.895129919052
 * Prec@1 90.030 Prec@5 99.750 Loss 0.2922
Avg Loading time: 6.9347 seconds
Avg Batch time: 6.9983 seconds

Best acc: 90.140
--------------------------------------------------------------------------------
Test time: 554.3573875427246

Epoch: [43][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.953)	BT: 0.174 (7.142)	Loss 0.3218 (0.2324)	Prec@1 87.500 (92.127)	
Epoch: [43][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.879)	BT: 0.174 (7.066)	Loss 0.2030 (0.2344)	Prec@1 92.969 (92.223)	
Epoch: [43][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.683)	BT: 0.188 (6.869)	Loss 0.1863 (0.2358)	Prec@1 93.750 (92.238)	
Epoch: [43][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.806)	BT: 0.177 (6.992)	Loss 0.1841 (0.2378)	Prec@1 92.188 (92.200)	
Epoch: [43][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.946)	BT: 0.178 (7.133)	Loss 0.2922 (0.2402)	Prec@1 87.500 (92.101)	
Total train loss: 0.2405
Avg Loading time: 6.9281 seconds
Avg Batch time: 7.1148 seconds

Train time: 2781.9751064777374
 * Prec@1 90.070 Prec@5 99.740 Loss 0.2913
Avg Loading time: 7.5913 seconds
Avg Batch time: 7.6586 seconds

Best acc: 90.140
--------------------------------------------------------------------------------
Test time: 607.0934205055237

Epoch: [44][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (7.210)	BT: 0.185 (7.396)	Loss 0.2668 (0.2383)	Prec@1 91.406 (92.458)	
Epoch: [44][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (7.452)	BT: 0.177 (7.638)	Loss 0.2751 (0.2435)	Prec@1 89.062 (92.182)	
Epoch: [44][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (7.367)	BT: 0.185 (7.553)	Loss 0.1868 (0.2421)	Prec@1 95.312 (92.258)	
Epoch: [44][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.907)	BT: 0.178 (7.093)	Loss 0.2377 (0.2426)	Prec@1 92.969 (92.213)	
Epoch: [44][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.979)	BT: 0.173 (7.165)	Loss 0.2015 (0.2415)	Prec@1 94.531 (92.190)	
Total train loss: 0.2415
Avg Loading time: 6.9613 seconds
Avg Batch time: 7.1473 seconds

Train time: 2794.657486438751
 * Prec@1 90.020 Prec@5 99.760 Loss 0.2915
Avg Loading time: 6.5651 seconds
Avg Batch time: 6.6283 seconds

Best acc: 90.140
--------------------------------------------------------------------------------
Test time: 524.2119898796082

Epoch: [45][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.446)	BT: 0.175 (6.633)	Loss 0.2380 (0.2424)	Prec@1 92.969 (91.997)	
Epoch: [45][155/391]	LR: 1.6000000000000003e-05	DT: 0.870 (6.569)	BT: 1.048 (6.756)	Loss 0.3145 (0.2443)	Prec@1 88.281 (91.967)	
Epoch: [45][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.921)	BT: 0.186 (7.108)	Loss 0.1783 (0.2454)	Prec@1 94.531 (91.917)	
Epoch: [45][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.989)	BT: 0.174 (7.175)	Loss 0.2097 (0.2427)	Prec@1 92.969 (91.950)	
Epoch: [45][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.987)	BT: 0.175 (7.173)	Loss 0.2751 (0.2416)	Prec@1 90.625 (92.033)	
Total train loss: 0.2416
Avg Loading time: 6.9690 seconds
Avg Batch time: 7.1552 seconds

Train time: 2797.750351190567
 * Prec@1 90.020 Prec@5 99.720 Loss 0.2927
Avg Loading time: 5.0932 seconds
Avg Batch time: 5.1542 seconds

Best acc: 90.140
--------------------------------------------------------------------------------
Test time: 407.7177526950836

Epoch: [46][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (7.554)	BT: 0.179 (7.742)	Loss 0.1808 (0.2400)	Prec@1 93.750 (92.167)	
Epoch: [46][155/391]	LR: 1.6000000000000003e-05	DT: 0.107 (7.710)	BT: 0.296 (7.898)	Loss 0.1885 (0.2428)	Prec@1 92.188 (91.972)	
Epoch: [46][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (7.619)	BT: 0.184 (7.807)	Loss 0.2798 (0.2434)	Prec@1 88.281 (91.897)	
Epoch: [46][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (7.627)	BT: 0.176 (7.814)	Loss 0.2576 (0.2439)	Prec@1 92.969 (91.857)	
Epoch: [46][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (7.739)	BT: 0.178 (7.927)	Loss 0.2263 (0.2432)	Prec@1 91.406 (91.935)	
Total train loss: 0.2433
Avg Loading time: 7.7191 seconds
Avg Batch time: 7.9068 seconds

Train time: 3091.7866418361664
 * Prec@1 90.020 Prec@5 99.720 Loss 0.2920
Avg Loading time: 6.9721 seconds
Avg Batch time: 7.0450 seconds

Best acc: 90.140
--------------------------------------------------------------------------------
Test time: 557.8921866416931

Epoch: [47][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.826)	BT: 0.176 (6.012)	Loss 0.2554 (0.2352)	Prec@1 94.531 (92.408)	
Epoch: [47][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.437)	BT: 0.178 (6.623)	Loss 0.2854 (0.2414)	Prec@1 91.406 (92.223)	
Epoch: [47][233/391]	LR: 1.6000000000000003e-05	DT: 1.545 (6.819)	BT: 1.735 (7.005)	Loss 0.1876 (0.2393)	Prec@1 92.188 (92.154)	
Epoch: [47][311/391]	LR: 1.6000000000000003e-05	DT: 6.228 (6.699)	BT: 6.414 (6.885)	Loss 0.2585 (0.2386)	Prec@1 92.969 (92.225)	
Epoch: [47][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.711)	BT: 0.178 (6.898)	Loss 0.1824 (0.2401)	Prec@1 94.531 (92.163)	
Total train loss: 0.2402
Avg Loading time: 6.6936 seconds
Avg Batch time: 6.8802 seconds

Train time: 2690.388189792633
 * Prec@1 89.950 Prec@5 99.740 Loss 0.2925
Avg Loading time: 6.9870 seconds
Avg Batch time: 7.0536 seconds

Best acc: 90.140
--------------------------------------------------------------------------------
Test time: 559.169385433197

Epoch: [48][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.830)	BT: 0.173 (7.020)	Loss 0.2018 (0.2430)	Prec@1 93.750 (91.977)	
Epoch: [48][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.673)	BT: 0.176 (6.862)	Loss 0.2715 (0.2414)	Prec@1 92.969 (92.177)	
Epoch: [48][233/391]	LR: 1.6000000000000003e-05	DT: 1.387 (6.646)	BT: 1.585 (6.834)	Loss 0.2312 (0.2435)	Prec@1 91.406 (92.044)	
Epoch: [48][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.734)	BT: 0.175 (6.922)	Loss 0.3074 (0.2413)	Prec@1 91.406 (92.125)	
Epoch: [48][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.839)	BT: 0.176 (7.027)	Loss 0.2240 (0.2413)	Prec@1 91.406 (92.121)	
Total train loss: 0.2413
Avg Loading time: 6.8217 seconds
Avg Batch time: 7.0093 seconds

Train time: 2740.7517449855804
 * Prec@1 90.050 Prec@5 99.740 Loss 0.2917
Avg Loading time: 7.4912 seconds
Avg Batch time: 7.5556 seconds

Best acc: 90.140
--------------------------------------------------------------------------------
Test time: 598.1977758407593

Epoch: [49][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.746)	BT: 0.177 (6.932)	Loss 0.2903 (0.2386)	Prec@1 89.062 (92.067)	
Epoch: [49][155/391]	LR: 1.6000000000000003e-05	DT: 0.300 (7.135)	BT: 0.487 (7.322)	Loss 0.2257 (0.2412)	Prec@1 92.188 (92.157)	
Epoch: [49][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (7.331)	BT: 0.187 (7.518)	Loss 0.1726 (0.2410)	Prec@1 93.750 (92.198)	
Epoch: [49][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (7.089)	BT: 0.170 (7.276)	Loss 0.2319 (0.2401)	Prec@1 90.625 (92.205)	
Epoch: [49][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (7.155)	BT: 0.171 (7.342)	Loss 0.3345 (0.2401)	Prec@1 87.500 (92.218)	
Total train loss: 0.2400
Avg Loading time: 7.1371 seconds
Avg Batch time: 7.3237 seconds

Train time: 2863.6235196590424
 * Prec@1 89.920 Prec@5 99.760 Loss 0.2915
Avg Loading time: 6.1563 seconds
Avg Batch time: 6.2184 seconds

Best acc: 90.140
--------------------------------------------------------------------------------
Test time: 491.8235595226288

