
      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x64/rram/one_batch/
          savedir: ../pretrained_models/frozen/x64/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 3
          frozen_layers: 3
DEVICE: cuda
GPU Id(s) being used: 3
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
 * Prec@1 1.280 Prec@5 5.340 Loss 4.6016
Avg Loading time: 3.4428 seconds
Avg Batch time: 3.4823 seconds

Pre-trained Prec@1 with 3 layers frozen: 1.2799999713897705 	 Loss: 4.6015625

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.01	DT: 0.000 (3.827)	BT: 0.070 (3.905)	Loss 1.8877 (2.9033)	Prec@1 57.812 (36.288)	
Epoch: [0][155/391]	LR: 0.01	DT: 0.000 (3.756)	BT: 0.084 (3.835)	Loss 1.4609 (2.3010)	Prec@1 67.969 (48.052)	
Epoch: [0][233/391]	LR: 0.01	DT: 0.000 (3.675)	BT: 0.085 (3.755)	Loss 1.3984 (2.0062)	Prec@1 63.281 (53.639)	
Epoch: [0][311/391]	LR: 0.01	DT: 0.000 (3.559)	BT: 0.073 (3.639)	Loss 1.1221 (1.8217)	Prec@1 69.531 (57.019)	
Epoch: [0][389/391]	LR: 0.01	DT: 0.000 (3.544)	BT: 0.069 (3.625)	Loss 1.0195 (1.6884)	Prec@1 71.875 (59.499)	
Total train loss: 1.6871
Avg Loading time: 3.5346 seconds
Avg Batch time: 3.6154 seconds

Train time: 1413.7316405773163
 * Prec@1 73.570 Prec@5 94.500 Loss 1.0039
Avg Loading time: 2.2593 seconds
Avg Batch time: 2.2927 seconds

Best acc: 73.570
--------------------------------------------------------------------------------
Test time: 182.48119640350342

Epoch: [1][77/391]	LR: 0.01	DT: 0.000 (1.607)	BT: 0.090 (1.693)	Loss 0.8550 (0.8586)	Prec@1 76.562 (77.885)	
Epoch: [1][155/391]	LR: 0.01	DT: 0.799 (1.708)	BT: 0.900 (1.794)	Loss 0.8857 (0.8618)	Prec@1 76.562 (77.579)	
Epoch: [1][233/391]	LR: 0.01	DT: 0.000 (1.666)	BT: 0.078 (1.751)	Loss 0.7520 (0.8549)	Prec@1 82.031 (77.404)	
Epoch: [1][311/391]	LR: 0.01	DT: 0.960 (1.390)	BT: 1.039 (1.477)	Loss 1.0059 (0.8507)	Prec@1 72.656 (77.406)	
Epoch: [1][389/391]	LR: 0.01	DT: 0.553 (1.583)	BT: 0.653 (1.671)	Loss 0.8447 (0.8457)	Prec@1 71.875 (77.314)	
Total train loss: 0.8456
Avg Loading time: 1.5790 seconds
Avg Batch time: 1.6667 seconds

Train time: 651.8036069869995
 * Prec@1 75.390 Prec@5 94.540 Loss 0.9082
Avg Loading time: 0.6683 seconds
Avg Batch time: 0.7033 seconds

Best acc: 75.390
--------------------------------------------------------------------------------
Test time: 56.7515983581543

Epoch: [2][77/391]	LR: 0.01	DT: 0.000 (0.841)	BT: 0.078 (0.929)	Loss 0.4785 (0.5321)	Prec@1 86.719 (86.018)	
Epoch: [2][155/391]	LR: 0.01	DT: 0.000 (0.857)	BT: 0.088 (0.944)	Loss 0.4763 (0.5334)	Prec@1 88.281 (85.887)	
Epoch: [2][233/391]	LR: 0.01	DT: 0.155 (0.880)	BT: 0.244 (0.967)	Loss 0.4985 (0.5353)	Prec@1 86.719 (85.837)	
Epoch: [2][311/391]	LR: 0.01	DT: 0.000 (0.963)	BT: 0.076 (1.049)	Loss 0.5020 (0.5400)	Prec@1 85.938 (85.552)	
Epoch: [2][389/391]	LR: 0.01	DT: 0.000 (1.067)	BT: 0.074 (1.153)	Loss 0.5391 (0.5475)	Prec@1 82.812 (85.306)	
Total train loss: 0.5477
Avg Loading time: 1.0642 seconds
Avg Batch time: 1.1505 seconds

Train time: 449.95625615119934
 * Prec@1 76.550 Prec@5 94.790 Loss 0.8799
Avg Loading time: 1.7375 seconds
Avg Batch time: 1.7758 seconds

Best acc: 76.550
--------------------------------------------------------------------------------
Test time: 141.4992687702179

Epoch: [3][77/391]	LR: 0.01	DT: 0.511 (1.396)	BT: 0.599 (1.481)	Loss 0.2983 (0.3438)	Prec@1 94.531 (91.827)	
Epoch: [3][155/391]	LR: 0.01	DT: 2.926 (1.518)	BT: 3.023 (1.604)	Loss 0.2922 (0.3428)	Prec@1 92.188 (91.662)	
Epoch: [3][233/391]	LR: 0.01	DT: 0.000 (1.665)	BT: 0.089 (1.751)	Loss 0.4485 (0.3413)	Prec@1 88.281 (91.627)	
Epoch: [3][311/391]	LR: 0.01	DT: 0.000 (1.799)	BT: 0.077 (1.886)	Loss 0.4282 (0.3439)	Prec@1 90.625 (91.514)	
Epoch: [3][389/391]	LR: 0.01	DT: 2.626 (1.850)	BT: 2.722 (1.937)	Loss 0.3130 (0.3494)	Prec@1 92.969 (91.250)	
Total train loss: 0.3497
Avg Loading time: 1.8449 seconds
Avg Batch time: 1.9318 seconds

Train time: 755.4259176254272
 * Prec@1 76.950 Prec@5 94.140 Loss 0.8950
Avg Loading time: 2.1651 seconds
Avg Batch time: 2.1990 seconds

Best acc: 76.950
--------------------------------------------------------------------------------
Test time: 175.24079418182373

Epoch: [4][77/391]	LR: 0.01	DT: 1.527 (0.415)	BT: 1.618 (0.509)	Loss 0.2551 (0.2221)	Prec@1 93.750 (95.423)	
Epoch: [4][155/391]	LR: 0.01	DT: 0.677 (0.560)	BT: 0.765 (0.653)	Loss 0.2257 (0.2093)	Prec@1 95.312 (95.703)	
Epoch: [4][233/391]	LR: 0.01	DT: 2.900 (0.708)	BT: 3.007 (0.801)	Loss 0.1711 (0.2090)	Prec@1 97.656 (95.650)	
Epoch: [4][311/391]	LR: 0.01	DT: 0.000 (0.826)	BT: 0.107 (0.918)	Loss 0.2676 (0.2133)	Prec@1 94.531 (95.488)	
Epoch: [4][389/391]	LR: 0.01	DT: 7.119 (0.957)	BT: 7.216 (1.050)	Loss 0.2632 (0.2170)	Prec@1 92.188 (95.321)	
Total train loss: 0.2171
Avg Loading time: 0.9547 seconds
Avg Batch time: 1.0471 seconds

Train time: 409.5287854671478
 * Prec@1 76.650 Prec@5 93.540 Loss 0.9434
Avg Loading time: 1.5887 seconds
Avg Batch time: 1.6238 seconds

Best acc: 76.950
--------------------------------------------------------------------------------
Test time: 129.05796456336975

Epoch: [5][77/391]	LR: 0.01	DT: 1.288 (1.253)	BT: 1.388 (1.345)	Loss 0.1975 (0.1473)	Prec@1 94.531 (97.246)	
Epoch: [5][155/391]	LR: 0.01	DT: 0.000 (1.318)	BT: 0.094 (1.410)	Loss 0.2499 (0.1495)	Prec@1 95.312 (97.246)	
Epoch: [5][233/391]	LR: 0.01	DT: 7.408 (1.423)	BT: 7.511 (1.515)	Loss 0.1694 (0.1489)	Prec@1 93.750 (97.246)	
Epoch: [5][311/391]	LR: 0.01	DT: 0.000 (1.530)	BT: 0.116 (1.622)	Loss 0.0991 (0.1517)	Prec@1 100.000 (97.173)	
Epoch: [5][389/391]	LR: 0.01	DT: 0.000 (1.674)	BT: 0.089 (1.766)	Loss 0.1669 (0.1540)	Prec@1 96.094 (97.053)	
Total train loss: 0.1541
Avg Loading time: 1.6695 seconds
Avg Batch time: 1.7617 seconds

Train time: 688.9366927146912
 * Prec@1 77.940 Prec@5 93.810 Loss 0.9136
Avg Loading time: 0.5654 seconds
Avg Batch time: 0.6017 seconds

Best acc: 77.940
--------------------------------------------------------------------------------
Test time: 48.743523597717285

Epoch: [6][77/391]	LR: 0.01	DT: 0.069 (1.272)	BT: 0.149 (1.359)	Loss 0.1382 (0.1116)	Prec@1 98.438 (98.247)	
Epoch: [6][155/391]	LR: 0.01	DT: 0.000 (1.419)	BT: 0.073 (1.506)	Loss 0.0701 (0.1067)	Prec@1 99.219 (98.392)	
Epoch: [6][233/391]	LR: 0.01	DT: 0.000 (1.412)	BT: 0.089 (1.498)	Loss 0.1216 (0.1057)	Prec@1 97.656 (98.364)	
Epoch: [6][311/391]	LR: 0.01	DT: 0.000 (1.520)	BT: 0.087 (1.607)	Loss 0.1057 (0.1067)	Prec@1 98.438 (98.337)	
Epoch: [6][389/391]	LR: 0.01	DT: 0.000 (1.698)	BT: 0.075 (1.785)	Loss 0.1572 (0.1090)	Prec@1 96.875 (98.241)	
Total train loss: 0.1091
Avg Loading time: 1.6937 seconds
Avg Batch time: 1.7809 seconds

Train time: 696.4554178714752
 * Prec@1 77.620 Prec@5 93.310 Loss 0.9409
Avg Loading time: 2.4517 seconds
Avg Batch time: 2.4891 seconds

Best acc: 77.940
--------------------------------------------------------------------------------
Test time: 197.3781282901764

Epoch: [7][77/391]	LR: 0.01	DT: 0.000 (1.436)	BT: 0.083 (1.526)	Loss 0.0627 (0.0882)	Prec@1 100.000 (98.888)	
Epoch: [7][155/391]	LR: 0.01	DT: 2.518 (1.530)	BT: 2.625 (1.619)	Loss 0.0646 (0.0841)	Prec@1 100.000 (98.913)	
Epoch: [7][233/391]	LR: 0.01	DT: 0.000 (1.655)	BT: 0.091 (1.745)	Loss 0.0944 (0.0839)	Prec@1 98.438 (98.912)	
Epoch: [7][311/391]	LR: 0.01	DT: 0.000 (1.769)	BT: 0.070 (1.857)	Loss 0.0696 (0.0849)	Prec@1 99.219 (98.858)	
Epoch: [7][389/391]	LR: 0.01	DT: 0.000 (1.924)	BT: 0.077 (2.011)	Loss 0.0678 (0.0868)	Prec@1 99.219 (98.782)	
Total train loss: 0.0869
Avg Loading time: 1.9186 seconds
Avg Batch time: 2.0062 seconds

Train time: 784.539389371872
 * Prec@1 78.060 Prec@5 93.310 Loss 0.9272
Avg Loading time: 1.3976 seconds
Avg Batch time: 1.4338 seconds

Best acc: 78.060
--------------------------------------------------------------------------------
Test time: 114.46574640274048

Epoch: [8][77/391]	LR: 0.01	DT: 0.000 (0.524)	BT: 0.077 (0.614)	Loss 0.0783 (0.0756)	Prec@1 97.656 (98.958)	
Epoch: [8][155/391]	LR: 0.01	DT: 0.000 (0.722)	BT: 0.089 (0.811)	Loss 0.0845 (0.0722)	Prec@1 98.438 (99.043)	
Epoch: [8][233/391]	LR: 0.01	DT: 0.000 (0.820)	BT: 0.077 (0.910)	Loss 0.1299 (0.0710)	Prec@1 98.438 (99.072)	
Epoch: [8][311/391]	LR: 0.01	DT: 0.000 (0.981)	BT: 0.096 (1.070)	Loss 0.1061 (0.0727)	Prec@1 96.875 (99.028)	
Epoch: [8][389/391]	LR: 0.01	DT: 0.000 (1.143)	BT: 0.078 (1.232)	Loss 0.0581 (0.0735)	Prec@1 99.219 (99.000)	
Total train loss: 0.0735
Avg Loading time: 1.1398 seconds
Avg Batch time: 1.2286 seconds

Train time: 480.4918644428253
 * Prec@1 78.120 Prec@5 93.500 Loss 0.9360
Avg Loading time: 1.8673 seconds
Avg Batch time: 1.9046 seconds

Best acc: 78.120
--------------------------------------------------------------------------------
Test time: 151.91794085502625

Epoch: [9][77/391]	LR: 0.01	DT: 5.015 (1.461)	BT: 5.119 (1.554)	Loss 0.0540 (0.0655)	Prec@1 99.219 (99.028)	
Epoch: [9][155/391]	LR: 0.01	DT: 0.000 (1.472)	BT: 0.075 (1.562)	Loss 0.0345 (0.0647)	Prec@1 100.000 (99.144)	
Epoch: [9][233/391]	LR: 0.01	DT: 0.000 (1.611)	BT: 0.079 (1.699)	Loss 0.0701 (0.0628)	Prec@1 100.000 (99.192)	
Epoch: [9][311/391]	LR: 0.01	DT: 0.000 (1.774)	BT: 0.085 (1.861)	Loss 0.0713 (0.0638)	Prec@1 97.656 (99.171)	
Epoch: [9][389/391]	LR: 0.01	DT: 16.458 (1.821)	BT: 16.568 (1.908)	Loss 0.0576 (0.0632)	Prec@1 98.438 (99.195)	
Total train loss: 0.0633
Avg Loading time: 1.8164 seconds
Avg Batch time: 1.9034 seconds

Train time: 744.3530869483948
 * Prec@1 77.880 Prec@5 92.790 Loss 0.9722
Avg Loading time: 1.9065 seconds
Avg Batch time: 1.9439 seconds

Best acc: 78.120
--------------------------------------------------------------------------------
Test time: 154.25468039512634

Epoch: [10][77/391]	LR: 0.001	DT: 0.000 (1.225)	BT: 0.088 (1.315)	Loss 0.0316 (0.0543)	Prec@1 100.000 (99.529)	
Epoch: [10][155/391]	LR: 0.001	DT: 10.661 (1.548)	BT: 10.762 (1.637)	Loss 0.0540 (0.0540)	Prec@1 100.000 (99.509)	
Epoch: [10][233/391]	LR: 0.001	DT: 7.096 (1.769)	BT: 7.202 (1.858)	Loss 0.0274 (0.0521)	Prec@1 100.000 (99.526)	
Epoch: [10][311/391]	LR: 0.001	DT: 0.000 (1.991)	BT: 0.080 (2.080)	Loss 0.0354 (0.0509)	Prec@1 100.000 (99.567)	
Epoch: [10][389/391]	LR: 0.001	DT: 0.000 (2.157)	BT: 0.079 (2.246)	Loss 0.0353 (0.0504)	Prec@1 100.000 (99.571)	
Total train loss: 0.0505
Avg Loading time: 2.1518 seconds
Avg Batch time: 2.2405 seconds

Train time: 876.1509299278259
 * Prec@1 78.730 Prec@5 93.300 Loss 0.9224
Avg Loading time: 2.1924 seconds
Avg Batch time: 2.2284 seconds

Best acc: 78.730
--------------------------------------------------------------------------------
Test time: 177.559387922287

Epoch: [11][77/391]	LR: 0.001	DT: 0.000 (1.745)	BT: 0.079 (1.830)	Loss 0.0558 (0.0478)	Prec@1 100.000 (99.529)	
Epoch: [11][155/391]	LR: 0.001	DT: 0.000 (1.903)	BT: 0.088 (1.988)	Loss 0.0488 (0.0465)	Prec@1 100.000 (99.614)	
Epoch: [11][233/391]	LR: 0.001	DT: 18.550 (1.810)	BT: 18.656 (1.896)	Loss 0.0524 (0.0457)	Prec@1 98.438 (99.629)	
Epoch: [11][311/391]	LR: 0.001	DT: 0.000 (1.867)	BT: 0.104 (1.954)	Loss 0.0423 (0.0446)	Prec@1 99.219 (99.639)	
Epoch: [11][389/391]	LR: 0.001	DT: 0.000 (1.896)	BT: 0.079 (1.984)	Loss 0.0336 (0.0448)	Prec@1 100.000 (99.639)	
Total train loss: 0.0449
Avg Loading time: 1.8913 seconds
Avg Batch time: 1.9792 seconds

Train time: 774.0014169216156
 * Prec@1 79.110 Prec@5 93.510 Loss 0.9058
Avg Loading time: 1.9431 seconds
Avg Batch time: 1.9807 seconds

Best acc: 79.110
--------------------------------------------------------------------------------
Test time: 157.67370176315308

Epoch: [12][77/391]	LR: 0.001	DT: 0.000 (1.242)	BT: 0.088 (1.333)	Loss 0.0405 (0.0412)	Prec@1 100.000 (99.770)	
Epoch: [12][155/391]	LR: 0.001	DT: 0.000 (1.278)	BT: 0.089 (1.370)	Loss 0.0226 (0.0421)	Prec@1 100.000 (99.745)	
Epoch: [12][233/391]	LR: 0.001	DT: 0.000 (1.380)	BT: 0.096 (1.473)	Loss 0.0313 (0.0428)	Prec@1 100.000 (99.723)	
Epoch: [12][311/391]	LR: 0.001	DT: 0.000 (1.458)	BT: 0.086 (1.551)	Loss 0.0445 (0.0420)	Prec@1 100.000 (99.740)	
Epoch: [12][389/391]	LR: 0.001	DT: 3.242 (1.595)	BT: 3.347 (1.688)	Loss 0.0426 (0.0422)	Prec@1 100.000 (99.736)	
Total train loss: 0.0422
Avg Loading time: 1.5907 seconds
Avg Batch time: 1.6835 seconds

Train time: 658.3512845039368
 * Prec@1 79.160 Prec@5 93.510 Loss 0.8945
Avg Loading time: 2.9673 seconds
Avg Batch time: 3.0037 seconds

Best acc: 79.160
--------------------------------------------------------------------------------
Test time: 238.51544880867004

Epoch: [13][77/391]	LR: 0.001	DT: 0.000 (0.913)	BT: 0.078 (1.003)	Loss 0.0337 (0.0396)	Prec@1 100.000 (99.850)	
Epoch: [13][155/391]	LR: 0.001	DT: 0.000 (0.917)	BT: 0.079 (1.006)	Loss 0.0320 (0.0412)	Prec@1 99.219 (99.725)	
Epoch: [13][233/391]	LR: 0.001	DT: 0.000 (1.159)	BT: 0.091 (1.246)	Loss 0.0351 (0.0408)	Prec@1 99.219 (99.733)	
Epoch: [13][311/391]	LR: 0.001	DT: 0.000 (1.129)	BT: 0.077 (1.215)	Loss 0.0377 (0.0406)	Prec@1 100.000 (99.752)	
Epoch: [13][389/391]	LR: 0.001	DT: 0.000 (1.250)	BT: 0.074 (1.336)	Loss 0.0519 (0.0403)	Prec@1 99.219 (99.744)	
Total train loss: 0.0403
Avg Loading time: 1.2467 seconds
Avg Batch time: 1.3331 seconds

Train time: 521.3432705402374
