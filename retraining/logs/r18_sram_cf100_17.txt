
      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/sram/one_batch/
          savedir: ../pretrained_models/frozen/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          workers: 8
          epochs: 40
          start_epoch: 0
          batch_size: 256
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.5
          milestones: [10, 20, 30]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 0
          frozen_layers: 17
DEVICE: cuda
GPU Id(s) being used: 0
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
 * Prec@1 1.110 Prec@5 4.770 Loss 4.6211
Avg Loading time: 5.1309 seconds
Avg Batch time: 5.1515 seconds

Pre-trained Prec@1 with 17 layers frozen: 1.1100000143051147 	 Loss: 4.62109375

Starting training on SRAM layers...
Epoch: [0][38/196]	LR: 0.1	DT: 0.000 (7.759)	BT: 0.006 (7.769)	Loss 1.8936 (2.5478)	Prec@1 54.688 (43.540)	
Epoch: [0][77/196]	LR: 0.1	DT: 0.000 (7.936)	BT: 0.006 (7.945)	Loss 1.5166 (2.1190)	Prec@1 61.719 (50.230)	
Epoch: [0][116/196]	LR: 0.1	DT: 0.000 (8.000)	BT: 0.006 (8.009)	Loss 1.3867 (1.9028)	Prec@1 62.109 (54.083)	
Epoch: [0][155/196]	LR: 0.1	DT: 0.000 (7.921)	BT: 0.008 (7.931)	Loss 1.3672 (1.7751)	Prec@1 65.234 (56.303)	
Epoch: [0][194/196]	LR: 0.1	DT: 0.000 (7.698)	BT: 0.011 (7.708)	Loss 1.5312 (1.6927)	Prec@1 59.375 (57.608)	
Total train loss: 1.6926
Avg Loading time: 7.6591 seconds
Avg Batch time: 7.6684 seconds

 * Prec@1 64.540 Prec@5 89.970 Loss 1.2930
Avg Loading time: 1.6025 seconds
Avg Batch time: 1.6104 seconds

Best acc: 64.540
--------------------------------------------------------------------------------
Epoch: [1][38/196]	LR: 0.1	DT: 0.000 (0.831)	BT: 0.009 (0.839)	Loss 1.3613 (1.1644)	Prec@1 61.328 (68.309)	
Epoch: [1][77/196]	LR: 0.1	DT: 0.753 (0.812)	BT: 0.763 (0.821)	Loss 1.2773 (1.1724)	Prec@1 67.188 (67.718)	
Epoch: [1][116/196]	LR: 0.1	DT: 0.177 (0.763)	BT: 0.193 (0.771)	Loss 1.1641 (1.1854)	Prec@1 67.578 (67.188)	
Epoch: [1][155/196]	LR: 0.1	DT: 0.000 (0.765)	BT: 0.013 (0.774)	Loss 1.3037 (1.1807)	Prec@1 62.109 (67.055)	
Epoch: [1][194/196]	LR: 0.1	DT: 1.959 (0.771)	BT: 1.970 (0.781)	Loss 1.2852 (1.1813)	Prec@1 62.891 (67.055)	
Total train loss: 1.1814
Avg Loading time: 0.7675 seconds
Avg Batch time: 0.7766 seconds

 * Prec@1 65.280 Prec@5 90.490 Loss 1.2295
Avg Loading time: 0.7185 seconds
Avg Batch time: 0.7243 seconds

Best acc: 65.280
--------------------------------------------------------------------------------
Epoch: [2][38/196]	LR: 0.1	DT: 0.000 (1.051)	BT: 0.005 (1.058)	Loss 1.1523 (1.0329)	Prec@1 71.094 (71.264)	
Epoch: [2][77/196]	LR: 0.1	DT: 0.000 (1.022)	BT: 0.006 (1.029)	Loss 1.0195 (1.0462)	Prec@1 72.266 (70.653)	
Epoch: [2][116/196]	LR: 0.1	DT: 0.000 (0.999)	BT: 0.005 (1.006)	Loss 1.1045 (1.0589)	Prec@1 70.312 (69.979)	
Epoch: [2][155/196]	LR: 0.1	DT: 0.000 (0.987)	BT: 0.006 (0.994)	Loss 1.0908 (1.0686)	Prec@1 69.141 (69.579)	
Epoch: [2][194/196]	LR: 0.1	DT: 0.000 (1.024)	BT: 0.007 (1.031)	Loss 1.1426 (1.0748)	Prec@1 70.312 (69.407)	
Total train loss: 1.0749
Avg Loading time: 1.0189 seconds
Avg Batch time: 1.0260 seconds

 * Prec@1 65.760 Prec@5 90.330 Loss 1.2246
Avg Loading time: 1.0886 seconds
Avg Batch time: 1.0949 seconds

Best acc: 65.760
--------------------------------------------------------------------------------
Epoch: [3][38/196]	LR: 0.1	DT: 0.000 (0.905)	BT: 0.005 (0.912)	Loss 1.0225 (0.9432)	Prec@1 72.266 (73.458)	
Epoch: [3][77/196]	LR: 0.1	DT: 0.000 (0.949)	BT: 0.008 (0.956)	Loss 0.9595 (0.9639)	Prec@1 75.000 (72.636)	
Epoch: [3][116/196]	LR: 0.1	DT: 0.051 (0.825)	BT: 0.059 (0.832)	Loss 0.9990 (0.9804)	Prec@1 68.750 (71.972)	
Epoch: [3][155/196]	LR: 0.1	DT: 0.000 (0.722)	BT: 0.006 (0.729)	Loss 0.8491 (0.9921)	Prec@1 76.172 (71.572)	
Epoch: [3][194/196]	LR: 0.1	DT: 0.046 (0.652)	BT: 0.062 (0.660)	Loss 1.2441 (1.0092)	Prec@1 61.719 (71.052)	
Total train loss: 1.0094
Avg Loading time: 0.6488 seconds
Avg Batch time: 0.6565 seconds

 * Prec@1 65.490 Prec@5 90.210 Loss 1.2305
Avg Loading time: 0.3901 seconds
Avg Batch time: 0.3953 seconds

Best acc: 65.760
--------------------------------------------------------------------------------
Epoch: [4][38/196]	LR: 0.1	DT: 0.000 (0.354)	BT: 0.009 (0.362)	Loss 0.9570 (0.9050)	Prec@1 71.094 (74.419)	
Epoch: [4][77/196]	LR: 0.1	DT: 0.000 (0.318)	BT: 0.009 (0.326)	Loss 1.0049 (0.9295)	Prec@1 71.875 (73.357)	
Epoch: [4][116/196]	LR: 0.1	DT: 0.140 (0.289)	BT: 0.147 (0.297)	Loss 0.9302 (0.9454)	Prec@1 74.219 (72.857)	
Epoch: [4][155/196]	LR: 0.1	DT: 0.392 (0.326)	BT: 0.401 (0.334)	Loss 1.0381 (0.9595)	Prec@1 71.875 (72.483)	
Epoch: [4][194/196]	LR: 0.1	DT: 0.000 (0.353)	BT: 0.006 (0.361)	Loss 1.0312 (0.9706)	Prec@1 68.750 (72.053)	
Total train loss: 0.9711
Avg Loading time: 0.3514 seconds
Avg Batch time: 0.3597 seconds

 * Prec@1 65.930 Prec@5 90.380 Loss 1.2207
Avg Loading time: 0.4439 seconds
Avg Batch time: 0.4494 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [5][38/196]	LR: 0.1	DT: 0.000 (0.474)	BT: 0.005 (0.482)	Loss 0.9009 (0.8529)	Prec@1 75.000 (75.541)	
Epoch: [5][77/196]	LR: 0.1	DT: 0.401 (0.462)	BT: 0.412 (0.470)	Loss 1.0215 (0.8914)	Prec@1 69.922 (74.484)	
Epoch: [5][116/196]	LR: 0.1	DT: 0.000 (0.471)	BT: 0.005 (0.478)	Loss 0.9185 (0.9139)	Prec@1 75.000 (73.601)	
Epoch: [5][155/196]	LR: 0.1	DT: 0.000 (0.472)	BT: 0.006 (0.480)	Loss 1.0723 (0.9252)	Prec@1 69.531 (73.160)	
Epoch: [5][194/196]	LR: 0.1	DT: 0.000 (0.473)	BT: 0.008 (0.481)	Loss 1.0195 (0.9398)	Prec@1 72.266 (72.796)	
Total train loss: 0.9403
Avg Loading time: 0.4711 seconds
Avg Batch time: 0.4784 seconds

 * Prec@1 65.630 Prec@5 90.060 Loss 1.2373
Avg Loading time: 0.4061 seconds
Avg Batch time: 0.4122 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [6][38/196]	LR: 0.1	DT: 0.000 (0.405)	BT: 0.008 (0.414)	Loss 0.8633 (0.8558)	Prec@1 76.953 (75.371)	
Epoch: [6][77/196]	LR: 0.1	DT: 1.675 (0.402)	BT: 1.686 (0.411)	Loss 0.9824 (0.8762)	Prec@1 71.875 (74.865)	
Epoch: [6][116/196]	LR: 0.1	DT: 0.010 (0.431)	BT: 0.016 (0.440)	Loss 1.0078 (0.8931)	Prec@1 70.703 (74.336)	
Epoch: [6][155/196]	LR: 0.1	DT: 0.000 (0.423)	BT: 0.009 (0.432)	Loss 1.0615 (0.9056)	Prec@1 68.359 (73.916)	
Epoch: [6][194/196]	LR: 0.1	DT: 0.000 (0.422)	BT: 0.006 (0.431)	Loss 0.8955 (0.9160)	Prec@1 72.656 (73.556)	
Total train loss: 0.9160
Avg Loading time: 0.4202 seconds
Avg Batch time: 0.4286 seconds

 * Prec@1 65.780 Prec@5 90.080 Loss 1.2373
Avg Loading time: 0.5528 seconds
Avg Batch time: 0.5588 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [7][38/196]	LR: 0.1	DT: 0.276 (0.560)	BT: 0.286 (0.569)	Loss 0.8706 (0.8344)	Prec@1 74.219 (75.811)	
Epoch: [7][77/196]	LR: 0.1	DT: 0.019 (0.536)	BT: 0.030 (0.545)	Loss 0.9883 (0.8514)	Prec@1 70.703 (75.005)	
Epoch: [7][116/196]	LR: 0.1	DT: 0.000 (0.557)	BT: 0.006 (0.566)	Loss 0.9438 (0.8725)	Prec@1 73.828 (74.372)	
Epoch: [7][155/196]	LR: 0.1	DT: 0.000 (0.553)	BT: 0.006 (0.562)	Loss 1.0195 (0.8890)	Prec@1 67.969 (73.936)	
Epoch: [7][194/196]	LR: 0.1	DT: 0.000 (0.530)	BT: 0.005 (0.538)	Loss 1.0498 (0.9016)	Prec@1 71.484 (73.660)	
Total train loss: 0.9017
Avg Loading time: 0.5271 seconds
Avg Batch time: 0.5355 seconds

 * Prec@1 65.290 Prec@5 89.970 Loss 1.2490
Avg Loading time: 0.2905 seconds
Avg Batch time: 0.2966 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [8][38/196]	LR: 0.1	DT: 0.000 (0.261)	BT: 0.007 (0.269)	Loss 0.7563 (0.8159)	Prec@1 76.562 (76.182)	
Epoch: [8][77/196]	LR: 0.1	DT: 0.000 (0.285)	BT: 0.005 (0.293)	Loss 0.8481 (0.8400)	Prec@1 76.172 (75.506)	
Epoch: [8][116/196]	LR: 0.1	DT: 0.000 (0.282)	BT: 0.006 (0.290)	Loss 0.9702 (0.8583)	Prec@1 74.219 (74.853)	
Epoch: [8][155/196]	LR: 0.1	DT: 0.000 (0.338)	BT: 0.008 (0.346)	Loss 0.9883 (0.8727)	Prec@1 70.703 (74.377)	
Epoch: [8][194/196]	LR: 0.1	DT: 0.000 (0.352)	BT: 0.011 (0.360)	Loss 1.0078 (0.8818)	Prec@1 72.266 (74.121)	
Total train loss: 0.8822
Avg Loading time: 0.3503 seconds
Avg Batch time: 0.3583 seconds

 * Prec@1 65.550 Prec@5 90.110 Loss 1.2510
Avg Loading time: 0.4238 seconds
Avg Batch time: 0.4298 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [9][38/196]	LR: 0.1	DT: 0.000 (0.398)	BT: 0.005 (0.405)	Loss 0.7944 (0.8008)	Prec@1 77.734 (77.023)	
Epoch: [9][77/196]	LR: 0.1	DT: 0.000 (0.393)	BT: 0.007 (0.400)	Loss 0.8535 (0.8178)	Prec@1 71.484 (76.122)	
Epoch: [9][116/196]	LR: 0.1	DT: 0.000 (0.412)	BT: 0.006 (0.420)	Loss 0.8955 (0.8373)	Prec@1 76.172 (75.377)	
Epoch: [9][155/196]	LR: 0.1	DT: 0.000 (0.427)	BT: 0.006 (0.435)	Loss 0.9907 (0.8568)	Prec@1 73.438 (74.787)	
Epoch: [9][194/196]	LR: 0.1	DT: 1.352 (0.434)	BT: 1.364 (0.441)	Loss 0.9434 (0.8704)	Prec@1 73.047 (74.379)	
Total train loss: 0.8706
Avg Loading time: 0.4315 seconds
Avg Batch time: 0.4392 seconds

 * Prec@1 65.830 Prec@5 90.120 Loss 1.2490
Avg Loading time: 0.4375 seconds
Avg Batch time: 0.4439 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [10][38/196]	LR: 0.05	DT: 0.000 (0.483)	BT: 0.006 (0.492)	Loss 0.8428 (0.7930)	Prec@1 73.828 (76.853)	
Epoch: [10][77/196]	LR: 0.05	DT: 0.000 (0.479)	BT: 0.011 (0.489)	Loss 0.8022 (0.7852)	Prec@1 73.047 (76.943)	
Epoch: [10][116/196]	LR: 0.05	DT: 1.074 (0.492)	BT: 1.089 (0.501)	Loss 0.7036 (0.7832)	Prec@1 79.688 (77.150)	
Epoch: [10][155/196]	LR: 0.05	DT: 0.000 (0.507)	BT: 0.006 (0.516)	Loss 0.8472 (0.7892)	Prec@1 76.562 (77.001)	
Epoch: [10][194/196]	LR: 0.05	DT: 0.000 (0.501)	BT: 0.006 (0.511)	Loss 0.8418 (0.7973)	Prec@1 74.609 (76.649)	
Total train loss: 0.7980
Avg Loading time: 0.4989 seconds
Avg Batch time: 0.5081 seconds

 * Prec@1 65.820 Prec@5 90.250 Loss 1.2471
Avg Loading time: 0.4979 seconds
Avg Batch time: 0.5037 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [11][38/196]	LR: 0.05	DT: 0.000 (0.521)	BT: 0.005 (0.530)	Loss 0.7202 (0.7372)	Prec@1 79.297 (78.796)	
Epoch: [11][77/196]	LR: 0.05	DT: 0.000 (0.545)	BT: 0.010 (0.553)	Loss 0.8276 (0.7554)	Prec@1 77.344 (78.110)	
Epoch: [11][116/196]	LR: 0.05	DT: 0.000 (0.543)	BT: 0.009 (0.551)	Loss 0.7603 (0.7656)	Prec@1 75.781 (77.698)	
Epoch: [11][155/196]	LR: 0.05	DT: 1.103 (0.550)	BT: 1.119 (0.558)	Loss 0.9517 (0.7761)	Prec@1 74.219 (77.384)	
Epoch: [11][194/196]	LR: 0.05	DT: 0.217 (0.602)	BT: 0.228 (0.611)	Loss 0.6626 (0.7823)	Prec@1 82.031 (77.091)	
Total train loss: 0.7823
Avg Loading time: 0.5994 seconds
Avg Batch time: 0.6075 seconds

 * Prec@1 65.760 Prec@5 90.130 Loss 1.2598
Avg Loading time: 0.5454 seconds
Avg Batch time: 0.5526 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [12][38/196]	LR: 0.05	DT: 0.000 (0.640)	BT: 0.007 (0.648)	Loss 0.7505 (0.7165)	Prec@1 77.344 (79.036)	
Epoch: [12][77/196]	LR: 0.05	DT: 0.000 (0.656)	BT: 0.005 (0.664)	Loss 0.8086 (0.7435)	Prec@1 78.125 (78.451)	
Epoch: [12][116/196]	LR: 0.05	DT: 0.000 (0.746)	BT: 0.007 (0.754)	Loss 0.7280 (0.7668)	Prec@1 79.688 (77.567)	
Epoch: [12][155/196]	LR: 0.05	DT: 0.000 (0.937)	BT: 0.009 (0.945)	Loss 0.7544 (0.7726)	Prec@1 79.688 (77.331)	
Epoch: [12][194/196]	LR: 0.05	DT: 0.151 (0.953)	BT: 0.158 (0.962)	Loss 0.8296 (0.7816)	Prec@1 75.781 (77.051)	
Total train loss: 0.7821
Avg Loading time: 0.9486 seconds
Avg Batch time: 0.9571 seconds

 * Prec@1 65.740 Prec@5 90.150 Loss 1.2646
Avg Loading time: 0.7079 seconds
Avg Batch time: 0.7132 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [13][38/196]	LR: 0.05	DT: 0.000 (0.595)	BT: 0.005 (0.602)	Loss 0.6860 (0.7311)	Prec@1 81.250 (78.726)	
Epoch: [13][77/196]	LR: 0.05	DT: 0.000 (0.636)	BT: 0.006 (0.644)	Loss 0.7402 (0.7439)	Prec@1 74.609 (78.365)	
Epoch: [13][116/196]	LR: 0.05	DT: 0.000 (0.661)	BT: 0.007 (0.669)	Loss 0.7466 (0.7576)	Prec@1 77.734 (77.965)	
Epoch: [13][155/196]	LR: 0.05	DT: 0.172 (0.669)	BT: 0.182 (0.677)	Loss 0.7051 (0.7651)	Prec@1 82.031 (77.769)	
Epoch: [13][194/196]	LR: 0.05	DT: 0.000 (0.675)	BT: 0.005 (0.683)	Loss 0.8843 (0.7749)	Prec@1 74.219 (77.434)	
Total train loss: 0.7753
Avg Loading time: 0.6720 seconds
Avg Batch time: 0.6799 seconds

 * Prec@1 65.560 Prec@5 90.100 Loss 1.2695
Avg Loading time: 0.6570 seconds
Avg Batch time: 0.6639 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [14][38/196]	LR: 0.05	DT: 0.000 (0.704)	BT: 0.005 (0.711)	Loss 0.8213 (0.7440)	Prec@1 75.781 (78.045)	
Epoch: [14][77/196]	LR: 0.05	DT: 0.000 (0.736)	BT: 0.005 (0.743)	Loss 0.7964 (0.7483)	Prec@1 76.172 (78.200)	
Epoch: [14][116/196]	LR: 0.05	DT: 0.000 (0.769)	BT: 0.005 (0.776)	Loss 0.7681 (0.7534)	Prec@1 78.516 (78.015)	
Epoch: [14][155/196]	LR: 0.05	DT: 0.000 (0.801)	BT: 0.006 (0.808)	Loss 0.8975 (0.7653)	Prec@1 71.484 (77.479)	
Epoch: [14][194/196]	LR: 0.05	DT: 0.000 (0.815)	BT: 0.006 (0.822)	Loss 0.8145 (0.7721)	Prec@1 80.078 (77.378)	
Total train loss: 0.7726
Avg Loading time: 0.8104 seconds
Avg Batch time: 0.8173 seconds

 * Prec@1 65.460 Prec@5 90.000 Loss 1.2803
Avg Loading time: 0.8613 seconds
Avg Batch time: 0.8668 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [15][38/196]	LR: 0.05	DT: 0.000 (1.026)	BT: 0.006 (1.034)	Loss 0.7476 (0.7308)	Prec@1 78.125 (78.335)	
Epoch: [15][77/196]	LR: 0.05	DT: 0.039 (0.902)	BT: 0.047 (0.911)	Loss 0.7275 (0.7446)	Prec@1 80.078 (78.215)	
Epoch: [15][116/196]	LR: 0.05	DT: 0.000 (0.883)	BT: 0.006 (0.892)	Loss 0.7627 (0.7495)	Prec@1 79.297 (78.072)	
Epoch: [15][155/196]	LR: 0.05	DT: 0.000 (0.884)	BT: 0.006 (0.893)	Loss 0.7007 (0.7609)	Prec@1 78.516 (77.692)	
Epoch: [15][194/196]	LR: 0.05	DT: 0.034 (0.880)	BT: 0.047 (0.888)	Loss 0.7939 (0.7662)	Prec@1 75.781 (77.530)	
Total train loss: 0.7668
Avg Loading time: 0.8752 seconds
Avg Batch time: 0.8837 seconds

 * Prec@1 65.370 Prec@5 89.920 Loss 1.2773
Avg Loading time: 0.7277 seconds
Avg Batch time: 0.7335 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [16][38/196]	LR: 0.05	DT: 0.000 (0.641)	BT: 0.006 (0.650)	Loss 0.7041 (0.7271)	Prec@1 78.125 (78.776)	
Epoch: [16][77/196]	LR: 0.05	DT: 0.000 (0.707)	BT: 0.006 (0.716)	Loss 0.8120 (0.7394)	Prec@1 75.391 (78.220)	
Epoch: [16][116/196]	LR: 0.05	DT: 0.000 (0.737)	BT: 0.008 (0.745)	Loss 0.6685 (0.7493)	Prec@1 80.859 (78.062)	
Epoch: [16][155/196]	LR: 0.05	DT: 4.096 (0.768)	BT: 4.108 (0.776)	Loss 0.8823 (0.7609)	Prec@1 72.266 (77.724)	
Epoch: [16][194/196]	LR: 0.05	DT: 1.993 (0.773)	BT: 2.005 (0.781)	Loss 0.7808 (0.7666)	Prec@1 74.609 (77.546)	
Total train loss: 0.7670
Avg Loading time: 0.7689 seconds
Avg Batch time: 0.7774 seconds

 * Prec@1 65.200 Prec@5 89.820 Loss 1.2910
Avg Loading time: 0.9495 seconds
Avg Batch time: 0.9559 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [17][38/196]	LR: 0.05	DT: 0.000 (0.983)	BT: 0.006 (0.992)	Loss 0.6729 (0.7042)	Prec@1 80.859 (79.487)	
Epoch: [17][77/196]	LR: 0.05	DT: 0.000 (0.942)	BT: 0.005 (0.951)	Loss 0.7637 (0.7208)	Prec@1 78.125 (78.946)	
Epoch: [17][116/196]	LR: 0.05	DT: 0.000 (0.911)	BT: 0.007 (0.920)	Loss 0.8604 (0.7416)	Prec@1 73.828 (78.205)	
Epoch: [17][155/196]	LR: 0.05	DT: 0.000 (0.902)	BT: 0.007 (0.911)	Loss 0.7803 (0.7521)	Prec@1 78.906 (77.887)	
Epoch: [17][194/196]	LR: 0.05	DT: 0.000 (0.877)	BT: 0.008 (0.886)	Loss 0.7930 (0.7651)	Prec@1 76.953 (77.522)	
Total train loss: 0.7653
Avg Loading time: 0.8727 seconds
Avg Batch time: 0.8814 seconds

 * Prec@1 65.090 Prec@5 89.860 Loss 1.2930
Avg Loading time: 0.9647 seconds
Avg Batch time: 0.9711 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [18][38/196]	LR: 0.05	DT: 0.000 (0.868)	BT: 0.007 (0.876)	Loss 0.7646 (0.7088)	Prec@1 75.391 (79.227)	
Epoch: [18][77/196]	LR: 0.05	DT: 0.000 (0.813)	BT: 0.006 (0.821)	Loss 0.7666 (0.7339)	Prec@1 76.172 (78.365)	
Epoch: [18][116/196]	LR: 0.05	DT: 0.000 (0.834)	BT: 0.005 (0.841)	Loss 0.7876 (0.7459)	Prec@1 77.734 (77.988)	
Epoch: [18][155/196]	LR: 0.05	DT: 0.007 (0.842)	BT: 0.014 (0.849)	Loss 0.8926 (0.7526)	Prec@1 74.219 (77.812)	
Epoch: [18][194/196]	LR: 0.05	DT: 0.000 (0.814)	BT: 0.005 (0.821)	Loss 0.8535 (0.7618)	Prec@1 76.562 (77.496)	
Total train loss: 0.7620
Avg Loading time: 0.8095 seconds
Avg Batch time: 0.8168 seconds

 * Prec@1 65.170 Prec@5 89.940 Loss 1.2959
Avg Loading time: 0.7926 seconds
Avg Batch time: 0.7990 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [19][38/196]	LR: 0.05	DT: 0.000 (0.984)	BT: 0.005 (0.992)	Loss 0.7725 (0.7180)	Prec@1 76.172 (78.956)	
Epoch: [19][77/196]	LR: 0.05	DT: 0.000 (0.961)	BT: 0.006 (0.969)	Loss 0.8691 (0.7313)	Prec@1 76.172 (78.676)	
Epoch: [19][116/196]	LR: 0.05	DT: 0.000 (0.949)	BT: 0.006 (0.956)	Loss 0.7622 (0.7417)	Prec@1 73.438 (78.132)	
Epoch: [19][155/196]	LR: 0.05	DT: 0.000 (0.954)	BT: 0.008 (0.962)	Loss 0.6865 (0.7525)	Prec@1 80.469 (77.722)	
Epoch: [19][194/196]	LR: 0.05	DT: 1.218 (0.932)	BT: 1.228 (0.939)	Loss 0.7207 (0.7606)	Prec@1 77.344 (77.422)	
Total train loss: 0.7605
Avg Loading time: 0.9272 seconds
Avg Batch time: 0.9347 seconds

 * Prec@1 65.250 Prec@5 89.700 Loss 1.3047
Avg Loading time: 0.8078 seconds
Avg Batch time: 0.8142 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [20][38/196]	LR: 0.025	DT: 0.000 (1.029)	BT: 0.004 (1.036)	Loss 0.6411 (0.6906)	Prec@1 82.031 (80.389)	
Epoch: [20][77/196]	LR: 0.025	DT: 0.000 (0.989)	BT: 0.005 (0.996)	Loss 0.8677 (0.7064)	Prec@1 75.781 (79.843)	
Epoch: [20][116/196]	LR: 0.025	DT: 0.000 (0.953)	BT: 0.007 (0.960)	Loss 0.6475 (0.7084)	Prec@1 81.250 (79.674)	
Epoch: [20][155/196]	LR: 0.025	DT: 0.000 (0.941)	BT: 0.006 (0.948)	Loss 0.7354 (0.7158)	Prec@1 82.031 (79.430)	
Epoch: [20][194/196]	LR: 0.025	DT: 0.000 (0.926)	BT: 0.009 (0.933)	Loss 0.8970 (0.7181)	Prec@1 73.828 (79.183)	
Total train loss: 0.7183
Avg Loading time: 0.9208 seconds
Avg Batch time: 0.9283 seconds

 * Prec@1 65.530 Prec@5 89.770 Loss 1.2959
Avg Loading time: 0.8088 seconds
Avg Batch time: 0.8145 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [21][38/196]	LR: 0.025	DT: 0.000 (0.848)	BT: 0.007 (0.855)	Loss 0.5791 (0.6806)	Prec@1 83.984 (80.248)	
Epoch: [21][77/196]	LR: 0.025	DT: 0.160 (0.873)	BT: 0.166 (0.881)	Loss 0.6279 (0.6833)	Prec@1 82.422 (80.193)	
Epoch: [21][116/196]	LR: 0.025	DT: 0.000 (0.931)	BT: 0.006 (0.940)	Loss 0.7236 (0.6990)	Prec@1 79.297 (79.571)	
Epoch: [21][155/196]	LR: 0.025	DT: 0.513 (0.953)	BT: 0.525 (0.961)	Loss 0.8384 (0.7095)	Prec@1 75.781 (79.247)	
Epoch: [21][194/196]	LR: 0.025	DT: 0.000 (0.970)	BT: 0.005 (0.979)	Loss 0.7900 (0.7131)	Prec@1 76.953 (79.183)	
Total train loss: 0.7137
Avg Loading time: 0.9648 seconds
Avg Batch time: 0.9737 seconds

 * Prec@1 65.460 Prec@5 89.670 Loss 1.2998
Avg Loading time: 1.2015 seconds
Avg Batch time: 1.2071 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [22][38/196]	LR: 0.025	DT: 0.019 (1.619)	BT: 0.025 (1.628)	Loss 0.7729 (0.6853)	Prec@1 76.562 (80.158)	
Epoch: [22][77/196]	LR: 0.025	DT: 0.000 (1.213)	BT: 0.005 (1.221)	Loss 0.7231 (0.6947)	Prec@1 80.078 (79.748)	
Epoch: [22][116/196]	LR: 0.025	DT: 0.000 (1.130)	BT: 0.006 (1.139)	Loss 0.8296 (0.7067)	Prec@1 77.734 (79.274)	
Epoch: [22][155/196]	LR: 0.025	DT: 0.000 (1.024)	BT: 0.008 (1.032)	Loss 0.7241 (0.7102)	Prec@1 77.734 (79.264)	
Epoch: [22][194/196]	LR: 0.025	DT: 0.000 (0.903)	BT: 0.006 (0.911)	Loss 0.7827 (0.7112)	Prec@1 75.000 (79.167)	
Total train loss: 0.7115
Avg Loading time: 0.8983 seconds
Avg Batch time: 0.9066 seconds

 * Prec@1 65.030 Prec@5 89.560 Loss 1.3096
Avg Loading time: 0.3627 seconds
Avg Batch time: 0.3685 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [23][38/196]	LR: 0.025	DT: 0.356 (0.398)	BT: 0.364 (0.406)	Loss 0.7217 (0.6915)	Prec@1 79.297 (79.698)	
Epoch: [23][77/196]	LR: 0.025	DT: 0.000 (0.374)	BT: 0.006 (0.382)	Loss 0.7407 (0.6964)	Prec@1 80.078 (79.412)	
Epoch: [23][116/196]	LR: 0.025	DT: 0.000 (0.329)	BT: 0.006 (0.337)	Loss 0.7681 (0.7036)	Prec@1 79.688 (79.367)	
Epoch: [23][155/196]	LR: 0.025	DT: 0.000 (0.385)	BT: 0.006 (0.393)	Loss 0.8784 (0.7070)	Prec@1 74.219 (79.279)	
Epoch: [23][194/196]	LR: 0.025	DT: 0.000 (0.410)	BT: 0.006 (0.418)	Loss 0.8052 (0.7103)	Prec@1 75.781 (79.163)	
Total train loss: 0.7104
Avg Loading time: 0.4081 seconds
Avg Batch time: 0.4156 seconds

 * Prec@1 65.110 Prec@5 89.590 Loss 1.3066
Avg Loading time: 0.4519 seconds
Avg Batch time: 0.4583 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [24][38/196]	LR: 0.025	DT: 0.000 (0.417)	BT: 0.006 (0.425)	Loss 0.6294 (0.6769)	Prec@1 79.297 (80.138)	
Epoch: [24][77/196]	LR: 0.025	DT: 0.000 (0.537)	BT: 0.007 (0.544)	Loss 0.7109 (0.6833)	Prec@1 81.250 (80.028)	
Epoch: [24][116/196]	LR: 0.025	DT: 0.000 (0.509)	BT: 0.006 (0.517)	Loss 0.7964 (0.6912)	Prec@1 79.297 (79.664)	
Epoch: [24][155/196]	LR: 0.025	DT: 0.159 (0.494)	BT: 0.168 (0.502)	Loss 0.7500 (0.7020)	Prec@1 77.344 (79.339)	
Epoch: [24][194/196]	LR: 0.025	DT: 0.000 (0.480)	BT: 0.006 (0.488)	Loss 0.7632 (0.7102)	Prec@1 75.391 (79.161)	
Total train loss: 0.7101
Avg Loading time: 0.4772 seconds
Avg Batch time: 0.4852 seconds

 * Prec@1 65.280 Prec@5 89.460 Loss 1.3096
Avg Loading time: 0.4179 seconds
Avg Batch time: 0.4233 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [25][38/196]	LR: 0.025	DT: 0.000 (0.406)	BT: 0.006 (0.415)	Loss 0.8174 (0.6782)	Prec@1 79.688 (80.248)	
Epoch: [25][77/196]	LR: 0.025	DT: 0.000 (0.404)	BT: 0.005 (0.413)	Loss 0.6489 (0.6789)	Prec@1 83.594 (80.213)	
Epoch: [25][116/196]	LR: 0.025	DT: 0.000 (0.405)	BT: 0.005 (0.413)	Loss 0.7485 (0.6904)	Prec@1 80.859 (79.901)	
Epoch: [25][155/196]	LR: 0.025	DT: 0.000 (0.400)	BT: 0.007 (0.408)	Loss 0.6055 (0.6952)	Prec@1 82.812 (79.655)	
Epoch: [25][194/196]	LR: 0.025	DT: 0.000 (0.404)	BT: 0.009 (0.412)	Loss 0.7090 (0.7060)	Prec@1 79.688 (79.143)	
Total train loss: 0.7061
Avg Loading time: 0.4015 seconds
Avg Batch time: 0.4096 seconds

 * Prec@1 65.020 Prec@5 89.680 Loss 1.3135
Avg Loading time: 0.4976 seconds
Avg Batch time: 0.5047 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [26][38/196]	LR: 0.025	DT: 0.000 (0.486)	BT: 0.005 (0.493)	Loss 0.6055 (0.6744)	Prec@1 82.031 (80.809)	
Epoch: [26][77/196]	LR: 0.025	DT: 0.001 (0.486)	BT: 0.010 (0.494)	Loss 0.6841 (0.6789)	Prec@1 78.516 (80.293)	
Epoch: [26][116/196]	LR: 0.025	DT: 0.362 (0.480)	BT: 0.373 (0.488)	Loss 0.7427 (0.6883)	Prec@1 77.734 (79.981)	
Epoch: [26][155/196]	LR: 0.025	DT: 0.018 (0.477)	BT: 0.025 (0.486)	Loss 0.7617 (0.6984)	Prec@1 78.516 (79.502)	
Epoch: [26][194/196]	LR: 0.025	DT: 0.000 (0.447)	BT: 0.005 (0.456)	Loss 0.7573 (0.7061)	Prec@1 78.516 (79.255)	
Total train loss: 0.7064
Avg Loading time: 0.4447 seconds
Avg Batch time: 0.4537 seconds

 * Prec@1 64.990 Prec@5 89.590 Loss 1.3174
Avg Loading time: 0.3215 seconds
Avg Batch time: 0.3286 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [27][38/196]	LR: 0.025	DT: 0.000 (0.268)	BT: 0.006 (0.277)	Loss 0.6255 (0.6801)	Prec@1 81.641 (79.948)	
Epoch: [27][77/196]	LR: 0.025	DT: 0.000 (0.263)	BT: 0.009 (0.271)	Loss 0.6963 (0.6893)	Prec@1 78.906 (79.898)	
Epoch: [27][116/196]	LR: 0.025	DT: 0.404 (0.260)	BT: 0.415 (0.269)	Loss 0.9170 (0.6975)	Prec@1 74.219 (79.581)	
Epoch: [27][155/196]	LR: 0.025	DT: 0.000 (0.257)	BT: 0.006 (0.265)	Loss 0.7236 (0.7014)	Prec@1 78.906 (79.417)	
Epoch: [27][194/196]	LR: 0.025	DT: 0.000 (0.294)	BT: 0.007 (0.303)	Loss 0.7515 (0.7127)	Prec@1 77.734 (79.093)	
Total train loss: 0.7126
Avg Loading time: 0.2926 seconds
Avg Batch time: 0.3014 seconds

 * Prec@1 65.250 Prec@5 89.520 Loss 1.3164
Avg Loading time: 0.4557 seconds
Avg Batch time: 0.4613 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [28][38/196]	LR: 0.025	DT: 0.000 (0.403)	BT: 0.006 (0.411)	Loss 0.6641 (0.6772)	Prec@1 80.078 (80.238)	
Epoch: [28][77/196]	LR: 0.025	DT: 0.000 (0.388)	BT: 0.007 (0.397)	Loss 0.7666 (0.6843)	Prec@1 76.562 (79.868)	
Epoch: [28][116/196]	LR: 0.025	DT: 0.000 (0.388)	BT: 0.004 (0.396)	Loss 0.6416 (0.6885)	Prec@1 82.031 (79.627)	
Epoch: [28][155/196]	LR: 0.025	DT: 0.000 (0.405)	BT: 0.005 (0.413)	Loss 0.6040 (0.6975)	Prec@1 84.375 (79.327)	
Epoch: [28][194/196]	LR: 0.025	DT: 0.000 (0.408)	BT: 0.006 (0.416)	Loss 0.7529 (0.7052)	Prec@1 78.906 (79.133)	
Total train loss: 0.7053
Avg Loading time: 0.4060 seconds
Avg Batch time: 0.4139 seconds

 * Prec@1 65.210 Prec@5 89.520 Loss 1.3213
Avg Loading time: 0.4840 seconds
Avg Batch time: 0.4895 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [29][38/196]	LR: 0.025	DT: 0.000 (0.473)	BT: 0.005 (0.480)	Loss 0.6250 (0.6871)	Prec@1 81.641 (80.168)	
Epoch: [29][77/196]	LR: 0.025	DT: 0.000 (0.452)	BT: 0.005 (0.459)	Loss 0.6113 (0.6884)	Prec@1 80.469 (80.008)	
Epoch: [29][116/196]	LR: 0.025	DT: 0.000 (0.443)	BT: 0.009 (0.450)	Loss 0.7212 (0.6939)	Prec@1 79.688 (79.721)	
Epoch: [29][155/196]	LR: 0.025	DT: 0.000 (0.455)	BT: 0.013 (0.462)	Loss 0.6011 (0.7043)	Prec@1 81.250 (79.344)	
Epoch: [29][194/196]	LR: 0.025	DT: 0.000 (0.469)	BT: 0.009 (0.477)	Loss 0.6631 (0.7096)	Prec@1 83.203 (79.153)	
Total train loss: 0.7097
Avg Loading time: 0.4670 seconds
Avg Batch time: 0.4743 seconds

 * Prec@1 64.890 Prec@5 89.480 Loss 1.3193
Avg Loading time: 0.5714 seconds
Avg Batch time: 0.5770 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [30][38/196]	LR: 0.0125	DT: 0.000 (0.665)	BT: 0.005 (0.672)	Loss 0.6831 (0.6676)	Prec@1 79.688 (80.268)	
Epoch: [30][77/196]	LR: 0.0125	DT: 0.000 (0.600)	BT: 0.005 (0.607)	Loss 0.6904 (0.6688)	Prec@1 78.125 (80.334)	
Epoch: [30][116/196]	LR: 0.0125	DT: 0.019 (0.570)	BT: 0.024 (0.576)	Loss 0.6812 (0.6709)	Prec@1 80.469 (80.509)	
Epoch: [30][155/196]	LR: 0.0125	DT: 0.000 (0.547)	BT: 0.007 (0.554)	Loss 0.8613 (0.6796)	Prec@1 73.438 (80.183)	
Epoch: [30][194/196]	LR: 0.0125	DT: 0.000 (0.543)	BT: 0.007 (0.550)	Loss 0.8608 (0.6853)	Prec@1 77.344 (80.010)	
Total train loss: 0.6854
Avg Loading time: 0.5400 seconds
Avg Batch time: 0.5471 seconds

 * Prec@1 64.910 Prec@5 89.490 Loss 1.3213
Avg Loading time: 0.5395 seconds
Avg Batch time: 0.5455 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [31][38/196]	LR: 0.0125	DT: 0.000 (0.572)	BT: 0.006 (0.580)	Loss 0.7368 (0.6596)	Prec@1 79.688 (80.769)	
Epoch: [31][77/196]	LR: 0.0125	DT: 0.000 (0.573)	BT: 0.007 (0.581)	Loss 0.6328 (0.6682)	Prec@1 78.516 (80.283)	
Epoch: [31][116/196]	LR: 0.0125	DT: 0.000 (0.582)	BT: 0.006 (0.590)	Loss 0.6938 (0.6705)	Prec@1 80.859 (80.262)	
Epoch: [31][155/196]	LR: 0.0125	DT: 0.000 (0.594)	BT: 0.005 (0.602)	Loss 0.6938 (0.6757)	Prec@1 79.297 (80.226)	
Epoch: [31][194/196]	LR: 0.0125	DT: 0.488 (0.604)	BT: 0.501 (0.611)	Loss 0.6411 (0.6834)	Prec@1 80.078 (79.988)	
Total train loss: 0.6837
Avg Loading time: 0.6006 seconds
Avg Batch time: 0.6082 seconds

 * Prec@1 64.960 Prec@5 89.560 Loss 1.3223
Avg Loading time: 0.6890 seconds
Avg Batch time: 0.6949 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [32][38/196]	LR: 0.0125	DT: 0.000 (0.863)	BT: 0.006 (0.872)	Loss 0.6792 (0.6629)	Prec@1 81.250 (81.200)	
Epoch: [32][77/196]	LR: 0.0125	DT: 0.000 (0.818)	BT: 0.005 (0.826)	Loss 0.8149 (0.6736)	Prec@1 73.047 (80.694)	
Epoch: [32][116/196]	LR: 0.0125	DT: 0.000 (0.820)	BT: 0.005 (0.828)	Loss 0.6240 (0.6735)	Prec@1 84.375 (80.606)	
Epoch: [32][155/196]	LR: 0.0125	DT: 1.160 (0.938)	BT: 1.171 (0.945)	Loss 0.6343 (0.6762)	Prec@1 79.297 (80.379)	
Epoch: [32][194/196]	LR: 0.0125	DT: 0.000 (1.189)	BT: 0.006 (1.197)	Loss 0.7329 (0.6796)	Prec@1 74.219 (80.268)	
Total train loss: 0.6798
Avg Loading time: 1.1830 seconds
Avg Batch time: 1.1908 seconds

 * Prec@1 64.910 Prec@5 89.540 Loss 1.3252
Avg Loading time: 1.1224 seconds
Avg Batch time: 1.1284 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [33][38/196]	LR: 0.0125	DT: 0.000 (1.226)	BT: 0.006 (1.234)	Loss 0.6406 (0.6846)	Prec@1 81.641 (80.048)	
Epoch: [33][77/196]	LR: 0.0125	DT: 0.000 (1.305)	BT: 0.004 (1.312)	Loss 0.6655 (0.6806)	Prec@1 78.906 (80.228)	
Epoch: [33][116/196]	LR: 0.0125	DT: 0.000 (1.233)	BT: 0.006 (1.240)	Loss 0.7710 (0.6769)	Prec@1 77.734 (80.315)	
Epoch: [33][155/196]	LR: 0.0125	DT: 0.000 (1.189)	BT: 0.007 (1.197)	Loss 0.7207 (0.6807)	Prec@1 77.734 (80.183)	
Epoch: [33][194/196]	LR: 0.0125	DT: 0.000 (1.118)	BT: 0.010 (1.125)	Loss 0.6274 (0.6807)	Prec@1 80.469 (80.172)	
Total train loss: 0.6811
Avg Loading time: 1.1120 seconds
Avg Batch time: 1.1197 seconds

 * Prec@1 64.670 Prec@5 89.600 Loss 1.3262
Avg Loading time: 0.8690 seconds
Avg Batch time: 0.8762 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [34][38/196]	LR: 0.0125	DT: 0.000 (0.920)	BT: 0.007 (0.928)	Loss 0.6924 (0.6666)	Prec@1 82.031 (81.090)	
Epoch: [34][77/196]	LR: 0.0125	DT: 0.000 (1.012)	BT: 0.006 (1.020)	Loss 0.7827 (0.6647)	Prec@1 80.469 (80.834)	
Epoch: [34][116/196]	LR: 0.0125	DT: 0.000 (1.024)	BT: 0.009 (1.033)	Loss 0.6533 (0.6680)	Prec@1 81.250 (80.549)	
Epoch: [34][155/196]	LR: 0.0125	DT: 0.488 (1.032)	BT: 0.498 (1.040)	Loss 0.7510 (0.6756)	Prec@1 76.562 (80.206)	
Epoch: [34][194/196]	LR: 0.0125	DT: 1.146 (1.035)	BT: 1.158 (1.044)	Loss 0.6455 (0.6806)	Prec@1 81.641 (80.028)	
Total train loss: 0.6805
Avg Loading time: 1.0295 seconds
Avg Batch time: 1.0382 seconds

 * Prec@1 64.810 Prec@5 89.350 Loss 1.3301
Avg Loading time: 1.0870 seconds
Avg Batch time: 1.0950 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [35][38/196]	LR: 0.0125	DT: 0.000 (1.340)	BT: 0.007 (1.349)	Loss 0.5806 (0.6530)	Prec@1 82.812 (81.010)	
Epoch: [35][77/196]	LR: 0.0125	DT: 0.397 (1.318)	BT: 0.410 (1.328)	Loss 0.7026 (0.6632)	Prec@1 78.906 (80.529)	
Epoch: [35][116/196]	LR: 0.0125	DT: 0.000 (1.224)	BT: 0.006 (1.234)	Loss 0.7095 (0.6706)	Prec@1 76.953 (80.305)	
Epoch: [35][155/196]	LR: 0.0125	DT: 0.000 (1.151)	BT: 0.006 (1.161)	Loss 0.7310 (0.6767)	Prec@1 79.688 (80.203)	
Epoch: [35][194/196]	LR: 0.0125	DT: 0.000 (1.088)	BT: 0.007 (1.097)	Loss 0.6016 (0.6809)	Prec@1 81.641 (80.064)	
Total train loss: 0.6813
Avg Loading time: 1.0825 seconds
Avg Batch time: 1.0913 seconds

 * Prec@1 64.790 Prec@5 89.510 Loss 1.3291
Avg Loading time: 0.8278 seconds
Avg Batch time: 0.8346 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [36][38/196]	LR: 0.0125	DT: 0.000 (0.858)	BT: 0.008 (0.867)	Loss 0.6431 (0.6548)	Prec@1 83.984 (80.929)	
Epoch: [36][77/196]	LR: 0.0125	DT: 0.000 (0.838)	BT: 0.005 (0.847)	Loss 0.6216 (0.6589)	Prec@1 82.812 (80.919)	
Epoch: [36][116/196]	LR: 0.0125	DT: 0.000 (0.806)	BT: 0.007 (0.815)	Loss 0.7222 (0.6620)	Prec@1 79.688 (80.716)	
Epoch: [36][155/196]	LR: 0.0125	DT: 0.000 (0.787)	BT: 0.006 (0.796)	Loss 0.7456 (0.6725)	Prec@1 78.125 (80.474)	
Epoch: [36][194/196]	LR: 0.0125	DT: 0.498 (0.754)	BT: 0.506 (0.763)	Loss 0.6118 (0.6810)	Prec@1 82.812 (80.202)	
Total train loss: 0.6814
Avg Loading time: 0.7500 seconds
Avg Batch time: 0.7590 seconds

 * Prec@1 65.060 Prec@5 89.580 Loss 1.3252
Avg Loading time: 0.7136 seconds
Avg Batch time: 0.7207 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [37][38/196]	LR: 0.0125	DT: 0.000 (0.871)	BT: 0.007 (0.879)	Loss 0.6255 (0.6600)	Prec@1 82.031 (81.220)	
Epoch: [37][77/196]	LR: 0.0125	DT: 0.000 (0.899)	BT: 0.006 (0.907)	Loss 0.7471 (0.6717)	Prec@1 80.078 (80.769)	
Epoch: [37][116/196]	LR: 0.0125	DT: 0.000 (0.908)	BT: 0.006 (0.916)	Loss 0.7334 (0.6760)	Prec@1 75.000 (80.459)	
Epoch: [37][155/196]	LR: 0.0125	DT: 0.000 (0.955)	BT: 0.006 (0.963)	Loss 0.6724 (0.6756)	Prec@1 82.031 (80.396)	
Epoch: [37][194/196]	LR: 0.0125	DT: 0.000 (0.926)	BT: 0.007 (0.935)	Loss 0.7173 (0.6783)	Prec@1 78.516 (80.240)	
Total train loss: 0.6783
Avg Loading time: 0.9215 seconds
Avg Batch time: 0.9298 seconds

 * Prec@1 65.070 Prec@5 89.430 Loss 1.3291
Avg Loading time: 0.7243 seconds
Avg Batch time: 0.7310 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [38][38/196]	LR: 0.0125	DT: 0.050 (0.797)	BT: 0.056 (0.806)	Loss 0.6919 (0.6727)	Prec@1 79.688 (80.769)	
Epoch: [38][77/196]	LR: 0.0125	DT: 0.000 (0.809)	BT: 0.010 (0.818)	Loss 0.7290 (0.6702)	Prec@1 78.906 (80.764)	
Epoch: [38][116/196]	LR: 0.0125	DT: 1.482 (0.819)	BT: 1.493 (0.828)	Loss 0.7793 (0.6752)	Prec@1 76.562 (80.322)	
Epoch: [38][155/196]	LR: 0.0125	DT: 0.000 (0.847)	BT: 0.009 (0.856)	Loss 0.7002 (0.6773)	Prec@1 82.422 (80.308)	
Epoch: [38][194/196]	LR: 0.0125	DT: 0.008 (0.820)	BT: 0.014 (0.829)	Loss 0.6348 (0.6802)	Prec@1 81.641 (80.248)	
Total train loss: 0.6807
Avg Loading time: 0.8156 seconds
Avg Batch time: 0.8248 seconds

 * Prec@1 64.810 Prec@5 89.360 Loss 1.3301
Avg Loading time: 0.7156 seconds
Avg Batch time: 0.7216 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
Epoch: [39][38/196]	LR: 0.0125	DT: 0.000 (0.833)	BT: 0.006 (0.842)	Loss 0.5933 (0.6712)	Prec@1 84.375 (80.589)	
Epoch: [39][77/196]	LR: 0.0125	DT: 0.000 (0.789)	BT: 0.006 (0.797)	Loss 0.7100 (0.6673)	Prec@1 79.688 (80.649)	
Epoch: [39][116/196]	LR: 0.0125	DT: 0.000 (0.805)	BT: 0.007 (0.813)	Loss 0.7456 (0.6678)	Prec@1 77.734 (80.629)	
Epoch: [39][155/196]	LR: 0.0125	DT: 0.000 (0.833)	BT: 0.008 (0.841)	Loss 0.6406 (0.6762)	Prec@1 81.250 (80.291)	
Epoch: [39][194/196]	LR: 0.0125	DT: 0.000 (0.834)	BT: 0.007 (0.843)	Loss 0.7461 (0.6816)	Prec@1 78.516 (80.110)	
Total train loss: 0.6815
Avg Loading time: 0.8301 seconds
Avg Batch time: 0.8383 seconds

 * Prec@1 64.750 Prec@5 89.330 Loss 1.3340
Avg Loading time: 0.9352 seconds
Avg Batch time: 0.9419 seconds

Best acc: 65.930
--------------------------------------------------------------------------------
