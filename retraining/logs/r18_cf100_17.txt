
      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/one_batch/
          savedir: ../pretrained_models/frozen/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          workers: 8
          epochs: 40
          start_epoch: 0
          batch_size: 256
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 3
          frozen_layers: 17
DEVICE: cuda
GPU Id(s) being used: 3
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
 * Prec@1 1.130 Prec@5 5.720 Loss 4.6211
Avg Loading time: 2.2555 seconds
Avg Batch time: 2.2910 seconds

Pre-trained Prec@1 with 17 layers frozen: 1.1299999952316284 	 Loss: 4.62109375

Starting training on SRAM layers...
Epoch: [0][38/196]	LR: 0.01	DT: 0.000 (4.841)	BT: 0.005 (4.849)	Loss 3.8652 (4.4078)	Prec@1 15.234 (6.410)	
Epoch: [0][77/196]	LR: 0.01	DT: 0.560 (4.500)	BT: 0.573 (4.509)	Loss 3.7012 (4.1004)	Prec@1 18.359 (10.777)	
Epoch: [0][116/196]	LR: 0.01	DT: 0.000 (4.513)	BT: 0.005 (4.522)	Loss 3.5176 (3.9262)	Prec@1 25.000 (13.795)	
Epoch: [0][155/196]	LR: 0.01	DT: 0.000 (4.536)	BT: 0.014 (4.545)	Loss 3.4082 (3.8074)	Prec@1 22.266 (15.820)	
Epoch: [0][194/196]	LR: 0.01	DT: 0.000 (4.045)	BT: 0.008 (4.054)	Loss 3.3926 (3.7211)	Prec@1 20.703 (17.426)	
Total train loss: 3.7207
Avg Loading time: 4.0246 seconds
Avg Batch time: 4.0332 seconds

 * Prec@1 25.560 Prec@5 52.590 Loss 3.3125
Avg Loading time: 3.4020 seconds
Avg Batch time: 3.4094 seconds

Best acc: 25.560
--------------------------------------------------------------------------------
Epoch: [1][38/196]	LR: 0.01	DT: 0.000 (0.849)	BT: 0.009 (0.857)	Loss 3.2812 (3.1766)	Prec@1 25.781 (28.986)	
Epoch: [1][77/196]	LR: 0.01	DT: 0.000 (0.456)	BT: 0.007 (0.464)	Loss 3.1328 (3.1518)	Prec@1 31.250 (29.392)	
Epoch: [1][116/196]	LR: 0.01	DT: 0.000 (0.365)	BT: 0.007 (0.372)	Loss 3.2227 (3.1462)	Prec@1 23.828 (28.839)	
Epoch: [1][155/196]	LR: 0.01	DT: 0.000 (0.370)	BT: 0.013 (0.378)	Loss 3.0566 (3.1323)	Prec@1 30.469 (28.931)	
Epoch: [1][194/196]	LR: 0.01	DT: 1.279 (0.418)	BT: 1.289 (0.426)	Loss 3.0762 (3.1177)	Prec@1 30.078 (29.107)	
Total train loss: 3.1175
Avg Loading time: 0.4162 seconds
Avg Batch time: 0.4237 seconds

 * Prec@1 28.940 Prec@5 56.940 Loss 3.1035
Avg Loading time: 0.5993 seconds
Avg Batch time: 0.6062 seconds

Best acc: 28.940
--------------------------------------------------------------------------------
Epoch: [2][38/196]	LR: 0.01	DT: 0.000 (0.634)	BT: 0.005 (0.642)	Loss 2.6836 (2.9145)	Prec@1 42.188 (32.953)	
Epoch: [2][77/196]	LR: 0.01	DT: 0.603 (0.656)	BT: 0.614 (0.664)	Loss 2.9824 (2.9171)	Prec@1 31.641 (32.898)	
Epoch: [2][116/196]	LR: 0.01	DT: 0.000 (0.659)	BT: 0.010 (0.667)	Loss 2.8965 (2.9136)	Prec@1 33.203 (32.903)	
Epoch: [2][155/196]	LR: 0.01	DT: 0.049 (0.689)	BT: 0.057 (0.698)	Loss 2.9219 (2.9071)	Prec@1 30.469 (33.028)	
Epoch: [2][194/196]	LR: 0.01	DT: 0.000 (0.707)	BT: 0.007 (0.716)	Loss 2.8926 (2.9073)	Prec@1 29.688 (32.855)	
Total train loss: 2.9073
Avg Loading time: 0.7036 seconds
Avg Batch time: 0.7119 seconds

 * Prec@1 30.400 Prec@5 58.300 Loss 3.0020
Avg Loading time: 0.9626 seconds
Avg Batch time: 0.9692 seconds

Best acc: 30.400
--------------------------------------------------------------------------------
Epoch: [3][38/196]	LR: 0.01	DT: 0.000 (0.997)	BT: 0.006 (1.006)	Loss 2.6973 (2.7689)	Prec@1 35.547 (35.557)	
Epoch: [3][77/196]	LR: 0.01	DT: 0.000 (1.080)	BT: 0.007 (1.089)	Loss 2.8027 (2.7708)	Prec@1 27.344 (35.427)	
Epoch: [3][116/196]	LR: 0.01	DT: 0.000 (1.188)	BT: 0.007 (1.197)	Loss 2.7148 (2.7747)	Prec@1 34.766 (35.186)	
Epoch: [3][155/196]	LR: 0.01	DT: 0.000 (1.337)	BT: 0.010 (1.345)	Loss 2.7598 (2.7768)	Prec@1 40.234 (35.069)	
Epoch: [3][194/196]	LR: 0.01	DT: 1.632 (1.587)	BT: 1.643 (1.595)	Loss 2.9375 (2.7831)	Prec@1 30.859 (34.818)	
Total train loss: 2.7832
Avg Loading time: 1.5786 seconds
Avg Batch time: 1.5870 seconds

 * Prec@1 30.980 Prec@5 58.330 Loss 2.9531
Avg Loading time: 3.6681 seconds
Avg Batch time: 3.6758 seconds

Best acc: 30.980
--------------------------------------------------------------------------------
Epoch: [4][38/196]	LR: 0.01	DT: 0.439 (2.058)	BT: 0.449 (2.068)	Loss 2.6289 (2.6456)	Prec@1 36.328 (38.001)	
Epoch: [4][77/196]	LR: 0.01	DT: 0.000 (1.252)	BT: 0.005 (1.261)	Loss 2.6797 (2.6685)	Prec@1 35.547 (37.415)	
Epoch: [4][116/196]	LR: 0.01	DT: 0.000 (0.914)	BT: 0.005 (0.922)	Loss 2.9004 (2.6776)	Prec@1 28.125 (37.186)	
Epoch: [4][155/196]	LR: 0.01	DT: 0.000 (0.723)	BT: 0.005 (0.731)	Loss 2.8086 (2.6925)	Prec@1 34.766 (36.624)	
Epoch: [4][194/196]	LR: 0.01	DT: 0.318 (0.599)	BT: 0.325 (0.607)	Loss 2.7090 (2.7003)	Prec@1 33.984 (36.348)	
Total train loss: 2.7006
Avg Loading time: 0.5960 seconds
Avg Batch time: 0.6036 seconds

 * Prec@1 31.020 Prec@5 58.920 Loss 2.9277
Avg Loading time: 0.1499 seconds
Avg Batch time: 0.1557 seconds

Best acc: 31.020
--------------------------------------------------------------------------------
Epoch: [5][38/196]	LR: 0.01	DT: 0.000 (0.122)	BT: 0.005 (0.129)	Loss 2.6094 (2.5692)	Prec@1 39.453 (39.333)	
Epoch: [5][77/196]	LR: 0.01	DT: 0.000 (0.089)	BT: 0.013 (0.101)	Loss 2.7734 (2.6042)	Prec@1 33.984 (38.186)	
Epoch: [5][116/196]	LR: 0.01	DT: 0.000 (0.091)	BT: 0.007 (0.101)	Loss 2.6699 (2.6249)	Prec@1 36.719 (37.694)	
Epoch: [5][155/196]	LR: 0.01	DT: 0.000 (0.095)	BT: 0.005 (0.105)	Loss 2.5898 (2.6303)	Prec@1 39.844 (37.568)	
Epoch: [5][194/196]	LR: 0.01	DT: 0.000 (0.108)	BT: 0.011 (0.118)	Loss 2.6582 (2.6395)	Prec@1 35.547 (37.165)	
Total train loss: 2.6395
Avg Loading time: 0.1077 seconds
Avg Batch time: 0.1172 seconds

 * Prec@1 30.990 Prec@5 59.250 Loss 2.9102
Avg Loading time: 0.1094 seconds
Avg Batch time: 0.1155 seconds

Best acc: 31.020
--------------------------------------------------------------------------------
Epoch: [6][38/196]	LR: 0.01	DT: 0.000 (0.088)	BT: 0.006 (0.096)	Loss 2.6270 (2.5445)	Prec@1 39.062 (39.683)	
Epoch: [6][77/196]	LR: 0.01	DT: 0.000 (0.064)	BT: 0.007 (0.072)	Loss 2.7402 (2.5607)	Prec@1 33.203 (39.098)	
Epoch: [6][116/196]	LR: 0.01	DT: 0.000 (0.056)	BT: 0.005 (0.064)	Loss 2.5781 (2.5819)	Prec@1 35.547 (38.335)	
Epoch: [6][155/196]	LR: 0.01	DT: 0.124 (0.053)	BT: 0.136 (0.061)	Loss 2.6309 (2.5867)	Prec@1 38.281 (38.068)	
Epoch: [6][194/196]	LR: 0.01	DT: 0.000 (0.079)	BT: 0.009 (0.087)	Loss 2.5527 (2.5950)	Prec@1 36.328 (37.760)	
Total train loss: 2.5947
Avg Loading time: 0.0787 seconds
Avg Batch time: 0.0866 seconds

 * Prec@1 31.070 Prec@5 59.300 Loss 2.9004
Avg Loading time: 0.2702 seconds
Avg Batch time: 0.2755 seconds

Best acc: 31.070
--------------------------------------------------------------------------------
Epoch: [7][38/196]	LR: 0.01	DT: 0.000 (0.460)	BT: 0.009 (0.468)	Loss 2.6406 (2.5047)	Prec@1 37.109 (39.924)	
Epoch: [7][77/196]	LR: 0.01	DT: 0.000 (0.474)	BT: 0.007 (0.483)	Loss 2.5000 (2.5096)	Prec@1 40.625 (39.598)	
Epoch: [7][116/196]	LR: 0.01	DT: 1.653 (0.478)	BT: 1.663 (0.486)	Loss 2.5801 (2.5373)	Prec@1 35.938 (38.899)	
Epoch: [7][155/196]	LR: 0.01	DT: 0.000 (0.482)	BT: 0.006 (0.490)	Loss 2.6133 (2.5572)	Prec@1 39.844 (38.241)	
Epoch: [7][194/196]	LR: 0.01	DT: 0.000 (0.493)	BT: 0.006 (0.501)	Loss 2.6738 (2.5611)	Prec@1 31.641 (38.055)	
Total train loss: 2.5611
Avg Loading time: 0.4901 seconds
Avg Batch time: 0.4984 seconds

 * Prec@1 31.060 Prec@5 59.210 Loss 2.8926
Avg Loading time: 0.6979 seconds
Avg Batch time: 0.7075 seconds

Best acc: 31.070
--------------------------------------------------------------------------------
Epoch: [8][38/196]	LR: 0.01	DT: 0.688 (0.616)	BT: 0.699 (0.624)	Loss 2.4297 (2.4938)	Prec@1 40.234 (39.934)	
Epoch: [8][77/196]	LR: 0.01	DT: 0.000 (0.649)	BT: 0.007 (0.658)	Loss 2.4492 (2.5072)	Prec@1 44.922 (39.368)	
Epoch: [8][116/196]	LR: 0.01	DT: 0.000 (0.678)	BT: 0.008 (0.686)	Loss 2.6387 (2.5167)	Prec@1 34.766 (38.979)	
Epoch: [8][155/196]	LR: 0.01	DT: 4.105 (0.710)	BT: 4.118 (0.719)	Loss 2.5742 (2.5211)	Prec@1 36.719 (38.795)	
Epoch: [8][194/196]	LR: 0.01	DT: 0.000 (0.694)	BT: 0.008 (0.703)	Loss 2.6680 (2.5329)	Prec@1 35.938 (38.427)	
Total train loss: 2.5331
Avg Loading time: 0.6930 seconds
Avg Batch time: 0.7020 seconds

 * Prec@1 31.200 Prec@5 59.200 Loss 2.9004
Avg Loading time: 0.8088 seconds
Avg Batch time: 0.8171 seconds

Best acc: 31.200
--------------------------------------------------------------------------------
Epoch: [9][38/196]	LR: 0.01	DT: 0.000 (0.977)	BT: 0.006 (0.985)	Loss 2.4102 (2.4283)	Prec@1 43.359 (40.645)	
Epoch: [9][77/196]	LR: 0.01	DT: 0.000 (1.098)	BT: 0.006 (1.106)	Loss 2.4160 (2.4533)	Prec@1 41.797 (40.360)	
Epoch: [9][116/196]	LR: 0.01	DT: 0.000 (1.209)	BT: 0.007 (1.218)	Loss 2.3613 (2.4787)	Prec@1 42.188 (39.707)	
Epoch: [9][155/196]	LR: 0.01	DT: 0.000 (1.311)	BT: 0.008 (1.320)	Loss 2.5410 (2.4962)	Prec@1 35.547 (39.233)	
Epoch: [9][194/196]	LR: 0.01	DT: 2.662 (1.737)	BT: 2.673 (1.746)	Loss 2.6309 (2.5091)	Prec@1 35.547 (38.940)	
Total train loss: 2.5093
Avg Loading time: 1.7280 seconds
Avg Batch time: 1.7368 seconds

 * Prec@1 30.870 Prec@5 59.110 Loss 2.8926
Avg Loading time: 2.3130 seconds
Avg Batch time: 2.3198 seconds

Best acc: 31.200
--------------------------------------------------------------------------------
Epoch: [10][38/196]	LR: 0.002	DT: 0.126 (0.206)	BT: 0.137 (0.214)	Loss 2.5371 (2.4146)	Prec@1 40.234 (41.757)	
Epoch: [10][77/196]	LR: 0.002	DT: 0.000 (0.169)	BT: 0.005 (0.177)	Loss 2.5918 (2.4137)	Prec@1 35.547 (41.496)	
Epoch: [10][116/196]	LR: 0.002	DT: 0.000 (0.170)	BT: 0.006 (0.177)	Loss 2.3398 (2.3987)	Prec@1 39.844 (41.817)	
Epoch: [10][155/196]	LR: 0.002	DT: 0.000 (0.166)	BT: 0.006 (0.174)	Loss 2.3711 (2.4031)	Prec@1 39.062 (41.837)	
Epoch: [10][194/196]	LR: 0.002	DT: 0.000 (0.163)	BT: 0.007 (0.171)	Loss 2.5762 (2.4092)	Prec@1 36.328 (41.538)	
Total train loss: 2.4102
Avg Loading time: 0.1626 seconds
Avg Batch time: 0.1701 seconds

 * Prec@1 31.490 Prec@5 59.640 Loss 2.8770
Avg Loading time: 0.1112 seconds
Avg Batch time: 0.1176 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [11][38/196]	LR: 0.002	DT: 0.000 (0.059)	BT: 0.005 (0.066)	Loss 2.2949 (2.3667)	Prec@1 42.578 (42.678)	
Epoch: [11][77/196]	LR: 0.002	DT: 0.022 (0.047)	BT: 0.027 (0.054)	Loss 2.3770 (2.3935)	Prec@1 44.531 (42.137)	
Epoch: [11][116/196]	LR: 0.002	DT: 0.000 (0.285)	BT: 0.006 (0.292)	Loss 2.3340 (2.3972)	Prec@1 47.266 (42.004)	
Epoch: [11][155/196]	LR: 0.002	DT: 1.186 (0.425)	BT: 1.196 (0.433)	Loss 2.4824 (2.4038)	Prec@1 41.016 (41.787)	
Epoch: [11][194/196]	LR: 0.002	DT: 0.000 (0.589)	BT: 0.007 (0.597)	Loss 2.3242 (2.4015)	Prec@1 45.703 (41.767)	
Total train loss: 2.4015
Avg Loading time: 0.5862 seconds
Avg Batch time: 0.5944 seconds

 * Prec@1 31.240 Prec@5 59.500 Loss 2.8809
Avg Loading time: 1.1527 seconds
Avg Batch time: 1.1587 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [12][38/196]	LR: 0.002	DT: 0.000 (0.166)	BT: 0.007 (0.175)	Loss 2.4512 (2.3735)	Prec@1 38.672 (42.668)	
Epoch: [12][77/196]	LR: 0.002	DT: 0.000 (0.112)	BT: 0.006 (0.119)	Loss 2.3438 (2.3888)	Prec@1 43.750 (41.962)	
Epoch: [12][116/196]	LR: 0.002	DT: 0.000 (0.232)	BT: 0.006 (0.240)	Loss 2.4414 (2.3935)	Prec@1 39.453 (41.970)	
Epoch: [12][155/196]	LR: 0.002	DT: 0.000 (0.293)	BT: 0.007 (0.301)	Loss 2.5117 (2.3973)	Prec@1 38.672 (41.852)	
Epoch: [12][194/196]	LR: 0.002	DT: 0.000 (0.323)	BT: 0.009 (0.331)	Loss 2.4238 (2.3968)	Prec@1 39.453 (41.789)	
Total train loss: 2.3969
Avg Loading time: 0.3216 seconds
Avg Batch time: 0.3298 seconds

 * Prec@1 31.210 Prec@5 59.410 Loss 2.8828
Avg Loading time: 0.5950 seconds
Avg Batch time: 0.6002 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [13][38/196]	LR: 0.002	DT: 0.037 (0.546)	BT: 0.043 (0.555)	Loss 2.3711 (2.3679)	Prec@1 40.625 (42.027)	
Epoch: [13][77/196]	LR: 0.002	DT: 0.000 (0.576)	BT: 0.006 (0.585)	Loss 2.3574 (2.3761)	Prec@1 44.531 (41.892)	
Epoch: [13][116/196]	LR: 0.002	DT: 0.000 (0.586)	BT: 0.009 (0.595)	Loss 2.4824 (2.3840)	Prec@1 40.234 (41.947)	
Epoch: [13][155/196]	LR: 0.002	DT: 0.599 (0.611)	BT: 0.611 (0.621)	Loss 2.3906 (2.3891)	Prec@1 42.578 (41.982)	
Epoch: [13][194/196]	LR: 0.002	DT: 1.165 (0.612)	BT: 1.177 (0.622)	Loss 2.4355 (2.3947)	Prec@1 38.281 (41.873)	
Total train loss: 2.3947
Avg Loading time: 0.6091 seconds
Avg Batch time: 0.6187 seconds

 * Prec@1 31.410 Prec@5 59.340 Loss 2.8828
Avg Loading time: 0.7908 seconds
Avg Batch time: 0.7971 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [14][38/196]	LR: 0.002	DT: 0.000 (0.819)	BT: 0.005 (0.826)	Loss 2.3691 (2.3530)	Prec@1 42.188 (42.909)	
Epoch: [14][77/196]	LR: 0.002	DT: 0.000 (0.867)	BT: 0.004 (0.875)	Loss 2.5625 (2.3760)	Prec@1 39.453 (42.318)	
Epoch: [14][116/196]	LR: 0.002	DT: 0.000 (0.909)	BT: 0.007 (0.917)	Loss 2.3008 (2.3764)	Prec@1 46.484 (42.354)	
Epoch: [14][155/196]	LR: 0.002	DT: 0.000 (0.987)	BT: 0.008 (0.995)	Loss 2.5137 (2.3864)	Prec@1 41.016 (42.132)	
Epoch: [14][194/196]	LR: 0.002	DT: 2.741 (1.075)	BT: 2.752 (1.082)	Loss 2.4082 (2.3931)	Prec@1 41.797 (41.851)	
Total train loss: 2.3932
Avg Loading time: 1.0693 seconds
Avg Batch time: 1.0767 seconds

 * Prec@1 31.420 Prec@5 59.330 Loss 2.8867
Avg Loading time: 1.7831 seconds
Avg Batch time: 1.7897 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [15][38/196]	LR: 0.002	DT: 0.000 (1.726)	BT: 0.007 (1.735)	Loss 2.2617 (2.3689)	Prec@1 42.578 (42.798)	
Epoch: [15][77/196]	LR: 0.002	DT: 0.000 (1.823)	BT: 0.009 (1.832)	Loss 2.3965 (2.3705)	Prec@1 42.969 (42.753)	
Epoch: [15][116/196]	LR: 0.002	DT: 0.212 (1.968)	BT: 0.218 (1.976)	Loss 2.4375 (2.3770)	Prec@1 41.016 (42.508)	
Epoch: [15][155/196]	LR: 0.002	DT: 0.000 (1.965)	BT: 0.006 (1.974)	Loss 2.3340 (2.3853)	Prec@1 42.578 (42.273)	
Epoch: [15][194/196]	LR: 0.002	DT: 0.292 (1.614)	BT: 0.304 (1.623)	Loss 2.4434 (2.3893)	Prec@1 42.578 (42.083)	
Total train loss: 2.3901
Avg Loading time: 1.6062 seconds
Avg Batch time: 1.6145 seconds

 * Prec@1 31.160 Prec@5 59.300 Loss 2.8887
Avg Loading time: 0.2341 seconds
Avg Batch time: 0.2390 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [16][38/196]	LR: 0.002	DT: 0.000 (0.145)	BT: 0.004 (0.151)	Loss 2.3262 (2.4003)	Prec@1 45.703 (41.677)	
Epoch: [16][77/196]	LR: 0.002	DT: 0.000 (0.113)	BT: 0.005 (0.121)	Loss 2.3672 (2.3805)	Prec@1 43.750 (42.233)	
Epoch: [16][116/196]	LR: 0.002	DT: 0.000 (0.098)	BT: 0.005 (0.106)	Loss 2.2227 (2.3779)	Prec@1 43.359 (42.331)	
Epoch: [16][155/196]	LR: 0.002	DT: 0.000 (0.087)	BT: 0.009 (0.094)	Loss 2.5137 (2.3866)	Prec@1 39.062 (41.990)	
Epoch: [16][194/196]	LR: 0.002	DT: 0.166 (0.294)	BT: 0.172 (0.301)	Loss 2.1914 (2.3919)	Prec@1 49.219 (41.943)	
Total train loss: 2.3917
Avg Loading time: 0.2921 seconds
Avg Batch time: 0.2998 seconds

 * Prec@1 31.000 Prec@5 59.240 Loss 2.8926
Avg Loading time: 1.8980 seconds
Avg Batch time: 1.9047 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [17][38/196]	LR: 0.002	DT: 0.001 (2.424)	BT: 0.007 (2.432)	Loss 2.4121 (2.3513)	Prec@1 41.797 (43.229)	
Epoch: [17][77/196]	LR: 0.002	DT: 0.000 (1.519)	BT: 0.007 (1.527)	Loss 2.3867 (2.3677)	Prec@1 40.234 (42.658)	
Epoch: [17][116/196]	LR: 0.002	DT: 0.000 (1.030)	BT: 0.005 (1.038)	Loss 2.4238 (2.3755)	Prec@1 45.312 (42.298)	
Epoch: [17][155/196]	LR: 0.002	DT: 0.000 (0.829)	BT: 0.007 (0.837)	Loss 2.2324 (2.3872)	Prec@1 48.047 (42.025)	
Epoch: [17][194/196]	LR: 0.002	DT: 2.326 (0.759)	BT: 2.334 (0.767)	Loss 2.3164 (2.3912)	Prec@1 46.094 (41.925)	
Total train loss: 2.3914
Avg Loading time: 0.7552 seconds
Avg Batch time: 0.7631 seconds

 * Prec@1 31.350 Prec@5 59.190 Loss 2.8867
Avg Loading time: 0.4195 seconds
Avg Batch time: 0.4259 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [18][38/196]	LR: 0.002	DT: 0.000 (0.381)	BT: 0.005 (0.389)	Loss 2.4180 (2.3743)	Prec@1 38.672 (42.258)	
Epoch: [18][77/196]	LR: 0.002	DT: 0.000 (0.416)	BT: 0.006 (0.424)	Loss 2.3848 (2.3738)	Prec@1 39.844 (42.398)	
Epoch: [18][116/196]	LR: 0.002	DT: 0.000 (0.433)	BT: 0.009 (0.441)	Loss 2.4023 (2.3851)	Prec@1 41.797 (42.214)	
Epoch: [18][155/196]	LR: 0.002	DT: 0.000 (0.477)	BT: 0.006 (0.485)	Loss 2.3457 (2.3897)	Prec@1 45.703 (42.015)	
Epoch: [18][194/196]	LR: 0.002	DT: 0.000 (0.488)	BT: 0.008 (0.496)	Loss 2.3262 (2.3902)	Prec@1 42.578 (42.079)	
Total train loss: 2.3902
Avg Loading time: 0.4857 seconds
Avg Batch time: 0.4938 seconds

 * Prec@1 31.180 Prec@5 59.310 Loss 2.8926
Avg Loading time: 0.5871 seconds
Avg Batch time: 0.5947 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [19][38/196]	LR: 0.002	DT: 0.000 (0.620)	BT: 0.005 (0.627)	Loss 2.4668 (2.3822)	Prec@1 41.797 (42.157)	
Epoch: [19][77/196]	LR: 0.002	DT: 0.000 (0.670)	BT: 0.005 (0.677)	Loss 2.3828 (2.3729)	Prec@1 47.656 (42.483)	
Epoch: [19][116/196]	LR: 0.002	DT: 0.000 (0.683)	BT: 0.006 (0.690)	Loss 2.4902 (2.3813)	Prec@1 40.625 (42.181)	
Epoch: [19][155/196]	LR: 0.002	DT: 0.000 (0.714)	BT: 0.007 (0.721)	Loss 2.4805 (2.3842)	Prec@1 40.625 (42.077)	
Epoch: [19][194/196]	LR: 0.002	DT: 0.000 (0.759)	BT: 0.009 (0.766)	Loss 2.3691 (2.3923)	Prec@1 42.969 (41.935)	
Total train loss: 2.3919
Avg Loading time: 0.7550 seconds
Avg Batch time: 0.7625 seconds

 * Prec@1 30.930 Prec@5 59.270 Loss 2.8945
Avg Loading time: 1.0459 seconds
Avg Batch time: 1.0533 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [20][38/196]	LR: 0.0004	DT: 0.000 (1.084)	BT: 0.007 (1.092)	Loss 2.3281 (2.3679)	Prec@1 42.578 (42.829)	
Epoch: [20][77/196]	LR: 0.0004	DT: 0.000 (1.152)	BT: 0.004 (1.160)	Loss 2.4766 (2.3655)	Prec@1 42.188 (42.733)	
Epoch: [20][116/196]	LR: 0.0004	DT: 0.000 (1.282)	BT: 0.006 (1.290)	Loss 2.3867 (2.3644)	Prec@1 40.625 (42.688)	
Epoch: [20][155/196]	LR: 0.0004	DT: 0.000 (1.395)	BT: 0.005 (1.403)	Loss 2.3281 (2.3607)	Prec@1 44.141 (42.696)	
Epoch: [20][194/196]	LR: 0.0004	DT: 0.000 (1.513)	BT: 0.008 (1.521)	Loss 2.6113 (2.3667)	Prec@1 35.938 (42.596)	
Total train loss: 2.3674
Avg Loading time: 1.5055 seconds
Avg Batch time: 1.5130 seconds

 * Prec@1 31.100 Prec@5 59.100 Loss 2.8926
Avg Loading time: 2.3934 seconds
Avg Batch time: 2.4012 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [21][38/196]	LR: 0.0004	DT: 0.000 (1.299)	BT: 0.005 (1.306)	Loss 2.1875 (2.3679)	Prec@1 46.484 (42.718)	
Epoch: [21][77/196]	LR: 0.0004	DT: 0.000 (0.753)	BT: 0.005 (0.761)	Loss 2.3066 (2.3589)	Prec@1 46.875 (42.944)	
Epoch: [21][116/196]	LR: 0.0004	DT: 0.000 (0.577)	BT: 0.006 (0.584)	Loss 2.4258 (2.3624)	Prec@1 41.406 (42.652)	
Epoch: [21][155/196]	LR: 0.0004	DT: 0.000 (0.479)	BT: 0.006 (0.486)	Loss 2.3145 (2.3623)	Prec@1 44.531 (42.691)	
Epoch: [21][194/196]	LR: 0.0004	DT: 0.000 (0.401)	BT: 0.006 (0.408)	Loss 2.4102 (2.3661)	Prec@1 41.016 (42.566)	
Total train loss: 2.3663
Avg Loading time: 0.3991 seconds
Avg Batch time: 0.4059 seconds

 * Prec@1 31.190 Prec@5 59.250 Loss 2.8926
Avg Loading time: 0.0955 seconds
Avg Batch time: 0.1015 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [22][38/196]	LR: 0.0004	DT: 0.000 (0.051)	BT: 0.006 (0.058)	Loss 2.4590 (2.3654)	Prec@1 39.453 (42.398)	
Epoch: [22][77/196]	LR: 0.0004	DT: 0.000 (0.154)	BT: 0.005 (0.161)	Loss 2.3184 (2.3654)	Prec@1 41.797 (42.648)	
Epoch: [22][116/196]	LR: 0.0004	DT: 0.000 (0.180)	BT: 0.007 (0.187)	Loss 2.2188 (2.3684)	Prec@1 46.875 (42.578)	
Epoch: [22][155/196]	LR: 0.0004	DT: 0.311 (0.150)	BT: 0.326 (0.157)	Loss 2.3887 (2.3700)	Prec@1 41.016 (42.546)	
Epoch: [22][194/196]	LR: 0.0004	DT: 0.000 (0.284)	BT: 0.005 (0.292)	Loss 2.4219 (2.3664)	Prec@1 35.938 (42.626)	
Total train loss: 2.3668
Avg Loading time: 0.2826 seconds
Avg Batch time: 0.2902 seconds

 * Prec@1 31.120 Prec@5 59.140 Loss 2.8945
Avg Loading time: 0.9994 seconds
Avg Batch time: 1.0058 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [23][38/196]	LR: 0.0004	DT: 0.000 (1.219)	BT: 0.009 (1.227)	Loss 2.3027 (2.3656)	Prec@1 42.969 (43.009)	
Epoch: [23][77/196]	LR: 0.0004	DT: 0.001 (0.748)	BT: 0.032 (0.757)	Loss 2.3242 (2.3588)	Prec@1 42.969 (43.159)	
Epoch: [23][116/196]	LR: 0.0004	DT: 0.000 (0.519)	BT: 0.006 (0.527)	Loss 2.4121 (2.3716)	Prec@1 38.672 (42.668)	
Epoch: [23][155/196]	LR: 0.0004	DT: 0.000 (0.465)	BT: 0.008 (0.473)	Loss 2.3086 (2.3684)	Prec@1 44.531 (42.508)	
Epoch: [23][194/196]	LR: 0.0004	DT: 0.000 (0.492)	BT: 0.007 (0.500)	Loss 2.3535 (2.3661)	Prec@1 44.531 (42.716)	
Total train loss: 2.3656
Avg Loading time: 0.4894 seconds
Avg Batch time: 0.4979 seconds

 * Prec@1 31.200 Prec@5 59.280 Loss 2.8945
Avg Loading time: 0.1049 seconds
Avg Batch time: 0.1112 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [24][38/196]	LR: 0.0004	DT: 0.021 (0.053)	BT: 0.026 (0.060)	Loss 2.2754 (2.3702)	Prec@1 47.266 (43.069)	
Epoch: [24][77/196]	LR: 0.0004	DT: 0.000 (0.044)	BT: 0.006 (0.051)	Loss 2.2402 (2.3655)	Prec@1 46.094 (42.653)	
Epoch: [24][116/196]	LR: 0.0004	DT: 0.000 (0.043)	BT: 0.006 (0.050)	Loss 2.3535 (2.3651)	Prec@1 39.844 (42.495)	
Epoch: [24][155/196]	LR: 0.0004	DT: 0.000 (0.041)	BT: 0.006 (0.048)	Loss 2.3848 (2.3636)	Prec@1 42.188 (42.531)	
Epoch: [24][194/196]	LR: 0.0004	DT: 0.051 (0.039)	BT: 0.058 (0.046)	Loss 2.4980 (2.3663)	Prec@1 39.453 (42.492)	
Total train loss: 2.3660
Avg Loading time: 0.0388 seconds
Avg Batch time: 0.0456 seconds

 * Prec@1 31.200 Prec@5 59.190 Loss 2.8945
Avg Loading time: 0.0720 seconds
Avg Batch time: 0.0772 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [25][38/196]	LR: 0.0004	DT: 0.000 (0.094)	BT: 0.005 (0.101)	Loss 2.4160 (2.3498)	Prec@1 40.625 (42.949)	
Epoch: [25][77/196]	LR: 0.0004	DT: 0.000 (0.066)	BT: 0.005 (0.073)	Loss 2.3281 (2.3652)	Prec@1 43.750 (42.778)	
Epoch: [25][116/196]	LR: 0.0004	DT: 0.000 (0.075)	BT: 0.006 (0.082)	Loss 2.3574 (2.3654)	Prec@1 39.844 (42.722)	
Epoch: [25][155/196]	LR: 0.0004	DT: 0.000 (0.078)	BT: 0.006 (0.085)	Loss 2.3418 (2.3624)	Prec@1 44.531 (42.834)	
Epoch: [25][194/196]	LR: 0.0004	DT: 0.000 (0.072)	BT: 0.007 (0.080)	Loss 2.3477 (2.3650)	Prec@1 43.750 (42.676)	
Total train loss: 2.3649
Avg Loading time: 0.0720 seconds
Avg Batch time: 0.0792 seconds

 * Prec@1 31.150 Prec@5 59.170 Loss 2.8926
Avg Loading time: 0.0548 seconds
Avg Batch time: 0.0602 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [26][38/196]	LR: 0.0004	DT: 0.000 (0.059)	BT: 0.006 (0.066)	Loss 2.1836 (2.3484)	Prec@1 47.656 (43.510)	
Epoch: [26][77/196]	LR: 0.0004	DT: 0.000 (0.051)	BT: 0.007 (0.057)	Loss 2.5566 (2.3634)	Prec@1 38.281 (43.254)	
Epoch: [26][116/196]	LR: 0.0004	DT: 0.000 (0.047)	BT: 0.005 (0.054)	Loss 2.3555 (2.3616)	Prec@1 41.797 (42.919)	
Epoch: [26][155/196]	LR: 0.0004	DT: 0.000 (0.044)	BT: 0.007 (0.051)	Loss 2.2617 (2.3608)	Prec@1 42.578 (42.914)	
Epoch: [26][194/196]	LR: 0.0004	DT: 0.000 (0.046)	BT: 0.006 (0.053)	Loss 2.3984 (2.3633)	Prec@1 43.359 (42.794)	
Total train loss: 2.3634
Avg Loading time: 0.0454 seconds
Avg Batch time: 0.0524 seconds

 * Prec@1 30.950 Prec@5 59.080 Loss 2.8965
Avg Loading time: 0.0509 seconds
Avg Batch time: 0.0556 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [27][38/196]	LR: 0.0004	DT: 0.000 (0.062)	BT: 0.006 (0.071)	Loss 2.5234 (2.3629)	Prec@1 40.625 (43.079)	
Epoch: [27][77/196]	LR: 0.0004	DT: 0.000 (0.057)	BT: 0.006 (0.065)	Loss 2.4062 (2.3633)	Prec@1 43.750 (42.959)	
Epoch: [27][116/196]	LR: 0.0004	DT: 0.032 (0.061)	BT: 0.040 (0.069)	Loss 2.3418 (2.3725)	Prec@1 45.703 (42.655)	
Epoch: [27][155/196]	LR: 0.0004	DT: 0.000 (0.058)	BT: 0.008 (0.067)	Loss 2.3516 (2.3660)	Prec@1 42.188 (42.826)	
Epoch: [27][194/196]	LR: 0.0004	DT: 0.086 (0.054)	BT: 0.092 (0.062)	Loss 2.2637 (2.3662)	Prec@1 46.875 (42.634)	
Total train loss: 2.3659
Avg Loading time: 0.0541 seconds
Avg Batch time: 0.0622 seconds

 * Prec@1 31.080 Prec@5 59.240 Loss 2.8906
Avg Loading time: 0.0555 seconds
Avg Batch time: 0.0607 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [28][38/196]	LR: 0.0004	DT: 0.000 (0.058)	BT: 0.006 (0.069)	Loss 2.5508 (2.3869)	Prec@1 40.625 (42.318)	
Epoch: [28][77/196]	LR: 0.0004	DT: 0.067 (0.048)	BT: 0.074 (0.058)	Loss 2.4082 (2.3664)	Prec@1 43.359 (42.588)	
Epoch: [28][116/196]	LR: 0.0004	DT: 0.000 (0.045)	BT: 0.007 (0.054)	Loss 2.2617 (2.3629)	Prec@1 46.094 (42.752)	
Epoch: [28][155/196]	LR: 0.0004	DT: 0.000 (0.043)	BT: 0.007 (0.051)	Loss 2.3398 (2.3640)	Prec@1 45.312 (42.746)	
Epoch: [28][194/196]	LR: 0.0004	DT: 0.000 (0.041)	BT: 0.005 (0.049)	Loss 2.3496 (2.3656)	Prec@1 44.922 (42.800)	
Total train loss: 2.3651
Avg Loading time: 0.0406 seconds
Avg Batch time: 0.0490 seconds

 * Prec@1 31.210 Prec@5 59.300 Loss 2.8926
Avg Loading time: 0.0596 seconds
Avg Batch time: 0.0649 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [29][38/196]	LR: 0.0004	DT: 0.000 (0.055)	BT: 0.005 (0.063)	Loss 2.3203 (2.3628)	Prec@1 42.969 (43.129)	
Epoch: [29][77/196]	LR: 0.0004	DT: 0.000 (0.046)	BT: 0.005 (0.054)	Loss 2.1758 (2.3587)	Prec@1 44.922 (42.768)	
Epoch: [29][116/196]	LR: 0.0004	DT: 0.000 (0.173)	BT: 0.006 (0.181)	Loss 2.3555 (2.3605)	Prec@1 44.141 (42.872)	
Epoch: [29][155/196]	LR: 0.0004	DT: 0.000 (0.263)	BT: 0.007 (0.270)	Loss 2.2480 (2.3668)	Prec@1 46.094 (42.731)	
Epoch: [29][194/196]	LR: 0.0004	DT: 0.000 (0.389)	BT: 0.012 (0.396)	Loss 2.5801 (2.3655)	Prec@1 36.328 (42.786)	
Total train loss: 2.3660
Avg Loading time: 0.3867 seconds
Avg Batch time: 0.3941 seconds

 * Prec@1 31.170 Prec@5 59.350 Loss 2.8945
Avg Loading time: 0.8011 seconds
Avg Batch time: 0.8071 seconds

Best acc: 31.490
--------------------------------------------------------------------------------
Epoch: [30][38/196]	LR: 8e-05	DT: 0.339 (0.783)	BT: 0.350 (0.791)	Loss 2.3301 (2.3759)	Prec@1 41.797 (42.398)	
Epoch: [30][77/196]	LR: 8e-05	DT: 0.082 (0.857)	BT: 0.088 (0.866)	Loss 2.2676 (2.3649)	Prec@1 47.266 (42.819)	
Epoch: [30][116/196]	LR: 8e-05	DT: 0.000 (1.696)	BT: 0.006 (1.705)	Loss 2.4336 (2.3650)	Prec@1 39.844 (43.019)	
Epoch: [30][155/196]	LR: 8e-05	DT: 0.000 (2.861)	BT: 0.007 (2.871)	Loss 2.3164 (2.3612)	Prec@1 42.188 (42.984)	
Epoch: [30][194/196]	LR: 8e-05	DT: 0.000 (3.970)	BT: 0.009 (3.980)	Loss 2.3730 (2.3610)	Prec@1 44.141 (42.933)	
Total train loss: 2.3612
Avg Loading time: 3.9499 seconds
Avg Batch time: 3.9597 seconds

