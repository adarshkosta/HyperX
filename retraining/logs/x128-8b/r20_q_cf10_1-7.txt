
      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/
          savedir: ../pretrained_models/frozen/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 60
          start_epoch: 0
          batch_size: 128
          lr: 0.002
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 7
          af_bit: 4
          w_bit: 7
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          exp: x128-8b
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 1
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.250 Prec@5 99.660 Loss 0.3286
Pre-trained Prec@1 with 1 layers frozen: 91.25 	 Loss: 0.32861328125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.002	Loss 0.0494 (0.0484)	Prec@1 97.656 (98.568)	
Epoch: [0][155/391]	LR: 0.002	Loss 0.0546 (0.0475)	Prec@1 99.219 (98.638)	
Epoch: [0][233/391]	LR: 0.002	Loss 0.0346 (0.0484)	Prec@1 99.219 (98.508)	
Epoch: [0][311/391]	LR: 0.002	Loss 0.0575 (0.0472)	Prec@1 99.219 (98.538)	
Epoch: [0][389/391]	LR: 0.002	Loss 0.0499 (0.0474)	Prec@1 98.438 (98.542)	
Total train loss: 0.0474

Train time: 79.54299426078796
 * Prec@1 91.460 Prec@5 99.610 Loss 0.3152
Best acc: 91.460
--------------------------------------------------------------------------------
Test time: 82.36396884918213

Epoch: [1][77/391]	LR: 0.002	Loss 0.0373 (0.0391)	Prec@1 98.438 (98.898)	
Epoch: [1][155/391]	LR: 0.002	Loss 0.0310 (0.0394)	Prec@1 99.219 (98.913)	
Epoch: [1][233/391]	LR: 0.002	Loss 0.0377 (0.0394)	Prec@1 98.438 (98.928)	
Epoch: [1][311/391]	LR: 0.002	Loss 0.0383 (0.0398)	Prec@1 98.438 (98.913)	
Epoch: [1][389/391]	LR: 0.002	Loss 0.0198 (0.0405)	Prec@1 100.000 (98.896)	
Total train loss: 0.0405

Train time: 27.342677354812622
 * Prec@1 91.500 Prec@5 99.660 Loss 0.3184
Best acc: 91.500
--------------------------------------------------------------------------------
Test time: 30.42436194419861

Epoch: [2][77/391]	LR: 0.002	Loss 0.0607 (0.0394)	Prec@1 99.219 (98.958)	
Epoch: [2][155/391]	LR: 0.002	Loss 0.0350 (0.0386)	Prec@1 99.219 (98.998)	
Epoch: [2][233/391]	LR: 0.002	Loss 0.0311 (0.0374)	Prec@1 100.000 (99.048)	
Epoch: [2][311/391]	LR: 0.002	Loss 0.0381 (0.0381)	Prec@1 100.000 (99.008)	
Epoch: [2][389/391]	LR: 0.002	Loss 0.0360 (0.0380)	Prec@1 97.656 (99.022)	
Total train loss: 0.0380

Train time: 23.666743993759155
 * Prec@1 91.410 Prec@5 99.590 Loss 0.3223
Best acc: 91.500
--------------------------------------------------------------------------------
Test time: 26.359009742736816

Epoch: [3][77/391]	LR: 0.002	Loss 0.0343 (0.0322)	Prec@1 98.438 (99.149)	
Epoch: [3][155/391]	LR: 0.002	Loss 0.0285 (0.0336)	Prec@1 100.000 (99.154)	
Epoch: [3][233/391]	LR: 0.002	Loss 0.0247 (0.0350)	Prec@1 98.438 (99.058)	
Epoch: [3][311/391]	LR: 0.002	Loss 0.0312 (0.0346)	Prec@1 99.219 (99.094)	
Epoch: [3][389/391]	LR: 0.002	Loss 0.0541 (0.0350)	Prec@1 97.656 (99.089)	
Total train loss: 0.0351

Train time: 24.087732315063477
 * Prec@1 91.570 Prec@5 99.650 Loss 0.3225
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 27.364951133728027

Epoch: [4][77/391]	LR: 0.002	Loss 0.0359 (0.0317)	Prec@1 99.219 (99.179)	
Epoch: [4][155/391]	LR: 0.002	Loss 0.0300 (0.0320)	Prec@1 99.219 (99.259)	
Epoch: [4][233/391]	LR: 0.002	Loss 0.0176 (0.0330)	Prec@1 100.000 (99.202)	
Epoch: [4][311/391]	LR: 0.002	Loss 0.0531 (0.0331)	Prec@1 97.656 (99.194)	
Epoch: [4][389/391]	LR: 0.002	Loss 0.0380 (0.0332)	Prec@1 98.438 (99.215)	
Total train loss: 0.0332

Train time: 23.841613292694092
 * Prec@1 91.310 Prec@5 99.540 Loss 0.3245
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.52747130393982

Epoch: [5][77/391]	LR: 0.002	Loss 0.0219 (0.0323)	Prec@1 99.219 (99.259)	
Epoch: [5][155/391]	LR: 0.002	Loss 0.0412 (0.0313)	Prec@1 98.438 (99.284)	
Epoch: [5][233/391]	LR: 0.002	Loss 0.0379 (0.0318)	Prec@1 100.000 (99.282)	
Epoch: [5][311/391]	LR: 0.002	Loss 0.0207 (0.0310)	Prec@1 100.000 (99.336)	
Epoch: [5][389/391]	LR: 0.002	Loss 0.0163 (0.0317)	Prec@1 100.000 (99.297)	
Total train loss: 0.0317

Train time: 23.48943257331848
 * Prec@1 91.420 Prec@5 99.570 Loss 0.3235
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.19299054145813

Epoch: [6][77/391]	LR: 0.002	Loss 0.0368 (0.0294)	Prec@1 100.000 (99.349)	
Epoch: [6][155/391]	LR: 0.002	Loss 0.0183 (0.0305)	Prec@1 99.219 (99.274)	
Epoch: [6][233/391]	LR: 0.002	Loss 0.0308 (0.0308)	Prec@1 98.438 (99.262)	
Epoch: [6][311/391]	LR: 0.002	Loss 0.0154 (0.0305)	Prec@1 100.000 (99.284)	
Epoch: [6][389/391]	LR: 0.002	Loss 0.0166 (0.0306)	Prec@1 100.000 (99.293)	
Total train loss: 0.0306

Train time: 23.38208270072937
 * Prec@1 91.480 Prec@5 99.600 Loss 0.3269
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 25.614967584609985

Epoch: [7][77/391]	LR: 0.002	Loss 0.0365 (0.0277)	Prec@1 100.000 (99.419)	
Epoch: [7][155/391]	LR: 0.002	Loss 0.0232 (0.0282)	Prec@1 100.000 (99.419)	
Epoch: [7][233/391]	LR: 0.002	Loss 0.0277 (0.0287)	Prec@1 99.219 (99.419)	
Epoch: [7][311/391]	LR: 0.002	Loss 0.0214 (0.0285)	Prec@1 99.219 (99.399)	
Epoch: [7][389/391]	LR: 0.002	Loss 0.0258 (0.0284)	Prec@1 100.000 (99.405)	
Total train loss: 0.0285

Train time: 24.039763689041138
 * Prec@1 91.350 Prec@5 99.610 Loss 0.3240
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.83606767654419

Epoch: [8][77/391]	LR: 0.002	Loss 0.0117 (0.0268)	Prec@1 100.000 (99.569)	
Epoch: [8][155/391]	LR: 0.002	Loss 0.0228 (0.0269)	Prec@1 100.000 (99.534)	
Epoch: [8][233/391]	LR: 0.002	Loss 0.0602 (0.0269)	Prec@1 96.875 (99.493)	
Epoch: [8][311/391]	LR: 0.002	Loss 0.0211 (0.0270)	Prec@1 99.219 (99.487)	
Epoch: [8][389/391]	LR: 0.002	Loss 0.0303 (0.0271)	Prec@1 99.219 (99.473)	
Total train loss: 0.0271

Train time: 24.35677433013916
 * Prec@1 91.410 Prec@5 99.590 Loss 0.3267
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.227749586105347

Epoch: [9][77/391]	LR: 0.002	Loss 0.0392 (0.0279)	Prec@1 98.438 (99.439)	
Epoch: [9][155/391]	LR: 0.002	Loss 0.0219 (0.0270)	Prec@1 99.219 (99.464)	
Epoch: [9][233/391]	LR: 0.002	Loss 0.0443 (0.0263)	Prec@1 99.219 (99.483)	
Epoch: [9][311/391]	LR: 0.002	Loss 0.0178 (0.0263)	Prec@1 100.000 (99.492)	
Epoch: [9][389/391]	LR: 0.002	Loss 0.0271 (0.0265)	Prec@1 100.000 (99.499)	
Total train loss: 0.0266

Train time: 24.775270223617554
 * Prec@1 91.270 Prec@5 99.610 Loss 0.3313
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 27.920927047729492

Epoch: [10][77/391]	LR: 0.002	Loss 0.0259 (0.0249)	Prec@1 99.219 (99.629)	
Epoch: [10][155/391]	LR: 0.002	Loss 0.0208 (0.0245)	Prec@1 100.000 (99.594)	
Epoch: [10][233/391]	LR: 0.002	Loss 0.0130 (0.0248)	Prec@1 100.000 (99.596)	
Epoch: [10][311/391]	LR: 0.002	Loss 0.0587 (0.0251)	Prec@1 96.094 (99.547)	
Epoch: [10][389/391]	LR: 0.002	Loss 0.0309 (0.0252)	Prec@1 100.000 (99.553)	
Total train loss: 0.0252

Train time: 24.16109347343445
 * Prec@1 91.430 Prec@5 99.610 Loss 0.3274
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.54181146621704

Epoch: [11][77/391]	LR: 0.002	Loss 0.0238 (0.0255)	Prec@1 100.000 (99.690)	
Epoch: [11][155/391]	LR: 0.002	Loss 0.0510 (0.0249)	Prec@1 98.438 (99.644)	
Epoch: [11][233/391]	LR: 0.002	Loss 0.0182 (0.0250)	Prec@1 100.000 (99.636)	
Epoch: [11][311/391]	LR: 0.002	Loss 0.0095 (0.0248)	Prec@1 100.000 (99.614)	
Epoch: [11][389/391]	LR: 0.002	Loss 0.0246 (0.0249)	Prec@1 100.000 (99.617)	
Total train loss: 0.0249

Train time: 23.440287828445435
 * Prec@1 91.290 Prec@5 99.570 Loss 0.3291
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.37205719947815

Epoch: [12][77/391]	LR: 0.002	Loss 0.0216 (0.0239)	Prec@1 100.000 (99.539)	
Epoch: [12][155/391]	LR: 0.002	Loss 0.0291 (0.0235)	Prec@1 99.219 (99.634)	
Epoch: [12][233/391]	LR: 0.002	Loss 0.0152 (0.0243)	Prec@1 100.000 (99.593)	
Epoch: [12][311/391]	LR: 0.002	Loss 0.0281 (0.0244)	Prec@1 100.000 (99.579)	
Epoch: [12][389/391]	LR: 0.002	Loss 0.0394 (0.0243)	Prec@1 99.219 (99.591)	
Total train loss: 0.0243

Train time: 24.008641958236694
 * Prec@1 91.440 Prec@5 99.520 Loss 0.3320
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.071160793304443

Epoch: [13][77/391]	LR: 0.002	Loss 0.0242 (0.0229)	Prec@1 99.219 (99.629)	
Epoch: [13][155/391]	LR: 0.002	Loss 0.0215 (0.0233)	Prec@1 100.000 (99.594)	
Epoch: [13][233/391]	LR: 0.002	Loss 0.0181 (0.0236)	Prec@1 100.000 (99.593)	
Epoch: [13][311/391]	LR: 0.002	Loss 0.0168 (0.0239)	Prec@1 100.000 (99.587)	
Epoch: [13][389/391]	LR: 0.002	Loss 0.0132 (0.0240)	Prec@1 100.000 (99.597)	
Total train loss: 0.0240

Train time: 24.246113538742065
 * Prec@1 91.330 Prec@5 99.580 Loss 0.3308
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 27.02388620376587

Epoch: [14][77/391]	LR: 0.002	Loss 0.0276 (0.0245)	Prec@1 99.219 (99.549)	
Epoch: [14][155/391]	LR: 0.002	Loss 0.0145 (0.0234)	Prec@1 100.000 (99.629)	
Epoch: [14][233/391]	LR: 0.002	Loss 0.0306 (0.0239)	Prec@1 99.219 (99.619)	
Epoch: [14][311/391]	LR: 0.002	Loss 0.0188 (0.0237)	Prec@1 100.000 (99.629)	
Epoch: [14][389/391]	LR: 0.002	Loss 0.0081 (0.0236)	Prec@1 100.000 (99.623)	
Total train loss: 0.0236

Train time: 24.17145013809204
 * Prec@1 91.310 Prec@5 99.610 Loss 0.3318
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.332908868789673

Epoch: [15][77/391]	LR: 0.002	Loss 0.0178 (0.0201)	Prec@1 100.000 (99.790)	
Epoch: [15][155/391]	LR: 0.002	Loss 0.0145 (0.0205)	Prec@1 100.000 (99.790)	
Epoch: [15][233/391]	LR: 0.002	Loss 0.0502 (0.0217)	Prec@1 99.219 (99.713)	
Epoch: [15][311/391]	LR: 0.002	Loss 0.0254 (0.0216)	Prec@1 99.219 (99.725)	
Epoch: [15][389/391]	LR: 0.002	Loss 0.0209 (0.0218)	Prec@1 100.000 (99.720)	
Total train loss: 0.0218

Train time: 23.166838884353638
 * Prec@1 91.340 Prec@5 99.530 Loss 0.3320
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.545151710510254

Epoch: [16][77/391]	LR: 0.002	Loss 0.0191 (0.0232)	Prec@1 100.000 (99.629)	
Epoch: [16][155/391]	LR: 0.002	Loss 0.0183 (0.0219)	Prec@1 100.000 (99.659)	
Epoch: [16][233/391]	LR: 0.002	Loss 0.0222 (0.0219)	Prec@1 100.000 (99.669)	
Epoch: [16][311/391]	LR: 0.002	Loss 0.0289 (0.0220)	Prec@1 99.219 (99.664)	
Epoch: [16][389/391]	LR: 0.002	Loss 0.0117 (0.0222)	Prec@1 100.000 (99.663)	
Total train loss: 0.0222

Train time: 23.854535579681396
 * Prec@1 91.240 Prec@5 99.560 Loss 0.3357
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 25.794190406799316

Epoch: [17][77/391]	LR: 0.002	Loss 0.0274 (0.0217)	Prec@1 99.219 (99.710)	
Epoch: [17][155/391]	LR: 0.002	Loss 0.0193 (0.0217)	Prec@1 100.000 (99.720)	
Epoch: [17][233/391]	LR: 0.002	Loss 0.0245 (0.0218)	Prec@1 99.219 (99.693)	
Epoch: [17][311/391]	LR: 0.002	Loss 0.0084 (0.0215)	Prec@1 100.000 (99.702)	
Epoch: [17][389/391]	LR: 0.002	Loss 0.0164 (0.0215)	Prec@1 100.000 (99.704)	
Total train loss: 0.0216

Train time: 26.30919861793518
 * Prec@1 91.190 Prec@5 99.580 Loss 0.3342
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 29.14518094062805

Epoch: [18][77/391]	LR: 0.002	Loss 0.0141 (0.0208)	Prec@1 100.000 (99.730)	
Epoch: [18][155/391]	LR: 0.002	Loss 0.0349 (0.0211)	Prec@1 99.219 (99.710)	
Epoch: [18][233/391]	LR: 0.002	Loss 0.0347 (0.0217)	Prec@1 99.219 (99.706)	
Epoch: [18][311/391]	LR: 0.002	Loss 0.0197 (0.0212)	Prec@1 100.000 (99.735)	
Epoch: [18][389/391]	LR: 0.002	Loss 0.0285 (0.0209)	Prec@1 99.219 (99.734)	
Total train loss: 0.0209

Train time: 23.960822582244873
 * Prec@1 91.240 Prec@5 99.520 Loss 0.3335
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.37519884109497

Epoch: [19][77/391]	LR: 0.002	Loss 0.0170 (0.0183)	Prec@1 100.000 (99.830)	
Epoch: [19][155/391]	LR: 0.002	Loss 0.0206 (0.0199)	Prec@1 100.000 (99.765)	
Epoch: [19][233/391]	LR: 0.002	Loss 0.0129 (0.0197)	Prec@1 100.000 (99.763)	
Epoch: [19][311/391]	LR: 0.002	Loss 0.0251 (0.0196)	Prec@1 99.219 (99.777)	
Epoch: [19][389/391]	LR: 0.002	Loss 0.0367 (0.0200)	Prec@1 99.219 (99.772)	
Total train loss: 0.0200

Train time: 23.26892399787903
 * Prec@1 91.220 Prec@5 99.550 Loss 0.3352
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.030500650405884

Epoch: [20][77/391]	LR: 0.0002	Loss 0.0149 (0.0190)	Prec@1 100.000 (99.810)	
Epoch: [20][155/391]	LR: 0.0002	Loss 0.0184 (0.0200)	Prec@1 99.219 (99.740)	
Epoch: [20][233/391]	LR: 0.0002	Loss 0.0132 (0.0200)	Prec@1 100.000 (99.730)	
Epoch: [20][311/391]	LR: 0.0002	Loss 0.0481 (0.0198)	Prec@1 99.219 (99.755)	
Epoch: [20][389/391]	LR: 0.0002	Loss 0.0235 (0.0197)	Prec@1 100.000 (99.766)	
Total train loss: 0.0197

Train time: 24.127657413482666
 * Prec@1 91.360 Prec@5 99.590 Loss 0.3333
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.663613319396973

Epoch: [21][77/391]	LR: 0.0002	Loss 0.0317 (0.0202)	Prec@1 99.219 (99.830)	
Epoch: [21][155/391]	LR: 0.0002	Loss 0.0328 (0.0197)	Prec@1 98.438 (99.780)	
Epoch: [21][233/391]	LR: 0.0002	Loss 0.0162 (0.0197)	Prec@1 100.000 (99.770)	
Epoch: [21][311/391]	LR: 0.0002	Loss 0.0134 (0.0200)	Prec@1 100.000 (99.735)	
Epoch: [21][389/391]	LR: 0.0002	Loss 0.0157 (0.0198)	Prec@1 100.000 (99.742)	
Total train loss: 0.0198

Train time: 23.884161949157715
 * Prec@1 91.280 Prec@5 99.540 Loss 0.3347
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.78062415122986

Epoch: [22][77/391]	LR: 0.0002	Loss 0.0255 (0.0189)	Prec@1 100.000 (99.750)	
Epoch: [22][155/391]	LR: 0.0002	Loss 0.0186 (0.0194)	Prec@1 100.000 (99.765)	
Epoch: [22][233/391]	LR: 0.0002	Loss 0.0210 (0.0199)	Prec@1 100.000 (99.753)	
Epoch: [22][311/391]	LR: 0.0002	Loss 0.0168 (0.0199)	Prec@1 99.219 (99.742)	
Epoch: [22][389/391]	LR: 0.0002	Loss 0.0135 (0.0199)	Prec@1 100.000 (99.746)	
Total train loss: 0.0199

Train time: 24.908658266067505
 * Prec@1 91.290 Prec@5 99.530 Loss 0.3362
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.934612274169922

Epoch: [23][77/391]	LR: 0.0002	Loss 0.0076 (0.0193)	Prec@1 100.000 (99.750)	
Epoch: [23][155/391]	LR: 0.0002	Loss 0.0142 (0.0196)	Prec@1 100.000 (99.795)	
Epoch: [23][233/391]	LR: 0.0002	Loss 0.0363 (0.0201)	Prec@1 99.219 (99.773)	
Epoch: [23][311/391]	LR: 0.0002	Loss 0.0109 (0.0198)	Prec@1 100.000 (99.777)	
Epoch: [23][389/391]	LR: 0.0002	Loss 0.0153 (0.0198)	Prec@1 100.000 (99.778)	
Total train loss: 0.0198

Train time: 24.178824424743652
 * Prec@1 91.330 Prec@5 99.600 Loss 0.3325
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.798545598983765

Epoch: [24][77/391]	LR: 0.0002	Loss 0.0143 (0.0188)	Prec@1 100.000 (99.790)	
Epoch: [24][155/391]	LR: 0.0002	Loss 0.0190 (0.0199)	Prec@1 100.000 (99.750)	
Epoch: [24][233/391]	LR: 0.0002	Loss 0.0113 (0.0199)	Prec@1 100.000 (99.773)	
Epoch: [24][311/391]	LR: 0.0002	Loss 0.0112 (0.0198)	Prec@1 100.000 (99.772)	
Epoch: [24][389/391]	LR: 0.0002	Loss 0.0133 (0.0198)	Prec@1 100.000 (99.766)	
Total train loss: 0.0198

Train time: 24.52318572998047
 * Prec@1 91.240 Prec@5 99.550 Loss 0.3335
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.49707293510437

Epoch: [25][77/391]	LR: 0.0002	Loss 0.0265 (0.0198)	Prec@1 99.219 (99.720)	
Epoch: [25][155/391]	LR: 0.0002	Loss 0.0199 (0.0196)	Prec@1 99.219 (99.790)	
Epoch: [25][233/391]	LR: 0.0002	Loss 0.0213 (0.0197)	Prec@1 100.000 (99.776)	
Epoch: [25][311/391]	LR: 0.0002	Loss 0.0257 (0.0195)	Prec@1 99.219 (99.795)	
Epoch: [25][389/391]	LR: 0.0002	Loss 0.0442 (0.0194)	Prec@1 98.438 (99.786)	
Total train loss: 0.0195

Train time: 24.908195972442627
 * Prec@1 91.240 Prec@5 99.550 Loss 0.3369
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 28.443829774856567

Epoch: [26][77/391]	LR: 0.0002	Loss 0.0160 (0.0197)	Prec@1 100.000 (99.740)	
Epoch: [26][155/391]	LR: 0.0002	Loss 0.0158 (0.0196)	Prec@1 99.219 (99.705)	
Epoch: [26][233/391]	LR: 0.0002	Loss 0.0097 (0.0196)	Prec@1 100.000 (99.726)	
Epoch: [26][311/391]	LR: 0.0002	Loss 0.0124 (0.0196)	Prec@1 100.000 (99.725)	
Epoch: [26][389/391]	LR: 0.0002	Loss 0.0086 (0.0195)	Prec@1 100.000 (99.740)	
Total train loss: 0.0195

Train time: 24.056273937225342
 * Prec@1 91.320 Prec@5 99.560 Loss 0.3328
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.046446084976196

Epoch: [27][77/391]	LR: 0.0002	Loss 0.0100 (0.0207)	Prec@1 100.000 (99.770)	
Epoch: [27][155/391]	LR: 0.0002	Loss 0.0856 (0.0204)	Prec@1 97.656 (99.785)	
Epoch: [27][233/391]	LR: 0.0002	Loss 0.0218 (0.0201)	Prec@1 100.000 (99.780)	
Epoch: [27][311/391]	LR: 0.0002	Loss 0.0129 (0.0199)	Prec@1 100.000 (99.795)	
Epoch: [27][389/391]	LR: 0.0002	Loss 0.0130 (0.0198)	Prec@1 100.000 (99.796)	
Total train loss: 0.0198

Train time: 23.564030170440674
 * Prec@1 91.320 Prec@5 99.560 Loss 0.3318
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.486274003982544

Epoch: [28][77/391]	LR: 0.0002	Loss 0.0200 (0.0198)	Prec@1 100.000 (99.800)	
Epoch: [28][155/391]	LR: 0.0002	Loss 0.0180 (0.0197)	Prec@1 100.000 (99.780)	
Epoch: [28][233/391]	LR: 0.0002	Loss 0.0178 (0.0196)	Prec@1 100.000 (99.773)	
Epoch: [28][311/391]	LR: 0.0002	Loss 0.0224 (0.0197)	Prec@1 100.000 (99.782)	
Epoch: [28][389/391]	LR: 0.0002	Loss 0.0207 (0.0197)	Prec@1 100.000 (99.778)	
Total train loss: 0.0197

Train time: 24.277953147888184
 * Prec@1 91.110 Prec@5 99.520 Loss 0.3379
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.207581758499146

Epoch: [29][77/391]	LR: 0.0002	Loss 0.0179 (0.0192)	Prec@1 100.000 (99.750)	
Epoch: [29][155/391]	LR: 0.0002	Loss 0.0118 (0.0202)	Prec@1 100.000 (99.720)	
Epoch: [29][233/391]	LR: 0.0002	Loss 0.0247 (0.0202)	Prec@1 99.219 (99.743)	
Epoch: [29][311/391]	LR: 0.0002	Loss 0.0090 (0.0199)	Prec@1 100.000 (99.752)	
Epoch: [29][389/391]	LR: 0.0002	Loss 0.0115 (0.0195)	Prec@1 100.000 (99.768)	
Total train loss: 0.0194

Train time: 23.951460123062134
 * Prec@1 91.370 Prec@5 99.590 Loss 0.3357
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.911394834518433

Epoch: [30][77/391]	LR: 2e-05	Loss 0.0103 (0.0181)	Prec@1 100.000 (99.840)	
Epoch: [30][155/391]	LR: 2e-05	Loss 0.0166 (0.0191)	Prec@1 100.000 (99.810)	
Epoch: [30][233/391]	LR: 2e-05	Loss 0.0146 (0.0190)	Prec@1 100.000 (99.806)	
Epoch: [30][311/391]	LR: 2e-05	Loss 0.0184 (0.0195)	Prec@1 100.000 (99.790)	
Epoch: [30][389/391]	LR: 2e-05	Loss 0.0137 (0.0194)	Prec@1 100.000 (99.810)	
Total train loss: 0.0195

Train time: 24.425114154815674
 * Prec@1 91.410 Prec@5 99.570 Loss 0.3301
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.529292106628418

Epoch: [31][77/391]	LR: 2e-05	Loss 0.0164 (0.0211)	Prec@1 100.000 (99.690)	
Epoch: [31][155/391]	LR: 2e-05	Loss 0.0174 (0.0208)	Prec@1 100.000 (99.710)	
Epoch: [31][233/391]	LR: 2e-05	Loss 0.0215 (0.0206)	Prec@1 100.000 (99.736)	
Epoch: [31][311/391]	LR: 2e-05	Loss 0.0109 (0.0199)	Prec@1 100.000 (99.780)	
Epoch: [31][389/391]	LR: 2e-05	Loss 0.0204 (0.0196)	Prec@1 100.000 (99.782)	
Total train loss: 0.0196

Train time: 24.102123260498047
 * Prec@1 91.250 Prec@5 99.530 Loss 0.3357
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.551308393478394

Epoch: [32][77/391]	LR: 2e-05	Loss 0.0099 (0.0197)	Prec@1 100.000 (99.830)	
Epoch: [32][155/391]	LR: 2e-05	Loss 0.0120 (0.0200)	Prec@1 100.000 (99.815)	
Epoch: [32][233/391]	LR: 2e-05	Loss 0.0076 (0.0200)	Prec@1 100.000 (99.820)	
Epoch: [32][311/391]	LR: 2e-05	Loss 0.0152 (0.0194)	Prec@1 100.000 (99.832)	
Epoch: [32][389/391]	LR: 2e-05	Loss 0.0130 (0.0190)	Prec@1 100.000 (99.834)	
Total train loss: 0.0190

Train time: 24.97112512588501
 * Prec@1 91.450 Prec@5 99.540 Loss 0.3315
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 27.10706663131714

Epoch: [33][77/391]	LR: 2e-05	Loss 0.0242 (0.0192)	Prec@1 99.219 (99.790)	
Epoch: [33][155/391]	LR: 2e-05	Loss 0.0159 (0.0193)	Prec@1 100.000 (99.785)	
Epoch: [33][233/391]	LR: 2e-05	Loss 0.0251 (0.0195)	Prec@1 99.219 (99.763)	
Epoch: [33][311/391]	LR: 2e-05	Loss 0.0353 (0.0196)	Prec@1 98.438 (99.750)	
Epoch: [33][389/391]	LR: 2e-05	Loss 0.0110 (0.0197)	Prec@1 100.000 (99.736)	
Total train loss: 0.0197

Train time: 24.18275475502014
 * Prec@1 91.300 Prec@5 99.560 Loss 0.3374
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 31.19599461555481

Epoch: [34][77/391]	LR: 2e-05	Loss 0.0132 (0.0203)	Prec@1 100.000 (99.830)	
Epoch: [34][155/391]	LR: 2e-05	Loss 0.0125 (0.0191)	Prec@1 100.000 (99.850)	
Epoch: [34][233/391]	LR: 2e-05	Loss 0.0197 (0.0193)	Prec@1 100.000 (99.806)	
Epoch: [34][311/391]	LR: 2e-05	Loss 0.0194 (0.0192)	Prec@1 99.219 (99.792)	
Epoch: [34][389/391]	LR: 2e-05	Loss 0.0164 (0.0194)	Prec@1 100.000 (99.782)	
Total train loss: 0.0195

Train time: 23.773762702941895
 * Prec@1 91.280 Prec@5 99.550 Loss 0.3357
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 25.824525356292725

Epoch: [35][77/391]	LR: 2e-05	Loss 0.0147 (0.0206)	Prec@1 100.000 (99.730)	
Epoch: [35][155/391]	LR: 2e-05	Loss 0.0163 (0.0196)	Prec@1 100.000 (99.740)	
Epoch: [35][233/391]	LR: 2e-05	Loss 0.0212 (0.0204)	Prec@1 100.000 (99.733)	
Epoch: [35][311/391]	LR: 2e-05	Loss 0.0288 (0.0206)	Prec@1 99.219 (99.732)	
Epoch: [35][389/391]	LR: 2e-05	Loss 0.0126 (0.0205)	Prec@1 100.000 (99.746)	
Total train loss: 0.0205

Train time: 23.737956762313843
 * Prec@1 91.290 Prec@5 99.600 Loss 0.3340
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.876771688461304

Epoch: [36][77/391]	LR: 2e-05	Loss 0.0092 (0.0189)	Prec@1 100.000 (99.820)	
Epoch: [36][155/391]	LR: 2e-05	Loss 0.0193 (0.0184)	Prec@1 100.000 (99.840)	
Epoch: [36][233/391]	LR: 2e-05	Loss 0.0112 (0.0187)	Prec@1 100.000 (99.810)	
Epoch: [36][311/391]	LR: 2e-05	Loss 0.0245 (0.0190)	Prec@1 99.219 (99.800)	
Epoch: [36][389/391]	LR: 2e-05	Loss 0.0351 (0.0191)	Prec@1 99.219 (99.802)	
Total train loss: 0.0191

Train time: 24.20517873764038
 * Prec@1 91.220 Prec@5 99.530 Loss 0.3333
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.083470106124878

Epoch: [37][77/391]	LR: 2e-05	Loss 0.0219 (0.0194)	Prec@1 100.000 (99.750)	
Epoch: [37][155/391]	LR: 2e-05	Loss 0.0254 (0.0201)	Prec@1 100.000 (99.780)	
Epoch: [37][233/391]	LR: 2e-05	Loss 0.0182 (0.0199)	Prec@1 100.000 (99.783)	
Epoch: [37][311/391]	LR: 2e-05	Loss 0.0340 (0.0195)	Prec@1 99.219 (99.790)	
Epoch: [37][389/391]	LR: 2e-05	Loss 0.0251 (0.0197)	Prec@1 100.000 (99.788)	
Total train loss: 0.0197

Train time: 21.39482831954956
 * Prec@1 91.330 Prec@5 99.560 Loss 0.3318
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 24.823914766311646

Epoch: [38][77/391]	LR: 2e-05	Loss 0.0295 (0.0200)	Prec@1 99.219 (99.780)	
Epoch: [38][155/391]	LR: 2e-05	Loss 0.0126 (0.0200)	Prec@1 100.000 (99.775)	
Epoch: [38][233/391]	LR: 2e-05	Loss 0.0181 (0.0199)	Prec@1 100.000 (99.776)	
Epoch: [38][311/391]	LR: 2e-05	Loss 0.0192 (0.0203)	Prec@1 99.219 (99.747)	
Epoch: [38][389/391]	LR: 2e-05	Loss 0.0091 (0.0199)	Prec@1 100.000 (99.750)	
Total train loss: 0.0199

Train time: 23.341917991638184
 * Prec@1 91.320 Prec@5 99.580 Loss 0.3357
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.798969268798828

Epoch: [39][77/391]	LR: 2e-05	Loss 0.0358 (0.0186)	Prec@1 99.219 (99.840)	
Epoch: [39][155/391]	LR: 2e-05	Loss 0.0218 (0.0185)	Prec@1 100.000 (99.850)	
Epoch: [39][233/391]	LR: 2e-05	Loss 0.0147 (0.0189)	Prec@1 100.000 (99.823)	
Epoch: [39][311/391]	LR: 2e-05	Loss 0.0114 (0.0191)	Prec@1 100.000 (99.820)	
Epoch: [39][389/391]	LR: 2e-05	Loss 0.0158 (0.0188)	Prec@1 100.000 (99.820)	
Total train loss: 0.0188

Train time: 22.530277967453003
 * Prec@1 91.240 Prec@5 99.580 Loss 0.3318
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 25.880958318710327

Epoch: [40][77/391]	LR: 2.0000000000000003e-06	Loss 0.0079 (0.0197)	Prec@1 100.000 (99.800)	
Epoch: [40][155/391]	LR: 2.0000000000000003e-06	Loss 0.0153 (0.0188)	Prec@1 100.000 (99.820)	
Epoch: [40][233/391]	LR: 2.0000000000000003e-06	Loss 0.0191 (0.0194)	Prec@1 100.000 (99.793)	
Epoch: [40][311/391]	LR: 2.0000000000000003e-06	Loss 0.0194 (0.0199)	Prec@1 100.000 (99.770)	
Epoch: [40][389/391]	LR: 2.0000000000000003e-06	Loss 0.0196 (0.0196)	Prec@1 99.219 (99.778)	
Total train loss: 0.0196

Train time: 24.36235547065735
 * Prec@1 91.290 Prec@5 99.560 Loss 0.3328
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.424004077911377

Epoch: [41][77/391]	LR: 2.0000000000000003e-06	Loss 0.0159 (0.0187)	Prec@1 100.000 (99.780)	
Epoch: [41][155/391]	LR: 2.0000000000000003e-06	Loss 0.0114 (0.0198)	Prec@1 100.000 (99.750)	
Epoch: [41][233/391]	LR: 2.0000000000000003e-06	Loss 0.0163 (0.0198)	Prec@1 100.000 (99.753)	
Epoch: [41][311/391]	LR: 2.0000000000000003e-06	Loss 0.0181 (0.0194)	Prec@1 100.000 (99.772)	
Epoch: [41][389/391]	LR: 2.0000000000000003e-06	Loss 0.0076 (0.0193)	Prec@1 100.000 (99.780)	
Total train loss: 0.0193

Train time: 23.661981105804443
 * Prec@1 91.300 Prec@5 99.590 Loss 0.3335
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.79990029335022

Epoch: [42][77/391]	LR: 2.0000000000000003e-06	Loss 0.0157 (0.0199)	Prec@1 100.000 (99.810)	
Epoch: [42][155/391]	LR: 2.0000000000000003e-06	Loss 0.0246 (0.0201)	Prec@1 98.438 (99.770)	
Epoch: [42][233/391]	LR: 2.0000000000000003e-06	Loss 0.0151 (0.0198)	Prec@1 100.000 (99.753)	
Epoch: [42][311/391]	LR: 2.0000000000000003e-06	Loss 0.0098 (0.0199)	Prec@1 100.000 (99.732)	
Epoch: [42][389/391]	LR: 2.0000000000000003e-06	Loss 0.0096 (0.0198)	Prec@1 100.000 (99.734)	
Total train loss: 0.0198

Train time: 23.39713478088379
 * Prec@1 91.480 Prec@5 99.540 Loss 0.3311
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 25.77042293548584

Epoch: [43][77/391]	LR: 2.0000000000000003e-06	Loss 0.0145 (0.0201)	Prec@1 100.000 (99.710)	
Epoch: [43][155/391]	LR: 2.0000000000000003e-06	Loss 0.0115 (0.0207)	Prec@1 100.000 (99.725)	
Epoch: [43][233/391]	LR: 2.0000000000000003e-06	Loss 0.0196 (0.0205)	Prec@1 100.000 (99.736)	
Epoch: [43][311/391]	LR: 2.0000000000000003e-06	Loss 0.0190 (0.0204)	Prec@1 99.219 (99.735)	
Epoch: [43][389/391]	LR: 2.0000000000000003e-06	Loss 0.0234 (0.0201)	Prec@1 99.219 (99.750)	
Total train loss: 0.0201

Train time: 24.50086259841919
 * Prec@1 91.400 Prec@5 99.570 Loss 0.3330
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 27.944573640823364

Epoch: [44][77/391]	LR: 2.0000000000000003e-06	Loss 0.0247 (0.0201)	Prec@1 100.000 (99.770)	
Epoch: [44][155/391]	LR: 2.0000000000000003e-06	Loss 0.0156 (0.0197)	Prec@1 100.000 (99.765)	
Epoch: [44][233/391]	LR: 2.0000000000000003e-06	Loss 0.0097 (0.0192)	Prec@1 100.000 (99.783)	
Epoch: [44][311/391]	LR: 2.0000000000000003e-06	Loss 0.0110 (0.0193)	Prec@1 100.000 (99.767)	
Epoch: [44][389/391]	LR: 2.0000000000000003e-06	Loss 0.0232 (0.0195)	Prec@1 100.000 (99.780)	
Total train loss: 0.0195

Train time: 23.781309843063354
 * Prec@1 91.360 Prec@5 99.540 Loss 0.3350
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 25.997042655944824

Epoch: [45][77/391]	LR: 2.0000000000000003e-06	Loss 0.0239 (0.0199)	Prec@1 100.000 (99.820)	
Epoch: [45][155/391]	LR: 2.0000000000000003e-06	Loss 0.0165 (0.0194)	Prec@1 100.000 (99.825)	
Epoch: [45][233/391]	LR: 2.0000000000000003e-06	Loss 0.0167 (0.0191)	Prec@1 100.000 (99.830)	
Epoch: [45][311/391]	LR: 2.0000000000000003e-06	Loss 0.0096 (0.0194)	Prec@1 100.000 (99.810)	
Epoch: [45][389/391]	LR: 2.0000000000000003e-06	Loss 0.0093 (0.0197)	Prec@1 100.000 (99.794)	
Total train loss: 0.0197

Train time: 23.723476886749268
 * Prec@1 91.050 Prec@5 99.540 Loss 0.3416
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 27.190765619277954

Epoch: [46][77/391]	LR: 2.0000000000000003e-06	Loss 0.0207 (0.0199)	Prec@1 100.000 (99.750)	
Epoch: [46][155/391]	LR: 2.0000000000000003e-06	Loss 0.0175 (0.0202)	Prec@1 100.000 (99.730)	
Epoch: [46][233/391]	LR: 2.0000000000000003e-06	Loss 0.0171 (0.0199)	Prec@1 100.000 (99.760)	
Epoch: [46][311/391]	LR: 2.0000000000000003e-06	Loss 0.0167 (0.0200)	Prec@1 100.000 (99.760)	
Epoch: [46][389/391]	LR: 2.0000000000000003e-06	Loss 0.0312 (0.0199)	Prec@1 99.219 (99.768)	
Total train loss: 0.0199

Train time: 24.784663200378418
 * Prec@1 91.270 Prec@5 99.570 Loss 0.3330
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 27.244433641433716

Epoch: [47][77/391]	LR: 2.0000000000000003e-06	Loss 0.0228 (0.0214)	Prec@1 99.219 (99.690)	
Epoch: [47][155/391]	LR: 2.0000000000000003e-06	Loss 0.0126 (0.0214)	Prec@1 100.000 (99.684)	
Epoch: [47][233/391]	LR: 2.0000000000000003e-06	Loss 0.0119 (0.0206)	Prec@1 100.000 (99.710)	
Epoch: [47][311/391]	LR: 2.0000000000000003e-06	Loss 0.0130 (0.0203)	Prec@1 100.000 (99.725)	
Epoch: [47][389/391]	LR: 2.0000000000000003e-06	Loss 0.0209 (0.0200)	Prec@1 100.000 (99.742)	
Total train loss: 0.0200

Train time: 24.328028202056885
 * Prec@1 91.160 Prec@5 99.560 Loss 0.3354
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 27.599483966827393

Epoch: [48][77/391]	LR: 2.0000000000000003e-06	Loss 0.0137 (0.0198)	Prec@1 100.000 (99.760)	
Epoch: [48][155/391]	LR: 2.0000000000000003e-06	Loss 0.0178 (0.0203)	Prec@1 100.000 (99.760)	
Epoch: [48][233/391]	LR: 2.0000000000000003e-06	Loss 0.0152 (0.0198)	Prec@1 100.000 (99.786)	
Epoch: [48][311/391]	LR: 2.0000000000000003e-06	Loss 0.0174 (0.0195)	Prec@1 100.000 (99.787)	
Epoch: [48][389/391]	LR: 2.0000000000000003e-06	Loss 0.0214 (0.0198)	Prec@1 100.000 (99.788)	
Total train loss: 0.0198

Train time: 23.614359855651855
 * Prec@1 91.250 Prec@5 99.550 Loss 0.3320
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.094831466674805

Epoch: [49][77/391]	LR: 2.0000000000000003e-06	Loss 0.0156 (0.0216)	Prec@1 100.000 (99.690)	
Epoch: [49][155/391]	LR: 2.0000000000000003e-06	Loss 0.0122 (0.0209)	Prec@1 100.000 (99.715)	
Epoch: [49][233/391]	LR: 2.0000000000000003e-06	Loss 0.0246 (0.0206)	Prec@1 100.000 (99.736)	
Epoch: [49][311/391]	LR: 2.0000000000000003e-06	Loss 0.0235 (0.0204)	Prec@1 100.000 (99.755)	
Epoch: [49][389/391]	LR: 2.0000000000000003e-06	Loss 0.0192 (0.0204)	Prec@1 100.000 (99.752)	
Total train loss: 0.0204

Train time: 24.433615922927856
 * Prec@1 91.310 Prec@5 99.570 Loss 0.3342
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 27.37956190109253

Epoch: [50][77/391]	LR: 2.0000000000000004e-07	Loss 0.0160 (0.0196)	Prec@1 100.000 (99.840)	
Epoch: [50][155/391]	LR: 2.0000000000000004e-07	Loss 0.0165 (0.0199)	Prec@1 100.000 (99.780)	
Epoch: [50][233/391]	LR: 2.0000000000000004e-07	Loss 0.0399 (0.0205)	Prec@1 98.438 (99.726)	
Epoch: [50][311/391]	LR: 2.0000000000000004e-07	Loss 0.0199 (0.0201)	Prec@1 100.000 (99.747)	
Epoch: [50][389/391]	LR: 2.0000000000000004e-07	Loss 0.0113 (0.0195)	Prec@1 100.000 (99.768)	
Total train loss: 0.0195

Train time: 26.27529215812683
 * Prec@1 91.320 Prec@5 99.520 Loss 0.3364
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 28.900116682052612

Epoch: [51][77/391]	LR: 2.0000000000000004e-07	Loss 0.0284 (0.0203)	Prec@1 99.219 (99.659)	
Epoch: [51][155/391]	LR: 2.0000000000000004e-07	Loss 0.0224 (0.0200)	Prec@1 100.000 (99.735)	
Epoch: [51][233/391]	LR: 2.0000000000000004e-07	Loss 0.0160 (0.0194)	Prec@1 100.000 (99.760)	
Epoch: [51][311/391]	LR: 2.0000000000000004e-07	Loss 0.0097 (0.0199)	Prec@1 100.000 (99.732)	
Epoch: [51][389/391]	LR: 2.0000000000000004e-07	Loss 0.0135 (0.0195)	Prec@1 100.000 (99.760)	
Total train loss: 0.0196

Train time: 24.3434841632843
 * Prec@1 91.380 Prec@5 99.560 Loss 0.3374
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 27.998359203338623

Epoch: [52][77/391]	LR: 2.0000000000000004e-07	Loss 0.0194 (0.0194)	Prec@1 100.000 (99.810)	
Epoch: [52][155/391]	LR: 2.0000000000000004e-07	Loss 0.0129 (0.0194)	Prec@1 100.000 (99.785)	
Epoch: [52][233/391]	LR: 2.0000000000000004e-07	Loss 0.0258 (0.0192)	Prec@1 99.219 (99.806)	
Epoch: [52][311/391]	LR: 2.0000000000000004e-07	Loss 0.0227 (0.0195)	Prec@1 99.219 (99.782)	
Epoch: [52][389/391]	LR: 2.0000000000000004e-07	Loss 0.0427 (0.0195)	Prec@1 98.438 (99.786)	
Total train loss: 0.0196

Train time: 24.149973392486572
 * Prec@1 91.300 Prec@5 99.580 Loss 0.3384
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.711105823516846

Epoch: [53][77/391]	LR: 2.0000000000000004e-07	Loss 0.0135 (0.0203)	Prec@1 100.000 (99.770)	
Epoch: [53][155/391]	LR: 2.0000000000000004e-07	Loss 0.0184 (0.0201)	Prec@1 100.000 (99.740)	
Epoch: [53][233/391]	LR: 2.0000000000000004e-07	Loss 0.0075 (0.0196)	Prec@1 100.000 (99.773)	
Epoch: [53][311/391]	LR: 2.0000000000000004e-07	Loss 0.0215 (0.0198)	Prec@1 100.000 (99.790)	
Epoch: [53][389/391]	LR: 2.0000000000000004e-07	Loss 0.0327 (0.0200)	Prec@1 99.219 (99.786)	
Total train loss: 0.0200

Train time: 24.80353021621704
 * Prec@1 91.420 Prec@5 99.540 Loss 0.3340
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 27.77587127685547

Epoch: [54][77/391]	LR: 2.0000000000000004e-07	Loss 0.0247 (0.0208)	Prec@1 100.000 (99.780)	
Epoch: [54][155/391]	LR: 2.0000000000000004e-07	Loss 0.0156 (0.0196)	Prec@1 100.000 (99.805)	
Epoch: [54][233/391]	LR: 2.0000000000000004e-07	Loss 0.0218 (0.0197)	Prec@1 100.000 (99.790)	
Epoch: [54][311/391]	LR: 2.0000000000000004e-07	Loss 0.0147 (0.0192)	Prec@1 100.000 (99.810)	
Epoch: [54][389/391]	LR: 2.0000000000000004e-07	Loss 0.0102 (0.0195)	Prec@1 100.000 (99.794)	
Total train loss: 0.0195

Train time: 23.246439933776855
 * Prec@1 91.220 Prec@5 99.580 Loss 0.3315
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 25.756234645843506

Epoch: [55][77/391]	LR: 2.0000000000000004e-07	Loss 0.0143 (0.0195)	Prec@1 100.000 (99.770)	
Epoch: [55][155/391]	LR: 2.0000000000000004e-07	Loss 0.0155 (0.0193)	Prec@1 100.000 (99.760)	
Epoch: [55][233/391]	LR: 2.0000000000000004e-07	Loss 0.0110 (0.0190)	Prec@1 100.000 (99.790)	
Epoch: [55][311/391]	LR: 2.0000000000000004e-07	Loss 0.0131 (0.0190)	Prec@1 100.000 (99.787)	
Epoch: [55][389/391]	LR: 2.0000000000000004e-07	Loss 0.0141 (0.0192)	Prec@1 100.000 (99.780)	
Total train loss: 0.0192

Train time: 24.338569164276123
 * Prec@1 91.320 Prec@5 99.560 Loss 0.3369
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 27.362648248672485

Epoch: [56][77/391]	LR: 2.0000000000000004e-07	Loss 0.0247 (0.0202)	Prec@1 100.000 (99.800)	
Epoch: [56][155/391]	LR: 2.0000000000000004e-07	Loss 0.0216 (0.0198)	Prec@1 99.219 (99.770)	
Epoch: [56][233/391]	LR: 2.0000000000000004e-07	Loss 0.0236 (0.0199)	Prec@1 99.219 (99.763)	
Epoch: [56][311/391]	LR: 2.0000000000000004e-07	Loss 0.0267 (0.0196)	Prec@1 100.000 (99.770)	
Epoch: [56][389/391]	LR: 2.0000000000000004e-07	Loss 0.0194 (0.0198)	Prec@1 100.000 (99.774)	
Total train loss: 0.0198

Train time: 24.250978469848633
 * Prec@1 91.330 Prec@5 99.600 Loss 0.3335
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 27.583744764328003

Epoch: [57][77/391]	LR: 2.0000000000000004e-07	Loss 0.0144 (0.0179)	Prec@1 100.000 (99.830)	
Epoch: [57][155/391]	LR: 2.0000000000000004e-07	Loss 0.0159 (0.0192)	Prec@1 100.000 (99.785)	
Epoch: [57][233/391]	LR: 2.0000000000000004e-07	Loss 0.0101 (0.0196)	Prec@1 100.000 (99.770)	
Epoch: [57][311/391]	LR: 2.0000000000000004e-07	Loss 0.0205 (0.0196)	Prec@1 99.219 (99.760)	
Epoch: [57][389/391]	LR: 2.0000000000000004e-07	Loss 0.0249 (0.0196)	Prec@1 100.000 (99.764)	
Total train loss: 0.0196

Train time: 23.279102563858032
 * Prec@1 91.360 Prec@5 99.560 Loss 0.3391
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.49908947944641

Epoch: [58][77/391]	LR: 2.0000000000000004e-07	Loss 0.0161 (0.0207)	Prec@1 100.000 (99.690)	
Epoch: [58][155/391]	LR: 2.0000000000000004e-07	Loss 0.0117 (0.0202)	Prec@1 100.000 (99.750)	
Epoch: [58][233/391]	LR: 2.0000000000000004e-07	Loss 0.0091 (0.0198)	Prec@1 100.000 (99.780)	
Epoch: [58][311/391]	LR: 2.0000000000000004e-07	Loss 0.0193 (0.0199)	Prec@1 99.219 (99.777)	
Epoch: [58][389/391]	LR: 2.0000000000000004e-07	Loss 0.0311 (0.0195)	Prec@1 100.000 (99.794)	
Total train loss: 0.0195

Train time: 23.619882345199585
 * Prec@1 91.140 Prec@5 99.570 Loss 0.3379
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 25.785487174987793

Epoch: [59][77/391]	LR: 2.0000000000000004e-07	Loss 0.0296 (0.0206)	Prec@1 99.219 (99.679)	
Epoch: [59][155/391]	LR: 2.0000000000000004e-07	Loss 0.0378 (0.0209)	Prec@1 99.219 (99.674)	
Epoch: [59][233/391]	LR: 2.0000000000000004e-07	Loss 0.0342 (0.0207)	Prec@1 99.219 (99.686)	
Epoch: [59][311/391]	LR: 2.0000000000000004e-07	Loss 0.0156 (0.0206)	Prec@1 100.000 (99.692)	
Epoch: [59][389/391]	LR: 2.0000000000000004e-07	Loss 0.0150 (0.0204)	Prec@1 100.000 (99.704)	
Total train loss: 0.0204

Train time: 22.807109355926514
 * Prec@1 91.300 Prec@5 99.570 Loss 0.3337
Best acc: 91.570
--------------------------------------------------------------------------------
Test time: 26.086698532104492


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/
          savedir: ../pretrained_models/frozen/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 60
          start_epoch: 0
          batch_size: 128
          lr: 0.002
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 7
          af_bit: 4
          w_bit: 7
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          exp: x128-8b
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 3
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 90.650 Prec@5 99.650 Loss 0.3528
Pre-trained Prec@1 with 3 layers frozen: 90.64999389648438 	 Loss: 0.352783203125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.002	Loss 0.0578 (0.0595)	Prec@1 98.438 (98.257)	
Epoch: [0][155/391]	LR: 0.002	Loss 0.0179 (0.0552)	Prec@1 100.000 (98.357)	
Epoch: [0][233/391]	LR: 0.002	Loss 0.0333 (0.0552)	Prec@1 99.219 (98.324)	
Epoch: [0][311/391]	LR: 0.002	Loss 0.0602 (0.0541)	Prec@1 96.875 (98.345)	
Epoch: [0][389/391]	LR: 0.002	Loss 0.0294 (0.0538)	Prec@1 99.219 (98.329)	
Total train loss: 0.0538

Train time: 68.93785381317139
 * Prec@1 91.190 Prec@5 99.670 Loss 0.3210
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 71.78196859359741

Epoch: [1][77/391]	LR: 0.002	Loss 0.0352 (0.0477)	Prec@1 100.000 (98.498)	
Epoch: [1][155/391]	LR: 0.002	Loss 0.0300 (0.0461)	Prec@1 100.000 (98.583)	
Epoch: [1][233/391]	LR: 0.002	Loss 0.0389 (0.0438)	Prec@1 98.438 (98.715)	
Epoch: [1][311/391]	LR: 0.002	Loss 0.0455 (0.0437)	Prec@1 99.219 (98.735)	
Epoch: [1][389/391]	LR: 0.002	Loss 0.0281 (0.0444)	Prec@1 99.219 (98.712)	
Total train loss: 0.0444

Train time: 23.037922859191895
 * Prec@1 91.240 Prec@5 99.630 Loss 0.3276
Best acc: 91.240
--------------------------------------------------------------------------------
Test time: 26.31799578666687

Epoch: [2][77/391]	LR: 0.002	Loss 0.0484 (0.0383)	Prec@1 98.438 (98.968)	
Epoch: [2][155/391]	LR: 0.002	Loss 0.0485 (0.0400)	Prec@1 97.656 (98.913)	
Epoch: [2][233/391]	LR: 0.002	Loss 0.0466 (0.0402)	Prec@1 98.438 (98.912)	
Epoch: [2][311/391]	LR: 0.002	Loss 0.0569 (0.0407)	Prec@1 97.656 (98.891)	
Epoch: [2][389/391]	LR: 0.002	Loss 0.0530 (0.0412)	Prec@1 97.656 (98.890)	
Total train loss: 0.0412

Train time: 22.34256410598755
 * Prec@1 91.180 Prec@5 99.620 Loss 0.3245
Best acc: 91.240
--------------------------------------------------------------------------------
Test time: 25.352725744247437

Epoch: [3][77/391]	LR: 0.002	Loss 0.0266 (0.0361)	Prec@1 100.000 (99.018)	
Epoch: [3][155/391]	LR: 0.002	Loss 0.0365 (0.0363)	Prec@1 99.219 (99.099)	
Epoch: [3][233/391]	LR: 0.002	Loss 0.0172 (0.0372)	Prec@1 100.000 (99.042)	
Epoch: [3][311/391]	LR: 0.002	Loss 0.0372 (0.0373)	Prec@1 99.219 (99.061)	
Epoch: [3][389/391]	LR: 0.002	Loss 0.0371 (0.0384)	Prec@1 99.219 (99.010)	
Total train loss: 0.0384

Train time: 21.647431135177612
 * Prec@1 91.270 Prec@5 99.600 Loss 0.3279
Best acc: 91.270
--------------------------------------------------------------------------------
Test time: 24.629688262939453

Epoch: [4][77/391]	LR: 0.002	Loss 0.0918 (0.0381)	Prec@1 96.875 (99.089)	
Epoch: [4][155/391]	LR: 0.002	Loss 0.0317 (0.0370)	Prec@1 99.219 (99.089)	
Epoch: [4][233/391]	LR: 0.002	Loss 0.0445 (0.0362)	Prec@1 98.438 (99.095)	
Epoch: [4][311/391]	LR: 0.002	Loss 0.0244 (0.0355)	Prec@1 100.000 (99.126)	
Epoch: [4][389/391]	LR: 0.002	Loss 0.0230 (0.0357)	Prec@1 100.000 (99.113)	
Total train loss: 0.0357

Train time: 24.1249577999115
 * Prec@1 91.160 Prec@5 99.580 Loss 0.3308
Best acc: 91.270
--------------------------------------------------------------------------------
Test time: 26.773630619049072

Epoch: [5][77/391]	LR: 0.002	Loss 0.0638 (0.0326)	Prec@1 98.438 (99.279)	
Epoch: [5][155/391]	LR: 0.002	Loss 0.0250 (0.0327)	Prec@1 99.219 (99.254)	
Epoch: [5][233/391]	LR: 0.002	Loss 0.0359 (0.0326)	Prec@1 99.219 (99.255)	
Epoch: [5][311/391]	LR: 0.002	Loss 0.0171 (0.0335)	Prec@1 99.219 (99.241)	
Epoch: [5][389/391]	LR: 0.002	Loss 0.0385 (0.0337)	Prec@1 99.219 (99.221)	
Total train loss: 0.0337

Train time: 22.39767098426819
 * Prec@1 91.110 Prec@5 99.560 Loss 0.3313
Best acc: 91.270
--------------------------------------------------------------------------------
Test time: 25.39857029914856

Epoch: [6][77/391]	LR: 0.002	Loss 0.0372 (0.0291)	Prec@1 99.219 (99.409)	
Epoch: [6][155/391]	LR: 0.002	Loss 0.0347 (0.0302)	Prec@1 99.219 (99.384)	
Epoch: [6][233/391]	LR: 0.002	Loss 0.0397 (0.0310)	Prec@1 98.438 (99.336)	
Epoch: [6][311/391]	LR: 0.002	Loss 0.0306 (0.0314)	Prec@1 100.000 (99.311)	
Epoch: [6][389/391]	LR: 0.002	Loss 0.0147 (0.0318)	Prec@1 100.000 (99.297)	
Total train loss: 0.0318

Train time: 21.97768211364746
 * Prec@1 91.100 Prec@5 99.560 Loss 0.3394
Best acc: 91.270
--------------------------------------------------------------------------------
Test time: 24.333828926086426

Epoch: [7][77/391]	LR: 0.002	Loss 0.0183 (0.0286)	Prec@1 100.000 (99.359)	
Epoch: [7][155/391]	LR: 0.002	Loss 0.0333 (0.0294)	Prec@1 98.438 (99.364)	
Epoch: [7][233/391]	LR: 0.002	Loss 0.0486 (0.0292)	Prec@1 99.219 (99.389)	
Epoch: [7][311/391]	LR: 0.002	Loss 0.0161 (0.0293)	Prec@1 100.000 (99.394)	
Epoch: [7][389/391]	LR: 0.002	Loss 0.0539 (0.0298)	Prec@1 98.438 (99.383)	
Total train loss: 0.0298

Train time: 21.612051725387573
 * Prec@1 91.230 Prec@5 99.550 Loss 0.3325
Best acc: 91.270
--------------------------------------------------------------------------------
Test time: 25.218719482421875

Epoch: [8][77/391]	LR: 0.002	Loss 0.0131 (0.0254)	Prec@1 100.000 (99.559)	
Epoch: [8][155/391]	LR: 0.002	Loss 0.0135 (0.0266)	Prec@1 100.000 (99.514)	
Epoch: [8][233/391]	LR: 0.002	Loss 0.0370 (0.0286)	Prec@1 99.219 (99.452)	
Epoch: [8][311/391]	LR: 0.002	Loss 0.0157 (0.0292)	Prec@1 100.000 (99.442)	
Epoch: [8][389/391]	LR: 0.002	Loss 0.0225 (0.0295)	Prec@1 100.000 (99.429)	
Total train loss: 0.0295

Train time: 21.701006650924683
 * Prec@1 91.220 Prec@5 99.630 Loss 0.3320
Best acc: 91.270
--------------------------------------------------------------------------------
Test time: 23.95631504058838

Epoch: [9][77/391]	LR: 0.002	Loss 0.0211 (0.0265)	Prec@1 100.000 (99.549)	
Epoch: [9][155/391]	LR: 0.002	Loss 0.0389 (0.0269)	Prec@1 98.438 (99.474)	
Epoch: [9][233/391]	LR: 0.002	Loss 0.0213 (0.0267)	Prec@1 99.219 (99.516)	
Epoch: [9][311/391]	LR: 0.002	Loss 0.0222 (0.0271)	Prec@1 99.219 (99.512)	
Epoch: [9][389/391]	LR: 0.002	Loss 0.0309 (0.0277)	Prec@1 99.219 (99.485)	
Total train loss: 0.0277

Train time: 20.545305252075195
 * Prec@1 91.290 Prec@5 99.570 Loss 0.3345
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 22.946746110916138

Epoch: [10][77/391]	LR: 0.002	Loss 0.0355 (0.0254)	Prec@1 99.219 (99.579)	
Epoch: [10][155/391]	LR: 0.002	Loss 0.0218 (0.0255)	Prec@1 100.000 (99.599)	
Epoch: [10][233/391]	LR: 0.002	Loss 0.0386 (0.0267)	Prec@1 99.219 (99.526)	
Epoch: [10][311/391]	LR: 0.002	Loss 0.0341 (0.0270)	Prec@1 99.219 (99.524)	
Epoch: [10][389/391]	LR: 0.002	Loss 0.0184 (0.0271)	Prec@1 100.000 (99.533)	
Total train loss: 0.0271

Train time: 21.469377994537354
 * Prec@1 91.150 Prec@5 99.580 Loss 0.3401
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.47900390625

Epoch: [11][77/391]	LR: 0.002	Loss 0.0284 (0.0266)	Prec@1 99.219 (99.529)	
Epoch: [11][155/391]	LR: 0.002	Loss 0.0443 (0.0255)	Prec@1 98.438 (99.559)	
Epoch: [11][233/391]	LR: 0.002	Loss 0.0195 (0.0254)	Prec@1 100.000 (99.583)	
Epoch: [11][311/391]	LR: 0.002	Loss 0.0195 (0.0258)	Prec@1 100.000 (99.557)	
Epoch: [11][389/391]	LR: 0.002	Loss 0.0129 (0.0264)	Prec@1 100.000 (99.537)	
Total train loss: 0.0264

Train time: 22.35935354232788
 * Prec@1 91.260 Prec@5 99.570 Loss 0.3345
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.37341570854187

Epoch: [12][77/391]	LR: 0.002	Loss 0.0151 (0.0246)	Prec@1 100.000 (99.589)	
Epoch: [12][155/391]	LR: 0.002	Loss 0.0254 (0.0254)	Prec@1 100.000 (99.574)	
Epoch: [12][233/391]	LR: 0.002	Loss 0.0246 (0.0252)	Prec@1 100.000 (99.606)	
Epoch: [12][311/391]	LR: 0.002	Loss 0.0153 (0.0252)	Prec@1 100.000 (99.612)	
Epoch: [12][389/391]	LR: 0.002	Loss 0.0617 (0.0252)	Prec@1 98.438 (99.605)	
Total train loss: 0.0252

Train time: 21.75543475151062
 * Prec@1 91.120 Prec@5 99.650 Loss 0.3435
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.983533143997192

Epoch: [13][77/391]	LR: 0.002	Loss 0.0334 (0.0225)	Prec@1 99.219 (99.669)	
Epoch: [13][155/391]	LR: 0.002	Loss 0.0210 (0.0235)	Prec@1 100.000 (99.649)	
Epoch: [13][233/391]	LR: 0.002	Loss 0.0348 (0.0243)	Prec@1 100.000 (99.633)	
Epoch: [13][311/391]	LR: 0.002	Loss 0.0217 (0.0245)	Prec@1 100.000 (99.609)	
Epoch: [13][389/391]	LR: 0.002	Loss 0.0267 (0.0245)	Prec@1 100.000 (99.621)	
Total train loss: 0.0246

Train time: 21.9423770904541
 * Prec@1 91.080 Prec@5 99.580 Loss 0.3413
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.40432834625244

Epoch: [14][77/391]	LR: 0.002	Loss 0.0370 (0.0244)	Prec@1 99.219 (99.639)	
Epoch: [14][155/391]	LR: 0.002	Loss 0.0132 (0.0237)	Prec@1 100.000 (99.659)	
Epoch: [14][233/391]	LR: 0.002	Loss 0.0122 (0.0242)	Prec@1 100.000 (99.629)	
Epoch: [14][311/391]	LR: 0.002	Loss 0.0216 (0.0239)	Prec@1 100.000 (99.632)	
Epoch: [14][389/391]	LR: 0.002	Loss 0.0217 (0.0240)	Prec@1 100.000 (99.645)	
Total train loss: 0.0241

Train time: 21.14153242111206
 * Prec@1 90.990 Prec@5 99.600 Loss 0.3423
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 23.454526662826538

Epoch: [15][77/391]	LR: 0.002	Loss 0.0103 (0.0238)	Prec@1 100.000 (99.579)	
Epoch: [15][155/391]	LR: 0.002	Loss 0.0209 (0.0248)	Prec@1 100.000 (99.589)	
Epoch: [15][233/391]	LR: 0.002	Loss 0.0361 (0.0237)	Prec@1 99.219 (99.609)	
Epoch: [15][311/391]	LR: 0.002	Loss 0.0240 (0.0237)	Prec@1 100.000 (99.622)	
Epoch: [15][389/391]	LR: 0.002	Loss 0.0216 (0.0236)	Prec@1 100.000 (99.635)	
Total train loss: 0.0237

Train time: 21.32192373275757
 * Prec@1 90.950 Prec@5 99.610 Loss 0.3484
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.158388137817383

Epoch: [16][77/391]	LR: 0.002	Loss 0.0170 (0.0226)	Prec@1 100.000 (99.639)	
Epoch: [16][155/391]	LR: 0.002	Loss 0.0245 (0.0230)	Prec@1 98.438 (99.649)	
Epoch: [16][233/391]	LR: 0.002	Loss 0.0251 (0.0226)	Prec@1 100.000 (99.686)	
Epoch: [16][311/391]	LR: 0.002	Loss 0.0454 (0.0225)	Prec@1 98.438 (99.677)	
Epoch: [16][389/391]	LR: 0.002	Loss 0.0283 (0.0226)	Prec@1 99.219 (99.667)	
Total train loss: 0.0227

Train time: 21.822814226150513
 * Prec@1 91.130 Prec@5 99.600 Loss 0.3411
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.842883110046387

Epoch: [17][77/391]	LR: 0.002	Loss 0.0152 (0.0247)	Prec@1 100.000 (99.579)	
Epoch: [17][155/391]	LR: 0.002	Loss 0.0293 (0.0232)	Prec@1 100.000 (99.619)	
Epoch: [17][233/391]	LR: 0.002	Loss 0.0095 (0.0226)	Prec@1 100.000 (99.646)	
Epoch: [17][311/391]	LR: 0.002	Loss 0.0490 (0.0231)	Prec@1 99.219 (99.634)	
Epoch: [17][389/391]	LR: 0.002	Loss 0.0354 (0.0230)	Prec@1 99.219 (99.641)	
Total train loss: 0.0230

Train time: 21.790955066680908
 * Prec@1 91.110 Prec@5 99.610 Loss 0.3384
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.04997491836548

Epoch: [18][77/391]	LR: 0.002	Loss 0.0121 (0.0226)	Prec@1 100.000 (99.700)	
Epoch: [18][155/391]	LR: 0.002	Loss 0.0287 (0.0228)	Prec@1 100.000 (99.695)	
Epoch: [18][233/391]	LR: 0.002	Loss 0.0211 (0.0234)	Prec@1 100.000 (99.666)	
Epoch: [18][311/391]	LR: 0.002	Loss 0.0378 (0.0227)	Prec@1 99.219 (99.679)	
Epoch: [18][389/391]	LR: 0.002	Loss 0.0147 (0.0227)	Prec@1 100.000 (99.675)	
Total train loss: 0.0227

Train time: 19.804521560668945
 * Prec@1 91.160 Prec@5 99.580 Loss 0.3435
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 21.741496086120605

Epoch: [19][77/391]	LR: 0.002	Loss 0.0161 (0.0209)	Prec@1 100.000 (99.750)	
Epoch: [19][155/391]	LR: 0.002	Loss 0.0144 (0.0214)	Prec@1 100.000 (99.705)	
Epoch: [19][233/391]	LR: 0.002	Loss 0.0421 (0.0213)	Prec@1 98.438 (99.716)	
Epoch: [19][311/391]	LR: 0.002	Loss 0.0207 (0.0209)	Prec@1 100.000 (99.742)	
Epoch: [19][389/391]	LR: 0.002	Loss 0.0353 (0.0209)	Prec@1 100.000 (99.746)	
Total train loss: 0.0209

Train time: 19.286264419555664
 * Prec@1 90.950 Prec@5 99.600 Loss 0.3442
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 22.206624031066895

Epoch: [20][77/391]	LR: 0.0002	Loss 0.0083 (0.0225)	Prec@1 100.000 (99.679)	
Epoch: [20][155/391]	LR: 0.0002	Loss 0.0166 (0.0216)	Prec@1 100.000 (99.730)	
Epoch: [20][233/391]	LR: 0.0002	Loss 0.0197 (0.0208)	Prec@1 100.000 (99.733)	
Epoch: [20][311/391]	LR: 0.0002	Loss 0.0184 (0.0209)	Prec@1 100.000 (99.722)	
Epoch: [20][389/391]	LR: 0.0002	Loss 0.0251 (0.0209)	Prec@1 99.219 (99.724)	
Total train loss: 0.0208

Train time: 19.235495805740356
 * Prec@1 91.160 Prec@5 99.590 Loss 0.3413
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 21.897722959518433

Epoch: [21][77/391]	LR: 0.0002	Loss 0.0205 (0.0213)	Prec@1 100.000 (99.720)	
Epoch: [21][155/391]	LR: 0.0002	Loss 0.0193 (0.0214)	Prec@1 100.000 (99.710)	
Epoch: [21][233/391]	LR: 0.0002	Loss 0.0224 (0.0204)	Prec@1 100.000 (99.733)	
Epoch: [21][311/391]	LR: 0.0002	Loss 0.0274 (0.0212)	Prec@1 100.000 (99.717)	
Epoch: [21][389/391]	LR: 0.0002	Loss 0.0399 (0.0211)	Prec@1 99.219 (99.730)	
Total train loss: 0.0211

Train time: 19.62135887145996
 * Prec@1 91.240 Prec@5 99.590 Loss 0.3459
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 23.450196743011475

Epoch: [22][77/391]	LR: 0.0002	Loss 0.0188 (0.0187)	Prec@1 100.000 (99.870)	
Epoch: [22][155/391]	LR: 0.0002	Loss 0.0313 (0.0199)	Prec@1 99.219 (99.810)	
Epoch: [22][233/391]	LR: 0.0002	Loss 0.0159 (0.0205)	Prec@1 100.000 (99.776)	
Epoch: [22][311/391]	LR: 0.0002	Loss 0.0202 (0.0207)	Prec@1 100.000 (99.765)	
Epoch: [22][389/391]	LR: 0.0002	Loss 0.0251 (0.0205)	Prec@1 100.000 (99.770)	
Total train loss: 0.0206

Train time: 18.499120950698853
 * Prec@1 91.090 Prec@5 99.580 Loss 0.3423
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 21.165066719055176

Epoch: [23][77/391]	LR: 0.0002	Loss 0.0212 (0.0200)	Prec@1 100.000 (99.700)	
Epoch: [23][155/391]	LR: 0.0002	Loss 0.0262 (0.0206)	Prec@1 99.219 (99.690)	
Epoch: [23][233/391]	LR: 0.0002	Loss 0.0209 (0.0200)	Prec@1 100.000 (99.733)	
Epoch: [23][311/391]	LR: 0.0002	Loss 0.0501 (0.0202)	Prec@1 98.438 (99.722)	
Epoch: [23][389/391]	LR: 0.0002	Loss 0.0300 (0.0200)	Prec@1 99.219 (99.748)	
Total train loss: 0.0201

Train time: 25.28827142715454
 * Prec@1 91.150 Prec@5 99.600 Loss 0.3423
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 27.26769518852234

Epoch: [24][77/391]	LR: 0.0002	Loss 0.0324 (0.0195)	Prec@1 99.219 (99.820)	
Epoch: [24][155/391]	LR: 0.0002	Loss 0.0243 (0.0210)	Prec@1 100.000 (99.735)	
Epoch: [24][233/391]	LR: 0.0002	Loss 0.0220 (0.0214)	Prec@1 100.000 (99.686)	
Epoch: [24][311/391]	LR: 0.0002	Loss 0.0198 (0.0210)	Prec@1 100.000 (99.730)	
Epoch: [24][389/391]	LR: 0.0002	Loss 0.0242 (0.0206)	Prec@1 100.000 (99.744)	
Total train loss: 0.0207

Train time: 21.34988522529602
 * Prec@1 91.110 Prec@5 99.570 Loss 0.3442
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.085617542266846

Epoch: [25][77/391]	LR: 0.0002	Loss 0.0352 (0.0211)	Prec@1 100.000 (99.720)	
Epoch: [25][155/391]	LR: 0.0002	Loss 0.0156 (0.0209)	Prec@1 100.000 (99.745)	
Epoch: [25][233/391]	LR: 0.0002	Loss 0.0175 (0.0209)	Prec@1 100.000 (99.760)	
Epoch: [25][311/391]	LR: 0.0002	Loss 0.0139 (0.0213)	Prec@1 100.000 (99.737)	
Epoch: [25][389/391]	LR: 0.0002	Loss 0.0180 (0.0208)	Prec@1 100.000 (99.750)	
Total train loss: 0.0209

Train time: 21.458528995513916
 * Prec@1 90.970 Prec@5 99.620 Loss 0.3450
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 23.97750949859619

Epoch: [26][77/391]	LR: 0.0002	Loss 0.0114 (0.0199)	Prec@1 100.000 (99.770)	
Epoch: [26][155/391]	LR: 0.0002	Loss 0.0202 (0.0203)	Prec@1 99.219 (99.750)	
Epoch: [26][233/391]	LR: 0.0002	Loss 0.0272 (0.0203)	Prec@1 97.656 (99.736)	
Epoch: [26][311/391]	LR: 0.0002	Loss 0.0121 (0.0203)	Prec@1 100.000 (99.725)	
Epoch: [26][389/391]	LR: 0.0002	Loss 0.0365 (0.0206)	Prec@1 98.438 (99.732)	
Total train loss: 0.0205

Train time: 20.897587776184082
 * Prec@1 91.170 Prec@5 99.590 Loss 0.3381
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 23.335878610610962

Epoch: [27][77/391]	LR: 0.0002	Loss 0.0122 (0.0207)	Prec@1 100.000 (99.740)	
Epoch: [27][155/391]	LR: 0.0002	Loss 0.0124 (0.0199)	Prec@1 100.000 (99.800)	
Epoch: [27][233/391]	LR: 0.0002	Loss 0.0213 (0.0200)	Prec@1 100.000 (99.783)	
Epoch: [27][311/391]	LR: 0.0002	Loss 0.0194 (0.0201)	Prec@1 99.219 (99.785)	
Epoch: [27][389/391]	LR: 0.0002	Loss 0.0277 (0.0199)	Prec@1 99.219 (99.790)	
Total train loss: 0.0199

Train time: 20.182133197784424
 * Prec@1 91.220 Prec@5 99.540 Loss 0.3435
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 22.942997932434082

Epoch: [28][77/391]	LR: 0.0002	Loss 0.0270 (0.0200)	Prec@1 100.000 (99.750)	
Epoch: [28][155/391]	LR: 0.0002	Loss 0.0427 (0.0203)	Prec@1 98.438 (99.755)	
Epoch: [28][233/391]	LR: 0.0002	Loss 0.0470 (0.0203)	Prec@1 99.219 (99.756)	
Epoch: [28][311/391]	LR: 0.0002	Loss 0.0196 (0.0203)	Prec@1 100.000 (99.772)	
Epoch: [28][389/391]	LR: 0.0002	Loss 0.0196 (0.0202)	Prec@1 100.000 (99.780)	
Total train loss: 0.0202

Train time: 21.69932508468628
 * Prec@1 91.160 Prec@5 99.610 Loss 0.3420
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.33408784866333

Epoch: [29][77/391]	LR: 0.0002	Loss 0.0317 (0.0199)	Prec@1 100.000 (99.830)	
Epoch: [29][155/391]	LR: 0.0002	Loss 0.0125 (0.0201)	Prec@1 100.000 (99.770)	
Epoch: [29][233/391]	LR: 0.0002	Loss 0.0272 (0.0204)	Prec@1 100.000 (99.753)	
Epoch: [29][311/391]	LR: 0.0002	Loss 0.0213 (0.0207)	Prec@1 100.000 (99.730)	
Epoch: [29][389/391]	LR: 0.0002	Loss 0.0262 (0.0211)	Prec@1 100.000 (99.716)	
Total train loss: 0.0211

Train time: 21.548829078674316
 * Prec@1 91.180 Prec@5 99.610 Loss 0.3413
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.288496494293213

Epoch: [30][77/391]	LR: 2e-05	Loss 0.0170 (0.0209)	Prec@1 100.000 (99.760)	
Epoch: [30][155/391]	LR: 2e-05	Loss 0.0105 (0.0208)	Prec@1 100.000 (99.755)	
Epoch: [30][233/391]	LR: 2e-05	Loss 0.0194 (0.0204)	Prec@1 100.000 (99.770)	
Epoch: [30][311/391]	LR: 2e-05	Loss 0.0127 (0.0205)	Prec@1 100.000 (99.747)	
Epoch: [30][389/391]	LR: 2e-05	Loss 0.0119 (0.0207)	Prec@1 100.000 (99.752)	
Total train loss: 0.0206

Train time: 21.211904287338257
 * Prec@1 91.140 Prec@5 99.620 Loss 0.3425
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 23.777599334716797

Epoch: [31][77/391]	LR: 2e-05	Loss 0.0130 (0.0202)	Prec@1 100.000 (99.810)	
Epoch: [31][155/391]	LR: 2e-05	Loss 0.0226 (0.0206)	Prec@1 100.000 (99.760)	
Epoch: [31][233/391]	LR: 2e-05	Loss 0.0199 (0.0208)	Prec@1 100.000 (99.743)	
Epoch: [31][311/391]	LR: 2e-05	Loss 0.0132 (0.0210)	Prec@1 100.000 (99.730)	
Epoch: [31][389/391]	LR: 2e-05	Loss 0.0158 (0.0208)	Prec@1 100.000 (99.742)	
Total train loss: 0.0208

Train time: 20.76207733154297
 * Prec@1 91.030 Prec@5 99.590 Loss 0.3445
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 23.281917095184326

Epoch: [32][77/391]	LR: 2e-05	Loss 0.0190 (0.0214)	Prec@1 100.000 (99.760)	
Epoch: [32][155/391]	LR: 2e-05	Loss 0.0338 (0.0212)	Prec@1 100.000 (99.795)	
Epoch: [32][233/391]	LR: 2e-05	Loss 0.0138 (0.0210)	Prec@1 100.000 (99.770)	
Epoch: [32][311/391]	LR: 2e-05	Loss 0.0111 (0.0205)	Prec@1 100.000 (99.780)	
Epoch: [32][389/391]	LR: 2e-05	Loss 0.0149 (0.0204)	Prec@1 100.000 (99.768)	
Total train loss: 0.0204

Train time: 20.895589351654053
 * Prec@1 91.070 Prec@5 99.620 Loss 0.3435
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 23.42827296257019

Epoch: [33][77/391]	LR: 2e-05	Loss 0.0097 (0.0195)	Prec@1 100.000 (99.800)	
Epoch: [33][155/391]	LR: 2e-05	Loss 0.0224 (0.0192)	Prec@1 100.000 (99.805)	
Epoch: [33][233/391]	LR: 2e-05	Loss 0.0272 (0.0197)	Prec@1 100.000 (99.790)	
Epoch: [33][311/391]	LR: 2e-05	Loss 0.0131 (0.0202)	Prec@1 100.000 (99.750)	
Epoch: [33][389/391]	LR: 2e-05	Loss 0.0140 (0.0204)	Prec@1 100.000 (99.750)	
Total train loss: 0.0204

Train time: 21.574172019958496
 * Prec@1 91.010 Prec@5 99.630 Loss 0.3430
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.104639530181885

Epoch: [34][77/391]	LR: 2e-05	Loss 0.0107 (0.0196)	Prec@1 100.000 (99.850)	
Epoch: [34][155/391]	LR: 2e-05	Loss 0.0165 (0.0200)	Prec@1 100.000 (99.810)	
Epoch: [34][233/391]	LR: 2e-05	Loss 0.0310 (0.0202)	Prec@1 100.000 (99.820)	
Epoch: [34][311/391]	LR: 2e-05	Loss 0.0157 (0.0196)	Prec@1 99.219 (99.835)	
Epoch: [34][389/391]	LR: 2e-05	Loss 0.0178 (0.0201)	Prec@1 100.000 (99.802)	
Total train loss: 0.0201

Train time: 21.335585594177246
 * Prec@1 91.140 Prec@5 99.610 Loss 0.3425
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 23.93760895729065

Epoch: [35][77/391]	LR: 2e-05	Loss 0.0098 (0.0210)	Prec@1 100.000 (99.770)	
Epoch: [35][155/391]	LR: 2e-05	Loss 0.0191 (0.0203)	Prec@1 99.219 (99.775)	
Epoch: [35][233/391]	LR: 2e-05	Loss 0.0179 (0.0201)	Prec@1 100.000 (99.770)	
Epoch: [35][311/391]	LR: 2e-05	Loss 0.0277 (0.0202)	Prec@1 100.000 (99.767)	
Epoch: [35][389/391]	LR: 2e-05	Loss 0.0142 (0.0201)	Prec@1 100.000 (99.762)	
Total train loss: 0.0200

Train time: 20.943522453308105
 * Prec@1 91.030 Prec@5 99.620 Loss 0.3423
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 23.280455827713013

Epoch: [36][77/391]	LR: 2e-05	Loss 0.0231 (0.0210)	Prec@1 99.219 (99.700)	
Epoch: [36][155/391]	LR: 2e-05	Loss 0.0261 (0.0210)	Prec@1 100.000 (99.695)	
Epoch: [36][233/391]	LR: 2e-05	Loss 0.0262 (0.0209)	Prec@1 100.000 (99.726)	
Epoch: [36][311/391]	LR: 2e-05	Loss 0.0134 (0.0210)	Prec@1 100.000 (99.727)	
Epoch: [36][389/391]	LR: 2e-05	Loss 0.0212 (0.0208)	Prec@1 99.219 (99.734)	
Total train loss: 0.0208

Train time: 21.518606901168823
 * Prec@1 91.110 Prec@5 99.600 Loss 0.3440
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.087913751602173

Epoch: [37][77/391]	LR: 2e-05	Loss 0.0273 (0.0208)	Prec@1 100.000 (99.710)	
Epoch: [37][155/391]	LR: 2e-05	Loss 0.0203 (0.0197)	Prec@1 99.219 (99.775)	
Epoch: [37][233/391]	LR: 2e-05	Loss 0.0174 (0.0206)	Prec@1 100.000 (99.753)	
Epoch: [37][311/391]	LR: 2e-05	Loss 0.0223 (0.0204)	Prec@1 99.219 (99.747)	
Epoch: [37][389/391]	LR: 2e-05	Loss 0.0307 (0.0204)	Prec@1 99.219 (99.754)	
Total train loss: 0.0205

Train time: 21.2316951751709
 * Prec@1 91.050 Prec@5 99.640 Loss 0.3423
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.241122484207153

Epoch: [38][77/391]	LR: 2e-05	Loss 0.0691 (0.0203)	Prec@1 98.438 (99.820)	
Epoch: [38][155/391]	LR: 2e-05	Loss 0.0399 (0.0202)	Prec@1 98.438 (99.795)	
Epoch: [38][233/391]	LR: 2e-05	Loss 0.0106 (0.0214)	Prec@1 100.000 (99.743)	
Epoch: [38][311/391]	LR: 2e-05	Loss 0.0176 (0.0214)	Prec@1 99.219 (99.732)	
Epoch: [38][389/391]	LR: 2e-05	Loss 0.0167 (0.0214)	Prec@1 100.000 (99.728)	
Total train loss: 0.0215

Train time: 21.928430557250977
 * Prec@1 91.140 Prec@5 99.610 Loss 0.3396
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.33971405029297

Epoch: [39][77/391]	LR: 2e-05	Loss 0.0183 (0.0212)	Prec@1 100.000 (99.690)	
Epoch: [39][155/391]	LR: 2e-05	Loss 0.0239 (0.0201)	Prec@1 99.219 (99.760)	
Epoch: [39][233/391]	LR: 2e-05	Loss 0.0198 (0.0201)	Prec@1 100.000 (99.770)	
Epoch: [39][311/391]	LR: 2e-05	Loss 0.0232 (0.0202)	Prec@1 100.000 (99.765)	
Epoch: [39][389/391]	LR: 2e-05	Loss 0.0205 (0.0201)	Prec@1 100.000 (99.760)	
Total train loss: 0.0202

Train time: 22.540252208709717
 * Prec@1 91.110 Prec@5 99.630 Loss 0.3413
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 25.13590431213379

Epoch: [40][77/391]	LR: 2.0000000000000003e-06	Loss 0.0150 (0.0187)	Prec@1 100.000 (99.840)	
Epoch: [40][155/391]	LR: 2.0000000000000003e-06	Loss 0.0110 (0.0192)	Prec@1 100.000 (99.810)	
Epoch: [40][233/391]	LR: 2.0000000000000003e-06	Loss 0.0160 (0.0193)	Prec@1 100.000 (99.793)	
Epoch: [40][311/391]	LR: 2.0000000000000003e-06	Loss 0.0117 (0.0192)	Prec@1 100.000 (99.795)	
Epoch: [40][389/391]	LR: 2.0000000000000003e-06	Loss 0.0122 (0.0194)	Prec@1 100.000 (99.782)	
Total train loss: 0.0194

Train time: 22.229172229766846
 * Prec@1 91.180 Prec@5 99.550 Loss 0.3425
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 25.036587238311768

Epoch: [41][77/391]	LR: 2.0000000000000003e-06	Loss 0.0179 (0.0201)	Prec@1 99.219 (99.780)	
Epoch: [41][155/391]	LR: 2.0000000000000003e-06	Loss 0.0148 (0.0202)	Prec@1 100.000 (99.785)	
Epoch: [41][233/391]	LR: 2.0000000000000003e-06	Loss 0.0197 (0.0204)	Prec@1 100.000 (99.750)	
Epoch: [41][311/391]	LR: 2.0000000000000003e-06	Loss 0.0106 (0.0199)	Prec@1 100.000 (99.747)	
Epoch: [41][389/391]	LR: 2.0000000000000003e-06	Loss 0.0291 (0.0203)	Prec@1 100.000 (99.748)	
Total train loss: 0.0204

Train time: 25.891868591308594
 * Prec@1 91.160 Prec@5 99.580 Loss 0.3455
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 28.682480335235596

Epoch: [42][77/391]	LR: 2.0000000000000003e-06	Loss 0.0095 (0.0208)	Prec@1 100.000 (99.750)	
Epoch: [42][155/391]	LR: 2.0000000000000003e-06	Loss 0.0165 (0.0211)	Prec@1 100.000 (99.745)	
Epoch: [42][233/391]	LR: 2.0000000000000003e-06	Loss 0.0120 (0.0208)	Prec@1 100.000 (99.773)	
Epoch: [42][311/391]	LR: 2.0000000000000003e-06	Loss 0.0198 (0.0210)	Prec@1 100.000 (99.750)	
Epoch: [42][389/391]	LR: 2.0000000000000003e-06	Loss 0.0383 (0.0207)	Prec@1 99.219 (99.748)	
Total train loss: 0.0207

Train time: 20.33436131477356
 * Prec@1 91.070 Prec@5 99.610 Loss 0.3452
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 23.05404543876648

Epoch: [43][77/391]	LR: 2.0000000000000003e-06	Loss 0.0548 (0.0220)	Prec@1 98.438 (99.730)	
Epoch: [43][155/391]	LR: 2.0000000000000003e-06	Loss 0.0195 (0.0210)	Prec@1 100.000 (99.760)	
Epoch: [43][233/391]	LR: 2.0000000000000003e-06	Loss 0.0267 (0.0208)	Prec@1 99.219 (99.746)	
Epoch: [43][311/391]	LR: 2.0000000000000003e-06	Loss 0.0103 (0.0205)	Prec@1 100.000 (99.755)	
Epoch: [43][389/391]	LR: 2.0000000000000003e-06	Loss 0.0515 (0.0206)	Prec@1 99.219 (99.752)	
Total train loss: 0.0207

Train time: 21.513756275177002
 * Prec@1 90.990 Prec@5 99.610 Loss 0.3423
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 23.81623148918152

Epoch: [44][77/391]	LR: 2.0000000000000003e-06	Loss 0.0280 (0.0207)	Prec@1 99.219 (99.750)	
Epoch: [44][155/391]	LR: 2.0000000000000003e-06	Loss 0.0185 (0.0193)	Prec@1 100.000 (99.780)	
Epoch: [44][233/391]	LR: 2.0000000000000003e-06	Loss 0.0307 (0.0196)	Prec@1 99.219 (99.773)	
Epoch: [44][311/391]	LR: 2.0000000000000003e-06	Loss 0.0110 (0.0197)	Prec@1 100.000 (99.777)	
Epoch: [44][389/391]	LR: 2.0000000000000003e-06	Loss 0.0120 (0.0202)	Prec@1 100.000 (99.774)	
Total train loss: 0.0202

Train time: 21.38395357131958
 * Prec@1 91.120 Prec@5 99.610 Loss 0.3394
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.069328784942627

Epoch: [45][77/391]	LR: 2.0000000000000003e-06	Loss 0.0188 (0.0190)	Prec@1 100.000 (99.800)	
Epoch: [45][155/391]	LR: 2.0000000000000003e-06	Loss 0.0259 (0.0203)	Prec@1 100.000 (99.745)	
Epoch: [45][233/391]	LR: 2.0000000000000003e-06	Loss 0.0307 (0.0209)	Prec@1 99.219 (99.746)	
Epoch: [45][311/391]	LR: 2.0000000000000003e-06	Loss 0.0217 (0.0207)	Prec@1 100.000 (99.757)	
Epoch: [45][389/391]	LR: 2.0000000000000003e-06	Loss 0.0363 (0.0209)	Prec@1 99.219 (99.758)	
Total train loss: 0.0208

Train time: 21.424907445907593
 * Prec@1 91.170 Prec@5 99.630 Loss 0.3411
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.133068323135376

Epoch: [46][77/391]	LR: 2.0000000000000003e-06	Loss 0.0236 (0.0231)	Prec@1 100.000 (99.639)	
Epoch: [46][155/391]	LR: 2.0000000000000003e-06	Loss 0.0250 (0.0215)	Prec@1 100.000 (99.664)	
Epoch: [46][233/391]	LR: 2.0000000000000003e-06	Loss 0.0224 (0.0212)	Prec@1 100.000 (99.686)	
Epoch: [46][311/391]	LR: 2.0000000000000003e-06	Loss 0.0238 (0.0210)	Prec@1 100.000 (99.712)	
Epoch: [46][389/391]	LR: 2.0000000000000003e-06	Loss 0.0264 (0.0207)	Prec@1 99.219 (99.728)	
Total train loss: 0.0207

Train time: 21.833081007003784
 * Prec@1 91.220 Prec@5 99.580 Loss 0.3391
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.608508110046387

Epoch: [47][77/391]	LR: 2.0000000000000003e-06	Loss 0.0090 (0.0215)	Prec@1 100.000 (99.669)	
Epoch: [47][155/391]	LR: 2.0000000000000003e-06	Loss 0.0147 (0.0201)	Prec@1 100.000 (99.735)	
Epoch: [47][233/391]	LR: 2.0000000000000003e-06	Loss 0.0216 (0.0202)	Prec@1 99.219 (99.743)	
Epoch: [47][311/391]	LR: 2.0000000000000003e-06	Loss 0.0131 (0.0202)	Prec@1 100.000 (99.750)	
Epoch: [47][389/391]	LR: 2.0000000000000003e-06	Loss 0.0085 (0.0199)	Prec@1 100.000 (99.772)	
Total train loss: 0.0199

Train time: 21.260067462921143
 * Prec@1 91.110 Prec@5 99.570 Loss 0.3428
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.084235429763794

Epoch: [48][77/391]	LR: 2.0000000000000003e-06	Loss 0.0146 (0.0192)	Prec@1 100.000 (99.760)	
Epoch: [48][155/391]	LR: 2.0000000000000003e-06	Loss 0.0127 (0.0202)	Prec@1 100.000 (99.765)	
Epoch: [48][233/391]	LR: 2.0000000000000003e-06	Loss 0.0115 (0.0204)	Prec@1 100.000 (99.766)	
Epoch: [48][311/391]	LR: 2.0000000000000003e-06	Loss 0.0184 (0.0202)	Prec@1 100.000 (99.787)	
Epoch: [48][389/391]	LR: 2.0000000000000003e-06	Loss 0.0195 (0.0203)	Prec@1 99.219 (99.770)	
Total train loss: 0.0203

Train time: 22.010951280593872
 * Prec@1 91.100 Prec@5 99.600 Loss 0.3447
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.714134693145752

Epoch: [49][77/391]	LR: 2.0000000000000003e-06	Loss 0.0343 (0.0193)	Prec@1 99.219 (99.760)	
Epoch: [49][155/391]	LR: 2.0000000000000003e-06	Loss 0.0169 (0.0194)	Prec@1 100.000 (99.820)	
Epoch: [49][233/391]	LR: 2.0000000000000003e-06	Loss 0.0181 (0.0196)	Prec@1 100.000 (99.810)	
Epoch: [49][311/391]	LR: 2.0000000000000003e-06	Loss 0.0160 (0.0198)	Prec@1 100.000 (99.800)	
Epoch: [49][389/391]	LR: 2.0000000000000003e-06	Loss 0.0154 (0.0198)	Prec@1 100.000 (99.814)	
Total train loss: 0.0198

Train time: 21.32174253463745
 * Prec@1 91.110 Prec@5 99.590 Loss 0.3445
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 23.92453670501709

Epoch: [50][77/391]	LR: 2.0000000000000004e-07	Loss 0.0258 (0.0215)	Prec@1 100.000 (99.770)	
Epoch: [50][155/391]	LR: 2.0000000000000004e-07	Loss 0.0138 (0.0211)	Prec@1 100.000 (99.750)	
Epoch: [50][233/391]	LR: 2.0000000000000004e-07	Loss 0.0155 (0.0205)	Prec@1 100.000 (99.756)	
Epoch: [50][311/391]	LR: 2.0000000000000004e-07	Loss 0.0210 (0.0209)	Prec@1 100.000 (99.737)	
Epoch: [50][389/391]	LR: 2.0000000000000004e-07	Loss 0.0149 (0.0208)	Prec@1 100.000 (99.734)	
Total train loss: 0.0208

Train time: 21.555824279785156
 * Prec@1 91.100 Prec@5 99.600 Loss 0.3423
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.393351554870605

Epoch: [51][77/391]	LR: 2.0000000000000004e-07	Loss 0.0299 (0.0216)	Prec@1 99.219 (99.730)	
Epoch: [51][155/391]	LR: 2.0000000000000004e-07	Loss 0.0173 (0.0206)	Prec@1 100.000 (99.775)	
Epoch: [51][233/391]	LR: 2.0000000000000004e-07	Loss 0.0191 (0.0203)	Prec@1 100.000 (99.760)	
Epoch: [51][311/391]	LR: 2.0000000000000004e-07	Loss 0.0237 (0.0204)	Prec@1 99.219 (99.775)	
Epoch: [51][389/391]	LR: 2.0000000000000004e-07	Loss 0.0181 (0.0203)	Prec@1 100.000 (99.770)	
Total train loss: 0.0203

Train time: 22.205116987228394
 * Prec@1 90.960 Prec@5 99.620 Loss 0.3442
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 25.11443042755127

Epoch: [52][77/391]	LR: 2.0000000000000004e-07	Loss 0.0157 (0.0216)	Prec@1 100.000 (99.669)	
Epoch: [52][155/391]	LR: 2.0000000000000004e-07	Loss 0.0230 (0.0219)	Prec@1 100.000 (99.669)	
Epoch: [52][233/391]	LR: 2.0000000000000004e-07	Loss 0.0157 (0.0216)	Prec@1 100.000 (99.686)	
Epoch: [52][311/391]	LR: 2.0000000000000004e-07	Loss 0.0157 (0.0216)	Prec@1 100.000 (99.695)	
Epoch: [52][389/391]	LR: 2.0000000000000004e-07	Loss 0.0174 (0.0211)	Prec@1 100.000 (99.722)	
Total train loss: 0.0211

Train time: 21.846715927124023
 * Prec@1 91.180 Prec@5 99.590 Loss 0.3391
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.81030797958374

Epoch: [53][77/391]	LR: 2.0000000000000004e-07	Loss 0.0107 (0.0194)	Prec@1 100.000 (99.820)	
Epoch: [53][155/391]	LR: 2.0000000000000004e-07	Loss 0.0374 (0.0199)	Prec@1 98.438 (99.800)	
Epoch: [53][233/391]	LR: 2.0000000000000004e-07	Loss 0.0276 (0.0198)	Prec@1 100.000 (99.803)	
Epoch: [53][311/391]	LR: 2.0000000000000004e-07	Loss 0.0104 (0.0197)	Prec@1 100.000 (99.797)	
Epoch: [53][389/391]	LR: 2.0000000000000004e-07	Loss 0.0136 (0.0195)	Prec@1 100.000 (99.800)	
Total train loss: 0.0195

Train time: 20.833229541778564
 * Prec@1 91.180 Prec@5 99.580 Loss 0.3433
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.55913805961609

Epoch: [54][77/391]	LR: 2.0000000000000004e-07	Loss 0.0384 (0.0201)	Prec@1 99.219 (99.780)	
Epoch: [54][155/391]	LR: 2.0000000000000004e-07	Loss 0.0088 (0.0204)	Prec@1 100.000 (99.755)	
Epoch: [54][233/391]	LR: 2.0000000000000004e-07	Loss 0.0287 (0.0204)	Prec@1 100.000 (99.760)	
Epoch: [54][311/391]	LR: 2.0000000000000004e-07	Loss 0.0268 (0.0203)	Prec@1 99.219 (99.755)	
Epoch: [54][389/391]	LR: 2.0000000000000004e-07	Loss 0.0160 (0.0202)	Prec@1 100.000 (99.762)	
Total train loss: 0.0202

Train time: 21.221444606781006
 * Prec@1 91.070 Prec@5 99.610 Loss 0.3372
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 23.53920269012451

Epoch: [55][77/391]	LR: 2.0000000000000004e-07	Loss 0.0172 (0.0191)	Prec@1 100.000 (99.800)	
Epoch: [55][155/391]	LR: 2.0000000000000004e-07	Loss 0.0142 (0.0199)	Prec@1 100.000 (99.790)	
Epoch: [55][233/391]	LR: 2.0000000000000004e-07	Loss 0.0129 (0.0203)	Prec@1 100.000 (99.780)	
Epoch: [55][311/391]	LR: 2.0000000000000004e-07	Loss 0.0105 (0.0202)	Prec@1 100.000 (99.780)	
Epoch: [55][389/391]	LR: 2.0000000000000004e-07	Loss 0.0156 (0.0204)	Prec@1 100.000 (99.762)	
Total train loss: 0.0204

Train time: 21.049299955368042
 * Prec@1 91.140 Prec@5 99.580 Loss 0.3411
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 23.65160298347473

Epoch: [56][77/391]	LR: 2.0000000000000004e-07	Loss 0.0280 (0.0176)	Prec@1 99.219 (99.860)	
Epoch: [56][155/391]	LR: 2.0000000000000004e-07	Loss 0.0335 (0.0183)	Prec@1 98.438 (99.805)	
Epoch: [56][233/391]	LR: 2.0000000000000004e-07	Loss 0.0333 (0.0194)	Prec@1 98.438 (99.796)	
Epoch: [56][311/391]	LR: 2.0000000000000004e-07	Loss 0.0109 (0.0199)	Prec@1 100.000 (99.785)	
Epoch: [56][389/391]	LR: 2.0000000000000004e-07	Loss 0.0120 (0.0198)	Prec@1 100.000 (99.786)	
Total train loss: 0.0198

Train time: 21.342531442642212
 * Prec@1 91.190 Prec@5 99.590 Loss 0.3408
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.742103099822998

Epoch: [57][77/391]	LR: 2.0000000000000004e-07	Loss 0.0314 (0.0199)	Prec@1 99.219 (99.760)	
Epoch: [57][155/391]	LR: 2.0000000000000004e-07	Loss 0.0160 (0.0209)	Prec@1 100.000 (99.735)	
Epoch: [57][233/391]	LR: 2.0000000000000004e-07	Loss 0.0162 (0.0205)	Prec@1 100.000 (99.743)	
Epoch: [57][311/391]	LR: 2.0000000000000004e-07	Loss 0.0155 (0.0207)	Prec@1 100.000 (99.747)	
Epoch: [57][389/391]	LR: 2.0000000000000004e-07	Loss 0.0231 (0.0204)	Prec@1 100.000 (99.766)	
Total train loss: 0.0204

Train time: 20.97916054725647
 * Prec@1 91.150 Prec@5 99.590 Loss 0.3433
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 23.692659378051758

Epoch: [58][77/391]	LR: 2.0000000000000004e-07	Loss 0.0187 (0.0209)	Prec@1 100.000 (99.750)	
Epoch: [58][155/391]	LR: 2.0000000000000004e-07	Loss 0.0189 (0.0208)	Prec@1 100.000 (99.745)	
Epoch: [58][233/391]	LR: 2.0000000000000004e-07	Loss 0.0241 (0.0206)	Prec@1 99.219 (99.736)	
Epoch: [58][311/391]	LR: 2.0000000000000004e-07	Loss 0.0266 (0.0205)	Prec@1 100.000 (99.755)	
Epoch: [58][389/391]	LR: 2.0000000000000004e-07	Loss 0.0386 (0.0206)	Prec@1 99.219 (99.752)	
Total train loss: 0.0206

Train time: 21.481505155563354
 * Prec@1 91.050 Prec@5 99.530 Loss 0.3440
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 24.404650926589966

Epoch: [59][77/391]	LR: 2.0000000000000004e-07	Loss 0.0302 (0.0198)	Prec@1 99.219 (99.790)	
Epoch: [59][155/391]	LR: 2.0000000000000004e-07	Loss 0.0142 (0.0201)	Prec@1 100.000 (99.780)	
Epoch: [59][233/391]	LR: 2.0000000000000004e-07	Loss 0.0271 (0.0202)	Prec@1 100.000 (99.780)	
Epoch: [59][311/391]	LR: 2.0000000000000004e-07	Loss 0.0128 (0.0200)	Prec@1 100.000 (99.770)	
Epoch: [59][389/391]	LR: 2.0000000000000004e-07	Loss 0.0204 (0.0201)	Prec@1 100.000 (99.776)	
Total train loss: 0.0201

Train time: 24.52797555923462
 * Prec@1 91.000 Prec@5 99.560 Loss 0.3457
Best acc: 91.290
--------------------------------------------------------------------------------
Test time: 27.704020023345947


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/
          savedir: ../pretrained_models/frozen/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 60
          start_epoch: 0
          batch_size: 128
          lr: 0.002
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 7
          af_bit: 4
          w_bit: 7
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          exp: x128-8b
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 5
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 89.440 Prec@5 99.570 Loss 0.3879
Pre-trained Prec@1 with 5 layers frozen: 89.43999481201172 	 Loss: 0.387939453125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.002	Loss 0.0220 (0.0636)	Prec@1 100.000 (97.957)	
Epoch: [0][155/391]	LR: 0.002	Loss 0.0851 (0.0617)	Prec@1 95.312 (97.967)	
Epoch: [0][233/391]	LR: 0.002	Loss 0.0847 (0.0596)	Prec@1 95.312 (98.057)	
Epoch: [0][311/391]	LR: 0.002	Loss 0.0450 (0.0594)	Prec@1 97.656 (98.034)	
Epoch: [0][389/391]	LR: 0.002	Loss 0.0231 (0.0593)	Prec@1 100.000 (98.051)	
Total train loss: 0.0594

Train time: 53.152381896972656
 * Prec@1 91.110 Prec@5 99.550 Loss 0.3323
Best acc: 91.110
--------------------------------------------------------------------------------
Test time: 56.67143511772156

Epoch: [1][77/391]	LR: 0.002	Loss 0.0317 (0.0439)	Prec@1 99.219 (98.868)	
Epoch: [1][155/391]	LR: 0.002	Loss 0.0569 (0.0465)	Prec@1 97.656 (98.663)	
Epoch: [1][233/391]	LR: 0.002	Loss 0.0363 (0.0475)	Prec@1 99.219 (98.571)	
Epoch: [1][311/391]	LR: 0.002	Loss 0.0408 (0.0483)	Prec@1 98.438 (98.543)	
Epoch: [1][389/391]	LR: 0.002	Loss 0.0470 (0.0486)	Prec@1 98.438 (98.526)	
Total train loss: 0.0486

Train time: 21.776768684387207
 * Prec@1 90.990 Prec@5 99.550 Loss 0.3323
Best acc: 91.110
--------------------------------------------------------------------------------
Test time: 25.484113693237305

Epoch: [2][77/391]	LR: 0.002	Loss 0.0434 (0.0466)	Prec@1 100.000 (98.718)	
Epoch: [2][155/391]	LR: 0.002	Loss 0.0622 (0.0467)	Prec@1 97.656 (98.643)	
Epoch: [2][233/391]	LR: 0.002	Loss 0.0759 (0.0453)	Prec@1 96.094 (98.711)	
Epoch: [2][311/391]	LR: 0.002	Loss 0.0396 (0.0457)	Prec@1 99.219 (98.695)	
Epoch: [2][389/391]	LR: 0.002	Loss 0.0437 (0.0451)	Prec@1 97.656 (98.696)	
Total train loss: 0.0451

Train time: 19.956600427627563
 * Prec@1 90.970 Prec@5 99.580 Loss 0.3328
Best acc: 91.110
--------------------------------------------------------------------------------
Test time: 22.703293800354004

Epoch: [3][77/391]	LR: 0.002	Loss 0.0289 (0.0349)	Prec@1 99.219 (99.219)	
Epoch: [3][155/391]	LR: 0.002	Loss 0.0127 (0.0398)	Prec@1 100.000 (98.983)	
Epoch: [3][233/391]	LR: 0.002	Loss 0.0294 (0.0398)	Prec@1 100.000 (98.995)	
Epoch: [3][311/391]	LR: 0.002	Loss 0.0641 (0.0398)	Prec@1 98.438 (98.986)	
Epoch: [3][389/391]	LR: 0.002	Loss 0.0645 (0.0397)	Prec@1 98.438 (98.980)	
Total train loss: 0.0398

Train time: 19.658974409103394
 * Prec@1 90.880 Prec@5 99.600 Loss 0.3379
Best acc: 91.110
--------------------------------------------------------------------------------
Test time: 22.604357957839966

Epoch: [4][77/391]	LR: 0.002	Loss 0.0579 (0.0351)	Prec@1 99.219 (99.209)	
Epoch: [4][155/391]	LR: 0.002	Loss 0.0532 (0.0365)	Prec@1 97.656 (99.124)	
Epoch: [4][233/391]	LR: 0.002	Loss 0.0261 (0.0375)	Prec@1 100.000 (99.069)	
Epoch: [4][311/391]	LR: 0.002	Loss 0.0274 (0.0377)	Prec@1 100.000 (99.061)	
Epoch: [4][389/391]	LR: 0.002	Loss 0.0306 (0.0382)	Prec@1 99.219 (99.022)	
Total train loss: 0.0382

Train time: 19.224709033966064
 * Prec@1 90.920 Prec@5 99.580 Loss 0.3406
Best acc: 91.110
--------------------------------------------------------------------------------
Test time: 20.974002599716187

Epoch: [5][77/391]	LR: 0.002	Loss 0.0314 (0.0359)	Prec@1 99.219 (99.169)	
Epoch: [5][155/391]	LR: 0.002	Loss 0.0820 (0.0361)	Prec@1 95.312 (99.184)	
Epoch: [5][233/391]	LR: 0.002	Loss 0.0198 (0.0352)	Prec@1 100.000 (99.199)	
Epoch: [5][311/391]	LR: 0.002	Loss 0.0430 (0.0354)	Prec@1 99.219 (99.174)	
Epoch: [5][389/391]	LR: 0.002	Loss 0.0430 (0.0354)	Prec@1 98.438 (99.185)	
Total train loss: 0.0354

Train time: 16.423003435134888
 * Prec@1 91.020 Prec@5 99.550 Loss 0.3369
Best acc: 91.110
--------------------------------------------------------------------------------
Test time: 19.117345094680786

Epoch: [6][77/391]	LR: 0.002	Loss 0.0253 (0.0311)	Prec@1 100.000 (99.329)	
Epoch: [6][155/391]	LR: 0.002	Loss 0.0412 (0.0308)	Prec@1 98.438 (99.344)	
Epoch: [6][233/391]	LR: 0.002	Loss 0.0145 (0.0320)	Prec@1 100.000 (99.255)	
Epoch: [6][311/391]	LR: 0.002	Loss 0.0315 (0.0322)	Prec@1 98.438 (99.259)	
Epoch: [6][389/391]	LR: 0.002	Loss 0.0236 (0.0329)	Prec@1 100.000 (99.255)	
Total train loss: 0.0329

Train time: 16.663973331451416
 * Prec@1 91.190 Prec@5 99.500 Loss 0.3389
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 19.974530935287476

Epoch: [7][77/391]	LR: 0.002	Loss 0.0242 (0.0301)	Prec@1 100.000 (99.449)	
Epoch: [7][155/391]	LR: 0.002	Loss 0.0223 (0.0303)	Prec@1 100.000 (99.449)	
Epoch: [7][233/391]	LR: 0.002	Loss 0.0318 (0.0303)	Prec@1 100.000 (99.422)	
Epoch: [7][311/391]	LR: 0.002	Loss 0.0190 (0.0304)	Prec@1 100.000 (99.419)	
Epoch: [7][389/391]	LR: 0.002	Loss 0.0247 (0.0310)	Prec@1 100.000 (99.385)	
Total train loss: 0.0310

Train time: 18.11668872833252
 * Prec@1 90.910 Prec@5 99.540 Loss 0.3423
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.970698833465576

Epoch: [8][77/391]	LR: 0.002	Loss 0.0456 (0.0303)	Prec@1 99.219 (99.369)	
Epoch: [8][155/391]	LR: 0.002	Loss 0.0208 (0.0299)	Prec@1 100.000 (99.379)	
Epoch: [8][233/391]	LR: 0.002	Loss 0.0271 (0.0309)	Prec@1 100.000 (99.342)	
Epoch: [8][311/391]	LR: 0.002	Loss 0.0199 (0.0305)	Prec@1 100.000 (99.389)	
Epoch: [8][389/391]	LR: 0.002	Loss 0.0382 (0.0306)	Prec@1 100.000 (99.367)	
Total train loss: 0.0306

Train time: 18.299062728881836
 * Prec@1 91.000 Prec@5 99.510 Loss 0.3457
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 20.759987831115723

Epoch: [9][77/391]	LR: 0.002	Loss 0.0361 (0.0292)	Prec@1 99.219 (99.419)	
Epoch: [9][155/391]	LR: 0.002	Loss 0.0424 (0.0278)	Prec@1 99.219 (99.469)	
Epoch: [9][233/391]	LR: 0.002	Loss 0.0209 (0.0278)	Prec@1 100.000 (99.466)	
Epoch: [9][311/391]	LR: 0.002	Loss 0.0240 (0.0284)	Prec@1 100.000 (99.444)	
Epoch: [9][389/391]	LR: 0.002	Loss 0.0122 (0.0287)	Prec@1 100.000 (99.447)	
Total train loss: 0.0287

Train time: 18.24626851081848
 * Prec@1 90.970 Prec@5 99.550 Loss 0.3430
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.635224103927612

Epoch: [10][77/391]	LR: 0.002	Loss 0.0177 (0.0277)	Prec@1 100.000 (99.529)	
Epoch: [10][155/391]	LR: 0.002	Loss 0.0231 (0.0273)	Prec@1 100.000 (99.559)	
Epoch: [10][233/391]	LR: 0.002	Loss 0.0283 (0.0279)	Prec@1 98.438 (99.506)	
Epoch: [10][311/391]	LR: 0.002	Loss 0.0297 (0.0281)	Prec@1 100.000 (99.499)	
Epoch: [10][389/391]	LR: 0.002	Loss 0.0245 (0.0284)	Prec@1 100.000 (99.493)	
Total train loss: 0.0284

Train time: 19.14637541770935
 * Prec@1 90.970 Prec@5 99.530 Loss 0.3428
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.716761112213135

Epoch: [11][77/391]	LR: 0.002	Loss 0.0257 (0.0273)	Prec@1 99.219 (99.509)	
Epoch: [11][155/391]	LR: 0.002	Loss 0.0278 (0.0276)	Prec@1 100.000 (99.479)	
Epoch: [11][233/391]	LR: 0.002	Loss 0.0463 (0.0283)	Prec@1 99.219 (99.416)	
Epoch: [11][311/391]	LR: 0.002	Loss 0.0265 (0.0282)	Prec@1 99.219 (99.439)	
Epoch: [11][389/391]	LR: 0.002	Loss 0.0161 (0.0281)	Prec@1 100.000 (99.465)	
Total train loss: 0.0282

Train time: 19.199079275131226
 * Prec@1 90.950 Prec@5 99.540 Loss 0.3425
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.52208685874939

Epoch: [12][77/391]	LR: 0.002	Loss 0.0269 (0.0251)	Prec@1 100.000 (99.609)	
Epoch: [12][155/391]	LR: 0.002	Loss 0.0139 (0.0257)	Prec@1 100.000 (99.599)	
Epoch: [12][233/391]	LR: 0.002	Loss 0.0163 (0.0249)	Prec@1 100.000 (99.636)	
Epoch: [12][311/391]	LR: 0.002	Loss 0.0205 (0.0257)	Prec@1 100.000 (99.589)	
Epoch: [12][389/391]	LR: 0.002	Loss 0.0705 (0.0269)	Prec@1 96.875 (99.531)	
Total train loss: 0.0270

Train time: 20.47357177734375
 * Prec@1 90.880 Prec@5 99.530 Loss 0.3489
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 23.679229259490967

Epoch: [13][77/391]	LR: 0.002	Loss 0.0224 (0.0262)	Prec@1 100.000 (99.559)	
Epoch: [13][155/391]	LR: 0.002	Loss 0.0123 (0.0263)	Prec@1 100.000 (99.569)	
Epoch: [13][233/391]	LR: 0.002	Loss 0.0385 (0.0260)	Prec@1 98.438 (99.559)	
Epoch: [13][311/391]	LR: 0.002	Loss 0.0080 (0.0262)	Prec@1 100.000 (99.562)	
Epoch: [13][389/391]	LR: 0.002	Loss 0.0542 (0.0259)	Prec@1 97.656 (99.577)	
Total train loss: 0.0259

Train time: 19.031359434127808
 * Prec@1 91.120 Prec@5 99.540 Loss 0.3403
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.641100883483887

Epoch: [14][77/391]	LR: 0.002	Loss 0.0106 (0.0238)	Prec@1 100.000 (99.579)	
Epoch: [14][155/391]	LR: 0.002	Loss 0.0165 (0.0242)	Prec@1 100.000 (99.589)	
Epoch: [14][233/391]	LR: 0.002	Loss 0.0200 (0.0237)	Prec@1 100.000 (99.623)	
Epoch: [14][311/391]	LR: 0.002	Loss 0.0571 (0.0240)	Prec@1 98.438 (99.617)	
Epoch: [14][389/391]	LR: 0.002	Loss 0.0349 (0.0242)	Prec@1 99.219 (99.633)	
Total train loss: 0.0242

Train time: 19.87834405899048
 * Prec@1 91.010 Prec@5 99.530 Loss 0.3516
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.376224040985107

Epoch: [15][77/391]	LR: 0.002	Loss 0.0197 (0.0250)	Prec@1 100.000 (99.589)	
Epoch: [15][155/391]	LR: 0.002	Loss 0.0256 (0.0229)	Prec@1 100.000 (99.664)	
Epoch: [15][233/391]	LR: 0.002	Loss 0.0153 (0.0235)	Prec@1 100.000 (99.686)	
Epoch: [15][311/391]	LR: 0.002	Loss 0.0420 (0.0238)	Prec@1 99.219 (99.667)	
Epoch: [15][389/391]	LR: 0.002	Loss 0.0226 (0.0235)	Prec@1 100.000 (99.679)	
Total train loss: 0.0235

Train time: 20.495933294296265
 * Prec@1 91.050 Prec@5 99.550 Loss 0.3472
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 24.289121627807617

Epoch: [16][77/391]	LR: 0.002	Loss 0.0170 (0.0236)	Prec@1 100.000 (99.679)	
Epoch: [16][155/391]	LR: 0.002	Loss 0.0330 (0.0229)	Prec@1 99.219 (99.720)	
Epoch: [16][233/391]	LR: 0.002	Loss 0.0124 (0.0232)	Prec@1 100.000 (99.673)	
Epoch: [16][311/391]	LR: 0.002	Loss 0.0192 (0.0235)	Prec@1 100.000 (99.642)	
Epoch: [16][389/391]	LR: 0.002	Loss 0.0165 (0.0236)	Prec@1 100.000 (99.647)	
Total train loss: 0.0236

Train time: 23.980608463287354
 * Prec@1 91.110 Prec@5 99.540 Loss 0.3457
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 26.301403522491455

Epoch: [17][77/391]	LR: 0.002	Loss 0.0412 (0.0231)	Prec@1 99.219 (99.740)	
Epoch: [17][155/391]	LR: 0.002	Loss 0.0152 (0.0233)	Prec@1 100.000 (99.695)	
Epoch: [17][233/391]	LR: 0.002	Loss 0.0241 (0.0233)	Prec@1 100.000 (99.700)	
Epoch: [17][311/391]	LR: 0.002	Loss 0.0227 (0.0234)	Prec@1 100.000 (99.700)	
Epoch: [17][389/391]	LR: 0.002	Loss 0.0087 (0.0236)	Prec@1 100.000 (99.679)	
Total train loss: 0.0236

Train time: 19.94601345062256
 * Prec@1 91.100 Prec@5 99.520 Loss 0.3499
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.67101550102234

Epoch: [18][77/391]	LR: 0.002	Loss 0.0116 (0.0210)	Prec@1 100.000 (99.790)	
Epoch: [18][155/391]	LR: 0.002	Loss 0.0366 (0.0221)	Prec@1 99.219 (99.725)	
Epoch: [18][233/391]	LR: 0.002	Loss 0.0226 (0.0220)	Prec@1 99.219 (99.723)	
Epoch: [18][311/391]	LR: 0.002	Loss 0.0224 (0.0225)	Prec@1 100.000 (99.695)	
Epoch: [18][389/391]	LR: 0.002	Loss 0.0211 (0.0228)	Prec@1 100.000 (99.679)	
Total train loss: 0.0228

Train time: 19.95690083503723
 * Prec@1 90.980 Prec@5 99.520 Loss 0.3467
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.38145112991333

Epoch: [19][77/391]	LR: 0.002	Loss 0.0152 (0.0232)	Prec@1 100.000 (99.649)	
Epoch: [19][155/391]	LR: 0.002	Loss 0.0183 (0.0226)	Prec@1 100.000 (99.644)	
Epoch: [19][233/391]	LR: 0.002	Loss 0.0173 (0.0220)	Prec@1 100.000 (99.669)	
Epoch: [19][311/391]	LR: 0.002	Loss 0.0266 (0.0221)	Prec@1 99.219 (99.674)	
Epoch: [19][389/391]	LR: 0.002	Loss 0.0287 (0.0220)	Prec@1 100.000 (99.667)	
Total train loss: 0.0220

Train time: 19.721110582351685
 * Prec@1 90.880 Prec@5 99.500 Loss 0.3506
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.53615975379944

Epoch: [20][77/391]	LR: 0.0002	Loss 0.0142 (0.0212)	Prec@1 100.000 (99.700)	
Epoch: [20][155/391]	LR: 0.0002	Loss 0.0167 (0.0213)	Prec@1 100.000 (99.720)	
Epoch: [20][233/391]	LR: 0.0002	Loss 0.0134 (0.0213)	Prec@1 100.000 (99.706)	
Epoch: [20][311/391]	LR: 0.0002	Loss 0.0168 (0.0211)	Prec@1 100.000 (99.720)	
Epoch: [20][389/391]	LR: 0.0002	Loss 0.0207 (0.0212)	Prec@1 100.000 (99.730)	
Total train loss: 0.0212

Train time: 20.4964656829834
 * Prec@1 90.900 Prec@5 99.500 Loss 0.3501
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 23.445573568344116

Epoch: [21][77/391]	LR: 0.0002	Loss 0.0163 (0.0208)	Prec@1 100.000 (99.710)	
Epoch: [21][155/391]	LR: 0.0002	Loss 0.0218 (0.0216)	Prec@1 100.000 (99.684)	
Epoch: [21][233/391]	LR: 0.0002	Loss 0.0086 (0.0215)	Prec@1 100.000 (99.710)	
Epoch: [21][311/391]	LR: 0.0002	Loss 0.0137 (0.0210)	Prec@1 100.000 (99.720)	
Epoch: [21][389/391]	LR: 0.0002	Loss 0.0190 (0.0208)	Prec@1 100.000 (99.726)	
Total train loss: 0.0208

Train time: 19.536298751831055
 * Prec@1 91.100 Prec@5 99.530 Loss 0.3457
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.117417097091675

Epoch: [22][77/391]	LR: 0.0002	Loss 0.0165 (0.0209)	Prec@1 100.000 (99.700)	
Epoch: [22][155/391]	LR: 0.0002	Loss 0.0178 (0.0208)	Prec@1 100.000 (99.720)	
Epoch: [22][233/391]	LR: 0.0002	Loss 0.0462 (0.0210)	Prec@1 98.438 (99.733)	
Epoch: [22][311/391]	LR: 0.0002	Loss 0.0392 (0.0209)	Prec@1 99.219 (99.747)	
Epoch: [22][389/391]	LR: 0.0002	Loss 0.0252 (0.0204)	Prec@1 100.000 (99.770)	
Total train loss: 0.0204

Train time: 20.52359390258789
 * Prec@1 91.170 Prec@5 99.570 Loss 0.3457
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 23.32045006752014

Epoch: [23][77/391]	LR: 0.0002	Loss 0.0353 (0.0225)	Prec@1 100.000 (99.679)	
Epoch: [23][155/391]	LR: 0.0002	Loss 0.0524 (0.0221)	Prec@1 99.219 (99.720)	
Epoch: [23][233/391]	LR: 0.0002	Loss 0.0225 (0.0215)	Prec@1 100.000 (99.746)	
Epoch: [23][311/391]	LR: 0.0002	Loss 0.0129 (0.0214)	Prec@1 100.000 (99.737)	
Epoch: [23][389/391]	LR: 0.0002	Loss 0.0217 (0.0216)	Prec@1 99.219 (99.720)	
Total train loss: 0.0217

Train time: 19.97251033782959
 * Prec@1 90.960 Prec@5 99.540 Loss 0.3479
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 23.008585691452026

Epoch: [24][77/391]	LR: 0.0002	Loss 0.0126 (0.0211)	Prec@1 100.000 (99.810)	
Epoch: [24][155/391]	LR: 0.0002	Loss 0.0148 (0.0215)	Prec@1 100.000 (99.765)	
Epoch: [24][233/391]	LR: 0.0002	Loss 0.0265 (0.0216)	Prec@1 99.219 (99.753)	
Epoch: [24][311/391]	LR: 0.0002	Loss 0.0278 (0.0220)	Prec@1 99.219 (99.732)	
Epoch: [24][389/391]	LR: 0.0002	Loss 0.0285 (0.0219)	Prec@1 99.219 (99.728)	
Total train loss: 0.0220

Train time: 19.032907724380493
 * Prec@1 90.890 Prec@5 99.550 Loss 0.3491
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.661831378936768

Epoch: [25][77/391]	LR: 0.0002	Loss 0.0425 (0.0231)	Prec@1 98.438 (99.730)	
Epoch: [25][155/391]	LR: 0.0002	Loss 0.0206 (0.0215)	Prec@1 100.000 (99.755)	
Epoch: [25][233/391]	LR: 0.0002	Loss 0.0105 (0.0211)	Prec@1 100.000 (99.773)	
Epoch: [25][311/391]	LR: 0.0002	Loss 0.0124 (0.0207)	Prec@1 100.000 (99.790)	
Epoch: [25][389/391]	LR: 0.0002	Loss 0.0267 (0.0209)	Prec@1 100.000 (99.764)	
Total train loss: 0.0209

Train time: 20.38199019432068
 * Prec@1 90.860 Prec@5 99.530 Loss 0.3491
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.911509037017822

Epoch: [26][77/391]	LR: 0.0002	Loss 0.0183 (0.0216)	Prec@1 100.000 (99.740)	
Epoch: [26][155/391]	LR: 0.0002	Loss 0.0191 (0.0207)	Prec@1 100.000 (99.790)	
Epoch: [26][233/391]	LR: 0.0002	Loss 0.0232 (0.0213)	Prec@1 100.000 (99.746)	
Epoch: [26][311/391]	LR: 0.0002	Loss 0.0082 (0.0212)	Prec@1 100.000 (99.750)	
Epoch: [26][389/391]	LR: 0.0002	Loss 0.0224 (0.0212)	Prec@1 100.000 (99.744)	
Total train loss: 0.0212

Train time: 20.47618055343628
 * Prec@1 91.130 Prec@5 99.560 Loss 0.3469
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 23.2554829120636

Epoch: [27][77/391]	LR: 0.0002	Loss 0.0125 (0.0220)	Prec@1 100.000 (99.730)	
Epoch: [27][155/391]	LR: 0.0002	Loss 0.0227 (0.0218)	Prec@1 100.000 (99.684)	
Epoch: [27][233/391]	LR: 0.0002	Loss 0.0206 (0.0217)	Prec@1 100.000 (99.703)	
Epoch: [27][311/391]	LR: 0.0002	Loss 0.0092 (0.0215)	Prec@1 100.000 (99.712)	
Epoch: [27][389/391]	LR: 0.0002	Loss 0.0145 (0.0212)	Prec@1 100.000 (99.718)	
Total train loss: 0.0213

Train time: 20.029547452926636
 * Prec@1 90.930 Prec@5 99.600 Loss 0.3513
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.640812873840332

Epoch: [28][77/391]	LR: 0.0002	Loss 0.0282 (0.0203)	Prec@1 100.000 (99.780)	
Epoch: [28][155/391]	LR: 0.0002	Loss 0.0166 (0.0203)	Prec@1 100.000 (99.795)	
Epoch: [28][233/391]	LR: 0.0002	Loss 0.0194 (0.0208)	Prec@1 99.219 (99.786)	
Epoch: [28][311/391]	LR: 0.0002	Loss 0.0329 (0.0205)	Prec@1 99.219 (99.777)	
Epoch: [28][389/391]	LR: 0.0002	Loss 0.0192 (0.0206)	Prec@1 100.000 (99.764)	
Total train loss: 0.0206

Train time: 19.753617763519287
 * Prec@1 90.920 Prec@5 99.520 Loss 0.3521
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.401978969573975

Epoch: [29][77/391]	LR: 0.0002	Loss 0.0161 (0.0231)	Prec@1 100.000 (99.690)	
Epoch: [29][155/391]	LR: 0.0002	Loss 0.0255 (0.0215)	Prec@1 100.000 (99.785)	
Epoch: [29][233/391]	LR: 0.0002	Loss 0.0158 (0.0208)	Prec@1 100.000 (99.776)	
Epoch: [29][311/391]	LR: 0.0002	Loss 0.0341 (0.0208)	Prec@1 100.000 (99.770)	
Epoch: [29][389/391]	LR: 0.0002	Loss 0.0179 (0.0210)	Prec@1 100.000 (99.732)	
Total train loss: 0.0210

Train time: 19.766066074371338
 * Prec@1 90.960 Prec@5 99.550 Loss 0.3521
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.793232202529907

Epoch: [30][77/391]	LR: 2e-05	Loss 0.0166 (0.0219)	Prec@1 100.000 (99.720)	
Epoch: [30][155/391]	LR: 2e-05	Loss 0.0177 (0.0216)	Prec@1 100.000 (99.730)	
Epoch: [30][233/391]	LR: 2e-05	Loss 0.0151 (0.0209)	Prec@1 100.000 (99.756)	
Epoch: [30][311/391]	LR: 2e-05	Loss 0.0145 (0.0206)	Prec@1 100.000 (99.772)	
Epoch: [30][389/391]	LR: 2e-05	Loss 0.0240 (0.0209)	Prec@1 100.000 (99.770)	
Total train loss: 0.0209

Train time: 20.07745337486267
 * Prec@1 90.890 Prec@5 99.560 Loss 0.3503
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.852909326553345

Epoch: [31][77/391]	LR: 2e-05	Loss 0.0156 (0.0220)	Prec@1 100.000 (99.669)	
Epoch: [31][155/391]	LR: 2e-05	Loss 0.0186 (0.0211)	Prec@1 100.000 (99.745)	
Epoch: [31][233/391]	LR: 2e-05	Loss 0.0147 (0.0212)	Prec@1 100.000 (99.726)	
Epoch: [31][311/391]	LR: 2e-05	Loss 0.0159 (0.0208)	Prec@1 100.000 (99.727)	
Epoch: [31][389/391]	LR: 2e-05	Loss 0.0316 (0.0206)	Prec@1 99.219 (99.746)	
Total train loss: 0.0207

Train time: 20.080978631973267
 * Prec@1 90.860 Prec@5 99.490 Loss 0.3479
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.36892294883728

Epoch: [32][77/391]	LR: 2e-05	Loss 0.0197 (0.0214)	Prec@1 100.000 (99.740)	
Epoch: [32][155/391]	LR: 2e-05	Loss 0.0242 (0.0202)	Prec@1 99.219 (99.770)	
Epoch: [32][233/391]	LR: 2e-05	Loss 0.0099 (0.0206)	Prec@1 100.000 (99.763)	
Epoch: [32][311/391]	LR: 2e-05	Loss 0.0104 (0.0206)	Prec@1 100.000 (99.762)	
Epoch: [32][389/391]	LR: 2e-05	Loss 0.0280 (0.0208)	Prec@1 99.219 (99.746)	
Total train loss: 0.0208

Train time: 19.911826372146606
 * Prec@1 91.000 Prec@5 99.550 Loss 0.3496
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.980358839035034

Epoch: [33][77/391]	LR: 2e-05	Loss 0.0186 (0.0208)	Prec@1 100.000 (99.669)	
Epoch: [33][155/391]	LR: 2e-05	Loss 0.0378 (0.0217)	Prec@1 98.438 (99.679)	
Epoch: [33][233/391]	LR: 2e-05	Loss 0.0280 (0.0208)	Prec@1 100.000 (99.733)	
Epoch: [33][311/391]	LR: 2e-05	Loss 0.0230 (0.0211)	Prec@1 100.000 (99.747)	
Epoch: [33][389/391]	LR: 2e-05	Loss 0.0240 (0.0211)	Prec@1 99.219 (99.734)	
Total train loss: 0.0211

Train time: 20.30991554260254
 * Prec@1 91.050 Prec@5 99.590 Loss 0.3511
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 23.39866304397583

Epoch: [34][77/391]	LR: 2e-05	Loss 0.0318 (0.0220)	Prec@1 99.219 (99.639)	
Epoch: [34][155/391]	LR: 2e-05	Loss 0.0188 (0.0212)	Prec@1 100.000 (99.674)	
Epoch: [34][233/391]	LR: 2e-05	Loss 0.0104 (0.0210)	Prec@1 100.000 (99.700)	
Epoch: [34][311/391]	LR: 2e-05	Loss 0.0129 (0.0213)	Prec@1 100.000 (99.705)	
Epoch: [34][389/391]	LR: 2e-05	Loss 0.0120 (0.0212)	Prec@1 100.000 (99.730)	
Total train loss: 0.0212

Train time: 20.799285173416138
 * Prec@1 90.940 Prec@5 99.550 Loss 0.3477
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 23.37768793106079

Epoch: [35][77/391]	LR: 2e-05	Loss 0.0188 (0.0223)	Prec@1 100.000 (99.700)	
Epoch: [35][155/391]	LR: 2e-05	Loss 0.0141 (0.0217)	Prec@1 100.000 (99.735)	
Epoch: [35][233/391]	LR: 2e-05	Loss 0.0234 (0.0214)	Prec@1 100.000 (99.726)	
Epoch: [35][311/391]	LR: 2e-05	Loss 0.0125 (0.0211)	Prec@1 100.000 (99.740)	
Epoch: [35][389/391]	LR: 2e-05	Loss 0.0355 (0.0215)	Prec@1 99.219 (99.724)	
Total train loss: 0.0215

Train time: 24.277865886688232
 * Prec@1 90.840 Prec@5 99.540 Loss 0.3474
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 26.725605487823486

Epoch: [36][77/391]	LR: 2e-05	Loss 0.0161 (0.0200)	Prec@1 100.000 (99.780)	
Epoch: [36][155/391]	LR: 2e-05	Loss 0.0136 (0.0204)	Prec@1 100.000 (99.760)	
Epoch: [36][233/391]	LR: 2e-05	Loss 0.0219 (0.0207)	Prec@1 100.000 (99.746)	
Epoch: [36][311/391]	LR: 2e-05	Loss 0.0175 (0.0210)	Prec@1 100.000 (99.735)	
Epoch: [36][389/391]	LR: 2e-05	Loss 0.0103 (0.0210)	Prec@1 100.000 (99.740)	
Total train loss: 0.0210

Train time: 19.32041597366333
 * Prec@1 91.120 Prec@5 99.560 Loss 0.3494
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.197962522506714

Epoch: [37][77/391]	LR: 2e-05	Loss 0.0151 (0.0210)	Prec@1 100.000 (99.649)	
Epoch: [37][155/391]	LR: 2e-05	Loss 0.0211 (0.0214)	Prec@1 100.000 (99.669)	
Epoch: [37][233/391]	LR: 2e-05	Loss 0.0196 (0.0214)	Prec@1 100.000 (99.669)	
Epoch: [37][311/391]	LR: 2e-05	Loss 0.0073 (0.0216)	Prec@1 100.000 (99.692)	
Epoch: [37][389/391]	LR: 2e-05	Loss 0.0167 (0.0216)	Prec@1 100.000 (99.694)	
Total train loss: 0.0216

Train time: 20.001692295074463
 * Prec@1 90.930 Prec@5 99.610 Loss 0.3472
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.513259649276733

Epoch: [38][77/391]	LR: 2e-05	Loss 0.0219 (0.0204)	Prec@1 100.000 (99.730)	
Epoch: [38][155/391]	LR: 2e-05	Loss 0.0126 (0.0211)	Prec@1 100.000 (99.720)	
Epoch: [38][233/391]	LR: 2e-05	Loss 0.0126 (0.0208)	Prec@1 100.000 (99.723)	
Epoch: [38][311/391]	LR: 2e-05	Loss 0.0478 (0.0209)	Prec@1 98.438 (99.732)	
Epoch: [38][389/391]	LR: 2e-05	Loss 0.0221 (0.0213)	Prec@1 100.000 (99.720)	
Total train loss: 0.0213

Train time: 19.936147212982178
 * Prec@1 90.860 Prec@5 99.540 Loss 0.3486
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.382060289382935

Epoch: [39][77/391]	LR: 2e-05	Loss 0.0229 (0.0203)	Prec@1 99.219 (99.770)	
Epoch: [39][155/391]	LR: 2e-05	Loss 0.0263 (0.0219)	Prec@1 99.219 (99.700)	
Epoch: [39][233/391]	LR: 2e-05	Loss 0.0442 (0.0215)	Prec@1 98.438 (99.716)	
Epoch: [39][311/391]	LR: 2e-05	Loss 0.0153 (0.0211)	Prec@1 100.000 (99.727)	
Epoch: [39][389/391]	LR: 2e-05	Loss 0.0160 (0.0214)	Prec@1 100.000 (99.714)	
Total train loss: 0.0215

Train time: 19.9483003616333
 * Prec@1 91.010 Prec@5 99.580 Loss 0.3508
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.566340684890747

Epoch: [40][77/391]	LR: 2.0000000000000003e-06	Loss 0.0187 (0.0191)	Prec@1 100.000 (99.810)	
Epoch: [40][155/391]	LR: 2.0000000000000003e-06	Loss 0.0249 (0.0203)	Prec@1 100.000 (99.785)	
Epoch: [40][233/391]	LR: 2.0000000000000003e-06	Loss 0.0071 (0.0208)	Prec@1 100.000 (99.760)	
Epoch: [40][311/391]	LR: 2.0000000000000003e-06	Loss 0.0149 (0.0205)	Prec@1 99.219 (99.767)	
Epoch: [40][389/391]	LR: 2.0000000000000003e-06	Loss 0.0163 (0.0208)	Prec@1 100.000 (99.756)	
Total train loss: 0.0208

Train time: 20.251993894577026
 * Prec@1 91.170 Prec@5 99.540 Loss 0.3464
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.875314712524414

Epoch: [41][77/391]	LR: 2.0000000000000003e-06	Loss 0.0133 (0.0196)	Prec@1 100.000 (99.760)	
Epoch: [41][155/391]	LR: 2.0000000000000003e-06	Loss 0.0152 (0.0210)	Prec@1 100.000 (99.765)	
Epoch: [41][233/391]	LR: 2.0000000000000003e-06	Loss 0.0273 (0.0212)	Prec@1 99.219 (99.743)	
Epoch: [41][311/391]	LR: 2.0000000000000003e-06	Loss 0.0219 (0.0211)	Prec@1 100.000 (99.752)	
Epoch: [41][389/391]	LR: 2.0000000000000003e-06	Loss 0.0206 (0.0211)	Prec@1 100.000 (99.752)	
Total train loss: 0.0211

Train time: 19.894739389419556
 * Prec@1 91.010 Prec@5 99.540 Loss 0.3462
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.849653720855713

Epoch: [42][77/391]	LR: 2.0000000000000003e-06	Loss 0.0134 (0.0213)	Prec@1 100.000 (99.710)	
Epoch: [42][155/391]	LR: 2.0000000000000003e-06	Loss 0.0157 (0.0216)	Prec@1 100.000 (99.695)	
Epoch: [42][233/391]	LR: 2.0000000000000003e-06	Loss 0.0138 (0.0207)	Prec@1 100.000 (99.750)	
Epoch: [42][311/391]	LR: 2.0000000000000003e-06	Loss 0.0125 (0.0208)	Prec@1 100.000 (99.757)	
Epoch: [42][389/391]	LR: 2.0000000000000003e-06	Loss 0.0159 (0.0207)	Prec@1 100.000 (99.756)	
Total train loss: 0.0207

Train time: 19.656524181365967
 * Prec@1 90.810 Prec@5 99.530 Loss 0.3481
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.41149926185608

Epoch: [43][77/391]	LR: 2.0000000000000003e-06	Loss 0.0180 (0.0218)	Prec@1 100.000 (99.750)	
Epoch: [43][155/391]	LR: 2.0000000000000003e-06	Loss 0.0155 (0.0212)	Prec@1 100.000 (99.780)	
Epoch: [43][233/391]	LR: 2.0000000000000003e-06	Loss 0.0199 (0.0209)	Prec@1 100.000 (99.783)	
Epoch: [43][311/391]	LR: 2.0000000000000003e-06	Loss 0.0225 (0.0208)	Prec@1 100.000 (99.795)	
Epoch: [43][389/391]	LR: 2.0000000000000003e-06	Loss 0.0075 (0.0210)	Prec@1 100.000 (99.774)	
Total train loss: 0.0210

Train time: 19.499343156814575
 * Prec@1 91.070 Prec@5 99.530 Loss 0.3491
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.93173861503601

Epoch: [44][77/391]	LR: 2.0000000000000003e-06	Loss 0.0111 (0.0206)	Prec@1 100.000 (99.720)	
Epoch: [44][155/391]	LR: 2.0000000000000003e-06	Loss 0.0116 (0.0212)	Prec@1 100.000 (99.730)	
Epoch: [44][233/391]	LR: 2.0000000000000003e-06	Loss 0.0220 (0.0206)	Prec@1 99.219 (99.750)	
Epoch: [44][311/391]	LR: 2.0000000000000003e-06	Loss 0.0180 (0.0208)	Prec@1 100.000 (99.737)	
Epoch: [44][389/391]	LR: 2.0000000000000003e-06	Loss 0.0254 (0.0207)	Prec@1 100.000 (99.740)	
Total train loss: 0.0207

Train time: 19.9153790473938
 * Prec@1 91.030 Prec@5 99.530 Loss 0.3462
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.94604754447937

Epoch: [45][77/391]	LR: 2.0000000000000003e-06	Loss 0.0133 (0.0205)	Prec@1 100.000 (99.780)	
Epoch: [45][155/391]	LR: 2.0000000000000003e-06	Loss 0.0472 (0.0215)	Prec@1 98.438 (99.755)	
Epoch: [45][233/391]	LR: 2.0000000000000003e-06	Loss 0.0519 (0.0213)	Prec@1 97.656 (99.763)	
Epoch: [45][311/391]	LR: 2.0000000000000003e-06	Loss 0.0265 (0.0211)	Prec@1 100.000 (99.757)	
Epoch: [45][389/391]	LR: 2.0000000000000003e-06	Loss 0.0262 (0.0217)	Prec@1 100.000 (99.734)	
Total train loss: 0.0217

Train time: 20.613512754440308
 * Prec@1 90.950 Prec@5 99.500 Loss 0.3528
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 23.00082015991211

Epoch: [46][77/391]	LR: 2.0000000000000003e-06	Loss 0.0238 (0.0195)	Prec@1 100.000 (99.840)	
Epoch: [46][155/391]	LR: 2.0000000000000003e-06	Loss 0.0155 (0.0213)	Prec@1 100.000 (99.755)	
Epoch: [46][233/391]	LR: 2.0000000000000003e-06	Loss 0.0254 (0.0211)	Prec@1 99.219 (99.760)	
Epoch: [46][311/391]	LR: 2.0000000000000003e-06	Loss 0.0590 (0.0214)	Prec@1 97.656 (99.722)	
Epoch: [46][389/391]	LR: 2.0000000000000003e-06	Loss 0.0146 (0.0216)	Prec@1 100.000 (99.716)	
Total train loss: 0.0216

Train time: 20.82680630683899
 * Prec@1 91.190 Prec@5 99.530 Loss 0.3442
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 23.38530993461609

Epoch: [47][77/391]	LR: 2.0000000000000003e-06	Loss 0.0224 (0.0207)	Prec@1 100.000 (99.760)	
Epoch: [47][155/391]	LR: 2.0000000000000003e-06	Loss 0.0277 (0.0215)	Prec@1 100.000 (99.720)	
Epoch: [47][233/391]	LR: 2.0000000000000003e-06	Loss 0.0390 (0.0212)	Prec@1 99.219 (99.716)	
Epoch: [47][311/391]	LR: 2.0000000000000003e-06	Loss 0.0160 (0.0212)	Prec@1 100.000 (99.725)	
Epoch: [47][389/391]	LR: 2.0000000000000003e-06	Loss 0.0388 (0.0210)	Prec@1 100.000 (99.732)	
Total train loss: 0.0211

Train time: 20.5369234085083
 * Prec@1 91.070 Prec@5 99.520 Loss 0.3481
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 23.4378559589386

Epoch: [48][77/391]	LR: 2.0000000000000003e-06	Loss 0.0241 (0.0204)	Prec@1 100.000 (99.790)	
Epoch: [48][155/391]	LR: 2.0000000000000003e-06	Loss 0.0101 (0.0210)	Prec@1 100.000 (99.725)	
Epoch: [48][233/391]	LR: 2.0000000000000003e-06	Loss 0.0127 (0.0214)	Prec@1 100.000 (99.730)	
Epoch: [48][311/391]	LR: 2.0000000000000003e-06	Loss 0.0173 (0.0209)	Prec@1 100.000 (99.745)	
Epoch: [48][389/391]	LR: 2.0000000000000003e-06	Loss 0.0363 (0.0209)	Prec@1 98.438 (99.744)	
Total train loss: 0.0209

Train time: 20.446649312973022
 * Prec@1 91.140 Prec@5 99.570 Loss 0.3440
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 23.610784769058228

Epoch: [49][77/391]	LR: 2.0000000000000003e-06	Loss 0.0127 (0.0208)	Prec@1 100.000 (99.770)	
Epoch: [49][155/391]	LR: 2.0000000000000003e-06	Loss 0.0151 (0.0209)	Prec@1 100.000 (99.745)	
Epoch: [49][233/391]	LR: 2.0000000000000003e-06	Loss 0.0101 (0.0211)	Prec@1 100.000 (99.733)	
Epoch: [49][311/391]	LR: 2.0000000000000003e-06	Loss 0.0158 (0.0212)	Prec@1 100.000 (99.725)	
Epoch: [49][389/391]	LR: 2.0000000000000003e-06	Loss 0.0343 (0.0211)	Prec@1 100.000 (99.726)	
Total train loss: 0.0211

Train time: 19.723543643951416
 * Prec@1 91.000 Prec@5 99.520 Loss 0.3501
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.26978635787964

Epoch: [50][77/391]	LR: 2.0000000000000004e-07	Loss 0.0130 (0.0211)	Prec@1 100.000 (99.750)	
Epoch: [50][155/391]	LR: 2.0000000000000004e-07	Loss 0.0298 (0.0207)	Prec@1 100.000 (99.745)	
Epoch: [50][233/391]	LR: 2.0000000000000004e-07	Loss 0.0219 (0.0206)	Prec@1 100.000 (99.750)	
Epoch: [50][311/391]	LR: 2.0000000000000004e-07	Loss 0.0175 (0.0208)	Prec@1 99.219 (99.755)	
Epoch: [50][389/391]	LR: 2.0000000000000004e-07	Loss 0.0201 (0.0207)	Prec@1 99.219 (99.750)	
Total train loss: 0.0207

Train time: 19.800305366516113
 * Prec@1 90.980 Prec@5 99.520 Loss 0.3508
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.846450328826904

Epoch: [51][77/391]	LR: 2.0000000000000004e-07	Loss 0.0170 (0.0218)	Prec@1 100.000 (99.649)	
Epoch: [51][155/391]	LR: 2.0000000000000004e-07	Loss 0.0092 (0.0224)	Prec@1 100.000 (99.639)	
Epoch: [51][233/391]	LR: 2.0000000000000004e-07	Loss 0.0303 (0.0223)	Prec@1 99.219 (99.693)	
Epoch: [51][311/391]	LR: 2.0000000000000004e-07	Loss 0.0199 (0.0221)	Prec@1 100.000 (99.702)	
Epoch: [51][389/391]	LR: 2.0000000000000004e-07	Loss 0.0147 (0.0215)	Prec@1 100.000 (99.712)	
Total train loss: 0.0215

Train time: 20.31334114074707
 * Prec@1 90.840 Prec@5 99.540 Loss 0.3499
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 23.68083620071411

Epoch: [52][77/391]	LR: 2.0000000000000004e-07	Loss 0.0081 (0.0215)	Prec@1 100.000 (99.750)	
Epoch: [52][155/391]	LR: 2.0000000000000004e-07	Loss 0.0170 (0.0209)	Prec@1 100.000 (99.765)	
Epoch: [52][233/391]	LR: 2.0000000000000004e-07	Loss 0.0178 (0.0214)	Prec@1 100.000 (99.746)	
Epoch: [52][311/391]	LR: 2.0000000000000004e-07	Loss 0.0158 (0.0218)	Prec@1 100.000 (99.722)	
Epoch: [52][389/391]	LR: 2.0000000000000004e-07	Loss 0.0130 (0.0221)	Prec@1 100.000 (99.700)	
Total train loss: 0.0221

Train time: 20.343997478485107
 * Prec@1 90.880 Prec@5 99.590 Loss 0.3513
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.96416187286377

Epoch: [53][77/391]	LR: 2.0000000000000004e-07	Loss 0.0228 (0.0217)	Prec@1 100.000 (99.710)	
Epoch: [53][155/391]	LR: 2.0000000000000004e-07	Loss 0.0330 (0.0214)	Prec@1 100.000 (99.735)	
Epoch: [53][233/391]	LR: 2.0000000000000004e-07	Loss 0.0147 (0.0213)	Prec@1 100.000 (99.733)	
Epoch: [53][311/391]	LR: 2.0000000000000004e-07	Loss 0.0147 (0.0209)	Prec@1 100.000 (99.750)	
Epoch: [53][389/391]	LR: 2.0000000000000004e-07	Loss 0.0117 (0.0209)	Prec@1 100.000 (99.744)	
Total train loss: 0.0209

Train time: 19.98984718322754
 * Prec@1 91.210 Prec@5 99.520 Loss 0.3462
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 22.990654230117798

Epoch: [54][77/391]	LR: 2.0000000000000004e-07	Loss 0.0229 (0.0200)	Prec@1 99.219 (99.760)	
Epoch: [54][155/391]	LR: 2.0000000000000004e-07	Loss 0.0258 (0.0217)	Prec@1 100.000 (99.735)	
Epoch: [54][233/391]	LR: 2.0000000000000004e-07	Loss 0.0184 (0.0212)	Prec@1 100.000 (99.743)	
Epoch: [54][311/391]	LR: 2.0000000000000004e-07	Loss 0.0171 (0.0211)	Prec@1 100.000 (99.742)	
Epoch: [54][389/391]	LR: 2.0000000000000004e-07	Loss 0.0184 (0.0213)	Prec@1 100.000 (99.732)	
Total train loss: 0.0213

Train time: 24.42840027809143
 * Prec@1 90.970 Prec@5 99.540 Loss 0.3521
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 27.76821732521057

Epoch: [55][77/391]	LR: 2.0000000000000004e-07	Loss 0.0298 (0.0217)	Prec@1 100.000 (99.690)	
Epoch: [55][155/391]	LR: 2.0000000000000004e-07	Loss 0.0209 (0.0204)	Prec@1 100.000 (99.740)	
Epoch: [55][233/391]	LR: 2.0000000000000004e-07	Loss 0.0202 (0.0207)	Prec@1 99.219 (99.730)	
Epoch: [55][311/391]	LR: 2.0000000000000004e-07	Loss 0.0119 (0.0209)	Prec@1 100.000 (99.720)	
Epoch: [55][389/391]	LR: 2.0000000000000004e-07	Loss 0.0192 (0.0209)	Prec@1 100.000 (99.722)	
Total train loss: 0.0210

Train time: 19.88696527481079
 * Prec@1 90.770 Prec@5 99.530 Loss 0.3513
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 22.351139783859253

Epoch: [56][77/391]	LR: 2.0000000000000004e-07	Loss 0.0312 (0.0210)	Prec@1 99.219 (99.770)	
Epoch: [56][155/391]	LR: 2.0000000000000004e-07	Loss 0.0162 (0.0218)	Prec@1 100.000 (99.725)	
Epoch: [56][233/391]	LR: 2.0000000000000004e-07	Loss 0.0225 (0.0216)	Prec@1 100.000 (99.723)	
Epoch: [56][311/391]	LR: 2.0000000000000004e-07	Loss 0.0231 (0.0208)	Prec@1 100.000 (99.755)	
Epoch: [56][389/391]	LR: 2.0000000000000004e-07	Loss 0.0084 (0.0210)	Prec@1 100.000 (99.726)	
Total train loss: 0.0211

Train time: 17.00491166114807
 * Prec@1 90.880 Prec@5 99.540 Loss 0.3508
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.09718918800354

Epoch: [57][77/391]	LR: 2.0000000000000004e-07	Loss 0.0312 (0.0216)	Prec@1 99.219 (99.679)	
Epoch: [57][155/391]	LR: 2.0000000000000004e-07	Loss 0.0223 (0.0218)	Prec@1 99.219 (99.735)	
Epoch: [57][233/391]	LR: 2.0000000000000004e-07	Loss 0.0223 (0.0216)	Prec@1 100.000 (99.743)	
Epoch: [57][311/391]	LR: 2.0000000000000004e-07	Loss 0.0161 (0.0219)	Prec@1 100.000 (99.732)	
Epoch: [57][389/391]	LR: 2.0000000000000004e-07	Loss 0.0278 (0.0217)	Prec@1 100.000 (99.728)	
Total train loss: 0.0217

Train time: 17.457072019577026
 * Prec@1 91.000 Prec@5 99.540 Loss 0.3484
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 20.815983772277832

Epoch: [58][77/391]	LR: 2.0000000000000004e-07	Loss 0.0132 (0.0210)	Prec@1 100.000 (99.730)	
Epoch: [58][155/391]	LR: 2.0000000000000004e-07	Loss 0.0179 (0.0210)	Prec@1 100.000 (99.715)	
Epoch: [58][233/391]	LR: 2.0000000000000004e-07	Loss 0.0147 (0.0210)	Prec@1 100.000 (99.716)	
Epoch: [58][311/391]	LR: 2.0000000000000004e-07	Loss 0.0222 (0.0211)	Prec@1 100.000 (99.722)	
Epoch: [58][389/391]	LR: 2.0000000000000004e-07	Loss 0.0174 (0.0210)	Prec@1 100.000 (99.732)	
Total train loss: 0.0210

Train time: 18.088154554367065
 * Prec@1 91.060 Prec@5 99.550 Loss 0.3474
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 23.091641187667847

Epoch: [59][77/391]	LR: 2.0000000000000004e-07	Loss 0.0168 (0.0189)	Prec@1 100.000 (99.820)	
Epoch: [59][155/391]	LR: 2.0000000000000004e-07	Loss 0.0468 (0.0200)	Prec@1 98.438 (99.815)	
Epoch: [59][233/391]	LR: 2.0000000000000004e-07	Loss 0.0281 (0.0200)	Prec@1 99.219 (99.806)	
Epoch: [59][311/391]	LR: 2.0000000000000004e-07	Loss 0.0105 (0.0202)	Prec@1 100.000 (99.787)	
Epoch: [59][389/391]	LR: 2.0000000000000004e-07	Loss 0.0133 (0.0202)	Prec@1 100.000 (99.782)	
Total train loss: 0.0203

Train time: 18.209107637405396
 * Prec@1 91.120 Prec@5 99.550 Loss 0.3484
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 20.5865261554718


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/
          savedir: ../pretrained_models/frozen/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 60
          start_epoch: 0
          batch_size: 128
          lr: 0.002
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 7
          af_bit: 4
          w_bit: 7
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          exp: x128-8b
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 7
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 88.840 Prec@5 99.480 Loss 0.4268
Pre-trained Prec@1 with 7 layers frozen: 88.83999633789062 	 Loss: 0.4267578125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.002	Loss 0.0494 (0.0715)	Prec@1 99.219 (97.646)	
Epoch: [0][155/391]	LR: 0.002	Loss 0.0776 (0.0705)	Prec@1 97.656 (97.666)	
Epoch: [0][233/391]	LR: 0.002	Loss 0.0806 (0.0682)	Prec@1 96.094 (97.793)	
Epoch: [0][311/391]	LR: 0.002	Loss 0.0504 (0.0660)	Prec@1 98.438 (97.884)	
Epoch: [0][389/391]	LR: 0.002	Loss 0.0823 (0.0659)	Prec@1 96.094 (97.845)	
Total train loss: 0.0659

Train time: 80.52222728729248
 * Prec@1 91.170 Prec@5 99.580 Loss 0.3308
Best acc: 91.170
--------------------------------------------------------------------------------
Test time: 84.14176964759827

Epoch: [1][77/391]	LR: 0.002	Loss 0.0452 (0.0511)	Prec@1 98.438 (98.488)	
Epoch: [1][155/391]	LR: 0.002	Loss 0.0975 (0.0524)	Prec@1 96.094 (98.342)	
Epoch: [1][233/391]	LR: 0.002	Loss 0.0389 (0.0532)	Prec@1 98.438 (98.324)	
Epoch: [1][311/391]	LR: 0.002	Loss 0.0651 (0.0532)	Prec@1 97.656 (98.322)	
Epoch: [1][389/391]	LR: 0.002	Loss 0.0311 (0.0523)	Prec@1 100.000 (98.375)	
Total train loss: 0.0522

Train time: 20.119571208953857
 * Prec@1 91.190 Prec@5 99.570 Loss 0.3328
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.720245361328125

Epoch: [2][77/391]	LR: 0.002	Loss 0.0519 (0.0464)	Prec@1 99.219 (98.618)	
Epoch: [2][155/391]	LR: 0.002	Loss 0.0585 (0.0459)	Prec@1 96.875 (98.638)	
Epoch: [2][233/391]	LR: 0.002	Loss 0.0453 (0.0460)	Prec@1 99.219 (98.634)	
Epoch: [2][311/391]	LR: 0.002	Loss 0.0266 (0.0469)	Prec@1 99.219 (98.608)	
Epoch: [2][389/391]	LR: 0.002	Loss 0.0184 (0.0470)	Prec@1 100.000 (98.596)	
Total train loss: 0.0470

Train time: 19.202101469039917
 * Prec@1 90.970 Prec@5 99.610 Loss 0.3379
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.45159673690796

Epoch: [3][77/391]	LR: 0.002	Loss 0.0410 (0.0419)	Prec@1 98.438 (99.018)	
Epoch: [3][155/391]	LR: 0.002	Loss 0.0463 (0.0430)	Prec@1 99.219 (98.848)	
Epoch: [3][233/391]	LR: 0.002	Loss 0.0346 (0.0433)	Prec@1 99.219 (98.815)	
Epoch: [3][311/391]	LR: 0.002	Loss 0.0909 (0.0436)	Prec@1 96.875 (98.806)	
Epoch: [3][389/391]	LR: 0.002	Loss 0.0344 (0.0437)	Prec@1 98.438 (98.806)	
Total train loss: 0.0437

Train time: 18.71820569038391
 * Prec@1 91.060 Prec@5 99.580 Loss 0.3386
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.468302488327026

Epoch: [4][77/391]	LR: 0.002	Loss 0.0314 (0.0370)	Prec@1 100.000 (99.139)	
Epoch: [4][155/391]	LR: 0.002	Loss 0.0321 (0.0383)	Prec@1 99.219 (99.028)	
Epoch: [4][233/391]	LR: 0.002	Loss 0.0608 (0.0387)	Prec@1 97.656 (98.972)	
Epoch: [4][311/391]	LR: 0.002	Loss 0.0257 (0.0391)	Prec@1 100.000 (98.986)	
Epoch: [4][389/391]	LR: 0.002	Loss 0.1116 (0.0394)	Prec@1 95.312 (98.968)	
Total train loss: 0.0395

Train time: 19.42339539527893
 * Prec@1 91.050 Prec@5 99.570 Loss 0.3391
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.001276969909668

Epoch: [5][77/391]	LR: 0.002	Loss 0.0801 (0.0373)	Prec@1 96.875 (99.038)	
Epoch: [5][155/391]	LR: 0.002	Loss 0.0693 (0.0383)	Prec@1 98.438 (99.013)	
Epoch: [5][233/391]	LR: 0.002	Loss 0.0318 (0.0378)	Prec@1 100.000 (99.052)	
Epoch: [5][311/391]	LR: 0.002	Loss 0.0350 (0.0378)	Prec@1 100.000 (99.048)	
Epoch: [5][389/391]	LR: 0.002	Loss 0.0555 (0.0381)	Prec@1 98.438 (99.052)	
Total train loss: 0.0380

Train time: 18.898725986480713
 * Prec@1 91.020 Prec@5 99.570 Loss 0.3369
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.403577089309692

Epoch: [6][77/391]	LR: 0.002	Loss 0.0336 (0.0359)	Prec@1 99.219 (99.109)	
Epoch: [6][155/391]	LR: 0.002	Loss 0.0519 (0.0357)	Prec@1 97.656 (99.149)	
Epoch: [6][233/391]	LR: 0.002	Loss 0.0233 (0.0351)	Prec@1 100.000 (99.169)	
Epoch: [6][311/391]	LR: 0.002	Loss 0.0232 (0.0353)	Prec@1 100.000 (99.151)	
Epoch: [6][389/391]	LR: 0.002	Loss 0.0756 (0.0357)	Prec@1 97.656 (99.137)	
Total train loss: 0.0358

Train time: 18.77214002609253
 * Prec@1 90.970 Prec@5 99.560 Loss 0.3430
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.285386085510254

Epoch: [7][77/391]	LR: 0.002	Loss 0.0605 (0.0342)	Prec@1 98.438 (99.249)	
Epoch: [7][155/391]	LR: 0.002	Loss 0.0665 (0.0346)	Prec@1 97.656 (99.214)	
Epoch: [7][233/391]	LR: 0.002	Loss 0.0225 (0.0352)	Prec@1 100.000 (99.205)	
Epoch: [7][311/391]	LR: 0.002	Loss 0.0314 (0.0344)	Prec@1 99.219 (99.221)	
Epoch: [7][389/391]	LR: 0.002	Loss 0.0240 (0.0345)	Prec@1 99.219 (99.245)	
Total train loss: 0.0346

Train time: 19.792104959487915
 * Prec@1 90.880 Prec@5 99.560 Loss 0.3425
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.368218898773193

Epoch: [8][77/391]	LR: 0.002	Loss 0.0414 (0.0337)	Prec@1 99.219 (99.229)	
Epoch: [8][155/391]	LR: 0.002	Loss 0.0341 (0.0326)	Prec@1 98.438 (99.294)	
Epoch: [8][233/391]	LR: 0.002	Loss 0.0202 (0.0317)	Prec@1 100.000 (99.322)	
Epoch: [8][311/391]	LR: 0.002	Loss 0.0211 (0.0317)	Prec@1 100.000 (99.324)	
Epoch: [8][389/391]	LR: 0.002	Loss 0.0321 (0.0322)	Prec@1 99.219 (99.305)	
Total train loss: 0.0322

Train time: 18.857696294784546
 * Prec@1 90.930 Prec@5 99.560 Loss 0.3440
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.713810682296753

Epoch: [9][77/391]	LR: 0.002	Loss 0.0323 (0.0281)	Prec@1 100.000 (99.439)	
Epoch: [9][155/391]	LR: 0.002	Loss 0.0237 (0.0286)	Prec@1 100.000 (99.424)	
Epoch: [9][233/391]	LR: 0.002	Loss 0.0210 (0.0281)	Prec@1 100.000 (99.446)	
Epoch: [9][311/391]	LR: 0.002	Loss 0.0269 (0.0287)	Prec@1 99.219 (99.442)	
Epoch: [9][389/391]	LR: 0.002	Loss 0.0325 (0.0290)	Prec@1 99.219 (99.437)	
Total train loss: 0.0290

Train time: 18.68117666244507
 * Prec@1 90.910 Prec@5 99.540 Loss 0.3413
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.28741192817688

Epoch: [10][77/391]	LR: 0.002	Loss 0.0440 (0.0275)	Prec@1 99.219 (99.539)	
Epoch: [10][155/391]	LR: 0.002	Loss 0.0488 (0.0295)	Prec@1 98.438 (99.424)	
Epoch: [10][233/391]	LR: 0.002	Loss 0.0151 (0.0299)	Prec@1 100.000 (99.406)	
Epoch: [10][311/391]	LR: 0.002	Loss 0.0193 (0.0296)	Prec@1 100.000 (99.429)	
Epoch: [10][389/391]	LR: 0.002	Loss 0.0434 (0.0292)	Prec@1 99.219 (99.447)	
Total train loss: 0.0292

Train time: 19.86864137649536
 * Prec@1 90.910 Prec@5 99.550 Loss 0.3459
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.679028749465942

Epoch: [11][77/391]	LR: 0.002	Loss 0.0217 (0.0304)	Prec@1 99.219 (99.399)	
Epoch: [11][155/391]	LR: 0.002	Loss 0.0235 (0.0294)	Prec@1 100.000 (99.444)	
Epoch: [11][233/391]	LR: 0.002	Loss 0.0110 (0.0298)	Prec@1 100.000 (99.429)	
Epoch: [11][311/391]	LR: 0.002	Loss 0.0552 (0.0297)	Prec@1 98.438 (99.449)	
Epoch: [11][389/391]	LR: 0.002	Loss 0.0207 (0.0296)	Prec@1 100.000 (99.455)	
Total train loss: 0.0296

Train time: 22.998944520950317
 * Prec@1 90.800 Prec@5 99.540 Loss 0.3538
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 25.73631262779236

Epoch: [12][77/391]	LR: 0.002	Loss 0.0191 (0.0280)	Prec@1 100.000 (99.529)	
Epoch: [12][155/391]	LR: 0.002	Loss 0.0099 (0.0271)	Prec@1 100.000 (99.539)	
Epoch: [12][233/391]	LR: 0.002	Loss 0.0208 (0.0268)	Prec@1 100.000 (99.553)	
Epoch: [12][311/391]	LR: 0.002	Loss 0.0305 (0.0278)	Prec@1 99.219 (99.514)	
Epoch: [12][389/391]	LR: 0.002	Loss 0.0794 (0.0275)	Prec@1 98.438 (99.535)	
Total train loss: 0.0275

Train time: 19.222447872161865
 * Prec@1 90.880 Prec@5 99.550 Loss 0.3518
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.69378662109375

Epoch: [13][77/391]	LR: 0.002	Loss 0.0132 (0.0249)	Prec@1 100.000 (99.659)	
Epoch: [13][155/391]	LR: 0.002	Loss 0.0441 (0.0256)	Prec@1 97.656 (99.629)	
Epoch: [13][233/391]	LR: 0.002	Loss 0.0114 (0.0259)	Prec@1 100.000 (99.609)	
Epoch: [13][311/391]	LR: 0.002	Loss 0.0256 (0.0256)	Prec@1 100.000 (99.629)	
Epoch: [13][389/391]	LR: 0.002	Loss 0.0214 (0.0261)	Prec@1 100.000 (99.587)	
Total train loss: 0.0261

Train time: 19.36092257499695
 * Prec@1 90.820 Prec@5 99.560 Loss 0.3506
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.508347988128662

Epoch: [14][77/391]	LR: 0.002	Loss 0.0152 (0.0268)	Prec@1 100.000 (99.529)	
Epoch: [14][155/391]	LR: 0.002	Loss 0.0156 (0.0271)	Prec@1 100.000 (99.524)	
Epoch: [14][233/391]	LR: 0.002	Loss 0.0592 (0.0277)	Prec@1 98.438 (99.523)	
Epoch: [14][311/391]	LR: 0.002	Loss 0.0341 (0.0269)	Prec@1 98.438 (99.552)	
Epoch: [14][389/391]	LR: 0.002	Loss 0.0216 (0.0267)	Prec@1 100.000 (99.543)	
Total train loss: 0.0268

Train time: 18.99673295021057
 * Prec@1 90.900 Prec@5 99.560 Loss 0.3501
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.38697338104248

Epoch: [15][77/391]	LR: 0.002	Loss 0.0277 (0.0249)	Prec@1 100.000 (99.649)	
Epoch: [15][155/391]	LR: 0.002	Loss 0.0389 (0.0250)	Prec@1 99.219 (99.634)	
Epoch: [15][233/391]	LR: 0.002	Loss 0.0126 (0.0253)	Prec@1 100.000 (99.626)	
Epoch: [15][311/391]	LR: 0.002	Loss 0.0175 (0.0255)	Prec@1 100.000 (99.607)	
Epoch: [15][389/391]	LR: 0.002	Loss 0.0411 (0.0254)	Prec@1 98.438 (99.599)	
Total train loss: 0.0254

Train time: 19.161408185958862
 * Prec@1 90.880 Prec@5 99.560 Loss 0.3496
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.18320345878601

Epoch: [16][77/391]	LR: 0.002	Loss 0.0122 (0.0225)	Prec@1 100.000 (99.700)	
Epoch: [16][155/391]	LR: 0.002	Loss 0.0401 (0.0236)	Prec@1 99.219 (99.669)	
Epoch: [16][233/391]	LR: 0.002	Loss 0.0166 (0.0239)	Prec@1 100.000 (99.666)	
Epoch: [16][311/391]	LR: 0.002	Loss 0.0298 (0.0252)	Prec@1 99.219 (99.594)	
Epoch: [16][389/391]	LR: 0.002	Loss 0.0233 (0.0252)	Prec@1 100.000 (99.603)	
Total train loss: 0.0252

Train time: 19.484509229660034
 * Prec@1 90.960 Prec@5 99.550 Loss 0.3486
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.056363105773926

Epoch: [17][77/391]	LR: 0.002	Loss 0.0335 (0.0230)	Prec@1 98.438 (99.679)	
Epoch: [17][155/391]	LR: 0.002	Loss 0.0158 (0.0226)	Prec@1 100.000 (99.710)	
Epoch: [17][233/391]	LR: 0.002	Loss 0.0217 (0.0227)	Prec@1 100.000 (99.723)	
Epoch: [17][311/391]	LR: 0.002	Loss 0.0374 (0.0228)	Prec@1 98.438 (99.715)	
Epoch: [17][389/391]	LR: 0.002	Loss 0.0334 (0.0235)	Prec@1 100.000 (99.692)	
Total train loss: 0.0235

Train time: 19.885977506637573
 * Prec@1 90.970 Prec@5 99.570 Loss 0.3511
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.290517568588257

Epoch: [18][77/391]	LR: 0.002	Loss 0.0153 (0.0236)	Prec@1 100.000 (99.619)	
Epoch: [18][155/391]	LR: 0.002	Loss 0.0205 (0.0242)	Prec@1 100.000 (99.599)	
Epoch: [18][233/391]	LR: 0.002	Loss 0.0414 (0.0236)	Prec@1 98.438 (99.633)	
Epoch: [18][311/391]	LR: 0.002	Loss 0.0356 (0.0239)	Prec@1 99.219 (99.622)	
Epoch: [18][389/391]	LR: 0.002	Loss 0.0193 (0.0234)	Prec@1 100.000 (99.637)	
Total train loss: 0.0234

Train time: 18.349106311798096
 * Prec@1 90.820 Prec@5 99.520 Loss 0.3560
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.588948965072632

Epoch: [19][77/391]	LR: 0.002	Loss 0.0183 (0.0221)	Prec@1 100.000 (99.690)	
Epoch: [19][155/391]	LR: 0.002	Loss 0.0188 (0.0232)	Prec@1 100.000 (99.639)	
Epoch: [19][233/391]	LR: 0.002	Loss 0.0151 (0.0236)	Prec@1 100.000 (99.626)	
Epoch: [19][311/391]	LR: 0.002	Loss 0.0295 (0.0230)	Prec@1 99.219 (99.679)	
Epoch: [19][389/391]	LR: 0.002	Loss 0.0269 (0.0231)	Prec@1 99.219 (99.694)	
Total train loss: 0.0231

Train time: 18.568126916885376
 * Prec@1 91.030 Prec@5 99.510 Loss 0.3545
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.731419324874878

Epoch: [20][77/391]	LR: 0.0002	Loss 0.0130 (0.0229)	Prec@1 100.000 (99.700)	
Epoch: [20][155/391]	LR: 0.0002	Loss 0.0245 (0.0222)	Prec@1 100.000 (99.740)	
Epoch: [20][233/391]	LR: 0.0002	Loss 0.0161 (0.0225)	Prec@1 100.000 (99.706)	
Epoch: [20][311/391]	LR: 0.0002	Loss 0.0155 (0.0225)	Prec@1 100.000 (99.715)	
Epoch: [20][389/391]	LR: 0.0002	Loss 0.0226 (0.0225)	Prec@1 100.000 (99.704)	
Total train loss: 0.0226

Train time: 19.37494993209839
 * Prec@1 90.820 Prec@5 99.520 Loss 0.3533
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.483755350112915

Epoch: [21][77/391]	LR: 0.0002	Loss 0.0147 (0.0228)	Prec@1 100.000 (99.629)	
Epoch: [21][155/391]	LR: 0.0002	Loss 0.0123 (0.0224)	Prec@1 100.000 (99.664)	
Epoch: [21][233/391]	LR: 0.0002	Loss 0.0307 (0.0223)	Prec@1 100.000 (99.686)	
Epoch: [21][311/391]	LR: 0.0002	Loss 0.0291 (0.0229)	Prec@1 100.000 (99.677)	
Epoch: [21][389/391]	LR: 0.0002	Loss 0.0194 (0.0222)	Prec@1 100.000 (99.696)	
Total train loss: 0.0222

Train time: 18.04170536994934
 * Prec@1 90.850 Prec@5 99.570 Loss 0.3550
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 20.17611265182495

Epoch: [22][77/391]	LR: 0.0002	Loss 0.0105 (0.0213)	Prec@1 100.000 (99.750)	
Epoch: [22][155/391]	LR: 0.0002	Loss 0.0241 (0.0211)	Prec@1 99.219 (99.790)	
Epoch: [22][233/391]	LR: 0.0002	Loss 0.0317 (0.0205)	Prec@1 98.438 (99.790)	
Epoch: [22][311/391]	LR: 0.0002	Loss 0.0091 (0.0205)	Prec@1 100.000 (99.795)	
Epoch: [22][389/391]	LR: 0.0002	Loss 0.0125 (0.0208)	Prec@1 100.000 (99.772)	
Total train loss: 0.0209

Train time: 18.82450580596924
 * Prec@1 90.870 Prec@5 99.560 Loss 0.3572
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.57667303085327

Epoch: [23][77/391]	LR: 0.0002	Loss 0.0294 (0.0212)	Prec@1 100.000 (99.770)	
Epoch: [23][155/391]	LR: 0.0002	Loss 0.0519 (0.0224)	Prec@1 99.219 (99.700)	
Epoch: [23][233/391]	LR: 0.0002	Loss 0.0374 (0.0226)	Prec@1 99.219 (99.696)	
Epoch: [23][311/391]	LR: 0.0002	Loss 0.0271 (0.0225)	Prec@1 100.000 (99.707)	
Epoch: [23][389/391]	LR: 0.0002	Loss 0.0087 (0.0221)	Prec@1 100.000 (99.704)	
Total train loss: 0.0221

Train time: 18.504855394363403
 * Prec@1 90.940 Prec@5 99.540 Loss 0.3530
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.007850170135498

Epoch: [24][77/391]	LR: 0.0002	Loss 0.0101 (0.0222)	Prec@1 100.000 (99.710)	
Epoch: [24][155/391]	LR: 0.0002	Loss 0.0150 (0.0225)	Prec@1 100.000 (99.725)	
Epoch: [24][233/391]	LR: 0.0002	Loss 0.0123 (0.0229)	Prec@1 100.000 (99.700)	
Epoch: [24][311/391]	LR: 0.0002	Loss 0.0173 (0.0225)	Prec@1 100.000 (99.720)	
Epoch: [24][389/391]	LR: 0.0002	Loss 0.0287 (0.0224)	Prec@1 99.219 (99.702)	
Total train loss: 0.0224

Train time: 18.00919222831726
 * Prec@1 90.890 Prec@5 99.500 Loss 0.3521
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.174437284469604

Epoch: [25][77/391]	LR: 0.0002	Loss 0.0238 (0.0206)	Prec@1 99.219 (99.740)	
Epoch: [25][155/391]	LR: 0.0002	Loss 0.0239 (0.0213)	Prec@1 100.000 (99.710)	
Epoch: [25][233/391]	LR: 0.0002	Loss 0.0149 (0.0210)	Prec@1 100.000 (99.733)	
Epoch: [25][311/391]	LR: 0.0002	Loss 0.0254 (0.0210)	Prec@1 100.000 (99.735)	
Epoch: [25][389/391]	LR: 0.0002	Loss 0.0260 (0.0211)	Prec@1 100.000 (99.736)	
Total train loss: 0.0211

Train time: 19.028844356536865
 * Prec@1 90.920 Prec@5 99.550 Loss 0.3535
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.848217964172363

Epoch: [26][77/391]	LR: 0.0002	Loss 0.0143 (0.0220)	Prec@1 100.000 (99.720)	
Epoch: [26][155/391]	LR: 0.0002	Loss 0.0156 (0.0217)	Prec@1 100.000 (99.740)	
Epoch: [26][233/391]	LR: 0.0002	Loss 0.0196 (0.0214)	Prec@1 100.000 (99.760)	
Epoch: [26][311/391]	LR: 0.0002	Loss 0.0245 (0.0218)	Prec@1 100.000 (99.747)	
Epoch: [26][389/391]	LR: 0.0002	Loss 0.0218 (0.0223)	Prec@1 100.000 (99.730)	
Total train loss: 0.0223

Train time: 18.992034435272217
 * Prec@1 90.860 Prec@5 99.540 Loss 0.3562
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.025378942489624

Epoch: [27][77/391]	LR: 0.0002	Loss 0.0272 (0.0224)	Prec@1 99.219 (99.710)	
Epoch: [27][155/391]	LR: 0.0002	Loss 0.0320 (0.0221)	Prec@1 100.000 (99.720)	
Epoch: [27][233/391]	LR: 0.0002	Loss 0.0338 (0.0217)	Prec@1 100.000 (99.733)	
Epoch: [27][311/391]	LR: 0.0002	Loss 0.0163 (0.0217)	Prec@1 100.000 (99.742)	
Epoch: [27][389/391]	LR: 0.0002	Loss 0.0169 (0.0220)	Prec@1 100.000 (99.738)	
Total train loss: 0.0219

Train time: 18.855462789535522
 * Prec@1 91.020 Prec@5 99.550 Loss 0.3508
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.026926279067993

Epoch: [28][77/391]	LR: 0.0002	Loss 0.0177 (0.0200)	Prec@1 100.000 (99.830)	
Epoch: [28][155/391]	LR: 0.0002	Loss 0.0132 (0.0205)	Prec@1 100.000 (99.800)	
Epoch: [28][233/391]	LR: 0.0002	Loss 0.0269 (0.0209)	Prec@1 100.000 (99.786)	
Epoch: [28][311/391]	LR: 0.0002	Loss 0.0236 (0.0216)	Prec@1 100.000 (99.742)	
Epoch: [28][389/391]	LR: 0.0002	Loss 0.0161 (0.0217)	Prec@1 100.000 (99.740)	
Total train loss: 0.0217

Train time: 18.696476221084595
 * Prec@1 90.920 Prec@5 99.520 Loss 0.3540
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.979604959487915

Epoch: [29][77/391]	LR: 0.0002	Loss 0.0118 (0.0238)	Prec@1 100.000 (99.629)	
Epoch: [29][155/391]	LR: 0.0002	Loss 0.0234 (0.0231)	Prec@1 100.000 (99.639)	
Epoch: [29][233/391]	LR: 0.0002	Loss 0.0208 (0.0227)	Prec@1 100.000 (99.673)	
Epoch: [29][311/391]	LR: 0.0002	Loss 0.0202 (0.0225)	Prec@1 99.219 (99.664)	
Epoch: [29][389/391]	LR: 0.0002	Loss 0.0168 (0.0220)	Prec@1 100.000 (99.685)	
Total train loss: 0.0220

Train time: 19.241868019104004
 * Prec@1 90.880 Prec@5 99.550 Loss 0.3513
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.684300899505615

Epoch: [30][77/391]	LR: 2e-05	Loss 0.0135 (0.0206)	Prec@1 100.000 (99.860)	
Epoch: [30][155/391]	LR: 2e-05	Loss 0.0198 (0.0211)	Prec@1 100.000 (99.785)	
Epoch: [30][233/391]	LR: 2e-05	Loss 0.0210 (0.0217)	Prec@1 100.000 (99.740)	
Epoch: [30][311/391]	LR: 2e-05	Loss 0.0141 (0.0217)	Prec@1 100.000 (99.757)	
Epoch: [30][389/391]	LR: 2e-05	Loss 0.0292 (0.0216)	Prec@1 99.219 (99.756)	
Total train loss: 0.0216

Train time: 18.709259033203125
 * Prec@1 90.840 Prec@5 99.530 Loss 0.3521
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.767658472061157

Epoch: [31][77/391]	LR: 2e-05	Loss 0.0214 (0.0206)	Prec@1 100.000 (99.740)	
Epoch: [31][155/391]	LR: 2e-05	Loss 0.0275 (0.0210)	Prec@1 99.219 (99.730)	
Epoch: [31][233/391]	LR: 2e-05	Loss 0.0174 (0.0222)	Prec@1 100.000 (99.693)	
Epoch: [31][311/391]	LR: 2e-05	Loss 0.0181 (0.0220)	Prec@1 100.000 (99.710)	
Epoch: [31][389/391]	LR: 2e-05	Loss 0.0223 (0.0219)	Prec@1 100.000 (99.728)	
Total train loss: 0.0220

Train time: 23.01346516609192
 * Prec@1 90.910 Prec@5 99.540 Loss 0.3521
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 25.574443101882935

Epoch: [32][77/391]	LR: 2e-05	Loss 0.0246 (0.0225)	Prec@1 99.219 (99.700)	
Epoch: [32][155/391]	LR: 2e-05	Loss 0.0371 (0.0221)	Prec@1 99.219 (99.690)	
Epoch: [32][233/391]	LR: 2e-05	Loss 0.0235 (0.0228)	Prec@1 100.000 (99.676)	
Epoch: [32][311/391]	LR: 2e-05	Loss 0.0207 (0.0226)	Prec@1 100.000 (99.677)	
Epoch: [32][389/391]	LR: 2e-05	Loss 0.0165 (0.0221)	Prec@1 100.000 (99.706)	
Total train loss: 0.0221

Train time: 19.51448082923889
 * Prec@1 90.940 Prec@5 99.540 Loss 0.3530
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.72529911994934

Epoch: [33][77/391]	LR: 2e-05	Loss 0.0124 (0.0201)	Prec@1 100.000 (99.760)	
Epoch: [33][155/391]	LR: 2e-05	Loss 0.0288 (0.0211)	Prec@1 100.000 (99.725)	
Epoch: [33][233/391]	LR: 2e-05	Loss 0.0197 (0.0217)	Prec@1 100.000 (99.726)	
Epoch: [33][311/391]	LR: 2e-05	Loss 0.0269 (0.0221)	Prec@1 99.219 (99.692)	
Epoch: [33][389/391]	LR: 2e-05	Loss 0.0273 (0.0218)	Prec@1 99.219 (99.712)	
Total train loss: 0.0218

Train time: 18.829224109649658
 * Prec@1 90.890 Prec@5 99.560 Loss 0.3533
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.52430248260498

Epoch: [34][77/391]	LR: 2e-05	Loss 0.0281 (0.0215)	Prec@1 99.219 (99.730)	
Epoch: [34][155/391]	LR: 2e-05	Loss 0.0169 (0.0223)	Prec@1 100.000 (99.715)	
Epoch: [34][233/391]	LR: 2e-05	Loss 0.0307 (0.0232)	Prec@1 99.219 (99.693)	
Epoch: [34][311/391]	LR: 2e-05	Loss 0.0079 (0.0229)	Prec@1 100.000 (99.707)	
Epoch: [34][389/391]	LR: 2e-05	Loss 0.0122 (0.0228)	Prec@1 100.000 (99.706)	
Total train loss: 0.0228

Train time: 18.809560298919678
 * Prec@1 90.910 Prec@5 99.570 Loss 0.3525
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.934674501419067

Epoch: [35][77/391]	LR: 2e-05	Loss 0.0167 (0.0237)	Prec@1 100.000 (99.629)	
Epoch: [35][155/391]	LR: 2e-05	Loss 0.0139 (0.0230)	Prec@1 100.000 (99.679)	
Epoch: [35][233/391]	LR: 2e-05	Loss 0.0121 (0.0225)	Prec@1 100.000 (99.693)	
Epoch: [35][311/391]	LR: 2e-05	Loss 0.0123 (0.0220)	Prec@1 100.000 (99.710)	
Epoch: [35][389/391]	LR: 2e-05	Loss 0.0122 (0.0223)	Prec@1 100.000 (99.702)	
Total train loss: 0.0223

Train time: 18.571165084838867
 * Prec@1 90.890 Prec@5 99.510 Loss 0.3506
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.035781383514404

Epoch: [36][77/391]	LR: 2e-05	Loss 0.0178 (0.0238)	Prec@1 100.000 (99.750)	
Epoch: [36][155/391]	LR: 2e-05	Loss 0.0252 (0.0227)	Prec@1 99.219 (99.740)	
Epoch: [36][233/391]	LR: 2e-05	Loss 0.0271 (0.0219)	Prec@1 98.438 (99.740)	
Epoch: [36][311/391]	LR: 2e-05	Loss 0.0137 (0.0216)	Prec@1 100.000 (99.735)	
Epoch: [36][389/391]	LR: 2e-05	Loss 0.0108 (0.0220)	Prec@1 100.000 (99.728)	
Total train loss: 0.0220

Train time: 18.69637370109558
 * Prec@1 90.960 Prec@5 99.550 Loss 0.3501
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.741135358810425

Epoch: [37][77/391]	LR: 2e-05	Loss 0.0141 (0.0214)	Prec@1 100.000 (99.800)	
Epoch: [37][155/391]	LR: 2e-05	Loss 0.0262 (0.0211)	Prec@1 100.000 (99.800)	
Epoch: [37][233/391]	LR: 2e-05	Loss 0.0341 (0.0214)	Prec@1 99.219 (99.746)	
Epoch: [37][311/391]	LR: 2e-05	Loss 0.0233 (0.0214)	Prec@1 99.219 (99.715)	
Epoch: [37][389/391]	LR: 2e-05	Loss 0.0088 (0.0215)	Prec@1 100.000 (99.720)	
Total train loss: 0.0216

Train time: 18.751902103424072
 * Prec@1 90.900 Prec@5 99.530 Loss 0.3535
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.744468688964844

Epoch: [38][77/391]	LR: 2e-05	Loss 0.0175 (0.0220)	Prec@1 100.000 (99.730)	
Epoch: [38][155/391]	LR: 2e-05	Loss 0.0240 (0.0223)	Prec@1 99.219 (99.725)	
Epoch: [38][233/391]	LR: 2e-05	Loss 0.0269 (0.0223)	Prec@1 100.000 (99.740)	
Epoch: [38][311/391]	LR: 2e-05	Loss 0.0273 (0.0217)	Prec@1 99.219 (99.740)	
Epoch: [38][389/391]	LR: 2e-05	Loss 0.0271 (0.0217)	Prec@1 99.219 (99.724)	
Total train loss: 0.0217

Train time: 17.95241689682007
 * Prec@1 91.050 Prec@5 99.530 Loss 0.3481
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 20.46493697166443

Epoch: [39][77/391]	LR: 2e-05	Loss 0.0296 (0.0217)	Prec@1 99.219 (99.720)	
Epoch: [39][155/391]	LR: 2e-05	Loss 0.0383 (0.0208)	Prec@1 98.438 (99.750)	
Epoch: [39][233/391]	LR: 2e-05	Loss 0.0175 (0.0214)	Prec@1 100.000 (99.736)	
Epoch: [39][311/391]	LR: 2e-05	Loss 0.0105 (0.0212)	Prec@1 100.000 (99.750)	
Epoch: [39][389/391]	LR: 2e-05	Loss 0.0164 (0.0210)	Prec@1 100.000 (99.744)	
Total train loss: 0.0211

Train time: 18.60742163658142
 * Prec@1 91.030 Prec@5 99.550 Loss 0.3513
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.674781560897827

Epoch: [40][77/391]	LR: 2.0000000000000003e-06	Loss 0.0155 (0.0210)	Prec@1 100.000 (99.740)	
Epoch: [40][155/391]	LR: 2.0000000000000003e-06	Loss 0.0125 (0.0218)	Prec@1 100.000 (99.715)	
Epoch: [40][233/391]	LR: 2.0000000000000003e-06	Loss 0.0248 (0.0220)	Prec@1 99.219 (99.690)	
Epoch: [40][311/391]	LR: 2.0000000000000003e-06	Loss 0.0268 (0.0217)	Prec@1 100.000 (99.720)	
Epoch: [40][389/391]	LR: 2.0000000000000003e-06	Loss 0.0239 (0.0217)	Prec@1 100.000 (99.726)	
Total train loss: 0.0216

Train time: 18.921436071395874
 * Prec@1 90.890 Prec@5 99.560 Loss 0.3547
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.134191274642944

Epoch: [41][77/391]	LR: 2.0000000000000003e-06	Loss 0.0148 (0.0217)	Prec@1 100.000 (99.750)	
Epoch: [41][155/391]	LR: 2.0000000000000003e-06	Loss 0.0230 (0.0221)	Prec@1 100.000 (99.690)	
Epoch: [41][233/391]	LR: 2.0000000000000003e-06	Loss 0.0154 (0.0223)	Prec@1 100.000 (99.676)	
Epoch: [41][311/391]	LR: 2.0000000000000003e-06	Loss 0.0096 (0.0224)	Prec@1 100.000 (99.679)	
Epoch: [41][389/391]	LR: 2.0000000000000003e-06	Loss 0.0179 (0.0224)	Prec@1 100.000 (99.679)	
Total train loss: 0.0224

Train time: 17.544160842895508
 * Prec@1 90.970 Prec@5 99.550 Loss 0.3579
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 19.530524253845215

Epoch: [42][77/391]	LR: 2.0000000000000003e-06	Loss 0.0193 (0.0213)	Prec@1 100.000 (99.750)	
Epoch: [42][155/391]	LR: 2.0000000000000003e-06	Loss 0.0125 (0.0224)	Prec@1 100.000 (99.705)	
Epoch: [42][233/391]	LR: 2.0000000000000003e-06	Loss 0.0243 (0.0223)	Prec@1 100.000 (99.706)	
Epoch: [42][311/391]	LR: 2.0000000000000003e-06	Loss 0.0494 (0.0219)	Prec@1 98.438 (99.732)	
Epoch: [42][389/391]	LR: 2.0000000000000003e-06	Loss 0.0137 (0.0216)	Prec@1 100.000 (99.740)	
Total train loss: 0.0216

Train time: 18.240434646606445
 * Prec@1 90.910 Prec@5 99.540 Loss 0.3496
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 20.55632185935974

Epoch: [43][77/391]	LR: 2.0000000000000003e-06	Loss 0.0478 (0.0208)	Prec@1 97.656 (99.790)	
Epoch: [43][155/391]	LR: 2.0000000000000003e-06	Loss 0.0246 (0.0210)	Prec@1 100.000 (99.820)	
Epoch: [43][233/391]	LR: 2.0000000000000003e-06	Loss 0.0162 (0.0208)	Prec@1 100.000 (99.803)	
Epoch: [43][311/391]	LR: 2.0000000000000003e-06	Loss 0.0157 (0.0211)	Prec@1 100.000 (99.755)	
Epoch: [43][389/391]	LR: 2.0000000000000003e-06	Loss 0.0205 (0.0215)	Prec@1 100.000 (99.744)	
Total train loss: 0.0215

Train time: 18.919841289520264
 * Prec@1 90.840 Prec@5 99.530 Loss 0.3540
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.993640422821045

Epoch: [44][77/391]	LR: 2.0000000000000003e-06	Loss 0.0260 (0.0200)	Prec@1 100.000 (99.820)	
Epoch: [44][155/391]	LR: 2.0000000000000003e-06	Loss 0.0676 (0.0212)	Prec@1 97.656 (99.780)	
Epoch: [44][233/391]	LR: 2.0000000000000003e-06	Loss 0.0125 (0.0222)	Prec@1 100.000 (99.760)	
Epoch: [44][311/391]	LR: 2.0000000000000003e-06	Loss 0.0238 (0.0223)	Prec@1 100.000 (99.730)	
Epoch: [44][389/391]	LR: 2.0000000000000003e-06	Loss 0.0169 (0.0223)	Prec@1 100.000 (99.732)	
Total train loss: 0.0223

Train time: 18.075555562973022
 * Prec@1 91.000 Prec@5 99.540 Loss 0.3521
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 20.773314476013184

Epoch: [45][77/391]	LR: 2.0000000000000003e-06	Loss 0.0239 (0.0201)	Prec@1 99.219 (99.800)	
Epoch: [45][155/391]	LR: 2.0000000000000003e-06	Loss 0.0173 (0.0207)	Prec@1 99.219 (99.755)	
Epoch: [45][233/391]	LR: 2.0000000000000003e-06	Loss 0.0156 (0.0218)	Prec@1 100.000 (99.736)	
Epoch: [45][311/391]	LR: 2.0000000000000003e-06	Loss 0.0155 (0.0220)	Prec@1 100.000 (99.735)	
Epoch: [45][389/391]	LR: 2.0000000000000003e-06	Loss 0.0239 (0.0218)	Prec@1 100.000 (99.726)	
Total train loss: 0.0221

Train time: 18.23970341682434
 * Prec@1 90.950 Prec@5 99.530 Loss 0.3545
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.451313972473145

Epoch: [46][77/391]	LR: 2.0000000000000003e-06	Loss 0.0344 (0.0199)	Prec@1 98.438 (99.770)	
Epoch: [46][155/391]	LR: 2.0000000000000003e-06	Loss 0.0152 (0.0201)	Prec@1 100.000 (99.785)	
Epoch: [46][233/391]	LR: 2.0000000000000003e-06	Loss 0.0183 (0.0206)	Prec@1 100.000 (99.776)	
Epoch: [46][311/391]	LR: 2.0000000000000003e-06	Loss 0.0226 (0.0212)	Prec@1 100.000 (99.750)	
Epoch: [46][389/391]	LR: 2.0000000000000003e-06	Loss 0.0169 (0.0216)	Prec@1 100.000 (99.738)	
Total train loss: 0.0217

Train time: 18.973132848739624
 * Prec@1 90.860 Prec@5 99.540 Loss 0.3503
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.507636547088623

Epoch: [47][77/391]	LR: 2.0000000000000003e-06	Loss 0.0240 (0.0224)	Prec@1 99.219 (99.629)	
Epoch: [47][155/391]	LR: 2.0000000000000003e-06	Loss 0.0184 (0.0223)	Prec@1 100.000 (99.684)	
Epoch: [47][233/391]	LR: 2.0000000000000003e-06	Loss 0.0239 (0.0219)	Prec@1 100.000 (99.700)	
Epoch: [47][311/391]	LR: 2.0000000000000003e-06	Loss 0.0124 (0.0219)	Prec@1 100.000 (99.715)	
Epoch: [47][389/391]	LR: 2.0000000000000003e-06	Loss 0.0249 (0.0218)	Prec@1 99.219 (99.712)	
Total train loss: 0.0220

Train time: 15.977547883987427
 * Prec@1 90.980 Prec@5 99.560 Loss 0.3579
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 18.38784909248352

Epoch: [48][77/391]	LR: 2.0000000000000003e-06	Loss 0.0125 (0.0211)	Prec@1 100.000 (99.800)	
Epoch: [48][155/391]	LR: 2.0000000000000003e-06	Loss 0.0191 (0.0213)	Prec@1 99.219 (99.770)	
Epoch: [48][233/391]	LR: 2.0000000000000003e-06	Loss 0.0169 (0.0214)	Prec@1 100.000 (99.766)	
Epoch: [48][311/391]	LR: 2.0000000000000003e-06	Loss 0.0228 (0.0217)	Prec@1 100.000 (99.742)	
Epoch: [48][389/391]	LR: 2.0000000000000003e-06	Loss 0.0325 (0.0218)	Prec@1 100.000 (99.742)	
Total train loss: 0.0218

Train time: 18.19141960144043
 * Prec@1 90.970 Prec@5 99.550 Loss 0.3577
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.184040069580078

Epoch: [49][77/391]	LR: 2.0000000000000003e-06	Loss 0.0108 (0.0207)	Prec@1 100.000 (99.790)	
Epoch: [49][155/391]	LR: 2.0000000000000003e-06	Loss 0.0226 (0.0214)	Prec@1 100.000 (99.735)	
Epoch: [49][233/391]	LR: 2.0000000000000003e-06	Loss 0.0164 (0.0211)	Prec@1 100.000 (99.756)	
Epoch: [49][311/391]	LR: 2.0000000000000003e-06	Loss 0.0218 (0.0217)	Prec@1 100.000 (99.747)	
Epoch: [49][389/391]	LR: 2.0000000000000003e-06	Loss 0.0370 (0.0216)	Prec@1 99.219 (99.744)	
Total train loss: 0.0216

Train time: 19.430055379867554
 * Prec@1 90.920 Prec@5 99.540 Loss 0.3523
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.153460264205933

Epoch: [50][77/391]	LR: 2.0000000000000004e-07	Loss 0.0137 (0.0211)	Prec@1 100.000 (99.679)	
Epoch: [50][155/391]	LR: 2.0000000000000004e-07	Loss 0.0378 (0.0215)	Prec@1 99.219 (99.725)	
Epoch: [50][233/391]	LR: 2.0000000000000004e-07	Loss 0.0288 (0.0216)	Prec@1 100.000 (99.716)	
Epoch: [50][311/391]	LR: 2.0000000000000004e-07	Loss 0.0307 (0.0216)	Prec@1 100.000 (99.710)	
Epoch: [50][389/391]	LR: 2.0000000000000004e-07	Loss 0.0215 (0.0219)	Prec@1 100.000 (99.710)	
Total train loss: 0.0220

Train time: 18.97977614402771
 * Prec@1 90.930 Prec@5 99.530 Loss 0.3535
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 20.982179164886475

Epoch: [51][77/391]	LR: 2.0000000000000004e-07	Loss 0.0308 (0.0223)	Prec@1 100.000 (99.740)	
Epoch: [51][155/391]	LR: 2.0000000000000004e-07	Loss 0.0259 (0.0229)	Prec@1 100.000 (99.755)	
Epoch: [51][233/391]	LR: 2.0000000000000004e-07	Loss 0.0403 (0.0224)	Prec@1 99.219 (99.753)	
Epoch: [51][311/391]	LR: 2.0000000000000004e-07	Loss 0.0196 (0.0223)	Prec@1 100.000 (99.740)	
Epoch: [51][389/391]	LR: 2.0000000000000004e-07	Loss 0.0208 (0.0221)	Prec@1 99.219 (99.736)	
Total train loss: 0.0221

Train time: 21.820670127868652
 * Prec@1 90.960 Prec@5 99.550 Loss 0.3508
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 23.988478422164917

Epoch: [52][77/391]	LR: 2.0000000000000004e-07	Loss 0.0119 (0.0208)	Prec@1 100.000 (99.790)	
Epoch: [52][155/391]	LR: 2.0000000000000004e-07	Loss 0.0348 (0.0205)	Prec@1 99.219 (99.785)	
Epoch: [52][233/391]	LR: 2.0000000000000004e-07	Loss 0.0155 (0.0209)	Prec@1 100.000 (99.763)	
Epoch: [52][311/391]	LR: 2.0000000000000004e-07	Loss 0.0119 (0.0214)	Prec@1 100.000 (99.740)	
Epoch: [52][389/391]	LR: 2.0000000000000004e-07	Loss 0.0092 (0.0213)	Prec@1 100.000 (99.734)	
Total train loss: 0.0214

Train time: 18.96782636642456
 * Prec@1 90.990 Prec@5 99.520 Loss 0.3513
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 22.122854948043823

Epoch: [53][77/391]	LR: 2.0000000000000004e-07	Loss 0.0333 (0.0219)	Prec@1 99.219 (99.730)	
Epoch: [53][155/391]	LR: 2.0000000000000004e-07	Loss 0.0218 (0.0225)	Prec@1 100.000 (99.695)	
Epoch: [53][233/391]	LR: 2.0000000000000004e-07	Loss 0.0157 (0.0223)	Prec@1 100.000 (99.703)	
Epoch: [53][311/391]	LR: 2.0000000000000004e-07	Loss 0.0151 (0.0224)	Prec@1 100.000 (99.702)	
Epoch: [53][389/391]	LR: 2.0000000000000004e-07	Loss 0.0190 (0.0223)	Prec@1 100.000 (99.698)	
Total train loss: 0.0223

Train time: 18.19615411758423
 * Prec@1 90.870 Prec@5 99.570 Loss 0.3506
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 20.636924028396606

Epoch: [54][77/391]	LR: 2.0000000000000004e-07	Loss 0.0149 (0.0217)	Prec@1 100.000 (99.720)	
Epoch: [54][155/391]	LR: 2.0000000000000004e-07	Loss 0.0149 (0.0228)	Prec@1 100.000 (99.669)	
Epoch: [54][233/391]	LR: 2.0000000000000004e-07	Loss 0.0250 (0.0224)	Prec@1 99.219 (99.703)	
Epoch: [54][311/391]	LR: 2.0000000000000004e-07	Loss 0.0206 (0.0222)	Prec@1 100.000 (99.695)	
Epoch: [54][389/391]	LR: 2.0000000000000004e-07	Loss 0.0201 (0.0222)	Prec@1 100.000 (99.700)	
Total train loss: 0.0222

Train time: 18.21438694000244
 * Prec@1 91.050 Prec@5 99.530 Loss 0.3540
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.091801404953003

Epoch: [55][77/391]	LR: 2.0000000000000004e-07	Loss 0.0376 (0.0228)	Prec@1 98.438 (99.629)	
Epoch: [55][155/391]	LR: 2.0000000000000004e-07	Loss 0.0256 (0.0228)	Prec@1 100.000 (99.664)	
Epoch: [55][233/391]	LR: 2.0000000000000004e-07	Loss 0.0212 (0.0221)	Prec@1 100.000 (99.693)	
Epoch: [55][311/391]	LR: 2.0000000000000004e-07	Loss 0.0221 (0.0228)	Prec@1 99.219 (99.672)	
Epoch: [55][389/391]	LR: 2.0000000000000004e-07	Loss 0.0424 (0.0223)	Prec@1 98.438 (99.692)	
Total train loss: 0.0223

Train time: 17.72451615333557
 * Prec@1 90.940 Prec@5 99.540 Loss 0.3523
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 20.572092056274414

Epoch: [56][77/391]	LR: 2.0000000000000004e-07	Loss 0.0273 (0.0213)	Prec@1 100.000 (99.760)	
Epoch: [56][155/391]	LR: 2.0000000000000004e-07	Loss 0.0239 (0.0214)	Prec@1 100.000 (99.765)	
Epoch: [56][233/391]	LR: 2.0000000000000004e-07	Loss 0.0109 (0.0214)	Prec@1 100.000 (99.760)	
Epoch: [56][311/391]	LR: 2.0000000000000004e-07	Loss 0.0113 (0.0216)	Prec@1 100.000 (99.767)	
Epoch: [56][389/391]	LR: 2.0000000000000004e-07	Loss 0.0215 (0.0221)	Prec@1 99.219 (99.732)	
Total train loss: 0.0221

Train time: 18.862550497055054
 * Prec@1 90.860 Prec@5 99.550 Loss 0.3557
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 20.881779670715332

Epoch: [57][77/391]	LR: 2.0000000000000004e-07	Loss 0.0146 (0.0212)	Prec@1 100.000 (99.730)	
Epoch: [57][155/391]	LR: 2.0000000000000004e-07	Loss 0.0078 (0.0213)	Prec@1 100.000 (99.720)	
Epoch: [57][233/391]	LR: 2.0000000000000004e-07	Loss 0.0284 (0.0218)	Prec@1 98.438 (99.733)	
Epoch: [57][311/391]	LR: 2.0000000000000004e-07	Loss 0.0173 (0.0224)	Prec@1 100.000 (99.717)	
Epoch: [57][389/391]	LR: 2.0000000000000004e-07	Loss 0.0127 (0.0222)	Prec@1 100.000 (99.724)	
Total train loss: 0.0221

Train time: 18.654441833496094
 * Prec@1 90.960 Prec@5 99.550 Loss 0.3552
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 20.91135334968567

Epoch: [58][77/391]	LR: 2.0000000000000004e-07	Loss 0.0116 (0.0219)	Prec@1 100.000 (99.679)	
Epoch: [58][155/391]	LR: 2.0000000000000004e-07	Loss 0.0207 (0.0218)	Prec@1 100.000 (99.710)	
Epoch: [58][233/391]	LR: 2.0000000000000004e-07	Loss 0.0194 (0.0214)	Prec@1 100.000 (99.730)	
Epoch: [58][311/391]	LR: 2.0000000000000004e-07	Loss 0.0310 (0.0216)	Prec@1 98.438 (99.725)	
Epoch: [58][389/391]	LR: 2.0000000000000004e-07	Loss 0.0164 (0.0220)	Prec@1 100.000 (99.694)	
Total train loss: 0.0221

Train time: 18.377411365509033
 * Prec@1 90.980 Prec@5 99.550 Loss 0.3508
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 21.37359380722046

Epoch: [59][77/391]	LR: 2.0000000000000004e-07	Loss 0.0273 (0.0202)	Prec@1 99.219 (99.750)	
Epoch: [59][155/391]	LR: 2.0000000000000004e-07	Loss 0.0174 (0.0217)	Prec@1 100.000 (99.684)	
Epoch: [59][233/391]	LR: 2.0000000000000004e-07	Loss 0.0173 (0.0212)	Prec@1 100.000 (99.740)	
Epoch: [59][311/391]	LR: 2.0000000000000004e-07	Loss 0.0153 (0.0212)	Prec@1 100.000 (99.752)	
Epoch: [59][389/391]	LR: 2.0000000000000004e-07	Loss 0.0177 (0.0212)	Prec@1 100.000 (99.748)	
Total train loss: 0.0213

Train time: 17.212480545043945
 * Prec@1 91.000 Prec@5 99.540 Loss 0.3545
Best acc: 91.190
--------------------------------------------------------------------------------
Test time: 19.877044439315796

