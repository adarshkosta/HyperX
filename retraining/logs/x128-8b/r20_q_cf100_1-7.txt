
      ==> Arguments:
          dataset: cifar100
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/
          savedir: ../pretrained_models/frozen/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar100_i8b5f_w8b7f.pth.tar
          mode: rram
          workers: 8
          epochs: 60
          start_epoch: 0
          batch_size: 128
          lr: 0.002
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 7
          af_bit: 5
          w_bit: 7
          wf_bit: 7
          milestones: [20, 30, 40, 50]
          exp: x128-8b
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 1
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar100_i8b5f_w8b7f.pth.tar ...
Original model accuracy: 69.61000061035156
 * Prec@1 68.380 Prec@5 90.110 Loss 1.2012
Pre-trained Prec@1 with 1 layers frozen: 68.37999725341797 	 Loss: 1.201171875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.002	Loss 0.5903 (0.5469)	Prec@1 82.031 (84.285)	
Epoch: [0][155/391]	LR: 0.002	Loss 0.6416 (0.5502)	Prec@1 78.906 (84.485)	
Epoch: [0][233/391]	LR: 0.002	Loss 0.5996 (0.5582)	Prec@1 83.594 (84.168)	
Epoch: [0][311/391]	LR: 0.002	Loss 0.6997 (0.5660)	Prec@1 75.781 (83.782)	
Epoch: [0][389/391]	LR: 0.002	Loss 0.5591 (0.5729)	Prec@1 84.375 (83.630)	
Total train loss: 0.5731

Train time: 173.81742334365845
 * Prec@1 68.010 Prec@5 89.920 Loss 1.2188
Best acc: 68.010
--------------------------------------------------------------------------------
Test time: 177.14618802070618

Epoch: [1][77/391]	LR: 0.002	Loss 0.4080 (0.5031)	Prec@1 89.844 (86.278)	
Epoch: [1][155/391]	LR: 0.002	Loss 0.5537 (0.5087)	Prec@1 84.375 (86.053)	
Epoch: [1][233/391]	LR: 0.002	Loss 0.5396 (0.5143)	Prec@1 85.938 (85.894)	
Epoch: [1][311/391]	LR: 0.002	Loss 0.5234 (0.5197)	Prec@1 85.156 (85.670)	
Epoch: [1][389/391]	LR: 0.002	Loss 0.6421 (0.5221)	Prec@1 78.906 (85.519)	
Total train loss: 0.5224

Train time: 24.4688401222229
 * Prec@1 68.390 Prec@5 89.880 Loss 1.2188
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 28.33164358139038

Epoch: [2][77/391]	LR: 0.002	Loss 0.5605 (0.4522)	Prec@1 85.938 (88.381)	
Epoch: [2][155/391]	LR: 0.002	Loss 0.4265 (0.4661)	Prec@1 91.406 (87.725)	
Epoch: [2][233/391]	LR: 0.002	Loss 0.5278 (0.4788)	Prec@1 85.938 (87.210)	
Epoch: [2][311/391]	LR: 0.002	Loss 0.5942 (0.4828)	Prec@1 82.812 (86.997)	
Epoch: [2][389/391]	LR: 0.002	Loss 0.5649 (0.4894)	Prec@1 83.594 (86.723)	
Total train loss: 0.4897

Train time: 23.652013778686523
 * Prec@1 68.320 Prec@5 89.550 Loss 1.2393
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.740978240966797

Epoch: [3][77/391]	LR: 0.002	Loss 0.4324 (0.4472)	Prec@1 86.719 (88.572)	
Epoch: [3][155/391]	LR: 0.002	Loss 0.5488 (0.4498)	Prec@1 86.719 (88.532)	
Epoch: [3][233/391]	LR: 0.002	Loss 0.3923 (0.4573)	Prec@1 90.625 (88.278)	
Epoch: [3][311/391]	LR: 0.002	Loss 0.4834 (0.4590)	Prec@1 89.844 (88.151)	
Epoch: [3][389/391]	LR: 0.002	Loss 0.4521 (0.4620)	Prec@1 87.500 (88.051)	
Total train loss: 0.4623

Train time: 23.525859355926514
 * Prec@1 67.750 Prec@5 89.580 Loss 1.2588
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.38219690322876

Epoch: [4][77/391]	LR: 0.002	Loss 0.4355 (0.4166)	Prec@1 88.281 (89.453)	
Epoch: [4][155/391]	LR: 0.002	Loss 0.3943 (0.4245)	Prec@1 90.625 (89.168)	
Epoch: [4][233/391]	LR: 0.002	Loss 0.3811 (0.4229)	Prec@1 89.844 (89.326)	
Epoch: [4][311/391]	LR: 0.002	Loss 0.5894 (0.4292)	Prec@1 82.812 (89.130)	
Epoch: [4][389/391]	LR: 0.002	Loss 0.4495 (0.4330)	Prec@1 87.500 (88.924)	
Total train loss: 0.4332

Train time: 24.702801942825317
 * Prec@1 67.580 Prec@5 89.130 Loss 1.2842
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 28.182709217071533

Epoch: [5][77/391]	LR: 0.002	Loss 0.3821 (0.3900)	Prec@1 91.406 (90.465)	
Epoch: [5][155/391]	LR: 0.002	Loss 0.4546 (0.4057)	Prec@1 89.844 (90.124)	
Epoch: [5][233/391]	LR: 0.002	Loss 0.4150 (0.4080)	Prec@1 92.969 (90.004)	
Epoch: [5][311/391]	LR: 0.002	Loss 0.3806 (0.4102)	Prec@1 92.969 (89.871)	
Epoch: [5][389/391]	LR: 0.002	Loss 0.5273 (0.4139)	Prec@1 85.938 (89.669)	
Total train loss: 0.4139

Train time: 23.488917350769043
 * Prec@1 67.370 Prec@5 89.080 Loss 1.2900
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.72956156730652

Epoch: [6][77/391]	LR: 0.002	Loss 0.2866 (0.3668)	Prec@1 94.531 (91.617)	
Epoch: [6][155/391]	LR: 0.002	Loss 0.4126 (0.3820)	Prec@1 90.625 (91.176)	
Epoch: [6][233/391]	LR: 0.002	Loss 0.3408 (0.3858)	Prec@1 93.750 (91.092)	
Epoch: [6][311/391]	LR: 0.002	Loss 0.3845 (0.3871)	Prec@1 89.062 (90.971)	
Epoch: [6][389/391]	LR: 0.002	Loss 0.2847 (0.3909)	Prec@1 94.531 (90.725)	
Total train loss: 0.3913

Train time: 25.973784923553467
 * Prec@1 67.320 Prec@5 89.180 Loss 1.2842
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 29.885820150375366

Epoch: [7][77/391]	LR: 0.002	Loss 0.3105 (0.3502)	Prec@1 94.531 (92.147)	
Epoch: [7][155/391]	LR: 0.002	Loss 0.4365 (0.3578)	Prec@1 90.625 (92.062)	
Epoch: [7][233/391]	LR: 0.002	Loss 0.3911 (0.3605)	Prec@1 89.844 (91.884)	
Epoch: [7][311/391]	LR: 0.002	Loss 0.4148 (0.3654)	Prec@1 90.625 (91.704)	
Epoch: [7][389/391]	LR: 0.002	Loss 0.4297 (0.3685)	Prec@1 91.406 (91.528)	
Total train loss: 0.3685

Train time: 23.506484270095825
 * Prec@1 67.120 Prec@5 89.000 Loss 1.3047
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.47769260406494

Epoch: [8][77/391]	LR: 0.002	Loss 0.2727 (0.3389)	Prec@1 94.531 (93.069)	
Epoch: [8][155/391]	LR: 0.002	Loss 0.3208 (0.3369)	Prec@1 95.312 (92.859)	
Epoch: [8][233/391]	LR: 0.002	Loss 0.4482 (0.3439)	Prec@1 88.281 (92.521)	
Epoch: [8][311/391]	LR: 0.002	Loss 0.3469 (0.3498)	Prec@1 89.062 (92.177)	
Epoch: [8][389/391]	LR: 0.002	Loss 0.4583 (0.3537)	Prec@1 85.156 (92.025)	
Total train loss: 0.3541

Train time: 24.41431164741516
 * Prec@1 67.160 Prec@5 88.750 Loss 1.3203
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.77594494819641

Epoch: [9][77/391]	LR: 0.002	Loss 0.3081 (0.3148)	Prec@1 93.750 (93.950)	
Epoch: [9][155/391]	LR: 0.002	Loss 0.2537 (0.3177)	Prec@1 96.875 (93.715)	
Epoch: [9][233/391]	LR: 0.002	Loss 0.2849 (0.3253)	Prec@1 94.531 (93.323)	
Epoch: [9][311/391]	LR: 0.002	Loss 0.3845 (0.3319)	Prec@1 91.406 (92.911)	
Epoch: [9][389/391]	LR: 0.002	Loss 0.3909 (0.3380)	Prec@1 90.625 (92.644)	
Total train loss: 0.3384

Train time: 23.529907703399658
 * Prec@1 66.660 Prec@5 88.450 Loss 1.3418
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.042151927947998

Epoch: [10][77/391]	LR: 0.002	Loss 0.2852 (0.3069)	Prec@1 95.312 (94.151)	
Epoch: [10][155/391]	LR: 0.002	Loss 0.3645 (0.3100)	Prec@1 91.406 (93.900)	
Epoch: [10][233/391]	LR: 0.002	Loss 0.4219 (0.3146)	Prec@1 89.844 (93.687)	
Epoch: [10][311/391]	LR: 0.002	Loss 0.3503 (0.3195)	Prec@1 91.406 (93.467)	
Epoch: [10][389/391]	LR: 0.002	Loss 0.3416 (0.3220)	Prec@1 91.406 (93.307)	
Total train loss: 0.3221

Train time: 26.956873416900635
 * Prec@1 66.250 Prec@5 88.480 Loss 1.3438
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 30.086472034454346

Epoch: [11][77/391]	LR: 0.002	Loss 0.2944 (0.2897)	Prec@1 93.750 (94.541)	
Epoch: [11][155/391]	LR: 0.002	Loss 0.3672 (0.2897)	Prec@1 91.406 (94.521)	
Epoch: [11][233/391]	LR: 0.002	Loss 0.2352 (0.2937)	Prec@1 97.656 (94.401)	
Epoch: [11][311/391]	LR: 0.002	Loss 0.3140 (0.3019)	Prec@1 93.750 (94.068)	
Epoch: [11][389/391]	LR: 0.002	Loss 0.3213 (0.3063)	Prec@1 90.625 (93.908)	
Total train loss: 0.3063

Train time: 24.226311445236206
 * Prec@1 66.390 Prec@5 88.370 Loss 1.3525
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.33392357826233

Epoch: [12][77/391]	LR: 0.002	Loss 0.2681 (0.2789)	Prec@1 95.312 (95.152)	
Epoch: [12][155/391]	LR: 0.002	Loss 0.2795 (0.2867)	Prec@1 95.312 (94.787)	
Epoch: [12][233/391]	LR: 0.002	Loss 0.2886 (0.2908)	Prec@1 93.750 (94.641)	
Epoch: [12][311/391]	LR: 0.002	Loss 0.3223 (0.2929)	Prec@1 93.750 (94.541)	
Epoch: [12][389/391]	LR: 0.002	Loss 0.3013 (0.2949)	Prec@1 92.188 (94.427)	
Total train loss: 0.2951

Train time: 23.549049377441406
 * Prec@1 66.270 Prec@5 88.020 Loss 1.3750
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.15469455718994

Epoch: [13][77/391]	LR: 0.002	Loss 0.2864 (0.2736)	Prec@1 93.750 (95.152)	
Epoch: [13][155/391]	LR: 0.002	Loss 0.3352 (0.2698)	Prec@1 93.750 (95.338)	
Epoch: [13][233/391]	LR: 0.002	Loss 0.2418 (0.2725)	Prec@1 96.875 (95.229)	
Epoch: [13][311/391]	LR: 0.002	Loss 0.2644 (0.2774)	Prec@1 95.312 (94.999)	
Epoch: [13][389/391]	LR: 0.002	Loss 0.3206 (0.2826)	Prec@1 92.969 (94.830)	
Total train loss: 0.2829

Train time: 24.15674662590027
 * Prec@1 65.550 Prec@5 88.090 Loss 1.3828
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.93567657470703

Epoch: [14][77/391]	LR: 0.002	Loss 0.2515 (0.2565)	Prec@1 95.312 (95.813)	
Epoch: [14][155/391]	LR: 0.002	Loss 0.2703 (0.2606)	Prec@1 96.875 (95.628)	
Epoch: [14][233/391]	LR: 0.002	Loss 0.2737 (0.2661)	Prec@1 94.531 (95.446)	
Epoch: [14][311/391]	LR: 0.002	Loss 0.3369 (0.2702)	Prec@1 91.406 (95.272)	
Epoch: [14][389/391]	LR: 0.002	Loss 0.2771 (0.2726)	Prec@1 92.969 (95.156)	
Total train loss: 0.2727

Train time: 23.470701456069946
 * Prec@1 65.970 Prec@5 87.940 Loss 1.3818
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.737637758255005

Epoch: [15][77/391]	LR: 0.002	Loss 0.2457 (0.2485)	Prec@1 95.312 (96.004)	
Epoch: [15][155/391]	LR: 0.002	Loss 0.2861 (0.2524)	Prec@1 95.312 (95.853)	
Epoch: [15][233/391]	LR: 0.002	Loss 0.3035 (0.2581)	Prec@1 93.750 (95.720)	
Epoch: [15][311/391]	LR: 0.002	Loss 0.2375 (0.2595)	Prec@1 97.656 (95.666)	
Epoch: [15][389/391]	LR: 0.002	Loss 0.2908 (0.2628)	Prec@1 93.750 (95.535)	
Total train loss: 0.2629

Train time: 23.97395420074463
 * Prec@1 65.970 Prec@5 87.460 Loss 1.4092
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.801719903945923

Epoch: [16][77/391]	LR: 0.002	Loss 0.1963 (0.2360)	Prec@1 99.219 (96.725)	
Epoch: [16][155/391]	LR: 0.002	Loss 0.2438 (0.2410)	Prec@1 95.312 (96.464)	
Epoch: [16][233/391]	LR: 0.002	Loss 0.2087 (0.2451)	Prec@1 98.438 (96.337)	
Epoch: [16][311/391]	LR: 0.002	Loss 0.2773 (0.2480)	Prec@1 92.188 (96.164)	
Epoch: [16][389/391]	LR: 0.002	Loss 0.2988 (0.2520)	Prec@1 94.531 (95.976)	
Total train loss: 0.2522

Train time: 23.707443237304688
 * Prec@1 65.570 Prec@5 87.520 Loss 1.4180
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.299395084381104

Epoch: [17][77/391]	LR: 0.002	Loss 0.2499 (0.2313)	Prec@1 96.875 (96.575)	
Epoch: [17][155/391]	LR: 0.002	Loss 0.1995 (0.2310)	Prec@1 97.656 (96.655)	
Epoch: [17][233/391]	LR: 0.002	Loss 0.2122 (0.2375)	Prec@1 97.656 (96.401)	
Epoch: [17][311/391]	LR: 0.002	Loss 0.2856 (0.2412)	Prec@1 94.531 (96.244)	
Epoch: [17][389/391]	LR: 0.002	Loss 0.2588 (0.2442)	Prec@1 94.531 (96.166)	
Total train loss: 0.2444

Train time: 23.85707426071167
 * Prec@1 65.790 Prec@5 87.630 Loss 1.4023
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.577390909194946

Epoch: [18][77/391]	LR: 0.002	Loss 0.2283 (0.2157)	Prec@1 96.875 (97.216)	
Epoch: [18][155/391]	LR: 0.002	Loss 0.2708 (0.2238)	Prec@1 95.312 (96.815)	
Epoch: [18][233/391]	LR: 0.002	Loss 0.2625 (0.2303)	Prec@1 95.312 (96.638)	
Epoch: [18][311/391]	LR: 0.002	Loss 0.1971 (0.2330)	Prec@1 97.656 (96.562)	
Epoch: [18][389/391]	LR: 0.002	Loss 0.2155 (0.2344)	Prec@1 97.656 (96.548)	
Total train loss: 0.2346

Train time: 23.488768577575684
 * Prec@1 65.590 Prec@5 87.190 Loss 1.4170
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.95426893234253

Epoch: [19][77/391]	LR: 0.002	Loss 0.2106 (0.2092)	Prec@1 95.312 (97.286)	
Epoch: [19][155/391]	LR: 0.002	Loss 0.2230 (0.2146)	Prec@1 98.438 (97.140)	
Epoch: [19][233/391]	LR: 0.002	Loss 0.2544 (0.2193)	Prec@1 95.312 (97.002)	
Epoch: [19][311/391]	LR: 0.002	Loss 0.2468 (0.2236)	Prec@1 95.312 (96.817)	
Epoch: [19][389/391]	LR: 0.002	Loss 0.2605 (0.2263)	Prec@1 96.875 (96.693)	
Total train loss: 0.2263

Train time: 24.841060161590576
 * Prec@1 64.850 Prec@5 87.590 Loss 1.4424
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.32103157043457

Epoch: [20][77/391]	LR: 0.0002	Loss 0.2029 (0.1986)	Prec@1 98.438 (97.696)	
Epoch: [20][155/391]	LR: 0.0002	Loss 0.2279 (0.2001)	Prec@1 100.000 (97.571)	
Epoch: [20][233/391]	LR: 0.0002	Loss 0.1731 (0.1998)	Prec@1 98.438 (97.579)	
Epoch: [20][311/391]	LR: 0.0002	Loss 0.2094 (0.1981)	Prec@1 96.875 (97.664)	
Epoch: [20][389/391]	LR: 0.0002	Loss 0.2412 (0.1978)	Prec@1 95.312 (97.676)	
Total train loss: 0.1980

Train time: 23.63906240463257
 * Prec@1 65.360 Prec@5 87.360 Loss 1.4248
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.18730354309082

Epoch: [21][77/391]	LR: 0.0002	Loss 0.1647 (0.1984)	Prec@1 96.875 (97.596)	
Epoch: [21][155/391]	LR: 0.0002	Loss 0.1835 (0.1953)	Prec@1 99.219 (97.671)	
Epoch: [21][233/391]	LR: 0.0002	Loss 0.1866 (0.1952)	Prec@1 98.438 (97.696)	
Epoch: [21][311/391]	LR: 0.0002	Loss 0.2139 (0.1941)	Prec@1 96.875 (97.766)	
Epoch: [21][389/391]	LR: 0.0002	Loss 0.2109 (0.1945)	Prec@1 96.875 (97.778)	
Total train loss: 0.1945

Train time: 24.51177191734314
 * Prec@1 65.610 Prec@5 87.170 Loss 1.4219
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.301702976226807

Epoch: [22][77/391]	LR: 0.0002	Loss 0.1556 (0.1855)	Prec@1 99.219 (97.887)	
Epoch: [22][155/391]	LR: 0.0002	Loss 0.2205 (0.1865)	Prec@1 96.875 (97.942)	
Epoch: [22][233/391]	LR: 0.0002	Loss 0.1798 (0.1875)	Prec@1 98.438 (97.987)	
Epoch: [22][311/391]	LR: 0.0002	Loss 0.1886 (0.1873)	Prec@1 98.438 (98.009)	
Epoch: [22][389/391]	LR: 0.0002	Loss 0.1976 (0.1874)	Prec@1 95.312 (97.969)	
Total train loss: 0.1874

Train time: 23.98411798477173
 * Prec@1 65.630 Prec@5 87.380 Loss 1.4141
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.470947980880737

Epoch: [23][77/391]	LR: 0.0002	Loss 0.2211 (0.1932)	Prec@1 97.656 (97.867)	
Epoch: [23][155/391]	LR: 0.0002	Loss 0.1993 (0.1930)	Prec@1 98.438 (97.902)	
Epoch: [23][233/391]	LR: 0.0002	Loss 0.1302 (0.1910)	Prec@1 99.219 (97.903)	
Epoch: [23][311/391]	LR: 0.0002	Loss 0.1766 (0.1892)	Prec@1 97.656 (97.962)	
Epoch: [23][389/391]	LR: 0.0002	Loss 0.2274 (0.1891)	Prec@1 95.312 (97.957)	
Total train loss: 0.1893

Train time: 24.69737434387207
 * Prec@1 65.800 Prec@5 87.360 Loss 1.4141
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.089345455169678

Epoch: [24][77/391]	LR: 0.0002	Loss 0.1610 (0.1848)	Prec@1 99.219 (98.247)	
Epoch: [24][155/391]	LR: 0.0002	Loss 0.1871 (0.1862)	Prec@1 99.219 (98.112)	
Epoch: [24][233/391]	LR: 0.0002	Loss 0.1996 (0.1861)	Prec@1 98.438 (98.047)	
Epoch: [24][311/391]	LR: 0.0002	Loss 0.1913 (0.1859)	Prec@1 98.438 (98.064)	
Epoch: [24][389/391]	LR: 0.0002	Loss 0.2034 (0.1856)	Prec@1 96.875 (98.093)	
Total train loss: 0.1855

Train time: 23.1253399848938
 * Prec@1 65.900 Prec@5 87.370 Loss 1.4111
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.516578435897827

Epoch: [25][77/391]	LR: 0.0002	Loss 0.1210 (0.1873)	Prec@1 99.219 (98.077)	
Epoch: [25][155/391]	LR: 0.0002	Loss 0.1405 (0.1850)	Prec@1 100.000 (98.102)	
Epoch: [25][233/391]	LR: 0.0002	Loss 0.1537 (0.1858)	Prec@1 99.219 (98.064)	
Epoch: [25][311/391]	LR: 0.0002	Loss 0.1225 (0.1855)	Prec@1 100.000 (98.057)	
Epoch: [25][389/391]	LR: 0.0002	Loss 0.1692 (0.1855)	Prec@1 98.438 (98.041)	
Total train loss: 0.1856

Train time: 23.724157094955444
 * Prec@1 65.750 Prec@5 87.220 Loss 1.4170
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.409627199172974

Epoch: [26][77/391]	LR: 0.0002	Loss 0.2177 (0.1821)	Prec@1 98.438 (98.127)	
Epoch: [26][155/391]	LR: 0.0002	Loss 0.1960 (0.1834)	Prec@1 96.094 (98.057)	
Epoch: [26][233/391]	LR: 0.0002	Loss 0.1880 (0.1831)	Prec@1 96.875 (98.097)	
Epoch: [26][311/391]	LR: 0.0002	Loss 0.1588 (0.1849)	Prec@1 98.438 (98.032)	
Epoch: [26][389/391]	LR: 0.0002	Loss 0.1990 (0.1848)	Prec@1 100.000 (98.045)	
Total train loss: 0.1848

Train time: 25.873902320861816
 * Prec@1 66.160 Prec@5 87.350 Loss 1.4141
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 28.897858381271362

Epoch: [27][77/391]	LR: 0.0002	Loss 0.2249 (0.1813)	Prec@1 96.094 (98.107)	
Epoch: [27][155/391]	LR: 0.0002	Loss 0.1699 (0.1833)	Prec@1 99.219 (98.127)	
Epoch: [27][233/391]	LR: 0.0002	Loss 0.1746 (0.1817)	Prec@1 97.656 (98.174)	
Epoch: [27][311/391]	LR: 0.0002	Loss 0.1619 (0.1816)	Prec@1 98.438 (98.202)	
Epoch: [27][389/391]	LR: 0.0002	Loss 0.2068 (0.1827)	Prec@1 96.094 (98.157)	
Total train loss: 0.1827

Train time: 23.733179092407227
 * Prec@1 65.780 Prec@5 87.220 Loss 1.4180
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.951369285583496

Epoch: [28][77/391]	LR: 0.0002	Loss 0.1774 (0.1843)	Prec@1 100.000 (98.127)	
Epoch: [28][155/391]	LR: 0.0002	Loss 0.2051 (0.1839)	Prec@1 97.656 (98.142)	
Epoch: [28][233/391]	LR: 0.0002	Loss 0.1995 (0.1839)	Prec@1 96.875 (98.154)	
Epoch: [28][311/391]	LR: 0.0002	Loss 0.1866 (0.1834)	Prec@1 98.438 (98.192)	
Epoch: [28][389/391]	LR: 0.0002	Loss 0.2086 (0.1836)	Prec@1 97.656 (98.153)	
Total train loss: 0.1838

Train time: 24.351120233535767
 * Prec@1 65.850 Prec@5 87.200 Loss 1.4170
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.667567253112793

Epoch: [29][77/391]	LR: 0.0002	Loss 0.1709 (0.1811)	Prec@1 100.000 (98.257)	
Epoch: [29][155/391]	LR: 0.0002	Loss 0.1902 (0.1830)	Prec@1 99.219 (98.217)	
Epoch: [29][233/391]	LR: 0.0002	Loss 0.1709 (0.1830)	Prec@1 98.438 (98.227)	
Epoch: [29][311/391]	LR: 0.0002	Loss 0.2161 (0.1823)	Prec@1 96.875 (98.220)	
Epoch: [29][389/391]	LR: 0.0002	Loss 0.1381 (0.1814)	Prec@1 99.219 (98.223)	
Total train loss: 0.1816

Train time: 24.79161834716797
 * Prec@1 65.730 Prec@5 87.310 Loss 1.4150
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.67825222015381

Epoch: [30][77/391]	LR: 2e-05	Loss 0.1520 (0.1778)	Prec@1 98.438 (98.227)	
Epoch: [30][155/391]	LR: 2e-05	Loss 0.1482 (0.1780)	Prec@1 100.000 (98.307)	
Epoch: [30][233/391]	LR: 2e-05	Loss 0.1801 (0.1805)	Prec@1 98.438 (98.264)	
Epoch: [30][311/391]	LR: 2e-05	Loss 0.2117 (0.1804)	Prec@1 97.656 (98.222)	
Epoch: [30][389/391]	LR: 2e-05	Loss 0.1875 (0.1796)	Prec@1 99.219 (98.253)	
Total train loss: 0.1797

Train time: 22.908111095428467
 * Prec@1 65.960 Prec@5 87.750 Loss 1.4092
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.10940647125244

Epoch: [31][77/391]	LR: 2e-05	Loss 0.1499 (0.1787)	Prec@1 97.656 (98.347)	
Epoch: [31][155/391]	LR: 2e-05	Loss 0.1259 (0.1788)	Prec@1 99.219 (98.347)	
Epoch: [31][233/391]	LR: 2e-05	Loss 0.1993 (0.1790)	Prec@1 99.219 (98.351)	
Epoch: [31][311/391]	LR: 2e-05	Loss 0.1589 (0.1783)	Prec@1 98.438 (98.327)	
Epoch: [31][389/391]	LR: 2e-05	Loss 0.1885 (0.1776)	Prec@1 99.219 (98.333)	
Total train loss: 0.1777

Train time: 24.349844217300415
 * Prec@1 65.810 Prec@5 87.370 Loss 1.4170
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.379920959472656

Epoch: [32][77/391]	LR: 2e-05	Loss 0.1448 (0.1790)	Prec@1 99.219 (98.267)	
Epoch: [32][155/391]	LR: 2e-05	Loss 0.1920 (0.1773)	Prec@1 97.656 (98.312)	
Epoch: [32][233/391]	LR: 2e-05	Loss 0.2087 (0.1779)	Prec@1 98.438 (98.304)	
Epoch: [32][311/391]	LR: 2e-05	Loss 0.2084 (0.1799)	Prec@1 99.219 (98.220)	
Epoch: [32][389/391]	LR: 2e-05	Loss 0.2141 (0.1797)	Prec@1 98.438 (98.247)	
Total train loss: 0.1798

Train time: 23.575951099395752
 * Prec@1 65.800 Prec@5 87.320 Loss 1.4180
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.512593030929565

Epoch: [33][77/391]	LR: 2e-05	Loss 0.1521 (0.1788)	Prec@1 99.219 (98.197)	
Epoch: [33][155/391]	LR: 2e-05	Loss 0.1755 (0.1797)	Prec@1 98.438 (98.282)	
Epoch: [33][233/391]	LR: 2e-05	Loss 0.1772 (0.1798)	Prec@1 97.656 (98.210)	
Epoch: [33][311/391]	LR: 2e-05	Loss 0.1438 (0.1788)	Prec@1 100.000 (98.222)	
Epoch: [33][389/391]	LR: 2e-05	Loss 0.2092 (0.1803)	Prec@1 98.438 (98.207)	
Total train loss: 0.1804

Train time: 24.235313653945923
 * Prec@1 65.830 Prec@5 87.080 Loss 1.4160
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.363581895828247

Epoch: [34][77/391]	LR: 2e-05	Loss 0.1785 (0.1785)	Prec@1 96.875 (98.037)	
Epoch: [34][155/391]	LR: 2e-05	Loss 0.1616 (0.1790)	Prec@1 98.438 (98.182)	
Epoch: [34][233/391]	LR: 2e-05	Loss 0.1831 (0.1803)	Prec@1 98.438 (98.187)	
Epoch: [34][311/391]	LR: 2e-05	Loss 0.1820 (0.1809)	Prec@1 99.219 (98.187)	
Epoch: [34][389/391]	LR: 2e-05	Loss 0.1660 (0.1809)	Prec@1 98.438 (98.191)	
Total train loss: 0.1810

Train time: 23.613571405410767
 * Prec@1 65.920 Prec@5 87.400 Loss 1.4072
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.909095287322998

Epoch: [35][77/391]	LR: 2e-05	Loss 0.1648 (0.1785)	Prec@1 99.219 (98.448)	
Epoch: [35][155/391]	LR: 2e-05	Loss 0.1843 (0.1801)	Prec@1 98.438 (98.412)	
Epoch: [35][233/391]	LR: 2e-05	Loss 0.1874 (0.1800)	Prec@1 98.438 (98.334)	
Epoch: [35][311/391]	LR: 2e-05	Loss 0.2019 (0.1800)	Prec@1 95.312 (98.337)	
Epoch: [35][389/391]	LR: 2e-05	Loss 0.1925 (0.1806)	Prec@1 98.438 (98.301)	
Total train loss: 0.1806

Train time: 23.946285247802734
 * Prec@1 65.760 Prec@5 87.330 Loss 1.4219
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.733191967010498

Epoch: [36][77/391]	LR: 2e-05	Loss 0.1899 (0.1827)	Prec@1 99.219 (98.077)	
Epoch: [36][155/391]	LR: 2e-05	Loss 0.1885 (0.1816)	Prec@1 97.656 (98.107)	
Epoch: [36][233/391]	LR: 2e-05	Loss 0.1826 (0.1797)	Prec@1 97.656 (98.200)	
Epoch: [36][311/391]	LR: 2e-05	Loss 0.1841 (0.1804)	Prec@1 98.438 (98.195)	
Epoch: [36][389/391]	LR: 2e-05	Loss 0.1660 (0.1799)	Prec@1 96.875 (98.237)	
Total train loss: 0.1801

Train time: 22.63937520980835
 * Prec@1 65.490 Prec@5 87.230 Loss 1.4287
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 25.95561957359314

Epoch: [37][77/391]	LR: 2e-05	Loss 0.1698 (0.1751)	Prec@1 98.438 (98.367)	
Epoch: [37][155/391]	LR: 2e-05	Loss 0.1543 (0.1747)	Prec@1 99.219 (98.362)	
Epoch: [37][233/391]	LR: 2e-05	Loss 0.1818 (0.1775)	Prec@1 98.438 (98.244)	
Epoch: [37][311/391]	LR: 2e-05	Loss 0.1307 (0.1774)	Prec@1 100.000 (98.242)	
Epoch: [37][389/391]	LR: 2e-05	Loss 0.1736 (0.1794)	Prec@1 98.438 (98.231)	
Total train loss: 0.1795

Train time: 24.048983573913574
 * Prec@1 65.710 Prec@5 87.310 Loss 1.4219
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.82078790664673

Epoch: [38][77/391]	LR: 2e-05	Loss 0.1736 (0.1814)	Prec@1 96.875 (98.107)	
Epoch: [38][155/391]	LR: 2e-05	Loss 0.1512 (0.1800)	Prec@1 98.438 (98.182)	
Epoch: [38][233/391]	LR: 2e-05	Loss 0.1599 (0.1803)	Prec@1 99.219 (98.200)	
Epoch: [38][311/391]	LR: 2e-05	Loss 0.1458 (0.1815)	Prec@1 98.438 (98.162)	
Epoch: [38][389/391]	LR: 2e-05	Loss 0.1659 (0.1822)	Prec@1 99.219 (98.135)	
Total train loss: 0.1822

Train time: 23.084264755249023
 * Prec@1 65.690 Prec@5 87.330 Loss 1.4189
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.164763689041138

Epoch: [39][77/391]	LR: 2e-05	Loss 0.2053 (0.1792)	Prec@1 98.438 (98.197)	
Epoch: [39][155/391]	LR: 2e-05	Loss 0.2042 (0.1778)	Prec@1 97.656 (98.292)	
Epoch: [39][233/391]	LR: 2e-05	Loss 0.1992 (0.1775)	Prec@1 98.438 (98.321)	
Epoch: [39][311/391]	LR: 2e-05	Loss 0.2068 (0.1799)	Prec@1 98.438 (98.267)	
Epoch: [39][389/391]	LR: 2e-05	Loss 0.1858 (0.1810)	Prec@1 97.656 (98.219)	
Total train loss: 0.1811

Train time: 24.76164984703064
 * Prec@1 65.950 Prec@5 87.550 Loss 1.4111
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.713210344314575

Epoch: [40][77/391]	LR: 2.0000000000000003e-06	Loss 0.1776 (0.1831)	Prec@1 100.000 (98.377)	
Epoch: [40][155/391]	LR: 2.0000000000000003e-06	Loss 0.1676 (0.1815)	Prec@1 99.219 (98.262)	
Epoch: [40][233/391]	LR: 2.0000000000000003e-06	Loss 0.1991 (0.1801)	Prec@1 97.656 (98.261)	
Epoch: [40][311/391]	LR: 2.0000000000000003e-06	Loss 0.1852 (0.1804)	Prec@1 96.875 (98.225)	
Epoch: [40][389/391]	LR: 2.0000000000000003e-06	Loss 0.1571 (0.1804)	Prec@1 100.000 (98.235)	
Total train loss: 0.1806

Train time: 23.381821155548096
 * Prec@1 65.910 Prec@5 87.480 Loss 1.4150
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.298245191574097

Epoch: [41][77/391]	LR: 2.0000000000000003e-06	Loss 0.1991 (0.1769)	Prec@1 96.875 (98.417)	
Epoch: [41][155/391]	LR: 2.0000000000000003e-06	Loss 0.1843 (0.1781)	Prec@1 98.438 (98.327)	
Epoch: [41][233/391]	LR: 2.0000000000000003e-06	Loss 0.1837 (0.1785)	Prec@1 99.219 (98.301)	
Epoch: [41][311/391]	LR: 2.0000000000000003e-06	Loss 0.1361 (0.1783)	Prec@1 99.219 (98.305)	
Epoch: [41][389/391]	LR: 2.0000000000000003e-06	Loss 0.1746 (0.1788)	Prec@1 96.875 (98.287)	
Total train loss: 0.1788

Train time: 19.31062912940979
 * Prec@1 65.980 Prec@5 87.260 Loss 1.4111
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 21.625823497772217

Epoch: [42][77/391]	LR: 2.0000000000000003e-06	Loss 0.2046 (0.1829)	Prec@1 98.438 (98.227)	
Epoch: [42][155/391]	LR: 2.0000000000000003e-06	Loss 0.1449 (0.1821)	Prec@1 97.656 (98.192)	
Epoch: [42][233/391]	LR: 2.0000000000000003e-06	Loss 0.1921 (0.1818)	Prec@1 97.656 (98.180)	
Epoch: [42][311/391]	LR: 2.0000000000000003e-06	Loss 0.1840 (0.1809)	Prec@1 98.438 (98.227)	
Epoch: [42][389/391]	LR: 2.0000000000000003e-06	Loss 0.1731 (0.1819)	Prec@1 97.656 (98.195)	
Total train loss: 0.1820

Train time: 20.901593923568726
 * Prec@1 65.670 Prec@5 87.310 Loss 1.4141
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 28.391506910324097

Epoch: [43][77/391]	LR: 2.0000000000000003e-06	Loss 0.1614 (0.1808)	Prec@1 99.219 (98.287)	
Epoch: [43][155/391]	LR: 2.0000000000000003e-06	Loss 0.2059 (0.1822)	Prec@1 97.656 (98.217)	
Epoch: [43][233/391]	LR: 2.0000000000000003e-06	Loss 0.1193 (0.1815)	Prec@1 100.000 (98.214)	
Epoch: [43][311/391]	LR: 2.0000000000000003e-06	Loss 0.1641 (0.1811)	Prec@1 97.656 (98.192)	
Epoch: [43][389/391]	LR: 2.0000000000000003e-06	Loss 0.1682 (0.1800)	Prec@1 97.656 (98.231)	
Total train loss: 0.1801

Train time: 20.42764163017273
 * Prec@1 65.850 Prec@5 87.580 Loss 1.4141
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 24.521974086761475

Epoch: [44][77/391]	LR: 2.0000000000000003e-06	Loss 0.1912 (0.1849)	Prec@1 98.438 (98.097)	
Epoch: [44][155/391]	LR: 2.0000000000000003e-06	Loss 0.1632 (0.1826)	Prec@1 99.219 (98.147)	
Epoch: [44][233/391]	LR: 2.0000000000000003e-06	Loss 0.1483 (0.1807)	Prec@1 98.438 (98.214)	
Epoch: [44][311/391]	LR: 2.0000000000000003e-06	Loss 0.1583 (0.1802)	Prec@1 99.219 (98.212)	
Epoch: [44][389/391]	LR: 2.0000000000000003e-06	Loss 0.1633 (0.1793)	Prec@1 99.219 (98.281)	
Total train loss: 0.1795

Train time: 20.13914179801941
 * Prec@1 65.640 Prec@5 87.350 Loss 1.4229
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 22.80624270439148

Epoch: [45][77/391]	LR: 2.0000000000000003e-06	Loss 0.1906 (0.1754)	Prec@1 98.438 (98.508)	
Epoch: [45][155/391]	LR: 2.0000000000000003e-06	Loss 0.1578 (0.1748)	Prec@1 99.219 (98.563)	
Epoch: [45][233/391]	LR: 2.0000000000000003e-06	Loss 0.2166 (0.1775)	Prec@1 95.312 (98.431)	
Epoch: [45][311/391]	LR: 2.0000000000000003e-06	Loss 0.1676 (0.1764)	Prec@1 99.219 (98.448)	
Epoch: [45][389/391]	LR: 2.0000000000000003e-06	Loss 0.2150 (0.1764)	Prec@1 97.656 (98.450)	
Total train loss: 0.1767

Train time: 23.046200037002563
 * Prec@1 65.640 Prec@5 87.400 Loss 1.4258
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.35673975944519

Epoch: [46][77/391]	LR: 2.0000000000000003e-06	Loss 0.2091 (0.1797)	Prec@1 99.219 (98.297)	
Epoch: [46][155/391]	LR: 2.0000000000000003e-06	Loss 0.1852 (0.1817)	Prec@1 96.875 (98.282)	
Epoch: [46][233/391]	LR: 2.0000000000000003e-06	Loss 0.1738 (0.1809)	Prec@1 98.438 (98.267)	
Epoch: [46][311/391]	LR: 2.0000000000000003e-06	Loss 0.2010 (0.1799)	Prec@1 96.094 (98.315)	
Epoch: [46][389/391]	LR: 2.0000000000000003e-06	Loss 0.1696 (0.1798)	Prec@1 100.000 (98.323)	
Total train loss: 0.1798

Train time: 23.136861562728882
 * Prec@1 65.740 Prec@5 87.270 Loss 1.4121
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.32672357559204

Epoch: [47][77/391]	LR: 2.0000000000000003e-06	Loss 0.1812 (0.1764)	Prec@1 100.000 (98.277)	
Epoch: [47][155/391]	LR: 2.0000000000000003e-06	Loss 0.1414 (0.1783)	Prec@1 97.656 (98.227)	
Epoch: [47][233/391]	LR: 2.0000000000000003e-06	Loss 0.1864 (0.1781)	Prec@1 99.219 (98.217)	
Epoch: [47][311/391]	LR: 2.0000000000000003e-06	Loss 0.2310 (0.1784)	Prec@1 97.656 (98.260)	
Epoch: [47][389/391]	LR: 2.0000000000000003e-06	Loss 0.1865 (0.1777)	Prec@1 98.438 (98.261)	
Total train loss: 0.1777

Train time: 23.052258729934692
 * Prec@1 65.770 Prec@5 87.190 Loss 1.4199
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.112491607666016

Epoch: [48][77/391]	LR: 2.0000000000000003e-06	Loss 0.1772 (0.1895)	Prec@1 98.438 (98.237)	
Epoch: [48][155/391]	LR: 2.0000000000000003e-06	Loss 0.1539 (0.1836)	Prec@1 98.438 (98.317)	
Epoch: [48][233/391]	LR: 2.0000000000000003e-06	Loss 0.1328 (0.1825)	Prec@1 99.219 (98.314)	
Epoch: [48][311/391]	LR: 2.0000000000000003e-06	Loss 0.1482 (0.1817)	Prec@1 100.000 (98.290)	
Epoch: [48][389/391]	LR: 2.0000000000000003e-06	Loss 0.1731 (0.1802)	Prec@1 99.219 (98.333)	
Total train loss: 0.1804

Train time: 23.43433403968811
 * Prec@1 65.770 Prec@5 87.350 Loss 1.4160
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.59981656074524

Epoch: [49][77/391]	LR: 2.0000000000000003e-06	Loss 0.1696 (0.1782)	Prec@1 98.438 (98.458)	
Epoch: [49][155/391]	LR: 2.0000000000000003e-06	Loss 0.2313 (0.1815)	Prec@1 95.312 (98.247)	
Epoch: [49][233/391]	LR: 2.0000000000000003e-06	Loss 0.1938 (0.1806)	Prec@1 97.656 (98.227)	
Epoch: [49][311/391]	LR: 2.0000000000000003e-06	Loss 0.1665 (0.1793)	Prec@1 99.219 (98.265)	
Epoch: [49][389/391]	LR: 2.0000000000000003e-06	Loss 0.1783 (0.1794)	Prec@1 98.438 (98.281)	
Total train loss: 0.1796

Train time: 23.60652804374695
 * Prec@1 65.890 Prec@5 87.320 Loss 1.4131
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.904613733291626

Epoch: [50][77/391]	LR: 2.0000000000000004e-07	Loss 0.1835 (0.1811)	Prec@1 98.438 (98.257)	
Epoch: [50][155/391]	LR: 2.0000000000000004e-07	Loss 0.2339 (0.1788)	Prec@1 96.094 (98.197)	
Epoch: [50][233/391]	LR: 2.0000000000000004e-07	Loss 0.2133 (0.1788)	Prec@1 96.094 (98.261)	
Epoch: [50][311/391]	LR: 2.0000000000000004e-07	Loss 0.1974 (0.1783)	Prec@1 97.656 (98.255)	
Epoch: [50][389/391]	LR: 2.0000000000000004e-07	Loss 0.2435 (0.1784)	Prec@1 92.969 (98.231)	
Total train loss: 0.1785

Train time: 24.659071922302246
 * Prec@1 65.900 Prec@5 87.560 Loss 1.4141
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.252214670181274

Epoch: [51][77/391]	LR: 2.0000000000000004e-07	Loss 0.1821 (0.1817)	Prec@1 98.438 (98.197)	
Epoch: [51][155/391]	LR: 2.0000000000000004e-07	Loss 0.2437 (0.1836)	Prec@1 95.312 (98.242)	
Epoch: [51][233/391]	LR: 2.0000000000000004e-07	Loss 0.1624 (0.1824)	Prec@1 99.219 (98.257)	
Epoch: [51][311/391]	LR: 2.0000000000000004e-07	Loss 0.2010 (0.1828)	Prec@1 97.656 (98.272)	
Epoch: [51][389/391]	LR: 2.0000000000000004e-07	Loss 0.1959 (0.1820)	Prec@1 96.094 (98.297)	
Total train loss: 0.1821

Train time: 23.533544301986694
 * Prec@1 65.680 Prec@5 87.390 Loss 1.4180
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.94092297554016

Epoch: [52][77/391]	LR: 2.0000000000000004e-07	Loss 0.2087 (0.1855)	Prec@1 98.438 (97.967)	
Epoch: [52][155/391]	LR: 2.0000000000000004e-07	Loss 0.1501 (0.1829)	Prec@1 98.438 (98.162)	
Epoch: [52][233/391]	LR: 2.0000000000000004e-07	Loss 0.1665 (0.1836)	Prec@1 97.656 (98.157)	
Epoch: [52][311/391]	LR: 2.0000000000000004e-07	Loss 0.1619 (0.1824)	Prec@1 98.438 (98.195)	
Epoch: [52][389/391]	LR: 2.0000000000000004e-07	Loss 0.2153 (0.1818)	Prec@1 97.656 (98.229)	
Total train loss: 0.1819

Train time: 23.602980613708496
 * Prec@1 65.940 Prec@5 87.300 Loss 1.4150
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 25.840386629104614

Epoch: [53][77/391]	LR: 2.0000000000000004e-07	Loss 0.2310 (0.1802)	Prec@1 96.094 (98.167)	
Epoch: [53][155/391]	LR: 2.0000000000000004e-07	Loss 0.1192 (0.1766)	Prec@1 99.219 (98.262)	
Epoch: [53][233/391]	LR: 2.0000000000000004e-07	Loss 0.1699 (0.1758)	Prec@1 97.656 (98.284)	
Epoch: [53][311/391]	LR: 2.0000000000000004e-07	Loss 0.2134 (0.1773)	Prec@1 96.875 (98.305)	
Epoch: [53][389/391]	LR: 2.0000000000000004e-07	Loss 0.1962 (0.1772)	Prec@1 96.875 (98.277)	
Total train loss: 0.1773

Train time: 24.032613515853882
 * Prec@1 65.770 Prec@5 87.460 Loss 1.4150
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.26825737953186

Epoch: [54][77/391]	LR: 2.0000000000000004e-07	Loss 0.1527 (0.1794)	Prec@1 99.219 (98.257)	
Epoch: [54][155/391]	LR: 2.0000000000000004e-07	Loss 0.1826 (0.1784)	Prec@1 97.656 (98.347)	
Epoch: [54][233/391]	LR: 2.0000000000000004e-07	Loss 0.1632 (0.1786)	Prec@1 100.000 (98.361)	
Epoch: [54][311/391]	LR: 2.0000000000000004e-07	Loss 0.1405 (0.1784)	Prec@1 99.219 (98.380)	
Epoch: [54][389/391]	LR: 2.0000000000000004e-07	Loss 0.1868 (0.1783)	Prec@1 97.656 (98.353)	
Total train loss: 0.1783

Train time: 24.36336588859558
 * Prec@1 65.510 Prec@5 87.190 Loss 1.4189
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 26.489861011505127

Epoch: [55][77/391]	LR: 2.0000000000000004e-07	Loss 0.1343 (0.1771)	Prec@1 99.219 (98.337)	
Epoch: [55][155/391]	LR: 2.0000000000000004e-07	Loss 0.1699 (0.1795)	Prec@1 97.656 (98.237)	
Epoch: [55][233/391]	LR: 2.0000000000000004e-07	Loss 0.1730 (0.1782)	Prec@1 96.094 (98.281)	
Epoch: [55][311/391]	LR: 2.0000000000000004e-07	Loss 0.1952 (0.1788)	Prec@1 97.656 (98.280)	
Epoch: [55][389/391]	LR: 2.0000000000000004e-07	Loss 0.1577 (0.1787)	Prec@1 98.438 (98.301)	
Total train loss: 0.1788

Train time: 24.652786254882812
 * Prec@1 65.880 Prec@5 87.430 Loss 1.4131
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 28.17747449874878

Epoch: [56][77/391]	LR: 2.0000000000000004e-07	Loss 0.1884 (0.1797)	Prec@1 99.219 (98.257)	
Epoch: [56][155/391]	LR: 2.0000000000000004e-07	Loss 0.1923 (0.1807)	Prec@1 98.438 (98.267)	
Epoch: [56][233/391]	LR: 2.0000000000000004e-07	Loss 0.1455 (0.1790)	Prec@1 98.438 (98.294)	
Epoch: [56][311/391]	LR: 2.0000000000000004e-07	Loss 0.1543 (0.1800)	Prec@1 99.219 (98.287)	
Epoch: [56][389/391]	LR: 2.0000000000000004e-07	Loss 0.1763 (0.1808)	Prec@1 100.000 (98.239)	
Total train loss: 0.1808

Train time: 25.23489546775818
 * Prec@1 65.800 Prec@5 87.450 Loss 1.4141
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.539848804473877

Epoch: [57][77/391]	LR: 2.0000000000000004e-07	Loss 0.1477 (0.1769)	Prec@1 100.000 (98.267)	
Epoch: [57][155/391]	LR: 2.0000000000000004e-07	Loss 0.1775 (0.1765)	Prec@1 97.656 (98.362)	
Epoch: [57][233/391]	LR: 2.0000000000000004e-07	Loss 0.1637 (0.1772)	Prec@1 97.656 (98.387)	
Epoch: [57][311/391]	LR: 2.0000000000000004e-07	Loss 0.1304 (0.1777)	Prec@1 100.000 (98.307)	
Epoch: [57][389/391]	LR: 2.0000000000000004e-07	Loss 0.2358 (0.1774)	Prec@1 96.875 (98.347)	
Total train loss: 0.1775

Train time: 24.412034273147583
 * Prec@1 65.800 Prec@5 87.470 Loss 1.4180
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 28.29140305519104

Epoch: [58][77/391]	LR: 2.0000000000000004e-07	Loss 0.2166 (0.1868)	Prec@1 97.656 (98.057)	
Epoch: [58][155/391]	LR: 2.0000000000000004e-07	Loss 0.2051 (0.1824)	Prec@1 96.875 (98.147)	
Epoch: [58][233/391]	LR: 2.0000000000000004e-07	Loss 0.1862 (0.1805)	Prec@1 96.875 (98.247)	
Epoch: [58][311/391]	LR: 2.0000000000000004e-07	Loss 0.2607 (0.1811)	Prec@1 94.531 (98.227)	
Epoch: [58][389/391]	LR: 2.0000000000000004e-07	Loss 0.1613 (0.1797)	Prec@1 98.438 (98.271)	
Total train loss: 0.1797

Train time: 24.820321321487427
 * Prec@1 66.150 Prec@5 87.320 Loss 1.4102
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 27.754449129104614

Epoch: [59][77/391]	LR: 2.0000000000000004e-07	Loss 0.1237 (0.1781)	Prec@1 99.219 (98.297)	
Epoch: [59][155/391]	LR: 2.0000000000000004e-07	Loss 0.1503 (0.1757)	Prec@1 99.219 (98.377)	
Epoch: [59][233/391]	LR: 2.0000000000000004e-07	Loss 0.1531 (0.1764)	Prec@1 99.219 (98.354)	
Epoch: [59][311/391]	LR: 2.0000000000000004e-07	Loss 0.2241 (0.1781)	Prec@1 96.094 (98.285)	
Epoch: [59][389/391]	LR: 2.0000000000000004e-07	Loss 0.1678 (0.1785)	Prec@1 98.438 (98.271)	
Total train loss: 0.1786

Train time: 26.85023307800293
 * Prec@1 65.800 Prec@5 87.230 Loss 1.4229
Best acc: 68.390
--------------------------------------------------------------------------------
Test time: 30.403457164764404


      ==> Arguments:
          dataset: cifar100
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/
          savedir: ../pretrained_models/frozen/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar100_i8b5f_w8b7f.pth.tar
          mode: rram
          workers: 8
          epochs: 60
          start_epoch: 0
          batch_size: 128
          lr: 0.002
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 7
          af_bit: 5
          w_bit: 7
          wf_bit: 7
          milestones: [20, 30, 40, 50]
          exp: x128-8b
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 3
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar100_i8b5f_w8b7f.pth.tar ...
Original model accuracy: 69.61000061035156
 * Prec@1 67.380 Prec@5 89.500 Loss 1.2559
Pre-trained Prec@1 with 3 layers frozen: 67.37999725341797 	 Loss: 1.255859375

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.002	Loss 0.6099 (0.5693)	Prec@1 82.812 (83.373)	
Epoch: [0][155/391]	LR: 0.002	Loss 0.6592 (0.5782)	Prec@1 82.031 (83.263)	
Epoch: [0][233/391]	LR: 0.002	Loss 0.7202 (0.5807)	Prec@1 79.688 (83.176)	
Epoch: [0][311/391]	LR: 0.002	Loss 0.6133 (0.5815)	Prec@1 83.594 (83.148)	
Epoch: [0][389/391]	LR: 0.002	Loss 0.5068 (0.5851)	Prec@1 86.719 (83.041)	
Total train loss: 0.5854

Train time: 86.67576813697815
 * Prec@1 68.750 Prec@5 90.120 Loss 1.2002
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 89.89155459403992

Epoch: [1][77/391]	LR: 0.002	Loss 0.5898 (0.4961)	Prec@1 82.812 (86.619)	
Epoch: [1][155/391]	LR: 0.002	Loss 0.3787 (0.5087)	Prec@1 92.188 (85.872)	
Epoch: [1][233/391]	LR: 0.002	Loss 0.5103 (0.5181)	Prec@1 85.156 (85.577)	
Epoch: [1][311/391]	LR: 0.002	Loss 0.5557 (0.5261)	Prec@1 82.812 (85.274)	
Epoch: [1][389/391]	LR: 0.002	Loss 0.5874 (0.5333)	Prec@1 84.375 (85.038)	
Total train loss: 0.5337

Train time: 23.01305842399597
 * Prec@1 68.150 Prec@5 89.700 Loss 1.2344
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 26.036079168319702

Epoch: [2][77/391]	LR: 0.002	Loss 0.5200 (0.4641)	Prec@1 85.156 (87.861)	
Epoch: [2][155/391]	LR: 0.002	Loss 0.4729 (0.4802)	Prec@1 85.156 (87.195)	
Epoch: [2][233/391]	LR: 0.002	Loss 0.5933 (0.4881)	Prec@1 82.031 (86.729)	
Epoch: [2][311/391]	LR: 0.002	Loss 0.4836 (0.4928)	Prec@1 89.062 (86.564)	
Epoch: [2][389/391]	LR: 0.002	Loss 0.4619 (0.4959)	Prec@1 86.719 (86.464)	
Total train loss: 0.4963

Train time: 22.585497856140137
 * Prec@1 68.020 Prec@5 89.760 Loss 1.2480
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.705767154693604

Epoch: [3][77/391]	LR: 0.002	Loss 0.5723 (0.4445)	Prec@1 82.812 (88.562)	
Epoch: [3][155/391]	LR: 0.002	Loss 0.5156 (0.4541)	Prec@1 85.156 (88.171)	
Epoch: [3][233/391]	LR: 0.002	Loss 0.5342 (0.4600)	Prec@1 89.062 (87.997)	
Epoch: [3][311/391]	LR: 0.002	Loss 0.4731 (0.4662)	Prec@1 84.375 (87.723)	
Epoch: [3][389/391]	LR: 0.002	Loss 0.4929 (0.4681)	Prec@1 85.938 (87.574)	
Total train loss: 0.4682

Train time: 22.02333664894104
 * Prec@1 67.520 Prec@5 89.460 Loss 1.2646
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.149762392044067

Epoch: [4][77/391]	LR: 0.002	Loss 0.4790 (0.4061)	Prec@1 83.594 (89.944)	
Epoch: [4][155/391]	LR: 0.002	Loss 0.5977 (0.4145)	Prec@1 82.812 (89.809)	
Epoch: [4][233/391]	LR: 0.002	Loss 0.4033 (0.4245)	Prec@1 89.062 (89.396)	
Epoch: [4][311/391]	LR: 0.002	Loss 0.4089 (0.4309)	Prec@1 88.281 (89.143)	
Epoch: [4][389/391]	LR: 0.002	Loss 0.5298 (0.4372)	Prec@1 87.500 (88.892)	
Total train loss: 0.4374

Train time: 22.802584171295166
 * Prec@1 67.700 Prec@5 89.270 Loss 1.2598
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.528679132461548

Epoch: [5][77/391]	LR: 0.002	Loss 0.3835 (0.4015)	Prec@1 89.844 (90.655)	
Epoch: [5][155/391]	LR: 0.002	Loss 0.4387 (0.4052)	Prec@1 88.281 (90.254)	
Epoch: [5][233/391]	LR: 0.002	Loss 0.4771 (0.4085)	Prec@1 88.281 (90.054)	
Epoch: [5][311/391]	LR: 0.002	Loss 0.5068 (0.4097)	Prec@1 85.156 (89.976)	
Epoch: [5][389/391]	LR: 0.002	Loss 0.3958 (0.4125)	Prec@1 89.844 (89.814)	
Total train loss: 0.4126

Train time: 22.962672472000122
 * Prec@1 67.190 Prec@5 89.160 Loss 1.2812
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 26.196577310562134

Epoch: [6][77/391]	LR: 0.002	Loss 0.4756 (0.3745)	Prec@1 89.062 (91.536)	
Epoch: [6][155/391]	LR: 0.002	Loss 0.3438 (0.3805)	Prec@1 91.406 (90.981)	
Epoch: [6][233/391]	LR: 0.002	Loss 0.5005 (0.3865)	Prec@1 82.812 (90.819)	
Epoch: [6][311/391]	LR: 0.002	Loss 0.4436 (0.3915)	Prec@1 87.500 (90.625)	
Epoch: [6][389/391]	LR: 0.002	Loss 0.4214 (0.3952)	Prec@1 89.062 (90.447)	
Total train loss: 0.3955

Train time: 21.72185969352722
 * Prec@1 66.880 Prec@5 89.250 Loss 1.3037
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.29018497467041

Epoch: [7][77/391]	LR: 0.002	Loss 0.3828 (0.3536)	Prec@1 89.062 (92.318)	
Epoch: [7][155/391]	LR: 0.002	Loss 0.3862 (0.3588)	Prec@1 92.188 (92.067)	
Epoch: [7][233/391]	LR: 0.002	Loss 0.3901 (0.3635)	Prec@1 91.406 (91.867)	
Epoch: [7][311/391]	LR: 0.002	Loss 0.4224 (0.3682)	Prec@1 91.406 (91.639)	
Epoch: [7][389/391]	LR: 0.002	Loss 0.3577 (0.3732)	Prec@1 89.844 (91.470)	
Total train loss: 0.3733

Train time: 22.051723957061768
 * Prec@1 67.160 Prec@5 88.800 Loss 1.3047
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.43647813796997

Epoch: [8][77/391]	LR: 0.002	Loss 0.3357 (0.3248)	Prec@1 92.969 (93.259)	
Epoch: [8][155/391]	LR: 0.002	Loss 0.3953 (0.3334)	Prec@1 89.844 (92.803)	
Epoch: [8][233/391]	LR: 0.002	Loss 0.3513 (0.3422)	Prec@1 92.188 (92.615)	
Epoch: [8][311/391]	LR: 0.002	Loss 0.4924 (0.3506)	Prec@1 87.500 (92.270)	
Epoch: [8][389/391]	LR: 0.002	Loss 0.4080 (0.3550)	Prec@1 88.281 (92.125)	
Total train loss: 0.3555

Train time: 21.444048404693604
 * Prec@1 66.430 Prec@5 88.410 Loss 1.3447
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.732293128967285

Epoch: [9][77/391]	LR: 0.002	Loss 0.2179 (0.3170)	Prec@1 99.219 (93.810)	
Epoch: [9][155/391]	LR: 0.002	Loss 0.4255 (0.3240)	Prec@1 89.062 (93.389)	
Epoch: [9][233/391]	LR: 0.002	Loss 0.3088 (0.3307)	Prec@1 94.531 (93.079)	
Epoch: [9][311/391]	LR: 0.002	Loss 0.3596 (0.3345)	Prec@1 89.844 (92.964)	
Epoch: [9][389/391]	LR: 0.002	Loss 0.3967 (0.3394)	Prec@1 91.406 (92.780)	
Total train loss: 0.3394

Train time: 21.96566414833069
 * Prec@1 66.580 Prec@5 88.280 Loss 1.3496
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.238444089889526

Epoch: [10][77/391]	LR: 0.002	Loss 0.3472 (0.2967)	Prec@1 92.969 (94.331)	
Epoch: [10][155/391]	LR: 0.002	Loss 0.3142 (0.3027)	Prec@1 93.750 (94.015)	
Epoch: [10][233/391]	LR: 0.002	Loss 0.3311 (0.3112)	Prec@1 93.750 (93.830)	
Epoch: [10][311/391]	LR: 0.002	Loss 0.2715 (0.3172)	Prec@1 96.094 (93.585)	
Epoch: [10][389/391]	LR: 0.002	Loss 0.3665 (0.3240)	Prec@1 94.531 (93.309)	
Total train loss: 0.3242

Train time: 22.000749588012695
 * Prec@1 66.600 Prec@5 88.290 Loss 1.3545
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.603179693222046

Epoch: [11][77/391]	LR: 0.002	Loss 0.3025 (0.2903)	Prec@1 92.188 (94.571)	
Epoch: [11][155/391]	LR: 0.002	Loss 0.3020 (0.2969)	Prec@1 92.188 (94.486)	
Epoch: [11][233/391]	LR: 0.002	Loss 0.3005 (0.3029)	Prec@1 94.531 (94.187)	
Epoch: [11][311/391]	LR: 0.002	Loss 0.3464 (0.3083)	Prec@1 89.844 (93.945)	
Epoch: [11][389/391]	LR: 0.002	Loss 0.3174 (0.3115)	Prec@1 92.969 (93.784)	
Total train loss: 0.3116

Train time: 21.673922777175903
 * Prec@1 66.220 Prec@5 88.340 Loss 1.3584
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.477484941482544

Epoch: [12][77/391]	LR: 0.002	Loss 0.2484 (0.2798)	Prec@1 96.875 (95.102)	
Epoch: [12][155/391]	LR: 0.002	Loss 0.3179 (0.2861)	Prec@1 93.750 (94.702)	
Epoch: [12][233/391]	LR: 0.002	Loss 0.3103 (0.2929)	Prec@1 94.531 (94.418)	
Epoch: [12][311/391]	LR: 0.002	Loss 0.3135 (0.2981)	Prec@1 95.312 (94.298)	
Epoch: [12][389/391]	LR: 0.002	Loss 0.3284 (0.3011)	Prec@1 92.188 (94.189)	
Total train loss: 0.3012

Train time: 21.492806673049927
 * Prec@1 66.010 Prec@5 87.800 Loss 1.3750
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.896656036376953

Epoch: [13][77/391]	LR: 0.002	Loss 0.2568 (0.2638)	Prec@1 96.094 (95.503)	
Epoch: [13][155/391]	LR: 0.002	Loss 0.2448 (0.2702)	Prec@1 97.656 (95.287)	
Epoch: [13][233/391]	LR: 0.002	Loss 0.3086 (0.2764)	Prec@1 93.750 (95.042)	
Epoch: [13][311/391]	LR: 0.002	Loss 0.2485 (0.2828)	Prec@1 95.312 (94.799)	
Epoch: [13][389/391]	LR: 0.002	Loss 0.2440 (0.2883)	Prec@1 95.312 (94.665)	
Total train loss: 0.2885

Train time: 25.456144094467163
 * Prec@1 66.070 Prec@5 87.870 Loss 1.3760
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 28.37844467163086

Epoch: [14][77/391]	LR: 0.002	Loss 0.2489 (0.2592)	Prec@1 96.094 (95.683)	
Epoch: [14][155/391]	LR: 0.002	Loss 0.2893 (0.2593)	Prec@1 95.312 (95.648)	
Epoch: [14][233/391]	LR: 0.002	Loss 0.2820 (0.2684)	Prec@1 96.094 (95.346)	
Epoch: [14][311/391]	LR: 0.002	Loss 0.2389 (0.2712)	Prec@1 96.875 (95.212)	
Epoch: [14][389/391]	LR: 0.002	Loss 0.3286 (0.2745)	Prec@1 93.750 (95.114)	
Total train loss: 0.2746

Train time: 22.221919059753418
 * Prec@1 65.640 Prec@5 87.870 Loss 1.3984
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.150120973587036

Epoch: [15][77/391]	LR: 0.002	Loss 0.1858 (0.2480)	Prec@1 98.438 (96.114)	
Epoch: [15][155/391]	LR: 0.002	Loss 0.3210 (0.2521)	Prec@1 94.531 (95.949)	
Epoch: [15][233/391]	LR: 0.002	Loss 0.3203 (0.2569)	Prec@1 92.188 (95.693)	
Epoch: [15][311/391]	LR: 0.002	Loss 0.2625 (0.2626)	Prec@1 97.656 (95.533)	
Epoch: [15][389/391]	LR: 0.002	Loss 0.2595 (0.2661)	Prec@1 94.531 (95.399)	
Total train loss: 0.2661

Train time: 22.34985661506653
 * Prec@1 66.020 Prec@5 88.040 Loss 1.3828
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.41013789176941

Epoch: [16][77/391]	LR: 0.002	Loss 0.2192 (0.2375)	Prec@1 99.219 (96.575)	
Epoch: [16][155/391]	LR: 0.002	Loss 0.2197 (0.2437)	Prec@1 98.438 (96.354)	
Epoch: [16][233/391]	LR: 0.002	Loss 0.2854 (0.2490)	Prec@1 95.312 (96.151)	
Epoch: [16][311/391]	LR: 0.002	Loss 0.3149 (0.2511)	Prec@1 93.750 (96.066)	
Epoch: [16][389/391]	LR: 0.002	Loss 0.2896 (0.2551)	Prec@1 92.969 (95.960)	
Total train loss: 0.2551

Train time: 21.380823850631714
 * Prec@1 65.600 Prec@5 87.710 Loss 1.4102
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.520107984542847

Epoch: [17][77/391]	LR: 0.002	Loss 0.2405 (0.2310)	Prec@1 95.312 (96.845)	
Epoch: [17][155/391]	LR: 0.002	Loss 0.2258 (0.2342)	Prec@1 95.312 (96.735)	
Epoch: [17][233/391]	LR: 0.002	Loss 0.2161 (0.2383)	Prec@1 96.875 (96.501)	
Epoch: [17][311/391]	LR: 0.002	Loss 0.2214 (0.2431)	Prec@1 96.875 (96.292)	
Epoch: [17][389/391]	LR: 0.002	Loss 0.2551 (0.2447)	Prec@1 95.312 (96.228)	
Total train loss: 0.2448

Train time: 21.86925172805786
 * Prec@1 65.480 Prec@5 87.420 Loss 1.4316
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.726332902908325

Epoch: [18][77/391]	LR: 0.002	Loss 0.2090 (0.2213)	Prec@1 95.312 (96.865)	
Epoch: [18][155/391]	LR: 0.002	Loss 0.2852 (0.2283)	Prec@1 95.312 (96.590)	
Epoch: [18][233/391]	LR: 0.002	Loss 0.2732 (0.2293)	Prec@1 95.312 (96.601)	
Epoch: [18][311/391]	LR: 0.002	Loss 0.2815 (0.2348)	Prec@1 94.531 (96.414)	
Epoch: [18][389/391]	LR: 0.002	Loss 0.3218 (0.2378)	Prec@1 94.531 (96.348)	
Total train loss: 0.2379

Train time: 21.428441047668457
 * Prec@1 65.360 Prec@5 87.270 Loss 1.4443
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.79323101043701

Epoch: [19][77/391]	LR: 0.002	Loss 0.1871 (0.2145)	Prec@1 99.219 (97.246)	
Epoch: [19][155/391]	LR: 0.002	Loss 0.2371 (0.2184)	Prec@1 99.219 (97.180)	
Epoch: [19][233/391]	LR: 0.002	Loss 0.2285 (0.2209)	Prec@1 95.312 (97.079)	
Epoch: [19][311/391]	LR: 0.002	Loss 0.2057 (0.2256)	Prec@1 95.312 (96.925)	
Epoch: [19][389/391]	LR: 0.002	Loss 0.2196 (0.2283)	Prec@1 98.438 (96.793)	
Total train loss: 0.2286

Train time: 21.008660078048706
 * Prec@1 65.630 Prec@5 87.540 Loss 1.4150
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.018670082092285

Epoch: [20][77/391]	LR: 0.0002	Loss 0.1729 (0.2035)	Prec@1 98.438 (97.446)	
Epoch: [20][155/391]	LR: 0.0002	Loss 0.1792 (0.1998)	Prec@1 98.438 (97.596)	
Epoch: [20][233/391]	LR: 0.0002	Loss 0.2198 (0.1997)	Prec@1 98.438 (97.546)	
Epoch: [20][311/391]	LR: 0.0002	Loss 0.1774 (0.2004)	Prec@1 99.219 (97.586)	
Epoch: [20][389/391]	LR: 0.0002	Loss 0.1831 (0.1989)	Prec@1 96.875 (97.600)	
Total train loss: 0.1990

Train time: 21.357682466506958
 * Prec@1 65.830 Prec@5 87.500 Loss 1.4170
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.32380509376526

Epoch: [21][77/391]	LR: 0.0002	Loss 0.2250 (0.1916)	Prec@1 96.875 (97.987)	
Epoch: [21][155/391]	LR: 0.0002	Loss 0.2556 (0.1952)	Prec@1 95.312 (97.867)	
Epoch: [21][233/391]	LR: 0.0002	Loss 0.1790 (0.1937)	Prec@1 96.875 (97.897)	
Epoch: [21][311/391]	LR: 0.0002	Loss 0.1495 (0.1926)	Prec@1 98.438 (97.954)	
Epoch: [21][389/391]	LR: 0.0002	Loss 0.2068 (0.1927)	Prec@1 98.438 (97.935)	
Total train loss: 0.1928

Train time: 22.26161503791809
 * Prec@1 65.520 Prec@5 87.320 Loss 1.4287
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.258540630340576

Epoch: [22][77/391]	LR: 0.0002	Loss 0.2113 (0.1874)	Prec@1 96.094 (98.037)	
Epoch: [22][155/391]	LR: 0.0002	Loss 0.1851 (0.1879)	Prec@1 99.219 (98.072)	
Epoch: [22][233/391]	LR: 0.0002	Loss 0.2134 (0.1889)	Prec@1 97.656 (98.000)	
Epoch: [22][311/391]	LR: 0.0002	Loss 0.2302 (0.1908)	Prec@1 98.438 (97.952)	
Epoch: [22][389/391]	LR: 0.0002	Loss 0.1914 (0.1898)	Prec@1 99.219 (97.981)	
Total train loss: 0.1900

Train time: 22.097240209579468
 * Prec@1 65.700 Prec@5 87.400 Loss 1.4170
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.715302228927612

Epoch: [23][77/391]	LR: 0.0002	Loss 0.1794 (0.1841)	Prec@1 97.656 (98.067)	
Epoch: [23][155/391]	LR: 0.0002	Loss 0.1793 (0.1867)	Prec@1 99.219 (97.947)	
Epoch: [23][233/391]	LR: 0.0002	Loss 0.1573 (0.1871)	Prec@1 97.656 (97.940)	
Epoch: [23][311/391]	LR: 0.0002	Loss 0.1465 (0.1874)	Prec@1 100.000 (97.949)	
Epoch: [23][389/391]	LR: 0.0002	Loss 0.2026 (0.1878)	Prec@1 96.875 (97.961)	
Total train loss: 0.1878

Train time: 21.127923011779785
 * Prec@1 65.700 Prec@5 87.700 Loss 1.4092
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 23.32408618927002

Epoch: [24][77/391]	LR: 0.0002	Loss 0.1460 (0.1897)	Prec@1 98.438 (97.917)	
Epoch: [24][155/391]	LR: 0.0002	Loss 0.1897 (0.1877)	Prec@1 97.656 (97.917)	
Epoch: [24][233/391]	LR: 0.0002	Loss 0.1774 (0.1880)	Prec@1 97.656 (97.987)	
Epoch: [24][311/391]	LR: 0.0002	Loss 0.2045 (0.1860)	Prec@1 98.438 (98.009)	
Epoch: [24][389/391]	LR: 0.0002	Loss 0.1511 (0.1866)	Prec@1 100.000 (98.047)	
Total train loss: 0.1867

Train time: 18.310051202774048
 * Prec@1 65.490 Prec@5 87.500 Loss 1.4248
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 20.69451332092285

Epoch: [25][77/391]	LR: 0.0002	Loss 0.2034 (0.1811)	Prec@1 96.094 (98.317)	
Epoch: [25][155/391]	LR: 0.0002	Loss 0.2184 (0.1835)	Prec@1 97.656 (98.122)	
Epoch: [25][233/391]	LR: 0.0002	Loss 0.1980 (0.1838)	Prec@1 97.656 (98.137)	
Epoch: [25][311/391]	LR: 0.0002	Loss 0.1321 (0.1856)	Prec@1 99.219 (98.062)	
Epoch: [25][389/391]	LR: 0.0002	Loss 0.1958 (0.1860)	Prec@1 96.875 (98.029)	
Total train loss: 0.1863

Train time: 18.53346586227417
 * Prec@1 65.620 Prec@5 87.510 Loss 1.4160
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 22.258915185928345

Epoch: [26][77/391]	LR: 0.0002	Loss 0.1813 (0.1818)	Prec@1 96.094 (98.207)	
Epoch: [26][155/391]	LR: 0.0002	Loss 0.1807 (0.1834)	Prec@1 98.438 (98.112)	
Epoch: [26][233/391]	LR: 0.0002	Loss 0.1672 (0.1848)	Prec@1 97.656 (98.060)	
Epoch: [26][311/391]	LR: 0.0002	Loss 0.1805 (0.1850)	Prec@1 96.875 (98.062)	
Epoch: [26][389/391]	LR: 0.0002	Loss 0.1920 (0.1855)	Prec@1 98.438 (98.055)	
Total train loss: 0.1856

Train time: 19.96885895729065
 * Prec@1 65.730 Prec@5 87.350 Loss 1.4248
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 23.29314422607422

Epoch: [27][77/391]	LR: 0.0002	Loss 0.1903 (0.1840)	Prec@1 98.438 (98.097)	
Epoch: [27][155/391]	LR: 0.0002	Loss 0.2129 (0.1856)	Prec@1 98.438 (97.992)	
Epoch: [27][233/391]	LR: 0.0002	Loss 0.1804 (0.1845)	Prec@1 98.438 (98.064)	
Epoch: [27][311/391]	LR: 0.0002	Loss 0.1978 (0.1847)	Prec@1 98.438 (98.052)	
Epoch: [27][389/391]	LR: 0.0002	Loss 0.1847 (0.1846)	Prec@1 96.094 (98.067)	
Total train loss: 0.1847

Train time: 18.537962913513184
 * Prec@1 65.580 Prec@5 87.660 Loss 1.4170
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 21.21279239654541

Epoch: [28][77/391]	LR: 0.0002	Loss 0.1302 (0.1813)	Prec@1 99.219 (98.357)	
Epoch: [28][155/391]	LR: 0.0002	Loss 0.1846 (0.1828)	Prec@1 100.000 (98.242)	
Epoch: [28][233/391]	LR: 0.0002	Loss 0.1941 (0.1822)	Prec@1 98.438 (98.227)	
Epoch: [28][311/391]	LR: 0.0002	Loss 0.1608 (0.1821)	Prec@1 100.000 (98.257)	
Epoch: [28][389/391]	LR: 0.0002	Loss 0.1875 (0.1819)	Prec@1 96.094 (98.241)	
Total train loss: 0.1822

Train time: 21.53531002998352
 * Prec@1 65.550 Prec@5 87.600 Loss 1.4180
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.84390902519226

Epoch: [29][77/391]	LR: 0.0002	Loss 0.1835 (0.1843)	Prec@1 98.438 (98.167)	
Epoch: [29][155/391]	LR: 0.0002	Loss 0.1842 (0.1801)	Prec@1 98.438 (98.277)	
Epoch: [29][233/391]	LR: 0.0002	Loss 0.1891 (0.1812)	Prec@1 98.438 (98.291)	
Epoch: [29][311/391]	LR: 0.0002	Loss 0.2097 (0.1818)	Prec@1 99.219 (98.257)	
Epoch: [29][389/391]	LR: 0.0002	Loss 0.2448 (0.1829)	Prec@1 96.875 (98.209)	
Total train loss: 0.1830

Train time: 21.598695516586304
 * Prec@1 65.520 Prec@5 87.540 Loss 1.4287
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 23.936920642852783

Epoch: [30][77/391]	LR: 2e-05	Loss 0.1672 (0.1789)	Prec@1 99.219 (98.337)	
Epoch: [30][155/391]	LR: 2e-05	Loss 0.1801 (0.1812)	Prec@1 97.656 (98.217)	
Epoch: [30][233/391]	LR: 2e-05	Loss 0.1635 (0.1806)	Prec@1 99.219 (98.231)	
Epoch: [30][311/391]	LR: 2e-05	Loss 0.1545 (0.1811)	Prec@1 98.438 (98.205)	
Epoch: [30][389/391]	LR: 2e-05	Loss 0.1805 (0.1810)	Prec@1 99.219 (98.209)	
Total train loss: 0.1811

Train time: 21.396934032440186
 * Prec@1 65.720 Prec@5 87.570 Loss 1.4180
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.323100805282593

Epoch: [31][77/391]	LR: 2e-05	Loss 0.2085 (0.1867)	Prec@1 97.656 (98.007)	
Epoch: [31][155/391]	LR: 2e-05	Loss 0.1863 (0.1833)	Prec@1 97.656 (98.172)	
Epoch: [31][233/391]	LR: 2e-05	Loss 0.2454 (0.1843)	Prec@1 95.312 (98.104)	
Epoch: [31][311/391]	LR: 2e-05	Loss 0.1980 (0.1847)	Prec@1 98.438 (98.112)	
Epoch: [31][389/391]	LR: 2e-05	Loss 0.1387 (0.1831)	Prec@1 99.219 (98.139)	
Total train loss: 0.1831

Train time: 21.973790645599365
 * Prec@1 65.590 Prec@5 87.280 Loss 1.4229
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 27.374816179275513

Epoch: [32][77/391]	LR: 2e-05	Loss 0.1750 (0.1829)	Prec@1 98.438 (98.177)	
Epoch: [32][155/391]	LR: 2e-05	Loss 0.1993 (0.1812)	Prec@1 97.656 (98.207)	
Epoch: [32][233/391]	LR: 2e-05	Loss 0.1945 (0.1824)	Prec@1 96.094 (98.184)	
Epoch: [32][311/391]	LR: 2e-05	Loss 0.1697 (0.1819)	Prec@1 97.656 (98.180)	
Epoch: [32][389/391]	LR: 2e-05	Loss 0.1543 (0.1820)	Prec@1 96.875 (98.169)	
Total train loss: 0.1821

Train time: 22.41934084892273
 * Prec@1 65.410 Prec@5 87.420 Loss 1.4189
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.85316491127014

Epoch: [33][77/391]	LR: 2e-05	Loss 0.2085 (0.1819)	Prec@1 97.656 (98.267)	
Epoch: [33][155/391]	LR: 2e-05	Loss 0.1768 (0.1807)	Prec@1 97.656 (98.367)	
Epoch: [33][233/391]	LR: 2e-05	Loss 0.1708 (0.1791)	Prec@1 99.219 (98.401)	
Epoch: [33][311/391]	LR: 2e-05	Loss 0.2144 (0.1797)	Prec@1 98.438 (98.340)	
Epoch: [33][389/391]	LR: 2e-05	Loss 0.1582 (0.1802)	Prec@1 97.656 (98.287)	
Total train loss: 0.1802

Train time: 21.103237867355347
 * Prec@1 65.540 Prec@5 87.450 Loss 1.4150
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 23.231788873672485

Epoch: [34][77/391]	LR: 2e-05	Loss 0.1848 (0.1831)	Prec@1 97.656 (98.137)	
Epoch: [34][155/391]	LR: 2e-05	Loss 0.1755 (0.1803)	Prec@1 98.438 (98.232)	
Epoch: [34][233/391]	LR: 2e-05	Loss 0.1812 (0.1811)	Prec@1 97.656 (98.220)	
Epoch: [34][311/391]	LR: 2e-05	Loss 0.1792 (0.1809)	Prec@1 100.000 (98.250)	
Epoch: [34][389/391]	LR: 2e-05	Loss 0.2568 (0.1816)	Prec@1 97.656 (98.257)	
Total train loss: 0.1817

Train time: 22.2602801322937
 * Prec@1 65.240 Prec@5 87.460 Loss 1.4248
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.779333114624023

Epoch: [35][77/391]	LR: 2e-05	Loss 0.1704 (0.1796)	Prec@1 100.000 (98.377)	
Epoch: [35][155/391]	LR: 2e-05	Loss 0.1840 (0.1792)	Prec@1 98.438 (98.377)	
Epoch: [35][233/391]	LR: 2e-05	Loss 0.2023 (0.1801)	Prec@1 95.312 (98.301)	
Epoch: [35][311/391]	LR: 2e-05	Loss 0.1824 (0.1811)	Prec@1 97.656 (98.220)	
Epoch: [35][389/391]	LR: 2e-05	Loss 0.1354 (0.1819)	Prec@1 99.219 (98.211)	
Total train loss: 0.1820

Train time: 21.483136892318726
 * Prec@1 65.520 Prec@5 87.450 Loss 1.4297
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.241225957870483

Epoch: [36][77/391]	LR: 2e-05	Loss 0.1711 (0.1788)	Prec@1 98.438 (98.468)	
Epoch: [36][155/391]	LR: 2e-05	Loss 0.1637 (0.1798)	Prec@1 99.219 (98.227)	
Epoch: [36][233/391]	LR: 2e-05	Loss 0.1880 (0.1794)	Prec@1 98.438 (98.334)	
Epoch: [36][311/391]	LR: 2e-05	Loss 0.1971 (0.1806)	Prec@1 98.438 (98.330)	
Epoch: [36][389/391]	LR: 2e-05	Loss 0.1700 (0.1816)	Prec@1 100.000 (98.287)	
Total train loss: 0.1816

Train time: 21.562837839126587
 * Prec@1 65.720 Prec@5 87.470 Loss 1.4199
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.80067205429077

Epoch: [37][77/391]	LR: 2e-05	Loss 0.2166 (0.1765)	Prec@1 96.875 (98.468)	
Epoch: [37][155/391]	LR: 2e-05	Loss 0.1324 (0.1768)	Prec@1 99.219 (98.367)	
Epoch: [37][233/391]	LR: 2e-05	Loss 0.1910 (0.1786)	Prec@1 98.438 (98.301)	
Epoch: [37][311/391]	LR: 2e-05	Loss 0.1985 (0.1799)	Prec@1 97.656 (98.277)	
Epoch: [37][389/391]	LR: 2e-05	Loss 0.1838 (0.1803)	Prec@1 99.219 (98.283)	
Total train loss: 0.1804

Train time: 21.348012924194336
 * Prec@1 65.620 Prec@5 87.380 Loss 1.4170
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.46096968650818

Epoch: [38][77/391]	LR: 2e-05	Loss 0.1752 (0.1805)	Prec@1 100.000 (98.107)	
Epoch: [38][155/391]	LR: 2e-05	Loss 0.1628 (0.1799)	Prec@1 99.219 (98.232)	
Epoch: [38][233/391]	LR: 2e-05	Loss 0.2159 (0.1796)	Prec@1 96.875 (98.301)	
Epoch: [38][311/391]	LR: 2e-05	Loss 0.2234 (0.1796)	Prec@1 97.656 (98.320)	
Epoch: [38][389/391]	LR: 2e-05	Loss 0.1523 (0.1799)	Prec@1 98.438 (98.261)	
Total train loss: 0.1799

Train time: 21.750900745391846
 * Prec@1 65.620 Prec@5 87.620 Loss 1.4180
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.810526609420776

Epoch: [39][77/391]	LR: 2e-05	Loss 0.1506 (0.1826)	Prec@1 100.000 (98.217)	
Epoch: [39][155/391]	LR: 2e-05	Loss 0.1724 (0.1827)	Prec@1 99.219 (98.167)	
Epoch: [39][233/391]	LR: 2e-05	Loss 0.1814 (0.1831)	Prec@1 97.656 (98.174)	
Epoch: [39][311/391]	LR: 2e-05	Loss 0.1573 (0.1835)	Prec@1 99.219 (98.235)	
Epoch: [39][389/391]	LR: 2e-05	Loss 0.1658 (0.1818)	Prec@1 97.656 (98.281)	
Total train loss: 0.1818

Train time: 21.054200649261475
 * Prec@1 65.560 Prec@5 87.310 Loss 1.4209
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.09247636795044

Epoch: [40][77/391]	LR: 2.0000000000000003e-06	Loss 0.1866 (0.1813)	Prec@1 98.438 (98.187)	
Epoch: [40][155/391]	LR: 2.0000000000000003e-06	Loss 0.1475 (0.1790)	Prec@1 98.438 (98.197)	
Epoch: [40][233/391]	LR: 2.0000000000000003e-06	Loss 0.2029 (0.1792)	Prec@1 99.219 (98.257)	
Epoch: [40][311/391]	LR: 2.0000000000000003e-06	Loss 0.1387 (0.1800)	Prec@1 99.219 (98.242)	
Epoch: [40][389/391]	LR: 2.0000000000000003e-06	Loss 0.2151 (0.1808)	Prec@1 97.656 (98.217)	
Total train loss: 0.1809

Train time: 22.153680086135864
 * Prec@1 65.700 Prec@5 87.400 Loss 1.4180
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.6660315990448

Epoch: [41][77/391]	LR: 2.0000000000000003e-06	Loss 0.1627 (0.1813)	Prec@1 99.219 (98.327)	
Epoch: [41][155/391]	LR: 2.0000000000000003e-06	Loss 0.1573 (0.1801)	Prec@1 99.219 (98.217)	
Epoch: [41][233/391]	LR: 2.0000000000000003e-06	Loss 0.1753 (0.1801)	Prec@1 96.875 (98.214)	
Epoch: [41][311/391]	LR: 2.0000000000000003e-06	Loss 0.1772 (0.1803)	Prec@1 96.875 (98.232)	
Epoch: [41][389/391]	LR: 2.0000000000000003e-06	Loss 0.1437 (0.1806)	Prec@1 98.438 (98.223)	
Total train loss: 0.1806

Train time: 20.76914930343628
 * Prec@1 65.740 Prec@5 87.630 Loss 1.4209
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 23.898969888687134

Epoch: [42][77/391]	LR: 2.0000000000000003e-06	Loss 0.1652 (0.1756)	Prec@1 99.219 (98.227)	
Epoch: [42][155/391]	LR: 2.0000000000000003e-06	Loss 0.1918 (0.1795)	Prec@1 98.438 (98.197)	
Epoch: [42][233/391]	LR: 2.0000000000000003e-06	Loss 0.2546 (0.1798)	Prec@1 96.094 (98.244)	
Epoch: [42][311/391]	LR: 2.0000000000000003e-06	Loss 0.1910 (0.1800)	Prec@1 97.656 (98.220)	
Epoch: [42][389/391]	LR: 2.0000000000000003e-06	Loss 0.1847 (0.1805)	Prec@1 98.438 (98.211)	
Total train loss: 0.1806

Train time: 21.725513458251953
 * Prec@1 65.800 Prec@5 87.510 Loss 1.4170
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.83134651184082

Epoch: [43][77/391]	LR: 2.0000000000000003e-06	Loss 0.1899 (0.1825)	Prec@1 96.094 (97.997)	
Epoch: [43][155/391]	LR: 2.0000000000000003e-06	Loss 0.1383 (0.1793)	Prec@1 98.438 (98.142)	
Epoch: [43][233/391]	LR: 2.0000000000000003e-06	Loss 0.2206 (0.1795)	Prec@1 96.875 (98.170)	
Epoch: [43][311/391]	LR: 2.0000000000000003e-06	Loss 0.1790 (0.1794)	Prec@1 99.219 (98.220)	
Epoch: [43][389/391]	LR: 2.0000000000000003e-06	Loss 0.1633 (0.1794)	Prec@1 98.438 (98.227)	
Total train loss: 0.1795

Train time: 20.841076135635376
 * Prec@1 65.350 Prec@5 87.200 Loss 1.4297
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 23.786343097686768

Epoch: [44][77/391]	LR: 2.0000000000000003e-06	Loss 0.2603 (0.1802)	Prec@1 95.312 (98.117)	
Epoch: [44][155/391]	LR: 2.0000000000000003e-06	Loss 0.1721 (0.1790)	Prec@1 99.219 (98.227)	
Epoch: [44][233/391]	LR: 2.0000000000000003e-06	Loss 0.1937 (0.1807)	Prec@1 96.875 (98.187)	
Epoch: [44][311/391]	LR: 2.0000000000000003e-06	Loss 0.1570 (0.1812)	Prec@1 99.219 (98.185)	
Epoch: [44][389/391]	LR: 2.0000000000000003e-06	Loss 0.2249 (0.1807)	Prec@1 98.438 (98.177)	
Total train loss: 0.1807

Train time: 21.85526752471924
 * Prec@1 65.650 Prec@5 87.390 Loss 1.4199
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.170448303222656

Epoch: [45][77/391]	LR: 2.0000000000000003e-06	Loss 0.2086 (0.1813)	Prec@1 97.656 (98.247)	
Epoch: [45][155/391]	LR: 2.0000000000000003e-06	Loss 0.1764 (0.1790)	Prec@1 99.219 (98.312)	
Epoch: [45][233/391]	LR: 2.0000000000000003e-06	Loss 0.1774 (0.1798)	Prec@1 99.219 (98.224)	
Epoch: [45][311/391]	LR: 2.0000000000000003e-06	Loss 0.2549 (0.1786)	Prec@1 93.750 (98.257)	
Epoch: [45][389/391]	LR: 2.0000000000000003e-06	Loss 0.1929 (0.1783)	Prec@1 97.656 (98.275)	
Total train loss: 0.1784

Train time: 21.94509983062744
 * Prec@1 65.570 Prec@5 87.480 Loss 1.4219
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.61374521255493

Epoch: [46][77/391]	LR: 2.0000000000000003e-06	Loss 0.2583 (0.1818)	Prec@1 96.875 (98.187)	
Epoch: [46][155/391]	LR: 2.0000000000000003e-06	Loss 0.1938 (0.1810)	Prec@1 96.094 (98.292)	
Epoch: [46][233/391]	LR: 2.0000000000000003e-06	Loss 0.1644 (0.1820)	Prec@1 98.438 (98.254)	
Epoch: [46][311/391]	LR: 2.0000000000000003e-06	Loss 0.1771 (0.1821)	Prec@1 96.875 (98.235)	
Epoch: [46][389/391]	LR: 2.0000000000000003e-06	Loss 0.2294 (0.1810)	Prec@1 92.969 (98.239)	
Total train loss: 0.1811

Train time: 20.957540273666382
 * Prec@1 65.590 Prec@5 87.550 Loss 1.4170
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.31220817565918

Epoch: [47][77/391]	LR: 2.0000000000000003e-06	Loss 0.2544 (0.1804)	Prec@1 95.312 (98.317)	
Epoch: [47][155/391]	LR: 2.0000000000000003e-06	Loss 0.1605 (0.1839)	Prec@1 99.219 (98.192)	
Epoch: [47][233/391]	LR: 2.0000000000000003e-06	Loss 0.1622 (0.1823)	Prec@1 96.875 (98.140)	
Epoch: [47][311/391]	LR: 2.0000000000000003e-06	Loss 0.1840 (0.1815)	Prec@1 96.875 (98.205)	
Epoch: [47][389/391]	LR: 2.0000000000000003e-06	Loss 0.1859 (0.1811)	Prec@1 97.656 (98.167)	
Total train loss: 0.1812

Train time: 21.537031412124634
 * Prec@1 65.370 Prec@5 87.470 Loss 1.4160
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.686269998550415

Epoch: [48][77/391]	LR: 2.0000000000000003e-06	Loss 0.2063 (0.1840)	Prec@1 98.438 (98.337)	
Epoch: [48][155/391]	LR: 2.0000000000000003e-06	Loss 0.1420 (0.1807)	Prec@1 98.438 (98.267)	
Epoch: [48][233/391]	LR: 2.0000000000000003e-06	Loss 0.2083 (0.1818)	Prec@1 96.094 (98.210)	
Epoch: [48][311/391]	LR: 2.0000000000000003e-06	Loss 0.1986 (0.1813)	Prec@1 99.219 (98.187)	
Epoch: [48][389/391]	LR: 2.0000000000000003e-06	Loss 0.1875 (0.1810)	Prec@1 96.875 (98.225)	
Total train loss: 0.1813

Train time: 22.002145051956177
 * Prec@1 65.570 Prec@5 87.280 Loss 1.4287
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.20779776573181

Epoch: [49][77/391]	LR: 2.0000000000000003e-06	Loss 0.1744 (0.1847)	Prec@1 98.438 (98.217)	
Epoch: [49][155/391]	LR: 2.0000000000000003e-06	Loss 0.2334 (0.1830)	Prec@1 96.094 (98.207)	
Epoch: [49][233/391]	LR: 2.0000000000000003e-06	Loss 0.1608 (0.1814)	Prec@1 100.000 (98.241)	
Epoch: [49][311/391]	LR: 2.0000000000000003e-06	Loss 0.1755 (0.1814)	Prec@1 99.219 (98.232)	
Epoch: [49][389/391]	LR: 2.0000000000000003e-06	Loss 0.1783 (0.1812)	Prec@1 96.875 (98.233)	
Total train loss: 0.1813

Train time: 22.349111318588257
 * Prec@1 65.840 Prec@5 87.350 Loss 1.4229
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 28.539491176605225

Epoch: [50][77/391]	LR: 2.0000000000000004e-07	Loss 0.2272 (0.1814)	Prec@1 97.656 (98.107)	
Epoch: [50][155/391]	LR: 2.0000000000000004e-07	Loss 0.2091 (0.1837)	Prec@1 98.438 (98.072)	
Epoch: [50][233/391]	LR: 2.0000000000000004e-07	Loss 0.1422 (0.1807)	Prec@1 98.438 (98.160)	
Epoch: [50][311/391]	LR: 2.0000000000000004e-07	Loss 0.1504 (0.1795)	Prec@1 99.219 (98.212)	
Epoch: [50][389/391]	LR: 2.0000000000000004e-07	Loss 0.1661 (0.1804)	Prec@1 99.219 (98.213)	
Total train loss: 0.1805

Train time: 22.05726957321167
 * Prec@1 65.600 Prec@5 87.670 Loss 1.4238
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.44938898086548

Epoch: [51][77/391]	LR: 2.0000000000000004e-07	Loss 0.2174 (0.1841)	Prec@1 97.656 (97.967)	
Epoch: [51][155/391]	LR: 2.0000000000000004e-07	Loss 0.1820 (0.1831)	Prec@1 99.219 (98.007)	
Epoch: [51][233/391]	LR: 2.0000000000000004e-07	Loss 0.1985 (0.1816)	Prec@1 100.000 (98.084)	
Epoch: [51][311/391]	LR: 2.0000000000000004e-07	Loss 0.1774 (0.1817)	Prec@1 98.438 (98.109)	
Epoch: [51][389/391]	LR: 2.0000000000000004e-07	Loss 0.1678 (0.1812)	Prec@1 98.438 (98.109)	
Total train loss: 0.1813

Train time: 21.359887838363647
 * Prec@1 65.470 Prec@5 87.500 Loss 1.4229
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.044610261917114

Epoch: [52][77/391]	LR: 2.0000000000000004e-07	Loss 0.2167 (0.1798)	Prec@1 97.656 (98.357)	
Epoch: [52][155/391]	LR: 2.0000000000000004e-07	Loss 0.1554 (0.1809)	Prec@1 98.438 (98.217)	
Epoch: [52][233/391]	LR: 2.0000000000000004e-07	Loss 0.1769 (0.1804)	Prec@1 98.438 (98.254)	
Epoch: [52][311/391]	LR: 2.0000000000000004e-07	Loss 0.1576 (0.1788)	Prec@1 99.219 (98.262)	
Epoch: [52][389/391]	LR: 2.0000000000000004e-07	Loss 0.1670 (0.1794)	Prec@1 98.438 (98.215)	
Total train loss: 0.1797

Train time: 21.89180588722229
 * Prec@1 65.480 Prec@5 87.580 Loss 1.4150
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.330132961273193

Epoch: [53][77/391]	LR: 2.0000000000000004e-07	Loss 0.2081 (0.1832)	Prec@1 95.312 (98.227)	
Epoch: [53][155/391]	LR: 2.0000000000000004e-07	Loss 0.1379 (0.1825)	Prec@1 100.000 (98.172)	
Epoch: [53][233/391]	LR: 2.0000000000000004e-07	Loss 0.1931 (0.1828)	Prec@1 99.219 (98.180)	
Epoch: [53][311/391]	LR: 2.0000000000000004e-07	Loss 0.2253 (0.1833)	Prec@1 96.094 (98.152)	
Epoch: [53][389/391]	LR: 2.0000000000000004e-07	Loss 0.2234 (0.1819)	Prec@1 97.656 (98.209)	
Total train loss: 0.1819

Train time: 22.292662382125854
 * Prec@1 65.430 Prec@5 87.170 Loss 1.4248
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.82972025871277

Epoch: [54][77/391]	LR: 2.0000000000000004e-07	Loss 0.1742 (0.1813)	Prec@1 98.438 (98.217)	
Epoch: [54][155/391]	LR: 2.0000000000000004e-07	Loss 0.1696 (0.1798)	Prec@1 97.656 (98.247)	
Epoch: [54][233/391]	LR: 2.0000000000000004e-07	Loss 0.1676 (0.1820)	Prec@1 97.656 (98.160)	
Epoch: [54][311/391]	LR: 2.0000000000000004e-07	Loss 0.2152 (0.1813)	Prec@1 96.875 (98.162)	
Epoch: [54][389/391]	LR: 2.0000000000000004e-07	Loss 0.1917 (0.1816)	Prec@1 97.656 (98.121)	
Total train loss: 0.1819

Train time: 22.235663414001465
 * Prec@1 65.490 Prec@5 87.420 Loss 1.4229
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.606818199157715

Epoch: [55][77/391]	LR: 2.0000000000000004e-07	Loss 0.2266 (0.1838)	Prec@1 96.094 (98.407)	
Epoch: [55][155/391]	LR: 2.0000000000000004e-07	Loss 0.1680 (0.1807)	Prec@1 98.438 (98.458)	
Epoch: [55][233/391]	LR: 2.0000000000000004e-07	Loss 0.1581 (0.1826)	Prec@1 98.438 (98.344)	
Epoch: [55][311/391]	LR: 2.0000000000000004e-07	Loss 0.1525 (0.1817)	Prec@1 98.438 (98.350)	
Epoch: [55][389/391]	LR: 2.0000000000000004e-07	Loss 0.1492 (0.1809)	Prec@1 100.000 (98.355)	
Total train loss: 0.1809

Train time: 21.26647710800171
 * Prec@1 65.440 Prec@5 87.540 Loss 1.4258
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.022438526153564

Epoch: [56][77/391]	LR: 2.0000000000000004e-07	Loss 0.1458 (0.1808)	Prec@1 99.219 (98.277)	
Epoch: [56][155/391]	LR: 2.0000000000000004e-07	Loss 0.1924 (0.1802)	Prec@1 99.219 (98.287)	
Epoch: [56][233/391]	LR: 2.0000000000000004e-07	Loss 0.2319 (0.1809)	Prec@1 99.219 (98.264)	
Epoch: [56][311/391]	LR: 2.0000000000000004e-07	Loss 0.1576 (0.1805)	Prec@1 100.000 (98.270)	
Epoch: [56][389/391]	LR: 2.0000000000000004e-07	Loss 0.1431 (0.1809)	Prec@1 99.219 (98.275)	
Total train loss: 0.1809

Train time: 21.283679485321045
 * Prec@1 65.490 Prec@5 87.400 Loss 1.4209
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.760292291641235

Epoch: [57][77/391]	LR: 2.0000000000000004e-07	Loss 0.1552 (0.1809)	Prec@1 97.656 (98.067)	
Epoch: [57][155/391]	LR: 2.0000000000000004e-07	Loss 0.1191 (0.1796)	Prec@1 99.219 (98.157)	
Epoch: [57][233/391]	LR: 2.0000000000000004e-07	Loss 0.2083 (0.1809)	Prec@1 97.656 (98.190)	
Epoch: [57][311/391]	LR: 2.0000000000000004e-07	Loss 0.1987 (0.1808)	Prec@1 96.094 (98.202)	
Epoch: [57][389/391]	LR: 2.0000000000000004e-07	Loss 0.1836 (0.1802)	Prec@1 98.438 (98.245)	
Total train loss: 0.1803

Train time: 21.764516830444336
 * Prec@1 65.520 Prec@5 87.370 Loss 1.4248
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.974621772766113

Epoch: [58][77/391]	LR: 2.0000000000000004e-07	Loss 0.2004 (0.1823)	Prec@1 97.656 (98.147)	
Epoch: [58][155/391]	LR: 2.0000000000000004e-07	Loss 0.1451 (0.1838)	Prec@1 98.438 (98.082)	
Epoch: [58][233/391]	LR: 2.0000000000000004e-07	Loss 0.1830 (0.1829)	Prec@1 98.438 (98.130)	
Epoch: [58][311/391]	LR: 2.0000000000000004e-07	Loss 0.1974 (0.1823)	Prec@1 96.875 (98.152)	
Epoch: [58][389/391]	LR: 2.0000000000000004e-07	Loss 0.2058 (0.1817)	Prec@1 98.438 (98.189)	
Total train loss: 0.1819

Train time: 22.23865056037903
 * Prec@1 65.600 Prec@5 87.420 Loss 1.4219
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 25.54503607749939

Epoch: [59][77/391]	LR: 2.0000000000000004e-07	Loss 0.2091 (0.1778)	Prec@1 97.656 (98.347)	
Epoch: [59][155/391]	LR: 2.0000000000000004e-07	Loss 0.1516 (0.1800)	Prec@1 99.219 (98.267)	
Epoch: [59][233/391]	LR: 2.0000000000000004e-07	Loss 0.1727 (0.1809)	Prec@1 97.656 (98.271)	
Epoch: [59][311/391]	LR: 2.0000000000000004e-07	Loss 0.1840 (0.1814)	Prec@1 97.656 (98.252)	
Epoch: [59][389/391]	LR: 2.0000000000000004e-07	Loss 0.1576 (0.1828)	Prec@1 99.219 (98.183)	
Total train loss: 0.1829

Train time: 21.8083336353302
 * Prec@1 65.550 Prec@5 87.510 Loss 1.4248
Best acc: 68.750
--------------------------------------------------------------------------------
Test time: 24.81670045852661


      ==> Arguments:
          dataset: cifar100
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/
          savedir: ../pretrained_models/frozen/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar100_i8b5f_w8b7f.pth.tar
          mode: rram
          workers: 8
          epochs: 60
          start_epoch: 0
          batch_size: 128
          lr: 0.002
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 7
          af_bit: 5
          w_bit: 7
          wf_bit: 7
          milestones: [20, 30, 40, 50]
          exp: x128-8b
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 5
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar100_i8b5f_w8b7f.pth.tar ...
Original model accuracy: 69.61000061035156
 * Prec@1 65.860 Prec@5 88.860 Loss 1.3145
Pre-trained Prec@1 with 5 layers frozen: 65.86000061035156 	 Loss: 1.314453125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.002	Loss 0.4810 (0.5897)	Prec@1 89.844 (82.853)	
Epoch: [0][155/391]	LR: 0.002	Loss 0.6299 (0.5984)	Prec@1 81.250 (82.742)	
Epoch: [0][233/391]	LR: 0.002	Loss 0.6001 (0.6006)	Prec@1 83.594 (82.699)	
Epoch: [0][311/391]	LR: 0.002	Loss 0.6211 (0.5990)	Prec@1 82.812 (82.840)	
Epoch: [0][389/391]	LR: 0.002	Loss 0.5405 (0.6015)	Prec@1 85.938 (82.804)	
Total train loss: 0.6014

Train time: 86.57346296310425
 * Prec@1 68.140 Prec@5 90.080 Loss 1.2207
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 90.11609625816345

Epoch: [1][77/391]	LR: 0.002	Loss 0.5918 (0.5098)	Prec@1 85.156 (85.988)	
Epoch: [1][155/391]	LR: 0.002	Loss 0.6162 (0.5276)	Prec@1 80.469 (85.071)	
Epoch: [1][233/391]	LR: 0.002	Loss 0.5474 (0.5340)	Prec@1 85.156 (84.966)	
Epoch: [1][311/391]	LR: 0.002	Loss 0.5488 (0.5406)	Prec@1 85.938 (84.808)	
Epoch: [1][389/391]	LR: 0.002	Loss 0.6216 (0.5439)	Prec@1 81.250 (84.706)	
Total train loss: 0.5441

Train time: 20.822770595550537
 * Prec@1 68.020 Prec@5 89.770 Loss 1.2305
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 24.36911368370056

Epoch: [2][77/391]	LR: 0.002	Loss 0.4275 (0.4708)	Prec@1 88.281 (87.470)	
Epoch: [2][155/391]	LR: 0.002	Loss 0.5249 (0.4840)	Prec@1 85.938 (86.919)	
Epoch: [2][233/391]	LR: 0.002	Loss 0.4485 (0.4918)	Prec@1 89.062 (86.609)	
Epoch: [2][311/391]	LR: 0.002	Loss 0.5444 (0.4987)	Prec@1 85.156 (86.456)	
Epoch: [2][389/391]	LR: 0.002	Loss 0.5435 (0.5046)	Prec@1 87.500 (86.202)	
Total train loss: 0.5048

Train time: 22.02552080154419
 * Prec@1 67.900 Prec@5 89.570 Loss 1.2451
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 25.6467227935791

Epoch: [3][77/391]	LR: 0.002	Loss 0.4631 (0.4529)	Prec@1 86.719 (88.612)	
Epoch: [3][155/391]	LR: 0.002	Loss 0.4084 (0.4620)	Prec@1 93.750 (87.996)	
Epoch: [3][233/391]	LR: 0.002	Loss 0.5054 (0.4636)	Prec@1 86.719 (87.891)	
Epoch: [3][311/391]	LR: 0.002	Loss 0.5054 (0.4717)	Prec@1 87.500 (87.610)	
Epoch: [3][389/391]	LR: 0.002	Loss 0.5059 (0.4746)	Prec@1 83.594 (87.434)	
Total train loss: 0.4746

Train time: 21.075363874435425
 * Prec@1 67.790 Prec@5 89.540 Loss 1.2588
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 23.141338348388672

Epoch: [4][77/391]	LR: 0.002	Loss 0.3408 (0.4233)	Prec@1 92.969 (89.233)	
Epoch: [4][155/391]	LR: 0.002	Loss 0.3074 (0.4245)	Prec@1 95.312 (89.148)	
Epoch: [4][233/391]	LR: 0.002	Loss 0.4331 (0.4330)	Prec@1 85.156 (88.932)	
Epoch: [4][311/391]	LR: 0.002	Loss 0.3755 (0.4385)	Prec@1 92.969 (88.639)	
Epoch: [4][389/391]	LR: 0.002	Loss 0.4197 (0.4443)	Prec@1 88.281 (88.476)	
Total train loss: 0.4445

Train time: 23.293762922286987
 * Prec@1 67.650 Prec@5 89.360 Loss 1.2695
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 26.280714988708496

Epoch: [5][77/391]	LR: 0.002	Loss 0.4136 (0.3995)	Prec@1 85.938 (90.164)	
Epoch: [5][155/391]	LR: 0.002	Loss 0.3108 (0.4029)	Prec@1 92.188 (90.164)	
Epoch: [5][233/391]	LR: 0.002	Loss 0.4221 (0.4164)	Prec@1 90.625 (89.747)	
Epoch: [5][311/391]	LR: 0.002	Loss 0.5068 (0.4193)	Prec@1 82.812 (89.551)	
Epoch: [5][389/391]	LR: 0.002	Loss 0.4424 (0.4247)	Prec@1 89.062 (89.299)	
Total train loss: 0.4248

Train time: 19.641010284423828
 * Prec@1 67.520 Prec@5 89.260 Loss 1.2764
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.105917930603027

Epoch: [6][77/391]	LR: 0.002	Loss 0.3655 (0.3669)	Prec@1 91.406 (91.837)	
Epoch: [6][155/391]	LR: 0.002	Loss 0.4084 (0.3783)	Prec@1 90.625 (91.361)	
Epoch: [6][233/391]	LR: 0.002	Loss 0.3352 (0.3888)	Prec@1 94.531 (90.952)	
Epoch: [6][311/391]	LR: 0.002	Loss 0.2927 (0.3950)	Prec@1 92.969 (90.715)	
Epoch: [6][389/391]	LR: 0.002	Loss 0.5601 (0.4014)	Prec@1 80.469 (90.441)	
Total train loss: 0.4016

Train time: 20.489082098007202
 * Prec@1 67.660 Prec@5 88.960 Loss 1.2900
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.99779438972473

Epoch: [7][77/391]	LR: 0.002	Loss 0.3345 (0.3519)	Prec@1 91.406 (92.528)	
Epoch: [7][155/391]	LR: 0.002	Loss 0.3440 (0.3589)	Prec@1 89.844 (92.147)	
Epoch: [7][233/391]	LR: 0.002	Loss 0.3311 (0.3678)	Prec@1 89.062 (91.593)	
Epoch: [7][311/391]	LR: 0.002	Loss 0.3408 (0.3742)	Prec@1 93.750 (91.411)	
Epoch: [7][389/391]	LR: 0.002	Loss 0.4099 (0.3813)	Prec@1 86.719 (91.160)	
Total train loss: 0.3813

Train time: 17.326026678085327
 * Prec@1 66.760 Prec@5 88.340 Loss 1.3311
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 20.697916507720947

Epoch: [8][77/391]	LR: 0.002	Loss 0.3521 (0.3401)	Prec@1 90.625 (93.129)	
Epoch: [8][155/391]	LR: 0.002	Loss 0.4539 (0.3457)	Prec@1 88.281 (92.733)	
Epoch: [8][233/391]	LR: 0.002	Loss 0.4890 (0.3520)	Prec@1 87.500 (92.435)	
Epoch: [8][311/391]	LR: 0.002	Loss 0.4465 (0.3574)	Prec@1 89.844 (92.155)	
Epoch: [8][389/391]	LR: 0.002	Loss 0.3762 (0.3627)	Prec@1 90.625 (91.915)	
Total train loss: 0.3630

Train time: 16.642863988876343
 * Prec@1 66.750 Prec@5 88.490 Loss 1.3350
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 19.1105535030365

Epoch: [9][77/391]	LR: 0.002	Loss 0.2949 (0.3150)	Prec@1 91.406 (93.660)	
Epoch: [9][155/391]	LR: 0.002	Loss 0.2751 (0.3268)	Prec@1 91.406 (93.309)	
Epoch: [9][233/391]	LR: 0.002	Loss 0.4485 (0.3344)	Prec@1 88.281 (92.982)	
Epoch: [9][311/391]	LR: 0.002	Loss 0.3882 (0.3389)	Prec@1 90.625 (92.816)	
Epoch: [9][389/391]	LR: 0.002	Loss 0.3833 (0.3416)	Prec@1 92.188 (92.698)	
Total train loss: 0.3418

Train time: 17.468714237213135
 * Prec@1 66.240 Prec@5 88.400 Loss 1.3477
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 20.80570912361145

Epoch: [10][77/391]	LR: 0.002	Loss 0.3757 (0.3061)	Prec@1 89.844 (94.030)	
Epoch: [10][155/391]	LR: 0.002	Loss 0.2964 (0.3102)	Prec@1 92.188 (93.905)	
Epoch: [10][233/391]	LR: 0.002	Loss 0.4526 (0.3203)	Prec@1 91.406 (93.493)	
Epoch: [10][311/391]	LR: 0.002	Loss 0.4160 (0.3265)	Prec@1 87.500 (93.292)	
Epoch: [10][389/391]	LR: 0.002	Loss 0.3503 (0.3300)	Prec@1 90.625 (93.145)	
Total train loss: 0.3301

Train time: 16.91020393371582
 * Prec@1 66.300 Prec@5 88.500 Loss 1.3594
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 20.182934284210205

Epoch: [11][77/391]	LR: 0.002	Loss 0.3232 (0.2955)	Prec@1 92.188 (94.401)	
Epoch: [11][155/391]	LR: 0.002	Loss 0.2522 (0.2996)	Prec@1 96.094 (94.331)	
Epoch: [11][233/391]	LR: 0.002	Loss 0.3003 (0.3067)	Prec@1 93.750 (94.087)	
Epoch: [11][311/391]	LR: 0.002	Loss 0.3086 (0.3133)	Prec@1 92.188 (93.803)	
Epoch: [11][389/391]	LR: 0.002	Loss 0.3049 (0.3169)	Prec@1 92.188 (93.644)	
Total train loss: 0.3172

Train time: 16.94334316253662
 * Prec@1 66.010 Prec@5 88.270 Loss 1.3682
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 19.398036003112793

Epoch: [12][77/391]	LR: 0.002	Loss 0.2372 (0.2784)	Prec@1 100.000 (95.022)	
Epoch: [12][155/391]	LR: 0.002	Loss 0.3259 (0.2878)	Prec@1 95.312 (94.797)	
Epoch: [12][233/391]	LR: 0.002	Loss 0.3257 (0.2879)	Prec@1 94.531 (94.775)	
Epoch: [12][311/391]	LR: 0.002	Loss 0.3459 (0.2919)	Prec@1 92.969 (94.609)	
Epoch: [12][389/391]	LR: 0.002	Loss 0.2874 (0.2980)	Prec@1 92.969 (94.357)	
Total train loss: 0.2983

Train time: 19.423616409301758
 * Prec@1 66.320 Prec@5 88.400 Loss 1.3740
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 21.976039171218872

Epoch: [13][77/391]	LR: 0.002	Loss 0.2189 (0.2695)	Prec@1 96.875 (95.333)	
Epoch: [13][155/391]	LR: 0.002	Loss 0.3245 (0.2763)	Prec@1 93.750 (94.942)	
Epoch: [13][233/391]	LR: 0.002	Loss 0.2900 (0.2805)	Prec@1 92.969 (94.915)	
Epoch: [13][311/391]	LR: 0.002	Loss 0.3071 (0.2849)	Prec@1 94.531 (94.784)	
Epoch: [13][389/391]	LR: 0.002	Loss 0.2942 (0.2894)	Prec@1 96.094 (94.603)	
Total train loss: 0.2897

Train time: 19.08125877380371
 * Prec@1 65.950 Prec@5 87.980 Loss 1.3799
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.2085542678833

Epoch: [14][77/391]	LR: 0.002	Loss 0.2422 (0.2657)	Prec@1 96.094 (95.683)	
Epoch: [14][155/391]	LR: 0.002	Loss 0.2216 (0.2685)	Prec@1 98.438 (95.543)	
Epoch: [14][233/391]	LR: 0.002	Loss 0.2866 (0.2728)	Prec@1 93.750 (95.296)	
Epoch: [14][311/391]	LR: 0.002	Loss 0.3237 (0.2767)	Prec@1 96.094 (95.082)	
Epoch: [14][389/391]	LR: 0.002	Loss 0.2568 (0.2793)	Prec@1 95.312 (95.036)	
Total train loss: 0.2794

Train time: 18.94775938987732
 * Prec@1 65.600 Prec@5 87.600 Loss 1.4072
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.16219973564148

Epoch: [15][77/391]	LR: 0.002	Loss 0.2644 (0.2586)	Prec@1 96.094 (95.933)	
Epoch: [15][155/391]	LR: 0.002	Loss 0.3120 (0.2631)	Prec@1 93.750 (95.658)	
Epoch: [15][233/391]	LR: 0.002	Loss 0.3037 (0.2665)	Prec@1 95.312 (95.509)	
Epoch: [15][311/391]	LR: 0.002	Loss 0.2859 (0.2689)	Prec@1 95.312 (95.413)	
Epoch: [15][389/391]	LR: 0.002	Loss 0.2871 (0.2711)	Prec@1 96.094 (95.325)	
Total train loss: 0.2713

Train time: 20.10753870010376
 * Prec@1 65.580 Prec@5 87.320 Loss 1.4229
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.24599575996399

Epoch: [16][77/391]	LR: 0.002	Loss 0.3079 (0.2465)	Prec@1 96.094 (96.494)	
Epoch: [16][155/391]	LR: 0.002	Loss 0.2529 (0.2473)	Prec@1 96.094 (96.379)	
Epoch: [16][233/391]	LR: 0.002	Loss 0.2664 (0.2539)	Prec@1 95.312 (96.040)	
Epoch: [16][311/391]	LR: 0.002	Loss 0.3323 (0.2579)	Prec@1 92.188 (95.841)	
Epoch: [16][389/391]	LR: 0.002	Loss 0.2605 (0.2610)	Prec@1 96.094 (95.737)	
Total train loss: 0.2613

Train time: 19.725862979888916
 * Prec@1 64.750 Prec@5 87.390 Loss 1.4404
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.91946053504944

Epoch: [17][77/391]	LR: 0.002	Loss 0.1823 (0.2309)	Prec@1 97.656 (96.715)	
Epoch: [17][155/391]	LR: 0.002	Loss 0.1981 (0.2359)	Prec@1 96.875 (96.650)	
Epoch: [17][233/391]	LR: 0.002	Loss 0.3252 (0.2431)	Prec@1 94.531 (96.408)	
Epoch: [17][311/391]	LR: 0.002	Loss 0.2920 (0.2470)	Prec@1 92.188 (96.267)	
Epoch: [17][389/391]	LR: 0.002	Loss 0.2471 (0.2506)	Prec@1 96.094 (96.092)	
Total train loss: 0.2507

Train time: 19.70377516746521
 * Prec@1 65.210 Prec@5 87.390 Loss 1.4229
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.115957021713257

Epoch: [18][77/391]	LR: 0.002	Loss 0.1814 (0.2189)	Prec@1 98.438 (97.085)	
Epoch: [18][155/391]	LR: 0.002	Loss 0.2281 (0.2287)	Prec@1 96.094 (96.755)	
Epoch: [18][233/391]	LR: 0.002	Loss 0.4231 (0.2336)	Prec@1 89.844 (96.638)	
Epoch: [18][311/391]	LR: 0.002	Loss 0.2825 (0.2377)	Prec@1 94.531 (96.464)	
Epoch: [18][389/391]	LR: 0.002	Loss 0.2573 (0.2412)	Prec@1 95.312 (96.324)	
Total train loss: 0.2414

Train time: 19.79118013381958
 * Prec@1 65.400 Prec@5 87.260 Loss 1.4336
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.23351764678955

Epoch: [19][77/391]	LR: 0.002	Loss 0.1914 (0.2079)	Prec@1 98.438 (97.446)	
Epoch: [19][155/391]	LR: 0.002	Loss 0.2135 (0.2157)	Prec@1 95.312 (97.246)	
Epoch: [19][233/391]	LR: 0.002	Loss 0.2583 (0.2244)	Prec@1 94.531 (96.945)	
Epoch: [19][311/391]	LR: 0.002	Loss 0.2737 (0.2280)	Prec@1 96.094 (96.870)	
Epoch: [19][389/391]	LR: 0.002	Loss 0.2480 (0.2312)	Prec@1 96.094 (96.725)	
Total train loss: 0.2314

Train time: 19.656866550445557
 * Prec@1 65.010 Prec@5 87.330 Loss 1.4502
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 23.256070852279663

Epoch: [20][77/391]	LR: 0.0002	Loss 0.2104 (0.2050)	Prec@1 100.000 (97.486)	
Epoch: [20][155/391]	LR: 0.0002	Loss 0.2100 (0.2022)	Prec@1 98.438 (97.681)	
Epoch: [20][233/391]	LR: 0.0002	Loss 0.2388 (0.2022)	Prec@1 97.656 (97.633)	
Epoch: [20][311/391]	LR: 0.0002	Loss 0.1929 (0.2030)	Prec@1 96.094 (97.594)	
Epoch: [20][389/391]	LR: 0.0002	Loss 0.1508 (0.2022)	Prec@1 98.438 (97.592)	
Total train loss: 0.2023

Train time: 20.251792430877686
 * Prec@1 65.420 Prec@5 87.410 Loss 1.4297
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.32148814201355

Epoch: [21][77/391]	LR: 0.0002	Loss 0.2096 (0.1970)	Prec@1 96.875 (97.536)	
Epoch: [21][155/391]	LR: 0.0002	Loss 0.1420 (0.1966)	Prec@1 98.438 (97.556)	
Epoch: [21][233/391]	LR: 0.0002	Loss 0.1857 (0.1955)	Prec@1 96.875 (97.666)	
Epoch: [21][311/391]	LR: 0.0002	Loss 0.1879 (0.1969)	Prec@1 98.438 (97.744)	
Epoch: [21][389/391]	LR: 0.0002	Loss 0.1747 (0.1965)	Prec@1 96.875 (97.756)	
Total train loss: 0.1965

Train time: 19.947731733322144
 * Prec@1 65.460 Prec@5 87.280 Loss 1.4316
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.50956654548645

Epoch: [22][77/391]	LR: 0.0002	Loss 0.1620 (0.1856)	Prec@1 100.000 (98.137)	
Epoch: [22][155/391]	LR: 0.0002	Loss 0.1909 (0.1927)	Prec@1 97.656 (97.992)	
Epoch: [22][233/391]	LR: 0.0002	Loss 0.1891 (0.1902)	Prec@1 97.656 (98.047)	
Epoch: [22][311/391]	LR: 0.0002	Loss 0.1838 (0.1916)	Prec@1 98.438 (97.992)	
Epoch: [22][389/391]	LR: 0.0002	Loss 0.1688 (0.1911)	Prec@1 100.000 (97.997)	
Total train loss: 0.1911

Train time: 20.04142665863037
 * Prec@1 65.510 Prec@5 87.410 Loss 1.4307
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 23.033843755722046

Epoch: [23][77/391]	LR: 0.0002	Loss 0.1614 (0.1906)	Prec@1 100.000 (97.947)	
Epoch: [23][155/391]	LR: 0.0002	Loss 0.2294 (0.1892)	Prec@1 96.875 (98.017)	
Epoch: [23][233/391]	LR: 0.0002	Loss 0.2129 (0.1890)	Prec@1 98.438 (98.094)	
Epoch: [23][311/391]	LR: 0.0002	Loss 0.2311 (0.1903)	Prec@1 97.656 (98.017)	
Epoch: [23][389/391]	LR: 0.0002	Loss 0.2291 (0.1906)	Prec@1 98.438 (97.981)	
Total train loss: 0.1908

Train time: 20.04795551300049
 * Prec@1 65.380 Prec@5 87.270 Loss 1.4385
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.754133701324463

Epoch: [24][77/391]	LR: 0.0002	Loss 0.1639 (0.1894)	Prec@1 99.219 (98.027)	
Epoch: [24][155/391]	LR: 0.0002	Loss 0.1930 (0.1909)	Prec@1 100.000 (98.022)	
Epoch: [24][233/391]	LR: 0.0002	Loss 0.1628 (0.1899)	Prec@1 97.656 (98.034)	
Epoch: [24][311/391]	LR: 0.0002	Loss 0.1771 (0.1898)	Prec@1 98.438 (98.059)	
Epoch: [24][389/391]	LR: 0.0002	Loss 0.1837 (0.1899)	Prec@1 98.438 (98.001)	
Total train loss: 0.1901

Train time: 23.539466381072998
 * Prec@1 65.160 Prec@5 87.130 Loss 1.4443
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 26.555408000946045

Epoch: [25][77/391]	LR: 0.0002	Loss 0.1545 (0.1854)	Prec@1 98.438 (97.977)	
Epoch: [25][155/391]	LR: 0.0002	Loss 0.2203 (0.1895)	Prec@1 96.875 (97.927)	
Epoch: [25][233/391]	LR: 0.0002	Loss 0.1980 (0.1897)	Prec@1 96.875 (97.937)	
Epoch: [25][311/391]	LR: 0.0002	Loss 0.1504 (0.1895)	Prec@1 99.219 (97.984)	
Epoch: [25][389/391]	LR: 0.0002	Loss 0.1855 (0.1893)	Prec@1 100.000 (98.019)	
Total train loss: 0.1893

Train time: 19.472970485687256
 * Prec@1 65.560 Prec@5 87.350 Loss 1.4268
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.13563108444214

Epoch: [26][77/391]	LR: 0.0002	Loss 0.2311 (0.1873)	Prec@1 96.094 (98.027)	
Epoch: [26][155/391]	LR: 0.0002	Loss 0.1838 (0.1870)	Prec@1 98.438 (98.037)	
Epoch: [26][233/391]	LR: 0.0002	Loss 0.2384 (0.1876)	Prec@1 95.312 (98.040)	
Epoch: [26][311/391]	LR: 0.0002	Loss 0.1935 (0.1871)	Prec@1 98.438 (98.097)	
Epoch: [26][389/391]	LR: 0.0002	Loss 0.1874 (0.1875)	Prec@1 97.656 (98.113)	
Total train loss: 0.1876

Train time: 20.652792930603027
 * Prec@1 65.410 Prec@5 87.240 Loss 1.4385
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 23.051825523376465

Epoch: [27][77/391]	LR: 0.0002	Loss 0.2155 (0.1862)	Prec@1 96.875 (98.127)	
Epoch: [27][155/391]	LR: 0.0002	Loss 0.1478 (0.1858)	Prec@1 100.000 (98.237)	
Epoch: [27][233/391]	LR: 0.0002	Loss 0.1700 (0.1861)	Prec@1 99.219 (98.207)	
Epoch: [27][311/391]	LR: 0.0002	Loss 0.2228 (0.1874)	Prec@1 96.875 (98.137)	
Epoch: [27][389/391]	LR: 0.0002	Loss 0.2056 (0.1878)	Prec@1 97.656 (98.105)	
Total train loss: 0.1878

Train time: 20.10328507423401
 * Prec@1 65.310 Prec@5 87.050 Loss 1.4336
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.788649797439575

Epoch: [28][77/391]	LR: 0.0002	Loss 0.1798 (0.1801)	Prec@1 98.438 (98.277)	
Epoch: [28][155/391]	LR: 0.0002	Loss 0.1473 (0.1785)	Prec@1 99.219 (98.342)	
Epoch: [28][233/391]	LR: 0.0002	Loss 0.1864 (0.1837)	Prec@1 97.656 (98.214)	
Epoch: [28][311/391]	LR: 0.0002	Loss 0.1764 (0.1859)	Prec@1 99.219 (98.114)	
Epoch: [28][389/391]	LR: 0.0002	Loss 0.1877 (0.1863)	Prec@1 98.438 (98.111)	
Total train loss: 0.1864

Train time: 19.962260961532593
 * Prec@1 65.220 Prec@5 87.000 Loss 1.4443
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.087217807769775

Epoch: [29][77/391]	LR: 0.0002	Loss 0.1964 (0.1779)	Prec@1 98.438 (98.417)	
Epoch: [29][155/391]	LR: 0.0002	Loss 0.1509 (0.1835)	Prec@1 99.219 (98.117)	
Epoch: [29][233/391]	LR: 0.0002	Loss 0.1686 (0.1828)	Prec@1 98.438 (98.097)	
Epoch: [29][311/391]	LR: 0.0002	Loss 0.1642 (0.1846)	Prec@1 100.000 (98.052)	
Epoch: [29][389/391]	LR: 0.0002	Loss 0.1740 (0.1844)	Prec@1 96.875 (98.073)	
Total train loss: 0.1844

Train time: 19.676918983459473
 * Prec@1 65.330 Prec@5 87.450 Loss 1.4287
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 21.890146732330322

Epoch: [30][77/391]	LR: 2e-05	Loss 0.1627 (0.1813)	Prec@1 97.656 (98.197)	
Epoch: [30][155/391]	LR: 2e-05	Loss 0.1577 (0.1822)	Prec@1 100.000 (98.192)	
Epoch: [30][233/391]	LR: 2e-05	Loss 0.2090 (0.1844)	Prec@1 97.656 (98.094)	
Epoch: [30][311/391]	LR: 2e-05	Loss 0.1653 (0.1835)	Prec@1 99.219 (98.145)	
Epoch: [30][389/391]	LR: 2e-05	Loss 0.1938 (0.1842)	Prec@1 98.438 (98.101)	
Total train loss: 0.1843

Train time: 19.5969979763031
 * Prec@1 65.200 Prec@5 87.300 Loss 1.4375
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.670244693756104

Epoch: [31][77/391]	LR: 2e-05	Loss 0.1456 (0.1866)	Prec@1 100.000 (97.987)	
Epoch: [31][155/391]	LR: 2e-05	Loss 0.1893 (0.1854)	Prec@1 100.000 (97.987)	
Epoch: [31][233/391]	LR: 2e-05	Loss 0.1638 (0.1839)	Prec@1 100.000 (98.100)	
Epoch: [31][311/391]	LR: 2e-05	Loss 0.1564 (0.1839)	Prec@1 99.219 (98.127)	
Epoch: [31][389/391]	LR: 2e-05	Loss 0.1555 (0.1834)	Prec@1 100.000 (98.155)	
Total train loss: 0.1834

Train time: 18.694846868515015
 * Prec@1 65.390 Prec@5 87.180 Loss 1.4385
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 21.086573123931885

Epoch: [32][77/391]	LR: 2e-05	Loss 0.1904 (0.1886)	Prec@1 98.438 (97.927)	
Epoch: [32][155/391]	LR: 2e-05	Loss 0.2015 (0.1874)	Prec@1 96.875 (97.917)	
Epoch: [32][233/391]	LR: 2e-05	Loss 0.2250 (0.1862)	Prec@1 96.875 (98.047)	
Epoch: [32][311/391]	LR: 2e-05	Loss 0.1919 (0.1860)	Prec@1 98.438 (98.079)	
Epoch: [32][389/391]	LR: 2e-05	Loss 0.1458 (0.1859)	Prec@1 98.438 (98.083)	
Total train loss: 0.1860

Train time: 18.99806308746338
 * Prec@1 65.680 Prec@5 87.140 Loss 1.4316
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 21.205958604812622

Epoch: [33][77/391]	LR: 2e-05	Loss 0.2126 (0.1791)	Prec@1 96.875 (98.327)	
Epoch: [33][155/391]	LR: 2e-05	Loss 0.1450 (0.1818)	Prec@1 100.000 (98.152)	
Epoch: [33][233/391]	LR: 2e-05	Loss 0.1908 (0.1828)	Prec@1 97.656 (98.187)	
Epoch: [33][311/391]	LR: 2e-05	Loss 0.1931 (0.1829)	Prec@1 98.438 (98.240)	
Epoch: [33][389/391]	LR: 2e-05	Loss 0.1764 (0.1837)	Prec@1 96.875 (98.213)	
Total train loss: 0.1839

Train time: 20.84237051010132
 * Prec@1 65.140 Prec@5 87.250 Loss 1.4365
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 23.823044538497925

Epoch: [34][77/391]	LR: 2e-05	Loss 0.1987 (0.1830)	Prec@1 98.438 (98.337)	
Epoch: [34][155/391]	LR: 2e-05	Loss 0.1833 (0.1846)	Prec@1 99.219 (98.297)	
Epoch: [34][233/391]	LR: 2e-05	Loss 0.2197 (0.1862)	Prec@1 96.875 (98.184)	
Epoch: [34][311/391]	LR: 2e-05	Loss 0.1471 (0.1842)	Prec@1 100.000 (98.252)	
Epoch: [34][389/391]	LR: 2e-05	Loss 0.1753 (0.1843)	Prec@1 97.656 (98.223)	
Total train loss: 0.1844

Train time: 19.316879272460938
 * Prec@1 65.260 Prec@5 87.210 Loss 1.4326
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 21.820095539093018

Epoch: [35][77/391]	LR: 2e-05	Loss 0.1705 (0.1823)	Prec@1 97.656 (98.207)	
Epoch: [35][155/391]	LR: 2e-05	Loss 0.1284 (0.1813)	Prec@1 98.438 (98.252)	
Epoch: [35][233/391]	LR: 2e-05	Loss 0.2286 (0.1845)	Prec@1 96.094 (98.117)	
Epoch: [35][311/391]	LR: 2e-05	Loss 0.1774 (0.1842)	Prec@1 99.219 (98.092)	
Epoch: [35][389/391]	LR: 2e-05	Loss 0.2245 (0.1842)	Prec@1 98.438 (98.079)	
Total train loss: 0.1842

Train time: 20.10475206375122
 * Prec@1 65.270 Prec@5 87.320 Loss 1.4336
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.616811513900757

Epoch: [36][77/391]	LR: 2e-05	Loss 0.1426 (0.1818)	Prec@1 100.000 (98.297)	
Epoch: [36][155/391]	LR: 2e-05	Loss 0.1650 (0.1850)	Prec@1 97.656 (98.167)	
Epoch: [36][233/391]	LR: 2e-05	Loss 0.1912 (0.1849)	Prec@1 97.656 (98.184)	
Epoch: [36][311/391]	LR: 2e-05	Loss 0.2236 (0.1837)	Prec@1 95.312 (98.202)	
Epoch: [36][389/391]	LR: 2e-05	Loss 0.1688 (0.1847)	Prec@1 99.219 (98.177)	
Total train loss: 0.1849

Train time: 19.970012426376343
 * Prec@1 65.380 Prec@5 87.240 Loss 1.4375
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 23.342462301254272

Epoch: [37][77/391]	LR: 2e-05	Loss 0.1940 (0.1850)	Prec@1 98.438 (98.097)	
Epoch: [37][155/391]	LR: 2e-05	Loss 0.2295 (0.1840)	Prec@1 97.656 (98.122)	
Epoch: [37][233/391]	LR: 2e-05	Loss 0.1620 (0.1851)	Prec@1 99.219 (98.057)	
Epoch: [37][311/391]	LR: 2e-05	Loss 0.1398 (0.1846)	Prec@1 100.000 (98.107)	
Epoch: [37][389/391]	LR: 2e-05	Loss 0.1699 (0.1846)	Prec@1 96.875 (98.143)	
Total train loss: 0.1846

Train time: 19.951234102249146
 * Prec@1 65.500 Prec@5 87.270 Loss 1.4365
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.171195030212402

Epoch: [38][77/391]	LR: 2e-05	Loss 0.1683 (0.1845)	Prec@1 98.438 (98.317)	
Epoch: [38][155/391]	LR: 2e-05	Loss 0.1486 (0.1876)	Prec@1 99.219 (98.177)	
Epoch: [38][233/391]	LR: 2e-05	Loss 0.1627 (0.1860)	Prec@1 98.438 (98.157)	
Epoch: [38][311/391]	LR: 2e-05	Loss 0.2034 (0.1845)	Prec@1 98.438 (98.200)	
Epoch: [38][389/391]	LR: 2e-05	Loss 0.1661 (0.1844)	Prec@1 100.000 (98.223)	
Total train loss: 0.1845

Train time: 20.272183179855347
 * Prec@1 65.420 Prec@5 87.340 Loss 1.4395
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.49868392944336

Epoch: [39][77/391]	LR: 2e-05	Loss 0.2213 (0.1815)	Prec@1 96.875 (98.207)	
Epoch: [39][155/391]	LR: 2e-05	Loss 0.2119 (0.1838)	Prec@1 98.438 (98.117)	
Epoch: [39][233/391]	LR: 2e-05	Loss 0.1600 (0.1840)	Prec@1 100.000 (98.140)	
Epoch: [39][311/391]	LR: 2e-05	Loss 0.1929 (0.1850)	Prec@1 96.875 (98.119)	
Epoch: [39][389/391]	LR: 2e-05	Loss 0.1973 (0.1862)	Prec@1 94.531 (98.107)	
Total train loss: 0.1864

Train time: 20.694854259490967
 * Prec@1 65.320 Prec@5 87.190 Loss 1.4375
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 23.915067195892334

Epoch: [40][77/391]	LR: 2.0000000000000003e-06	Loss 0.2083 (0.1871)	Prec@1 95.312 (98.107)	
Epoch: [40][155/391]	LR: 2.0000000000000003e-06	Loss 0.1780 (0.1858)	Prec@1 98.438 (98.102)	
Epoch: [40][233/391]	LR: 2.0000000000000003e-06	Loss 0.2351 (0.1861)	Prec@1 96.094 (98.044)	
Epoch: [40][311/391]	LR: 2.0000000000000003e-06	Loss 0.2156 (0.1861)	Prec@1 96.875 (98.067)	
Epoch: [40][389/391]	LR: 2.0000000000000003e-06	Loss 0.1561 (0.1855)	Prec@1 100.000 (98.113)	
Total train loss: 0.1855

Train time: 19.869627475738525
 * Prec@1 65.450 Prec@5 87.290 Loss 1.4336
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.47165322303772

Epoch: [41][77/391]	LR: 2.0000000000000003e-06	Loss 0.1747 (0.1810)	Prec@1 100.000 (98.137)	
Epoch: [41][155/391]	LR: 2.0000000000000003e-06	Loss 0.2345 (0.1842)	Prec@1 96.875 (98.142)	
Epoch: [41][233/391]	LR: 2.0000000000000003e-06	Loss 0.1393 (0.1841)	Prec@1 100.000 (98.174)	
Epoch: [41][311/391]	LR: 2.0000000000000003e-06	Loss 0.2026 (0.1847)	Prec@1 99.219 (98.160)	
Epoch: [41][389/391]	LR: 2.0000000000000003e-06	Loss 0.1720 (0.1839)	Prec@1 98.438 (98.167)	
Total train loss: 0.1841

Train time: 19.537065982818604
 * Prec@1 65.260 Prec@5 87.490 Loss 1.4307
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.310991764068604

Epoch: [42][77/391]	LR: 2.0000000000000003e-06	Loss 0.1819 (0.1754)	Prec@1 98.438 (98.618)	
Epoch: [42][155/391]	LR: 2.0000000000000003e-06	Loss 0.2083 (0.1791)	Prec@1 97.656 (98.417)	
Epoch: [42][233/391]	LR: 2.0000000000000003e-06	Loss 0.2025 (0.1810)	Prec@1 97.656 (98.367)	
Epoch: [42][311/391]	LR: 2.0000000000000003e-06	Loss 0.1625 (0.1821)	Prec@1 98.438 (98.317)	
Epoch: [42][389/391]	LR: 2.0000000000000003e-06	Loss 0.2391 (0.1831)	Prec@1 94.531 (98.287)	
Total train loss: 0.1832

Train time: 19.087257146835327
 * Prec@1 65.380 Prec@5 87.420 Loss 1.4346
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.162222385406494

Epoch: [43][77/391]	LR: 2.0000000000000003e-06	Loss 0.2151 (0.1822)	Prec@1 96.875 (98.197)	
Epoch: [43][155/391]	LR: 2.0000000000000003e-06	Loss 0.1399 (0.1835)	Prec@1 98.438 (98.247)	
Epoch: [43][233/391]	LR: 2.0000000000000003e-06	Loss 0.2012 (0.1833)	Prec@1 96.875 (98.174)	
Epoch: [43][311/391]	LR: 2.0000000000000003e-06	Loss 0.1388 (0.1828)	Prec@1 100.000 (98.185)	
Epoch: [43][389/391]	LR: 2.0000000000000003e-06	Loss 0.2178 (0.1820)	Prec@1 96.875 (98.201)	
Total train loss: 0.1821

Train time: 20.302658319473267
 * Prec@1 65.300 Prec@5 87.070 Loss 1.4365
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.773123025894165

Epoch: [44][77/391]	LR: 2.0000000000000003e-06	Loss 0.1492 (0.1783)	Prec@1 99.219 (98.438)	
Epoch: [44][155/391]	LR: 2.0000000000000003e-06	Loss 0.1743 (0.1813)	Prec@1 98.438 (98.392)	
Epoch: [44][233/391]	LR: 2.0000000000000003e-06	Loss 0.2230 (0.1838)	Prec@1 97.656 (98.287)	
Epoch: [44][311/391]	LR: 2.0000000000000003e-06	Loss 0.2069 (0.1847)	Prec@1 95.312 (98.187)	
Epoch: [44][389/391]	LR: 2.0000000000000003e-06	Loss 0.1855 (0.1844)	Prec@1 99.219 (98.185)	
Total train loss: 0.1845

Train time: 23.61962342262268
 * Prec@1 65.080 Prec@5 87.250 Loss 1.4336
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 26.8489089012146

Epoch: [45][77/391]	LR: 2.0000000000000003e-06	Loss 0.1947 (0.1861)	Prec@1 98.438 (98.397)	
Epoch: [45][155/391]	LR: 2.0000000000000003e-06	Loss 0.1794 (0.1880)	Prec@1 99.219 (98.177)	
Epoch: [45][233/391]	LR: 2.0000000000000003e-06	Loss 0.1913 (0.1864)	Prec@1 97.656 (98.154)	
Epoch: [45][311/391]	LR: 2.0000000000000003e-06	Loss 0.1809 (0.1839)	Prec@1 99.219 (98.265)	
Epoch: [45][389/391]	LR: 2.0000000000000003e-06	Loss 0.1992 (0.1835)	Prec@1 97.656 (98.225)	
Total train loss: 0.1838

Train time: 19.729845762252808
 * Prec@1 65.470 Prec@5 87.070 Loss 1.4385
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 21.850172758102417

Epoch: [46][77/391]	LR: 2.0000000000000003e-06	Loss 0.1957 (0.1837)	Prec@1 97.656 (98.117)	
Epoch: [46][155/391]	LR: 2.0000000000000003e-06	Loss 0.1434 (0.1827)	Prec@1 100.000 (98.157)	
Epoch: [46][233/391]	LR: 2.0000000000000003e-06	Loss 0.1750 (0.1847)	Prec@1 98.438 (98.080)	
Epoch: [46][311/391]	LR: 2.0000000000000003e-06	Loss 0.1703 (0.1845)	Prec@1 98.438 (98.140)	
Epoch: [46][389/391]	LR: 2.0000000000000003e-06	Loss 0.1853 (0.1841)	Prec@1 99.219 (98.203)	
Total train loss: 0.1843

Train time: 20.610633850097656
 * Prec@1 65.310 Prec@5 87.230 Loss 1.4424
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.77380657196045

Epoch: [47][77/391]	LR: 2.0000000000000003e-06	Loss 0.1975 (0.1888)	Prec@1 97.656 (97.987)	
Epoch: [47][155/391]	LR: 2.0000000000000003e-06	Loss 0.2115 (0.1868)	Prec@1 97.656 (98.102)	
Epoch: [47][233/391]	LR: 2.0000000000000003e-06	Loss 0.2064 (0.1851)	Prec@1 97.656 (98.180)	
Epoch: [47][311/391]	LR: 2.0000000000000003e-06	Loss 0.1987 (0.1847)	Prec@1 98.438 (98.157)	
Epoch: [47][389/391]	LR: 2.0000000000000003e-06	Loss 0.2208 (0.1844)	Prec@1 95.312 (98.149)	
Total train loss: 0.1845

Train time: 20.190492868423462
 * Prec@1 65.370 Prec@5 87.240 Loss 1.4346
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 23.28949475288391

Epoch: [48][77/391]	LR: 2.0000000000000003e-06	Loss 0.1543 (0.1806)	Prec@1 98.438 (98.277)	
Epoch: [48][155/391]	LR: 2.0000000000000003e-06	Loss 0.2152 (0.1804)	Prec@1 99.219 (98.342)	
Epoch: [48][233/391]	LR: 2.0000000000000003e-06	Loss 0.1659 (0.1825)	Prec@1 97.656 (98.307)	
Epoch: [48][311/391]	LR: 2.0000000000000003e-06	Loss 0.1677 (0.1827)	Prec@1 99.219 (98.307)	
Epoch: [48][389/391]	LR: 2.0000000000000003e-06	Loss 0.1903 (0.1829)	Prec@1 97.656 (98.295)	
Total train loss: 0.1831

Train time: 19.34137749671936
 * Prec@1 65.500 Prec@5 87.290 Loss 1.4404
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 21.817954301834106

Epoch: [49][77/391]	LR: 2.0000000000000003e-06	Loss 0.1611 (0.1822)	Prec@1 100.000 (98.247)	
Epoch: [49][155/391]	LR: 2.0000000000000003e-06	Loss 0.1699 (0.1786)	Prec@1 99.219 (98.352)	
Epoch: [49][233/391]	LR: 2.0000000000000003e-06	Loss 0.1942 (0.1818)	Prec@1 96.875 (98.281)	
Epoch: [49][311/391]	LR: 2.0000000000000003e-06	Loss 0.1836 (0.1824)	Prec@1 98.438 (98.287)	
Epoch: [49][389/391]	LR: 2.0000000000000003e-06	Loss 0.2173 (0.1821)	Prec@1 98.438 (98.315)	
Total train loss: 0.1822

Train time: 20.161895513534546
 * Prec@1 65.160 Prec@5 87.080 Loss 1.4404
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.356837511062622

Epoch: [50][77/391]	LR: 2.0000000000000004e-07	Loss 0.2079 (0.1913)	Prec@1 97.656 (98.007)	
Epoch: [50][155/391]	LR: 2.0000000000000004e-07	Loss 0.1732 (0.1866)	Prec@1 98.438 (98.157)	
Epoch: [50][233/391]	LR: 2.0000000000000004e-07	Loss 0.1960 (0.1849)	Prec@1 98.438 (98.160)	
Epoch: [50][311/391]	LR: 2.0000000000000004e-07	Loss 0.1740 (0.1855)	Prec@1 100.000 (98.160)	
Epoch: [50][389/391]	LR: 2.0000000000000004e-07	Loss 0.1893 (0.1856)	Prec@1 96.875 (98.147)	
Total train loss: 0.1857

Train time: 19.720026969909668
 * Prec@1 65.000 Prec@5 87.390 Loss 1.4355
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.345990657806396

Epoch: [51][77/391]	LR: 2.0000000000000004e-07	Loss 0.1617 (0.1859)	Prec@1 98.438 (98.227)	
Epoch: [51][155/391]	LR: 2.0000000000000004e-07	Loss 0.1638 (0.1865)	Prec@1 96.094 (98.217)	
Epoch: [51][233/391]	LR: 2.0000000000000004e-07	Loss 0.2051 (0.1861)	Prec@1 97.656 (98.294)	
Epoch: [51][311/391]	LR: 2.0000000000000004e-07	Loss 0.2385 (0.1859)	Prec@1 96.094 (98.287)	
Epoch: [51][389/391]	LR: 2.0000000000000004e-07	Loss 0.1548 (0.1851)	Prec@1 98.438 (98.251)	
Total train loss: 0.1852

Train time: 19.871973991394043
 * Prec@1 65.430 Prec@5 87.290 Loss 1.4355
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.3711154460907

Epoch: [52][77/391]	LR: 2.0000000000000004e-07	Loss 0.1658 (0.1847)	Prec@1 97.656 (98.237)	
Epoch: [52][155/391]	LR: 2.0000000000000004e-07	Loss 0.1519 (0.1829)	Prec@1 99.219 (98.242)	
Epoch: [52][233/391]	LR: 2.0000000000000004e-07	Loss 0.2142 (0.1848)	Prec@1 96.875 (98.210)	
Epoch: [52][311/391]	LR: 2.0000000000000004e-07	Loss 0.1572 (0.1854)	Prec@1 100.000 (98.162)	
Epoch: [52][389/391]	LR: 2.0000000000000004e-07	Loss 0.1599 (0.1851)	Prec@1 100.000 (98.147)	
Total train loss: 0.1852

Train time: 19.576866149902344
 * Prec@1 65.350 Prec@5 87.220 Loss 1.4395
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.093034029006958

Epoch: [53][77/391]	LR: 2.0000000000000004e-07	Loss 0.2212 (0.1866)	Prec@1 96.875 (97.947)	
Epoch: [53][155/391]	LR: 2.0000000000000004e-07	Loss 0.1824 (0.1844)	Prec@1 98.438 (97.982)	
Epoch: [53][233/391]	LR: 2.0000000000000004e-07	Loss 0.1969 (0.1825)	Prec@1 98.438 (98.160)	
Epoch: [53][311/391]	LR: 2.0000000000000004e-07	Loss 0.1654 (0.1833)	Prec@1 98.438 (98.147)	
Epoch: [53][389/391]	LR: 2.0000000000000004e-07	Loss 0.1879 (0.1834)	Prec@1 97.656 (98.159)	
Total train loss: 0.1835

Train time: 19.781110525131226
 * Prec@1 65.170 Prec@5 87.280 Loss 1.4404
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.95594811439514

Epoch: [54][77/391]	LR: 2.0000000000000004e-07	Loss 0.1697 (0.1843)	Prec@1 99.219 (98.197)	
Epoch: [54][155/391]	LR: 2.0000000000000004e-07	Loss 0.2062 (0.1844)	Prec@1 96.875 (98.167)	
Epoch: [54][233/391]	LR: 2.0000000000000004e-07	Loss 0.1722 (0.1864)	Prec@1 100.000 (98.090)	
Epoch: [54][311/391]	LR: 2.0000000000000004e-07	Loss 0.1564 (0.1856)	Prec@1 97.656 (98.142)	
Epoch: [54][389/391]	LR: 2.0000000000000004e-07	Loss 0.2240 (0.1841)	Prec@1 97.656 (98.159)	
Total train loss: 0.1841

Train time: 19.018697261810303
 * Prec@1 65.180 Prec@5 87.310 Loss 1.4326
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 21.286247968673706

Epoch: [55][77/391]	LR: 2.0000000000000004e-07	Loss 0.1678 (0.1895)	Prec@1 98.438 (98.157)	
Epoch: [55][155/391]	LR: 2.0000000000000004e-07	Loss 0.2064 (0.1864)	Prec@1 97.656 (98.132)	
Epoch: [55][233/391]	LR: 2.0000000000000004e-07	Loss 0.1847 (0.1832)	Prec@1 98.438 (98.217)	
Epoch: [55][311/391]	LR: 2.0000000000000004e-07	Loss 0.1519 (0.1829)	Prec@1 100.000 (98.187)	
Epoch: [55][389/391]	LR: 2.0000000000000004e-07	Loss 0.2485 (0.1824)	Prec@1 96.094 (98.205)	
Total train loss: 0.1825

Train time: 19.611759185791016
 * Prec@1 65.450 Prec@5 87.300 Loss 1.4434
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 21.717962980270386

Epoch: [56][77/391]	LR: 2.0000000000000004e-07	Loss 0.1779 (0.1816)	Prec@1 96.875 (98.167)	
Epoch: [56][155/391]	LR: 2.0000000000000004e-07	Loss 0.2141 (0.1812)	Prec@1 96.094 (98.267)	
Epoch: [56][233/391]	LR: 2.0000000000000004e-07	Loss 0.1696 (0.1822)	Prec@1 98.438 (98.227)	
Epoch: [56][311/391]	LR: 2.0000000000000004e-07	Loss 0.1975 (0.1815)	Prec@1 97.656 (98.232)	
Epoch: [56][389/391]	LR: 2.0000000000000004e-07	Loss 0.1716 (0.1816)	Prec@1 100.000 (98.229)	
Total train loss: 0.1818

Train time: 20.04576301574707
 * Prec@1 65.490 Prec@5 87.150 Loss 1.4355
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.98266577720642

Epoch: [57][77/391]	LR: 2.0000000000000004e-07	Loss 0.1938 (0.1798)	Prec@1 97.656 (98.177)	
Epoch: [57][155/391]	LR: 2.0000000000000004e-07	Loss 0.2175 (0.1835)	Prec@1 96.094 (98.072)	
Epoch: [57][233/391]	LR: 2.0000000000000004e-07	Loss 0.1720 (0.1846)	Prec@1 99.219 (98.047)	
Epoch: [57][311/391]	LR: 2.0000000000000004e-07	Loss 0.1484 (0.1831)	Prec@1 100.000 (98.079)	
Epoch: [57][389/391]	LR: 2.0000000000000004e-07	Loss 0.1799 (0.1838)	Prec@1 97.656 (98.111)	
Total train loss: 0.1839

Train time: 19.175293684005737
 * Prec@1 65.170 Prec@5 87.210 Loss 1.4434
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 21.55342674255371

Epoch: [58][77/391]	LR: 2.0000000000000004e-07	Loss 0.1823 (0.1854)	Prec@1 98.438 (98.297)	
Epoch: [58][155/391]	LR: 2.0000000000000004e-07	Loss 0.1987 (0.1877)	Prec@1 97.656 (98.052)	
Epoch: [58][233/391]	LR: 2.0000000000000004e-07	Loss 0.1804 (0.1872)	Prec@1 98.438 (98.077)	
Epoch: [58][311/391]	LR: 2.0000000000000004e-07	Loss 0.1863 (0.1869)	Prec@1 98.438 (98.130)	
Epoch: [58][389/391]	LR: 2.0000000000000004e-07	Loss 0.1675 (0.1857)	Prec@1 98.438 (98.155)	
Total train loss: 0.1857

Train time: 20.061471462249756
 * Prec@1 65.450 Prec@5 87.360 Loss 1.4326
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.524179935455322

Epoch: [59][77/391]	LR: 2.0000000000000004e-07	Loss 0.1873 (0.1794)	Prec@1 96.875 (98.157)	
Epoch: [59][155/391]	LR: 2.0000000000000004e-07	Loss 0.1682 (0.1796)	Prec@1 99.219 (98.292)	
Epoch: [59][233/391]	LR: 2.0000000000000004e-07	Loss 0.2183 (0.1825)	Prec@1 96.094 (98.190)	
Epoch: [59][311/391]	LR: 2.0000000000000004e-07	Loss 0.1520 (0.1836)	Prec@1 99.219 (98.197)	
Epoch: [59][389/391]	LR: 2.0000000000000004e-07	Loss 0.1287 (0.1844)	Prec@1 100.000 (98.215)	
Total train loss: 0.1845

Train time: 19.401302099227905
 * Prec@1 65.410 Prec@5 87.200 Loss 1.4355
Best acc: 68.140
--------------------------------------------------------------------------------
Test time: 22.39482808113098


      ==> Arguments:
          dataset: cifar100
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/
          savedir: ../pretrained_models/frozen/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar100_i8b5f_w8b7f.pth.tar
          mode: rram
          workers: 8
          epochs: 60
          start_epoch: 0
          batch_size: 128
          lr: 0.002
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 7
          af_bit: 5
          w_bit: 7
          wf_bit: 7
          milestones: [20, 30, 40, 50]
          exp: x128-8b
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 7
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar100_i8b5f_w8b7f.pth.tar ...
Original model accuracy: 69.61000061035156
 * Prec@1 64.350 Prec@5 88.100 Loss 1.3789
Pre-trained Prec@1 with 7 layers frozen: 64.3499984741211 	 Loss: 1.37890625

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.002	Loss 0.5908 (0.6073)	Prec@1 86.719 (82.352)	
Epoch: [0][155/391]	LR: 0.002	Loss 0.5703 (0.6121)	Prec@1 83.594 (82.146)	
Epoch: [0][233/391]	LR: 0.002	Loss 0.5708 (0.6130)	Prec@1 85.938 (82.125)	
Epoch: [0][311/391]	LR: 0.002	Loss 0.7256 (0.6147)	Prec@1 78.125 (82.076)	
Epoch: [0][389/391]	LR: 0.002	Loss 0.6172 (0.6169)	Prec@1 85.938 (82.045)	
Total train loss: 0.6169

Train time: 88.27725648880005
 * Prec@1 67.990 Prec@5 89.920 Loss 1.2305
Best acc: 67.990
--------------------------------------------------------------------------------
Test time: 92.473304271698

Epoch: [1][77/391]	LR: 0.002	Loss 0.5303 (0.5298)	Prec@1 85.156 (85.557)	
Epoch: [1][155/391]	LR: 0.002	Loss 0.5947 (0.5399)	Prec@1 81.250 (85.191)	
Epoch: [1][233/391]	LR: 0.002	Loss 0.4834 (0.5471)	Prec@1 88.281 (84.766)	
Epoch: [1][311/391]	LR: 0.002	Loss 0.7065 (0.5506)	Prec@1 80.469 (84.648)	
Epoch: [1][389/391]	LR: 0.002	Loss 0.6768 (0.5545)	Prec@1 80.469 (84.527)	
Total train loss: 0.5550

Train time: 17.736730098724365
 * Prec@1 67.970 Prec@5 89.710 Loss 1.2393
Best acc: 67.990
--------------------------------------------------------------------------------
Test time: 21.35171151161194

Epoch: [2][77/391]	LR: 0.002	Loss 0.5273 (0.4897)	Prec@1 85.938 (87.079)	
Epoch: [2][155/391]	LR: 0.002	Loss 0.5669 (0.4962)	Prec@1 82.812 (86.624)	
Epoch: [2][233/391]	LR: 0.002	Loss 0.5361 (0.5056)	Prec@1 86.719 (86.331)	
Epoch: [2][311/391]	LR: 0.002	Loss 0.5010 (0.5092)	Prec@1 86.719 (86.165)	
Epoch: [2][389/391]	LR: 0.002	Loss 0.5547 (0.5154)	Prec@1 85.938 (85.901)	
Total train loss: 0.5155

Train time: 16.246537685394287
 * Prec@1 68.070 Prec@5 89.840 Loss 1.2432
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 19.372259616851807

Epoch: [3][77/391]	LR: 0.002	Loss 0.4883 (0.4587)	Prec@1 89.062 (88.251)	
Epoch: [3][155/391]	LR: 0.002	Loss 0.6523 (0.4690)	Prec@1 79.688 (87.861)	
Epoch: [3][233/391]	LR: 0.002	Loss 0.6079 (0.4705)	Prec@1 85.156 (87.807)	
Epoch: [3][311/391]	LR: 0.002	Loss 0.4768 (0.4753)	Prec@1 89.062 (87.492)	
Epoch: [3][389/391]	LR: 0.002	Loss 0.4673 (0.4811)	Prec@1 88.281 (87.246)	
Total train loss: 0.4810

Train time: 15.662782669067383
 * Prec@1 67.260 Prec@5 89.290 Loss 1.2725
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 20.051069736480713

Epoch: [4][77/391]	LR: 0.002	Loss 0.3577 (0.4266)	Prec@1 91.406 (89.243)	
Epoch: [4][155/391]	LR: 0.002	Loss 0.4873 (0.4393)	Prec@1 85.938 (88.922)	
Epoch: [4][233/391]	LR: 0.002	Loss 0.5073 (0.4419)	Prec@1 85.156 (88.742)	
Epoch: [4][311/391]	LR: 0.002	Loss 0.6523 (0.4514)	Prec@1 78.125 (88.384)	
Epoch: [4][389/391]	LR: 0.002	Loss 0.4263 (0.4578)	Prec@1 87.500 (88.127)	
Total train loss: 0.4580

Train time: 19.150662899017334
 * Prec@1 67.120 Prec@5 89.060 Loss 1.2871
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.56722116470337

Epoch: [5][77/391]	LR: 0.002	Loss 0.4646 (0.4028)	Prec@1 88.281 (90.745)	
Epoch: [5][155/391]	LR: 0.002	Loss 0.4504 (0.4156)	Prec@1 89.844 (90.199)	
Epoch: [5][233/391]	LR: 0.002	Loss 0.5342 (0.4205)	Prec@1 85.156 (89.807)	
Epoch: [5][311/391]	LR: 0.002	Loss 0.4436 (0.4270)	Prec@1 89.062 (89.553)	
Epoch: [5][389/391]	LR: 0.002	Loss 0.5166 (0.4329)	Prec@1 85.156 (89.267)	
Total train loss: 0.4331

Train time: 17.891197681427002
 * Prec@1 66.980 Prec@5 89.130 Loss 1.2910
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.116530418395996

Epoch: [6][77/391]	LR: 0.002	Loss 0.3896 (0.3859)	Prec@1 86.719 (90.976)	
Epoch: [6][155/391]	LR: 0.002	Loss 0.4490 (0.3913)	Prec@1 90.625 (90.705)	
Epoch: [6][233/391]	LR: 0.002	Loss 0.4409 (0.3939)	Prec@1 89.062 (90.558)	
Epoch: [6][311/391]	LR: 0.002	Loss 0.4036 (0.4020)	Prec@1 89.844 (90.224)	
Epoch: [6][389/391]	LR: 0.002	Loss 0.3782 (0.4082)	Prec@1 89.844 (89.976)	
Total train loss: 0.4082

Train time: 18.67742896080017
 * Prec@1 66.900 Prec@5 88.630 Loss 1.3154
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.534091234207153

Epoch: [7][77/391]	LR: 0.002	Loss 0.3967 (0.3723)	Prec@1 91.406 (91.526)	
Epoch: [7][155/391]	LR: 0.002	Loss 0.4685 (0.3775)	Prec@1 91.406 (91.331)	
Epoch: [7][233/391]	LR: 0.002	Loss 0.3354 (0.3819)	Prec@1 93.750 (91.193)	
Epoch: [7][311/391]	LR: 0.002	Loss 0.4153 (0.3842)	Prec@1 95.312 (91.091)	
Epoch: [7][389/391]	LR: 0.002	Loss 0.4817 (0.3886)	Prec@1 88.281 (90.871)	
Total train loss: 0.3889

Train time: 19.32529878616333
 * Prec@1 66.710 Prec@5 88.440 Loss 1.3301
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.781890869140625

Epoch: [8][77/391]	LR: 0.002	Loss 0.3999 (0.3435)	Prec@1 92.969 (92.768)	
Epoch: [8][155/391]	LR: 0.002	Loss 0.4043 (0.3495)	Prec@1 92.188 (92.418)	
Epoch: [8][233/391]	LR: 0.002	Loss 0.3757 (0.3563)	Prec@1 92.188 (92.077)	
Epoch: [8][311/391]	LR: 0.002	Loss 0.3054 (0.3642)	Prec@1 92.969 (91.859)	
Epoch: [8][389/391]	LR: 0.002	Loss 0.2773 (0.3698)	Prec@1 92.188 (91.627)	
Total train loss: 0.3699

Train time: 19.04888367652893
 * Prec@1 66.950 Prec@5 88.480 Loss 1.3389
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.142492294311523

Epoch: [9][77/391]	LR: 0.002	Loss 0.3286 (0.3346)	Prec@1 92.969 (93.049)	
Epoch: [9][155/391]	LR: 0.002	Loss 0.3171 (0.3397)	Prec@1 94.531 (92.733)	
Epoch: [9][233/391]	LR: 0.002	Loss 0.3247 (0.3444)	Prec@1 91.406 (92.635)	
Epoch: [9][311/391]	LR: 0.002	Loss 0.3164 (0.3489)	Prec@1 94.531 (92.458)	
Epoch: [9][389/391]	LR: 0.002	Loss 0.4238 (0.3521)	Prec@1 89.062 (92.266)	
Total train loss: 0.3522

Train time: 18.192612886428833
 * Prec@1 66.220 Prec@5 88.280 Loss 1.3604
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.151324033737183

Epoch: [10][77/391]	LR: 0.002	Loss 0.2712 (0.3129)	Prec@1 95.312 (94.121)	
Epoch: [10][155/391]	LR: 0.002	Loss 0.3105 (0.3167)	Prec@1 92.969 (93.960)	
Epoch: [10][233/391]	LR: 0.002	Loss 0.2961 (0.3240)	Prec@1 95.312 (93.523)	
Epoch: [10][311/391]	LR: 0.002	Loss 0.3489 (0.3308)	Prec@1 90.625 (93.177)	
Epoch: [10][389/391]	LR: 0.002	Loss 0.3967 (0.3345)	Prec@1 91.406 (92.983)	
Total train loss: 0.3346

Train time: 17.860604524612427
 * Prec@1 65.900 Prec@5 88.210 Loss 1.3643
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 20.35232710838318

Epoch: [11][77/391]	LR: 0.002	Loss 0.3149 (0.3055)	Prec@1 90.625 (94.331)	
Epoch: [11][155/391]	LR: 0.002	Loss 0.3398 (0.3060)	Prec@1 91.406 (94.121)	
Epoch: [11][233/391]	LR: 0.002	Loss 0.3032 (0.3140)	Prec@1 92.188 (93.817)	
Epoch: [11][311/391]	LR: 0.002	Loss 0.3130 (0.3176)	Prec@1 96.094 (93.567)	
Epoch: [11][389/391]	LR: 0.002	Loss 0.3015 (0.3234)	Prec@1 93.750 (93.303)	
Total train loss: 0.3236

Train time: 18.958855152130127
 * Prec@1 65.830 Prec@5 88.120 Loss 1.3750
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.923612117767334

Epoch: [12][77/391]	LR: 0.002	Loss 0.2678 (0.2977)	Prec@1 95.312 (94.441)	
Epoch: [12][155/391]	LR: 0.002	Loss 0.3501 (0.2985)	Prec@1 92.188 (94.446)	
Epoch: [12][233/391]	LR: 0.002	Loss 0.2393 (0.3011)	Prec@1 96.094 (94.401)	
Epoch: [12][311/391]	LR: 0.002	Loss 0.3191 (0.3047)	Prec@1 94.531 (94.173)	
Epoch: [12][389/391]	LR: 0.002	Loss 0.3455 (0.3084)	Prec@1 93.750 (93.996)	
Total train loss: 0.3085

Train time: 19.713834524154663
 * Prec@1 66.000 Prec@5 87.890 Loss 1.3838
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 22.77192258834839

Epoch: [13][77/391]	LR: 0.002	Loss 0.3701 (0.2812)	Prec@1 90.625 (95.142)	
Epoch: [13][155/391]	LR: 0.002	Loss 0.3130 (0.2848)	Prec@1 92.188 (95.087)	
Epoch: [13][233/391]	LR: 0.002	Loss 0.3286 (0.2917)	Prec@1 92.188 (94.742)	
Epoch: [13][311/391]	LR: 0.002	Loss 0.3037 (0.2964)	Prec@1 93.750 (94.451)	
Epoch: [13][389/391]	LR: 0.002	Loss 0.3755 (0.2981)	Prec@1 91.406 (94.365)	
Total train loss: 0.2983

Train time: 19.023350954055786
 * Prec@1 65.600 Prec@5 87.920 Loss 1.4004
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.887300968170166

Epoch: [14][77/391]	LR: 0.002	Loss 0.2957 (0.2667)	Prec@1 94.531 (95.343)	
Epoch: [14][155/391]	LR: 0.002	Loss 0.2421 (0.2746)	Prec@1 97.656 (95.247)	
Epoch: [14][233/391]	LR: 0.002	Loss 0.2551 (0.2791)	Prec@1 96.094 (95.132)	
Epoch: [14][311/391]	LR: 0.002	Loss 0.2615 (0.2831)	Prec@1 96.875 (95.065)	
Epoch: [14][389/391]	LR: 0.002	Loss 0.2661 (0.2858)	Prec@1 94.531 (94.904)	
Total train loss: 0.2858

Train time: 19.491795301437378
 * Prec@1 65.460 Prec@5 87.550 Loss 1.4121
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.421547174453735

Epoch: [15][77/391]	LR: 0.002	Loss 0.2742 (0.2583)	Prec@1 96.094 (95.964)	
Epoch: [15][155/391]	LR: 0.002	Loss 0.2947 (0.2593)	Prec@1 96.094 (95.979)	
Epoch: [15][233/391]	LR: 0.002	Loss 0.2399 (0.2645)	Prec@1 98.438 (95.713)	
Epoch: [15][311/391]	LR: 0.002	Loss 0.2795 (0.2687)	Prec@1 94.531 (95.455)	
Epoch: [15][389/391]	LR: 0.002	Loss 0.2537 (0.2712)	Prec@1 95.312 (95.373)	
Total train loss: 0.2713

Train time: 19.040737628936768
 * Prec@1 65.720 Prec@5 87.600 Loss 1.4111
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 22.01943302154541

Epoch: [16][77/391]	LR: 0.002	Loss 0.2971 (0.2415)	Prec@1 91.406 (96.204)	
Epoch: [16][155/391]	LR: 0.002	Loss 0.2444 (0.2513)	Prec@1 95.312 (96.049)	
Epoch: [16][233/391]	LR: 0.002	Loss 0.2568 (0.2567)	Prec@1 94.531 (95.877)	
Epoch: [16][311/391]	LR: 0.002	Loss 0.2808 (0.2583)	Prec@1 93.750 (95.798)	
Epoch: [16][389/391]	LR: 0.002	Loss 0.3096 (0.2615)	Prec@1 94.531 (95.697)	
Total train loss: 0.2616

Train time: 18.68420910835266
 * Prec@1 64.930 Prec@5 87.510 Loss 1.4346
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.284666538238525

Epoch: [17][77/391]	LR: 0.002	Loss 0.1796 (0.2373)	Prec@1 100.000 (96.655)	
Epoch: [17][155/391]	LR: 0.002	Loss 0.2358 (0.2436)	Prec@1 95.312 (96.214)	
Epoch: [17][233/391]	LR: 0.002	Loss 0.2505 (0.2469)	Prec@1 98.438 (96.124)	
Epoch: [17][311/391]	LR: 0.002	Loss 0.2191 (0.2503)	Prec@1 96.875 (95.966)	
Epoch: [17][389/391]	LR: 0.002	Loss 0.2986 (0.2541)	Prec@1 91.406 (95.877)	
Total train loss: 0.2543

Train time: 18.19842767715454
 * Prec@1 64.750 Prec@5 87.470 Loss 1.4385
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.171882390975952

Epoch: [18][77/391]	LR: 0.002	Loss 0.3093 (0.2330)	Prec@1 95.312 (96.865)	
Epoch: [18][155/391]	LR: 0.002	Loss 0.2563 (0.2361)	Prec@1 96.875 (96.630)	
Epoch: [18][233/391]	LR: 0.002	Loss 0.2781 (0.2380)	Prec@1 93.750 (96.518)	
Epoch: [18][311/391]	LR: 0.002	Loss 0.3335 (0.2430)	Prec@1 94.531 (96.307)	
Epoch: [18][389/391]	LR: 0.002	Loss 0.2578 (0.2459)	Prec@1 95.312 (96.170)	
Total train loss: 0.2459

Train time: 18.52673649787903
 * Prec@1 65.370 Prec@5 87.250 Loss 1.4307
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.68777871131897

Epoch: [19][77/391]	LR: 0.002	Loss 0.2443 (0.2196)	Prec@1 97.656 (97.366)	
Epoch: [19][155/391]	LR: 0.002	Loss 0.2247 (0.2241)	Prec@1 98.438 (97.070)	
Epoch: [19][233/391]	LR: 0.002	Loss 0.2461 (0.2304)	Prec@1 95.312 (96.835)	
Epoch: [19][311/391]	LR: 0.002	Loss 0.2250 (0.2336)	Prec@1 95.312 (96.717)	
Epoch: [19][389/391]	LR: 0.002	Loss 0.2671 (0.2356)	Prec@1 95.312 (96.585)	
Total train loss: 0.2357

Train time: 18.640275239944458
 * Prec@1 64.940 Prec@5 87.120 Loss 1.4521
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.379127740859985

Epoch: [20][77/391]	LR: 0.0002	Loss 0.2546 (0.2035)	Prec@1 96.094 (97.556)	
Epoch: [20][155/391]	LR: 0.0002	Loss 0.2310 (0.2055)	Prec@1 96.094 (97.471)	
Epoch: [20][233/391]	LR: 0.0002	Loss 0.2321 (0.2057)	Prec@1 96.094 (97.503)	
Epoch: [20][311/391]	LR: 0.0002	Loss 0.2913 (0.2043)	Prec@1 94.531 (97.514)	
Epoch: [20][389/391]	LR: 0.0002	Loss 0.2142 (0.2041)	Prec@1 96.875 (97.534)	
Total train loss: 0.2041

Train time: 22.895514965057373
 * Prec@1 65.510 Prec@5 87.240 Loss 1.4443
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 25.047237396240234

Epoch: [21][77/391]	LR: 0.0002	Loss 0.2190 (0.2029)	Prec@1 98.438 (97.536)	
Epoch: [21][155/391]	LR: 0.0002	Loss 0.2151 (0.2020)	Prec@1 96.094 (97.721)	
Epoch: [21][233/391]	LR: 0.0002	Loss 0.1475 (0.2010)	Prec@1 99.219 (97.716)	
Epoch: [21][311/391]	LR: 0.0002	Loss 0.1744 (0.1997)	Prec@1 99.219 (97.716)	
Epoch: [21][389/391]	LR: 0.0002	Loss 0.1775 (0.1990)	Prec@1 99.219 (97.732)	
Total train loss: 0.1991

Train time: 19.659730911254883
 * Prec@1 65.410 Prec@5 87.370 Loss 1.4365
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.8433780670166

Epoch: [22][77/391]	LR: 0.0002	Loss 0.2198 (0.1913)	Prec@1 97.656 (98.127)	
Epoch: [22][155/391]	LR: 0.0002	Loss 0.2081 (0.1943)	Prec@1 99.219 (98.022)	
Epoch: [22][233/391]	LR: 0.0002	Loss 0.1926 (0.1947)	Prec@1 95.312 (97.907)	
Epoch: [22][311/391]	LR: 0.0002	Loss 0.2236 (0.1951)	Prec@1 96.875 (97.867)	
Epoch: [22][389/391]	LR: 0.0002	Loss 0.1953 (0.1957)	Prec@1 98.438 (97.847)	
Total train loss: 0.1958

Train time: 18.3536057472229
 * Prec@1 65.720 Prec@5 87.170 Loss 1.4443
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.226799964904785

Epoch: [23][77/391]	LR: 0.0002	Loss 0.2428 (0.1993)	Prec@1 96.094 (97.596)	
Epoch: [23][155/391]	LR: 0.0002	Loss 0.2551 (0.1961)	Prec@1 95.312 (97.711)	
Epoch: [23][233/391]	LR: 0.0002	Loss 0.1968 (0.1947)	Prec@1 99.219 (97.800)	
Epoch: [23][311/391]	LR: 0.0002	Loss 0.1388 (0.1948)	Prec@1 99.219 (97.794)	
Epoch: [23][389/391]	LR: 0.0002	Loss 0.1954 (0.1951)	Prec@1 97.656 (97.782)	
Total train loss: 0.1953

Train time: 18.498008012771606
 * Prec@1 65.600 Prec@5 87.390 Loss 1.4375
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.0298171043396

Epoch: [24][77/391]	LR: 0.0002	Loss 0.2261 (0.1893)	Prec@1 98.438 (97.987)	
Epoch: [24][155/391]	LR: 0.0002	Loss 0.1843 (0.1932)	Prec@1 98.438 (97.811)	
Epoch: [24][233/391]	LR: 0.0002	Loss 0.1688 (0.1940)	Prec@1 99.219 (97.786)	
Epoch: [24][311/391]	LR: 0.0002	Loss 0.1997 (0.1931)	Prec@1 99.219 (97.822)	
Epoch: [24][389/391]	LR: 0.0002	Loss 0.1698 (0.1931)	Prec@1 98.438 (97.871)	
Total train loss: 0.1932

Train time: 18.579989671707153
 * Prec@1 65.330 Prec@5 87.430 Loss 1.4443
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.688406944274902

Epoch: [25][77/391]	LR: 0.0002	Loss 0.1615 (0.1887)	Prec@1 98.438 (98.017)	
Epoch: [25][155/391]	LR: 0.0002	Loss 0.1732 (0.1916)	Prec@1 98.438 (97.977)	
Epoch: [25][233/391]	LR: 0.0002	Loss 0.1453 (0.1927)	Prec@1 98.438 (97.910)	
Epoch: [25][311/391]	LR: 0.0002	Loss 0.1432 (0.1916)	Prec@1 100.000 (97.924)	
Epoch: [25][389/391]	LR: 0.0002	Loss 0.1404 (0.1919)	Prec@1 99.219 (97.917)	
Total train loss: 0.1919

Train time: 18.543758630752563
 * Prec@1 65.340 Prec@5 87.160 Loss 1.4424
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.345613956451416

Epoch: [26][77/391]	LR: 0.0002	Loss 0.1949 (0.1907)	Prec@1 97.656 (97.997)	
Epoch: [26][155/391]	LR: 0.0002	Loss 0.2004 (0.1925)	Prec@1 98.438 (97.937)	
Epoch: [26][233/391]	LR: 0.0002	Loss 0.1818 (0.1922)	Prec@1 99.219 (97.987)	
Epoch: [26][311/391]	LR: 0.0002	Loss 0.1908 (0.1919)	Prec@1 98.438 (98.062)	
Epoch: [26][389/391]	LR: 0.0002	Loss 0.2186 (0.1914)	Prec@1 98.438 (98.083)	
Total train loss: 0.1914

Train time: 18.243863821029663
 * Prec@1 65.620 Prec@5 87.280 Loss 1.4414
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 20.304117441177368

Epoch: [27][77/391]	LR: 0.0002	Loss 0.1859 (0.1857)	Prec@1 97.656 (98.167)	
Epoch: [27][155/391]	LR: 0.0002	Loss 0.1840 (0.1897)	Prec@1 99.219 (97.972)	
Epoch: [27][233/391]	LR: 0.0002	Loss 0.1753 (0.1888)	Prec@1 98.438 (97.980)	
Epoch: [27][311/391]	LR: 0.0002	Loss 0.2180 (0.1888)	Prec@1 96.094 (98.004)	
Epoch: [27][389/391]	LR: 0.0002	Loss 0.1517 (0.1891)	Prec@1 97.656 (98.025)	
Total train loss: 0.1892

Train time: 19.013046741485596
 * Prec@1 65.640 Prec@5 87.350 Loss 1.4404
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.059873342514038

Epoch: [28][77/391]	LR: 0.0002	Loss 0.2627 (0.1893)	Prec@1 94.531 (97.897)	
Epoch: [28][155/391]	LR: 0.0002	Loss 0.1906 (0.1903)	Prec@1 97.656 (97.922)	
Epoch: [28][233/391]	LR: 0.0002	Loss 0.1765 (0.1902)	Prec@1 99.219 (97.963)	
Epoch: [28][311/391]	LR: 0.0002	Loss 0.1938 (0.1915)	Prec@1 100.000 (97.917)	
Epoch: [28][389/391]	LR: 0.0002	Loss 0.1576 (0.1917)	Prec@1 99.219 (97.921)	
Total train loss: 0.1917

Train time: 18.569888830184937
 * Prec@1 65.600 Prec@5 87.250 Loss 1.4443
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.663519382476807

Epoch: [29][77/391]	LR: 0.0002	Loss 0.1752 (0.1856)	Prec@1 96.875 (98.047)	
Epoch: [29][155/391]	LR: 0.0002	Loss 0.1493 (0.1863)	Prec@1 99.219 (98.172)	
Epoch: [29][233/391]	LR: 0.0002	Loss 0.2081 (0.1847)	Prec@1 97.656 (98.120)	
Epoch: [29][311/391]	LR: 0.0002	Loss 0.1637 (0.1868)	Prec@1 99.219 (98.079)	
Epoch: [29][389/391]	LR: 0.0002	Loss 0.1509 (0.1877)	Prec@1 100.000 (98.035)	
Total train loss: 0.1879

Train time: 18.448971033096313
 * Prec@1 65.320 Prec@5 87.250 Loss 1.4404
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 20.83641767501831

Epoch: [30][77/391]	LR: 2e-05	Loss 0.1315 (0.1818)	Prec@1 100.000 (98.237)	
Epoch: [30][155/391]	LR: 2e-05	Loss 0.1599 (0.1844)	Prec@1 100.000 (98.152)	
Epoch: [30][233/391]	LR: 2e-05	Loss 0.2035 (0.1865)	Prec@1 98.438 (98.174)	
Epoch: [30][311/391]	LR: 2e-05	Loss 0.1927 (0.1863)	Prec@1 98.438 (98.160)	
Epoch: [30][389/391]	LR: 2e-05	Loss 0.1600 (0.1860)	Prec@1 100.000 (98.125)	
Total train loss: 0.1862

Train time: 18.220471143722534
 * Prec@1 65.130 Prec@5 87.130 Loss 1.4531
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.428114414215088

Epoch: [31][77/391]	LR: 2e-05	Loss 0.1782 (0.1872)	Prec@1 99.219 (98.207)	
Epoch: [31][155/391]	LR: 2e-05	Loss 0.2266 (0.1854)	Prec@1 98.438 (98.257)	
Epoch: [31][233/391]	LR: 2e-05	Loss 0.1702 (0.1865)	Prec@1 98.438 (98.190)	
Epoch: [31][311/391]	LR: 2e-05	Loss 0.1744 (0.1868)	Prec@1 99.219 (98.197)	
Epoch: [31][389/391]	LR: 2e-05	Loss 0.1667 (0.1871)	Prec@1 99.219 (98.193)	
Total train loss: 0.1873

Train time: 18.839226007461548
 * Prec@1 65.300 Prec@5 87.430 Loss 1.4463
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.84163212776184

Epoch: [32][77/391]	LR: 2e-05	Loss 0.1962 (0.1862)	Prec@1 97.656 (98.257)	
Epoch: [32][155/391]	LR: 2e-05	Loss 0.2072 (0.1866)	Prec@1 96.875 (98.237)	
Epoch: [32][233/391]	LR: 2e-05	Loss 0.2507 (0.1872)	Prec@1 93.750 (98.150)	
Epoch: [32][311/391]	LR: 2e-05	Loss 0.1672 (0.1868)	Prec@1 98.438 (98.177)	
Epoch: [32][389/391]	LR: 2e-05	Loss 0.1517 (0.1876)	Prec@1 98.438 (98.171)	
Total train loss: 0.1877

Train time: 18.886305809020996
 * Prec@1 65.520 Prec@5 87.280 Loss 1.4395
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 20.958397388458252

Epoch: [33][77/391]	LR: 2e-05	Loss 0.1270 (0.1888)	Prec@1 100.000 (98.157)	
Epoch: [33][155/391]	LR: 2e-05	Loss 0.1849 (0.1905)	Prec@1 98.438 (98.137)	
Epoch: [33][233/391]	LR: 2e-05	Loss 0.1910 (0.1896)	Prec@1 100.000 (98.104)	
Epoch: [33][311/391]	LR: 2e-05	Loss 0.1761 (0.1879)	Prec@1 99.219 (98.099)	
Epoch: [33][389/391]	LR: 2e-05	Loss 0.2134 (0.1880)	Prec@1 96.875 (98.093)	
Total train loss: 0.1880

Train time: 18.306583404541016
 * Prec@1 65.220 Prec@5 87.260 Loss 1.4463
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 20.960512161254883

Epoch: [34][77/391]	LR: 2e-05	Loss 0.1587 (0.1924)	Prec@1 99.219 (98.107)	
Epoch: [34][155/391]	LR: 2e-05	Loss 0.1920 (0.1891)	Prec@1 98.438 (98.162)	
Epoch: [34][233/391]	LR: 2e-05	Loss 0.1991 (0.1874)	Prec@1 99.219 (98.140)	
Epoch: [34][311/391]	LR: 2e-05	Loss 0.1891 (0.1876)	Prec@1 96.094 (98.119)	
Epoch: [34][389/391]	LR: 2e-05	Loss 0.1707 (0.1878)	Prec@1 98.438 (98.091)	
Total train loss: 0.1878

Train time: 18.876131772994995
 * Prec@1 65.650 Prec@5 87.440 Loss 1.4473
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.630247116088867

Epoch: [35][77/391]	LR: 2e-05	Loss 0.2310 (0.1888)	Prec@1 96.875 (98.167)	
Epoch: [35][155/391]	LR: 2e-05	Loss 0.1713 (0.1873)	Prec@1 100.000 (98.227)	
Epoch: [35][233/391]	LR: 2e-05	Loss 0.1571 (0.1876)	Prec@1 98.438 (98.184)	
Epoch: [35][311/391]	LR: 2e-05	Loss 0.2046 (0.1879)	Prec@1 97.656 (98.145)	
Epoch: [35][389/391]	LR: 2e-05	Loss 0.1741 (0.1871)	Prec@1 98.438 (98.157)	
Total train loss: 0.1872

Train time: 18.087791204452515
 * Prec@1 65.370 Prec@5 87.160 Loss 1.4434
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 20.57336449623108

Epoch: [36][77/391]	LR: 2e-05	Loss 0.1503 (0.1815)	Prec@1 97.656 (98.117)	
Epoch: [36][155/391]	LR: 2e-05	Loss 0.1801 (0.1849)	Prec@1 98.438 (98.232)	
Epoch: [36][233/391]	LR: 2e-05	Loss 0.1694 (0.1862)	Prec@1 97.656 (98.251)	
Epoch: [36][311/391]	LR: 2e-05	Loss 0.1370 (0.1856)	Prec@1 99.219 (98.227)	
Epoch: [36][389/391]	LR: 2e-05	Loss 0.1580 (0.1865)	Prec@1 100.000 (98.183)	
Total train loss: 0.1866

Train time: 18.46888780593872
 * Prec@1 65.110 Prec@5 87.290 Loss 1.4443
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.518670082092285

Epoch: [37][77/391]	LR: 2e-05	Loss 0.2157 (0.1853)	Prec@1 98.438 (97.997)	
Epoch: [37][155/391]	LR: 2e-05	Loss 0.1676 (0.1888)	Prec@1 99.219 (97.927)	
Epoch: [37][233/391]	LR: 2e-05	Loss 0.1801 (0.1891)	Prec@1 99.219 (97.983)	
Epoch: [37][311/391]	LR: 2e-05	Loss 0.1858 (0.1897)	Prec@1 99.219 (97.984)	
Epoch: [37][389/391]	LR: 2e-05	Loss 0.1801 (0.1889)	Prec@1 97.656 (98.033)	
Total train loss: 0.1890

Train time: 19.61307978630066
 * Prec@1 65.120 Prec@5 87.060 Loss 1.4580
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 22.731473207473755

Epoch: [38][77/391]	LR: 2e-05	Loss 0.1614 (0.1875)	Prec@1 95.312 (98.037)	
Epoch: [38][155/391]	LR: 2e-05	Loss 0.1729 (0.1880)	Prec@1 98.438 (98.062)	
Epoch: [38][233/391]	LR: 2e-05	Loss 0.2078 (0.1872)	Prec@1 96.875 (98.067)	
Epoch: [38][311/391]	LR: 2e-05	Loss 0.1525 (0.1871)	Prec@1 99.219 (98.082)	
Epoch: [38][389/391]	LR: 2e-05	Loss 0.1749 (0.1873)	Prec@1 98.438 (98.075)	
Total train loss: 0.1874

Train time: 19.329424619674683
 * Prec@1 65.310 Prec@5 87.270 Loss 1.4492
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.42317485809326

Epoch: [39][77/391]	LR: 2e-05	Loss 0.2388 (0.1862)	Prec@1 96.094 (98.017)	
Epoch: [39][155/391]	LR: 2e-05	Loss 0.1754 (0.1887)	Prec@1 96.094 (98.047)	
Epoch: [39][233/391]	LR: 2e-05	Loss 0.1655 (0.1873)	Prec@1 98.438 (98.090)	
Epoch: [39][311/391]	LR: 2e-05	Loss 0.1895 (0.1879)	Prec@1 98.438 (98.082)	
Epoch: [39][389/391]	LR: 2e-05	Loss 0.1974 (0.1879)	Prec@1 96.875 (98.073)	
Total train loss: 0.1880

Train time: 19.19377565383911
 * Prec@1 65.300 Prec@5 87.320 Loss 1.4385
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 22.300158262252808

Epoch: [40][77/391]	LR: 2.0000000000000003e-06	Loss 0.2559 (0.1909)	Prec@1 96.094 (98.037)	
Epoch: [40][155/391]	LR: 2.0000000000000003e-06	Loss 0.1826 (0.1909)	Prec@1 98.438 (97.977)	
Epoch: [40][233/391]	LR: 2.0000000000000003e-06	Loss 0.1837 (0.1893)	Prec@1 97.656 (98.050)	
Epoch: [40][311/391]	LR: 2.0000000000000003e-06	Loss 0.2401 (0.1893)	Prec@1 95.312 (97.989)	
Epoch: [40][389/391]	LR: 2.0000000000000003e-06	Loss 0.1897 (0.1889)	Prec@1 95.312 (98.021)	
Total train loss: 0.1888

Train time: 18.818212509155273
 * Prec@1 65.650 Prec@5 87.310 Loss 1.4434
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 25.82620644569397

Epoch: [41][77/391]	LR: 2.0000000000000003e-06	Loss 0.1609 (0.1873)	Prec@1 99.219 (98.017)	
Epoch: [41][155/391]	LR: 2.0000000000000003e-06	Loss 0.1826 (0.1882)	Prec@1 98.438 (98.102)	
Epoch: [41][233/391]	LR: 2.0000000000000003e-06	Loss 0.1782 (0.1903)	Prec@1 99.219 (98.040)	
Epoch: [41][311/391]	LR: 2.0000000000000003e-06	Loss 0.2021 (0.1877)	Prec@1 97.656 (98.094)	
Epoch: [41][389/391]	LR: 2.0000000000000003e-06	Loss 0.2208 (0.1883)	Prec@1 98.438 (98.075)	
Total train loss: 0.1884

Train time: 18.56833004951477
 * Prec@1 65.480 Prec@5 87.210 Loss 1.4395
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.086017847061157

Epoch: [42][77/391]	LR: 2.0000000000000003e-06	Loss 0.1908 (0.1833)	Prec@1 96.094 (98.207)	
Epoch: [42][155/391]	LR: 2.0000000000000003e-06	Loss 0.1930 (0.1838)	Prec@1 96.875 (98.197)	
Epoch: [42][233/391]	LR: 2.0000000000000003e-06	Loss 0.1646 (0.1850)	Prec@1 99.219 (98.254)	
Epoch: [42][311/391]	LR: 2.0000000000000003e-06	Loss 0.2314 (0.1860)	Prec@1 96.875 (98.245)	
Epoch: [42][389/391]	LR: 2.0000000000000003e-06	Loss 0.2404 (0.1858)	Prec@1 99.219 (98.257)	
Total train loss: 0.1860

Train time: 18.798390865325928
 * Prec@1 65.250 Prec@5 87.280 Loss 1.4395
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.77617907524109

Epoch: [43][77/391]	LR: 2.0000000000000003e-06	Loss 0.1726 (0.1853)	Prec@1 99.219 (98.217)	
Epoch: [43][155/391]	LR: 2.0000000000000003e-06	Loss 0.2209 (0.1857)	Prec@1 96.094 (98.172)	
Epoch: [43][233/391]	LR: 2.0000000000000003e-06	Loss 0.2888 (0.1871)	Prec@1 93.750 (98.127)	
Epoch: [43][311/391]	LR: 2.0000000000000003e-06	Loss 0.1677 (0.1875)	Prec@1 98.438 (98.160)	
Epoch: [43][389/391]	LR: 2.0000000000000003e-06	Loss 0.1541 (0.1874)	Prec@1 98.438 (98.173)	
Total train loss: 0.1875

Train time: 18.793245553970337
 * Prec@1 65.630 Prec@5 87.380 Loss 1.4414
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.8277006149292

Epoch: [44][77/391]	LR: 2.0000000000000003e-06	Loss 0.1760 (0.1828)	Prec@1 97.656 (98.047)	
Epoch: [44][155/391]	LR: 2.0000000000000003e-06	Loss 0.1914 (0.1876)	Prec@1 97.656 (98.032)	
Epoch: [44][233/391]	LR: 2.0000000000000003e-06	Loss 0.1580 (0.1867)	Prec@1 98.438 (98.084)	
Epoch: [44][311/391]	LR: 2.0000000000000003e-06	Loss 0.1929 (0.1868)	Prec@1 100.000 (98.054)	
Epoch: [44][389/391]	LR: 2.0000000000000003e-06	Loss 0.1814 (0.1867)	Prec@1 98.438 (98.079)	
Total train loss: 0.1867

Train time: 19.280852794647217
 * Prec@1 65.350 Prec@5 87.260 Loss 1.4424
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.418258905410767

Epoch: [45][77/391]	LR: 2.0000000000000003e-06	Loss 0.2026 (0.1863)	Prec@1 97.656 (98.037)	
Epoch: [45][155/391]	LR: 2.0000000000000003e-06	Loss 0.1871 (0.1847)	Prec@1 97.656 (98.057)	
Epoch: [45][233/391]	LR: 2.0000000000000003e-06	Loss 0.3035 (0.1864)	Prec@1 93.750 (98.040)	
Epoch: [45][311/391]	LR: 2.0000000000000003e-06	Loss 0.2382 (0.1885)	Prec@1 96.875 (98.017)	
Epoch: [45][389/391]	LR: 2.0000000000000003e-06	Loss 0.2288 (0.1881)	Prec@1 95.312 (98.029)	
Total train loss: 0.1883

Train time: 19.537341594696045
 * Prec@1 65.500 Prec@5 87.390 Loss 1.4453
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.940037965774536

Epoch: [46][77/391]	LR: 2.0000000000000003e-06	Loss 0.1761 (0.1866)	Prec@1 99.219 (98.067)	
Epoch: [46][155/391]	LR: 2.0000000000000003e-06	Loss 0.1948 (0.1856)	Prec@1 97.656 (98.122)	
Epoch: [46][233/391]	LR: 2.0000000000000003e-06	Loss 0.1604 (0.1850)	Prec@1 99.219 (98.117)	
Epoch: [46][311/391]	LR: 2.0000000000000003e-06	Loss 0.2279 (0.1859)	Prec@1 96.094 (98.097)	
Epoch: [46][389/391]	LR: 2.0000000000000003e-06	Loss 0.1786 (0.1866)	Prec@1 99.219 (98.067)	
Total train loss: 0.1866

Train time: 18.41146945953369
 * Prec@1 65.440 Prec@5 87.330 Loss 1.4424
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.213960886001587

Epoch: [47][77/391]	LR: 2.0000000000000003e-06	Loss 0.2129 (0.1793)	Prec@1 99.219 (98.538)	
Epoch: [47][155/391]	LR: 2.0000000000000003e-06	Loss 0.2120 (0.1849)	Prec@1 98.438 (98.277)	
Epoch: [47][233/391]	LR: 2.0000000000000003e-06	Loss 0.2324 (0.1853)	Prec@1 96.875 (98.214)	
Epoch: [47][311/391]	LR: 2.0000000000000003e-06	Loss 0.2157 (0.1871)	Prec@1 96.094 (98.167)	
Epoch: [47][389/391]	LR: 2.0000000000000003e-06	Loss 0.1951 (0.1882)	Prec@1 98.438 (98.127)	
Total train loss: 0.1883

Train time: 18.773744583129883
 * Prec@1 65.160 Prec@5 87.370 Loss 1.4463
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.13943648338318

Epoch: [48][77/391]	LR: 2.0000000000000003e-06	Loss 0.1967 (0.1865)	Prec@1 98.438 (98.277)	
Epoch: [48][155/391]	LR: 2.0000000000000003e-06	Loss 0.1791 (0.1852)	Prec@1 99.219 (98.192)	
Epoch: [48][233/391]	LR: 2.0000000000000003e-06	Loss 0.1786 (0.1865)	Prec@1 97.656 (98.190)	
Epoch: [48][311/391]	LR: 2.0000000000000003e-06	Loss 0.1643 (0.1876)	Prec@1 98.438 (98.132)	
Epoch: [48][389/391]	LR: 2.0000000000000003e-06	Loss 0.1646 (0.1880)	Prec@1 97.656 (98.081)	
Total train loss: 0.1880

Train time: 18.693575143814087
 * Prec@1 65.270 Prec@5 87.360 Loss 1.4434
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.825448274612427

Epoch: [49][77/391]	LR: 2.0000000000000003e-06	Loss 0.1790 (0.1907)	Prec@1 98.438 (98.077)	
Epoch: [49][155/391]	LR: 2.0000000000000003e-06	Loss 0.2430 (0.1884)	Prec@1 97.656 (98.087)	
Epoch: [49][233/391]	LR: 2.0000000000000003e-06	Loss 0.1541 (0.1868)	Prec@1 98.438 (98.067)	
Epoch: [49][311/391]	LR: 2.0000000000000003e-06	Loss 0.1592 (0.1867)	Prec@1 98.438 (98.084)	
Epoch: [49][389/391]	LR: 2.0000000000000003e-06	Loss 0.1588 (0.1875)	Prec@1 96.875 (98.067)	
Total train loss: 0.1875

Train time: 19.138426303863525
 * Prec@1 65.360 Prec@5 87.390 Loss 1.4453
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 22.27375626564026

Epoch: [50][77/391]	LR: 2.0000000000000004e-07	Loss 0.2231 (0.1854)	Prec@1 97.656 (98.307)	
Epoch: [50][155/391]	LR: 2.0000000000000004e-07	Loss 0.1387 (0.1851)	Prec@1 99.219 (98.202)	
Epoch: [50][233/391]	LR: 2.0000000000000004e-07	Loss 0.1639 (0.1851)	Prec@1 99.219 (98.220)	
Epoch: [50][311/391]	LR: 2.0000000000000004e-07	Loss 0.1648 (0.1847)	Prec@1 99.219 (98.225)	
Epoch: [50][389/391]	LR: 2.0000000000000004e-07	Loss 0.1772 (0.1861)	Prec@1 98.438 (98.173)	
Total train loss: 0.1862

Train time: 18.88041615486145
 * Prec@1 65.370 Prec@5 87.410 Loss 1.4473
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.206167459487915

Epoch: [51][77/391]	LR: 2.0000000000000004e-07	Loss 0.1447 (0.1823)	Prec@1 99.219 (98.427)	
Epoch: [51][155/391]	LR: 2.0000000000000004e-07	Loss 0.2379 (0.1854)	Prec@1 95.312 (98.192)	
Epoch: [51][233/391]	LR: 2.0000000000000004e-07	Loss 0.1659 (0.1854)	Prec@1 100.000 (98.164)	
Epoch: [51][311/391]	LR: 2.0000000000000004e-07	Loss 0.2054 (0.1864)	Prec@1 96.875 (98.124)	
Epoch: [51][389/391]	LR: 2.0000000000000004e-07	Loss 0.1710 (0.1851)	Prec@1 100.000 (98.151)	
Total train loss: 0.1853

Train time: 19.020811557769775
 * Prec@1 65.410 Prec@5 87.220 Loss 1.4473
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.88990092277527

Epoch: [52][77/391]	LR: 2.0000000000000004e-07	Loss 0.1689 (0.1853)	Prec@1 97.656 (98.227)	
Epoch: [52][155/391]	LR: 2.0000000000000004e-07	Loss 0.1591 (0.1880)	Prec@1 99.219 (98.132)	
Epoch: [52][233/391]	LR: 2.0000000000000004e-07	Loss 0.2296 (0.1892)	Prec@1 97.656 (98.087)	
Epoch: [52][311/391]	LR: 2.0000000000000004e-07	Loss 0.2323 (0.1890)	Prec@1 96.875 (98.069)	
Epoch: [52][389/391]	LR: 2.0000000000000004e-07	Loss 0.1620 (0.1884)	Prec@1 96.094 (98.063)	
Total train loss: 0.1884

Train time: 19.66244125366211
 * Prec@1 65.390 Prec@5 87.160 Loss 1.4482
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 22.362080097198486

Epoch: [53][77/391]	LR: 2.0000000000000004e-07	Loss 0.1866 (0.1849)	Prec@1 98.438 (98.107)	
Epoch: [53][155/391]	LR: 2.0000000000000004e-07	Loss 0.2373 (0.1881)	Prec@1 95.312 (98.147)	
Epoch: [53][233/391]	LR: 2.0000000000000004e-07	Loss 0.2161 (0.1869)	Prec@1 97.656 (98.090)	
Epoch: [53][311/391]	LR: 2.0000000000000004e-07	Loss 0.2034 (0.1871)	Prec@1 98.438 (98.114)	
Epoch: [53][389/391]	LR: 2.0000000000000004e-07	Loss 0.2012 (0.1880)	Prec@1 95.312 (98.095)	
Total train loss: 0.1882

Train time: 19.115248680114746
 * Prec@1 65.500 Prec@5 87.390 Loss 1.4424
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 21.63892889022827

Epoch: [54][77/391]	LR: 2.0000000000000004e-07	Loss 0.1486 (0.1904)	Prec@1 99.219 (98.047)	
Epoch: [54][155/391]	LR: 2.0000000000000004e-07	Loss 0.2625 (0.1885)	Prec@1 96.094 (98.092)	
Epoch: [54][233/391]	LR: 2.0000000000000004e-07	Loss 0.2251 (0.1888)	Prec@1 96.875 (97.987)	
Epoch: [54][311/391]	LR: 2.0000000000000004e-07	Loss 0.2009 (0.1883)	Prec@1 98.438 (98.044)	
Epoch: [54][389/391]	LR: 2.0000000000000004e-07	Loss 0.2224 (0.1874)	Prec@1 97.656 (98.079)	
Total train loss: 0.1875

Train time: 19.070470333099365
 * Prec@1 65.530 Prec@5 87.270 Loss 1.4434
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 22.075455904006958

Epoch: [55][77/391]	LR: 2.0000000000000004e-07	Loss 0.2363 (0.1850)	Prec@1 94.531 (98.147)	
Epoch: [55][155/391]	LR: 2.0000000000000004e-07	Loss 0.2002 (0.1867)	Prec@1 97.656 (98.082)	
Epoch: [55][233/391]	LR: 2.0000000000000004e-07	Loss 0.1809 (0.1869)	Prec@1 99.219 (98.090)	
Epoch: [55][311/391]	LR: 2.0000000000000004e-07	Loss 0.1920 (0.1872)	Prec@1 97.656 (98.102)	
Epoch: [55][389/391]	LR: 2.0000000000000004e-07	Loss 0.2065 (0.1874)	Prec@1 98.438 (98.089)	
Total train loss: 0.1874

Train time: 15.984055757522583
 * Prec@1 65.490 Prec@5 87.160 Loss 1.4502
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 19.496336460113525

Epoch: [56][77/391]	LR: 2.0000000000000004e-07	Loss 0.2218 (0.1881)	Prec@1 96.094 (98.187)	
Epoch: [56][155/391]	LR: 2.0000000000000004e-07	Loss 0.1882 (0.1884)	Prec@1 96.875 (98.037)	
Epoch: [56][233/391]	LR: 2.0000000000000004e-07	Loss 0.1930 (0.1885)	Prec@1 97.656 (98.034)	
Epoch: [56][311/391]	LR: 2.0000000000000004e-07	Loss 0.1958 (0.1882)	Prec@1 98.438 (98.014)	
Epoch: [56][389/391]	LR: 2.0000000000000004e-07	Loss 0.1367 (0.1878)	Prec@1 100.000 (98.053)	
Total train loss: 0.1879

Train time: 15.540384769439697
 * Prec@1 65.380 Prec@5 87.240 Loss 1.4482
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 17.296188592910767

Epoch: [57][77/391]	LR: 2.0000000000000004e-07	Loss 0.1759 (0.1864)	Prec@1 98.438 (98.277)	
Epoch: [57][155/391]	LR: 2.0000000000000004e-07	Loss 0.1482 (0.1879)	Prec@1 99.219 (98.092)	
Epoch: [57][233/391]	LR: 2.0000000000000004e-07	Loss 0.1967 (0.1891)	Prec@1 98.438 (98.040)	
Epoch: [57][311/391]	LR: 2.0000000000000004e-07	Loss 0.2432 (0.1888)	Prec@1 95.312 (98.032)	
Epoch: [57][389/391]	LR: 2.0000000000000004e-07	Loss 0.1798 (0.1882)	Prec@1 96.875 (98.025)	
Total train loss: 0.1883

Train time: 14.462739706039429
 * Prec@1 65.840 Prec@5 87.250 Loss 1.4404
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 16.28912591934204

Epoch: [58][77/391]	LR: 2.0000000000000004e-07	Loss 0.2042 (0.1900)	Prec@1 96.875 (97.987)	
Epoch: [58][155/391]	LR: 2.0000000000000004e-07	Loss 0.1603 (0.1876)	Prec@1 98.438 (97.997)	
Epoch: [58][233/391]	LR: 2.0000000000000004e-07	Loss 0.2080 (0.1873)	Prec@1 98.438 (98.007)	
Epoch: [58][311/391]	LR: 2.0000000000000004e-07	Loss 0.1515 (0.1868)	Prec@1 100.000 (98.062)	
Epoch: [58][389/391]	LR: 2.0000000000000004e-07	Loss 0.1998 (0.1877)	Prec@1 97.656 (98.059)	
Total train loss: 0.1878

Train time: 14.93541431427002
 * Prec@1 65.310 Prec@5 87.110 Loss 1.4580
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 18.07281756401062

Epoch: [59][77/391]	LR: 2.0000000000000004e-07	Loss 0.1522 (0.1878)	Prec@1 98.438 (98.177)	
Epoch: [59][155/391]	LR: 2.0000000000000004e-07	Loss 0.1884 (0.1872)	Prec@1 98.438 (98.157)	
Epoch: [59][233/391]	LR: 2.0000000000000004e-07	Loss 0.1932 (0.1875)	Prec@1 98.438 (98.147)	
Epoch: [59][311/391]	LR: 2.0000000000000004e-07	Loss 0.1710 (0.1881)	Prec@1 97.656 (98.167)	
Epoch: [59][389/391]	LR: 2.0000000000000004e-07	Loss 0.1818 (0.1891)	Prec@1 97.656 (98.121)	
Total train loss: 0.1892

Train time: 15.526118516921997
 * Prec@1 65.230 Prec@5 87.220 Loss 1.4492
Best acc: 68.070
--------------------------------------------------------------------------------
Test time: 18.602306842803955

