
      ==> Arguments:
          dataset: cifar100
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/one_batch/
          savedir: ../pretrained_models/frozen/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          workers: 8
          epochs: 40
          start_epoch: 0
          batch_size: 256
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.5
          milestones: [10, 20, 30]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 17
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
 * Prec@1 1.130 Prec@5 5.720 Loss 4.6211
Avg Loading time: 5.4203 seconds
Avg Batch time: 5.4411 seconds

Pre-trained Prec@1 with 17 layers frozen: 1.1299999952316284 	 Loss: 4.62109375

Starting training on SRAM layers...
Epoch: [0][38/196]	LR: 0.1	DT: 0.075 (8.590)	BT: 0.087 (8.601)	Loss 3.4062 (3.9109)	Prec@1 23.047 (14.403)	
Epoch: [0][77/196]	LR: 0.1	DT: 0.000 (8.551)	BT: 0.008 (8.562)	Loss 3.2969 (3.6604)	Prec@1 20.312 (18.154)	
Epoch: [0][116/196]	LR: 0.1	DT: 0.000 (8.385)	BT: 0.009 (8.395)	Loss 3.0918 (3.5046)	Prec@1 31.641 (20.653)	
Epoch: [0][155/196]	LR: 0.1	DT: 2.593 (8.217)	BT: 2.604 (8.227)	Loss 3.1172 (3.3989)	Prec@1 25.000 (22.175)	
Epoch: [0][194/196]	LR: 0.1	DT: 0.000 (7.789)	BT: 0.009 (7.800)	Loss 3.0645 (3.3256)	Prec@1 25.391 (23.285)	
Total train loss: 3.3252
Avg Loading time: 7.7497 seconds
Avg Batch time: 7.7598 seconds

 * Prec@1 29.130 Prec@5 57.600 Loss 2.9727
Avg Loading time: 0.9593 seconds
Avg Batch time: 0.9662 seconds

Best acc: 29.130
--------------------------------------------------------------------------------
Epoch: [1][38/196]	LR: 0.1	DT: 0.000 (0.721)	BT: 0.006 (0.728)	Loss 2.9551 (2.7614)	Prec@1 29.297 (34.285)	
Epoch: [1][77/196]	LR: 0.1	DT: 0.000 (0.728)	BT: 0.006 (0.735)	Loss 2.8184 (2.7626)	Prec@1 33.984 (33.654)	
Epoch: [1][116/196]	LR: 0.1	DT: 0.000 (0.747)	BT: 0.006 (0.754)	Loss 2.8906 (2.7852)	Prec@1 29.688 (32.746)	
Epoch: [1][155/196]	LR: 0.1	DT: 0.000 (0.764)	BT: 0.006 (0.772)	Loss 2.7676 (2.7905)	Prec@1 29.688 (32.454)	
Epoch: [1][194/196]	LR: 0.1	DT: 0.000 (0.749)	BT: 0.006 (0.757)	Loss 2.8301 (2.7926)	Prec@1 32.031 (32.252)	
Total train loss: 2.7925
Avg Loading time: 0.7450 seconds
Avg Batch time: 0.7529 seconds

 * Prec@1 30.530 Prec@5 59.140 Loss 2.8848
Avg Loading time: 0.9858 seconds
Avg Batch time: 0.9922 seconds

Best acc: 30.530
--------------------------------------------------------------------------------
Epoch: [2][38/196]	LR: 0.1	DT: 0.813 (1.002)	BT: 0.827 (1.011)	Loss 2.3672 (2.5686)	Prec@1 42.578 (36.699)	
Epoch: [2][77/196]	LR: 0.1	DT: 0.000 (0.986)	BT: 0.006 (0.995)	Loss 2.7227 (2.5970)	Prec@1 34.766 (35.922)	
Epoch: [2][116/196]	LR: 0.1	DT: 0.000 (0.976)	BT: 0.005 (0.985)	Loss 2.7500 (2.6175)	Prec@1 34.375 (35.470)	
Epoch: [2][155/196]	LR: 0.1	DT: 0.000 (1.020)	BT: 0.007 (1.029)	Loss 2.7305 (2.6312)	Prec@1 32.812 (35.349)	
Epoch: [2][194/196]	LR: 0.1	DT: 0.000 (1.033)	BT: 0.007 (1.042)	Loss 2.6777 (2.6470)	Prec@1 30.859 (34.892)	
Total train loss: 2.6470
Avg Loading time: 1.0282 seconds
Avg Batch time: 1.0368 seconds

 * Prec@1 30.810 Prec@5 59.040 Loss 2.8770
Avg Loading time: 1.0768 seconds
Avg Batch time: 1.0833 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [3][38/196]	LR: 0.1	DT: 0.000 (0.801)	BT: 0.005 (0.809)	Loss 2.4688 (2.4801)	Prec@1 40.234 (38.201)	
Epoch: [3][77/196]	LR: 0.1	DT: 0.000 (0.753)	BT: 0.007 (0.761)	Loss 2.5645 (2.5021)	Prec@1 30.078 (37.520)	
Epoch: [3][116/196]	LR: 0.1	DT: 0.000 (0.649)	BT: 0.007 (0.658)	Loss 2.4922 (2.5267)	Prec@1 36.719 (36.762)	
Epoch: [3][155/196]	LR: 0.1	DT: 0.000 (0.584)	BT: 0.007 (0.593)	Loss 2.6191 (2.5470)	Prec@1 40.234 (36.458)	
Epoch: [3][194/196]	LR: 0.1	DT: 0.152 (0.537)	BT: 0.159 (0.545)	Loss 2.8633 (2.5659)	Prec@1 32.422 (36.064)	
Total train loss: 2.5661
Avg Loading time: 0.5342 seconds
Avg Batch time: 0.5426 seconds

 * Prec@1 30.280 Prec@5 58.980 Loss 2.8828
Avg Loading time: 0.3389 seconds
Avg Batch time: 0.3460 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [4][38/196]	LR: 0.1	DT: 0.000 (0.351)	BT: 0.006 (0.361)	Loss 2.4121 (2.4019)	Prec@1 41.016 (40.224)	
Epoch: [4][77/196]	LR: 0.1	DT: 0.000 (0.296)	BT: 0.005 (0.305)	Loss 2.4824 (2.4443)	Prec@1 38.672 (39.113)	
Epoch: [4][116/196]	LR: 0.1	DT: 0.000 (0.299)	BT: 0.007 (0.307)	Loss 2.7383 (2.4708)	Prec@1 31.250 (38.585)	
Epoch: [4][155/196]	LR: 0.1	DT: 0.333 (0.353)	BT: 0.344 (0.361)	Loss 2.6934 (2.4989)	Prec@1 32.031 (37.783)	
Epoch: [4][194/196]	LR: 0.1	DT: 0.000 (0.363)	BT: 0.009 (0.372)	Loss 2.5664 (2.5176)	Prec@1 33.984 (37.302)	
Total train loss: 2.5180
Avg Loading time: 0.3608 seconds
Avg Batch time: 0.3699 seconds

 * Prec@1 30.450 Prec@5 59.610 Loss 2.8770
Avg Loading time: 0.4947 seconds
Avg Batch time: 0.5008 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [5][38/196]	LR: 0.1	DT: 0.000 (0.460)	BT: 0.006 (0.469)	Loss 2.3926 (2.3544)	Prec@1 40.625 (40.535)	
Epoch: [5][77/196]	LR: 0.1	DT: 0.000 (0.454)	BT: 0.007 (0.462)	Loss 2.6211 (2.4082)	Prec@1 32.812 (39.203)	
Epoch: [5][116/196]	LR: 0.1	DT: 0.000 (0.463)	BT: 0.007 (0.472)	Loss 2.5566 (2.4424)	Prec@1 37.891 (38.598)	
Epoch: [5][155/196]	LR: 0.1	DT: 0.419 (0.474)	BT: 0.430 (0.483)	Loss 2.4727 (2.4588)	Prec@1 40.625 (38.384)	
Epoch: [5][194/196]	LR: 0.1	DT: 0.000 (0.447)	BT: 0.009 (0.456)	Loss 2.5684 (2.4790)	Prec@1 37.891 (37.833)	
Total train loss: 2.4791
Avg Loading time: 0.4450 seconds
Avg Batch time: 0.4539 seconds

 * Prec@1 30.350 Prec@5 59.480 Loss 2.8887
Avg Loading time: 0.4254 seconds
Avg Batch time: 0.4317 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [6][38/196]	LR: 0.1	DT: 0.234 (0.366)	BT: 0.249 (0.375)	Loss 2.4961 (2.3603)	Prec@1 40.625 (40.745)	
Epoch: [6][77/196]	LR: 0.1	DT: 0.000 (0.431)	BT: 0.006 (0.439)	Loss 2.6191 (2.3884)	Prec@1 32.422 (39.814)	
Epoch: [6][116/196]	LR: 0.1	DT: 0.963 (0.432)	BT: 0.973 (0.441)	Loss 2.4355 (2.4229)	Prec@1 35.938 (38.959)	
Epoch: [6][155/196]	LR: 0.1	DT: 0.000 (0.428)	BT: 0.006 (0.437)	Loss 2.5312 (2.4354)	Prec@1 35.938 (38.549)	
Epoch: [6][194/196]	LR: 0.1	DT: 0.000 (0.431)	BT: 0.007 (0.440)	Loss 2.4219 (2.4519)	Prec@1 37.500 (38.151)	
Total train loss: 2.4516
Avg Loading time: 0.4286 seconds
Avg Batch time: 0.4373 seconds

 * Prec@1 30.530 Prec@5 59.230 Loss 2.8809
Avg Loading time: 0.6126 seconds
Avg Batch time: 0.6193 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [7][38/196]	LR: 0.1	DT: 0.000 (0.528)	BT: 0.005 (0.537)	Loss 2.5078 (2.3403)	Prec@1 37.500 (40.976)	
Epoch: [7][77/196]	LR: 0.1	DT: 0.000 (0.560)	BT: 0.006 (0.568)	Loss 2.3633 (2.3510)	Prec@1 42.969 (40.595)	
Epoch: [7][116/196]	LR: 0.1	DT: 0.000 (0.585)	BT: 0.006 (0.593)	Loss 2.4746 (2.3906)	Prec@1 36.719 (39.697)	
Epoch: [7][155/196]	LR: 0.1	DT: 0.000 (0.557)	BT: 0.010 (0.565)	Loss 2.5215 (2.4201)	Prec@1 37.109 (38.900)	
Epoch: [7][194/196]	LR: 0.1	DT: 0.096 (0.512)	BT: 0.102 (0.520)	Loss 2.5801 (2.4319)	Prec@1 33.594 (38.606)	
Total train loss: 2.4319
Avg Loading time: 0.5093 seconds
Avg Batch time: 0.5173 seconds

 * Prec@1 30.630 Prec@5 59.260 Loss 2.8926
Avg Loading time: 0.2860 seconds
Avg Batch time: 0.2932 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [8][38/196]	LR: 0.1	DT: 0.000 (0.296)	BT: 0.010 (0.304)	Loss 2.2891 (2.3391)	Prec@1 39.453 (40.545)	
Epoch: [8][77/196]	LR: 0.1	DT: 0.000 (0.275)	BT: 0.007 (0.284)	Loss 2.3555 (2.3693)	Prec@1 44.922 (39.623)	
Epoch: [8][116/196]	LR: 0.1	DT: 0.000 (0.327)	BT: 0.006 (0.336)	Loss 2.5273 (2.3853)	Prec@1 34.766 (39.286)	
Epoch: [8][155/196]	LR: 0.1	DT: 0.197 (0.363)	BT: 0.204 (0.372)	Loss 2.5000 (2.3975)	Prec@1 37.500 (39.015)	
Epoch: [8][194/196]	LR: 0.1	DT: 0.433 (0.359)	BT: 0.445 (0.368)	Loss 2.6094 (2.4169)	Prec@1 36.719 (38.546)	
Total train loss: 2.4172
Avg Loading time: 0.3575 seconds
Avg Batch time: 0.3664 seconds

 * Prec@1 30.610 Prec@5 59.060 Loss 2.8965
Avg Loading time: 0.4506 seconds
Avg Batch time: 0.4576 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [9][38/196]	LR: 0.1	DT: 0.000 (0.353)	BT: 0.008 (0.363)	Loss 2.2832 (2.2914)	Prec@1 43.359 (41.316)	
Epoch: [9][77/196]	LR: 0.1	DT: 0.000 (0.378)	BT: 0.006 (0.387)	Loss 2.2832 (2.3272)	Prec@1 42.188 (40.895)	
Epoch: [9][116/196]	LR: 0.1	DT: 0.460 (0.411)	BT: 0.471 (0.419)	Loss 2.2754 (2.3614)	Prec@1 42.578 (40.131)	
Epoch: [9][155/196]	LR: 0.1	DT: 0.000 (0.419)	BT: 0.006 (0.427)	Loss 2.4082 (2.3864)	Prec@1 36.719 (39.546)	
Epoch: [9][194/196]	LR: 0.1	DT: 0.111 (0.416)	BT: 0.117 (0.425)	Loss 2.5352 (2.4051)	Prec@1 35.156 (39.103)	
Total train loss: 2.4055
Avg Loading time: 0.4142 seconds
Avg Batch time: 0.4227 seconds

 * Prec@1 30.190 Prec@5 59.160 Loss 2.9062
Avg Loading time: 0.4626 seconds
Avg Batch time: 0.4698 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [10][38/196]	LR: 0.05	DT: 0.000 (0.465)	BT: 0.006 (0.473)	Loss 2.4492 (2.2877)	Prec@1 38.672 (42.278)	
Epoch: [10][77/196]	LR: 0.05	DT: 0.000 (0.475)	BT: 0.006 (0.483)	Loss 2.5195 (2.2925)	Prec@1 37.500 (41.907)	
Epoch: [10][116/196]	LR: 0.05	DT: 0.017 (0.497)	BT: 0.022 (0.505)	Loss 2.2344 (2.2846)	Prec@1 38.281 (41.947)	
Epoch: [10][155/196]	LR: 0.05	DT: 0.000 (0.507)	BT: 0.006 (0.515)	Loss 2.2480 (2.2964)	Prec@1 40.234 (41.724)	
Epoch: [10][194/196]	LR: 0.05	DT: 0.000 (0.493)	BT: 0.009 (0.501)	Loss 2.5137 (2.3098)	Prec@1 37.500 (41.276)	
Total train loss: 2.3109
Avg Loading time: 0.4902 seconds
Avg Batch time: 0.4989 seconds

 * Prec@1 30.670 Prec@5 59.310 Loss 2.9004
Avg Loading time: 0.5346 seconds
Avg Batch time: 0.5408 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [11][38/196]	LR: 0.05	DT: 0.000 (0.527)	BT: 0.006 (0.536)	Loss 2.1445 (2.2176)	Prec@1 42.188 (43.309)	
Epoch: [11][77/196]	LR: 0.05	DT: 0.000 (0.567)	BT: 0.006 (0.576)	Loss 2.2461 (2.2626)	Prec@1 43.359 (42.348)	
Epoch: [11][116/196]	LR: 0.05	DT: 0.000 (0.548)	BT: 0.009 (0.557)	Loss 2.2637 (2.2781)	Prec@1 46.484 (42.074)	
Epoch: [11][155/196]	LR: 0.05	DT: 0.031 (0.555)	BT: 0.037 (0.564)	Loss 2.3809 (2.2942)	Prec@1 41.406 (41.632)	
Epoch: [11][194/196]	LR: 0.05	DT: 0.926 (0.602)	BT: 0.938 (0.611)	Loss 2.2031 (2.3000)	Prec@1 44.922 (41.470)	
Total train loss: 2.3000
Avg Loading time: 0.5990 seconds
Avg Batch time: 0.6080 seconds

 * Prec@1 30.390 Prec@5 59.500 Loss 2.9180
Avg Loading time: 0.6150 seconds
Avg Batch time: 0.6219 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [12][38/196]	LR: 0.05	DT: 0.000 (0.651)	BT: 0.006 (0.658)	Loss 2.3652 (2.2274)	Prec@1 37.500 (42.959)	
Epoch: [12][77/196]	LR: 0.05	DT: 0.000 (0.685)	BT: 0.005 (0.692)	Loss 2.2363 (2.2551)	Prec@1 42.969 (42.072)	
Epoch: [12][116/196]	LR: 0.05	DT: 0.000 (0.877)	BT: 0.009 (0.884)	Loss 2.3672 (2.2703)	Prec@1 39.453 (41.857)	
Epoch: [12][155/196]	LR: 0.05	DT: 0.000 (1.005)	BT: 0.007 (1.013)	Loss 2.4395 (2.2848)	Prec@1 34.375 (41.607)	
Epoch: [12][194/196]	LR: 0.05	DT: 0.000 (0.974)	BT: 0.009 (0.981)	Loss 2.3613 (2.2936)	Prec@1 40.234 (41.308)	
Total train loss: 2.2937
Avg Loading time: 0.9686 seconds
Avg Batch time: 0.9764 seconds

 * Prec@1 30.710 Prec@5 59.200 Loss 2.9199
Avg Loading time: 0.6518 seconds
Avg Batch time: 0.6587 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [13][38/196]	LR: 0.05	DT: 0.000 (0.663)	BT: 0.007 (0.672)	Loss 2.2207 (2.2171)	Prec@1 43.359 (42.768)	
Epoch: [13][77/196]	LR: 0.05	DT: 0.938 (0.665)	BT: 0.950 (0.674)	Loss 2.2305 (2.2412)	Prec@1 44.922 (42.162)	
Epoch: [13][116/196]	LR: 0.05	DT: 0.203 (0.681)	BT: 0.211 (0.690)	Loss 2.4355 (2.2628)	Prec@1 39.062 (41.954)	
Epoch: [13][155/196]	LR: 0.05	DT: 1.285 (0.699)	BT: 1.297 (0.708)	Loss 2.2988 (2.2771)	Prec@1 43.750 (41.814)	
Epoch: [13][194/196]	LR: 0.05	DT: 0.000 (0.672)	BT: 0.007 (0.682)	Loss 2.3887 (2.2919)	Prec@1 37.500 (41.480)	
Total train loss: 2.2920
Avg Loading time: 0.6690 seconds
Avg Batch time: 0.6785 seconds

 * Prec@1 30.720 Prec@5 59.190 Loss 2.9238
Avg Loading time: 0.6969 seconds
Avg Batch time: 0.7041 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [14][38/196]	LR: 0.05	DT: 0.000 (0.805)	BT: 0.005 (0.813)	Loss 2.2402 (2.2014)	Prec@1 44.922 (44.221)	
Epoch: [14][77/196]	LR: 0.05	DT: 0.000 (0.816)	BT: 0.005 (0.824)	Loss 2.4902 (2.2392)	Prec@1 38.281 (43.284)	
Epoch: [14][116/196]	LR: 0.05	DT: 0.000 (0.804)	BT: 0.006 (0.811)	Loss 2.1973 (2.2508)	Prec@1 44.531 (42.815)	
Epoch: [14][155/196]	LR: 0.05	DT: 0.000 (0.840)	BT: 0.007 (0.848)	Loss 2.4785 (2.2724)	Prec@1 37.891 (42.213)	
Epoch: [14][194/196]	LR: 0.05	DT: 0.000 (0.815)	BT: 0.008 (0.822)	Loss 2.3223 (2.2891)	Prec@1 40.625 (41.707)	
Total train loss: 2.2893
Avg Loading time: 0.8108 seconds
Avg Batch time: 0.8183 seconds

 * Prec@1 30.490 Prec@5 58.990 Loss 2.9277
Avg Loading time: 1.0716 seconds
Avg Batch time: 1.0783 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [15][38/196]	LR: 0.05	DT: 0.223 (0.950)	BT: 0.234 (0.959)	Loss 2.0977 (2.2171)	Prec@1 41.406 (43.580)	
Epoch: [15][77/196]	LR: 0.05	DT: 0.000 (0.851)	BT: 0.006 (0.860)	Loss 2.2656 (2.2333)	Prec@1 44.531 (43.219)	
Epoch: [15][116/196]	LR: 0.05	DT: 0.190 (0.876)	BT: 0.197 (0.885)	Loss 2.3281 (2.2513)	Prec@1 41.406 (42.585)	
Epoch: [15][155/196]	LR: 0.05	DT: 0.000 (0.882)	BT: 0.009 (0.891)	Loss 2.2324 (2.2715)	Prec@1 39.453 (41.917)	
Epoch: [15][194/196]	LR: 0.05	DT: 0.217 (0.852)	BT: 0.226 (0.861)	Loss 2.3652 (2.2850)	Prec@1 40.625 (41.552)	
Total train loss: 2.2861
Avg Loading time: 0.8473 seconds
Avg Batch time: 0.8564 seconds

 * Prec@1 30.340 Prec@5 59.180 Loss 2.9375
Avg Loading time: 0.7529 seconds
Avg Batch time: 0.7595 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [16][38/196]	LR: 0.05	DT: 0.000 (0.748)	BT: 0.007 (0.758)	Loss 2.1895 (2.2559)	Prec@1 43.359 (41.607)	
Epoch: [16][77/196]	LR: 0.05	DT: 0.000 (0.758)	BT: 0.006 (0.768)	Loss 2.2305 (2.2444)	Prec@1 42.969 (42.157)	
Epoch: [16][116/196]	LR: 0.05	DT: 0.000 (0.772)	BT: 0.007 (0.781)	Loss 2.0918 (2.2537)	Prec@1 45.312 (42.107)	
Epoch: [16][155/196]	LR: 0.05	DT: 0.000 (0.804)	BT: 0.011 (0.813)	Loss 2.4785 (2.2732)	Prec@1 37.500 (41.614)	
Epoch: [16][194/196]	LR: 0.05	DT: 2.511 (0.817)	BT: 2.520 (0.825)	Loss 2.0938 (2.2868)	Prec@1 44.141 (41.404)	
Total train loss: 2.2869
Avg Loading time: 0.8125 seconds
Avg Batch time: 0.8211 seconds

 * Prec@1 29.920 Prec@5 59.340 Loss 2.9434
Avg Loading time: 0.9370 seconds
Avg Batch time: 0.9432 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [17][38/196]	LR: 0.05	DT: 0.000 (1.000)	BT: 0.005 (1.010)	Loss 2.2930 (2.2020)	Prec@1 43.359 (43.690)	
Epoch: [17][77/196]	LR: 0.05	DT: 0.000 (0.936)	BT: 0.007 (0.945)	Loss 2.2871 (2.2316)	Prec@1 41.406 (42.974)	
Epoch: [17][116/196]	LR: 0.05	DT: 0.000 (0.908)	BT: 0.009 (0.916)	Loss 2.3438 (2.2496)	Prec@1 41.406 (42.331)	
Epoch: [17][155/196]	LR: 0.05	DT: 3.013 (0.896)	BT: 3.033 (0.905)	Loss 2.1309 (2.2728)	Prec@1 46.875 (41.797)	
Epoch: [17][194/196]	LR: 0.05	DT: 0.014 (0.857)	BT: 0.025 (0.865)	Loss 2.2695 (2.2855)	Prec@1 42.578 (41.472)	
Total train loss: 2.2857
Avg Loading time: 0.8522 seconds
Avg Batch time: 0.8606 seconds

 * Prec@1 30.390 Prec@5 59.150 Loss 2.9414
Avg Loading time: 0.9059 seconds
Avg Batch time: 0.9129 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [18][38/196]	LR: 0.05	DT: 0.000 (0.822)	BT: 0.005 (0.830)	Loss 2.2812 (2.2184)	Prec@1 40.625 (42.829)	
Epoch: [18][77/196]	LR: 0.05	DT: 0.000 (0.805)	BT: 0.007 (0.812)	Loss 2.2695 (2.2351)	Prec@1 39.844 (42.668)	
Epoch: [18][116/196]	LR: 0.05	DT: 0.000 (0.838)	BT: 0.008 (0.846)	Loss 2.2832 (2.2598)	Prec@1 40.234 (42.157)	
Epoch: [18][155/196]	LR: 0.05	DT: 0.319 (0.835)	BT: 0.335 (0.844)	Loss 2.2207 (2.2742)	Prec@1 44.141 (41.769)	
Epoch: [18][194/196]	LR: 0.05	DT: 1.155 (0.800)	BT: 1.169 (0.809)	Loss 2.2383 (2.2845)	Prec@1 42.578 (41.637)	
Total train loss: 2.2846
Avg Loading time: 0.7964 seconds
Avg Batch time: 0.8052 seconds

 * Prec@1 30.420 Prec@5 58.890 Loss 2.9473
Avg Loading time: 0.9050 seconds
Avg Batch time: 0.9121 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [19][38/196]	LR: 0.05	DT: 0.000 (1.035)	BT: 0.005 (1.044)	Loss 2.3066 (2.2334)	Prec@1 42.578 (42.668)	
Epoch: [19][77/196]	LR: 0.05	DT: 0.000 (0.978)	BT: 0.007 (0.987)	Loss 2.2773 (2.2339)	Prec@1 44.922 (42.803)	
Epoch: [19][116/196]	LR: 0.05	DT: 0.000 (0.964)	BT: 0.006 (0.973)	Loss 2.4121 (2.2551)	Prec@1 38.281 (42.167)	
Epoch: [19][155/196]	LR: 0.05	DT: 0.000 (0.959)	BT: 0.008 (0.968)	Loss 2.4043 (2.2687)	Prec@1 40.625 (41.829)	
Epoch: [19][194/196]	LR: 0.05	DT: 1.578 (0.916)	BT: 1.590 (0.925)	Loss 2.3320 (2.2865)	Prec@1 40.234 (41.420)	
Total train loss: 2.2862
Avg Loading time: 0.9113 seconds
Avg Batch time: 0.9202 seconds

 * Prec@1 30.440 Prec@5 58.900 Loss 2.9453
Avg Loading time: 0.9783 seconds
Avg Batch time: 0.9846 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [20][38/196]	LR: 0.025	DT: 0.000 (1.015)	BT: 0.009 (1.024)	Loss 2.1543 (2.2011)	Prec@1 44.531 (43.970)	
Epoch: [20][77/196]	LR: 0.025	DT: 0.000 (0.962)	BT: 0.007 (0.971)	Loss 2.3301 (2.2068)	Prec@1 42.188 (43.765)	
Epoch: [20][116/196]	LR: 0.025	DT: 0.000 (0.941)	BT: 0.007 (0.950)	Loss 2.2793 (2.2139)	Prec@1 41.797 (43.413)	
Epoch: [20][155/196]	LR: 0.025	DT: 0.000 (0.920)	BT: 0.009 (0.929)	Loss 2.1875 (2.2164)	Prec@1 44.922 (43.257)	
Epoch: [20][194/196]	LR: 0.025	DT: 0.101 (0.879)	BT: 0.107 (0.888)	Loss 2.5703 (2.2299)	Prec@1 33.984 (42.977)	
Total train loss: 2.2307
Avg Loading time: 0.8744 seconds
Avg Batch time: 0.8834 seconds

 * Prec@1 30.380 Prec@5 58.970 Loss 2.9453
Avg Loading time: 0.8722 seconds
Avg Batch time: 0.8789 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [21][38/196]	LR: 0.025	DT: 0.000 (0.904)	BT: 0.006 (0.912)	Loss 1.9736 (2.1921)	Prec@1 47.656 (44.341)	
Epoch: [21][77/196]	LR: 0.025	DT: 0.000 (0.952)	BT: 0.018 (0.961)	Loss 2.1465 (2.1937)	Prec@1 45.703 (43.980)	
Epoch: [21][116/196]	LR: 0.025	DT: 0.000 (0.978)	BT: 0.007 (0.987)	Loss 2.3086 (2.2057)	Prec@1 42.578 (43.576)	
Epoch: [21][155/196]	LR: 0.025	DT: 0.000 (1.014)	BT: 0.007 (1.023)	Loss 2.1621 (2.2140)	Prec@1 46.094 (43.374)	
Epoch: [21][194/196]	LR: 0.025	DT: 0.000 (1.029)	BT: 0.007 (1.037)	Loss 2.3477 (2.2262)	Prec@1 39.844 (42.947)	
Total train loss: 2.2264
Avg Loading time: 1.0234 seconds
Avg Batch time: 1.0319 seconds

 * Prec@1 30.160 Prec@5 59.030 Loss 2.9492
Avg Loading time: 1.5240 seconds
Avg Batch time: 1.5308 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [22][38/196]	LR: 0.025	DT: 0.000 (0.974)	BT: 0.006 (0.982)	Loss 2.3008 (2.1870)	Prec@1 40.625 (43.620)	
Epoch: [22][77/196]	LR: 0.025	DT: 0.000 (0.994)	BT: 0.006 (1.002)	Loss 2.1699 (2.1981)	Prec@1 43.750 (43.505)	
Epoch: [22][116/196]	LR: 0.025	DT: 0.000 (0.942)	BT: 0.006 (0.950)	Loss 2.0996 (2.2109)	Prec@1 46.094 (43.196)	
Epoch: [22][155/196]	LR: 0.025	DT: 0.000 (0.820)	BT: 0.008 (0.828)	Loss 2.2793 (2.2234)	Prec@1 40.234 (43.034)	
Epoch: [22][194/196]	LR: 0.025	DT: 0.000 (0.723)	BT: 0.008 (0.731)	Loss 2.2812 (2.2274)	Prec@1 35.156 (42.905)	
Total train loss: 2.2279
Avg Loading time: 0.7195 seconds
Avg Batch time: 0.7270 seconds

 * Prec@1 30.090 Prec@5 59.160 Loss 2.9629
Avg Loading time: 0.4030 seconds
Avg Batch time: 0.4096 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [23][38/196]	LR: 0.025	DT: 0.000 (0.394)	BT: 0.006 (0.403)	Loss 2.1191 (2.1859)	Prec@1 46.094 (44.291)	
Epoch: [23][77/196]	LR: 0.025	DT: 0.000 (0.331)	BT: 0.007 (0.340)	Loss 2.1543 (2.1876)	Prec@1 43.359 (44.055)	
Epoch: [23][116/196]	LR: 0.025	DT: 0.000 (0.363)	BT: 0.008 (0.373)	Loss 2.2793 (2.2141)	Prec@1 39.844 (43.206)	
Epoch: [23][155/196]	LR: 0.025	DT: 0.000 (0.409)	BT: 0.011 (0.418)	Loss 2.1797 (2.2181)	Prec@1 42.578 (42.979)	
Epoch: [23][194/196]	LR: 0.025	DT: 1.714 (0.418)	BT: 1.726 (0.427)	Loss 2.2598 (2.2247)	Prec@1 41.797 (42.917)	
Total train loss: 2.2241
Avg Loading time: 0.4162 seconds
Avg Batch time: 0.4253 seconds

 * Prec@1 30.400 Prec@5 59.000 Loss 2.9629
Avg Loading time: 0.4753 seconds
Avg Batch time: 0.4826 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [24][38/196]	LR: 0.025	DT: 0.000 (0.617)	BT: 0.006 (0.625)	Loss 2.0859 (2.1915)	Prec@1 46.875 (44.411)	
Epoch: [24][77/196]	LR: 0.025	DT: 0.000 (0.555)	BT: 0.006 (0.563)	Loss 2.0645 (2.1975)	Prec@1 50.000 (43.935)	
Epoch: [24][116/196]	LR: 0.025	DT: 0.000 (0.528)	BT: 0.006 (0.535)	Loss 2.2344 (2.2075)	Prec@1 41.016 (43.443)	
Epoch: [24][155/196]	LR: 0.025	DT: 0.000 (0.516)	BT: 0.006 (0.524)	Loss 2.2637 (2.2153)	Prec@1 41.016 (43.199)	
Epoch: [24][194/196]	LR: 0.025	DT: 0.000 (0.493)	BT: 0.006 (0.501)	Loss 2.4238 (2.2254)	Prec@1 39.844 (42.903)	
Total train loss: 2.2253
Avg Loading time: 0.4908 seconds
Avg Batch time: 0.4984 seconds

 * Prec@1 30.240 Prec@5 59.420 Loss 2.9531
Avg Loading time: 0.4460 seconds
Avg Batch time: 0.4525 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [25][38/196]	LR: 0.025	DT: 0.000 (0.405)	BT: 0.007 (0.415)	Loss 2.2793 (2.1657)	Prec@1 41.406 (44.391)	
Epoch: [25][77/196]	LR: 0.025	DT: 0.000 (0.394)	BT: 0.006 (0.404)	Loss 2.1641 (2.1968)	Prec@1 43.359 (43.810)	
Epoch: [25][116/196]	LR: 0.025	DT: 0.000 (0.390)	BT: 0.006 (0.399)	Loss 2.2363 (2.2050)	Prec@1 39.453 (43.526)	
Epoch: [25][155/196]	LR: 0.025	DT: 0.000 (0.395)	BT: 0.007 (0.404)	Loss 2.2051 (2.2120)	Prec@1 45.703 (43.327)	
Epoch: [25][194/196]	LR: 0.025	DT: 0.090 (0.410)	BT: 0.101 (0.419)	Loss 2.2402 (2.2233)	Prec@1 41.406 (43.013)	
Total train loss: 2.2234
Avg Loading time: 0.4076 seconds
Avg Batch time: 0.4166 seconds

 * Prec@1 30.250 Prec@5 59.440 Loss 2.9629
Avg Loading time: 0.5236 seconds
Avg Batch time: 0.5296 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [26][38/196]	LR: 0.025	DT: 0.000 (0.491)	BT: 0.006 (0.499)	Loss 2.0117 (2.1660)	Prec@1 44.531 (44.441)	
Epoch: [26][77/196]	LR: 0.025	DT: 0.000 (0.472)	BT: 0.006 (0.480)	Loss 2.4277 (2.1947)	Prec@1 37.891 (43.785)	
Epoch: [26][116/196]	LR: 0.025	DT: 0.000 (0.477)	BT: 0.008 (0.485)	Loss 2.2070 (2.2026)	Prec@1 42.969 (43.396)	
Epoch: [26][155/196]	LR: 0.025	DT: 0.000 (0.440)	BT: 0.006 (0.449)	Loss 2.1016 (2.2099)	Prec@1 43.750 (43.182)	
Epoch: [26][194/196]	LR: 0.025	DT: 0.249 (0.416)	BT: 0.256 (0.425)	Loss 2.3242 (2.2209)	Prec@1 42.578 (42.905)	
Total train loss: 2.2210
Avg Loading time: 0.4139 seconds
Avg Batch time: 0.4226 seconds

 * Prec@1 30.230 Prec@5 59.040 Loss 2.9727
Avg Loading time: 0.3118 seconds
Avg Batch time: 0.3188 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [27][38/196]	LR: 0.025	DT: 0.000 (0.252)	BT: 0.007 (0.261)	Loss 2.3828 (2.1848)	Prec@1 42.578 (44.020)	
Epoch: [27][77/196]	LR: 0.025	DT: 0.000 (0.237)	BT: 0.006 (0.246)	Loss 2.2832 (2.1944)	Prec@1 42.578 (43.845)	
Epoch: [27][116/196]	LR: 0.025	DT: 0.293 (0.244)	BT: 0.304 (0.253)	Loss 2.2383 (2.2156)	Prec@1 42.188 (43.139)	
Epoch: [27][155/196]	LR: 0.025	DT: 0.000 (0.292)	BT: 0.007 (0.301)	Loss 2.1914 (2.2163)	Prec@1 41.406 (43.119)	
Epoch: [27][194/196]	LR: 0.025	DT: 0.000 (0.323)	BT: 0.007 (0.332)	Loss 2.1465 (2.2256)	Prec@1 45.703 (42.788)	
Total train loss: 2.2254
Avg Loading time: 0.3214 seconds
Avg Batch time: 0.3301 seconds

 * Prec@1 30.470 Prec@5 59.130 Loss 2.9688
Avg Loading time: 0.4415 seconds
Avg Batch time: 0.4481 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [28][38/196]	LR: 0.025	DT: 0.237 (0.381)	BT: 0.247 (0.391)	Loss 2.4141 (2.2049)	Prec@1 40.625 (43.720)	
Epoch: [28][77/196]	LR: 0.025	DT: 0.294 (0.377)	BT: 0.307 (0.386)	Loss 2.2617 (2.1905)	Prec@1 42.969 (43.550)	
Epoch: [28][116/196]	LR: 0.025	DT: 0.000 (0.400)	BT: 0.005 (0.409)	Loss 2.1387 (2.1969)	Prec@1 45.312 (43.463)	
Epoch: [28][155/196]	LR: 0.025	DT: 0.000 (0.403)	BT: 0.008 (0.412)	Loss 2.2480 (2.2107)	Prec@1 45.703 (43.302)	
Epoch: [28][194/196]	LR: 0.025	DT: 0.000 (0.418)	BT: 0.006 (0.427)	Loss 2.2402 (2.2232)	Prec@1 43.359 (43.017)	
Total train loss: 2.2226
Avg Loading time: 0.4155 seconds
Avg Batch time: 0.4245 seconds

 * Prec@1 30.400 Prec@5 59.250 Loss 2.9707
Avg Loading time: 0.4990 seconds
Avg Batch time: 0.5052 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [29][38/196]	LR: 0.025	DT: 0.000 (0.437)	BT: 0.006 (0.445)	Loss 2.1641 (2.1808)	Prec@1 43.359 (44.241)	
Epoch: [29][77/196]	LR: 0.025	DT: 0.000 (0.421)	BT: 0.006 (0.429)	Loss 1.9521 (2.1857)	Prec@1 48.828 (43.690)	
Epoch: [29][116/196]	LR: 0.025	DT: 0.000 (0.457)	BT: 0.008 (0.465)	Loss 2.2129 (2.1995)	Prec@1 45.312 (43.466)	
Epoch: [29][155/196]	LR: 0.025	DT: 0.000 (0.464)	BT: 0.009 (0.472)	Loss 2.0977 (2.2163)	Prec@1 43.359 (43.099)	
Epoch: [29][194/196]	LR: 0.025	DT: 0.105 (0.483)	BT: 0.114 (0.492)	Loss 2.5332 (2.2230)	Prec@1 37.500 (42.959)	
Total train loss: 2.2237
Avg Loading time: 0.4810 seconds
Avg Batch time: 0.4896 seconds

 * Prec@1 30.270 Prec@5 59.220 Loss 2.9746
Avg Loading time: 0.6757 seconds
Avg Batch time: 0.6821 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [30][38/196]	LR: 0.0125	DT: 0.000 (0.537)	BT: 0.008 (0.545)	Loss 2.1484 (2.1897)	Prec@1 45.703 (43.810)	
Epoch: [30][77/196]	LR: 0.0125	DT: 0.000 (0.509)	BT: 0.006 (0.518)	Loss 2.1191 (2.1799)	Prec@1 47.656 (44.206)	
Epoch: [30][116/196]	LR: 0.0125	DT: 0.000 (0.513)	BT: 0.006 (0.521)	Loss 2.2969 (2.1863)	Prec@1 41.406 (44.134)	
Epoch: [30][155/196]	LR: 0.0125	DT: 0.000 (0.509)	BT: 0.006 (0.517)	Loss 2.1406 (2.1863)	Prec@1 42.969 (43.985)	
Epoch: [30][194/196]	LR: 0.0125	DT: 0.000 (0.513)	BT: 0.006 (0.520)	Loss 2.2148 (2.1906)	Prec@1 46.875 (43.822)	
Total train loss: 2.1909
Avg Loading time: 0.5100 seconds
Avg Batch time: 0.5177 seconds

 * Prec@1 30.380 Prec@5 59.120 Loss 2.9746
Avg Loading time: 0.5972 seconds
Avg Batch time: 0.6033 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [31][38/196]	LR: 0.0125	DT: 0.000 (0.612)	BT: 0.005 (0.620)	Loss 2.1953 (2.1398)	Prec@1 43.359 (45.553)	
Epoch: [31][77/196]	LR: 0.0125	DT: 0.000 (0.598)	BT: 0.005 (0.606)	Loss 2.1973 (2.1628)	Prec@1 42.188 (44.757)	
Epoch: [31][116/196]	LR: 0.0125	DT: 0.000 (0.605)	BT: 0.007 (0.612)	Loss 1.9717 (2.1744)	Prec@1 50.000 (44.364)	
Epoch: [31][155/196]	LR: 0.0125	DT: 0.000 (0.608)	BT: 0.008 (0.615)	Loss 2.1191 (2.1814)	Prec@1 44.922 (44.048)	
Epoch: [31][194/196]	LR: 0.0125	DT: 0.000 (0.624)	BT: 0.006 (0.631)	Loss 2.2031 (2.1899)	Prec@1 42.188 (43.824)	
Total train loss: 2.1896
Avg Loading time: 0.6203 seconds
Avg Batch time: 0.6276 seconds

 * Prec@1 30.460 Prec@5 58.840 Loss 2.9785
Avg Loading time: 0.8511 seconds
Avg Batch time: 0.8571 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [32][38/196]	LR: 0.0125	DT: 0.001 (0.761)	BT: 0.006 (0.769)	Loss 2.1348 (2.1715)	Prec@1 45.703 (44.191)	
Epoch: [32][77/196]	LR: 0.0125	DT: 0.000 (0.793)	BT: 0.005 (0.801)	Loss 2.3008 (2.1704)	Prec@1 41.016 (44.035)	
Epoch: [32][116/196]	LR: 0.0125	DT: 0.000 (0.933)	BT: 0.006 (0.941)	Loss 2.1797 (2.1708)	Prec@1 46.484 (44.071)	
Epoch: [32][155/196]	LR: 0.0125	DT: 0.457 (1.267)	BT: 0.470 (1.276)	Loss 2.1289 (2.1775)	Prec@1 42.969 (43.890)	
Epoch: [32][194/196]	LR: 0.0125	DT: 0.000 (1.243)	BT: 0.013 (1.252)	Loss 2.2285 (2.1876)	Prec@1 45.703 (43.774)	
Total train loss: 2.1883
Avg Loading time: 1.2368 seconds
Avg Batch time: 1.2454 seconds

 * Prec@1 30.340 Prec@5 59.320 Loss 2.9824
Avg Loading time: 1.1626 seconds
Avg Batch time: 1.1688 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [33][38/196]	LR: 0.0125	DT: 0.000 (1.405)	BT: 0.009 (1.414)	Loss 2.2598 (2.1974)	Prec@1 44.531 (43.319)	
Epoch: [33][77/196]	LR: 0.0125	DT: 0.000 (1.249)	BT: 0.007 (1.257)	Loss 2.1309 (2.1941)	Prec@1 46.484 (43.730)	
Epoch: [33][116/196]	LR: 0.0125	DT: 0.000 (1.180)	BT: 0.005 (1.188)	Loss 2.2246 (2.1844)	Prec@1 41.797 (44.064)	
Epoch: [33][155/196]	LR: 0.0125	DT: 0.000 (1.095)	BT: 0.006 (1.103)	Loss 2.2305 (2.1865)	Prec@1 46.875 (43.980)	
Epoch: [33][194/196]	LR: 0.0125	DT: 0.000 (1.045)	BT: 0.009 (1.053)	Loss 2.1523 (2.1864)	Prec@1 43.750 (43.904)	
Total train loss: 2.1875
Avg Loading time: 1.0394 seconds
Avg Batch time: 1.0479 seconds

 * Prec@1 30.350 Prec@5 58.960 Loss 2.9805
Avg Loading time: 0.8490 seconds
Avg Batch time: 0.8559 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [34][38/196]	LR: 0.0125	DT: 0.000 (1.102)	BT: 0.007 (1.110)	Loss 1.9229 (2.1520)	Prec@1 49.609 (45.062)	
Epoch: [34][77/196]	LR: 0.0125	DT: 0.000 (1.071)	BT: 0.006 (1.079)	Loss 2.3691 (2.1651)	Prec@1 40.625 (44.291)	
Epoch: [34][116/196]	LR: 0.0125	DT: 0.129 (1.062)	BT: 0.139 (1.070)	Loss 2.1055 (2.1713)	Prec@1 46.484 (44.438)	
Epoch: [34][155/196]	LR: 0.0125	DT: 0.000 (1.060)	BT: 0.008 (1.069)	Loss 2.1133 (2.1818)	Prec@1 44.141 (44.083)	
Epoch: [34][194/196]	LR: 0.0125	DT: 0.084 (1.054)	BT: 0.098 (1.062)	Loss 2.1348 (2.1873)	Prec@1 44.922 (43.868)	
Total train loss: 2.1877
Avg Loading time: 1.0482 seconds
Avg Batch time: 1.0567 seconds

 * Prec@1 30.350 Prec@5 59.160 Loss 2.9863
Avg Loading time: 1.3392 seconds
Avg Batch time: 1.3455 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [35][38/196]	LR: 0.0125	DT: 0.000 (1.371)	BT: 0.007 (1.380)	Loss 2.0371 (2.1493)	Prec@1 44.531 (45.232)	
Epoch: [35][77/196]	LR: 0.0125	DT: 0.000 (1.196)	BT: 0.008 (1.204)	Loss 2.1562 (2.1494)	Prec@1 41.797 (44.987)	
Epoch: [35][116/196]	LR: 0.0125	DT: 0.000 (1.124)	BT: 0.008 (1.133)	Loss 2.1074 (2.1658)	Prec@1 45.312 (44.525)	
Epoch: [35][155/196]	LR: 0.0125	DT: 1.557 (1.051)	BT: 1.567 (1.059)	Loss 2.0469 (2.1809)	Prec@1 47.656 (44.111)	
Epoch: [35][194/196]	LR: 0.0125	DT: 0.000 (0.994)	BT: 0.005 (1.002)	Loss 2.1484 (2.1882)	Prec@1 42.188 (43.786)	
Total train loss: 2.1885
Avg Loading time: 0.9886 seconds
Avg Batch time: 0.9966 seconds

 * Prec@1 30.300 Prec@5 59.020 Loss 2.9805
Avg Loading time: 0.7761 seconds
Avg Batch time: 0.7825 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [36][38/196]	LR: 0.0125	DT: 0.000 (0.873)	BT: 0.005 (0.880)	Loss 2.2500 (2.1577)	Prec@1 38.672 (44.461)	
Epoch: [36][77/196]	LR: 0.0125	DT: 0.000 (0.824)	BT: 0.013 (0.831)	Loss 2.0840 (2.1626)	Prec@1 48.047 (44.266)	
Epoch: [36][116/196]	LR: 0.0125	DT: 0.000 (0.791)	BT: 0.006 (0.799)	Loss 2.1602 (2.1654)	Prec@1 40.234 (44.214)	
Epoch: [36][155/196]	LR: 0.0125	DT: 0.000 (0.765)	BT: 0.006 (0.773)	Loss 2.2988 (2.1784)	Prec@1 40.234 (44.060)	
Epoch: [36][194/196]	LR: 0.0125	DT: 0.000 (0.741)	BT: 0.008 (0.749)	Loss 2.1816 (2.1874)	Prec@1 43.750 (43.782)	
Total train loss: 2.1879
Avg Loading time: 0.7368 seconds
Avg Batch time: 0.7449 seconds

 * Prec@1 30.500 Prec@5 59.010 Loss 2.9824
Avg Loading time: 0.8025 seconds
Avg Batch time: 0.8087 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [37][38/196]	LR: 0.0125	DT: 0.000 (0.945)	BT: 0.005 (0.954)	Loss 2.1523 (2.1500)	Prec@1 46.875 (44.561)	
Epoch: [37][77/196]	LR: 0.0125	DT: 0.000 (0.946)	BT: 0.005 (0.953)	Loss 2.0410 (2.1582)	Prec@1 51.172 (44.511)	
Epoch: [37][116/196]	LR: 0.0125	DT: 0.000 (0.989)	BT: 0.006 (0.996)	Loss 2.2812 (2.1710)	Prec@1 45.703 (44.308)	
Epoch: [37][155/196]	LR: 0.0125	DT: 0.000 (0.974)	BT: 0.008 (0.981)	Loss 2.1113 (2.1808)	Prec@1 45.703 (43.968)	
Epoch: [37][194/196]	LR: 0.0125	DT: 0.000 (0.908)	BT: 0.006 (0.916)	Loss 2.3652 (2.1885)	Prec@1 39.062 (43.744)	
Total train loss: 2.1889
Avg Loading time: 0.9036 seconds
Avg Batch time: 0.9109 seconds

 * Prec@1 30.060 Prec@5 58.700 Loss 2.9980
Avg Loading time: 0.7710 seconds
Avg Batch time: 0.7771 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [38][38/196]	LR: 0.0125	DT: 0.000 (0.830)	BT: 0.005 (0.838)	Loss 2.2734 (2.1668)	Prec@1 42.578 (44.972)	
Epoch: [38][77/196]	LR: 0.0125	DT: 0.001 (0.827)	BT: 0.007 (0.835)	Loss 2.3203 (2.1740)	Prec@1 38.281 (44.461)	
Epoch: [38][116/196]	LR: 0.0125	DT: 0.000 (0.884)	BT: 0.005 (0.891)	Loss 2.2715 (2.1780)	Prec@1 41.797 (44.221)	
Epoch: [38][155/196]	LR: 0.0125	DT: 0.000 (0.863)	BT: 0.006 (0.870)	Loss 2.1230 (2.1816)	Prec@1 45.312 (44.055)	
Epoch: [38][194/196]	LR: 0.0125	DT: 0.000 (0.822)	BT: 0.006 (0.830)	Loss 2.0293 (2.1864)	Prec@1 46.094 (43.986)	
Total train loss: 2.1870
Avg Loading time: 0.8181 seconds
Avg Batch time: 0.8254 seconds

 * Prec@1 30.310 Prec@5 59.150 Loss 2.9844
Avg Loading time: 0.8080 seconds
Avg Batch time: 0.8138 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
Epoch: [39][38/196]	LR: 0.0125	DT: 0.000 (0.767)	BT: 0.009 (0.774)	Loss 2.1309 (2.1594)	Prec@1 48.438 (44.832)	
Epoch: [39][77/196]	LR: 0.0125	DT: 0.411 (0.796)	BT: 0.421 (0.804)	Loss 2.1777 (2.1697)	Prec@1 42.578 (44.426)	
Epoch: [39][116/196]	LR: 0.0125	DT: 0.000 (0.840)	BT: 0.007 (0.848)	Loss 2.2500 (2.1775)	Prec@1 46.094 (44.221)	
Epoch: [39][155/196]	LR: 0.0125	DT: 0.000 (0.854)	BT: 0.007 (0.862)	Loss 2.1621 (2.1864)	Prec@1 41.797 (43.938)	
Epoch: [39][194/196]	LR: 0.0125	DT: 0.000 (0.863)	BT: 0.008 (0.871)	Loss 2.3516 (2.1901)	Prec@1 39.062 (43.808)	
Total train loss: 2.1905
Avg Loading time: 0.8587 seconds
Avg Batch time: 0.8669 seconds

 * Prec@1 30.000 Prec@5 59.020 Loss 2.9902
Avg Loading time: 0.6770 seconds
Avg Batch time: 0.6825 seconds

Best acc: 30.810
--------------------------------------------------------------------------------
