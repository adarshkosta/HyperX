
      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x128/
          savedir: ../pretrained_models/frozen/x128/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram_new
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 1
Savedir:  ../pretrained_models/frozen/x128/rram_new/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x128/rram/one_batch/cifar10/resnet18/train/relu1
Test path:  /home/nano01/a/esoufler/activations/x128/rram_new/one_batch/cifar10/resnet18/test/relu1
ResNet18(
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu2): ReLU(inplace=True)
  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu3): ReLU(inplace=True)
  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu4): ReLU(inplace=True)
  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu5): ReLU(inplace=True)
  (conv6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv1): Sequential(
    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu6): ReLU(inplace=True)
  (conv7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu7): ReLU(inplace=True)
  (conv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 12.100 Prec@5 56.090 Loss 2.2812
Avg Loading time: 4.4429 seconds
Avg Batch time: 4.5626 seconds

Pre-trained Prec@1 with 1 layers frozen: 12.09999942779541 	 Loss: 2.28125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.01	DT: 0.000 (4.445)	BT: 0.267 (4.744)	Loss 0.6104 (0.9082)	Prec@1 81.250 (75.280)	
Epoch: [0][155/391]	LR: 0.01	DT: 0.000 (4.620)	BT: 0.250 (4.908)	Loss 0.3740 (0.6825)	Prec@1 91.406 (81.866)	
Epoch: [0][233/391]	LR: 0.01	DT: 1.042 (4.735)	BT: 1.336 (5.019)	Loss 0.3154 (0.5741)	Prec@1 89.062 (84.816)	
Epoch: [0][311/391]	LR: 0.01	DT: 0.000 (4.680)	BT: 0.250 (4.962)	Loss 0.2578 (0.5067)	Prec@1 91.406 (86.493)	
Epoch: [0][389/391]	LR: 0.01	DT: 0.000 (4.696)	BT: 0.256 (4.977)	Loss 0.2732 (0.4613)	Prec@1 92.969 (87.528)	
Total train loss: 0.4609
Avg Loading time: 4.6844 seconds
Avg Batch time: 4.9650 seconds

Train time: 1941.5471014976501
 * Prec@1 92.190 Prec@5 99.810 Loss 0.2622
Avg Loading time: 3.9960 seconds
Avg Batch time: 4.1119 seconds

Best acc: 92.190
--------------------------------------------------------------------------------
Test time: 327.749995470047

Epoch: [1][77/391]	LR: 0.01	DT: 0.000 (4.639)	BT: 0.259 (4.933)	Loss 0.1403 (0.1759)	Prec@1 96.094 (95.533)	
Epoch: [1][155/391]	LR: 0.01	DT: 0.000 (4.597)	BT: 0.262 (4.879)	Loss 0.1884 (0.1758)	Prec@1 96.094 (95.503)	
Epoch: [1][233/391]	LR: 0.01	DT: 0.000 (4.535)	BT: 0.284 (4.813)	Loss 0.1781 (0.1732)	Prec@1 95.312 (95.496)	
Epoch: [1][311/391]	LR: 0.01	DT: 0.000 (4.428)	BT: 0.253 (4.703)	Loss 0.1048 (0.1725)	Prec@1 98.438 (95.425)	
Epoch: [1][389/391]	LR: 0.01	DT: 0.000 (4.516)	BT: 0.248 (4.790)	Loss 0.2184 (0.1714)	Prec@1 93.750 (95.381)	
Total train loss: 0.1714
Avg Loading time: 4.5043 seconds
Avg Batch time: 4.7784 seconds

Train time: 1868.4474411010742
 * Prec@1 93.580 Prec@5 99.840 Loss 0.2142
Avg Loading time: 4.1608 seconds
Avg Batch time: 4.2755 seconds

Best acc: 93.580
--------------------------------------------------------------------------------
Test time: 340.19732308387756

Epoch: [2][77/391]	LR: 0.01	DT: 1.321 (4.529)	BT: 1.601 (4.842)	Loss 0.1155 (0.0880)	Prec@1 96.875 (98.147)	
Epoch: [2][155/391]	LR: 0.01	DT: 0.000 (4.553)	BT: 0.272 (4.849)	Loss 0.0543 (0.0867)	Prec@1 100.000 (98.157)	
Epoch: [2][233/391]	LR: 0.01	DT: 5.122 (4.559)	BT: 5.432 (4.850)	Loss 0.0956 (0.0843)	Prec@1 98.438 (98.251)	
Epoch: [2][311/391]	LR: 0.01	DT: 0.000 (4.476)	BT: 0.245 (4.762)	Loss 0.0825 (0.0823)	Prec@1 97.656 (98.292)	
Epoch: [2][389/391]	LR: 0.01	DT: 0.000 (4.472)	BT: 0.257 (4.756)	Loss 0.0927 (0.0825)	Prec@1 98.438 (98.267)	
Total train loss: 0.0825
Avg Loading time: 4.4611 seconds
Avg Batch time: 4.7442 seconds

Train time: 1855.1812326908112
 * Prec@1 93.520 Prec@5 99.750 Loss 0.2253
Avg Loading time: 3.9983 seconds
Avg Batch time: 4.1152 seconds

Best acc: 93.580
--------------------------------------------------------------------------------
Test time: 327.08202266693115

Epoch: [3][77/391]	LR: 0.01	DT: 0.000 (5.245)	BT: 0.265 (5.554)	Loss 0.0491 (0.0493)	Prec@1 100.000 (99.409)	
Epoch: [3][155/391]	LR: 0.01	DT: 0.000 (5.186)	BT: 0.258 (5.480)	Loss 0.0305 (0.0484)	Prec@1 100.000 (99.429)	
Epoch: [3][233/391]	LR: 0.01	DT: 3.553 (5.073)	BT: 3.871 (5.360)	Loss 0.0276 (0.0467)	Prec@1 100.000 (99.476)	
Epoch: [3][311/391]	LR: 0.01	DT: 0.000 (4.947)	BT: 0.264 (5.232)	Loss 0.0421 (0.0458)	Prec@1 100.000 (99.517)	
Epoch: [3][389/391]	LR: 0.01	DT: 0.000 (4.925)	BT: 0.257 (5.207)	Loss 0.0300 (0.0453)	Prec@1 100.000 (99.527)	
Total train loss: 0.0453
Avg Loading time: 4.9123 seconds
Avg Batch time: 5.1940 seconds

Train time: 2031.0889854431152
 * Prec@1 94.210 Prec@5 99.810 Loss 0.1866
Avg Loading time: 3.8558 seconds
Avg Batch time: 3.9699 seconds

Best acc: 94.210
--------------------------------------------------------------------------------
Test time: 316.25185084342957

Epoch: [4][77/391]	LR: 0.01	DT: 0.000 (4.928)	BT: 0.249 (5.244)	Loss 0.0198 (0.0318)	Prec@1 100.000 (99.810)	
Epoch: [4][155/391]	LR: 0.01	DT: 0.000 (4.941)	BT: 0.270 (5.236)	Loss 0.0246 (0.0307)	Prec@1 100.000 (99.840)	
Epoch: [4][233/391]	LR: 0.01	DT: 2.213 (4.953)	BT: 2.514 (5.241)	Loss 0.0264 (0.0311)	Prec@1 100.000 (99.816)	
Epoch: [4][311/391]	LR: 0.01	DT: 0.000 (4.758)	BT: 0.252 (5.043)	Loss 0.0312 (0.0306)	Prec@1 100.000 (99.825)	
Epoch: [4][389/391]	LR: 0.01	DT: 0.000 (4.730)	BT: 0.256 (5.015)	Loss 0.0268 (0.0307)	Prec@1 100.000 (99.818)	
Total train loss: 0.0307
Avg Loading time: 4.7183 seconds
Avg Batch time: 5.0029 seconds

Train time: 1956.2241230010986
 * Prec@1 94.630 Prec@5 99.790 Loss 0.1770
Avg Loading time: 3.9359 seconds
Avg Batch time: 4.0513 seconds

Best acc: 94.630
--------------------------------------------------------------------------------
Test time: 322.4914927482605

Epoch: [5][77/391]	LR: 0.01	DT: 0.000 (4.385)	BT: 0.257 (4.675)	Loss 0.0186 (0.0228)	Prec@1 100.000 (99.950)	
Epoch: [5][155/391]	LR: 0.01	DT: 0.000 (4.357)	BT: 0.265 (4.641)	Loss 0.0159 (0.0229)	Prec@1 100.000 (99.950)	
Epoch: [5][233/391]	LR: 0.01	DT: 2.790 (4.351)	BT: 3.092 (4.634)	Loss 0.0301 (0.0232)	Prec@1 100.000 (99.953)	
Epoch: [5][311/391]	LR: 0.01	DT: 0.000 (4.246)	BT: 0.248 (4.528)	Loss 0.0294 (0.0238)	Prec@1 100.000 (99.942)	
Epoch: [5][389/391]	LR: 0.01	DT: 1.767 (4.319)	BT: 2.085 (4.600)	Loss 0.0194 (0.0238)	Prec@1 100.000 (99.938)	
Total train loss: 0.0238
Avg Loading time: 4.3079 seconds
Avg Batch time: 4.5887 seconds

Train time: 1794.2628214359283
 * Prec@1 94.750 Prec@5 99.740 Loss 0.1746
Avg Loading time: 3.8217 seconds
Avg Batch time: 3.9355 seconds

Best acc: 94.750
--------------------------------------------------------------------------------
Test time: 313.3541853427887

Epoch: [6][77/391]	LR: 0.01	DT: 0.000 (4.795)	BT: 0.266 (5.087)	Loss 0.0319 (0.0207)	Prec@1 99.219 (99.980)	
Epoch: [6][155/391]	LR: 0.01	DT: 0.000 (4.733)	BT: 0.278 (5.021)	Loss 0.0179 (0.0207)	Prec@1 100.000 (99.975)	
Epoch: [6][233/391]	LR: 0.01	DT: 0.000 (4.730)	BT: 0.255 (5.011)	Loss 0.0212 (0.0211)	Prec@1 100.000 (99.963)	
Epoch: [6][311/391]	LR: 0.01	DT: 0.000 (4.615)	BT: 0.261 (4.893)	Loss 0.0152 (0.0212)	Prec@1 100.000 (99.967)	
Epoch: [6][389/391]	LR: 0.01	DT: 0.000 (4.612)	BT: 0.266 (4.889)	Loss 0.0231 (0.0211)	Prec@1 100.000 (99.972)	
Total train loss: 0.0211
Avg Loading time: 4.6006 seconds
Avg Batch time: 4.8773 seconds

Train time: 1907.0846350193024
 * Prec@1 94.890 Prec@5 99.730 Loss 0.1716
Avg Loading time: 3.8514 seconds
Avg Batch time: 3.9681 seconds

Best acc: 94.890
--------------------------------------------------------------------------------
Test time: 315.9495186805725

Epoch: [7][77/391]	LR: 0.01	DT: 0.000 (6.447)	BT: 0.252 (6.744)	Loss 0.0196 (0.0197)	Prec@1 100.000 (99.980)	
Epoch: [7][155/391]	LR: 0.01	DT: 0.000 (6.426)	BT: 0.265 (6.716)	Loss 0.0166 (0.0193)	Prec@1 100.000 (99.975)	
Epoch: [7][233/391]	LR: 0.01	DT: 0.000 (6.403)	BT: 0.268 (6.689)	Loss 0.0154 (0.0193)	Prec@1 100.000 (99.983)	
Epoch: [7][311/391]	LR: 0.01	DT: 0.000 (5.958)	BT: 0.249 (6.242)	Loss 0.0182 (0.0193)	Prec@1 100.000 (99.985)	
Epoch: [7][389/391]	LR: 0.01	DT: 0.000 (5.704)	BT: 0.257 (5.987)	Loss 0.0225 (0.0190)	Prec@1 100.000 (99.986)	
Total train loss: 0.0191
Avg Loading time: 5.6895 seconds
Avg Batch time: 5.9718 seconds

Train time: 2335.1974704265594
 * Prec@1 94.880 Prec@5 99.770 Loss 0.1700
Avg Loading time: 3.8639 seconds
Avg Batch time: 3.9768 seconds

Best acc: 94.890
--------------------------------------------------------------------------------
Test time: 316.1849629878998

Epoch: [8][77/391]	LR: 0.01	DT: 0.000 (4.908)	BT: 0.257 (5.199)	Loss 0.0153 (0.0166)	Prec@1 100.000 (100.000)	
Epoch: [8][155/391]	LR: 0.01	DT: 0.000 (4.900)	BT: 0.272 (5.180)	Loss 0.0123 (0.0169)	Prec@1 100.000 (99.995)	
Epoch: [8][233/391]	LR: 0.01	DT: 0.000 (4.913)	BT: 0.293 (5.193)	Loss 0.0182 (0.0171)	Prec@1 100.000 (99.993)	
Epoch: [8][311/391]	LR: 0.01	DT: 0.000 (4.815)	BT: 0.263 (5.095)	Loss 0.0408 (0.0172)	Prec@1 99.219 (99.992)	
Epoch: [8][389/391]	LR: 0.01	DT: 0.000 (4.784)	BT: 0.254 (5.064)	Loss 0.0145 (0.0172)	Prec@1 100.000 (99.992)	
Total train loss: 0.0172
Avg Loading time: 4.7714 seconds
Avg Batch time: 5.0516 seconds

Train time: 1975.4040269851685
 * Prec@1 94.900 Prec@5 99.740 Loss 0.1716
Avg Loading time: 4.0523 seconds
Avg Batch time: 4.1707 seconds

Best acc: 94.900
--------------------------------------------------------------------------------
Test time: 331.7104024887085

Epoch: [9][77/391]	LR: 0.01	DT: 0.000 (4.924)	BT: 0.265 (5.231)	Loss 0.0142 (0.0162)	Prec@1 100.000 (100.000)	
Epoch: [9][155/391]	LR: 0.01	DT: 0.000 (4.808)	BT: 0.257 (5.101)	Loss 0.0140 (0.0167)	Prec@1 100.000 (99.995)	
Epoch: [9][233/391]	LR: 0.01	DT: 1.479 (4.723)	BT: 1.760 (5.011)	Loss 0.0163 (0.0167)	Prec@1 100.000 (99.997)	
Epoch: [9][311/391]	LR: 0.01	DT: 0.000 (4.520)	BT: 0.262 (4.805)	Loss 0.0174 (0.0166)	Prec@1 100.000 (99.997)	
Epoch: [9][389/391]	LR: 0.01	DT: 0.000 (4.465)	BT: 0.265 (4.748)	Loss 0.0129 (0.0165)	Prec@1 100.000 (99.998)	
Total train loss: 0.0165
Avg Loading time: 4.4538 seconds
Avg Batch time: 4.7366 seconds

Train time: 1852.2511687278748
 * Prec@1 94.850 Prec@5 99.740 Loss 0.1691
Avg Loading time: 4.3954 seconds
Avg Batch time: 4.5180 seconds

Best acc: 94.900
--------------------------------------------------------------------------------
Test time: 358.66340136528015

Epoch: [10][77/391]	LR: 0.002	DT: 0.000 (4.473)	BT: 0.259 (4.780)	Loss 0.0319 (0.0165)	Prec@1 100.000 (100.000)	
Epoch: [10][155/391]	LR: 0.002	DT: 0.000 (4.473)	BT: 0.269 (4.768)	Loss 0.0121 (0.0162)	Prec@1 100.000 (99.990)	
Epoch: [10][233/391]	LR: 0.002	DT: 8.115 (4.484)	BT: 8.392 (4.772)	Loss 0.0123 (0.0158)	Prec@1 100.000 (99.993)	
Epoch: [10][311/391]	LR: 0.002	DT: 0.000 (4.393)	BT: 0.255 (4.677)	Loss 0.0202 (0.0157)	Prec@1 100.000 (99.990)	
Epoch: [10][389/391]	LR: 0.002	DT: 0.000 (4.507)	BT: 0.265 (4.789)	Loss 0.0188 (0.0156)	Prec@1 100.000 (99.992)	
Total train loss: 0.0156
Avg Loading time: 4.4953 seconds
Avg Batch time: 4.7771 seconds

Train time: 1868.089370727539
 * Prec@1 94.930 Prec@5 99.750 Loss 0.1699
Avg Loading time: 4.0176 seconds
Avg Batch time: 4.1315 seconds

Best acc: 94.930
--------------------------------------------------------------------------------
Test time: 328.3272671699524

Epoch: [11][77/391]	LR: 0.002	DT: 0.000 (5.241)	BT: 0.253 (5.533)	Loss 0.0193 (0.0157)	Prec@1 100.000 (99.990)	
Epoch: [11][155/391]	LR: 0.002	DT: 0.000 (5.182)	BT: 0.279 (5.467)	Loss 0.0232 (0.0157)	Prec@1 100.000 (99.990)	
Epoch: [11][233/391]	LR: 0.002	DT: 2.948 (5.017)	BT: 3.244 (5.299)	Loss 0.0198 (0.0152)	Prec@1 100.000 (99.993)	
Epoch: [11][311/391]	LR: 0.002	DT: 0.000 (4.888)	BT: 0.261 (5.169)	Loss 0.0143 (0.0155)	Prec@1 100.000 (99.995)	
Epoch: [11][389/391]	LR: 0.002	DT: 0.000 (4.869)	BT: 0.249 (5.148)	Loss 0.0107 (0.0154)	Prec@1 100.000 (99.992)	
Total train loss: 0.0154
Avg Loading time: 4.8561 seconds
Avg Batch time: 5.1357 seconds

Train time: 2008.2123634815216
 * Prec@1 94.840 Prec@5 99.760 Loss 0.1703
Avg Loading time: 4.0424 seconds
Avg Batch time: 4.1782 seconds

Best acc: 94.930
--------------------------------------------------------------------------------
Test time: 332.05099868774414

Epoch: [12][77/391]	LR: 0.002	DT: 0.000 (5.138)	BT: 0.267 (5.452)	Loss 0.0158 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [12][155/391]	LR: 0.002	DT: 0.000 (5.265)	BT: 0.255 (5.565)	Loss 0.0119 (0.0155)	Prec@1 100.000 (100.000)	
Epoch: [12][233/391]	LR: 0.002	DT: 6.305 (5.598)	BT: 6.662 (5.891)	Loss 0.0170 (0.0155)	Prec@1 100.000 (100.000)	
Epoch: [12][311/391]	LR: 0.002	DT: 0.000 (5.849)	BT: 0.257 (6.138)	Loss 0.0100 (0.0155)	Prec@1 100.000 (100.000)	
Epoch: [12][389/391]	LR: 0.002	DT: 0.000 (6.386)	BT: 0.255 (6.672)	Loss 0.0135 (0.0156)	Prec@1 100.000 (99.998)	
Total train loss: 0.0156
Avg Loading time: 6.3698 seconds
Avg Batch time: 6.6555 seconds

Train time: 2602.386789083481
 * Prec@1 94.800 Prec@5 99.750 Loss 0.1727
Avg Loading time: 7.1107 seconds
Avg Batch time: 7.2242 seconds

Best acc: 94.930
--------------------------------------------------------------------------------
Test time: 572.4714601039886

Epoch: [13][77/391]	LR: 0.002	DT: 0.000 (8.731)	BT: 0.249 (9.032)	Loss 0.0104 (0.0156)	Prec@1 100.000 (99.990)	
Epoch: [13][155/391]	LR: 0.002	DT: 0.000 (8.098)	BT: 0.261 (8.390)	Loss 0.0197 (0.0156)	Prec@1 100.000 (99.985)	
Epoch: [13][233/391]	LR: 0.002	DT: 0.000 (7.582)	BT: 0.282 (7.867)	Loss 0.0147 (0.0157)	Prec@1 100.000 (99.990)	
Epoch: [13][311/391]	LR: 0.002	DT: 0.000 (7.031)	BT: 0.264 (7.313)	Loss 0.0171 (0.0156)	Prec@1 100.000 (99.992)	
Epoch: [13][389/391]	LR: 0.002	DT: 0.000 (6.943)	BT: 0.252 (7.222)	Loss 0.0159 (0.0157)	Prec@1 100.000 (99.992)	
Total train loss: 0.0157
Avg Loading time: 6.9250 seconds
Avg Batch time: 7.2044 seconds

Train time: 2816.998382329941
 * Prec@1 94.890 Prec@5 99.730 Loss 0.1707
Avg Loading time: 6.6014 seconds
Avg Batch time: 6.7131 seconds

Best acc: 94.930
--------------------------------------------------------------------------------
Test time: 532.0996291637421

Epoch: [14][77/391]	LR: 0.002	DT: 0.000 (7.692)	BT: 0.253 (7.968)	Loss 0.0128 (0.0146)	Prec@1 100.000 (100.000)	
Epoch: [14][155/391]	LR: 0.002	DT: 0.000 (7.611)	BT: 0.258 (7.888)	Loss 0.0153 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [14][233/391]	LR: 0.002	DT: 0.000 (7.591)	BT: 0.278 (7.868)	Loss 0.0135 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [14][311/391]	LR: 0.002	DT: 0.000 (7.362)	BT: 0.268 (7.640)	Loss 0.0304 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [14][389/391]	LR: 0.002	DT: 0.000 (7.089)	BT: 0.266 (7.367)	Loss 0.0322 (0.0152)	Prec@1 100.000 (100.000)	
Total train loss: 0.0152
Avg Loading time: 7.0707 seconds
Avg Batch time: 7.3488 seconds

Train time: 2873.565134048462
 * Prec@1 94.870 Prec@5 99.730 Loss 0.1696
Avg Loading time: 6.2395 seconds
Avg Batch time: 6.3530 seconds

Best acc: 94.930
--------------------------------------------------------------------------------
Test time: 503.5928966999054

Epoch: [15][77/391]	LR: 0.002	DT: 0.000 (7.589)	BT: 0.266 (7.876)	Loss 0.0101 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [15][155/391]	LR: 0.002	DT: 4.572 (7.649)	BT: 4.857 (7.932)	Loss 0.0132 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [15][233/391]	LR: 0.002	DT: 0.000 (7.608)	BT: 0.266 (7.890)	Loss 0.0153 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [15][311/391]	LR: 0.002	DT: 1.421 (7.249)	BT: 1.695 (7.531)	Loss 0.0131 (0.0155)	Prec@1 100.000 (99.997)	
Epoch: [15][389/391]	LR: 0.002	DT: 0.000 (7.081)	BT: 0.265 (7.363)	Loss 0.0175 (0.0153)	Prec@1 100.000 (99.998)	
Total train loss: 0.0153
Avg Loading time: 7.0630 seconds
Avg Batch time: 7.3449 seconds

Train time: 2872.027062892914
 * Prec@1 94.810 Prec@5 99.750 Loss 0.1704
Avg Loading time: 6.2258 seconds
Avg Batch time: 6.3358 seconds

Best acc: 94.930
--------------------------------------------------------------------------------
Test time: 502.416068315506

Epoch: [16][77/391]	LR: 0.002	DT: 0.000 (7.535)	BT: 0.260 (7.824)	Loss 0.0172 (0.0157)	Prec@1 100.000 (100.000)	
Epoch: [16][155/391]	LR: 0.002	DT: 0.000 (7.477)	BT: 0.265 (7.761)	Loss 0.0116 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [16][233/391]	LR: 0.002	DT: 0.000 (8.074)	BT: 0.270 (8.356)	Loss 0.0242 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [16][311/391]	LR: 0.002	DT: 0.000 (7.623)	BT: 0.254 (7.903)	Loss 0.0122 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [16][389/391]	LR: 0.002	DT: 0.000 (7.644)	BT: 0.266 (7.923)	Loss 0.0158 (0.0153)	Prec@1 100.000 (100.000)	
Total train loss: 0.0153
Avg Loading time: 7.6244 seconds
Avg Batch time: 7.9032 seconds

Train time: 3090.3022198677063
 * Prec@1 94.790 Prec@5 99.750 Loss 0.1698
Avg Loading time: 6.5299 seconds
Avg Batch time: 6.6499 seconds

Best acc: 94.930
--------------------------------------------------------------------------------
Test time: 527.1257064342499

Epoch: [17][77/391]	LR: 0.002	DT: 0.000 (7.561)	BT: 0.276 (7.885)	Loss 0.0154 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [17][155/391]	LR: 0.002	DT: 0.000 (7.678)	BT: 0.398 (8.005)	Loss 0.0141 (0.0152)	Prec@1 100.000 (99.995)	
Epoch: [17][233/391]	LR: 0.002	DT: 0.000 (7.669)	BT: 0.387 (7.998)	Loss 0.0195 (0.0154)	Prec@1 100.000 (99.997)	
Epoch: [17][311/391]	LR: 0.002	DT: 0.000 (7.128)	BT: 0.271 (7.455)	Loss 0.0122 (0.0153)	Prec@1 100.000 (99.997)	
Epoch: [17][389/391]	LR: 0.002	DT: 0.000 (7.238)	BT: 0.392 (7.564)	Loss 0.0111 (0.0151)	Prec@1 100.000 (99.998)	
Total train loss: 0.0151
Avg Loading time: 7.2199 seconds
Avg Batch time: 7.5453 seconds

Train time: 2950.3674483299255
 * Prec@1 94.930 Prec@5 99.720 Loss 0.1719
Avg Loading time: 6.8746 seconds
Avg Batch time: 6.9901 seconds

Best acc: 94.930
--------------------------------------------------------------------------------
Test time: 553.9837608337402

Epoch: [18][77/391]	LR: 0.002	DT: 0.000 (8.003)	BT: 0.275 (8.284)	Loss 0.0127 (0.0145)	Prec@1 100.000 (100.000)	
Epoch: [18][155/391]	LR: 0.002	DT: 0.289 (7.751)	BT: 0.635 (8.039)	Loss 0.0171 (0.0148)	Prec@1 100.000 (100.000)	
Epoch: [18][233/391]	LR: 0.002	DT: 0.493 (7.519)	BT: 0.849 (7.820)	Loss 0.0148 (0.0148)	Prec@1 100.000 (100.000)	
Epoch: [18][311/391]	LR: 0.002	DT: 0.000 (7.006)	BT: 0.303 (7.313)	Loss 0.0129 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [18][389/391]	LR: 0.002	DT: 0.000 (7.052)	BT: 0.335 (7.365)	Loss 0.0143 (0.0147)	Prec@1 100.000 (100.000)	
Total train loss: 0.0147
Avg Loading time: 7.0341 seconds
Avg Batch time: 7.3463 seconds

Train time: 2872.5771923065186
 * Prec@1 94.920 Prec@5 99.730 Loss 0.1708
Avg Loading time: 7.3374 seconds
Avg Batch time: 7.4647 seconds

Best acc: 94.930
--------------------------------------------------------------------------------
Test time: 591.4387557506561

Epoch: [19][77/391]	LR: 0.002	DT: 0.000 (7.297)	BT: 0.432 (7.639)	Loss 0.0258 (0.0153)	Prec@1 100.000 (99.990)	
Epoch: [19][155/391]	LR: 0.002	DT: 0.000 (7.207)	BT: 0.282 (7.539)	Loss 0.0170 (0.0152)	Prec@1 100.000 (99.995)	
Epoch: [19][233/391]	LR: 0.002	DT: 0.000 (6.897)	BT: 0.294 (7.226)	Loss 0.0418 (0.0151)	Prec@1 100.000 (99.997)	
Epoch: [19][311/391]	LR: 0.002	DT: 0.000 (7.047)	BT: 0.351 (7.372)	Loss 0.0172 (0.0153)	Prec@1 100.000 (99.992)	
Epoch: [19][389/391]	LR: 0.002	DT: 0.000 (7.133)	BT: 0.368 (7.458)	Loss 0.0125 (0.0152)	Prec@1 100.000 (99.994)	
Total train loss: 0.0152
Avg Loading time: 7.1145 seconds
Avg Batch time: 7.4399 seconds

Train time: 2909.0640273094177
 * Prec@1 94.780 Prec@5 99.730 Loss 0.1707
Avg Loading time: 6.9255 seconds
Avg Batch time: 7.0470 seconds

Best acc: 94.930
--------------------------------------------------------------------------------
Test time: 558.4406983852386

Epoch: [20][77/391]	LR: 0.0004	DT: 0.000 (8.008)	BT: 0.406 (8.358)	Loss 0.0099 (0.0155)	Prec@1 100.000 (100.000)	
Epoch: [20][155/391]	LR: 0.0004	DT: 0.000 (7.943)	BT: 0.358 (8.286)	Loss 0.0121 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [20][233/391]	LR: 0.0004	DT: 0.000 (7.352)	BT: 0.285 (7.690)	Loss 0.0179 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [20][311/391]	LR: 0.0004	DT: 1.508 (7.096)	BT: 1.795 (7.434)	Loss 0.0170 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [20][389/391]	LR: 0.0004	DT: 0.000 (7.035)	BT: 0.255 (7.374)	Loss 0.0122 (0.0153)	Prec@1 100.000 (99.998)	
Total train loss: 0.0153
Avg Loading time: 7.0176 seconds
Avg Batch time: 7.3555 seconds

Train time: 2876.1289739608765
 * Prec@1 95.050 Prec@5 99.720 Loss 0.1703
Avg Loading time: 6.2096 seconds
Avg Batch time: 6.3348 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 503.2358877658844

Epoch: [21][77/391]	LR: 0.0004	DT: 0.000 (7.309)	BT: 0.256 (7.651)	Loss 0.0153 (0.0163)	Prec@1 100.000 (100.000)	
Epoch: [21][155/391]	LR: 0.0004	DT: 0.000 (7.326)	BT: 0.394 (7.659)	Loss 0.0139 (0.0157)	Prec@1 100.000 (100.000)	
Epoch: [21][233/391]	LR: 0.0004	DT: 5.205 (6.810)	BT: 5.543 (7.140)	Loss 0.0162 (0.0157)	Prec@1 100.000 (99.997)	
Epoch: [21][311/391]	LR: 0.0004	DT: 0.000 (6.765)	BT: 0.372 (7.096)	Loss 0.0135 (0.0154)	Prec@1 100.000 (99.997)	
Epoch: [21][389/391]	LR: 0.0004	DT: 0.000 (6.790)	BT: 0.287 (7.123)	Loss 0.0100 (0.0153)	Prec@1 100.000 (99.998)	
Total train loss: 0.0153
Avg Loading time: 6.7727 seconds
Avg Batch time: 7.1056 seconds

Train time: 2778.343793153763
 * Prec@1 94.850 Prec@5 99.740 Loss 0.1700
Avg Loading time: 6.1337 seconds
Avg Batch time: 6.2564 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 496.03803849220276

Epoch: [22][77/391]	LR: 0.0004	DT: 0.000 (7.215)	BT: 0.261 (7.551)	Loss 0.0116 (0.0146)	Prec@1 100.000 (100.000)	
Epoch: [22][155/391]	LR: 0.0004	DT: 0.000 (6.917)	BT: 0.367 (7.253)	Loss 0.0268 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [22][233/391]	LR: 0.0004	DT: 0.000 (6.633)	BT: 0.261 (6.964)	Loss 0.0199 (0.0150)	Prec@1 100.000 (99.997)	
Epoch: [22][311/391]	LR: 0.0004	DT: 0.000 (6.547)	BT: 0.286 (6.877)	Loss 0.0100 (0.0148)	Prec@1 100.000 (99.997)	
Epoch: [22][389/391]	LR: 0.0004	DT: 0.210 (6.588)	BT: 0.497 (6.919)	Loss 0.0197 (0.0150)	Prec@1 100.000 (99.998)	
Total train loss: 0.0150
Avg Loading time: 6.5709 seconds
Avg Batch time: 6.9018 seconds

Train time: 2698.730443716049
 * Prec@1 94.860 Prec@5 99.740 Loss 0.1694
Avg Loading time: 6.1417 seconds
Avg Batch time: 6.2634 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 496.7736554145813

Epoch: [23][77/391]	LR: 0.0004	DT: 0.000 (7.278)	BT: 0.343 (7.610)	Loss 0.0206 (0.0156)	Prec@1 100.000 (99.980)	
Epoch: [23][155/391]	LR: 0.0004	DT: 0.000 (6.809)	BT: 0.264 (7.137)	Loss 0.0168 (0.0151)	Prec@1 100.000 (99.990)	
Epoch: [23][233/391]	LR: 0.0004	DT: 0.000 (6.739)	BT: 0.341 (7.068)	Loss 0.0178 (0.0151)	Prec@1 100.000 (99.993)	
Epoch: [23][311/391]	LR: 0.0004	DT: 0.000 (6.561)	BT: 0.351 (6.889)	Loss 0.0103 (0.0151)	Prec@1 100.000 (99.995)	
Epoch: [23][389/391]	LR: 0.0004	DT: 0.000 (6.630)	BT: 0.323 (6.960)	Loss 0.0148 (0.0151)	Prec@1 100.000 (99.996)	
Total train loss: 0.0151
Avg Loading time: 6.6130 seconds
Avg Batch time: 6.9426 seconds

Train time: 2714.627148628235
 * Prec@1 94.820 Prec@5 99.730 Loss 0.1722
Avg Loading time: 5.8511 seconds
Avg Batch time: 5.9693 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 473.3199486732483

Epoch: [24][77/391]	LR: 0.0004	DT: 0.000 (7.347)	BT: 0.259 (7.664)	Loss 0.0164 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [24][155/391]	LR: 0.0004	DT: 0.000 (6.661)	BT: 0.393 (6.985)	Loss 0.0163 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [24][233/391]	LR: 0.0004	DT: 0.000 (6.656)	BT: 0.342 (6.982)	Loss 0.0169 (0.0154)	Prec@1 100.000 (100.000)	
Epoch: [24][311/391]	LR: 0.0004	DT: 0.000 (6.469)	BT: 0.268 (6.797)	Loss 0.0126 (0.0155)	Prec@1 100.000 (100.000)	
Epoch: [24][389/391]	LR: 0.0004	DT: 0.000 (6.469)	BT: 0.258 (6.796)	Loss 0.0175 (0.0153)	Prec@1 100.000 (99.998)	
Total train loss: 0.0153
Avg Loading time: 6.4521 seconds
Avg Batch time: 6.7794 seconds

Train time: 2650.810299396515
 * Prec@1 94.870 Prec@5 99.730 Loss 0.1697
Avg Loading time: 5.9887 seconds
Avg Batch time: 6.1151 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 484.8338692188263

Epoch: [25][77/391]	LR: 0.0004	DT: 0.000 (7.574)	BT: 0.408 (7.918)	Loss 0.0189 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [25][155/391]	LR: 0.0004	DT: 2.552 (6.797)	BT: 2.878 (7.122)	Loss 0.0103 (0.0148)	Prec@1 100.000 (100.000)	
Epoch: [25][233/391]	LR: 0.0004	DT: 3.217 (6.910)	BT: 3.574 (7.236)	Loss 0.0108 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [25][311/391]	LR: 0.0004	DT: 0.000 (6.830)	BT: 0.369 (7.156)	Loss 0.0096 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [25][389/391]	LR: 0.0004	DT: 0.000 (6.849)	BT: 0.341 (7.178)	Loss 0.0161 (0.0151)	Prec@1 100.000 (100.000)	
Total train loss: 0.0151
Avg Loading time: 6.8317 seconds
Avg Batch time: 7.1599 seconds

Train time: 2799.6651985645294
 * Prec@1 94.860 Prec@5 99.700 Loss 0.1721
Avg Loading time: 6.2397 seconds
Avg Batch time: 6.3590 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 504.13734316825867

Epoch: [26][77/391]	LR: 0.0004	DT: 0.000 (7.284)	BT: 0.369 (7.614)	Loss 0.0135 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [26][155/391]	LR: 0.0004	DT: 0.000 (6.735)	BT: 0.272 (7.068)	Loss 0.0121 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [26][233/391]	LR: 0.0004	DT: 2.184 (6.777)	BT: 2.609 (7.111)	Loss 0.0164 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [26][311/391]	LR: 0.0004	DT: 0.000 (6.667)	BT: 0.351 (7.000)	Loss 0.0172 (0.0148)	Prec@1 100.000 (100.000)	
Epoch: [26][389/391]	LR: 0.0004	DT: 0.278 (6.693)	BT: 0.647 (7.024)	Loss 0.0217 (0.0150)	Prec@1 100.000 (100.000)	
Total train loss: 0.0150
Avg Loading time: 6.6757 seconds
Avg Batch time: 7.0064 seconds

Train time: 2739.5461161136627
 * Prec@1 94.960 Prec@5 99.720 Loss 0.1699
Avg Loading time: 6.0029 seconds
Avg Batch time: 6.1210 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 485.2993268966675

Epoch: [27][77/391]	LR: 0.0004	DT: 0.000 (6.224)	BT: 0.268 (6.549)	Loss 0.0170 (0.0157)	Prec@1 100.000 (100.000)	
Epoch: [27][155/391]	LR: 0.0004	DT: 0.602 (6.180)	BT: 0.926 (6.501)	Loss 0.0154 (0.0155)	Prec@1 100.000 (100.000)	
Epoch: [27][233/391]	LR: 0.0004	DT: 3.189 (6.340)	BT: 3.514 (6.661)	Loss 0.0123 (0.0154)	Prec@1 100.000 (99.993)	
Epoch: [27][311/391]	LR: 0.0004	DT: 0.000 (6.277)	BT: 0.342 (6.602)	Loss 0.0188 (0.0154)	Prec@1 100.000 (99.992)	
Epoch: [27][389/391]	LR: 0.0004	DT: 0.000 (6.351)	BT: 0.370 (6.677)	Loss 0.0128 (0.0154)	Prec@1 100.000 (99.992)	
Total train loss: 0.0154
Avg Loading time: 6.3352 seconds
Avg Batch time: 6.6605 seconds

Train time: 2604.4038500785828
 * Prec@1 94.850 Prec@5 99.760 Loss 0.1711
Avg Loading time: 6.0471 seconds
Avg Batch time: 6.1653 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 489.12311935424805

Epoch: [28][77/391]	LR: 0.0004	DT: 0.000 (5.855)	BT: 0.262 (6.183)	Loss 0.0131 (0.0155)	Prec@1 100.000 (99.990)	
Epoch: [28][155/391]	LR: 0.0004	DT: 7.435 (6.255)	BT: 7.782 (6.580)	Loss 0.0152 (0.0153)	Prec@1 100.000 (99.990)	
Epoch: [28][233/391]	LR: 0.0004	DT: 0.000 (6.399)	BT: 0.330 (6.723)	Loss 0.0164 (0.0149)	Prec@1 100.000 (99.993)	
Epoch: [28][311/391]	LR: 0.0004	DT: 0.000 (6.406)	BT: 0.344 (6.728)	Loss 0.0163 (0.0150)	Prec@1 100.000 (99.990)	
Epoch: [28][389/391]	LR: 0.0004	DT: 0.000 (6.537)	BT: 0.347 (6.859)	Loss 0.0148 (0.0151)	Prec@1 100.000 (99.992)	
Total train loss: 0.0151
Avg Loading time: 6.5198 seconds
Avg Batch time: 6.8416 seconds

Train time: 2675.1405363082886
 * Prec@1 94.830 Prec@5 99.720 Loss 0.1719
Avg Loading time: 5.9262 seconds
Avg Batch time: 6.0453 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 479.5603783130646

Epoch: [29][77/391]	LR: 0.0004	DT: 0.000 (5.620)	BT: 0.358 (5.953)	Loss 0.0102 (0.0156)	Prec@1 100.000 (99.990)	
Epoch: [29][155/391]	LR: 0.0004	DT: 0.000 (6.337)	BT: 0.258 (6.663)	Loss 0.0211 (0.0155)	Prec@1 100.000 (99.995)	
Epoch: [29][233/391]	LR: 0.0004	DT: 0.000 (6.564)	BT: 0.258 (6.891)	Loss 0.0185 (0.0153)	Prec@1 100.000 (99.997)	
Epoch: [29][311/391]	LR: 0.0004	DT: 0.000 (6.497)	BT: 0.337 (6.823)	Loss 0.0142 (0.0155)	Prec@1 100.000 (99.992)	
Epoch: [29][389/391]	LR: 0.0004	DT: 0.000 (6.570)	BT: 0.367 (6.896)	Loss 0.0128 (0.0154)	Prec@1 100.000 (99.994)	
Total train loss: 0.0154
Avg Loading time: 6.5529 seconds
Avg Batch time: 6.8787 seconds

Train time: 2689.763323068619
 * Prec@1 94.880 Prec@5 99.740 Loss 0.1696
Avg Loading time: 6.1802 seconds
Avg Batch time: 6.2978 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 499.41282749176025

Epoch: [30][77/391]	LR: 8e-05	DT: 0.000 (6.028)	BT: 0.312 (6.367)	Loss 0.0132 (0.0145)	Prec@1 100.000 (100.000)	
Epoch: [30][155/391]	LR: 8e-05	DT: 0.000 (6.400)	BT: 0.312 (6.734)	Loss 0.0126 (0.0146)	Prec@1 100.000 (100.000)	
Epoch: [30][233/391]	LR: 8e-05	DT: 0.000 (6.469)	BT: 0.338 (6.800)	Loss 0.0180 (0.0148)	Prec@1 100.000 (99.997)	
Epoch: [30][311/391]	LR: 8e-05	DT: 0.000 (6.376)	BT: 0.302 (6.704)	Loss 0.0139 (0.0148)	Prec@1 100.000 (99.997)	
Epoch: [30][389/391]	LR: 8e-05	DT: 0.000 (6.423)	BT: 0.265 (6.750)	Loss 0.0170 (0.0149)	Prec@1 100.000 (99.998)	
Total train loss: 0.0149
Avg Loading time: 6.4062 seconds
Avg Batch time: 6.7334 seconds

Train time: 2632.925230741501
 * Prec@1 94.780 Prec@5 99.730 Loss 0.1727
Avg Loading time: 4.9205 seconds
Avg Batch time: 5.0428 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 400.39658761024475

Epoch: [31][77/391]	LR: 8e-05	DT: 0.000 (6.238)	BT: 0.264 (6.577)	Loss 0.0110 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [31][155/391]	LR: 8e-05	DT: 0.000 (6.425)	BT: 0.333 (6.757)	Loss 0.0173 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [31][233/391]	LR: 8e-05	DT: 5.388 (6.541)	BT: 5.706 (6.870)	Loss 0.0169 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [31][311/391]	LR: 8e-05	DT: 0.000 (6.451)	BT: 0.269 (6.780)	Loss 0.0113 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [31][389/391]	LR: 8e-05	DT: 0.000 (6.507)	BT: 0.343 (6.836)	Loss 0.0142 (0.0151)	Prec@1 100.000 (100.000)	
Total train loss: 0.0151
Avg Loading time: 6.4903 seconds
Avg Batch time: 6.8186 seconds

Train time: 2666.143275499344
 * Prec@1 94.820 Prec@5 99.740 Loss 0.1697
Avg Loading time: 4.1566 seconds
Avg Batch time: 4.2755 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 339.6765592098236

Epoch: [32][77/391]	LR: 8e-05	DT: 1.139 (6.985)	BT: 1.469 (7.318)	Loss 0.0134 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 8e-05	DT: 0.000 (6.783)	BT: 0.268 (7.116)	Loss 0.0158 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [32][233/391]	LR: 8e-05	DT: 2.989 (6.688)	BT: 3.270 (7.017)	Loss 0.0096 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [32][311/391]	LR: 8e-05	DT: 0.000 (6.552)	BT: 0.263 (6.883)	Loss 0.0187 (0.0150)	Prec@1 100.000 (99.995)	
Epoch: [32][389/391]	LR: 8e-05	DT: 0.000 (6.572)	BT: 0.340 (6.902)	Loss 0.0235 (0.0151)	Prec@1 100.000 (99.992)	
Total train loss: 0.0151
Avg Loading time: 6.5549 seconds
Avg Batch time: 6.8854 seconds

Train time: 2692.2491974830627
 * Prec@1 94.840 Prec@5 99.760 Loss 0.1715
Avg Loading time: 3.8860 seconds
Avg Batch time: 4.0054 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 318.19458270072937

Epoch: [33][77/391]	LR: 8e-05	DT: 0.000 (6.717)	BT: 0.328 (7.048)	Loss 0.0142 (0.0148)	Prec@1 100.000 (99.980)	
Epoch: [33][155/391]	LR: 8e-05	DT: 0.000 (6.670)	BT: 0.260 (6.998)	Loss 0.0108 (0.0151)	Prec@1 100.000 (99.990)	
Epoch: [33][233/391]	LR: 8e-05	DT: 10.287 (6.709)	BT: 10.587 (7.035)	Loss 0.0165 (0.0150)	Prec@1 100.000 (99.993)	
Epoch: [33][311/391]	LR: 8e-05	DT: 0.000 (6.544)	BT: 0.267 (6.871)	Loss 0.0190 (0.0153)	Prec@1 100.000 (99.992)	
Epoch: [33][389/391]	LR: 8e-05	DT: 0.000 (6.530)	BT: 0.349 (6.857)	Loss 0.0149 (0.0153)	Prec@1 100.000 (99.994)	
Total train loss: 0.0153
Avg Loading time: 6.5129 seconds
Avg Batch time: 6.8400 seconds

Train time: 2674.568946838379
 * Prec@1 94.790 Prec@5 99.740 Loss 0.1707
Avg Loading time: 3.9671 seconds
Avg Batch time: 4.0942 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 325.2121365070343

Epoch: [34][77/391]	LR: 8e-05	DT: 0.000 (6.702)	BT: 0.355 (7.038)	Loss 0.0109 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [34][155/391]	LR: 8e-05	DT: 1.087 (6.627)	BT: 1.428 (6.959)	Loss 0.0161 (0.0153)	Prec@1 100.000 (99.995)	
Epoch: [34][233/391]	LR: 8e-05	DT: 4.484 (6.658)	BT: 4.835 (6.988)	Loss 0.0115 (0.0152)	Prec@1 100.000 (99.997)	
Epoch: [34][311/391]	LR: 8e-05	DT: 0.938 (6.492)	BT: 1.307 (6.821)	Loss 0.0142 (0.0151)	Prec@1 100.000 (99.997)	
Epoch: [34][389/391]	LR: 8e-05	DT: 0.000 (6.415)	BT: 0.277 (6.744)	Loss 0.0110 (0.0153)	Prec@1 100.000 (99.996)	
Total train loss: 0.0153
Avg Loading time: 6.3988 seconds
Avg Batch time: 6.7275 seconds

Train time: 2630.508124113083
 * Prec@1 94.910 Prec@5 99.740 Loss 0.1696
Avg Loading time: 4.7422 seconds
Avg Batch time: 4.8643 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 386.0884714126587

Epoch: [35][77/391]	LR: 8e-05	DT: 0.000 (6.698)	BT: 0.286 (7.033)	Loss 0.0108 (0.0146)	Prec@1 100.000 (100.000)	
Epoch: [35][155/391]	LR: 8e-05	DT: 0.000 (6.653)	BT: 0.335 (6.983)	Loss 0.0152 (0.0146)	Prec@1 100.000 (100.000)	
Epoch: [35][233/391]	LR: 8e-05	DT: 0.000 (6.644)	BT: 0.327 (6.973)	Loss 0.0149 (0.0148)	Prec@1 100.000 (99.997)	
Epoch: [35][311/391]	LR: 8e-05	DT: 0.000 (6.485)	BT: 0.356 (6.814)	Loss 0.0172 (0.0148)	Prec@1 100.000 (99.997)	
Epoch: [35][389/391]	LR: 8e-05	DT: 0.000 (6.313)	BT: 0.347 (6.640)	Loss 0.0107 (0.0147)	Prec@1 100.000 (99.998)	
Total train loss: 0.0147
Avg Loading time: 6.2968 seconds
Avg Batch time: 6.6237 seconds

Train time: 2589.895770072937
 * Prec@1 94.930 Prec@5 99.750 Loss 0.1692
Avg Loading time: 4.9090 seconds
Avg Batch time: 5.0301 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 399.07989501953125

Epoch: [36][77/391]	LR: 8e-05	DT: 0.000 (6.646)	BT: 0.334 (6.970)	Loss 0.0108 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [36][155/391]	LR: 8e-05	DT: 0.000 (6.604)	BT: 0.364 (6.932)	Loss 0.0188 (0.0154)	Prec@1 100.000 (100.000)	
Epoch: [36][233/391]	LR: 8e-05	DT: 2.397 (6.597)	BT: 2.732 (6.924)	Loss 0.0131 (0.0155)	Prec@1 100.000 (99.997)	
Epoch: [36][311/391]	LR: 8e-05	DT: 0.000 (6.416)	BT: 0.303 (6.742)	Loss 0.0128 (0.0154)	Prec@1 100.000 (99.997)	
Epoch: [36][389/391]	LR: 8e-05	DT: 0.000 (6.174)	BT: 0.326 (6.501)	Loss 0.0117 (0.0153)	Prec@1 100.000 (99.994)	
Total train loss: 0.0153
Avg Loading time: 6.1579 seconds
Avg Batch time: 6.4847 seconds

Train time: 2535.5390877723694
 * Prec@1 94.800 Prec@5 99.740 Loss 0.1715
Avg Loading time: 5.5940 seconds
Avg Batch time: 5.7144 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 453.1784315109253

Epoch: [37][77/391]	LR: 8e-05	DT: 0.000 (6.654)	BT: 0.309 (6.991)	Loss 0.0185 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [37][155/391]	LR: 8e-05	DT: 0.000 (6.573)	BT: 0.355 (6.908)	Loss 0.0122 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [37][233/391]	LR: 8e-05	DT: 0.000 (6.570)	BT: 0.358 (6.902)	Loss 0.0155 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [37][311/391]	LR: 8e-05	DT: 0.000 (6.398)	BT: 0.375 (6.729)	Loss 0.0203 (0.0152)	Prec@1 100.000 (99.997)	
Epoch: [37][389/391]	LR: 8e-05	DT: 0.772 (6.174)	BT: 1.139 (6.504)	Loss 0.0123 (0.0153)	Prec@1 100.000 (99.996)	
Total train loss: 0.0153
Avg Loading time: 6.1585 seconds
Avg Batch time: 6.4882 seconds

Train time: 2536.918488264084
 * Prec@1 94.820 Prec@5 99.740 Loss 0.1696
Avg Loading time: 5.6310 seconds
Avg Batch time: 5.7484 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 455.92122650146484

Epoch: [38][77/391]	LR: 8e-05	DT: 0.000 (6.567)	BT: 0.342 (6.913)	Loss 0.0195 (0.0156)	Prec@1 100.000 (100.000)	
Epoch: [38][155/391]	LR: 8e-05	DT: 0.000 (6.508)	BT: 0.261 (6.846)	Loss 0.0148 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [38][233/391]	LR: 8e-05	DT: 0.000 (6.521)	BT: 0.268 (6.853)	Loss 0.0162 (0.0151)	Prec@1 100.000 (99.993)	
Epoch: [38][311/391]	LR: 8e-05	DT: 0.000 (6.251)	BT: 0.338 (6.581)	Loss 0.0159 (0.0150)	Prec@1 100.000 (99.995)	
Epoch: [38][389/391]	LR: 8e-05	DT: 0.000 (6.135)	BT: 0.354 (6.464)	Loss 0.0150 (0.0150)	Prec@1 100.000 (99.996)	
Total train loss: 0.0150
Avg Loading time: 6.1196 seconds
Avg Batch time: 6.4484 seconds

Train time: 2521.3517949581146
 * Prec@1 94.910 Prec@5 99.700 Loss 0.1714
Avg Loading time: 5.6338 seconds
Avg Batch time: 5.7534 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 456.2086114883423

Epoch: [39][77/391]	LR: 8e-05	DT: 0.000 (6.562)	BT: 0.361 (6.899)	Loss 0.0122 (0.0150)	Prec@1 100.000 (99.990)	
Epoch: [39][155/391]	LR: 8e-05	DT: 0.000 (6.502)	BT: 0.273 (6.832)	Loss 0.0106 (0.0151)	Prec@1 100.000 (99.995)	
Epoch: [39][233/391]	LR: 8e-05	DT: 0.000 (6.490)	BT: 0.339 (6.819)	Loss 0.0104 (0.0151)	Prec@1 100.000 (99.997)	
Epoch: [39][311/391]	LR: 8e-05	DT: 0.000 (6.134)	BT: 0.339 (6.461)	Loss 0.0166 (0.0151)	Prec@1 100.000 (99.995)	
Epoch: [39][389/391]	LR: 8e-05	DT: 0.000 (6.136)	BT: 0.353 (6.464)	Loss 0.0113 (0.0152)	Prec@1 100.000 (99.994)	
Total train loss: 0.0152
Avg Loading time: 6.1201 seconds
Avg Batch time: 6.4479 seconds

Train time: 2521.1909153461456
 * Prec@1 94.920 Prec@5 99.750 Loss 0.1688
Avg Loading time: 5.7374 seconds
Avg Batch time: 5.8557 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 464.4120874404907

Epoch: [40][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.614)	BT: 0.348 (6.933)	Loss 0.0146 (0.0148)	Prec@1 100.000 (100.000)	
Epoch: [40][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.529)	BT: 0.331 (6.855)	Loss 0.0146 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [40][233/391]	LR: 1.6000000000000003e-05	DT: 7.030 (6.555)	BT: 7.395 (6.885)	Loss 0.0143 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [40][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.089)	BT: 0.346 (6.418)	Loss 0.0226 (0.0151)	Prec@1 100.000 (99.997)	
Epoch: [40][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.129)	BT: 0.268 (6.459)	Loss 0.0129 (0.0151)	Prec@1 100.000 (99.998)	
Total train loss: 0.0152
Avg Loading time: 6.1132 seconds
Avg Batch time: 6.4425 seconds

Train time: 2519.195109128952
 * Prec@1 94.950 Prec@5 99.720 Loss 0.1718
Avg Loading time: 5.6857 seconds
Avg Batch time: 5.8056 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 460.3865463733673

Epoch: [41][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.595)	BT: 0.305 (6.935)	Loss 0.0125 (0.0144)	Prec@1 100.000 (100.000)	
Epoch: [41][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.541)	BT: 0.339 (6.874)	Loss 0.0170 (0.0156)	Prec@1 100.000 (99.985)	
Epoch: [41][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.547)	BT: 0.259 (6.877)	Loss 0.0136 (0.0156)	Prec@1 100.000 (99.980)	
Epoch: [41][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.104)	BT: 0.358 (6.435)	Loss 0.0140 (0.0155)	Prec@1 100.000 (99.985)	
Epoch: [41][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.150)	BT: 0.387 (6.480)	Loss 0.0139 (0.0157)	Prec@1 100.000 (99.982)	
Total train loss: 0.0157
Avg Loading time: 6.1346 seconds
Avg Batch time: 6.4644 seconds

Train time: 2527.633719444275
 * Prec@1 94.770 Prec@5 99.720 Loss 0.1722
Avg Loading time: 5.6966 seconds
Avg Batch time: 5.8167 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 461.2526993751526

Epoch: [42][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.740)	BT: 0.334 (7.075)	Loss 0.0230 (0.0157)	Prec@1 100.000 (100.000)	
Epoch: [42][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.634)	BT: 0.344 (6.965)	Loss 0.0162 (0.0157)	Prec@1 100.000 (99.990)	
Epoch: [42][233/391]	LR: 1.6000000000000003e-05	DT: 2.113 (6.518)	BT: 2.445 (6.847)	Loss 0.0133 (0.0155)	Prec@1 100.000 (99.993)	
Epoch: [42][311/391]	LR: 1.6000000000000003e-05	DT: 1.041 (6.149)	BT: 1.408 (6.478)	Loss 0.0141 (0.0155)	Prec@1 100.000 (99.995)	
Epoch: [42][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.166)	BT: 0.381 (6.496)	Loss 0.0119 (0.0154)	Prec@1 100.000 (99.996)	
Total train loss: 0.0154
Avg Loading time: 6.1507 seconds
Avg Batch time: 6.4803 seconds

Train time: 2533.867260694504
 * Prec@1 94.970 Prec@5 99.710 Loss 0.1710
Avg Loading time: 5.9037 seconds
Avg Batch time: 6.0240 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 477.83310770988464

Epoch: [43][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.672)	BT: 0.268 (7.006)	Loss 0.0110 (0.0140)	Prec@1 100.000 (100.000)	
Epoch: [43][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.562)	BT: 0.269 (6.894)	Loss 0.0187 (0.0144)	Prec@1 100.000 (99.995)	
Epoch: [43][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.358)	BT: 0.269 (6.687)	Loss 0.0161 (0.0146)	Prec@1 100.000 (99.997)	
Epoch: [43][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.090)	BT: 0.254 (6.411)	Loss 0.0103 (0.0147)	Prec@1 100.000 (99.997)	
Epoch: [43][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.181)	BT: 0.263 (6.494)	Loss 0.0111 (0.0147)	Prec@1 100.000 (99.998)	
Total train loss: 0.0147
Avg Loading time: 6.1650 seconds
Avg Batch time: 6.4784 seconds

Train time: 2533.114515542984
 * Prec@1 94.810 Prec@5 99.750 Loss 0.1696
Avg Loading time: 6.5715 seconds
Avg Batch time: 6.6862 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 530.0189135074615

Epoch: [44][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.711)	BT: 0.266 (6.990)	Loss 0.0122 (0.0151)	Prec@1 100.000 (99.990)	
Epoch: [44][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.593)	BT: 0.363 (6.875)	Loss 0.0158 (0.0152)	Prec@1 100.000 (99.990)	
Epoch: [44][233/391]	LR: 1.6000000000000003e-05	DT: 0.802 (6.402)	BT: 1.068 (6.685)	Loss 0.0150 (0.0154)	Prec@1 100.000 (99.993)	
Epoch: [44][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.142)	BT: 0.264 (6.426)	Loss 0.0166 (0.0153)	Prec@1 100.000 (99.995)	
Epoch: [44][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.155)	BT: 0.256 (6.438)	Loss 0.0129 (0.0153)	Prec@1 100.000 (99.996)	
Total train loss: 0.0153
Avg Loading time: 6.1391 seconds
Avg Batch time: 6.4217 seconds

Train time: 2510.9199373722076
 * Prec@1 94.870 Prec@5 99.710 Loss 0.1711
Avg Loading time: 5.6077 seconds
Avg Batch time: 5.7191 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 453.58349609375

Epoch: [45][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.680)	BT: 0.280 (6.970)	Loss 0.0164 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [45][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.560)	BT: 0.269 (6.848)	Loss 0.0353 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [45][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.413)	BT: 0.270 (6.699)	Loss 0.0127 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [45][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.099)	BT: 0.263 (6.383)	Loss 0.0101 (0.0151)	Prec@1 100.000 (99.997)	
Epoch: [45][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.145)	BT: 0.275 (6.428)	Loss 0.0162 (0.0152)	Prec@1 100.000 (99.998)	
Total train loss: 0.0152
Avg Loading time: 6.1290 seconds
Avg Batch time: 6.4120 seconds

Train time: 2507.228424310684
 * Prec@1 94.860 Prec@5 99.740 Loss 0.1696
Avg Loading time: 5.7368 seconds
Avg Batch time: 5.8480 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 463.90971779823303

Epoch: [46][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.785)	BT: 0.257 (7.076)	Loss 0.0145 (0.0145)	Prec@1 100.000 (100.000)	
Epoch: [46][155/391]	LR: 1.6000000000000003e-05	DT: 0.682 (6.642)	BT: 0.978 (6.925)	Loss 0.0157 (0.0145)	Prec@1 100.000 (100.000)	
Epoch: [46][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.464)	BT: 0.268 (6.744)	Loss 0.0107 (0.0147)	Prec@1 100.000 (100.000)	
Epoch: [46][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.167)	BT: 0.278 (6.447)	Loss 0.0130 (0.0146)	Prec@1 100.000 (100.000)	
Epoch: [46][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.209)	BT: 0.257 (6.489)	Loss 0.0111 (0.0145)	Prec@1 100.000 (100.000)	
Total train loss: 0.0145
Avg Loading time: 6.1930 seconds
Avg Batch time: 6.4724 seconds

Train time: 2530.918567419052
 * Prec@1 94.830 Prec@5 99.730 Loss 0.1698
Avg Loading time: 5.7191 seconds
Avg Batch time: 5.8311 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 462.5989410877228

Epoch: [47][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.847)	BT: 0.267 (7.137)	Loss 0.0118 (0.0156)	Prec@1 100.000 (100.000)	
Epoch: [47][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.791)	BT: 0.305 (7.075)	Loss 0.0271 (0.0158)	Prec@1 100.000 (100.000)	
Epoch: [47][233/391]	LR: 1.6000000000000003e-05	DT: 4.227 (6.568)	BT: 4.509 (6.854)	Loss 0.0132 (0.0156)	Prec@1 100.000 (99.997)	
Epoch: [47][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.341)	BT: 0.289 (6.630)	Loss 0.0114 (0.0154)	Prec@1 100.000 (99.997)	
Epoch: [47][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.335)	BT: 0.291 (6.627)	Loss 0.0177 (0.0152)	Prec@1 100.000 (99.998)	
Total train loss: 0.0152
Avg Loading time: 6.3192 seconds
Avg Batch time: 6.6105 seconds

Train time: 2584.771891593933
 * Prec@1 94.850 Prec@5 99.720 Loss 0.1708
Avg Loading time: 5.8696 seconds
Avg Batch time: 5.9876 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 475.0039076805115

Epoch: [48][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.848)	BT: 0.294 (7.149)	Loss 0.0139 (0.0149)	Prec@1 100.000 (99.990)	
Epoch: [48][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.681)	BT: 0.285 (6.983)	Loss 0.0126 (0.0152)	Prec@1 100.000 (99.995)	
Epoch: [48][233/391]	LR: 1.6000000000000003e-05	DT: 4.265 (6.413)	BT: 4.577 (6.715)	Loss 0.0226 (0.0152)	Prec@1 100.000 (99.997)	
Epoch: [48][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.263)	BT: 0.267 (6.559)	Loss 0.0232 (0.0153)	Prec@1 100.000 (99.997)	
Epoch: [48][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.298)	BT: 0.248 (6.590)	Loss 0.0144 (0.0151)	Prec@1 100.000 (99.998)	
Total train loss: 0.0151
Avg Loading time: 6.2817 seconds
Avg Batch time: 6.5731 seconds

Train time: 2570.1830625534058
 * Prec@1 94.850 Prec@5 99.740 Loss 0.1707
Avg Loading time: 5.8653 seconds
Avg Batch time: 5.9817 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 474.4966514110565

Epoch: [49][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.767)	BT: 0.266 (7.054)	Loss 0.0187 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [49][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (6.727)	BT: 0.269 (7.016)	Loss 0.0175 (0.0154)	Prec@1 100.000 (99.995)	
Epoch: [49][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.886)	BT: 0.320 (6.172)	Loss 0.0123 (0.0150)	Prec@1 100.000 (99.997)	
Epoch: [49][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.400)	BT: 0.258 (5.685)	Loss 0.0195 (0.0152)	Prec@1 100.000 (99.997)	
Epoch: [49][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (5.144)	BT: 0.257 (5.428)	Loss 0.0103 (0.0152)	Prec@1 100.000 (99.998)	
Total train loss: 0.0152
Avg Loading time: 5.1306 seconds
Avg Batch time: 5.4143 seconds

Train time: 2117.025582551956
 * Prec@1 94.830 Prec@5 99.730 Loss 0.1710
Avg Loading time: 3.7916 seconds
Avg Batch time: 3.9067 seconds

Best acc: 95.050
--------------------------------------------------------------------------------
Test time: 310.5321912765503


      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x128/
          savedir: ../pretrained_models/frozen/x128/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram_new
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 3
Savedir:  ../pretrained_models/frozen/x128/rram_new/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x128/rram/one_batch/cifar10/resnet18/train/relu3
Test path:  /home/nano01/a/esoufler/activations/x128/rram_new/one_batch/cifar10/resnet18/test/relu3
ResNet18(
  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu4): ReLU(inplace=True)
  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu5): ReLU(inplace=True)
  (conv6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv1): Sequential(
    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu6): ReLU(inplace=True)
  (conv7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu7): ReLU(inplace=True)
  (conv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 7.410 Prec@5 47.340 Loss 2.3281
Avg Loading time: 1.1634 seconds
Avg Batch time: 1.2261 seconds

Pre-trained Prec@1 with 3 layers frozen: 7.409999847412109 	 Loss: 2.328125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.01	DT: 0.000 (1.304)	BT: 0.170 (1.489)	Loss 0.5571 (0.8931)	Prec@1 85.156 (76.042)	
Epoch: [0][155/391]	LR: 0.01	DT: 0.000 (1.276)	BT: 0.171 (1.455)	Loss 0.4468 (0.6775)	Prec@1 83.594 (82.051)	
Epoch: [0][233/391]	LR: 0.01	DT: 0.000 (1.271)	BT: 0.170 (1.448)	Loss 0.4771 (0.5700)	Prec@1 85.156 (84.776)	
Epoch: [0][311/391]	LR: 0.01	DT: 0.000 (1.246)	BT: 0.168 (1.422)	Loss 0.3313 (0.5046)	Prec@1 89.844 (86.398)	
Epoch: [0][389/391]	LR: 0.01	DT: 0.000 (1.239)	BT: 0.172 (1.414)	Loss 0.2600 (0.4619)	Prec@1 92.188 (87.410)	
Total train loss: 0.4617
Avg Loading time: 1.2356 seconds
Avg Batch time: 1.4105 seconds

Train time: 551.6537322998047
 * Prec@1 92.370 Prec@5 99.800 Loss 0.2590
Avg Loading time: 1.2856 seconds
Avg Batch time: 1.3407 seconds

Best acc: 92.370
--------------------------------------------------------------------------------
Test time: 107.71225452423096

Epoch: [1][77/391]	LR: 0.01	DT: 0.000 (0.808)	BT: 0.169 (0.980)	Loss 0.1395 (0.1687)	Prec@1 96.094 (96.134)	
Epoch: [1][155/391]	LR: 0.01	DT: 0.000 (0.796)	BT: 0.169 (0.968)	Loss 0.1572 (0.1650)	Prec@1 96.875 (95.928)	
Epoch: [1][233/391]	LR: 0.01	DT: 0.888 (0.808)	BT: 1.061 (0.980)	Loss 0.1508 (0.1644)	Prec@1 94.531 (95.810)	
Epoch: [1][311/391]	LR: 0.01	DT: 0.000 (0.796)	BT: 0.170 (0.968)	Loss 0.1649 (0.1633)	Prec@1 96.875 (95.738)	
Epoch: [1][389/391]	LR: 0.01	DT: 0.000 (0.823)	BT: 0.168 (0.995)	Loss 0.2069 (0.1621)	Prec@1 94.531 (95.725)	
Total train loss: 0.1621
Avg Loading time: 0.8212 seconds
Avg Batch time: 0.9928 seconds

Train time: 391.68546986579895
 * Prec@1 93.390 Prec@5 99.860 Loss 0.2172
Avg Loading time: 1.1313 seconds
Avg Batch time: 1.1907 seconds

Best acc: 93.390
--------------------------------------------------------------------------------
Test time: 100.25084686279297

Epoch: [2][77/391]	LR: 0.01	DT: 0.000 (0.802)	BT: 0.172 (0.973)	Loss 0.1324 (0.0837)	Prec@1 98.438 (98.548)	
Epoch: [2][155/391]	LR: 0.01	DT: 0.000 (0.805)	BT: 0.170 (0.976)	Loss 0.0535 (0.0790)	Prec@1 100.000 (98.543)	
Epoch: [2][233/391]	LR: 0.01	DT: 1.721 (0.810)	BT: 1.888 (0.982)	Loss 0.0727 (0.0777)	Prec@1 98.438 (98.571)	
Epoch: [2][311/391]	LR: 0.01	DT: 0.000 (0.798)	BT: 0.170 (0.970)	Loss 0.0472 (0.0782)	Prec@1 100.000 (98.525)	
Epoch: [2][389/391]	LR: 0.01	DT: 0.000 (0.795)	BT: 0.166 (0.967)	Loss 0.0505 (0.0785)	Prec@1 100.000 (98.480)	
Total train loss: 0.0786
Avg Loading time: 0.7934 seconds
Avg Batch time: 0.9646 seconds

Train time: 377.2724173069
 * Prec@1 93.740 Prec@5 99.770 Loss 0.2070
Avg Loading time: 1.1379 seconds
Avg Batch time: 1.1888 seconds

Best acc: 93.740
--------------------------------------------------------------------------------
Test time: 95.98190259933472

Epoch: [3][77/391]	LR: 0.01	DT: 0.000 (0.806)	BT: 0.167 (0.977)	Loss 0.0560 (0.0475)	Prec@1 99.219 (99.399)	
Epoch: [3][155/391]	LR: 0.01	DT: 0.000 (0.834)	BT: 0.169 (1.005)	Loss 0.0695 (0.0465)	Prec@1 99.219 (99.484)	
Epoch: [3][233/391]	LR: 0.01	DT: 0.000 (0.826)	BT: 0.172 (0.997)	Loss 0.0541 (0.0449)	Prec@1 99.219 (99.509)	
Epoch: [3][311/391]	LR: 0.01	DT: 0.000 (0.812)	BT: 0.172 (0.983)	Loss 0.0584 (0.0437)	Prec@1 99.219 (99.532)	
Epoch: [3][389/391]	LR: 0.01	DT: 0.000 (0.831)	BT: 0.171 (1.003)	Loss 0.0269 (0.0430)	Prec@1 100.000 (99.549)	
Total train loss: 0.0430
Avg Loading time: 0.8290 seconds
Avg Batch time: 1.0004 seconds

Train time: 391.29347491264343
 * Prec@1 94.480 Prec@5 99.780 Loss 0.1884
Avg Loading time: 0.8759 seconds
Avg Batch time: 0.9358 seconds

Best acc: 94.480
--------------------------------------------------------------------------------
Test time: 76.03403830528259

Epoch: [4][77/391]	LR: 0.01	DT: 0.000 (0.796)	BT: 0.170 (0.967)	Loss 0.0189 (0.0293)	Prec@1 100.000 (99.870)	
Epoch: [4][155/391]	LR: 0.01	DT: 0.000 (0.796)	BT: 0.168 (0.967)	Loss 0.0189 (0.0292)	Prec@1 100.000 (99.880)	
Epoch: [4][233/391]	LR: 0.01	DT: 0.000 (0.793)	BT: 0.171 (0.963)	Loss 0.0304 (0.0300)	Prec@1 100.000 (99.860)	
Epoch: [4][311/391]	LR: 0.01	DT: 0.000 (0.773)	BT: 0.170 (0.944)	Loss 0.0287 (0.0294)	Prec@1 100.000 (99.870)	
Epoch: [4][389/391]	LR: 0.01	DT: 0.000 (0.791)	BT: 0.169 (0.962)	Loss 0.0195 (0.0294)	Prec@1 100.000 (99.872)	
Total train loss: 0.0294
Avg Loading time: 0.7885 seconds
Avg Batch time: 0.9594 seconds

Train time: 375.2095332145691
 * Prec@1 94.580 Prec@5 99.790 Loss 0.1810
Avg Loading time: 1.1124 seconds
Avg Batch time: 1.1648 seconds

Best acc: 94.580
--------------------------------------------------------------------------------
Test time: 93.2756757736206

Epoch: [5][77/391]	LR: 0.01	DT: 0.000 (0.772)	BT: 0.168 (0.944)	Loss 0.0312 (0.0243)	Prec@1 99.219 (99.930)	
Epoch: [5][155/391]	LR: 0.01	DT: 0.000 (0.776)	BT: 0.172 (0.948)	Loss 0.0268 (0.0234)	Prec@1 100.000 (99.950)	
Epoch: [5][233/391]	LR: 0.01	DT: 0.112 (0.775)	BT: 0.280 (0.947)	Loss 0.0258 (0.0228)	Prec@1 100.000 (99.960)	
Epoch: [5][311/391]	LR: 0.01	DT: 0.000 (0.771)	BT: 0.185 (0.943)	Loss 0.0269 (0.0226)	Prec@1 100.000 (99.955)	
Epoch: [5][389/391]	LR: 0.01	DT: 0.000 (0.770)	BT: 0.168 (0.942)	Loss 0.0189 (0.0230)	Prec@1 100.000 (99.944)	
Total train loss: 0.0231
Avg Loading time: 0.7680 seconds
Avg Batch time: 0.9396 seconds

Train time: 367.49543476104736
 * Prec@1 94.640 Prec@5 99.770 Loss 0.1790
Avg Loading time: 0.9478 seconds
Avg Batch time: 1.0059 seconds

Best acc: 94.640
--------------------------------------------------------------------------------
Test time: 81.28961253166199

Epoch: [6][77/391]	LR: 0.01	DT: 0.000 (0.760)	BT: 0.167 (0.932)	Loss 0.0135 (0.0207)	Prec@1 100.000 (99.960)	
Epoch: [6][155/391]	LR: 0.01	DT: 0.000 (0.813)	BT: 0.171 (0.984)	Loss 0.0164 (0.0202)	Prec@1 100.000 (99.970)	
Epoch: [6][233/391]	LR: 0.01	DT: 0.000 (0.825)	BT: 0.184 (0.997)	Loss 0.0208 (0.0203)	Prec@1 100.000 (99.973)	
Epoch: [6][311/391]	LR: 0.01	DT: 0.000 (0.805)	BT: 0.172 (0.977)	Loss 0.0236 (0.0204)	Prec@1 100.000 (99.975)	
Epoch: [6][389/391]	LR: 0.01	DT: 0.000 (0.802)	BT: 0.169 (0.974)	Loss 0.0204 (0.0202)	Prec@1 100.000 (99.978)	
Total train loss: 0.0203
Avg Loading time: 0.7999 seconds
Avg Batch time: 0.9714 seconds

Train time: 379.93576312065125
 * Prec@1 94.710 Prec@5 99.770 Loss 0.1748
Avg Loading time: 1.0571 seconds
Avg Batch time: 1.1094 seconds

Best acc: 94.710
--------------------------------------------------------------------------------
Test time: 89.5360791683197

Epoch: [7][77/391]	LR: 0.01	DT: 0.000 (0.768)	BT: 0.171 (0.940)	Loss 0.0296 (0.0199)	Prec@1 100.000 (99.980)	
Epoch: [7][155/391]	LR: 0.01	DT: 0.233 (0.775)	BT: 0.405 (0.947)	Loss 0.0145 (0.0190)	Prec@1 100.000 (99.985)	
Epoch: [7][233/391]	LR: 0.01	DT: 0.000 (0.782)	BT: 0.176 (0.954)	Loss 0.0318 (0.0189)	Prec@1 100.000 (99.990)	
Epoch: [7][311/391]	LR: 0.01	DT: 0.337 (0.772)	BT: 0.504 (0.944)	Loss 0.0199 (0.0190)	Prec@1 100.000 (99.987)	
Epoch: [7][389/391]	LR: 0.01	DT: 0.000 (0.790)	BT: 0.167 (0.962)	Loss 0.0153 (0.0190)	Prec@1 100.000 (99.982)	
Total train loss: 0.0190
Avg Loading time: 0.7882 seconds
Avg Batch time: 0.9601 seconds

Train time: 375.4849576950073
 * Prec@1 94.660 Prec@5 99.770 Loss 0.1760
Avg Loading time: 0.9030 seconds
Avg Batch time: 0.9598 seconds

Best acc: 94.710
--------------------------------------------------------------------------------
Test time: 76.68487358093262

Epoch: [8][77/391]	LR: 0.01	DT: 0.000 (0.734)	BT: 0.172 (0.906)	Loss 0.0232 (0.0180)	Prec@1 100.000 (99.970)	
Epoch: [8][155/391]	LR: 0.01	DT: 0.000 (0.754)	BT: 0.174 (0.926)	Loss 0.0224 (0.0178)	Prec@1 100.000 (99.985)	
Epoch: [8][233/391]	LR: 0.01	DT: 3.027 (0.769)	BT: 3.195 (0.941)	Loss 0.0145 (0.0178)	Prec@1 100.000 (99.990)	
Epoch: [8][311/391]	LR: 0.01	DT: 0.000 (0.761)	BT: 0.170 (0.933)	Loss 0.0133 (0.0177)	Prec@1 100.000 (99.992)	
Epoch: [8][389/391]	LR: 0.01	DT: 0.000 (0.770)	BT: 0.170 (0.942)	Loss 0.0162 (0.0175)	Prec@1 100.000 (99.994)	
Total train loss: 0.0175
Avg Loading time: 0.7676 seconds
Avg Batch time: 0.9396 seconds

Train time: 367.5135200023651
 * Prec@1 94.710 Prec@5 99.810 Loss 0.1766
Avg Loading time: 0.9156 seconds
Avg Batch time: 0.9705 seconds

Best acc: 94.710
--------------------------------------------------------------------------------
Test time: 78.00580167770386

Epoch: [9][77/391]	LR: 0.01	DT: 0.233 (0.722)	BT: 0.405 (0.894)	Loss 0.0128 (0.0164)	Prec@1 100.000 (99.990)	
Epoch: [9][155/391]	LR: 0.01	DT: 0.000 (0.783)	BT: 0.173 (0.955)	Loss 0.0159 (0.0158)	Prec@1 100.000 (99.995)	
Epoch: [9][233/391]	LR: 0.01	DT: 0.000 (0.785)	BT: 0.172 (0.957)	Loss 0.0251 (0.0160)	Prec@1 100.000 (99.997)	
Epoch: [9][311/391]	LR: 0.01	DT: 0.220 (0.768)	BT: 0.392 (0.940)	Loss 0.0125 (0.0160)	Prec@1 100.000 (99.995)	
Epoch: [9][389/391]	LR: 0.01	DT: 0.000 (0.775)	BT: 0.171 (0.947)	Loss 0.0152 (0.0161)	Prec@1 100.000 (99.994)	
Total train loss: 0.0161
Avg Loading time: 0.7726 seconds
Avg Batch time: 0.9449 seconds

Train time: 369.561749458313
 * Prec@1 94.690 Prec@5 99.810 Loss 0.1772
Avg Loading time: 1.0439 seconds
Avg Batch time: 1.0992 seconds

Best acc: 94.710
--------------------------------------------------------------------------------
Test time: 88.6018717288971

Epoch: [10][77/391]	LR: 0.002	DT: 0.000 (0.804)	BT: 0.174 (0.976)	Loss 0.0135 (0.0155)	Prec@1 100.000 (100.000)	
Epoch: [10][155/391]	LR: 0.002	DT: 0.701 (0.791)	BT: 0.867 (0.963)	Loss 0.0126 (0.0156)	Prec@1 100.000 (100.000)	
Epoch: [10][233/391]	LR: 0.002	DT: 0.877 (0.794)	BT: 1.046 (0.966)	Loss 0.0178 (0.0159)	Prec@1 100.000 (99.997)	
Epoch: [10][311/391]	LR: 0.002	DT: 0.000 (0.777)	BT: 0.169 (0.948)	Loss 0.0162 (0.0158)	Prec@1 100.000 (99.997)	
Epoch: [10][389/391]	LR: 0.002	DT: 0.000 (0.794)	BT: 0.168 (0.966)	Loss 0.0148 (0.0157)	Prec@1 100.000 (99.996)	
Total train loss: 0.0157
Avg Loading time: 0.7924 seconds
Avg Batch time: 0.9639 seconds

Train time: 376.95957684516907
 * Prec@1 94.670 Prec@5 99.760 Loss 0.1780
Avg Loading time: 0.9038 seconds
Avg Batch time: 0.9524 seconds

Best acc: 94.710
--------------------------------------------------------------------------------
Test time: 76.41543340682983

Epoch: [11][77/391]	LR: 0.002	DT: 0.000 (0.771)	BT: 0.170 (0.945)	Loss 0.0117 (0.0156)	Prec@1 100.000 (100.000)	
Epoch: [11][155/391]	LR: 0.002	DT: 0.000 (0.784)	BT: 0.175 (0.957)	Loss 0.0137 (0.0157)	Prec@1 100.000 (100.000)	
Epoch: [11][233/391]	LR: 0.002	DT: 1.817 (0.787)	BT: 1.989 (0.960)	Loss 0.0123 (0.0156)	Prec@1 100.000 (99.997)	
Epoch: [11][311/391]	LR: 0.002	DT: 0.000 (0.774)	BT: 0.171 (0.946)	Loss 0.0146 (0.0157)	Prec@1 100.000 (99.997)	
Epoch: [11][389/391]	LR: 0.002	DT: 0.000 (0.778)	BT: 0.171 (0.950)	Loss 0.0108 (0.0159)	Prec@1 100.000 (99.992)	
Total train loss: 0.0159
Avg Loading time: 0.7758 seconds
Avg Batch time: 0.9477 seconds

Train time: 370.71006655693054
 * Prec@1 94.770 Prec@5 99.800 Loss 0.1746
Avg Loading time: 0.9098 seconds
Avg Batch time: 0.9674 seconds

Best acc: 94.770
--------------------------------------------------------------------------------
Test time: 77.97839093208313

Epoch: [12][77/391]	LR: 0.002	DT: 0.000 (0.719)	BT: 0.171 (0.890)	Loss 0.0132 (0.0156)	Prec@1 100.000 (99.990)	
Epoch: [12][155/391]	LR: 0.002	DT: 0.000 (0.754)	BT: 0.168 (0.925)	Loss 0.0239 (0.0157)	Prec@1 100.000 (99.985)	
Epoch: [12][233/391]	LR: 0.002	DT: 1.810 (0.786)	BT: 1.980 (0.957)	Loss 0.0104 (0.0157)	Prec@1 100.000 (99.987)	
Epoch: [12][311/391]	LR: 0.002	DT: 0.000 (0.772)	BT: 0.168 (0.943)	Loss 0.0109 (0.0158)	Prec@1 100.000 (99.990)	
Epoch: [12][389/391]	LR: 0.002	DT: 0.000 (0.775)	BT: 0.172 (0.946)	Loss 0.0155 (0.0155)	Prec@1 100.000 (99.992)	
Total train loss: 0.0155
Avg Loading time: 0.7730 seconds
Avg Batch time: 0.9441 seconds

Train time: 369.25333428382874
 * Prec@1 94.900 Prec@5 99.820 Loss 0.1753
Avg Loading time: 1.0962 seconds
Avg Batch time: 1.1514 seconds

Best acc: 94.900
--------------------------------------------------------------------------------
Test time: 92.06444692611694

Epoch: [13][77/391]	LR: 0.002	DT: 0.000 (0.681)	BT: 0.173 (0.855)	Loss 0.0137 (0.0155)	Prec@1 100.000 (100.000)	
Epoch: [13][155/391]	LR: 0.002	DT: 0.165 (0.734)	BT: 0.334 (0.906)	Loss 0.0146 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [13][233/391]	LR: 0.002	DT: 0.000 (0.755)	BT: 0.170 (0.927)	Loss 0.0111 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [13][311/391]	LR: 0.002	DT: 0.000 (0.754)	BT: 0.172 (0.926)	Loss 0.0121 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [13][389/391]	LR: 0.002	DT: 0.000 (0.769)	BT: 0.170 (0.941)	Loss 0.0137 (0.0152)	Prec@1 100.000 (100.000)	
Total train loss: 0.0152
Avg Loading time: 0.7670 seconds
Avg Batch time: 0.9387 seconds

Train time: 367.1345520019531
 * Prec@1 94.640 Prec@5 99.800 Loss 0.1770
Avg Loading time: 0.9643 seconds
Avg Batch time: 1.0162 seconds

Best acc: 94.900
--------------------------------------------------------------------------------
Test time: 81.00241374969482

Epoch: [14][77/391]	LR: 0.002	DT: 0.000 (0.693)	BT: 0.170 (0.864)	Loss 0.0117 (0.0143)	Prec@1 100.000 (99.990)	
Epoch: [14][155/391]	LR: 0.002	DT: 0.000 (0.743)	BT: 0.169 (0.915)	Loss 0.0163 (0.0145)	Prec@1 100.000 (99.995)	
Epoch: [14][233/391]	LR: 0.002	DT: 0.000 (0.764)	BT: 0.167 (0.935)	Loss 0.0121 (0.0149)	Prec@1 100.000 (99.997)	
Epoch: [14][311/391]	LR: 0.002	DT: 0.000 (0.752)	BT: 0.168 (0.922)	Loss 0.0119 (0.0149)	Prec@1 100.000 (99.997)	
Epoch: [14][389/391]	LR: 0.002	DT: 0.000 (0.764)	BT: 0.170 (0.935)	Loss 0.0127 (0.0149)	Prec@1 100.000 (99.998)	
Total train loss: 0.0149
Avg Loading time: 0.7617 seconds
Avg Batch time: 0.9324 seconds

Train time: 364.70445013046265
 * Prec@1 94.620 Prec@5 99.820 Loss 0.1759
Avg Loading time: 0.9139 seconds
Avg Batch time: 0.9729 seconds

Best acc: 94.900
--------------------------------------------------------------------------------
Test time: 77.56701135635376

Epoch: [15][77/391]	LR: 0.002	DT: 0.000 (0.668)	BT: 0.171 (0.839)	Loss 0.0124 (0.0141)	Prec@1 100.000 (99.990)	
Epoch: [15][155/391]	LR: 0.002	DT: 0.000 (0.721)	BT: 0.173 (0.893)	Loss 0.0150 (0.0147)	Prec@1 100.000 (99.990)	
Epoch: [15][233/391]	LR: 0.002	DT: 1.160 (0.768)	BT: 1.332 (0.941)	Loss 0.0166 (0.0148)	Prec@1 100.000 (99.993)	
Epoch: [15][311/391]	LR: 0.002	DT: 0.000 (0.761)	BT: 0.172 (0.933)	Loss 0.0127 (0.0148)	Prec@1 100.000 (99.995)	
Epoch: [15][389/391]	LR: 0.002	DT: 0.000 (0.775)	BT: 0.168 (0.947)	Loss 0.0168 (0.0148)	Prec@1 100.000 (99.996)	
Total train loss: 0.0148
Avg Loading time: 0.7729 seconds
Avg Batch time: 0.9447 seconds

Train time: 369.50731778144836
 * Prec@1 94.680 Prec@5 99.810 Loss 0.1768
Avg Loading time: 1.0451 seconds
Avg Batch time: 1.0951 seconds

Best acc: 94.900
--------------------------------------------------------------------------------
Test time: 87.40547728538513

Epoch: [16][77/391]	LR: 0.002	DT: 0.000 (0.675)	BT: 0.169 (0.848)	Loss 0.0104 (0.0146)	Prec@1 100.000 (100.000)	
Epoch: [16][155/391]	LR: 0.002	DT: 0.000 (0.724)	BT: 0.171 (0.896)	Loss 0.0127 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [16][233/391]	LR: 0.002	DT: 1.224 (0.752)	BT: 1.398 (0.925)	Loss 0.0281 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [16][311/391]	LR: 0.002	DT: 1.185 (0.756)	BT: 1.360 (0.928)	Loss 0.0161 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [16][389/391]	LR: 0.002	DT: 0.000 (0.771)	BT: 0.170 (0.944)	Loss 0.0121 (0.0151)	Prec@1 100.000 (100.000)	
Total train loss: 0.0151
Avg Loading time: 0.7694 seconds
Avg Batch time: 0.9415 seconds

Train time: 368.2264473438263
 * Prec@1 94.780 Prec@5 99.780 Loss 0.1749
Avg Loading time: 0.9552 seconds
Avg Batch time: 1.0093 seconds

Best acc: 94.900
--------------------------------------------------------------------------------
Test time: 80.36604642868042

Epoch: [17][77/391]	LR: 0.002	DT: 0.000 (0.693)	BT: 0.171 (0.866)	Loss 0.0154 (0.0147)	Prec@1 100.000 (100.000)	
Epoch: [17][155/391]	LR: 0.002	DT: 0.000 (0.749)	BT: 0.170 (0.921)	Loss 0.0104 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [17][233/391]	LR: 0.002	DT: 0.729 (0.842)	BT: 0.910 (1.015)	Loss 0.0134 (0.0153)	Prec@1 100.000 (99.993)	
Epoch: [17][311/391]	LR: 0.002	DT: 0.000 (0.898)	BT: 0.167 (1.070)	Loss 0.0227 (0.0154)	Prec@1 100.000 (99.995)	
Epoch: [17][389/391]	LR: 0.002	DT: 0.000 (0.979)	BT: 0.167 (1.151)	Loss 0.0165 (0.0152)	Prec@1 100.000 (99.996)	
Total train loss: 0.0152
Avg Loading time: 0.9764 seconds
Avg Batch time: 1.1483 seconds

Train time: 449.157915353775
 * Prec@1 94.760 Prec@5 99.800 Loss 0.1771
Avg Loading time: 1.3134 seconds
Avg Batch time: 1.3637 seconds

Best acc: 94.900
--------------------------------------------------------------------------------
Test time: 108.49466300010681

Epoch: [18][77/391]	LR: 0.002	DT: 0.000 (0.713)	BT: 0.169 (0.885)	Loss 0.0104 (0.0155)	Prec@1 100.000 (99.990)	
Epoch: [18][155/391]	LR: 0.002	DT: 0.000 (0.873)	BT: 0.167 (1.045)	Loss 0.0129 (0.0151)	Prec@1 100.000 (99.995)	
Epoch: [18][233/391]	LR: 0.002	DT: 0.000 (0.916)	BT: 0.167 (1.088)	Loss 0.0105 (0.0152)	Prec@1 100.000 (99.993)	
Epoch: [18][311/391]	LR: 0.002	DT: 0.000 (0.932)	BT: 0.169 (1.104)	Loss 0.0198 (0.0154)	Prec@1 100.000 (99.992)	
Epoch: [18][389/391]	LR: 0.002	DT: 0.000 (0.961)	BT: 0.171 (1.132)	Loss 0.0154 (0.0153)	Prec@1 100.000 (99.994)	
Total train loss: 0.0153
Avg Loading time: 0.9583 seconds
Avg Batch time: 1.1299 seconds

Train time: 441.8923888206482
 * Prec@1 94.730 Prec@5 99.830 Loss 0.1766
Avg Loading time: 1.1061 seconds
Avg Batch time: 1.1592 seconds

Best acc: 94.900
--------------------------------------------------------------------------------
Test time: 92.26996874809265

Epoch: [19][77/391]	LR: 0.002	DT: 0.000 (0.682)	BT: 0.169 (0.853)	Loss 0.0133 (0.0152)	Prec@1 100.000 (99.990)	
Epoch: [19][155/391]	LR: 0.002	DT: 0.000 (0.747)	BT: 0.172 (0.919)	Loss 0.0196 (0.0151)	Prec@1 100.000 (99.995)	
Epoch: [19][233/391]	LR: 0.002	DT: 0.000 (0.802)	BT: 0.172 (0.973)	Loss 0.0241 (0.0154)	Prec@1 100.000 (99.993)	
Epoch: [19][311/391]	LR: 0.002	DT: 0.000 (0.830)	BT: 0.171 (1.002)	Loss 0.0173 (0.0156)	Prec@1 100.000 (99.980)	
Epoch: [19][389/391]	LR: 0.002	DT: 0.000 (0.874)	BT: 0.168 (1.046)	Loss 0.0126 (0.0154)	Prec@1 100.000 (99.982)	
Total train loss: 0.0154
Avg Loading time: 0.8714 seconds
Avg Batch time: 1.0432 seconds

Train time: 407.9639332294464
 * Prec@1 94.780 Prec@5 99.810 Loss 0.1750
Avg Loading time: 1.0260 seconds
Avg Batch time: 1.0745 seconds

Best acc: 94.900
--------------------------------------------------------------------------------
Test time: 85.87470769882202

Epoch: [20][77/391]	LR: 0.0004	DT: 0.000 (0.650)	BT: 0.168 (0.822)	Loss 0.0156 (0.0148)	Prec@1 100.000 (100.000)	
Epoch: [20][155/391]	LR: 0.0004	DT: 0.000 (0.716)	BT: 0.170 (0.889)	Loss 0.0219 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [20][233/391]	LR: 0.0004	DT: 1.744 (0.755)	BT: 1.910 (0.927)	Loss 0.0102 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [20][311/391]	LR: 0.0004	DT: 0.000 (0.789)	BT: 0.167 (0.961)	Loss 0.0255 (0.0151)	Prec@1 100.000 (99.995)	
Epoch: [20][389/391]	LR: 0.0004	DT: 0.000 (0.841)	BT: 0.171 (1.013)	Loss 0.0129 (0.0151)	Prec@1 100.000 (99.996)	
Total train loss: 0.0151
Avg Loading time: 0.8386 seconds
Avg Batch time: 1.0103 seconds

Train time: 395.1627197265625
 * Prec@1 94.740 Prec@5 99.820 Loss 0.1761
Avg Loading time: 1.0225 seconds
Avg Batch time: 1.0772 seconds

Best acc: 94.900
--------------------------------------------------------------------------------
Test time: 85.69172835350037

Epoch: [21][77/391]	LR: 0.0004	DT: 0.278 (0.727)	BT: 0.451 (0.900)	Loss 0.0124 (0.0154)	Prec@1 100.000 (99.970)	
Epoch: [21][155/391]	LR: 0.0004	DT: 0.000 (0.769)	BT: 0.171 (0.941)	Loss 0.0132 (0.0150)	Prec@1 100.000 (99.985)	
Epoch: [21][233/391]	LR: 0.0004	DT: 0.000 (0.804)	BT: 0.172 (0.976)	Loss 0.0123 (0.0151)	Prec@1 100.000 (99.987)	
Epoch: [21][311/391]	LR: 0.0004	DT: 0.000 (0.807)	BT: 0.171 (0.978)	Loss 0.0109 (0.0150)	Prec@1 100.000 (99.982)	
Epoch: [21][389/391]	LR: 0.0004	DT: 0.000 (0.832)	BT: 0.173 (1.004)	Loss 0.0190 (0.0150)	Prec@1 100.000 (99.986)	
Total train loss: 0.0150
Avg Loading time: 0.8301 seconds
Avg Batch time: 1.0018 seconds

Train time: 391.8275034427643
 * Prec@1 94.810 Prec@5 99.820 Loss 0.1754
Avg Loading time: 0.9290 seconds
Avg Batch time: 0.9817 seconds

Best acc: 94.900
--------------------------------------------------------------------------------
Test time: 78.13438630104065

Epoch: [22][77/391]	LR: 0.0004	DT: 0.000 (0.630)	BT: 0.169 (0.802)	Loss 0.0154 (0.0147)	Prec@1 100.000 (100.000)	
Epoch: [22][155/391]	LR: 0.0004	DT: 0.000 (0.729)	BT: 0.169 (0.901)	Loss 0.0153 (0.0148)	Prec@1 100.000 (100.000)	
Epoch: [22][233/391]	LR: 0.0004	DT: 0.000 (0.757)	BT: 0.177 (0.929)	Loss 0.0145 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [22][311/391]	LR: 0.0004	DT: 0.000 (0.803)	BT: 0.168 (0.974)	Loss 0.0149 (0.0151)	Prec@1 100.000 (99.995)	
Epoch: [22][389/391]	LR: 0.0004	DT: 0.000 (0.848)	BT: 0.170 (1.020)	Loss 0.0132 (0.0150)	Prec@1 100.000 (99.996)	
Total train loss: 0.0150
Avg Loading time: 0.8460 seconds
Avg Batch time: 1.0178 seconds

Train time: 398.10917830467224
 * Prec@1 94.760 Prec@5 99.790 Loss 0.1760
Avg Loading time: 0.9962 seconds
Avg Batch time: 1.0475 seconds

Best acc: 94.900
--------------------------------------------------------------------------------
Test time: 83.32815289497375

Epoch: [23][77/391]	LR: 0.0004	DT: 0.000 (0.634)	BT: 0.171 (0.807)	Loss 0.0135 (0.0155)	Prec@1 100.000 (99.990)	
Epoch: [23][155/391]	LR: 0.0004	DT: 0.515 (0.714)	BT: 0.688 (0.887)	Loss 0.0141 (0.0156)	Prec@1 100.000 (99.995)	
Epoch: [23][233/391]	LR: 0.0004	DT: 0.816 (0.761)	BT: 0.989 (0.934)	Loss 0.0163 (0.0154)	Prec@1 100.000 (99.993)	
Epoch: [23][311/391]	LR: 0.0004	DT: 0.000 (0.788)	BT: 0.174 (0.961)	Loss 0.0237 (0.0153)	Prec@1 100.000 (99.992)	
Epoch: [23][389/391]	LR: 0.0004	DT: 0.000 (0.863)	BT: 0.195 (1.038)	Loss 0.0102 (0.0152)	Prec@1 100.000 (99.994)	
Total train loss: 0.0152
Avg Loading time: 0.8612 seconds
Avg Batch time: 1.0352 seconds

Train time: 404.86050820350647
 * Prec@1 94.910 Prec@5 99.830 Loss 0.1746
Avg Loading time: 1.1224 seconds
Avg Batch time: 1.1806 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 94.45960688591003

Epoch: [24][77/391]	LR: 0.0004	DT: 0.000 (0.694)	BT: 0.197 (0.892)	Loss 0.0165 (0.0146)	Prec@1 100.000 (100.000)	
Epoch: [24][155/391]	LR: 0.0004	DT: 0.000 (0.777)	BT: 0.169 (0.970)	Loss 0.0191 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [24][233/391]	LR: 0.0004	DT: 0.000 (0.812)	BT: 0.180 (0.997)	Loss 0.0159 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [24][311/391]	LR: 0.0004	DT: 0.000 (0.851)	BT: 0.168 (1.033)	Loss 0.0151 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [24][389/391]	LR: 0.0004	DT: 0.000 (0.894)	BT: 0.167 (1.073)	Loss 0.0138 (0.0153)	Prec@1 100.000 (100.000)	
Total train loss: 0.0152
Avg Loading time: 0.8917 seconds
Avg Batch time: 1.0709 seconds

Train time: 418.87718391418457
 * Prec@1 94.710 Prec@5 99.770 Loss 0.1766
Avg Loading time: 0.9863 seconds
Avg Batch time: 1.0410 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 82.8763074874878

Epoch: [25][77/391]	LR: 0.0004	DT: 0.000 (0.637)	BT: 0.169 (0.809)	Loss 0.0158 (0.0155)	Prec@1 100.000 (99.990)	
Epoch: [25][155/391]	LR: 0.0004	DT: 0.000 (0.730)	BT: 0.169 (0.901)	Loss 0.0161 (0.0153)	Prec@1 100.000 (99.995)	
Epoch: [25][233/391]	LR: 0.0004	DT: 0.000 (0.826)	BT: 0.168 (0.996)	Loss 0.0166 (0.0154)	Prec@1 100.000 (99.997)	
Epoch: [25][311/391]	LR: 0.0004	DT: 0.000 (0.868)	BT: 0.169 (1.038)	Loss 0.0109 (0.0153)	Prec@1 100.000 (99.997)	
Epoch: [25][389/391]	LR: 0.0004	DT: 0.000 (0.926)	BT: 0.170 (1.097)	Loss 0.0135 (0.0151)	Prec@1 100.000 (99.998)	
Total train loss: 0.0151
Avg Loading time: 0.9240 seconds
Avg Batch time: 1.0946 seconds

Train time: 428.0849697589874
 * Prec@1 94.700 Prec@5 99.800 Loss 0.1761
Avg Loading time: 1.2157 seconds
Avg Batch time: 1.2723 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 101.16751432418823

Epoch: [26][77/391]	LR: 0.0004	DT: 0.000 (0.971)	BT: 0.168 (1.142)	Loss 0.0159 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [26][155/391]	LR: 0.0004	DT: 0.000 (1.064)	BT: 0.172 (1.235)	Loss 0.0122 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [26][233/391]	LR: 0.0004	DT: 0.000 (1.102)	BT: 0.167 (1.274)	Loss 0.0119 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [26][311/391]	LR: 0.0004	DT: 0.000 (1.140)	BT: 0.169 (1.312)	Loss 0.0138 (0.0152)	Prec@1 100.000 (99.997)	
Epoch: [26][389/391]	LR: 0.0004	DT: 0.000 (1.153)	BT: 0.170 (1.325)	Loss 0.0157 (0.0151)	Prec@1 100.000 (99.998)	
Total train loss: 0.0151
Avg Loading time: 1.1501 seconds
Avg Batch time: 1.3217 seconds

Train time: 516.8725435733795
 * Prec@1 94.770 Prec@5 99.800 Loss 0.1763
Avg Loading time: 1.3656 seconds
Avg Batch time: 1.4179 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 112.68609046936035

Epoch: [27][77/391]	LR: 0.0004	DT: 1.131 (1.002)	BT: 1.305 (1.175)	Loss 0.0140 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [27][155/391]	LR: 0.0004	DT: 0.000 (1.120)	BT: 0.190 (1.296)	Loss 0.0149 (0.0150)	Prec@1 100.000 (99.995)	
Epoch: [27][233/391]	LR: 0.0004	DT: 0.000 (1.156)	BT: 0.196 (1.337)	Loss 0.0116 (0.0150)	Prec@1 100.000 (99.997)	
Epoch: [27][311/391]	LR: 0.0004	DT: 0.000 (1.183)	BT: 0.170 (1.362)	Loss 0.0237 (0.0150)	Prec@1 100.000 (99.997)	
Epoch: [27][389/391]	LR: 0.0004	DT: 1.601 (1.197)	BT: 1.774 (1.375)	Loss 0.0123 (0.0149)	Prec@1 100.000 (99.998)	
Total train loss: 0.0149
Avg Loading time: 1.1941 seconds
Avg Batch time: 1.3717 seconds

Train time: 536.4586205482483
 * Prec@1 94.670 Prec@5 99.800 Loss 0.1764
Avg Loading time: 1.3804 seconds
Avg Batch time: 1.4295 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 113.57323265075684

Epoch: [28][77/391]	LR: 0.0004	DT: 0.000 (0.798)	BT: 0.173 (0.976)	Loss 0.0138 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [28][155/391]	LR: 0.0004	DT: 0.000 (0.883)	BT: 0.190 (1.063)	Loss 0.0161 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [28][233/391]	LR: 0.0004	DT: 1.846 (0.948)	BT: 2.026 (1.129)	Loss 0.0142 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [28][311/391]	LR: 0.0004	DT: 0.000 (1.017)	BT: 0.187 (1.198)	Loss 0.0121 (0.0151)	Prec@1 100.000 (99.997)	
Epoch: [28][389/391]	LR: 0.0004	DT: 0.000 (1.074)	BT: 0.184 (1.256)	Loss 0.0141 (0.0150)	Prec@1 100.000 (99.998)	
Total train loss: 0.0150
Avg Loading time: 1.0710 seconds
Avg Batch time: 1.2532 seconds

Train time: 490.06164813041687
 * Prec@1 94.880 Prec@5 99.820 Loss 0.1758
Avg Loading time: 1.4049 seconds
Avg Batch time: 1.4559 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 116.20113110542297

Epoch: [29][77/391]	LR: 0.0004	DT: 0.000 (0.748)	BT: 0.173 (0.927)	Loss 0.0180 (0.0147)	Prec@1 100.000 (100.000)	
Epoch: [29][155/391]	LR: 0.0004	DT: 0.000 (0.814)	BT: 0.168 (0.990)	Loss 0.0174 (0.0145)	Prec@1 100.000 (100.000)	
Epoch: [29][233/391]	LR: 0.0004	DT: 2.743 (0.912)	BT: 2.930 (1.088)	Loss 0.0117 (0.0146)	Prec@1 100.000 (99.997)	
Epoch: [29][311/391]	LR: 0.0004	DT: 0.000 (0.943)	BT: 0.189 (1.123)	Loss 0.0175 (0.0146)	Prec@1 100.000 (99.997)	
Epoch: [29][389/391]	LR: 0.0004	DT: 0.000 (1.001)	BT: 0.188 (1.181)	Loss 0.0218 (0.0146)	Prec@1 100.000 (99.996)	
Total train loss: 0.0146
Avg Loading time: 0.9988 seconds
Avg Batch time: 1.1779 seconds

Train time: 460.66710114479065
 * Prec@1 94.800 Prec@5 99.810 Loss 0.1765
Avg Loading time: 1.3999 seconds
Avg Batch time: 1.4541 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 115.95814228057861

Epoch: [30][77/391]	LR: 8e-05	DT: 0.000 (0.787)	BT: 0.167 (0.958)	Loss 0.0152 (0.0143)	Prec@1 100.000 (100.000)	
Epoch: [30][155/391]	LR: 8e-05	DT: 3.308 (0.833)	BT: 3.481 (1.004)	Loss 0.0148 (0.0151)	Prec@1 100.000 (99.985)	
Epoch: [30][233/391]	LR: 8e-05	DT: 0.000 (0.839)	BT: 0.168 (1.010)	Loss 0.0173 (0.0151)	Prec@1 100.000 (99.990)	
Epoch: [30][311/391]	LR: 8e-05	DT: 0.652 (0.870)	BT: 0.825 (1.042)	Loss 0.0104 (0.0149)	Prec@1 100.000 (99.992)	
Epoch: [30][389/391]	LR: 8e-05	DT: 0.000 (0.914)	BT: 0.167 (1.086)	Loss 0.0204 (0.0149)	Prec@1 100.000 (99.994)	
Total train loss: 0.0149
Avg Loading time: 0.9118 seconds
Avg Batch time: 1.0831 seconds

Train time: 423.6486885547638
 * Prec@1 94.770 Prec@5 99.770 Loss 0.1772
Avg Loading time: 1.0751 seconds
Avg Batch time: 1.1312 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 90.70666980743408

Epoch: [31][77/391]	LR: 8e-05	DT: 0.000 (0.763)	BT: 0.168 (0.935)	Loss 0.0136 (0.0155)	Prec@1 100.000 (100.000)	
Epoch: [31][155/391]	LR: 8e-05	DT: 1.083 (1.008)	BT: 1.255 (1.179)	Loss 0.0140 (0.0154)	Prec@1 100.000 (100.000)	
Epoch: [31][233/391]	LR: 8e-05	DT: 3.784 (1.086)	BT: 3.984 (1.258)	Loss 0.0173 (0.0155)	Prec@1 100.000 (100.000)	
Epoch: [31][311/391]	LR: 8e-05	DT: 0.000 (1.105)	BT: 0.172 (1.277)	Loss 0.0124 (0.0154)	Prec@1 100.000 (100.000)	
Epoch: [31][389/391]	LR: 8e-05	DT: 0.000 (1.138)	BT: 0.170 (1.310)	Loss 0.0161 (0.0152)	Prec@1 100.000 (100.000)	
Total train loss: 0.0152
Avg Loading time: 1.1350 seconds
Avg Batch time: 1.3066 seconds

Train time: 511.0216031074524
 * Prec@1 94.740 Prec@5 99.790 Loss 0.1757
Avg Loading time: 1.3616 seconds
Avg Batch time: 1.4079 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 111.81387162208557

Epoch: [32][77/391]	LR: 8e-05	DT: 2.420 (1.005)	BT: 2.596 (1.177)	Loss 0.0124 (0.0142)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 8e-05	DT: 0.000 (0.973)	BT: 0.169 (1.145)	Loss 0.0161 (0.0143)	Prec@1 100.000 (100.000)	
Epoch: [32][233/391]	LR: 8e-05	DT: 0.000 (1.021)	BT: 0.176 (1.193)	Loss 0.0120 (0.0145)	Prec@1 100.000 (100.000)	
Epoch: [32][311/391]	LR: 8e-05	DT: 0.000 (1.045)	BT: 0.171 (1.217)	Loss 0.0143 (0.0145)	Prec@1 100.000 (100.000)	
Epoch: [32][389/391]	LR: 8e-05	DT: 0.195 (1.083)	BT: 0.368 (1.258)	Loss 0.0146 (0.0147)	Prec@1 100.000 (100.000)	
Total train loss: 0.0147
Avg Loading time: 1.0802 seconds
Avg Batch time: 1.2546 seconds

Train time: 490.6550600528717
 * Prec@1 94.780 Prec@5 99.810 Loss 0.1759
Avg Loading time: 1.3340 seconds
Avg Batch time: 1.3907 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 111.53086447715759

Epoch: [33][77/391]	LR: 8e-05	DT: 0.000 (0.863)	BT: 0.171 (1.035)	Loss 0.0164 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [33][155/391]	LR: 8e-05	DT: 0.000 (0.901)	BT: 0.171 (1.073)	Loss 0.0132 (0.0149)	Prec@1 100.000 (99.995)	
Epoch: [33][233/391]	LR: 8e-05	DT: 1.995 (0.924)	BT: 2.164 (1.096)	Loss 0.0111 (0.0149)	Prec@1 100.000 (99.997)	
Epoch: [33][311/391]	LR: 8e-05	DT: 0.000 (0.935)	BT: 0.171 (1.107)	Loss 0.0132 (0.0147)	Prec@1 100.000 (99.997)	
Epoch: [33][389/391]	LR: 8e-05	DT: 0.000 (0.979)	BT: 0.167 (1.151)	Loss 0.0103 (0.0148)	Prec@1 100.000 (99.996)	
Total train loss: 0.0148
Avg Loading time: 0.9761 seconds
Avg Batch time: 1.1485 seconds

Train time: 449.19136214256287
 * Prec@1 94.820 Prec@5 99.810 Loss 0.1765
Avg Loading time: 1.0932 seconds
Avg Batch time: 1.1461 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 92.18281173706055

Epoch: [34][77/391]	LR: 8e-05	DT: 0.000 (0.864)	BT: 0.187 (1.053)	Loss 0.0118 (0.0145)	Prec@1 100.000 (100.000)	
Epoch: [34][155/391]	LR: 8e-05	DT: 0.186 (0.835)	BT: 0.376 (1.025)	Loss 0.0218 (0.0147)	Prec@1 100.000 (100.000)	
Epoch: [34][233/391]	LR: 8e-05	DT: 5.032 (0.856)	BT: 5.205 (1.044)	Loss 0.0175 (0.0151)	Prec@1 100.000 (99.997)	
Epoch: [34][311/391]	LR: 8e-05	DT: 0.000 (0.860)	BT: 0.174 (1.044)	Loss 0.0165 (0.0153)	Prec@1 100.000 (99.997)	
Epoch: [34][389/391]	LR: 8e-05	DT: 0.000 (0.888)	BT: 0.171 (1.069)	Loss 0.0177 (0.0152)	Prec@1 100.000 (99.996)	
Total train loss: 0.0152
Avg Loading time: 0.8855 seconds
Avg Batch time: 1.0670 seconds

Train time: 417.3142454624176
 * Prec@1 94.590 Prec@5 99.800 Loss 0.1755
Avg Loading time: 1.0032 seconds
Avg Batch time: 1.0548 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 85.01909923553467

Epoch: [35][77/391]	LR: 8e-05	DT: 0.000 (0.868)	BT: 0.171 (1.041)	Loss 0.0150 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [35][155/391]	LR: 8e-05	DT: 0.000 (0.840)	BT: 0.170 (1.013)	Loss 0.0246 (0.0154)	Prec@1 100.000 (100.000)	
Epoch: [35][233/391]	LR: 8e-05	DT: 0.000 (0.840)	BT: 0.171 (1.012)	Loss 0.0122 (0.0153)	Prec@1 100.000 (100.000)	
Epoch: [35][311/391]	LR: 8e-05	DT: 0.000 (0.821)	BT: 0.171 (0.992)	Loss 0.0258 (0.0154)	Prec@1 100.000 (99.997)	
Epoch: [35][389/391]	LR: 8e-05	DT: 0.000 (0.825)	BT: 0.172 (0.997)	Loss 0.0412 (0.0154)	Prec@1 99.219 (99.994)	
Total train loss: 0.0154
Avg Loading time: 0.8229 seconds
Avg Batch time: 0.9946 seconds

Train time: 388.99266934394836
 * Prec@1 94.770 Prec@5 99.800 Loss 0.1786
Avg Loading time: 1.0562 seconds
Avg Batch time: 1.1126 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 89.57452201843262

Epoch: [36][77/391]	LR: 8e-05	DT: 0.000 (0.815)	BT: 0.173 (0.986)	Loss 0.0141 (0.0159)	Prec@1 100.000 (100.000)	
Epoch: [36][155/391]	LR: 8e-05	DT: 1.252 (0.810)	BT: 1.423 (0.982)	Loss 0.0148 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [36][233/391]	LR: 8e-05	DT: 0.000 (0.813)	BT: 0.170 (0.985)	Loss 0.0138 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [36][311/391]	LR: 8e-05	DT: 0.000 (0.825)	BT: 0.169 (0.997)	Loss 0.0121 (0.0151)	Prec@1 100.000 (99.997)	
Epoch: [36][389/391]	LR: 8e-05	DT: 0.000 (0.841)	BT: 0.166 (1.012)	Loss 0.0136 (0.0150)	Prec@1 100.000 (99.998)	
Total train loss: 0.0150
Avg Loading time: 0.8386 seconds
Avg Batch time: 1.0100 seconds

Train time: 394.9671678543091
 * Prec@1 94.770 Prec@5 99.810 Loss 0.1738
Avg Loading time: 0.9800 seconds
Avg Batch time: 1.0355 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 83.17643857002258

Epoch: [37][77/391]	LR: 8e-05	DT: 0.000 (0.778)	BT: 0.170 (0.951)	Loss 0.0254 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [37][155/391]	LR: 8e-05	DT: 0.000 (0.783)	BT: 0.169 (0.955)	Loss 0.0164 (0.0151)	Prec@1 100.000 (99.990)	
Epoch: [37][233/391]	LR: 8e-05	DT: 0.332 (0.784)	BT: 0.502 (0.956)	Loss 0.0131 (0.0149)	Prec@1 100.000 (99.993)	
Epoch: [37][311/391]	LR: 8e-05	DT: 0.000 (0.774)	BT: 0.173 (0.946)	Loss 0.0137 (0.0149)	Prec@1 100.000 (99.995)	
Epoch: [37][389/391]	LR: 8e-05	DT: 0.000 (0.779)	BT: 0.167 (0.951)	Loss 0.0128 (0.0151)	Prec@1 100.000 (99.996)	
Total train loss: 0.0151
Avg Loading time: 0.7773 seconds
Avg Batch time: 0.9487 seconds

Train time: 371.0529947280884
 * Prec@1 94.700 Prec@5 99.820 Loss 0.1760
Avg Loading time: 1.1309 seconds
Avg Batch time: 1.1895 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 94.57553172111511

Epoch: [38][77/391]	LR: 8e-05	DT: 0.000 (0.782)	BT: 0.169 (0.953)	Loss 0.0110 (0.0157)	Prec@1 100.000 (99.990)	
Epoch: [38][155/391]	LR: 8e-05	DT: 0.000 (0.797)	BT: 0.170 (0.968)	Loss 0.0150 (0.0149)	Prec@1 100.000 (99.995)	
Epoch: [38][233/391]	LR: 8e-05	DT: 2.292 (0.798)	BT: 2.459 (0.969)	Loss 0.0118 (0.0149)	Prec@1 100.000 (99.997)	
Epoch: [38][311/391]	LR: 8e-05	DT: 0.000 (0.792)	BT: 0.168 (0.963)	Loss 0.0108 (0.0148)	Prec@1 100.000 (99.997)	
Epoch: [38][389/391]	LR: 8e-05	DT: 0.000 (0.807)	BT: 0.167 (0.979)	Loss 0.0155 (0.0147)	Prec@1 100.000 (99.998)	
Total train loss: 0.0147
Avg Loading time: 0.8050 seconds
Avg Batch time: 0.9764 seconds

Train time: 381.8793468475342
 * Prec@1 94.750 Prec@5 99.820 Loss 0.1775
Avg Loading time: 1.0573 seconds
Avg Batch time: 1.1133 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 89.91204595565796

Epoch: [39][77/391]	LR: 8e-05	DT: 0.000 (0.768)	BT: 0.172 (0.940)	Loss 0.0173 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [39][155/391]	LR: 8e-05	DT: 0.000 (0.785)	BT: 0.169 (0.957)	Loss 0.0132 (0.0151)	Prec@1 100.000 (99.995)	
Epoch: [39][233/391]	LR: 8e-05	DT: 0.000 (0.817)	BT: 0.171 (0.988)	Loss 0.0158 (0.0150)	Prec@1 100.000 (99.997)	
Epoch: [39][311/391]	LR: 8e-05	DT: 0.000 (0.800)	BT: 0.167 (0.971)	Loss 0.0118 (0.0150)	Prec@1 100.000 (99.997)	
Epoch: [39][389/391]	LR: 8e-05	DT: 0.000 (0.806)	BT: 0.169 (0.977)	Loss 0.0127 (0.0149)	Prec@1 100.000 (99.996)	
Total train loss: 0.0150
Avg Loading time: 0.8038 seconds
Avg Batch time: 0.9749 seconds

Train time: 381.29749965667725
 * Prec@1 94.820 Prec@5 99.830 Loss 0.1754
Avg Loading time: 0.9566 seconds
Avg Batch time: 1.0129 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 81.77427434921265

Epoch: [40][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.769)	BT: 0.175 (0.940)	Loss 0.0152 (0.0151)	Prec@1 100.000 (100.000)	
Epoch: [40][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.781)	BT: 0.168 (0.953)	Loss 0.0170 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [40][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.788)	BT: 0.175 (0.960)	Loss 0.0127 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [40][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.780)	BT: 0.170 (0.951)	Loss 0.0254 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [40][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.788)	BT: 0.168 (0.960)	Loss 0.0238 (0.0150)	Prec@1 100.000 (99.996)	
Total train loss: 0.0150
Avg Loading time: 0.7862 seconds
Avg Batch time: 0.9577 seconds

Train time: 374.56664967536926
 * Prec@1 94.780 Prec@5 99.800 Loss 0.1785
Avg Loading time: 0.9624 seconds
Avg Batch time: 1.0191 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 81.18302464485168

Epoch: [41][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.779)	BT: 0.175 (0.951)	Loss 0.0109 (0.0149)	Prec@1 100.000 (99.990)	
Epoch: [41][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.787)	BT: 0.170 (0.959)	Loss 0.0107 (0.0151)	Prec@1 100.000 (99.995)	
Epoch: [41][233/391]	LR: 1.6000000000000003e-05	DT: 2.948 (0.798)	BT: 3.117 (0.970)	Loss 0.0136 (0.0152)	Prec@1 100.000 (99.997)	
Epoch: [41][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.778)	BT: 0.172 (0.950)	Loss 0.0198 (0.0152)	Prec@1 100.000 (99.995)	
Epoch: [41][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.778)	BT: 0.168 (0.950)	Loss 0.0134 (0.0151)	Prec@1 100.000 (99.996)	
Total train loss: 0.0151
Avg Loading time: 0.7758 seconds
Avg Batch time: 0.9474 seconds

Train time: 370.56361150741577
 * Prec@1 94.800 Prec@5 99.790 Loss 0.1766
Avg Loading time: 0.9810 seconds
Avg Batch time: 1.0361 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 83.59090232849121

Epoch: [42][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.770)	BT: 0.171 (0.942)	Loss 0.0113 (0.0152)	Prec@1 100.000 (100.000)	
Epoch: [42][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.784)	BT: 0.169 (0.956)	Loss 0.0103 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [42][233/391]	LR: 1.6000000000000003e-05	DT: 0.956 (0.789)	BT: 1.123 (0.961)	Loss 0.0102 (0.0149)	Prec@1 100.000 (99.993)	
Epoch: [42][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.793)	BT: 0.172 (0.965)	Loss 0.0135 (0.0151)	Prec@1 100.000 (99.995)	
Epoch: [42][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.794)	BT: 0.170 (0.965)	Loss 0.0129 (0.0150)	Prec@1 100.000 (99.996)	
Total train loss: 0.0150
Avg Loading time: 0.7915 seconds
Avg Batch time: 0.9628 seconds

Train time: 376.57840967178345
 * Prec@1 94.810 Prec@5 99.840 Loss 0.1760
Avg Loading time: 1.0019 seconds
Avg Batch time: 1.0524 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 84.88806533813477

Epoch: [43][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.767)	BT: 0.171 (0.939)	Loss 0.0178 (0.0148)	Prec@1 100.000 (100.000)	
Epoch: [43][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.778)	BT: 0.171 (0.950)	Loss 0.0133 (0.0149)	Prec@1 100.000 (99.995)	
Epoch: [43][233/391]	LR: 1.6000000000000003e-05	DT: 2.529 (0.788)	BT: 2.702 (0.959)	Loss 0.0134 (0.0150)	Prec@1 100.000 (99.997)	
Epoch: [43][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.777)	BT: 0.169 (0.949)	Loss 0.0133 (0.0150)	Prec@1 100.000 (99.997)	
Epoch: [43][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.783)	BT: 0.168 (0.955)	Loss 0.0184 (0.0150)	Prec@1 100.000 (99.998)	
Total train loss: 0.0150
Avg Loading time: 0.7813 seconds
Avg Batch time: 0.9527 seconds

Train time: 372.5993173122406
 * Prec@1 94.730 Prec@5 99.800 Loss 0.1766
Avg Loading time: 0.8954 seconds
Avg Batch time: 0.9498 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 76.81951975822449

Epoch: [44][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.833)	BT: 0.169 (1.007)	Loss 0.0243 (0.0147)	Prec@1 100.000 (100.000)	
Epoch: [44][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.816)	BT: 0.173 (0.988)	Loss 0.0185 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [44][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.810)	BT: 0.188 (0.982)	Loss 0.0115 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [44][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.788)	BT: 0.170 (0.960)	Loss 0.0103 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [44][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.789)	BT: 0.170 (0.961)	Loss 0.0122 (0.0149)	Prec@1 100.000 (100.000)	
Total train loss: 0.0149
Avg Loading time: 0.7874 seconds
Avg Batch time: 0.9590 seconds

Train time: 375.06489634513855
 * Prec@1 94.750 Prec@5 99.770 Loss 0.1758
Avg Loading time: 0.9622 seconds
Avg Batch time: 1.0194 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 82.2977466583252

Epoch: [45][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.769)	BT: 0.172 (0.941)	Loss 0.0140 (0.0150)	Prec@1 100.000 (100.000)	
Epoch: [45][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.781)	BT: 0.170 (0.953)	Loss 0.0183 (0.0148)	Prec@1 100.000 (99.995)	
Epoch: [45][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.789)	BT: 0.172 (0.961)	Loss 0.0108 (0.0149)	Prec@1 100.000 (99.997)	
Epoch: [45][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.790)	BT: 0.168 (0.962)	Loss 0.0114 (0.0150)	Prec@1 100.000 (99.997)	
Epoch: [45][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.790)	BT: 0.170 (0.962)	Loss 0.0120 (0.0150)	Prec@1 100.000 (99.998)	
Total train loss: 0.0150
Avg Loading time: 0.7881 seconds
Avg Batch time: 0.9597 seconds

Train time: 375.3655331134796
 * Prec@1 94.690 Prec@5 99.810 Loss 0.1763
Avg Loading time: 1.0516 seconds
Avg Batch time: 1.0973 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 88.41967272758484

Epoch: [46][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.772)	BT: 0.174 (0.944)	Loss 0.0126 (0.0145)	Prec@1 100.000 (100.000)	
Epoch: [46][155/391]	LR: 1.6000000000000003e-05	DT: 1.749 (0.779)	BT: 1.918 (0.951)	Loss 0.0134 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [46][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.779)	BT: 0.170 (0.951)	Loss 0.0209 (0.0152)	Prec@1 100.000 (99.997)	
Epoch: [46][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.775)	BT: 0.169 (0.947)	Loss 0.0127 (0.0152)	Prec@1 100.000 (99.997)	
Epoch: [46][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.781)	BT: 0.173 (0.952)	Loss 0.0148 (0.0152)	Prec@1 100.000 (99.998)	
Total train loss: 0.0152
Avg Loading time: 0.7785 seconds
Avg Batch time: 0.9499 seconds

Train time: 371.53438425064087
 * Prec@1 94.800 Prec@5 99.800 Loss 0.1765
Avg Loading time: 0.9019 seconds
Avg Batch time: 0.9617 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 77.69191336631775

Epoch: [47][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.815)	BT: 0.170 (0.988)	Loss 0.0179 (0.0141)	Prec@1 100.000 (100.000)	
Epoch: [47][155/391]	LR: 1.6000000000000003e-05	DT: 2.973 (0.819)	BT: 3.144 (0.991)	Loss 0.0359 (0.0147)	Prec@1 99.219 (99.995)	
Epoch: [47][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.796)	BT: 0.170 (0.968)	Loss 0.0124 (0.0147)	Prec@1 100.000 (99.997)	
Epoch: [47][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.789)	BT: 0.174 (0.961)	Loss 0.0226 (0.0148)	Prec@1 100.000 (99.997)	
Epoch: [47][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.791)	BT: 0.167 (0.963)	Loss 0.0124 (0.0148)	Prec@1 100.000 (99.998)	
Total train loss: 0.0148
Avg Loading time: 0.7890 seconds
Avg Batch time: 0.9609 seconds

Train time: 375.83173990249634
 * Prec@1 94.740 Prec@5 99.830 Loss 0.1774
Avg Loading time: 0.8935 seconds
Avg Batch time: 0.9531 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 77.424968957901

Epoch: [48][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.774)	BT: 0.170 (0.946)	Loss 0.0106 (0.0152)	Prec@1 100.000 (99.980)	
Epoch: [48][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.784)	BT: 0.174 (0.956)	Loss 0.0095 (0.0149)	Prec@1 100.000 (99.990)	
Epoch: [48][233/391]	LR: 1.6000000000000003e-05	DT: 2.416 (0.787)	BT: 2.583 (0.958)	Loss 0.0124 (0.0150)	Prec@1 100.000 (99.993)	
Epoch: [48][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.788)	BT: 0.174 (0.959)	Loss 0.0132 (0.0149)	Prec@1 100.000 (99.995)	
Epoch: [48][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.786)	BT: 0.168 (0.957)	Loss 0.0147 (0.0150)	Prec@1 100.000 (99.996)	
Total train loss: 0.0150
Avg Loading time: 0.7840 seconds
Avg Batch time: 0.9550 seconds

Train time: 373.51623606681824
 * Prec@1 94.640 Prec@5 99.800 Loss 0.1758
Avg Loading time: 1.0354 seconds
Avg Batch time: 1.0820 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 86.43818831443787

Epoch: [49][77/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.764)	BT: 0.171 (0.937)	Loss 0.0160 (0.0145)	Prec@1 100.000 (100.000)	
Epoch: [49][155/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.789)	BT: 0.170 (0.962)	Loss 0.0164 (0.0149)	Prec@1 100.000 (100.000)	
Epoch: [49][233/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.791)	BT: 0.180 (0.963)	Loss 0.0108 (0.0148)	Prec@1 100.000 (100.000)	
Epoch: [49][311/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.779)	BT: 0.171 (0.951)	Loss 0.0117 (0.0148)	Prec@1 100.000 (100.000)	
Epoch: [49][389/391]	LR: 1.6000000000000003e-05	DT: 0.000 (0.789)	BT: 0.170 (0.961)	Loss 0.0140 (0.0148)	Prec@1 100.000 (100.000)	
Total train loss: 0.0148
Avg Loading time: 0.7874 seconds
Avg Batch time: 0.9593 seconds

Train time: 375.18036580085754
 * Prec@1 94.870 Prec@5 99.830 Loss 0.1746
Avg Loading time: 0.9138 seconds
Avg Batch time: 0.9682 seconds

Best acc: 94.910
--------------------------------------------------------------------------------
Test time: 78.07804036140442

