
      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x128/
          savedir: ../pretrained_models/frozen/x128/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram_new
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 0
          frozen_layers: 9
Savedir:  ../pretrained_models/frozen/x128/rram_new/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 0
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x128/rram/one_batch/cifar10/resnet18/train/relu9
Test path:  /home/nano01/a/esoufler/activations/x128/rram_new/one_batch/cifar10/resnet18/test/relu9
ResNet18(
  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 12.960 Prec@5 57.660 Loss 2.2773
Avg Loading time: 0.5823 seconds
Avg Batch time: 0.6061 seconds

Pre-trained Prec@1 with 9 layers frozen: 12.960000038146973 	 Loss: 2.27734375

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (0.958)	BT: 0.081 (1.041)	Loss 0.5684 (0.7130)	Prec@1 81.250 (77.033)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (1.885)	BT: 0.087 (1.969)	Loss 0.4771 (0.5942)	Prec@1 82.812 (80.484)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (2.458)	BT: 0.082 (2.542)	Loss 0.4111 (0.5335)	Prec@1 89.062 (82.422)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (2.907)	BT: 0.085 (2.992)	Loss 0.3088 (0.4957)	Prec@1 91.406 (83.536)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (3.235)	BT: 0.082 (3.320)	Loss 0.2454 (0.4687)	Prec@1 91.406 (84.383)	
Total train loss: 0.4684
Avg Loading time: 3.2269 seconds
Avg Batch time: 3.3117 seconds

Train time: 1295.0048291683197
 * Prec@1 87.620 Prec@5 99.570 Loss 0.3638
Avg Loading time: 4.5170 seconds
Avg Batch time: 4.5380 seconds

Best acc: 87.620
--------------------------------------------------------------------------------
Test time: 360.6234676837921

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (3.689)	BT: 0.081 (3.775)	Loss 0.2157 (0.2160)	Prec@1 93.750 (92.939)	
Epoch: [1][155/391]	LR: 0.1	DT: 2.563 (3.794)	BT: 2.651 (3.880)	Loss 0.3262 (0.2220)	Prec@1 89.062 (92.568)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.413 (3.883)	BT: 0.493 (3.969)	Loss 0.2058 (0.2272)	Prec@1 91.406 (92.361)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (3.851)	BT: 0.083 (3.938)	Loss 0.1588 (0.2301)	Prec@1 96.094 (92.250)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (3.753)	BT: 0.080 (3.839)	Loss 0.2710 (0.2332)	Prec@1 88.281 (92.123)	
Total train loss: 0.2333
Avg Loading time: 3.7434 seconds
Avg Batch time: 3.8294 seconds

Train time: 1497.3641579151154
 * Prec@1 88.110 Prec@5 99.660 Loss 0.3462
Avg Loading time: 2.8998 seconds
Avg Batch time: 2.9218 seconds

Best acc: 88.110
--------------------------------------------------------------------------------
Test time: 231.84720134735107

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (3.363)	BT: 0.082 (3.449)	Loss 0.1862 (0.1314)	Prec@1 92.969 (95.853)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (3.662)	BT: 0.080 (3.749)	Loss 0.1493 (0.1286)	Prec@1 93.750 (95.808)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (3.927)	BT: 0.096 (4.014)	Loss 0.1896 (0.1334)	Prec@1 92.969 (95.566)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (3.965)	BT: 0.079 (4.051)	Loss 0.1672 (0.1382)	Prec@1 92.969 (95.318)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (4.085)	BT: 0.082 (4.172)	Loss 0.1337 (0.1458)	Prec@1 96.094 (94.996)	
Total train loss: 0.1458
Avg Loading time: 4.0748 seconds
Avg Batch time: 4.1612 seconds

Train time: 1627.1922028064728
 * Prec@1 85.710 Prec@5 99.090 Loss 0.4648
Avg Loading time: 4.7780 seconds
Avg Batch time: 4.8040 seconds

Best acc: 88.110
--------------------------------------------------------------------------------
Test time: 380.60504627227783

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (3.434)	BT: 0.105 (3.521)	Loss 0.0709 (0.0948)	Prec@1 99.219 (96.935)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (3.307)	BT: 0.084 (3.393)	Loss 0.1083 (0.0922)	Prec@1 97.656 (96.975)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (2.861)	BT: 0.082 (2.947)	Loss 0.0852 (0.0967)	Prec@1 98.438 (96.788)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (2.325)	BT: 0.082 (2.409)	Loss 0.0586 (0.1009)	Prec@1 96.875 (96.595)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (2.260)	BT: 0.081 (2.344)	Loss 0.0788 (0.1056)	Prec@1 97.656 (96.466)	
Total train loss: 0.1056
Avg Loading time: 2.2542 seconds
Avg Batch time: 2.3386 seconds

Train time: 914.4471321105957
 * Prec@1 89.480 Prec@5 99.520 Loss 0.3564
Avg Loading time: 0.2303 seconds
Avg Batch time: 0.2543 seconds

Best acc: 89.480
--------------------------------------------------------------------------------
Test time: 21.163922786712646

Epoch: [4][77/391]	LR: 0.1	DT: 0.315 (0.186)	BT: 0.399 (0.269)	Loss 0.1295 (0.0737)	Prec@1 95.312 (97.456)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.204)	BT: 0.093 (0.287)	Loss 0.0883 (0.0765)	Prec@1 96.875 (97.386)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.441 (0.207)	BT: 0.520 (0.291)	Loss 0.1013 (0.0807)	Prec@1 96.875 (97.256)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.199)	BT: 0.080 (0.283)	Loss 0.0761 (0.0821)	Prec@1 96.875 (97.228)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.188)	BT: 0.082 (0.272)	Loss 0.0922 (0.0828)	Prec@1 93.750 (97.181)	
Total train loss: 0.0828
Avg Loading time: 0.1870 seconds
Avg Batch time: 0.2716 seconds

Train time: 106.26263213157654
 * Prec@1 89.310 Prec@5 99.590 Loss 0.3513
Avg Loading time: 0.1178 seconds
Avg Batch time: 0.1409 seconds

Best acc: 89.480
--------------------------------------------------------------------------------
Test time: 11.695019006729126

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.133)	BT: 0.082 (0.219)	Loss 0.0257 (0.0565)	Prec@1 100.000 (98.207)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.129)	BT: 0.083 (0.217)	Loss 0.0453 (0.0529)	Prec@1 98.438 (98.332)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.000 (0.110)	BT: 0.096 (0.198)	Loss 0.1028 (0.0558)	Prec@1 95.312 (98.200)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.095)	BT: 0.098 (0.184)	Loss 0.0460 (0.0581)	Prec@1 99.219 (98.124)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.077)	BT: 0.083 (0.166)	Loss 0.0302 (0.0594)	Prec@1 99.219 (98.081)	
Total train loss: 0.0593
Avg Loading time: 0.0767 seconds
Avg Batch time: 0.1656 seconds

Train time: 64.83459115028381
 * Prec@1 88.550 Prec@5 99.510 Loss 0.4009
Avg Loading time: 0.0344 seconds
Avg Batch time: 0.0637 seconds

Best acc: 89.480
--------------------------------------------------------------------------------
Test time: 5.614086151123047

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.205)	BT: 0.083 (0.293)	Loss 0.0169 (0.0438)	Prec@1 99.219 (98.688)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.180)	BT: 0.082 (0.266)	Loss 0.0117 (0.0405)	Prec@1 100.000 (98.823)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.533 (0.198)	BT: 0.612 (0.282)	Loss 0.0669 (0.0405)	Prec@1 97.656 (98.788)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.018 (0.207)	BT: 0.099 (0.291)	Loss 0.0957 (0.0438)	Prec@1 96.094 (98.663)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.210)	BT: 0.080 (0.294)	Loss 0.0574 (0.0474)	Prec@1 97.656 (98.532)	
Total train loss: 0.0478
Avg Loading time: 0.2099 seconds
Avg Batch time: 0.2936 seconds

Train time: 114.88339734077454
 * Prec@1 88.380 Prec@5 99.510 Loss 0.4065
Avg Loading time: 0.3334 seconds
Avg Batch time: 0.3552 seconds

Best acc: 89.480
--------------------------------------------------------------------------------
Test time: 28.61280846595764

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.257)	BT: 0.083 (0.340)	Loss 0.0710 (0.0497)	Prec@1 98.438 (98.357)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.245)	BT: 0.082 (0.328)	Loss 0.0360 (0.0475)	Prec@1 97.656 (98.483)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.073 (0.234)	BT: 0.154 (0.317)	Loss 0.0126 (0.0452)	Prec@1 100.000 (98.568)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.226)	BT: 0.093 (0.309)	Loss 0.0206 (0.0452)	Prec@1 99.219 (98.568)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.225)	BT: 0.095 (0.308)	Loss 0.0432 (0.0456)	Prec@1 99.219 (98.530)	
Total train loss: 0.0456
Avg Loading time: 0.2240 seconds
Avg Batch time: 0.3071 seconds

Train time: 120.13631868362427
 * Prec@1 89.900 Prec@5 99.350 Loss 0.3652
Avg Loading time: 0.3358 seconds
Avg Batch time: 0.3577 seconds

Best acc: 89.900
--------------------------------------------------------------------------------
Test time: 29.244662284851074

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.267)	BT: 0.081 (0.350)	Loss 0.0222 (0.0362)	Prec@1 99.219 (98.888)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.477 (0.258)	BT: 0.561 (0.341)	Loss 0.0884 (0.0371)	Prec@1 98.438 (98.768)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.240)	BT: 0.082 (0.322)	Loss 0.0186 (0.0383)	Prec@1 99.219 (98.781)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.239)	BT: 0.081 (0.322)	Loss 0.0547 (0.0412)	Prec@1 98.438 (98.673)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.237)	BT: 0.096 (0.321)	Loss 0.0268 (0.0452)	Prec@1 99.219 (98.574)	
Total train loss: 0.0452
Avg Loading time: 0.2367 seconds
Avg Batch time: 0.3203 seconds

Train time: 125.29727172851562
 * Prec@1 89.770 Prec@5 99.440 Loss 0.3621
Avg Loading time: 0.3395 seconds
Avg Batch time: 0.3622 seconds

Best acc: 89.900
--------------------------------------------------------------------------------
Test time: 29.177716493606567

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.228)	BT: 0.082 (0.311)	Loss 0.0081 (0.0333)	Prec@1 100.000 (98.928)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.304)	BT: 0.083 (0.387)	Loss 0.0256 (0.0306)	Prec@1 99.219 (99.023)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.329)	BT: 0.082 (0.412)	Loss 0.0533 (0.0313)	Prec@1 97.656 (99.022)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.339)	BT: 0.081 (0.422)	Loss 0.0223 (0.0339)	Prec@1 100.000 (98.936)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.344)	BT: 0.082 (0.426)	Loss 0.0433 (0.0351)	Prec@1 99.219 (98.884)	
Total train loss: 0.0351
Avg Loading time: 0.3428 seconds
Avg Batch time: 0.4254 seconds

Train time: 166.41959047317505
 * Prec@1 88.320 Prec@5 99.200 Loss 0.4165
Avg Loading time: 0.4138 seconds
Avg Batch time: 0.4355 seconds

Best acc: 89.900
--------------------------------------------------------------------------------
Test time: 34.95567846298218

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.331)	BT: 0.083 (0.414)	Loss 0.0133 (0.0213)	Prec@1 100.000 (99.419)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.287)	BT: 0.082 (0.369)	Loss 0.0206 (0.0182)	Prec@1 99.219 (99.509)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.267)	BT: 0.091 (0.350)	Loss 0.0100 (0.0160)	Prec@1 100.000 (99.599)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.286)	BT: 0.083 (0.369)	Loss 0.0076 (0.0141)	Prec@1 100.000 (99.664)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.309)	BT: 0.080 (0.392)	Loss 0.0064 (0.0129)	Prec@1 100.000 (99.710)	
Total train loss: 0.0128
Avg Loading time: 0.3084 seconds
Avg Batch time: 0.3913 seconds

Train time: 153.08473920822144
 * Prec@1 92.700 Prec@5 99.750 Loss 0.2527
Avg Loading time: 0.4343 seconds
Avg Batch time: 0.4550 seconds

Best acc: 92.700
--------------------------------------------------------------------------------
Test time: 36.93942189216614

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.409)	BT: 0.082 (0.491)	Loss 0.0010 (0.0050)	Prec@1 100.000 (99.990)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.401)	BT: 0.081 (0.483)	Loss 0.0026 (0.0046)	Prec@1 100.000 (99.985)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.392)	BT: 0.081 (0.474)	Loss 0.0061 (0.0045)	Prec@1 100.000 (99.987)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.394)	BT: 0.081 (0.476)	Loss 0.0018 (0.0044)	Prec@1 100.000 (99.985)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.390)	BT: 0.081 (0.472)	Loss 0.0014 (0.0044)	Prec@1 100.000 (99.984)	
Total train loss: 0.0044
Avg Loading time: 0.3887 seconds
Avg Batch time: 0.4709 seconds

Train time: 184.17435932159424
 * Prec@1 92.870 Prec@5 99.780 Loss 0.2498
Avg Loading time: 0.3890 seconds
Avg Batch time: 0.4120 seconds

Best acc: 92.870
--------------------------------------------------------------------------------
Test time: 33.537227630615234

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.398)	BT: 0.081 (0.481)	Loss 0.0081 (0.0040)	Prec@1 99.219 (99.960)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.496 (0.338)	BT: 0.578 (0.420)	Loss 0.0053 (0.0040)	Prec@1 100.000 (99.960)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.304)	BT: 0.082 (0.386)	Loss 0.0015 (0.0038)	Prec@1 100.000 (99.970)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.315)	BT: 0.083 (0.398)	Loss 0.0077 (0.0037)	Prec@1 100.000 (99.975)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.325)	BT: 0.080 (0.408)	Loss 0.0010 (0.0037)	Prec@1 100.000 (99.974)	
Total train loss: 0.0037
Avg Loading time: 0.3246 seconds
Avg Batch time: 0.4070 seconds

Train time: 159.18694758415222
 * Prec@1 92.990 Prec@5 99.750 Loss 0.2490
Avg Loading time: 0.5478 seconds
Avg Batch time: 0.5684 seconds

Best acc: 92.990
--------------------------------------------------------------------------------
Test time: 45.94821810722351

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.413)	BT: 0.080 (0.496)	Loss 0.0023 (0.0029)	Prec@1 100.000 (99.990)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.131 (0.402)	BT: 0.218 (0.485)	Loss 0.0026 (0.0033)	Prec@1 100.000 (99.975)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.257 (0.351)	BT: 0.339 (0.434)	Loss 0.0021 (0.0032)	Prec@1 100.000 (99.980)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.323)	BT: 0.082 (0.406)	Loss 0.0010 (0.0032)	Prec@1 100.000 (99.977)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.310)	BT: 0.080 (0.393)	Loss 0.0054 (0.0032)	Prec@1 100.000 (99.980)	
Total train loss: 0.0032
Avg Loading time: 0.3094 seconds
Avg Batch time: 0.3925 seconds

Train time: 153.553377866745
 * Prec@1 92.970 Prec@5 99.750 Loss 0.2512
Avg Loading time: 0.3962 seconds
Avg Batch time: 0.4182 seconds

Best acc: 92.990
--------------------------------------------------------------------------------
Test time: 33.56951904296875

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.469)	BT: 0.081 (0.551)	Loss 0.0023 (0.0025)	Prec@1 100.000 (100.000)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.431)	BT: 0.082 (0.513)	Loss 0.0017 (0.0026)	Prec@1 100.000 (100.000)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.416)	BT: 0.084 (0.499)	Loss 0.0016 (0.0026)	Prec@1 100.000 (99.997)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.402)	BT: 0.081 (0.485)	Loss 0.0017 (0.0026)	Prec@1 100.000 (99.997)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.399)	BT: 0.082 (0.481)	Loss 0.0033 (0.0026)	Prec@1 100.000 (99.998)	
Total train loss: 0.0026
Avg Loading time: 0.3977 seconds
Avg Batch time: 0.4799 seconds

Train time: 187.71527671813965
 * Prec@1 93.100 Prec@5 99.770 Loss 0.2462
Avg Loading time: 0.3672 seconds
Avg Batch time: 0.3902 seconds

Best acc: 93.100
--------------------------------------------------------------------------------
Test time: 31.855631589889526

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.388)	BT: 0.080 (0.470)	Loss 0.0024 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.409)	BT: 0.081 (0.491)	Loss 0.0013 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.406 (0.382)	BT: 0.487 (0.464)	Loss 0.0020 (0.0024)	Prec@1 100.000 (99.997)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.345)	BT: 0.083 (0.427)	Loss 0.0013 (0.0024)	Prec@1 100.000 (99.997)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.331)	BT: 0.080 (0.414)	Loss 0.0027 (0.0024)	Prec@1 100.000 (99.998)	
Total train loss: 0.0024
Avg Loading time: 0.3302 seconds
Avg Batch time: 0.4130 seconds

Train time: 161.53744173049927
 * Prec@1 93.120 Prec@5 99.770 Loss 0.2465
Avg Loading time: 0.3279 seconds
Avg Batch time: 0.3504 seconds

Best acc: 93.120
--------------------------------------------------------------------------------
Test time: 28.70528769493103

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.275)	BT: 0.080 (0.357)	Loss 0.0018 (0.0025)	Prec@1 100.000 (99.990)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.248)	BT: 0.085 (0.331)	Loss 0.0025 (0.0024)	Prec@1 100.000 (99.995)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.237)	BT: 0.084 (0.320)	Loss 0.0027 (0.0024)	Prec@1 100.000 (99.997)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.178)	BT: 0.086 (0.262)	Loss 0.0017 (0.0023)	Prec@1 100.000 (99.997)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.183)	BT: 0.088 (0.268)	Loss 0.0010 (0.0023)	Prec@1 100.000 (99.996)	
Total train loss: 0.0023
Avg Loading time: 0.1822 seconds
Avg Batch time: 0.2671 seconds

Train time: 104.50082659721375
 * Prec@1 93.160 Prec@5 99.770 Loss 0.2434
Avg Loading time: 0.2352 seconds
Avg Batch time: 0.2581 seconds

Best acc: 93.160
--------------------------------------------------------------------------------
Test time: 21.37334966659546

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.223)	BT: 0.081 (0.305)	Loss 0.0026 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.195)	BT: 0.089 (0.277)	Loss 0.0015 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.165)	BT: 0.084 (0.249)	Loss 0.0028 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.147)	BT: 0.096 (0.232)	Loss 0.0015 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.135)	BT: 0.083 (0.221)	Loss 0.0016 (0.0023)	Prec@1 100.000 (100.000)	
Total train loss: 0.0023
Avg Loading time: 0.1349 seconds
Avg Batch time: 0.2207 seconds

Train time: 86.35406255722046
 * Prec@1 93.160 Prec@5 99.740 Loss 0.2487
Avg Loading time: 0.1186 seconds
Avg Batch time: 0.1429 seconds

Best acc: 93.160
--------------------------------------------------------------------------------
Test time: 11.84981894493103

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.081)	BT: 0.088 (0.169)	Loss 0.0026 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.072)	BT: 0.085 (0.161)	Loss 0.0030 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.149 (0.075)	BT: 0.245 (0.164)	Loss 0.0016 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.072)	BT: 0.093 (0.162)	Loss 0.0013 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.073)	BT: 0.081 (0.162)	Loss 0.0026 (0.0022)	Prec@1 100.000 (99.994)	
Total train loss: 0.0022
Avg Loading time: 0.0724 seconds
Avg Batch time: 0.1618 seconds

Train time: 63.35017418861389
 * Prec@1 93.190 Prec@5 99.750 Loss 0.2487
Avg Loading time: 0.1118 seconds
Avg Batch time: 0.1357 seconds

Best acc: 93.190
--------------------------------------------------------------------------------
Test time: 11.740182399749756

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.072)	BT: 0.088 (0.162)	Loss 0.0026 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.460 (0.066)	BT: 0.542 (0.156)	Loss 0.0044 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.058)	BT: 0.092 (0.148)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.056)	BT: 0.094 (0.147)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.060)	BT: 0.096 (0.152)	Loss 0.0025 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0602 seconds
Avg Batch time: 0.1517 seconds

Train time: 59.37476921081543
 * Prec@1 93.020 Prec@5 99.770 Loss 0.2466
Avg Loading time: 0.1046 seconds
Avg Batch time: 0.1297 seconds

Best acc: 93.190
--------------------------------------------------------------------------------
Test time: 10.806200981140137

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.047)	BT: 0.088 (0.133)	Loss 0.0035 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.036)	BT: 0.096 (0.124)	Loss 0.0025 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.032)	BT: 0.084 (0.120)	Loss 0.0023 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.105 (0.113)	Loss 0.0035 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.060 (0.022)	BT: 0.151 (0.111)	Loss 0.0017 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0220 seconds
Avg Batch time: 0.1107 seconds

Train time: 43.34078001976013
 * Prec@1 93.190 Prec@5 99.750 Loss 0.2484
Avg Loading time: 0.1634 seconds
Avg Batch time: 0.1871 seconds

Best acc: 93.190
--------------------------------------------------------------------------------
Test time: 15.326898574829102

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.195)	BT: 0.081 (0.277)	Loss 0.0013 (0.0018)	Prec@1 100.000 (99.990)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.234)	BT: 0.080 (0.317)	Loss 0.0008 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.242)	BT: 0.095 (0.324)	Loss 0.0034 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.253)	BT: 0.083 (0.335)	Loss 0.0016 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.268)	BT: 0.082 (0.350)	Loss 0.0021 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.2678 seconds
Avg Batch time: 0.3496 seconds

Train time: 136.78031086921692
 * Prec@1 93.050 Prec@5 99.750 Loss 0.2484
Avg Loading time: 0.3088 seconds
Avg Batch time: 0.3332 seconds

Best acc: 93.190
--------------------------------------------------------------------------------
Test time: 26.870322942733765

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.281)	BT: 0.081 (0.363)	Loss 0.0040 (0.0022)	Prec@1 100.000 (99.980)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.270)	BT: 0.081 (0.352)	Loss 0.0018 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.149 (0.274)	BT: 0.228 (0.356)	Loss 0.0082 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.277)	BT: 0.080 (0.359)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.992)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.647 (0.279)	BT: 0.730 (0.360)	Loss 0.0035 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.2778 seconds
Avg Batch time: 0.3595 seconds

Train time: 140.6438112258911
 * Prec@1 93.160 Prec@5 99.740 Loss 0.2465
Avg Loading time: 0.2813 seconds
Avg Batch time: 0.3035 seconds

Best acc: 93.190
--------------------------------------------------------------------------------
Test time: 24.531718730926514

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.298)	BT: 0.081 (0.380)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.288)	BT: 0.082 (0.370)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.990)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.280)	BT: 0.083 (0.362)	Loss 0.0017 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.284)	BT: 0.081 (0.366)	Loss 0.0031 (0.0021)	Prec@1 100.000 (99.992)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.290)	BT: 0.082 (0.372)	Loss 0.0026 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.2889 seconds
Avg Batch time: 0.3709 seconds

Train time: 145.08366918563843
 * Prec@1 93.230 Prec@5 99.740 Loss 0.2487
Avg Loading time: 0.3492 seconds
Avg Batch time: 0.3720 seconds

Best acc: 93.230
--------------------------------------------------------------------------------
Test time: 30.364044427871704

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.333)	BT: 0.082 (0.415)	Loss 0.0033 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.318)	BT: 0.082 (0.400)	Loss 0.0018 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.307)	BT: 0.085 (0.389)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.301)	BT: 0.082 (0.383)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.992)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.290)	BT: 0.081 (0.373)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.2895 seconds
Avg Batch time: 0.3718 seconds

Train time: 145.44442105293274
 * Prec@1 93.190 Prec@5 99.730 Loss 0.2472
Avg Loading time: 0.3312 seconds
Avg Batch time: 0.3520 seconds

Best acc: 93.230
--------------------------------------------------------------------------------
Test time: 28.374931573867798

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.262)	BT: 0.080 (0.344)	Loss 0.0024 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.258)	BT: 0.083 (0.340)	Loss 0.0015 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.247)	BT: 0.083 (0.330)	Loss 0.0017 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.240)	BT: 0.081 (0.323)	Loss 0.0017 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.240)	BT: 0.082 (0.323)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.2391 seconds
Avg Batch time: 0.3226 seconds

Train time: 126.22863626480103
 * Prec@1 93.170 Prec@5 99.750 Loss 0.2488
Avg Loading time: 0.2915 seconds
Avg Batch time: 0.3128 seconds

Best acc: 93.230
--------------------------------------------------------------------------------
Test time: 25.27650237083435

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.223)	BT: 0.080 (0.306)	Loss 0.0028 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.238)	BT: 0.087 (0.321)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.534 (0.244)	BT: 0.613 (0.327)	Loss 0.0094 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.233)	BT: 0.082 (0.317)	Loss 0.0053 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.234)	BT: 0.082 (0.318)	Loss 0.0022 (0.0023)	Prec@1 100.000 (99.986)	
Total train loss: 0.0023
Avg Loading time: 0.2337 seconds
Avg Batch time: 0.3173 seconds

Train time: 124.11802554130554
 * Prec@1 93.020 Prec@5 99.740 Loss 0.2496
Avg Loading time: 0.3322 seconds
Avg Batch time: 0.3532 seconds

Best acc: 93.230
--------------------------------------------------------------------------------
Test time: 28.45659899711609

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.235)	BT: 0.091 (0.317)	Loss 0.0077 (0.0024)	Prec@1 99.219 (99.990)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.243)	BT: 0.091 (0.326)	Loss 0.0007 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.249)	BT: 0.081 (0.332)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.241)	BT: 0.083 (0.324)	Loss 0.0020 (0.0020)	Prec@1 100.000 (99.992)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.246)	BT: 0.081 (0.329)	Loss 0.0014 (0.0019)	Prec@1 100.000 (99.994)	
Total train loss: 0.0019
Avg Loading time: 0.2449 seconds
Avg Batch time: 0.3280 seconds

Train time: 128.31553411483765
 * Prec@1 93.240 Prec@5 99.740 Loss 0.2474
Avg Loading time: 0.3727 seconds
Avg Batch time: 0.3945 seconds

Best acc: 93.240
--------------------------------------------------------------------------------
Test time: 32.17364764213562

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.267)	BT: 0.080 (0.349)	Loss 0.0037 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.260)	BT: 0.082 (0.343)	Loss 0.0031 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.242)	BT: 0.095 (0.325)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.243)	BT: 0.080 (0.326)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.252)	BT: 0.082 (0.335)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.2516 seconds
Avg Batch time: 0.3344 seconds

Train time: 130.83516812324524
 * Prec@1 93.250 Prec@5 99.750 Loss 0.2456
Avg Loading time: 0.3254 seconds
Avg Batch time: 0.3474 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 28.441990852355957

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.217)	BT: 0.081 (0.298)	Loss 0.0014 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.233)	BT: 0.085 (0.315)	Loss 0.0016 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.231)	BT: 0.084 (0.314)	Loss 0.0017 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.228)	BT: 0.081 (0.311)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.232)	BT: 0.082 (0.315)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.2312 seconds
Avg Batch time: 0.3143 seconds

Train time: 122.97342324256897
 * Prec@1 93.060 Prec@5 99.750 Loss 0.2482
Avg Loading time: 0.3626 seconds
Avg Batch time: 0.3839 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 30.902788400650024

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.268)	BT: 0.083 (0.350)	Loss 0.0007 (0.0018)	Prec@1 100.000 (99.990)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.257)	BT: 0.083 (0.339)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.270)	BT: 0.085 (0.352)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.268)	BT: 0.081 (0.351)	Loss 0.0014 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.273)	BT: 0.082 (0.356)	Loss 0.0031 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.2720 seconds
Avg Batch time: 0.3549 seconds

Train time: 138.82156944274902
 * Prec@1 93.110 Prec@5 99.750 Loss 0.2498
Avg Loading time: 0.3712 seconds
Avg Batch time: 0.3932 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 31.630128860473633

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.257)	BT: 0.080 (0.339)	Loss 0.0013 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.297)	BT: 0.081 (0.380)	Loss 0.0030 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.361)	BT: 0.082 (0.444)	Loss 0.0054 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.370)	BT: 0.082 (0.452)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.376)	BT: 0.079 (0.459)	Loss 0.0023 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.3753 seconds
Avg Batch time: 0.4577 seconds

Train time: 179.02858686447144
 * Prec@1 93.160 Prec@5 99.750 Loss 0.2468
Avg Loading time: 0.3923 seconds
Avg Batch time: 0.4146 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 33.31797909736633

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.085 (0.100)	Loss 0.0022 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.184 (0.022)	BT: 0.281 (0.110)	Loss 0.0029 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.085)	BT: 0.090 (0.172)	Loss 0.0037 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.797 (0.100)	BT: 0.894 (0.186)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.108)	BT: 0.083 (0.195)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.1081 seconds
Avg Batch time: 0.1946 seconds

Train time: 76.16161441802979
 * Prec@1 93.030 Prec@5 99.730 Loss 0.2502
Avg Loading time: 0.2136 seconds
Avg Batch time: 0.2355 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 19.17835521697998

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.220)	BT: 0.080 (0.303)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.192)	BT: 0.082 (0.276)	Loss 0.0011 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.533 (0.181)	BT: 0.619 (0.265)	Loss 0.0010 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.156)	BT: 0.096 (0.241)	Loss 0.0017 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.141)	BT: 0.095 (0.227)	Loss 0.0017 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.1405 seconds
Avg Batch time: 0.2266 seconds

Train time: 88.65136742591858
 * Prec@1 93.200 Prec@5 99.770 Loss 0.2458
Avg Loading time: 0.1145 seconds
Avg Batch time: 0.1368 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 11.358327865600586

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.060)	BT: 0.096 (0.151)	Loss 0.0014 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.060)	BT: 0.095 (0.151)	Loss 0.0024 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.593 (0.061)	BT: 0.681 (0.152)	Loss 0.0014 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.062)	BT: 0.099 (0.153)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.066)	BT: 0.095 (0.157)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0655 seconds
Avg Batch time: 0.1572 seconds

Train time: 61.534135818481445
 * Prec@1 93.230 Prec@5 99.730 Loss 0.2490
Avg Loading time: 0.1081 seconds
Avg Batch time: 0.1321 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 10.977216005325317

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.077)	BT: 0.096 (0.163)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.096)	BT: 0.095 (0.184)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.022 (0.127)	BT: 0.108 (0.215)	Loss 0.0020 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.117)	BT: 0.098 (0.206)	Loss 0.0029 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.102)	BT: 0.081 (0.191)	Loss 0.0042 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.1021 seconds
Avg Batch time: 0.1904 seconds

Train time: 74.50926542282104
 * Prec@1 93.230 Prec@5 99.740 Loss 0.2469
Avg Loading time: 0.0331 seconds
Avg Batch time: 0.0600 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 5.576807737350464

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.541 (0.050)	BT: 0.626 (0.139)	Loss 0.0026 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.105)	BT: 0.095 (0.194)	Loss 0.0010 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.134)	BT: 0.082 (0.222)	Loss 0.0018 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.161)	BT: 0.084 (0.247)	Loss 0.0024 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.170)	BT: 0.081 (0.255)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.1706 seconds
Avg Batch time: 0.2560 seconds

Train time: 100.16943526268005
 * Prec@1 92.990 Prec@5 99.770 Loss 0.2468
Avg Loading time: 0.3342 seconds
Avg Batch time: 0.3578 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 28.82998752593994

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.235)	BT: 0.083 (0.317)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.242)	BT: 0.079 (0.324)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.184 (0.248)	BT: 0.286 (0.330)	Loss 0.0021 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.249)	BT: 0.082 (0.332)	Loss 0.0019 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.254)	BT: 0.094 (0.337)	Loss 0.0019 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.2535 seconds
Avg Batch time: 0.3363 seconds

Train time: 131.56364822387695
 * Prec@1 93.190 Prec@5 99.760 Loss 0.2462
Avg Loading time: 0.3725 seconds
Avg Batch time: 0.3934 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 31.64497709274292

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.248)	BT: 0.081 (0.330)	Loss 0.0019 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.303)	BT: 0.089 (0.385)	Loss 0.0011 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.291)	BT: 0.083 (0.373)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.279)	BT: 0.081 (0.361)	Loss 0.0025 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.094 (0.278)	BT: 0.174 (0.360)	Loss 0.0023 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.2776 seconds
Avg Batch time: 0.3597 seconds

Train time: 140.7102439403534
 * Prec@1 93.140 Prec@5 99.760 Loss 0.2454
Avg Loading time: 0.3749 seconds
Avg Batch time: 0.3998 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 32.1612389087677

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.263)	BT: 0.081 (0.345)	Loss 0.0027 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.270)	BT: 0.082 (0.352)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 1.156 (0.286)	BT: 1.240 (0.368)	Loss 0.0033 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.292)	BT: 0.083 (0.374)	Loss 0.0023 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.282)	BT: 0.095 (0.365)	Loss 0.0009 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.2815 seconds
Avg Batch time: 0.3640 seconds

Train time: 142.3873074054718
 * Prec@1 93.130 Prec@5 99.740 Loss 0.2476
Avg Loading time: 0.4393 seconds
Avg Batch time: 0.4612 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 36.98692274093628

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.351)	BT: 0.082 (0.433)	Loss 0.0012 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.343)	BT: 0.081 (0.425)	Loss 0.0015 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.339)	BT: 0.083 (0.421)	Loss 0.0032 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.314)	BT: 0.080 (0.396)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.326)	BT: 0.081 (0.408)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.3251 seconds
Avg Batch time: 0.4074 seconds

Train time: 159.3411545753479
 * Prec@1 93.180 Prec@5 99.750 Loss 0.2480
Avg Loading time: 0.4207 seconds
Avg Batch time: 0.4435 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 35.595051527023315

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.297)	BT: 0.081 (0.378)	Loss 0.0010 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.307)	BT: 0.082 (0.389)	Loss 0.0031 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.323)	BT: 0.084 (0.405)	Loss 0.0009 (0.0018)	Prec@1 100.000 (99.997)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.302)	BT: 0.080 (0.384)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.289)	BT: 0.083 (0.371)	Loss 0.0011 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.2881 seconds
Avg Batch time: 0.3704 seconds

Train time: 144.89421486854553
 * Prec@1 93.220 Prec@5 99.740 Loss 0.2498
Avg Loading time: 0.2895 seconds
Avg Batch time: 0.3138 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 25.35076355934143

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.362)	BT: 0.081 (0.444)	Loss 0.0009 (0.0018)	Prec@1 100.000 (99.990)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.347)	BT: 0.081 (0.429)	Loss 0.0016 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.386 (0.314)	BT: 0.470 (0.396)	Loss 0.0021 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.297)	BT: 0.084 (0.379)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.992)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.289)	BT: 0.082 (0.372)	Loss 0.0023 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.2885 seconds
Avg Batch time: 0.3710 seconds

Train time: 145.13764905929565
 * Prec@1 93.060 Prec@5 99.760 Loss 0.2460
Avg Loading time: 0.3085 seconds
Avg Batch time: 0.3318 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 26.762627124786377

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.293)	BT: 0.081 (0.376)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.286)	BT: 0.082 (0.369)	Loss 0.0023 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.239 (0.288)	BT: 0.321 (0.371)	Loss 0.0011 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.108 (0.276)	BT: 0.189 (0.359)	Loss 0.0017 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.290)	BT: 0.080 (0.372)	Loss 0.0034 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.2889 seconds
Avg Batch time: 0.3715 seconds

Train time: 145.3246579170227
 * Prec@1 93.170 Prec@5 99.750 Loss 0.2476
Avg Loading time: 0.3524 seconds
Avg Batch time: 0.3765 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 30.303414583206177

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.314)	BT: 0.083 (0.396)	Loss 0.0014 (0.0023)	Prec@1 100.000 (99.970)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.306)	BT: 0.082 (0.388)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.985)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.290)	BT: 0.082 (0.372)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.987)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.267)	BT: 0.082 (0.350)	Loss 0.0018 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.254)	BT: 0.082 (0.337)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.990)	
Total train loss: 0.0020
Avg Loading time: 0.2535 seconds
Avg Batch time: 0.3365 seconds

Train time: 131.63258934020996
 * Prec@1 93.140 Prec@5 99.730 Loss 0.2496
Avg Loading time: 0.4275 seconds
Avg Batch time: 0.4483 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 35.9828314781189

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.333)	BT: 0.083 (0.416)	Loss 0.0032 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.322)	BT: 0.087 (0.405)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.313)	BT: 0.086 (0.396)	Loss 0.0031 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.303)	BT: 0.081 (0.386)	Loss 0.0018 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.297)	BT: 0.082 (0.379)	Loss 0.0035 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.2961 seconds
Avg Batch time: 0.3784 seconds

Train time: 148.03343725204468
 * Prec@1 93.120 Prec@5 99.750 Loss 0.2494
Avg Loading time: 0.2982 seconds
Avg Batch time: 0.3218 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 25.97827458381653

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.303)	BT: 0.081 (0.385)	Loss 0.0032 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.300)	BT: 0.083 (0.382)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.307)	BT: 0.083 (0.390)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.303)	BT: 0.081 (0.385)	Loss 0.0009 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.284)	BT: 0.080 (0.366)	Loss 0.0011 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.2829 seconds
Avg Batch time: 0.3652 seconds

Train time: 142.86159253120422
 * Prec@1 93.090 Prec@5 99.750 Loss 0.2484
Avg Loading time: 0.0776 seconds
Avg Batch time: 0.1031 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 8.702614545822144

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.100 (0.099)	Loss 0.0021 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.041)	BT: 0.095 (0.130)	Loss 0.0008 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.081)	BT: 0.083 (0.169)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.927 (0.095)	BT: 1.007 (0.182)	Loss 0.0014 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.101)	BT: 0.082 (0.188)	Loss 0.0025 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.1008 seconds
Avg Batch time: 0.1877 seconds

Train time: 73.46407103538513
 * Prec@1 93.030 Prec@5 99.740 Loss 0.2500
Avg Loading time: 0.1499 seconds
Avg Batch time: 0.1702 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 13.988037586212158

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.099)	BT: 0.082 (0.183)	Loss 0.0017 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.098)	BT: 0.084 (0.184)	Loss 0.0019 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.107)	BT: 0.087 (0.193)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.103)	BT: 0.106 (0.190)	Loss 0.0013 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.101)	BT: 0.082 (0.188)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.1009 seconds
Avg Batch time: 0.1881 seconds

Train time: 73.63381290435791
 * Prec@1 93.100 Prec@5 99.730 Loss 0.2505
Avg Loading time: 0.1357 seconds
Avg Batch time: 0.1603 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 13.32522439956665

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.073)	BT: 0.085 (0.163)	Loss 0.0008 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.072)	BT: 0.090 (0.163)	Loss 0.0011 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.090)	BT: 0.095 (0.180)	Loss 0.0050 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.100)	BT: 0.089 (0.190)	Loss 0.0017 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.100)	BT: 0.081 (0.190)	Loss 0.0006 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.0999 seconds
Avg Batch time: 0.1894 seconds

Train time: 74.12065815925598
 * Prec@1 93.180 Prec@5 99.740 Loss 0.2480
Avg Loading time: 0.1046 seconds
Avg Batch time: 0.1263 seconds

Best acc: 93.250
--------------------------------------------------------------------------------
Test time: 10.517568826675415


      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x128/
          savedir: ../pretrained_models/frozen/x128/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram_new
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 0
          frozen_layers: 11
Savedir:  ../pretrained_models/frozen/x128/rram_new/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 0
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x128/rram/one_batch/cifar10/resnet18/train/relu11
Test path:  /home/nano01/a/esoufler/activations/x128/rram_new/one_batch/cifar10/resnet18/test/relu11
ResNet18(
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 8.150 Prec@5 46.660 Loss 2.3359
Avg Loading time: 0.6274 seconds
Avg Batch time: 0.6518 seconds

Pre-trained Prec@1 with 11 layers frozen: 8.149999618530273 	 Loss: 2.3359375

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (1.730)	BT: 0.061 (1.791)	Loss 0.5132 (0.8268)	Prec@1 86.719 (73.758)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (1.775)	BT: 0.062 (1.837)	Loss 0.5195 (0.6797)	Prec@1 82.031 (77.910)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.491 (1.809)	BT: 0.552 (1.871)	Loss 0.3245 (0.6050)	Prec@1 89.062 (80.128)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (1.802)	BT: 0.060 (1.864)	Loss 0.4624 (0.5595)	Prec@1 85.938 (81.473)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (1.834)	BT: 0.060 (1.896)	Loss 0.3943 (0.5274)	Prec@1 86.719 (82.524)	
Total train loss: 0.5272
Avg Loading time: 1.8288 seconds
Avg Batch time: 1.8911 seconds

Train time: 739.5028545856476
 * Prec@1 84.250 Prec@5 99.480 Loss 0.4619
Avg Loading time: 0.4329 seconds
Avg Batch time: 0.4482 seconds

Best acc: 84.250
--------------------------------------------------------------------------------
Test time: 36.30483341217041

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.287)	BT: 0.062 (0.348)	Loss 0.2275 (0.2424)	Prec@1 92.969 (91.937)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.267)	BT: 0.061 (0.328)	Loss 0.2769 (0.2509)	Prec@1 90.625 (91.567)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.156 (0.267)	BT: 0.217 (0.328)	Loss 0.2023 (0.2544)	Prec@1 93.750 (91.503)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.261)	BT: 0.060 (0.322)	Loss 0.2189 (0.2568)	Prec@1 95.312 (91.339)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.265)	BT: 0.061 (0.326)	Loss 0.2871 (0.2593)	Prec@1 89.062 (91.200)	
Total train loss: 0.2594
Avg Loading time: 0.2648 seconds
Avg Batch time: 0.3256 seconds

Train time: 127.39877510070801
 * Prec@1 86.040 Prec@5 99.490 Loss 0.4255
Avg Loading time: 0.3114 seconds
Avg Batch time: 0.3278 seconds

Best acc: 86.040
--------------------------------------------------------------------------------
Test time: 26.814210653305054

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.269)	BT: 0.062 (0.331)	Loss 0.0818 (0.1321)	Prec@1 98.438 (95.964)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.037 (0.244)	BT: 0.098 (0.305)	Loss 0.2087 (0.1422)	Prec@1 92.969 (95.453)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (0.237)	BT: 0.063 (0.298)	Loss 0.1290 (0.1522)	Prec@1 96.094 (95.005)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.239)	BT: 0.061 (0.300)	Loss 0.2451 (0.1577)	Prec@1 91.406 (94.779)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.257)	BT: 0.059 (0.318)	Loss 0.1256 (0.1606)	Prec@1 96.875 (94.611)	
Total train loss: 0.1606
Avg Loading time: 0.2563 seconds
Avg Batch time: 0.3174 seconds

Train time: 124.18047595024109
 * Prec@1 87.210 Prec@5 99.510 Loss 0.3984
Avg Loading time: 0.4463 seconds
Avg Batch time: 0.4622 seconds

Best acc: 87.210
--------------------------------------------------------------------------------
Test time: 37.42205357551575

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.318)	BT: 0.062 (0.379)	Loss 0.0678 (0.0886)	Prec@1 99.219 (97.216)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.317)	BT: 0.061 (0.378)	Loss 0.1403 (0.0903)	Prec@1 94.531 (97.130)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.059 (0.314)	BT: 0.122 (0.376)	Loss 0.0608 (0.0948)	Prec@1 96.875 (96.875)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.312)	BT: 0.060 (0.373)	Loss 0.0749 (0.0985)	Prec@1 96.875 (96.760)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.313)	BT: 0.060 (0.374)	Loss 0.1035 (0.1007)	Prec@1 94.531 (96.635)	
Total train loss: 0.1008
Avg Loading time: 0.3117 seconds
Avg Batch time: 0.3727 seconds

Train time: 145.80550241470337
 * Prec@1 88.540 Prec@5 99.590 Loss 0.3667
Avg Loading time: 0.3527 seconds
Avg Batch time: 0.3691 seconds

Best acc: 88.540
--------------------------------------------------------------------------------
Test time: 30.04726791381836

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.354)	BT: 0.060 (0.416)	Loss 0.0580 (0.0640)	Prec@1 99.219 (97.927)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.366)	BT: 0.062 (0.428)	Loss 0.0712 (0.0635)	Prec@1 97.656 (97.897)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.248 (0.359)	BT: 0.319 (0.420)	Loss 0.0305 (0.0644)	Prec@1 99.219 (97.890)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.352)	BT: 0.062 (0.413)	Loss 0.0562 (0.0686)	Prec@1 98.438 (97.739)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.342)	BT: 0.060 (0.404)	Loss 0.0941 (0.0744)	Prec@1 96.875 (97.540)	
Total train loss: 0.0743
Avg Loading time: 0.3415 seconds
Avg Batch time: 0.4026 seconds

Train time: 157.48176860809326
 * Prec@1 87.250 Prec@5 99.240 Loss 0.4668
Avg Loading time: 0.3936 seconds
Avg Batch time: 0.4093 seconds

Best acc: 88.540
--------------------------------------------------------------------------------
Test time: 32.84680438041687

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.352)	BT: 0.061 (0.413)	Loss 0.0316 (0.0589)	Prec@1 100.000 (98.187)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.335)	BT: 0.061 (0.397)	Loss 0.0367 (0.0536)	Prec@1 99.219 (98.377)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.000 (0.346)	BT: 0.062 (0.407)	Loss 0.0793 (0.0545)	Prec@1 97.656 (98.334)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.333)	BT: 0.061 (0.394)	Loss 0.0799 (0.0586)	Prec@1 97.656 (98.117)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.323)	BT: 0.061 (0.384)	Loss 0.0426 (0.0603)	Prec@1 98.438 (98.071)	
Total train loss: 0.0603
Avg Loading time: 0.3217 seconds
Avg Batch time: 0.3828 seconds

Train time: 149.74521160125732
 * Prec@1 88.050 Prec@5 99.200 Loss 0.4299
Avg Loading time: 0.3341 seconds
Avg Batch time: 0.3516 seconds

Best acc: 88.540
--------------------------------------------------------------------------------
Test time: 28.270970582962036

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.334)	BT: 0.060 (0.394)	Loss 0.0097 (0.0394)	Prec@1 100.000 (98.988)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.336)	BT: 0.061 (0.397)	Loss 0.0120 (0.0382)	Prec@1 99.219 (98.943)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.919 (0.327)	BT: 0.981 (0.388)	Loss 0.0421 (0.0401)	Prec@1 98.438 (98.825)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.320)	BT: 0.061 (0.381)	Loss 0.0451 (0.0412)	Prec@1 97.656 (98.796)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.322)	BT: 0.060 (0.383)	Loss 0.0781 (0.0434)	Prec@1 98.438 (98.722)	
Total train loss: 0.0435
Avg Loading time: 0.3210 seconds
Avg Batch time: 0.3821 seconds

Train time: 149.4631450176239
 * Prec@1 87.040 Prec@5 99.100 Loss 0.4763
Avg Loading time: 0.3188 seconds
Avg Batch time: 0.3350 seconds

Best acc: 88.540
--------------------------------------------------------------------------------
Test time: 26.988577604293823

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.294)	BT: 0.061 (0.355)	Loss 0.0558 (0.0354)	Prec@1 97.656 (98.938)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.298)	BT: 0.061 (0.359)	Loss 0.0065 (0.0334)	Prec@1 100.000 (98.993)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.956 (0.302)	BT: 1.019 (0.364)	Loss 0.0325 (0.0338)	Prec@1 100.000 (98.975)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.299)	BT: 0.061 (0.360)	Loss 0.0566 (0.0361)	Prec@1 97.656 (98.863)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.304)	BT: 0.061 (0.365)	Loss 0.0278 (0.0377)	Prec@1 99.219 (98.824)	
Total train loss: 0.0377
Avg Loading time: 0.3030 seconds
Avg Batch time: 0.3640 seconds

Train time: 142.38821721076965
 * Prec@1 87.580 Prec@5 99.130 Loss 0.4673
Avg Loading time: 0.3379 seconds
Avg Batch time: 0.3514 seconds

Best acc: 88.540
--------------------------------------------------------------------------------
Test time: 28.282397747039795

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.252)	BT: 0.061 (0.313)	Loss 0.0319 (0.0347)	Prec@1 99.219 (98.978)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.101 (0.198)	BT: 0.172 (0.259)	Loss 0.0284 (0.0339)	Prec@1 99.219 (99.058)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.147)	BT: 0.062 (0.210)	Loss 0.0159 (0.0332)	Prec@1 100.000 (99.048)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.110)	BT: 0.064 (0.173)	Loss 0.0448 (0.0327)	Prec@1 97.656 (99.048)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.105)	BT: 0.072 (0.169)	Loss 0.0498 (0.0340)	Prec@1 99.219 (98.994)	
Total train loss: 0.0340
Avg Loading time: 0.1048 seconds
Avg Batch time: 0.1685 seconds

Train time: 65.96036672592163
 * Prec@1 89.050 Prec@5 99.330 Loss 0.4067
Avg Loading time: 0.1946 seconds
Avg Batch time: 0.2122 seconds

Best acc: 89.050
--------------------------------------------------------------------------------
Test time: 17.687490224838257

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.083)	BT: 0.063 (0.144)	Loss 0.0088 (0.0230)	Prec@1 100.000 (99.369)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.067 (0.092)	BT: 0.124 (0.154)	Loss 0.0252 (0.0239)	Prec@1 100.000 (99.354)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.101)	BT: 0.065 (0.164)	Loss 0.1304 (0.0265)	Prec@1 96.094 (99.265)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.098)	BT: 0.064 (0.160)	Loss 0.0306 (0.0286)	Prec@1 99.219 (99.186)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.094)	BT: 0.069 (0.158)	Loss 0.0243 (0.0309)	Prec@1 100.000 (99.095)	
Total train loss: 0.0310
Avg Loading time: 0.0941 seconds
Avg Batch time: 0.1574 seconds

Train time: 61.6098415851593
 * Prec@1 87.760 Prec@5 99.270 Loss 0.4541
Avg Loading time: 0.1122 seconds
Avg Batch time: 0.1293 seconds

Best acc: 89.050
--------------------------------------------------------------------------------
Test time: 10.716721057891846

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.078)	BT: 0.061 (0.142)	Loss 0.0237 (0.0165)	Prec@1 99.219 (99.619)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.063)	BT: 0.061 (0.128)	Loss 0.0124 (0.0138)	Prec@1 99.219 (99.705)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.060)	BT: 0.068 (0.125)	Loss 0.0077 (0.0122)	Prec@1 100.000 (99.760)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.056)	BT: 0.074 (0.122)	Loss 0.0027 (0.0118)	Prec@1 100.000 (99.757)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.055)	BT: 0.062 (0.121)	Loss 0.0029 (0.0110)	Prec@1 100.000 (99.770)	
Total train loss: 0.0110
Avg Loading time: 0.0544 seconds
Avg Batch time: 0.1211 seconds

Train time: 47.4503288269043
 * Prec@1 91.220 Prec@5 99.530 Loss 0.3228
Avg Loading time: 0.0767 seconds
Avg Batch time: 0.0912 seconds

Best acc: 91.220
--------------------------------------------------------------------------------
Test time: 8.11555790901184

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.054)	BT: 0.070 (0.119)	Loss 0.0031 (0.0051)	Prec@1 100.000 (99.940)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.048)	BT: 0.073 (0.114)	Loss 0.0015 (0.0051)	Prec@1 100.000 (99.940)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.386 (0.051)	BT: 0.450 (0.118)	Loss 0.0083 (0.0050)	Prec@1 100.000 (99.950)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.051)	BT: 0.072 (0.119)	Loss 0.0054 (0.0049)	Prec@1 100.000 (99.960)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.049)	BT: 0.065 (0.116)	Loss 0.0100 (0.0047)	Prec@1 100.000 (99.964)	
Total train loss: 0.0047
Avg Loading time: 0.0486 seconds
Avg Batch time: 0.1161 seconds

Train time: 45.475122690200806
 * Prec@1 91.320 Prec@5 99.500 Loss 0.3206
Avg Loading time: 0.1151 seconds
Avg Batch time: 0.1317 seconds

Best acc: 91.320
--------------------------------------------------------------------------------
Test time: 11.298484563827515

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.060)	BT: 0.071 (0.123)	Loss 0.0043 (0.0037)	Prec@1 100.000 (99.980)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.049)	BT: 0.067 (0.115)	Loss 0.0237 (0.0039)	Prec@1 99.219 (99.975)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.047)	BT: 0.068 (0.113)	Loss 0.0034 (0.0039)	Prec@1 100.000 (99.973)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.045)	BT: 0.063 (0.112)	Loss 0.0023 (0.0038)	Prec@1 100.000 (99.975)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.050)	BT: 0.070 (0.116)	Loss 0.0013 (0.0037)	Prec@1 100.000 (99.978)	
Total train loss: 0.0037
Avg Loading time: 0.0497 seconds
Avg Batch time: 0.1162 seconds

Train time: 45.52131652832031
 * Prec@1 91.440 Prec@5 99.550 Loss 0.3203
Avg Loading time: 0.0609 seconds
Avg Batch time: 0.0784 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 7.101244211196899

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.040)	BT: 0.072 (0.108)	Loss 0.0014 (0.0030)	Prec@1 100.000 (99.990)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.043 (0.036)	BT: 0.103 (0.103)	Loss 0.0017 (0.0034)	Prec@1 100.000 (99.970)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.031)	BT: 0.063 (0.098)	Loss 0.0025 (0.0035)	Prec@1 100.000 (99.970)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.027)	BT: 0.071 (0.093)	Loss 0.0012 (0.0034)	Prec@1 100.000 (99.970)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.026)	BT: 0.061 (0.093)	Loss 0.0022 (0.0034)	Prec@1 100.000 (99.970)	
Total train loss: 0.0034
Avg Loading time: 0.0258 seconds
Avg Batch time: 0.0924 seconds

Train time: 36.18697667121887
 * Prec@1 91.330 Prec@5 99.550 Loss 0.3218
Avg Loading time: 0.0400 seconds
Avg Batch time: 0.0586 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 5.139010906219482

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.065 (0.073)	Loss 0.0039 (0.0031)	Prec@1 100.000 (99.990)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.653 (0.020)	BT: 0.725 (0.087)	Loss 0.0047 (0.0029)	Prec@1 100.000 (99.990)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.561 (0.051)	BT: 0.623 (0.118)	Loss 0.0065 (0.0029)	Prec@1 100.000 (99.990)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.082)	BT: 0.061 (0.148)	Loss 0.0015 (0.0028)	Prec@1 100.000 (99.992)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.114)	BT: 0.061 (0.178)	Loss 0.0017 (0.0028)	Prec@1 100.000 (99.994)	
Total train loss: 0.0028
Avg Loading time: 0.1135 seconds
Avg Batch time: 0.1778 seconds

Train time: 69.604896068573
 * Prec@1 91.420 Prec@5 99.490 Loss 0.3193
Avg Loading time: 0.2955 seconds
Avg Batch time: 0.3123 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 25.182915687561035

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.306)	BT: 0.060 (0.366)	Loss 0.0094 (0.0025)	Prec@1 100.000 (100.000)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.337 (0.298)	BT: 0.399 (0.359)	Loss 0.0009 (0.0025)	Prec@1 100.000 (99.995)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.314)	BT: 0.061 (0.375)	Loss 0.0036 (0.0025)	Prec@1 100.000 (99.993)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.302)	BT: 0.061 (0.363)	Loss 0.0029 (0.0025)	Prec@1 100.000 (99.995)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.298)	BT: 0.059 (0.358)	Loss 0.0020 (0.0025)	Prec@1 100.000 (99.996)	
Total train loss: 0.0025
Avg Loading time: 0.2973 seconds
Avg Batch time: 0.3577 seconds

Train time: 139.91411781311035
 * Prec@1 91.360 Prec@5 99.520 Loss 0.3181
Avg Loading time: 0.3615 seconds
Avg Batch time: 0.3754 seconds

Best acc: 91.440
--------------------------------------------------------------------------------
Test time: 30.16714906692505

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.312)	BT: 0.060 (0.372)	Loss 0.0009 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.305)	BT: 0.061 (0.366)	Loss 0.0012 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.247 (0.310)	BT: 0.308 (0.371)	Loss 0.0019 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.296)	BT: 0.060 (0.357)	Loss 0.0034 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.296)	BT: 0.059 (0.356)	Loss 0.0016 (0.0022)	Prec@1 100.000 (99.998)	
Total train loss: 0.0022
Avg Loading time: 0.2951 seconds
Avg Batch time: 0.3555 seconds

Train time: 139.09724617004395
 * Prec@1 91.560 Prec@5 99.530 Loss 0.3169
Avg Loading time: 0.3424 seconds
Avg Batch time: 0.3587 seconds

Best acc: 91.560
--------------------------------------------------------------------------------
Test time: 29.239885330200195

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.293)	BT: 0.059 (0.355)	Loss 0.0014 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.328 (0.299)	BT: 0.388 (0.360)	Loss 0.0027 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.023 (0.298)	BT: 0.083 (0.359)	Loss 0.0010 (0.0023)	Prec@1 100.000 (99.993)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.299)	BT: 0.061 (0.360)	Loss 0.0025 (0.0023)	Prec@1 100.000 (99.995)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.300)	BT: 0.060 (0.360)	Loss 0.0020 (0.0023)	Prec@1 100.000 (99.996)	
Total train loss: 0.0023
Avg Loading time: 0.2991 seconds
Avg Batch time: 0.3597 seconds

Train time: 140.70168495178223
 * Prec@1 91.520 Prec@5 99.520 Loss 0.3191
Avg Loading time: 0.3473 seconds
Avg Batch time: 0.3616 seconds

Best acc: 91.560
--------------------------------------------------------------------------------
Test time: 29.070489406585693

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.274)	BT: 0.060 (0.335)	Loss 0.0019 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.311)	BT: 0.061 (0.372)	Loss 0.0019 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.312)	BT: 0.061 (0.372)	Loss 0.0011 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.309)	BT: 0.060 (0.369)	Loss 0.0009 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.291)	BT: 0.060 (0.352)	Loss 0.0021 (0.0022)	Prec@1 100.000 (99.998)	
Total train loss: 0.0022
Avg Loading time: 0.2902 seconds
Avg Batch time: 0.3507 seconds

Train time: 137.2186369895935
 * Prec@1 91.730 Prec@5 99.510 Loss 0.3188
Avg Loading time: 0.2937 seconds
Avg Batch time: 0.3110 seconds

Best acc: 91.730
--------------------------------------------------------------------------------
Test time: 25.477579355239868

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.231)	BT: 0.061 (0.292)	Loss 0.0019 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.240)	BT: 0.061 (0.300)	Loss 0.0015 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.242)	BT: 0.060 (0.303)	Loss 0.0024 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.236)	BT: 0.061 (0.297)	Loss 0.0018 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.243)	BT: 0.061 (0.304)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.2423 seconds
Avg Batch time: 0.3032 seconds

Train time: 118.63280200958252
 * Prec@1 91.650 Prec@5 99.510 Loss 0.3203
Avg Loading time: 0.2878 seconds
Avg Batch time: 0.3047 seconds

Best acc: 91.730
--------------------------------------------------------------------------------
Test time: 24.55633020401001

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.260)	BT: 0.060 (0.320)	Loss 0.0017 (0.0018)	Prec@1 100.000 (99.990)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.253)	BT: 0.060 (0.313)	Loss 0.0007 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.257)	BT: 0.060 (0.318)	Loss 0.0025 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.252)	BT: 0.060 (0.313)	Loss 0.0018 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.250)	BT: 0.060 (0.310)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.2491 seconds
Avg Batch time: 0.3096 seconds

Train time: 121.12982726097107
 * Prec@1 91.610 Prec@5 99.520 Loss 0.3174
Avg Loading time: 0.2961 seconds
Avg Batch time: 0.3122 seconds

Best acc: 91.730
--------------------------------------------------------------------------------
Test time: 25.18074607849121

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.234)	BT: 0.061 (0.294)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.235)	BT: 0.060 (0.296)	Loss 0.0008 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.259)	BT: 0.060 (0.320)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.249)	BT: 0.060 (0.310)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.278)	BT: 0.061 (0.338)	Loss 0.0014 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.2770 seconds
Avg Batch time: 0.3376 seconds

Train time: 132.06759309768677
 * Prec@1 91.620 Prec@5 99.500 Loss 0.3191
Avg Loading time: 0.2818 seconds
Avg Batch time: 0.2975 seconds

Best acc: 91.730
--------------------------------------------------------------------------------
Test time: 24.06120467185974

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.230)	BT: 0.060 (0.291)	Loss 0.0027 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.233)	BT: 0.061 (0.293)	Loss 0.0038 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.967 (0.223)	BT: 1.028 (0.284)	Loss 0.0025 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.227)	BT: 0.061 (0.288)	Loss 0.0018 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.232)	BT: 0.060 (0.292)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.2313 seconds
Avg Batch time: 0.2918 seconds

Train time: 114.15700697898865
 * Prec@1 91.660 Prec@5 99.500 Loss 0.3176
Avg Loading time: 0.2905 seconds
Avg Batch time: 0.3088 seconds

Best acc: 91.730
--------------------------------------------------------------------------------
Test time: 24.904454708099365

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.373 (0.243)	BT: 0.432 (0.304)	Loss 0.0021 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.248)	BT: 0.061 (0.308)	Loss 0.0013 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.253)	BT: 0.063 (0.314)	Loss 0.0021 (0.0022)	Prec@1 100.000 (99.993)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.233)	BT: 0.062 (0.294)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.992)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.044 (0.219)	BT: 0.104 (0.280)	Loss 0.0022 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.2188 seconds
Avg Batch time: 0.2796 seconds

Train time: 109.4034276008606
 * Prec@1 91.640 Prec@5 99.480 Loss 0.3167
Avg Loading time: 0.2218 seconds
Avg Batch time: 0.2396 seconds

Best acc: 91.730
--------------------------------------------------------------------------------
Test time: 19.43906593322754

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.161)	BT: 0.060 (0.221)	Loss 0.0015 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.153)	BT: 0.070 (0.216)	Loss 0.0040 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.382 (0.168)	BT: 0.445 (0.230)	Loss 0.0089 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.171)	BT: 0.073 (0.233)	Loss 0.0026 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.172)	BT: 0.060 (0.234)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.1719 seconds
Avg Batch time: 0.2337 seconds

Train time: 91.43869519233704
 * Prec@1 91.600 Prec@5 99.480 Loss 0.3188
Avg Loading time: 0.3018 seconds
Avg Batch time: 0.3202 seconds

Best acc: 91.730
--------------------------------------------------------------------------------
Test time: 25.812065362930298

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.191)	BT: 0.061 (0.252)	Loss 0.0021 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.206)	BT: 0.061 (0.266)	Loss 0.0024 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.212)	BT: 0.061 (0.273)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.207)	BT: 0.060 (0.268)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.203)	BT: 0.063 (0.264)	Loss 0.0014 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.2024 seconds
Avg Batch time: 0.2635 seconds

Train time: 103.09288144111633
 * Prec@1 91.580 Prec@5 99.540 Loss 0.3193
Avg Loading time: 0.2675 seconds
Avg Batch time: 0.2847 seconds

Best acc: 91.730
--------------------------------------------------------------------------------
Test time: 23.010924339294434

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.206)	BT: 0.060 (0.266)	Loss 0.0019 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.214)	BT: 0.060 (0.275)	Loss 0.0008 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.187 (0.215)	BT: 0.249 (0.276)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.212)	BT: 0.061 (0.273)	Loss 0.0010 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.211)	BT: 0.060 (0.271)	Loss 0.0007 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.2102 seconds
Avg Batch time: 0.2707 seconds

Train time: 105.92483139038086
 * Prec@1 91.740 Prec@5 99.520 Loss 0.3169
Avg Loading time: 0.2583 seconds
Avg Batch time: 0.2754 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 22.659736156463623

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.211)	BT: 0.061 (0.272)	Loss 0.0035 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.295 (0.199)	BT: 0.354 (0.259)	Loss 0.0011 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.942 (0.222)	BT: 1.003 (0.282)	Loss 0.0049 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.210)	BT: 0.061 (0.270)	Loss 0.0020 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.193)	BT: 0.060 (0.254)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.1923 seconds
Avg Batch time: 0.2532 seconds

Train time: 99.07261323928833
 * Prec@1 91.470 Prec@5 99.530 Loss 0.3196
Avg Loading time: 0.0905 seconds
Avg Batch time: 0.1055 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 8.831779718399048

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.066 (0.071)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.032)	BT: 0.071 (0.097)	Loss 0.0045 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.382 (0.056)	BT: 0.452 (0.121)	Loss 0.0007 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.064)	BT: 0.065 (0.130)	Loss 0.0014 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.068)	BT: 0.064 (0.134)	Loss 0.0024 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0680 seconds
Avg Batch time: 0.1333 seconds

Train time: 52.20549988746643
 * Prec@1 91.740 Prec@5 99.530 Loss 0.3193
Avg Loading time: 0.1372 seconds
Avg Batch time: 0.1545 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 12.724887371063232

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.075)	BT: 0.063 (0.138)	Loss 0.0026 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.062)	BT: 0.078 (0.126)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.110 (0.056)	BT: 0.169 (0.121)	Loss 0.0018 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.056)	BT: 0.072 (0.121)	Loss 0.0014 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.059)	BT: 0.071 (0.125)	Loss 0.0027 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.0587 seconds
Avg Batch time: 0.1245 seconds

Train time: 48.756449699401855
 * Prec@1 91.660 Prec@5 99.490 Loss 0.3191
Avg Loading time: 0.0921 seconds
Avg Batch time: 0.1106 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 9.238102674484253

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.040)	BT: 0.064 (0.108)	Loss 0.0007 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.182 (0.040)	BT: 0.255 (0.107)	Loss 0.0008 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.286 (0.035)	BT: 0.346 (0.102)	Loss 0.0027 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.035)	BT: 0.071 (0.102)	Loss 0.0125 (0.0020)	Prec@1 99.219 (99.995)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.036)	BT: 0.071 (0.103)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0357 seconds
Avg Batch time: 0.1029 seconds

Train time: 40.297117471694946
 * Prec@1 91.610 Prec@5 99.470 Loss 0.3167
Avg Loading time: 0.0769 seconds
Avg Batch time: 0.0937 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 7.91997766494751

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.031)	BT: 0.072 (0.100)	Loss 0.0015 (0.0024)	Prec@1 100.000 (99.980)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.028)	BT: 0.071 (0.095)	Loss 0.0013 (0.0023)	Prec@1 100.000 (99.985)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.028)	BT: 0.067 (0.095)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.029)	BT: 0.069 (0.097)	Loss 0.0014 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.013 (0.030)	BT: 0.074 (0.098)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.988)	
Total train loss: 0.0021
Avg Loading time: 0.0295 seconds
Avg Batch time: 0.0978 seconds

Train time: 38.32604765892029
 * Prec@1 91.730 Prec@5 99.520 Loss 0.3167
Avg Loading time: 0.0729 seconds
Avg Batch time: 0.0925 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 7.801692962646484

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.053)	BT: 0.071 (0.120)	Loss 0.0015 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.048)	BT: 0.068 (0.116)	Loss 0.0026 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.045)	BT: 0.065 (0.113)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.041)	BT: 0.067 (0.108)	Loss 0.0014 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.045 (0.042)	BT: 0.109 (0.109)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0418 seconds
Avg Batch time: 0.1088 seconds

Train time: 42.60383129119873
 * Prec@1 91.680 Prec@5 99.500 Loss 0.3171
Avg Loading time: 0.1070 seconds
Avg Batch time: 0.1235 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 10.260340452194214

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.076)	BT: 0.071 (0.140)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.065)	BT: 0.064 (0.131)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.055)	BT: 0.072 (0.120)	Loss 0.0024 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.049)	BT: 0.062 (0.115)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.997)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.046)	BT: 0.069 (0.112)	Loss 0.0014 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.0455 seconds
Avg Batch time: 0.1117 seconds

Train time: 43.76048970222473
 * Prec@1 91.710 Prec@5 99.500 Loss 0.3191
Avg Loading time: 0.0277 seconds
Avg Batch time: 0.0478 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 4.2726781368255615

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.069 (0.077)	Loss 0.0015 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.073 (0.074)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.077 (0.032)	BT: 0.146 (0.101)	Loss 0.0018 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.047)	BT: 0.061 (0.116)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.055)	BT: 0.060 (0.123)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0552 seconds
Avg Batch time: 0.1228 seconds

Train time: 48.08251667022705
 * Prec@1 91.650 Prec@5 99.490 Loss 0.3188
Avg Loading time: 0.1377 seconds
Avg Batch time: 0.1545 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 12.701972723007202

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.130)	BT: 0.061 (0.191)	Loss 0.0025 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.125)	BT: 0.061 (0.187)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.188 (0.141)	BT: 0.249 (0.203)	Loss 0.0008 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.141)	BT: 0.061 (0.203)	Loss 0.0020 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.145)	BT: 0.060 (0.207)	Loss 0.0075 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.1445 seconds
Avg Batch time: 0.2065 seconds

Train time: 80.81498217582703
 * Prec@1 91.690 Prec@5 99.470 Loss 0.3193
Avg Loading time: 0.2077 seconds
Avg Batch time: 0.2255 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 18.34918236732483

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.123 (0.175)	BT: 0.181 (0.236)	Loss 0.0012 (0.0025)	Prec@1 100.000 (99.980)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.154)	BT: 0.071 (0.215)	Loss 0.0014 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.181 (0.159)	BT: 0.241 (0.221)	Loss 0.0022 (0.0021)	Prec@1 100.000 (99.993)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.161)	BT: 0.061 (0.223)	Loss 0.0021 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.214 (0.159)	BT: 0.273 (0.221)	Loss 0.0022 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.1586 seconds
Avg Batch time: 0.2205 seconds

Train time: 86.27724027633667
 * Prec@1 91.600 Prec@5 99.460 Loss 0.3220
Avg Loading time: 0.2087 seconds
Avg Batch time: 0.2252 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 18.353993892669678

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.169)	BT: 0.060 (0.229)	Loss 0.0015 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.165)	BT: 0.062 (0.226)	Loss 0.0016 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.022 (0.165)	BT: 0.083 (0.226)	Loss 0.0033 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.164)	BT: 0.060 (0.226)	Loss 0.0023 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.163)	BT: 0.060 (0.225)	Loss 0.0010 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.1625 seconds
Avg Batch time: 0.2241 seconds

Train time: 87.67975687980652
 * Prec@1 91.620 Prec@5 99.480 Loss 0.3145
Avg Loading time: 0.2047 seconds
Avg Batch time: 0.2218 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 18.026190757751465

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.157)	BT: 0.066 (0.219)	Loss 0.0008 (0.0021)	Prec@1 100.000 (99.980)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.286 (0.162)	BT: 0.346 (0.224)	Loss 0.0017 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.321 (0.160)	BT: 0.384 (0.221)	Loss 0.0026 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.155)	BT: 0.061 (0.217)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.987)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.157)	BT: 0.061 (0.219)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.990)	
Total train loss: 0.0020
Avg Loading time: 0.1567 seconds
Avg Batch time: 0.2182 seconds

Train time: 85.40052652359009
 * Prec@1 91.610 Prec@5 99.500 Loss 0.3198
Avg Loading time: 0.2144 seconds
Avg Batch time: 0.2309 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 18.752747297286987

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.128)	BT: 0.061 (0.191)	Loss 0.0074 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.148)	BT: 0.060 (0.209)	Loss 0.0010 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.150)	BT: 0.062 (0.213)	Loss 0.0005 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.152)	BT: 0.065 (0.215)	Loss 0.0016 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.154)	BT: 0.060 (0.217)	Loss 0.0010 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.1539 seconds
Avg Batch time: 0.2161 seconds

Train time: 84.56194305419922
 * Prec@1 91.680 Prec@5 99.510 Loss 0.3186
Avg Loading time: 0.2204 seconds
Avg Batch time: 0.2370 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 19.23358964920044

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.165)	BT: 0.060 (0.226)	Loss 0.0011 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.175)	BT: 0.061 (0.237)	Loss 0.0014 (0.0018)	Prec@1 100.000 (99.995)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.173)	BT: 0.062 (0.234)	Loss 0.0017 (0.0019)	Prec@1 100.000 (99.993)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.171)	BT: 0.071 (0.232)	Loss 0.0032 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.178)	BT: 0.060 (0.239)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.996)	
Total train loss: 0.0019
Avg Loading time: 0.1772 seconds
Avg Batch time: 0.2386 seconds

Train time: 93.38553762435913
 * Prec@1 91.640 Prec@5 99.460 Loss 0.3169
Avg Loading time: 0.2221 seconds
Avg Batch time: 0.2373 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 19.23722219467163

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.144)	BT: 0.061 (0.205)	Loss 0.0010 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.133 (0.157)	BT: 0.193 (0.218)	Loss 0.0019 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.617 (0.156)	BT: 0.689 (0.218)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.159)	BT: 0.061 (0.220)	Loss 0.0072 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.160)	BT: 0.071 (0.222)	Loss 0.0017 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.1597 seconds
Avg Batch time: 0.2211 seconds

Train time: 86.52932620048523
 * Prec@1 91.610 Prec@5 99.490 Loss 0.3201
Avg Loading time: 0.2161 seconds
Avg Batch time: 0.2325 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 18.910418033599854

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.151)	BT: 0.060 (0.212)	Loss 0.0014 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.150)	BT: 0.066 (0.212)	Loss 0.0040 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.524 (0.153)	BT: 0.587 (0.215)	Loss 0.0021 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.154)	BT: 0.073 (0.217)	Loss 0.0050 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.156)	BT: 0.060 (0.218)	Loss 0.0009 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.1551 seconds
Avg Batch time: 0.2174 seconds

Train time: 85.07106924057007
 * Prec@1 91.530 Prec@5 99.560 Loss 0.3181
Avg Loading time: 0.2039 seconds
Avg Batch time: 0.2211 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 17.967863082885742

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.158)	BT: 0.061 (0.219)	Loss 0.0026 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.157)	BT: 0.064 (0.219)	Loss 0.0014 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.153)	BT: 0.063 (0.215)	Loss 0.0016 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.146)	BT: 0.062 (0.208)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.069 (0.149)	BT: 0.127 (0.211)	Loss 0.0007 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.1486 seconds
Avg Batch time: 0.2109 seconds

Train time: 82.54477739334106
 * Prec@1 91.650 Prec@5 99.470 Loss 0.3164
Avg Loading time: 0.1855 seconds
Avg Batch time: 0.2033 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 16.578415632247925

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.132)	BT: 0.060 (0.194)	Loss 0.0018 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.135)	BT: 0.061 (0.198)	Loss 0.0014 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.244 (0.143)	BT: 0.304 (0.206)	Loss 0.0020 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.145)	BT: 0.064 (0.208)	Loss 0.0014 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.147)	BT: 0.061 (0.210)	Loss 0.0039 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.1468 seconds
Avg Batch time: 0.2092 seconds

Train time: 81.88961458206177
 * Prec@1 91.600 Prec@5 99.480 Loss 0.3179
Avg Loading time: 0.2046 seconds
Avg Batch time: 0.2205 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 17.916555881500244

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.140)	BT: 0.062 (0.202)	Loss 0.0007 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.150 (0.141)	BT: 0.215 (0.203)	Loss 0.0022 (0.0017)	Prec@1 100.000 (100.000)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.329 (0.150)	BT: 0.388 (0.212)	Loss 0.0007 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.156)	BT: 0.061 (0.218)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.173)	BT: 0.060 (0.235)	Loss 0.0017 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.1726 seconds
Avg Batch time: 0.2345 seconds

Train time: 91.75903820991516
 * Prec@1 91.590 Prec@5 99.500 Loss 0.3154
Avg Loading time: 0.1986 seconds
Avg Batch time: 0.2162 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 17.6128830909729

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.174)	BT: 0.061 (0.235)	Loss 0.0011 (0.0022)	Prec@1 100.000 (99.980)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.177)	BT: 0.062 (0.239)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.197)	BT: 0.062 (0.258)	Loss 0.0017 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.201)	BT: 0.060 (0.262)	Loss 0.0012 (0.0019)	Prec@1 100.000 (99.992)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.206)	BT: 0.060 (0.267)	Loss 0.0019 (0.0019)	Prec@1 100.000 (99.994)	
Total train loss: 0.0019
Avg Loading time: 0.2053 seconds
Avg Batch time: 0.2663 seconds

Train time: 104.19682788848877
 * Prec@1 91.530 Prec@5 99.480 Loss 0.3179
Avg Loading time: 0.1945 seconds
Avg Batch time: 0.2106 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 17.150741815567017

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.168)	BT: 0.060 (0.229)	Loss 0.0037 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.160)	BT: 0.060 (0.222)	Loss 0.0008 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.160)	BT: 0.060 (0.222)	Loss 0.0022 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.158)	BT: 0.063 (0.220)	Loss 0.0033 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.157)	BT: 0.067 (0.219)	Loss 0.0037 (0.0019)	Prec@1 100.000 (99.998)	
Total train loss: 0.0019
Avg Loading time: 0.1566 seconds
Avg Batch time: 0.2186 seconds

Train time: 85.54352712631226
 * Prec@1 91.640 Prec@5 99.470 Loss 0.3201
Avg Loading time: 0.2090 seconds
Avg Batch time: 0.2257 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 18.347941637039185

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.192)	BT: 0.062 (0.252)	Loss 0.0008 (0.0016)	Prec@1 100.000 (100.000)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.189)	BT: 0.060 (0.250)	Loss 0.0019 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.146 (0.198)	BT: 0.207 (0.259)	Loss 0.0017 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.203)	BT: 0.060 (0.264)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.203)	BT: 0.059 (0.264)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Total train loss: 0.0018
Avg Loading time: 0.2028 seconds
Avg Batch time: 0.2636 seconds

Train time: 103.15053009986877
 * Prec@1 91.660 Prec@5 99.500 Loss 0.3193
Avg Loading time: 0.2877 seconds
Avg Batch time: 0.3055 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 24.654427528381348

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.030 (0.196)	BT: 0.090 (0.256)	Loss 0.0024 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.212)	BT: 0.061 (0.272)	Loss 0.0031 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.214)	BT: 0.064 (0.275)	Loss 0.0069 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.216)	BT: 0.061 (0.276)	Loss 0.0014 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.217)	BT: 0.059 (0.278)	Loss 0.0028 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.2166 seconds
Avg Batch time: 0.2772 seconds

Train time: 108.4655294418335
 * Prec@1 91.650 Prec@5 99.520 Loss 0.3184
Avg Loading time: 0.2489 seconds
Avg Batch time: 0.2649 seconds

Best acc: 91.740
--------------------------------------------------------------------------------
Test time: 21.46168804168701

