
      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x128/
          savedir: ../pretrained_models/frozen/x128/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram_new
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 5
Savedir:  ../pretrained_models/frozen/x128/rram_new/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x128/rram/one_batch/cifar10/resnet18/train/relu5
Test path:  /home/nano01/a/esoufler/activations/x128/rram_new/one_batch/cifar10/resnet18/test/relu5
ResNet18(
  (conv6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv1): Sequential(
    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu6): ReLU(inplace=True)
  (conv7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu7): ReLU(inplace=True)
  (conv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 8.800 Prec@5 42.920 Loss 2.3359
Avg Loading time: 2.0319 seconds
Avg Batch time: 2.0769 seconds

Pre-trained Prec@1 with 5 layers frozen: 8.800000190734863 	 Loss: 2.3359375

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (2.137)	BT: 0.140 (2.279)	Loss 0.3711 (0.8038)	Prec@1 88.281 (73.838)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (2.030)	BT: 0.138 (2.172)	Loss 0.4360 (0.6393)	Prec@1 85.938 (78.941)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (1.859)	BT: 0.150 (2.001)	Loss 0.2991 (0.5622)	Prec@1 91.406 (81.303)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (1.702)	BT: 0.144 (1.844)	Loss 0.3301 (0.5148)	Prec@1 88.281 (82.772)	
Epoch: [0][389/391]	LR: 0.1	DT: 1.017 (1.629)	BT: 1.160 (1.772)	Loss 0.3606 (0.4826)	Prec@1 89.062 (83.838)	
Total train loss: 0.4823
Avg Loading time: 1.6249 seconds
Avg Batch time: 1.7678 seconds

Train time: 691.3196213245392
 * Prec@1 86.090 Prec@5 99.630 Loss 0.4082
Avg Loading time: 0.1316 seconds
Avg Batch time: 0.1966 seconds

Best acc: 86.090
--------------------------------------------------------------------------------
Test time: 16.630303621292114

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.027)	BT: 0.201 (0.231)	Loss 0.2175 (0.2511)	Prec@1 90.625 (91.757)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.026)	BT: 0.173 (0.225)	Loss 0.2620 (0.2432)	Prec@1 92.969 (91.942)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.019)	BT: 0.240 (0.219)	Loss 0.2344 (0.2544)	Prec@1 91.406 (91.450)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.173 (0.217)	Loss 0.1810 (0.2539)	Prec@1 95.312 (91.511)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.011)	BT: 0.151 (0.216)	Loss 0.2827 (0.2503)	Prec@1 88.281 (91.603)	
Total train loss: 0.2505
Avg Loading time: 0.0112 seconds
Avg Batch time: 0.2160 seconds

Train time: 84.60266494750977
 * Prec@1 87.460 Prec@5 99.460 Loss 0.3816
Avg Loading time: 0.0780 seconds
Avg Batch time: 0.1454 seconds

Best acc: 87.460
--------------------------------------------------------------------------------
Test time: 12.674372911453247

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.211 (0.237)	Loss 0.1024 (0.1566)	Prec@1 96.094 (94.872)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.015)	BT: 0.173 (0.223)	Loss 0.1389 (0.1555)	Prec@1 94.531 (94.907)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (0.010)	BT: 0.263 (0.216)	Loss 0.2429 (0.1593)	Prec@1 91.406 (94.715)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.171 (0.214)	Loss 0.1565 (0.1612)	Prec@1 94.531 (94.584)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.163 (0.213)	Loss 0.1980 (0.1667)	Prec@1 92.188 (94.349)	
Total train loss: 0.1667
Avg Loading time: 0.0061 seconds
Avg Batch time: 0.2124 seconds

Train time: 83.18671464920044
 * Prec@1 89.430 Prec@5 99.570 Loss 0.3225
Avg Loading time: 0.0874 seconds
Avg Batch time: 0.1575 seconds

Best acc: 89.430
--------------------------------------------------------------------------------
Test time: 13.620108842849731

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.029)	BT: 0.180 (0.238)	Loss 0.0880 (0.1121)	Prec@1 97.656 (96.224)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.169 (0.220)	Loss 0.1366 (0.1103)	Prec@1 95.312 (96.254)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.010)	BT: 0.193 (0.215)	Loss 0.2529 (0.1151)	Prec@1 92.969 (96.070)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.214 (0.215)	Loss 0.0974 (0.1190)	Prec@1 95.312 (95.936)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.169 (0.212)	Loss 0.1284 (0.1212)	Prec@1 96.094 (95.845)	
Total train loss: 0.1213
Avg Loading time: 0.0062 seconds
Avg Batch time: 0.2121 seconds

Train time: 83.06750297546387
 * Prec@1 88.430 Prec@5 99.680 Loss 0.3601
Avg Loading time: 0.0741 seconds
Avg Batch time: 0.1544 seconds

Best acc: 89.430
--------------------------------------------------------------------------------
Test time: 12.84839653968811

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.027)	BT: 0.193 (0.239)	Loss 0.0557 (0.0801)	Prec@1 99.219 (97.446)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.006 (0.014)	BT: 0.214 (0.223)	Loss 0.1074 (0.0821)	Prec@1 96.875 (97.406)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.009)	BT: 0.199 (0.216)	Loss 0.1134 (0.0860)	Prec@1 96.875 (97.229)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.262 (0.215)	Loss 0.1986 (0.0892)	Prec@1 93.750 (97.053)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.187 (0.213)	Loss 0.1013 (0.0930)	Prec@1 95.312 (96.881)	
Total train loss: 0.0930
Avg Loading time: 0.0057 seconds
Avg Batch time: 0.2126 seconds

Train time: 83.22649145126343
 * Prec@1 87.760 Prec@5 99.500 Loss 0.4067
Avg Loading time: 0.0840 seconds
Avg Batch time: 0.1575 seconds

Best acc: 89.430
--------------------------------------------------------------------------------
Test time: 13.10390591621399

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.029)	BT: 0.210 (0.235)	Loss 0.0662 (0.0750)	Prec@1 97.656 (97.666)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.002 (0.015)	BT: 0.180 (0.219)	Loss 0.0515 (0.0744)	Prec@1 97.656 (97.606)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.002 (0.010)	BT: 0.218 (0.213)	Loss 0.1084 (0.0750)	Prec@1 92.969 (97.526)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.206 (0.212)	Loss 0.0532 (0.0773)	Prec@1 98.438 (97.473)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.151 (0.210)	Loss 0.0601 (0.0808)	Prec@1 97.656 (97.344)	
Total train loss: 0.0808
Avg Loading time: 0.0062 seconds
Avg Batch time: 0.2095 seconds

Train time: 82.01954317092896
 * Prec@1 89.240 Prec@5 99.560 Loss 0.3579
Avg Loading time: 0.0900 seconds
Avg Batch time: 0.1613 seconds

Best acc: 89.430
--------------------------------------------------------------------------------
Test time: 13.398700714111328

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.037)	BT: 0.223 (0.239)	Loss 0.0681 (0.0550)	Prec@1 97.656 (98.227)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.000 (0.019)	BT: 0.166 (0.222)	Loss 0.0446 (0.0572)	Prec@1 98.438 (98.102)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.013)	BT: 0.244 (0.218)	Loss 0.0641 (0.0545)	Prec@1 98.438 (98.231)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.010)	BT: 0.204 (0.217)	Loss 0.0505 (0.0585)	Prec@1 98.438 (98.097)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.151 (0.214)	Loss 0.0521 (0.0617)	Prec@1 97.656 (97.949)	
Total train loss: 0.0617
Avg Loading time: 0.0077 seconds
Avg Batch time: 0.2139 seconds

Train time: 83.75405168533325
 * Prec@1 89.190 Prec@5 99.630 Loss 0.3579
Avg Loading time: 0.0785 seconds
Avg Batch time: 0.1537 seconds

Best acc: 89.430
--------------------------------------------------------------------------------
Test time: 12.791764974594116

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.228 (0.236)	Loss 0.0248 (0.0534)	Prec@1 100.000 (98.377)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.189 (0.220)	Loss 0.0319 (0.0507)	Prec@1 99.219 (98.417)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.001 (0.010)	BT: 0.274 (0.216)	Loss 0.0299 (0.0500)	Prec@1 99.219 (98.448)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.202 (0.217)	Loss 0.0410 (0.0530)	Prec@1 98.438 (98.330)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.161 (0.213)	Loss 0.0691 (0.0562)	Prec@1 98.438 (98.203)	
Total train loss: 0.0563
Avg Loading time: 0.0059 seconds
Avg Batch time: 0.2125 seconds

Train time: 83.19689989089966
 * Prec@1 89.030 Prec@5 99.280 Loss 0.4121
Avg Loading time: 0.0841 seconds
Avg Batch time: 0.1668 seconds

Best acc: 89.430
--------------------------------------------------------------------------------
Test time: 13.826158285140991

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.026)	BT: 0.209 (0.227)	Loss 0.0391 (0.0464)	Prec@1 98.438 (98.478)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.013)	BT: 0.172 (0.215)	Loss 0.0376 (0.0455)	Prec@1 98.438 (98.533)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.000 (0.009)	BT: 0.200 (0.213)	Loss 0.0868 (0.0466)	Prec@1 96.875 (98.541)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.001 (0.007)	BT: 0.258 (0.212)	Loss 0.0617 (0.0484)	Prec@1 98.438 (98.405)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.173 (0.209)	Loss 0.0423 (0.0501)	Prec@1 98.438 (98.353)	
Total train loss: 0.0501
Avg Loading time: 0.0057 seconds
Avg Batch time: 0.2083 seconds

Train time: 81.55626964569092
 * Prec@1 90.640 Prec@5 99.650 Loss 0.3184
Avg Loading time: 0.1003 seconds
Avg Batch time: 0.1707 seconds

Best acc: 90.640
--------------------------------------------------------------------------------
Test time: 14.611411809921265

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.024)	BT: 0.263 (0.232)	Loss 0.0375 (0.0316)	Prec@1 98.438 (99.139)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.012)	BT: 0.226 (0.217)	Loss 0.0777 (0.0340)	Prec@1 97.656 (99.003)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.221 (0.216)	Loss 0.0457 (0.0360)	Prec@1 98.438 (98.878)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.194 (0.215)	Loss 0.0559 (0.0379)	Prec@1 98.438 (98.841)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.181 (0.212)	Loss 0.0734 (0.0411)	Prec@1 96.094 (98.704)	
Total train loss: 0.0411
Avg Loading time: 0.0051 seconds
Avg Batch time: 0.2119 seconds

Train time: 82.97551608085632
 * Prec@1 90.160 Prec@5 99.380 Loss 0.3545
Avg Loading time: 0.0861 seconds
Avg Batch time: 0.1617 seconds

Best acc: 90.640
--------------------------------------------------------------------------------
Test time: 13.452193260192871

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.028)	BT: 0.206 (0.231)	Loss 0.0099 (0.0213)	Prec@1 100.000 (99.429)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.002 (0.014)	BT: 0.277 (0.217)	Loss 0.0316 (0.0171)	Prec@1 99.219 (99.604)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.010)	BT: 0.193 (0.215)	Loss 0.0059 (0.0151)	Prec@1 100.000 (99.656)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.222 (0.214)	Loss 0.0069 (0.0136)	Prec@1 100.000 (99.707)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.207 (0.212)	Loss 0.0045 (0.0124)	Prec@1 100.000 (99.752)	
Total train loss: 0.0124
Avg Loading time: 0.0060 seconds
Avg Batch time: 0.2120 seconds

Train time: 82.9849681854248
 * Prec@1 93.700 Prec@5 99.790 Loss 0.2206
Avg Loading time: 0.0823 seconds
Avg Batch time: 0.1560 seconds

Best acc: 93.700
--------------------------------------------------------------------------------
Test time: 13.383514642715454

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.007 (0.050)	BT: 0.185 (0.239)	Loss 0.0035 (0.0047)	Prec@1 100.000 (99.990)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.176 (0.219)	Loss 0.0032 (0.0046)	Prec@1 100.000 (99.985)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.017)	BT: 0.202 (0.217)	Loss 0.0017 (0.0047)	Prec@1 100.000 (99.967)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.168 (0.215)	Loss 0.0028 (0.0047)	Prec@1 100.000 (99.965)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.010)	BT: 0.180 (0.213)	Loss 0.0032 (0.0046)	Prec@1 100.000 (99.964)	
Total train loss: 0.0046
Avg Loading time: 0.0104 seconds
Avg Batch time: 0.2126 seconds

Train time: 83.2615795135498
 * Prec@1 93.590 Prec@5 99.760 Loss 0.2198
Avg Loading time: 0.0898 seconds
Avg Batch time: 0.1732 seconds

Best acc: 93.700
--------------------------------------------------------------------------------
Test time: 14.367778301239014

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.029)	BT: 0.204 (0.237)	Loss 0.0018 (0.0036)	Prec@1 100.000 (99.990)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.015)	BT: 0.176 (0.223)	Loss 0.0041 (0.0035)	Prec@1 100.000 (99.995)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.010)	BT: 0.218 (0.219)	Loss 0.0028 (0.0036)	Prec@1 100.000 (99.983)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.193 (0.213)	Loss 0.0025 (0.0036)	Prec@1 100.000 (99.985)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.186 (0.209)	Loss 0.0037 (0.0036)	Prec@1 100.000 (99.986)	
Total train loss: 0.0036
Avg Loading time: 0.0061 seconds
Avg Batch time: 0.2091 seconds

Train time: 81.88916516304016
 * Prec@1 93.490 Prec@5 99.780 Loss 0.2192
Avg Loading time: 0.0983 seconds
Avg Batch time: 0.1664 seconds

Best acc: 93.700
--------------------------------------------------------------------------------
Test time: 13.777724981307983

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.030)	BT: 0.149 (0.225)	Loss 0.0013 (0.0029)	Prec@1 100.000 (99.990)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.015)	BT: 0.168 (0.218)	Loss 0.0016 (0.0030)	Prec@1 100.000 (99.985)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.010)	BT: 0.194 (0.217)	Loss 0.0027 (0.0031)	Prec@1 100.000 (99.983)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.178 (0.212)	Loss 0.0016 (0.0031)	Prec@1 100.000 (99.982)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.210 (0.211)	Loss 0.0029 (0.0031)	Prec@1 100.000 (99.986)	
Total train loss: 0.0031
Avg Loading time: 0.0063 seconds
Avg Batch time: 0.2107 seconds

Train time: 82.50040197372437
 * Prec@1 93.740 Prec@5 99.780 Loss 0.2188
Avg Loading time: 0.0890 seconds
Avg Batch time: 0.1675 seconds

Best acc: 93.740
--------------------------------------------------------------------------------
Test time: 14.344399213790894

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.025)	BT: 0.166 (0.229)	Loss 0.0049 (0.0028)	Prec@1 100.000 (100.000)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.171 (0.219)	Loss 0.0019 (0.0026)	Prec@1 100.000 (100.000)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.188 (0.217)	Loss 0.0017 (0.0027)	Prec@1 100.000 (100.000)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.198 (0.212)	Loss 0.0012 (0.0027)	Prec@1 100.000 (99.997)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.189 (0.210)	Loss 0.0050 (0.0028)	Prec@1 100.000 (99.994)	
Total train loss: 0.0028
Avg Loading time: 0.0052 seconds
Avg Batch time: 0.2102 seconds

Train time: 82.26822257041931
 * Prec@1 93.620 Prec@5 99.770 Loss 0.2178
Avg Loading time: 0.0817 seconds
Avg Batch time: 0.1608 seconds

Best acc: 93.740
--------------------------------------------------------------------------------
Test time: 13.339312314987183

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.023)	BT: 0.221 (0.223)	Loss 0.0014 (0.0027)	Prec@1 100.000 (99.990)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.012)	BT: 0.170 (0.220)	Loss 0.0030 (0.0025)	Prec@1 100.000 (99.995)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.005 (0.008)	BT: 0.187 (0.215)	Loss 0.0018 (0.0026)	Prec@1 100.000 (99.993)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.229 (0.212)	Loss 0.0021 (0.0026)	Prec@1 100.000 (99.992)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.196 (0.211)	Loss 0.0015 (0.0026)	Prec@1 100.000 (99.990)	
Total train loss: 0.0026
Avg Loading time: 0.0049 seconds
Avg Batch time: 0.2110 seconds

Train time: 82.63309335708618
 * Prec@1 93.680 Prec@5 99.790 Loss 0.2188
Avg Loading time: 0.1121 seconds
Avg Batch time: 0.1809 seconds

Best acc: 93.740
--------------------------------------------------------------------------------
Test time: 14.97244906425476

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.022)	BT: 0.263 (0.217)	Loss 0.0013 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.011)	BT: 0.209 (0.216)	Loss 0.0028 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.164 (0.212)	Loss 0.0021 (0.0025)	Prec@1 100.000 (99.997)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.227 (0.210)	Loss 0.0017 (0.0026)	Prec@1 100.000 (99.997)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.227 (0.210)	Loss 0.0027 (0.0026)	Prec@1 100.000 (99.998)	
Total train loss: 0.0026
Avg Loading time: 0.0046 seconds
Avg Batch time: 0.2097 seconds

Train time: 82.11386013031006
 * Prec@1 93.760 Prec@5 99.790 Loss 0.2186
Avg Loading time: 0.0970 seconds
Avg Batch time: 0.1648 seconds

Best acc: 93.760
--------------------------------------------------------------------------------
Test time: 14.254270792007446

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.026)	BT: 0.207 (0.235)	Loss 0.0039 (0.0027)	Prec@1 100.000 (99.990)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.156 (0.222)	Loss 0.0024 (0.0025)	Prec@1 100.000 (99.995)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.176 (0.215)	Loss 0.0015 (0.0024)	Prec@1 100.000 (99.993)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.193 (0.213)	Loss 0.0018 (0.0025)	Prec@1 100.000 (99.990)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.176 (0.212)	Loss 0.0018 (0.0025)	Prec@1 100.000 (99.992)	
Total train loss: 0.0025
Avg Loading time: 0.0055 seconds
Avg Batch time: 0.2117 seconds

Train time: 82.91310596466064
 * Prec@1 93.670 Prec@5 99.780 Loss 0.2170
Avg Loading time: 0.0754 seconds
Avg Batch time: 0.1560 seconds

Best acc: 93.760
--------------------------------------------------------------------------------
Test time: 13.01479434967041

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.019)	BT: 0.228 (0.224)	Loss 0.0024 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.010)	BT: 0.257 (0.215)	Loss 0.0029 (0.0023)	Prec@1 100.000 (99.995)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.178 (0.213)	Loss 0.0009 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.212 (0.213)	Loss 0.0042 (0.0023)	Prec@1 100.000 (99.997)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.227 (0.211)	Loss 0.0081 (0.0023)	Prec@1 100.000 (99.998)	
Total train loss: 0.0023
Avg Loading time: 0.0041 seconds
Avg Batch time: 0.2104 seconds

Train time: 82.38035273551941
 * Prec@1 93.850 Prec@5 99.820 Loss 0.2166
Avg Loading time: 0.0809 seconds
Avg Batch time: 0.1456 seconds

Best acc: 93.850
--------------------------------------------------------------------------------
Test time: 12.557762861251831

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.027)	BT: 0.295 (0.238)	Loss 0.0013 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.233 (0.222)	Loss 0.0021 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.217 (0.216)	Loss 0.0017 (0.0022)	Prec@1 100.000 (99.993)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.210 (0.213)	Loss 0.0018 (0.0022)	Prec@1 100.000 (99.992)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.192 (0.211)	Loss 0.0015 (0.0022)	Prec@1 100.000 (99.992)	
Total train loss: 0.0023
Avg Loading time: 0.0057 seconds
Avg Batch time: 0.2112 seconds

Train time: 82.67897629737854
 * Prec@1 93.880 Prec@5 99.790 Loss 0.2159
Avg Loading time: 0.0774 seconds
Avg Batch time: 0.1486 seconds

Best acc: 93.880
--------------------------------------------------------------------------------
Test time: 12.882771253585815

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.210 (0.233)	Loss 0.0024 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.013)	BT: 0.189 (0.219)	Loss 0.0022 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.009)	BT: 0.208 (0.212)	Loss 0.0010 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.200 (0.211)	Loss 0.0008 (0.0022)	Prec@1 100.000 (99.992)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.166 (0.212)	Loss 0.0017 (0.0022)	Prec@1 100.000 (99.994)	
Total train loss: 0.0022
Avg Loading time: 0.0080 seconds
Avg Batch time: 0.2113 seconds

Train time: 82.75450158119202
 * Prec@1 93.810 Prec@5 99.770 Loss 0.2144
Avg Loading time: 0.1068 seconds
Avg Batch time: 0.1752 seconds

Best acc: 93.880
--------------------------------------------------------------------------------
Test time: 14.420946836471558

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.025)	BT: 0.212 (0.238)	Loss 0.0012 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.013)	BT: 0.180 (0.223)	Loss 0.0025 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.009)	BT: 0.196 (0.215)	Loss 0.0023 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.207 (0.214)	Loss 0.0021 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.171 (0.212)	Loss 0.0010 (0.0022)	Prec@1 100.000 (99.996)	
Total train loss: 0.0022
Avg Loading time: 0.0056 seconds
Avg Batch time: 0.2117 seconds

Train time: 82.92230892181396
 * Prec@1 93.840 Prec@5 99.790 Loss 0.2155
Avg Loading time: 0.0763 seconds
Avg Batch time: 0.1467 seconds

Best acc: 93.880
--------------------------------------------------------------------------------
Test time: 12.25836992263794

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.027)	BT: 0.249 (0.238)	Loss 0.0040 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.014)	BT: 0.197 (0.223)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.009)	BT: 0.220 (0.214)	Loss 0.0036 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.259 (0.221)	Loss 0.0033 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.012)	BT: 0.170 (0.219)	Loss 0.0037 (0.0022)	Prec@1 100.000 (99.992)	
Total train loss: 0.0022
Avg Loading time: 0.0120 seconds
Avg Batch time: 0.2183 seconds

Train time: 85.47385215759277
 * Prec@1 93.790 Prec@5 99.780 Loss 0.2142
Avg Loading time: 0.0830 seconds
Avg Batch time: 0.1557 seconds

Best acc: 93.880
--------------------------------------------------------------------------------
Test time: 12.957989931106567

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.001 (0.027)	BT: 0.223 (0.242)	Loss 0.0017 (0.0027)	Prec@1 100.000 (99.990)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.014)	BT: 0.197 (0.224)	Loss 0.0015 (0.0024)	Prec@1 100.000 (99.995)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.009)	BT: 0.206 (0.216)	Loss 0.0009 (0.0024)	Prec@1 100.000 (99.993)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.221 (0.215)	Loss 0.0011 (0.0024)	Prec@1 100.000 (99.990)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.162 (0.213)	Loss 0.0010 (0.0024)	Prec@1 100.000 (99.992)	
Total train loss: 0.0024
Avg Loading time: 0.0056 seconds
Avg Batch time: 0.2129 seconds

Train time: 83.37937641143799
 * Prec@1 93.810 Prec@5 99.780 Loss 0.2170
Avg Loading time: 0.0688 seconds
Avg Batch time: 0.1255 seconds

Best acc: 93.880
--------------------------------------------------------------------------------
Test time: 10.488014459609985

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.200 (0.178)	Loss 0.0011 (0.0024)	Prec@1 100.000 (99.990)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.151 (0.173)	Loss 0.0021 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.150 (0.172)	Loss 0.0015 (0.0022)	Prec@1 100.000 (99.993)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.169 (0.172)	Loss 0.0009 (0.0022)	Prec@1 100.000 (99.992)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.009)	BT: 0.161 (0.176)	Loss 0.0012 (0.0022)	Prec@1 100.000 (99.994)	
Total train loss: 0.0022
Avg Loading time: 0.0085 seconds
Avg Batch time: 0.1755 seconds

Train time: 68.69978260993958
 * Prec@1 93.810 Prec@5 99.790 Loss 0.2142
Avg Loading time: 0.0969 seconds
Avg Batch time: 0.1502 seconds

Best acc: 93.880
--------------------------------------------------------------------------------
Test time: 12.427818298339844

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.067)	BT: 0.144 (0.224)	Loss 0.0011 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.071)	BT: 0.146 (0.229)	Loss 0.0028 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.606 (0.080)	BT: 0.761 (0.238)	Loss 0.0013 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.095)	BT: 0.143 (0.252)	Loss 0.0014 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.121)	BT: 0.147 (0.276)	Loss 0.0031 (0.0021)	Prec@1 100.000 (100.000)	
Total train loss: 0.0021
Avg Loading time: 0.1209 seconds
Avg Batch time: 0.2758 seconds

Train time: 107.91662883758545
 * Prec@1 93.740 Prec@5 99.780 Loss 0.2136
Avg Loading time: 0.0756 seconds
Avg Batch time: 0.1385 seconds

Best acc: 93.880
--------------------------------------------------------------------------------
Test time: 11.58741044998169

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.001 (0.022)	BT: 0.205 (0.218)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.011)	BT: 0.209 (0.209)	Loss 0.0011 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.162 (0.203)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.195 (0.204)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.176 (0.201)	Loss 0.0020 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0046 seconds
Avg Batch time: 0.2012 seconds

Train time: 78.77415013313293
 * Prec@1 93.830 Prec@5 99.800 Loss 0.2156
Avg Loading time: 0.0890 seconds
Avg Batch time: 0.1562 seconds

Best acc: 93.880
--------------------------------------------------------------------------------
Test time: 12.987123012542725

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.026)	BT: 0.173 (0.220)	Loss 0.0010 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.013)	BT: 0.184 (0.210)	Loss 0.0030 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.009)	BT: 0.264 (0.206)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.228 (0.204)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.170 (0.202)	Loss 0.0010 (0.0021)	Prec@1 100.000 (100.000)	
Total train loss: 0.0021
Avg Loading time: 0.0055 seconds
Avg Batch time: 0.2015 seconds

Train time: 78.8703064918518
 * Prec@1 93.810 Prec@5 99.800 Loss 0.2164
Avg Loading time: 0.0760 seconds
Avg Batch time: 0.1482 seconds

Best acc: 93.880
--------------------------------------------------------------------------------
Test time: 12.350975751876831

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.022)	BT: 0.206 (0.213)	Loss 0.0018 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.011)	BT: 0.191 (0.206)	Loss 0.0023 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.184 (0.203)	Loss 0.0030 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.002 (0.006)	BT: 0.213 (0.202)	Loss 0.0039 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.160 (0.200)	Loss 0.0025 (0.0022)	Prec@1 100.000 (100.000)	
Total train loss: 0.0022
Avg Loading time: 0.0053 seconds
Avg Batch time: 0.1999 seconds

Train time: 78.27782559394836
 * Prec@1 93.870 Prec@5 99.790 Loss 0.2156
Avg Loading time: 0.0867 seconds
Avg Batch time: 0.1507 seconds

Best acc: 93.880
--------------------------------------------------------------------------------
Test time: 12.558430910110474

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.024)	BT: 0.226 (0.228)	Loss 0.0021 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.012)	BT: 0.169 (0.214)	Loss 0.0026 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.199 (0.204)	Loss 0.0005 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.191 (0.203)	Loss 0.0037 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.172 (0.201)	Loss 0.0020 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0051 seconds
Avg Batch time: 0.2007 seconds

Train time: 78.59440803527832
 * Prec@1 93.820 Prec@5 99.810 Loss 0.2166
Avg Loading time: 0.0763 seconds
Avg Batch time: 0.1470 seconds

Best acc: 93.880
--------------------------------------------------------------------------------
Test time: 12.25056505203247

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.023)	BT: 0.178 (0.219)	Loss 0.0023 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.185 (0.206)	Loss 0.0018 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.233 (0.203)	Loss 0.0023 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.212 (0.204)	Loss 0.0012 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.175 (0.201)	Loss 0.0018 (0.0022)	Prec@1 100.000 (100.000)	
Total train loss: 0.0022
Avg Loading time: 0.0048 seconds
Avg Batch time: 0.2011 seconds

Train time: 78.73244142532349
 * Prec@1 93.790 Prec@5 99.780 Loss 0.2156
Avg Loading time: 0.1007 seconds
Avg Batch time: 0.1647 seconds

Best acc: 93.880
--------------------------------------------------------------------------------
Test time: 13.650922060012817

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.197 (0.215)	Loss 0.0010 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.173 (0.205)	Loss 0.0119 (0.0022)	Prec@1 99.219 (99.990)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.203 (0.201)	Loss 0.0020 (0.0022)	Prec@1 100.000 (99.993)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.165 (0.199)	Loss 0.0015 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.001 (0.005)	BT: 0.175 (0.198)	Loss 0.0016 (0.0022)	Prec@1 100.000 (99.994)	
Total train loss: 0.0022
Avg Loading time: 0.0050 seconds
Avg Batch time: 0.1973 seconds

Train time: 77.25586795806885
 * Prec@1 93.880 Prec@5 99.770 Loss 0.2144
Avg Loading time: 0.1084 seconds
Avg Batch time: 0.1674 seconds

Best acc: 93.880
--------------------------------------------------------------------------------
Test time: 13.90355634689331

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.021)	BT: 0.189 (0.215)	Loss 0.0021 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.211 (0.210)	Loss 0.0022 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.171 (0.206)	Loss 0.0009 (0.0022)	Prec@1 100.000 (99.993)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.197 (0.205)	Loss 0.0028 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.181 (0.203)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0044 seconds
Avg Batch time: 0.2024 seconds

Train time: 79.25083422660828
 * Prec@1 93.950 Prec@5 99.780 Loss 0.2144
Avg Loading time: 0.0842 seconds
Avg Batch time: 0.1429 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 12.392459154129028

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.023)	BT: 0.181 (0.221)	Loss 0.0013 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.177 (0.209)	Loss 0.0021 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.009 (0.008)	BT: 0.231 (0.206)	Loss 0.0012 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.207 (0.206)	Loss 0.0025 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.185 (0.204)	Loss 0.0014 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0048 seconds
Avg Batch time: 0.2036 seconds

Train time: 79.72567796707153
 * Prec@1 93.820 Prec@5 99.770 Loss 0.2140
Avg Loading time: 0.0862 seconds
Avg Batch time: 0.1560 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 12.985962390899658

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.024)	BT: 0.173 (0.221)	Loss 0.0030 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.012)	BT: 0.174 (0.211)	Loss 0.0021 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.008)	BT: 0.178 (0.209)	Loss 0.0016 (0.0022)	Prec@1 100.000 (99.993)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.156 (0.206)	Loss 0.0012 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.181 (0.204)	Loss 0.0020 (0.0021)	Prec@1 100.000 (99.992)	
Total train loss: 0.0021
Avg Loading time: 0.0052 seconds
Avg Batch time: 0.2038 seconds

Train time: 79.80568432807922
 * Prec@1 93.810 Prec@5 99.800 Loss 0.2142
Avg Loading time: 0.0824 seconds
Avg Batch time: 0.1472 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 12.337014436721802

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.021)	BT: 0.218 (0.221)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.190 (0.208)	Loss 0.0010 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.222 (0.205)	Loss 0.0023 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.209 (0.202)	Loss 0.0025 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.162 (0.202)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0045 seconds
Avg Batch time: 0.2013 seconds

Train time: 78.82146167755127
 * Prec@1 93.920 Prec@5 99.810 Loss 0.2156
Avg Loading time: 0.1095 seconds
Avg Batch time: 0.1756 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 14.572926759719849

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.042)	BT: 0.171 (0.235)	Loss 0.0022 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.021)	BT: 0.232 (0.217)	Loss 0.0014 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.014)	BT: 0.221 (0.207)	Loss 0.0012 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.177 (0.203)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.173 (0.202)	Loss 0.0019 (0.0021)	Prec@1 100.000 (99.998)	
Total train loss: 0.0021
Avg Loading time: 0.0088 seconds
Avg Batch time: 0.2014 seconds

Train time: 78.8391261100769
 * Prec@1 93.850 Prec@5 99.780 Loss 0.2150
Avg Loading time: 0.0817 seconds
Avg Batch time: 0.1468 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 12.245140790939331

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.021)	BT: 0.211 (0.224)	Loss 0.0017 (0.0024)	Prec@1 100.000 (99.990)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.195 (0.208)	Loss 0.0036 (0.0023)	Prec@1 100.000 (99.995)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.184 (0.203)	Loss 0.0019 (0.0022)	Prec@1 100.000 (99.993)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.204 (0.203)	Loss 0.0007 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.193 (0.201)	Loss 0.0046 (0.0022)	Prec@1 100.000 (99.996)	
Total train loss: 0.0022
Avg Loading time: 0.0044 seconds
Avg Batch time: 0.2011 seconds

Train time: 78.71986508369446
 * Prec@1 93.920 Prec@5 99.800 Loss 0.2158
Avg Loading time: 0.0891 seconds
Avg Batch time: 0.1529 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 12.70270586013794

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.026)	BT: 0.219 (0.219)	Loss 0.0022 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.013)	BT: 0.236 (0.210)	Loss 0.0008 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.193 (0.206)	Loss 0.0019 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.203 (0.205)	Loss 0.0021 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.170 (0.204)	Loss 0.0021 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0054 seconds
Avg Batch time: 0.2042 seconds

Train time: 79.91526103019714
 * Prec@1 93.690 Prec@5 99.780 Loss 0.2172
Avg Loading time: 0.0961 seconds
Avg Batch time: 0.1610 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 13.371150493621826

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.020)	BT: 0.213 (0.220)	Loss 0.0012 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.010)	BT: 0.219 (0.211)	Loss 0.0018 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.231 (0.206)	Loss 0.0008 (0.0022)	Prec@1 100.000 (99.993)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.194 (0.204)	Loss 0.0012 (0.0022)	Prec@1 100.000 (99.992)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.148 (0.202)	Loss 0.0014 (0.0022)	Prec@1 100.000 (99.994)	
Total train loss: 0.0022
Avg Loading time: 0.0042 seconds
Avg Batch time: 0.2015 seconds

Train time: 78.88728141784668
 * Prec@1 93.820 Prec@5 99.800 Loss 0.2158
Avg Loading time: 0.0806 seconds
Avg Batch time: 0.1428 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 11.878143548965454

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.025)	BT: 0.212 (0.222)	Loss 0.0012 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.013)	BT: 0.262 (0.213)	Loss 0.0009 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.183 (0.208)	Loss 0.0016 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.221 (0.206)	Loss 0.0009 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.173 (0.202)	Loss 0.0009 (0.0021)	Prec@1 100.000 (99.998)	
Total train loss: 0.0021
Avg Loading time: 0.0052 seconds
Avg Batch time: 0.2015 seconds

Train time: 78.91645503044128
 * Prec@1 93.890 Prec@5 99.800 Loss 0.2155
Avg Loading time: 0.0828 seconds
Avg Batch time: 0.1489 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 12.467183828353882

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.248 (0.217)	Loss 0.0019 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.206 (0.207)	Loss 0.0025 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.168 (0.203)	Loss 0.0018 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.191 (0.201)	Loss 0.0037 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.158 (0.199)	Loss 0.0034 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0048 seconds
Avg Batch time: 0.1988 seconds

Train time: 77.83285999298096
 * Prec@1 93.780 Prec@5 99.760 Loss 0.2162
Avg Loading time: 0.0838 seconds
Avg Batch time: 0.1571 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 13.096490383148193

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.020)	BT: 0.252 (0.213)	Loss 0.0029 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.189 (0.206)	Loss 0.0018 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.224 (0.205)	Loss 0.0025 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.188 (0.203)	Loss 0.0020 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.148 (0.202)	Loss 0.0025 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0042 seconds
Avg Batch time: 0.2014 seconds

Train time: 78.82721877098083
 * Prec@1 93.740 Prec@5 99.790 Loss 0.2155
Avg Loading time: 0.0768 seconds
Avg Batch time: 0.1460 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 12.13252854347229

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.179 (0.223)	Loss 0.0022 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.012)	BT: 0.157 (0.209)	Loss 0.0018 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.182 (0.201)	Loss 0.0006 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.184 (0.201)	Loss 0.0028 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.207 (0.200)	Loss 0.0027 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0049 seconds
Avg Batch time: 0.2002 seconds

Train time: 78.36525583267212
 * Prec@1 93.880 Prec@5 99.790 Loss 0.2158
Avg Loading time: 0.0912 seconds
Avg Batch time: 0.1571 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 13.064680337905884

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.025)	BT: 0.204 (0.228)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.013)	BT: 0.156 (0.210)	Loss 0.0022 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.201 (0.206)	Loss 0.0025 (0.0021)	Prec@1 100.000 (99.993)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.188 (0.203)	Loss 0.0020 (0.0022)	Prec@1 100.000 (99.992)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.169 (0.203)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0053 seconds
Avg Batch time: 0.2025 seconds

Train time: 79.26939129829407
 * Prec@1 93.720 Prec@5 99.800 Loss 0.2152
Avg Loading time: 0.1039 seconds
Avg Batch time: 0.1703 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 14.095022439956665

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.021)	BT: 0.185 (0.215)	Loss 0.0016 (0.0022)	Prec@1 100.000 (99.980)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.218 (0.209)	Loss 0.0015 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.165 (0.205)	Loss 0.0012 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.240 (0.202)	Loss 0.0033 (0.0022)	Prec@1 100.000 (99.992)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.174 (0.201)	Loss 0.0014 (0.0022)	Prec@1 100.000 (99.994)	
Total train loss: 0.0022
Avg Loading time: 0.0044 seconds
Avg Batch time: 0.2010 seconds

Train time: 78.6687912940979
 * Prec@1 93.870 Prec@5 99.780 Loss 0.2148
Avg Loading time: 0.0986 seconds
Avg Batch time: 0.1548 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 12.833690166473389

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.001 (0.022)	BT: 0.196 (0.220)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.211 (0.209)	Loss 0.0018 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.007)	BT: 0.197 (0.203)	Loss 0.0008 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.001 (0.006)	BT: 0.219 (0.203)	Loss 0.0010 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.144 (0.202)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0046 seconds
Avg Batch time: 0.2014 seconds

Train time: 78.84753274917603
 * Prec@1 93.930 Prec@5 99.780 Loss 0.2146
Avg Loading time: 0.0838 seconds
Avg Batch time: 0.1498 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 12.47826886177063

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.023)	BT: 0.193 (0.227)	Loss 0.0018 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.012)	BT: 0.151 (0.205)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.008)	BT: 0.155 (0.191)	Loss 0.0016 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.190 (0.186)	Loss 0.0008 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.144 (0.181)	Loss 0.0017 (0.0022)	Prec@1 100.000 (99.996)	
Total train loss: 0.0022
Avg Loading time: 0.0048 seconds
Avg Batch time: 0.1805 seconds

Train time: 70.63056087493896
 * Prec@1 93.810 Prec@5 99.760 Loss 0.2168
Avg Loading time: 0.0655 seconds
Avg Batch time: 0.1195 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 10.024288177490234

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.018)	BT: 0.195 (0.186)	Loss 0.0019 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.169 (0.177)	Loss 0.0013 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.165 (0.174)	Loss 0.0025 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.147 (0.172)	Loss 0.0008 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.144 (0.171)	Loss 0.0051 (0.0022)	Prec@1 100.000 (99.998)	
Total train loss: 0.0022
Avg Loading time: 0.0038 seconds
Avg Batch time: 0.1709 seconds

Train time: 66.8695375919342
 * Prec@1 93.890 Prec@5 99.800 Loss 0.2155
Avg Loading time: 0.0994 seconds
Avg Batch time: 0.1461 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 12.131373882293701

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.019)	BT: 0.172 (0.189)	Loss 0.0033 (0.0024)	Prec@1 100.000 (99.990)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.149 (0.180)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.189 (0.178)	Loss 0.0012 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.156 (0.180)	Loss 0.0027 (0.0022)	Prec@1 100.000 (99.992)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.176 (0.183)	Loss 0.0029 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0039 seconds
Avg Batch time: 0.1831 seconds

Train time: 71.675053358078
 * Prec@1 93.820 Prec@5 99.800 Loss 0.2140
Avg Loading time: 0.0884 seconds
Avg Batch time: 0.1520 seconds

Best acc: 93.950
--------------------------------------------------------------------------------
Test time: 12.674838542938232


      ==> Arguments:
          dataset: cifar10
          model: resnet18
          load_dir: /home/nano01/a/esoufler/activations/x128/
          savedir: ../pretrained_models/frozen/x128/
          pretrained: ../pretrained_models/ideal/resnet18fp_imnet.pth.tar
          mode_train: rram
          mode_test: rram_new
          workers: 8
          epochs: 50
          start_epoch: 0
          batch_size: 128
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.2
          milestones: [10, 20, 30, 40]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 2
          frozen_layers: 7
Savedir:  ../pretrained_models/frozen/x128/rram_new/cifar10/resnet18
DEVICE: cuda
GPU Id(s) being used: 2
==> Building model for resnet18 ...
==> Initializing model with pre-trained parameters (except classifier)...
==> Load pretrained model form ../pretrained_models/ideal/resnet18fp_imnet.pth.tar ...
Original model accuracy on ImageNet: 69.93189239501953
Train path:  /home/nano01/a/esoufler/activations/x128/rram/one_batch/cifar10/resnet18/train/relu7
Test path:  /home/nano01/a/esoufler/activations/x128/rram_new/one_batch/cifar10/resnet18/test/relu7
ResNet18(
  (conv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu8): ReLU(inplace=True)
  (conv9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu9): ReLU(inplace=True)
  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu10): ReLU(inplace=True)
  (conv11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu11): ReLU(inplace=True)
  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu12): ReLU(inplace=True)
  (conv13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu13): ReLU(inplace=True)
  (conv14): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (relu14): ReLU(inplace=True)
  (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu15): ReLU(inplace=True)
  (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (bn18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): Linear(in_features=512, out_features=10, bias=False)
  (bn19): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 10.700 Prec@5 51.740 Loss 2.3027
Avg Loading time: 0.7236 seconds
Avg Batch time: 0.7573 seconds

Pre-trained Prec@1 with 7 layers frozen: 10.699999809265137 	 Loss: 2.302734375

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.1	DT: 0.000 (0.835)	BT: 0.104 (0.941)	Loss 0.3599 (0.6978)	Prec@1 88.281 (77.925)	
Epoch: [0][155/391]	LR: 0.1	DT: 0.000 (0.779)	BT: 0.103 (0.885)	Loss 0.4258 (0.5740)	Prec@1 88.281 (81.365)	
Epoch: [0][233/391]	LR: 0.1	DT: 0.000 (0.760)	BT: 0.108 (0.866)	Loss 0.3650 (0.5153)	Prec@1 88.281 (83.120)	
Epoch: [0][311/391]	LR: 0.1	DT: 0.000 (0.734)	BT: 0.104 (0.840)	Loss 0.3103 (0.4796)	Prec@1 90.625 (84.232)	
Epoch: [0][389/391]	LR: 0.1	DT: 0.000 (0.721)	BT: 0.124 (0.828)	Loss 0.2703 (0.4513)	Prec@1 89.844 (85.104)	
Total train loss: 0.4511
Avg Loading time: 0.7196 seconds
Avg Batch time: 0.8259 seconds

Train time: 323.05108523368835
 * Prec@1 85.920 Prec@5 99.530 Loss 0.4050
Avg Loading time: 0.0890 seconds
Avg Batch time: 0.1175 seconds

Best acc: 85.920
--------------------------------------------------------------------------------
Test time: 10.340120553970337

Epoch: [1][77/391]	LR: 0.1	DT: 0.000 (0.016)	BT: 0.108 (0.141)	Loss 0.2080 (0.2203)	Prec@1 94.531 (92.708)	
Epoch: [1][155/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.124 (0.132)	Loss 0.2837 (0.2266)	Prec@1 89.844 (92.363)	
Epoch: [1][233/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.106 (0.129)	Loss 0.2544 (0.2300)	Prec@1 92.969 (92.254)	
Epoch: [1][311/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.118 (0.129)	Loss 0.2269 (0.2331)	Prec@1 93.750 (92.155)	
Epoch: [1][389/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.120 (0.128)	Loss 0.2112 (0.2357)	Prec@1 94.531 (92.079)	
Total train loss: 0.2356
Avg Loading time: 0.0035 seconds
Avg Batch time: 0.1275 seconds

Train time: 49.9621045589447
 * Prec@1 89.650 Prec@5 99.740 Loss 0.3032
Avg Loading time: 0.0728 seconds
Avg Batch time: 0.1056 seconds

Best acc: 89.650
--------------------------------------------------------------------------------
Test time: 9.445778369903564

Epoch: [2][77/391]	LR: 0.1	DT: 0.000 (0.017)	BT: 0.105 (0.135)	Loss 0.1298 (0.1367)	Prec@1 96.875 (95.543)	
Epoch: [2][155/391]	LR: 0.1	DT: 0.000 (0.009)	BT: 0.123 (0.128)	Loss 0.1248 (0.1342)	Prec@1 96.875 (95.608)	
Epoch: [2][233/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.127 (0.125)	Loss 0.1055 (0.1406)	Prec@1 95.312 (95.302)	
Epoch: [2][311/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.123 (0.125)	Loss 0.1373 (0.1479)	Prec@1 96.094 (95.017)	
Epoch: [2][389/391]	LR: 0.1	DT: 0.000 (0.005)	BT: 0.108 (0.125)	Loss 0.1367 (0.1519)	Prec@1 96.875 (94.816)	
Total train loss: 0.1519
Avg Loading time: 0.0050 seconds
Avg Batch time: 0.1247 seconds

Train time: 48.853310346603394
 * Prec@1 88.930 Prec@5 99.670 Loss 0.3433
Avg Loading time: 0.0720 seconds
Avg Batch time: 0.1033 seconds

Best acc: 89.650
--------------------------------------------------------------------------------
Test time: 8.782864570617676

Epoch: [3][77/391]	LR: 0.1	DT: 0.000 (0.023)	BT: 0.127 (0.146)	Loss 0.0653 (0.0893)	Prec@1 97.656 (97.286)	
Epoch: [3][155/391]	LR: 0.1	DT: 0.002 (0.023)	BT: 0.117 (0.142)	Loss 0.1349 (0.0941)	Prec@1 94.531 (97.035)	
Epoch: [3][233/391]	LR: 0.1	DT: 0.000 (0.022)	BT: 0.109 (0.141)	Loss 0.0878 (0.1005)	Prec@1 97.656 (96.772)	
Epoch: [3][311/391]	LR: 0.1	DT: 0.000 (0.029)	BT: 0.120 (0.148)	Loss 0.0958 (0.1042)	Prec@1 96.875 (96.627)	
Epoch: [3][389/391]	LR: 0.1	DT: 0.000 (0.028)	BT: 0.123 (0.148)	Loss 0.0649 (0.1095)	Prec@1 98.438 (96.380)	
Total train loss: 0.1097
Avg Loading time: 0.0283 seconds
Avg Batch time: 0.1476 seconds

Train time: 57.83628988265991
 * Prec@1 88.140 Prec@5 99.400 Loss 0.3843
Avg Loading time: 0.1173 seconds
Avg Batch time: 0.1478 seconds

Best acc: 89.650
--------------------------------------------------------------------------------
Test time: 12.27635908126831

Epoch: [4][77/391]	LR: 0.1	DT: 0.000 (0.035)	BT: 0.134 (0.152)	Loss 0.1242 (0.0847)	Prec@1 95.312 (97.286)	
Epoch: [4][155/391]	LR: 0.1	DT: 0.000 (0.021)	BT: 0.107 (0.139)	Loss 0.0345 (0.0767)	Prec@1 100.000 (97.546)	
Epoch: [4][233/391]	LR: 0.1	DT: 0.000 (0.014)	BT: 0.122 (0.134)	Loss 0.1073 (0.0779)	Prec@1 96.875 (97.453)	
Epoch: [4][311/391]	LR: 0.1	DT: 0.000 (0.017)	BT: 0.125 (0.137)	Loss 0.0669 (0.0836)	Prec@1 97.656 (97.203)	
Epoch: [4][389/391]	LR: 0.1	DT: 0.000 (0.013)	BT: 0.111 (0.134)	Loss 0.1234 (0.0891)	Prec@1 96.094 (97.037)	
Total train loss: 0.0892
Avg Loading time: 0.0133 seconds
Avg Batch time: 0.1343 seconds

Train time: 52.62460684776306
 * Prec@1 89.270 Prec@5 99.650 Loss 0.3511
Avg Loading time: 0.0650 seconds
Avg Batch time: 0.1000 seconds

Best acc: 89.650
--------------------------------------------------------------------------------
Test time: 8.542391538619995

Epoch: [5][77/391]	LR: 0.1	DT: 0.000 (0.015)	BT: 0.153 (0.138)	Loss 0.1534 (0.0636)	Prec@1 92.969 (97.947)	
Epoch: [5][155/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.116 (0.130)	Loss 0.0811 (0.0591)	Prec@1 97.656 (98.102)	
Epoch: [5][233/391]	LR: 0.1	DT: 0.133 (0.015)	BT: 0.242 (0.137)	Loss 0.0210 (0.0566)	Prec@1 99.219 (98.190)	
Epoch: [5][311/391]	LR: 0.1	DT: 0.000 (0.012)	BT: 0.127 (0.134)	Loss 0.0609 (0.0577)	Prec@1 96.875 (98.124)	
Epoch: [5][389/391]	LR: 0.1	DT: 0.000 (0.010)	BT: 0.128 (0.132)	Loss 0.0842 (0.0638)	Prec@1 97.656 (97.911)	
Total train loss: 0.0639
Avg Loading time: 0.0099 seconds
Avg Batch time: 0.1320 seconds

Train time: 51.69995045661926
 * Prec@1 89.780 Prec@5 99.470 Loss 0.3579
Avg Loading time: 0.0806 seconds
Avg Batch time: 0.1117 seconds

Best acc: 89.780
--------------------------------------------------------------------------------
Test time: 9.936252117156982

Epoch: [6][77/391]	LR: 0.1	DT: 0.000 (0.049)	BT: 0.133 (0.169)	Loss 0.0459 (0.0500)	Prec@1 99.219 (98.518)	
Epoch: [6][155/391]	LR: 0.1	DT: 0.001 (0.025)	BT: 0.123 (0.144)	Loss 0.0546 (0.0519)	Prec@1 96.875 (98.463)	
Epoch: [6][233/391]	LR: 0.1	DT: 0.000 (0.017)	BT: 0.120 (0.136)	Loss 0.0273 (0.0513)	Prec@1 99.219 (98.451)	
Epoch: [6][311/391]	LR: 0.1	DT: 0.000 (0.013)	BT: 0.126 (0.134)	Loss 0.0790 (0.0528)	Prec@1 96.875 (98.330)	
Epoch: [6][389/391]	LR: 0.1	DT: 0.000 (0.010)	BT: 0.120 (0.131)	Loss 0.0461 (0.0566)	Prec@1 97.656 (98.143)	
Total train loss: 0.0567
Avg Loading time: 0.0102 seconds
Avg Batch time: 0.1312 seconds

Train time: 51.44562292098999
 * Prec@1 89.980 Prec@5 99.490 Loss 0.3496
Avg Loading time: 0.0772 seconds
Avg Batch time: 0.1078 seconds

Best acc: 89.980
--------------------------------------------------------------------------------
Test time: 9.559541702270508

Epoch: [7][77/391]	LR: 0.1	DT: 0.000 (0.017)	BT: 0.144 (0.141)	Loss 0.1283 (0.0484)	Prec@1 96.094 (98.498)	
Epoch: [7][155/391]	LR: 0.1	DT: 0.000 (0.008)	BT: 0.113 (0.132)	Loss 0.0385 (0.0474)	Prec@1 98.438 (98.538)	
Epoch: [7][233/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.108 (0.129)	Loss 0.0597 (0.0472)	Prec@1 96.875 (98.558)	
Epoch: [7][311/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.139 (0.127)	Loss 0.0278 (0.0499)	Prec@1 99.219 (98.405)	
Epoch: [7][389/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.112 (0.126)	Loss 0.0813 (0.0505)	Prec@1 96.875 (98.389)	
Total train loss: 0.0505
Avg Loading time: 0.0036 seconds
Avg Batch time: 0.1260 seconds

Train time: 49.37843108177185
 * Prec@1 90.840 Prec@5 99.510 Loss 0.3215
Avg Loading time: 0.0536 seconds
Avg Batch time: 0.0885 seconds

Best acc: 90.840
--------------------------------------------------------------------------------
Test time: 8.058483123779297

Epoch: [8][77/391]	LR: 0.1	DT: 0.000 (0.015)	BT: 0.161 (0.133)	Loss 0.0087 (0.0326)	Prec@1 100.000 (98.988)	
Epoch: [8][155/391]	LR: 0.1	DT: 0.000 (0.007)	BT: 0.121 (0.127)	Loss 0.0398 (0.0316)	Prec@1 98.438 (99.033)	
Epoch: [8][233/391]	LR: 0.1	DT: 0.001 (0.005)	BT: 0.125 (0.128)	Loss 0.0245 (0.0330)	Prec@1 100.000 (98.965)	
Epoch: [8][311/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.108 (0.127)	Loss 0.0352 (0.0350)	Prec@1 98.438 (98.901)	
Epoch: [8][389/391]	LR: 0.1	DT: 0.000 (0.003)	BT: 0.119 (0.127)	Loss 0.0483 (0.0391)	Prec@1 98.438 (98.742)	
Total train loss: 0.0391
Avg Loading time: 0.0032 seconds
Avg Batch time: 0.1265 seconds

Train time: 49.53507375717163
 * Prec@1 90.460 Prec@5 99.550 Loss 0.3357
Avg Loading time: 0.0696 seconds
Avg Batch time: 0.1028 seconds

Best acc: 90.840
--------------------------------------------------------------------------------
Test time: 8.751997709274292

Epoch: [9][77/391]	LR: 0.1	DT: 0.000 (0.017)	BT: 0.111 (0.138)	Loss 0.0652 (0.0401)	Prec@1 97.656 (98.728)	
Epoch: [9][155/391]	LR: 0.1	DT: 0.000 (0.009)	BT: 0.115 (0.131)	Loss 0.0384 (0.0404)	Prec@1 98.438 (98.718)	
Epoch: [9][233/391]	LR: 0.1	DT: 0.000 (0.006)	BT: 0.124 (0.128)	Loss 0.0144 (0.0416)	Prec@1 100.000 (98.678)	
Epoch: [9][311/391]	LR: 0.1	DT: 0.001 (0.004)	BT: 0.120 (0.127)	Loss 0.0305 (0.0415)	Prec@1 99.219 (98.693)	
Epoch: [9][389/391]	LR: 0.1	DT: 0.000 (0.004)	BT: 0.111 (0.127)	Loss 0.0610 (0.0438)	Prec@1 98.438 (98.632)	
Total train loss: 0.0437
Avg Loading time: 0.0037 seconds
Avg Batch time: 0.1269 seconds

Train time: 49.72069573402405
 * Prec@1 90.650 Prec@5 99.450 Loss 0.3286
Avg Loading time: 0.0649 seconds
Avg Batch time: 0.0965 seconds

Best acc: 90.840
--------------------------------------------------------------------------------
Test time: 8.209834337234497

Epoch: [10][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.132 (0.139)	Loss 0.0155 (0.0221)	Prec@1 100.000 (99.359)	
Epoch: [10][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.145 (0.129)	Loss 0.0268 (0.0180)	Prec@1 99.219 (99.559)	
Epoch: [10][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.107 (0.126)	Loss 0.0157 (0.0154)	Prec@1 100.000 (99.633)	
Epoch: [10][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.126 (0.125)	Loss 0.0024 (0.0138)	Prec@1 100.000 (99.669)	
Epoch: [10][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.003)	BT: 0.118 (0.124)	Loss 0.0066 (0.0124)	Prec@1 100.000 (99.718)	
Total train loss: 0.0124
Avg Loading time: 0.0031 seconds
Avg Batch time: 0.1243 seconds

Train time: 48.73908472061157
 * Prec@1 93.290 Prec@5 99.680 Loss 0.2400
Avg Loading time: 0.0701 seconds
Avg Batch time: 0.1024 seconds

Best acc: 93.290
--------------------------------------------------------------------------------
Test time: 9.196388483047485

Epoch: [11][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.015)	BT: 0.108 (0.140)	Loss 0.0071 (0.0043)	Prec@1 100.000 (99.980)	
Epoch: [11][155/391]	LR: 0.020000000000000004	DT: 0.001 (0.008)	BT: 0.138 (0.131)	Loss 0.0032 (0.0050)	Prec@1 100.000 (99.965)	
Epoch: [11][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.112 (0.128)	Loss 0.0034 (0.0050)	Prec@1 100.000 (99.960)	
Epoch: [11][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.132 (0.127)	Loss 0.0022 (0.0050)	Prec@1 100.000 (99.955)	
Epoch: [11][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.003)	BT: 0.117 (0.127)	Loss 0.0017 (0.0049)	Prec@1 100.000 (99.956)	
Total train loss: 0.0049
Avg Loading time: 0.0032 seconds
Avg Batch time: 0.1265 seconds

Train time: 49.59393882751465
 * Prec@1 93.600 Prec@5 99.690 Loss 0.2302
Avg Loading time: 0.0695 seconds
Avg Batch time: 0.1008 seconds

Best acc: 93.600
--------------------------------------------------------------------------------
Test time: 9.091480493545532

Epoch: [12][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.059)	BT: 0.111 (0.178)	Loss 0.0046 (0.0041)	Prec@1 100.000 (99.970)	
Epoch: [12][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.030)	BT: 0.115 (0.149)	Loss 0.0018 (0.0041)	Prec@1 100.000 (99.960)	
Epoch: [12][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.020)	BT: 0.142 (0.141)	Loss 0.0026 (0.0039)	Prec@1 100.000 (99.970)	
Epoch: [12][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.017)	BT: 0.110 (0.139)	Loss 0.0018 (0.0037)	Prec@1 100.000 (99.977)	
Epoch: [12][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.115 (0.135)	Loss 0.0017 (0.0037)	Prec@1 100.000 (99.978)	
Total train loss: 0.0037
Avg Loading time: 0.0139 seconds
Avg Batch time: 0.1353 seconds

Train time: 53.02687692642212
 * Prec@1 93.530 Prec@5 99.700 Loss 0.2321
Avg Loading time: 0.0749 seconds
Avg Batch time: 0.1091 seconds

Best acc: 93.600
--------------------------------------------------------------------------------
Test time: 9.254053592681885

Epoch: [13][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.016)	BT: 0.107 (0.145)	Loss 0.0027 (0.0034)	Prec@1 100.000 (99.990)	
Epoch: [13][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.008)	BT: 0.114 (0.134)	Loss 0.0016 (0.0034)	Prec@1 100.000 (99.985)	
Epoch: [13][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.111 (0.131)	Loss 0.0007 (0.0033)	Prec@1 100.000 (99.983)	
Epoch: [13][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.120 (0.128)	Loss 0.0016 (0.0033)	Prec@1 100.000 (99.982)	
Epoch: [13][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.003)	BT: 0.107 (0.127)	Loss 0.0021 (0.0033)	Prec@1 100.000 (99.984)	
Total train loss: 0.0033
Avg Loading time: 0.0033 seconds
Avg Batch time: 0.1264 seconds

Train time: 49.55382680892944
 * Prec@1 93.520 Prec@5 99.720 Loss 0.2294
Avg Loading time: 0.0662 seconds
Avg Batch time: 0.0970 seconds

Best acc: 93.600
--------------------------------------------------------------------------------
Test time: 8.322547912597656

Epoch: [14][77/391]	LR: 0.020000000000000004	DT: 0.001 (0.017)	BT: 0.118 (0.138)	Loss 0.0065 (0.0029)	Prec@1 100.000 (100.000)	
Epoch: [14][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.123 (0.133)	Loss 0.0011 (0.0028)	Prec@1 100.000 (100.000)	
Epoch: [14][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.130 (0.129)	Loss 0.0035 (0.0030)	Prec@1 100.000 (99.993)	
Epoch: [14][311/391]	LR: 0.020000000000000004	DT: 0.005 (0.005)	BT: 0.136 (0.129)	Loss 0.0022 (0.0029)	Prec@1 100.000 (99.995)	
Epoch: [14][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.125 (0.129)	Loss 0.0014 (0.0029)	Prec@1 100.000 (99.994)	
Total train loss: 0.0029
Avg Loading time: 0.0039 seconds
Avg Batch time: 0.1286 seconds

Train time: 50.395336627960205
 * Prec@1 93.560 Prec@5 99.730 Loss 0.2300
Avg Loading time: 0.0664 seconds
Avg Batch time: 0.1057 seconds

Best acc: 93.600
--------------------------------------------------------------------------------
Test time: 8.940318822860718

Epoch: [15][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.015)	BT: 0.129 (0.140)	Loss 0.0026 (0.0029)	Prec@1 100.000 (99.990)	
Epoch: [15][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.143 (0.134)	Loss 0.0047 (0.0029)	Prec@1 100.000 (99.990)	
Epoch: [15][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.116 (0.130)	Loss 0.0012 (0.0027)	Prec@1 100.000 (99.990)	
Epoch: [15][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.139 (0.129)	Loss 0.0035 (0.0026)	Prec@1 100.000 (99.992)	
Epoch: [15][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.003)	BT: 0.111 (0.128)	Loss 0.0041 (0.0027)	Prec@1 100.000 (99.992)	
Total train loss: 0.0027
Avg Loading time: 0.0031 seconds
Avg Batch time: 0.1275 seconds

Train time: 49.966036319732666
 * Prec@1 93.500 Prec@5 99.750 Loss 0.2312
Avg Loading time: 0.0590 seconds
Avg Batch time: 0.0935 seconds

Best acc: 93.600
--------------------------------------------------------------------------------
Test time: 8.068971157073975

Epoch: [16][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.018)	BT: 0.105 (0.138)	Loss 0.0039 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [16][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.121 (0.131)	Loss 0.0012 (0.0025)	Prec@1 100.000 (99.995)	
Epoch: [16][233/391]	LR: 0.020000000000000004	DT: 0.002 (0.006)	BT: 0.124 (0.129)	Loss 0.0017 (0.0026)	Prec@1 100.000 (99.997)	
Epoch: [16][311/391]	LR: 0.020000000000000004	DT: 0.003 (0.005)	BT: 0.125 (0.128)	Loss 0.0025 (0.0025)	Prec@1 100.000 (99.997)	
Epoch: [16][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.109 (0.126)	Loss 0.0014 (0.0024)	Prec@1 100.000 (99.996)	
Total train loss: 0.0025
Avg Loading time: 0.0038 seconds
Avg Batch time: 0.1263 seconds

Train time: 49.52686405181885
 * Prec@1 93.740 Prec@5 99.770 Loss 0.2253
Avg Loading time: 0.0759 seconds
Avg Batch time: 0.1060 seconds

Best acc: 93.740
--------------------------------------------------------------------------------
Test time: 9.453599691390991

Epoch: [17][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.017)	BT: 0.160 (0.142)	Loss 0.0014 (0.0024)	Prec@1 100.000 (100.000)	
Epoch: [17][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.009)	BT: 0.106 (0.132)	Loss 0.0019 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [17][233/391]	LR: 0.020000000000000004	DT: 0.002 (0.006)	BT: 0.122 (0.127)	Loss 0.0050 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [17][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.108 (0.126)	Loss 0.0022 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [17][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.118 (0.126)	Loss 0.0022 (0.0023)	Prec@1 100.000 (99.998)	
Total train loss: 0.0023
Avg Loading time: 0.0036 seconds
Avg Batch time: 0.1254 seconds

Train time: 49.167367696762085
 * Prec@1 93.660 Prec@5 99.750 Loss 0.2260
Avg Loading time: 0.0491 seconds
Avg Batch time: 0.0861 seconds

Best acc: 93.740
--------------------------------------------------------------------------------
Test time: 7.413916110992432

Epoch: [18][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.013)	BT: 0.117 (0.134)	Loss 0.0034 (0.0022)	Prec@1 100.000 (99.970)	
Epoch: [18][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.006)	BT: 0.145 (0.128)	Loss 0.0023 (0.0025)	Prec@1 100.000 (99.970)	
Epoch: [18][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.146 (0.126)	Loss 0.0023 (0.0025)	Prec@1 100.000 (99.980)	
Epoch: [18][311/391]	LR: 0.020000000000000004	DT: 0.000 (0.004)	BT: 0.128 (0.124)	Loss 0.0034 (0.0023)	Prec@1 100.000 (99.985)	
Epoch: [18][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.003)	BT: 0.105 (0.124)	Loss 0.0015 (0.0024)	Prec@1 100.000 (99.982)	
Total train loss: 0.0024
Avg Loading time: 0.0029 seconds
Avg Batch time: 0.1236 seconds

Train time: 48.42362713813782
 * Prec@1 93.630 Prec@5 99.730 Loss 0.2275
Avg Loading time: 0.0612 seconds
Avg Batch time: 0.0947 seconds

Best acc: 93.740
--------------------------------------------------------------------------------
Test time: 8.1246178150177

Epoch: [19][77/391]	LR: 0.020000000000000004	DT: 0.000 (0.014)	BT: 0.117 (0.138)	Loss 0.0011 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [19][155/391]	LR: 0.020000000000000004	DT: 0.000 (0.007)	BT: 0.110 (0.131)	Loss 0.0015 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [19][233/391]	LR: 0.020000000000000004	DT: 0.000 (0.005)	BT: 0.117 (0.128)	Loss 0.0014 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [19][311/391]	LR: 0.020000000000000004	DT: 0.003 (0.004)	BT: 0.134 (0.126)	Loss 0.0016 (0.0023)	Prec@1 100.000 (99.992)	
Epoch: [19][389/391]	LR: 0.020000000000000004	DT: 0.000 (0.017)	BT: 0.107 (0.139)	Loss 0.0023 (0.0022)	Prec@1 100.000 (99.994)	
Total train loss: 0.0023
Avg Loading time: 0.0167 seconds
Avg Batch time: 0.1385 seconds

Train time: 54.287896394729614
 * Prec@1 93.730 Prec@5 99.700 Loss 0.2240
Avg Loading time: 0.0691 seconds
Avg Batch time: 0.0998 seconds

Best acc: 93.740
--------------------------------------------------------------------------------
Test time: 8.519820213317871

Epoch: [20][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.014)	BT: 0.120 (0.135)	Loss 0.0024 (0.0024)	Prec@1 100.000 (99.990)	
Epoch: [20][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.125 (0.130)	Loss 0.0012 (0.0023)	Prec@1 100.000 (99.990)	
Epoch: [20][233/391]	LR: 0.004000000000000001	DT: 0.002 (0.005)	BT: 0.145 (0.129)	Loss 0.0033 (0.0023)	Prec@1 100.000 (99.993)	
Epoch: [20][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.121 (0.129)	Loss 0.0017 (0.0022)	Prec@1 100.000 (99.992)	
Epoch: [20][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.123 (0.128)	Loss 0.0023 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0060 seconds
Avg Batch time: 0.1283 seconds

Train time: 50.27392935752869
 * Prec@1 93.760 Prec@5 99.700 Loss 0.2271
Avg Loading time: 0.0522 seconds
Avg Batch time: 0.0860 seconds

Best acc: 93.760
--------------------------------------------------------------------------------
Test time: 7.876492977142334

Epoch: [21][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.016)	BT: 0.113 (0.142)	Loss 0.0021 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [21][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.112 (0.134)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [21][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.115 (0.129)	Loss 0.0017 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [21][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.164 (0.128)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [21][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.108 (0.128)	Loss 0.0028 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0035 seconds
Avg Batch time: 0.1281 seconds

Train time: 50.21036243438721
 * Prec@1 93.750 Prec@5 99.720 Loss 0.2246
Avg Loading time: 0.0754 seconds
Avg Batch time: 0.1095 seconds

Best acc: 93.760
--------------------------------------------------------------------------------
Test time: 9.296542882919312

Epoch: [22][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.011)	BT: 0.117 (0.138)	Loss 0.0013 (0.0023)	Prec@1 100.000 (100.000)	
Epoch: [22][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.143 (0.133)	Loss 0.0080 (0.0023)	Prec@1 100.000 (99.995)	
Epoch: [22][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.113 (0.130)	Loss 0.0009 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [22][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.120 (0.128)	Loss 0.0018 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [22][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.002)	BT: 0.108 (0.127)	Loss 0.0021 (0.0022)	Prec@1 100.000 (99.996)	
Total train loss: 0.0022
Avg Loading time: 0.0024 seconds
Avg Batch time: 0.1272 seconds

Train time: 49.85910987854004
 * Prec@1 93.700 Prec@5 99.700 Loss 0.2294
Avg Loading time: 0.0534 seconds
Avg Batch time: 0.0871 seconds

Best acc: 93.760
--------------------------------------------------------------------------------
Test time: 7.481782674789429

Epoch: [23][77/391]	LR: 0.004000000000000001	DT: 0.001 (0.014)	BT: 0.118 (0.133)	Loss 0.0010 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [23][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.129 (0.125)	Loss 0.0016 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [23][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.116 (0.124)	Loss 0.0011 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [23][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.126 (0.124)	Loss 0.0029 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [23][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.108 (0.122)	Loss 0.0008 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0029 seconds
Avg Batch time: 0.1220 seconds

Train time: 47.8013391494751
 * Prec@1 93.620 Prec@5 99.720 Loss 0.2250
Avg Loading time: 0.0647 seconds
Avg Batch time: 0.0942 seconds

Best acc: 93.760
--------------------------------------------------------------------------------
Test time: 8.090169668197632

Epoch: [24][77/391]	LR: 0.004000000000000001	DT: 0.001 (0.015)	BT: 0.120 (0.136)	Loss 0.0034 (0.0027)	Prec@1 100.000 (99.970)	
Epoch: [24][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.112 (0.128)	Loss 0.0021 (0.0024)	Prec@1 100.000 (99.985)	
Epoch: [24][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.125 (0.125)	Loss 0.0011 (0.0023)	Prec@1 100.000 (99.983)	
Epoch: [24][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.115 (0.125)	Loss 0.0015 (0.0024)	Prec@1 100.000 (99.985)	
Epoch: [24][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.113 (0.125)	Loss 0.0011 (0.0023)	Prec@1 100.000 (99.988)	
Total train loss: 0.0023
Avg Loading time: 0.0033 seconds
Avg Batch time: 0.1252 seconds

Train time: 49.06661653518677
 * Prec@1 93.750 Prec@5 99.700 Loss 0.2256
Avg Loading time: 0.0597 seconds
Avg Batch time: 0.0931 seconds

Best acc: 93.760
--------------------------------------------------------------------------------
Test time: 7.993646621704102

Epoch: [25][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.014)	BT: 0.109 (0.136)	Loss 0.0028 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [25][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.007)	BT: 0.115 (0.128)	Loss 0.0042 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [25][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.131 (0.127)	Loss 0.0030 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [25][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.120 (0.126)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [25][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.113 (0.125)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.998)	
Total train loss: 0.0021
Avg Loading time: 0.0030 seconds
Avg Batch time: 0.1248 seconds

Train time: 48.88449668884277
 * Prec@1 93.760 Prec@5 99.720 Loss 0.2264
Avg Loading time: 0.0745 seconds
Avg Batch time: 0.1068 seconds

Best acc: 93.760
--------------------------------------------------------------------------------
Test time: 9.068489074707031

Epoch: [26][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.012)	BT: 0.113 (0.139)	Loss 0.0017 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [26][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.006)	BT: 0.129 (0.129)	Loss 0.0016 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [26][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.114 (0.127)	Loss 0.0017 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [26][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.115 (0.126)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.992)	
Epoch: [26][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.108 (0.125)	Loss 0.0010 (0.0022)	Prec@1 100.000 (99.994)	
Total train loss: 0.0022
Avg Loading time: 0.0026 seconds
Avg Batch time: 0.1251 seconds

Train time: 49.0140323638916
 * Prec@1 93.710 Prec@5 99.720 Loss 0.2264
Avg Loading time: 0.0627 seconds
Avg Batch time: 0.0948 seconds

Best acc: 93.760
--------------------------------------------------------------------------------
Test time: 8.085984945297241

Epoch: [27][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.015)	BT: 0.117 (0.136)	Loss 0.0048 (0.0020)	Prec@1 100.000 (99.990)	
Epoch: [27][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.129 (0.128)	Loss 0.0029 (0.0019)	Prec@1 100.000 (99.995)	
Epoch: [27][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.112 (0.127)	Loss 0.0060 (0.0020)	Prec@1 100.000 (99.993)	
Epoch: [27][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.119 (0.127)	Loss 0.0011 (0.0020)	Prec@1 100.000 (99.992)	
Epoch: [27][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.107 (0.126)	Loss 0.0019 (0.0020)	Prec@1 100.000 (99.994)	
Total train loss: 0.0020
Avg Loading time: 0.0034 seconds
Avg Batch time: 0.1257 seconds

Train time: 49.27206516265869
 * Prec@1 93.680 Prec@5 99.730 Loss 0.2271
Avg Loading time: 0.0380 seconds
Avg Batch time: 0.0732 seconds

Best acc: 93.760
--------------------------------------------------------------------------------
Test time: 6.3497865200042725

Epoch: [28][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.010)	BT: 0.115 (0.123)	Loss 0.0023 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [28][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.005)	BT: 0.106 (0.117)	Loss 0.0049 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [28][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.118 (0.115)	Loss 0.0012 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [28][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.113 (0.114)	Loss 0.0023 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [28][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.002)	BT: 0.116 (0.115)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0022 seconds
Avg Batch time: 0.1146 seconds

Train time: 44.868082761764526
 * Prec@1 93.760 Prec@5 99.720 Loss 0.2230
Avg Loading time: 0.0356 seconds
Avg Batch time: 0.0690 seconds

Best acc: 93.760
--------------------------------------------------------------------------------
Test time: 6.0126612186431885

Epoch: [29][77/391]	LR: 0.004000000000000001	DT: 0.000 (0.008)	BT: 0.108 (0.120)	Loss 0.0007 (0.0024)	Prec@1 100.000 (99.980)	
Epoch: [29][155/391]	LR: 0.004000000000000001	DT: 0.000 (0.004)	BT: 0.111 (0.115)	Loss 0.0024 (0.0022)	Prec@1 100.000 (99.985)	
Epoch: [29][233/391]	LR: 0.004000000000000001	DT: 0.000 (0.003)	BT: 0.117 (0.113)	Loss 0.0015 (0.0022)	Prec@1 100.000 (99.987)	
Epoch: [29][311/391]	LR: 0.004000000000000001	DT: 0.000 (0.002)	BT: 0.107 (0.111)	Loss 0.0016 (0.0022)	Prec@1 100.000 (99.990)	
Epoch: [29][389/391]	LR: 0.004000000000000001	DT: 0.000 (0.002)	BT: 0.118 (0.113)	Loss 0.0014 (0.0022)	Prec@1 100.000 (99.990)	
Total train loss: 0.0022
Avg Loading time: 0.0018 seconds
Avg Batch time: 0.1134 seconds

Train time: 44.41447138786316
 * Prec@1 93.770 Prec@5 99.690 Loss 0.2268
Avg Loading time: 0.0298 seconds
Avg Batch time: 0.0615 seconds

Best acc: 93.770
--------------------------------------------------------------------------------
Test time: 5.874657154083252

Epoch: [30][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.105 (0.122)	Loss 0.0026 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [30][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.106 (0.116)	Loss 0.0013 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [30][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.112 (0.114)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [30][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.115 (0.113)	Loss 0.0015 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [30][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.002)	BT: 0.105 (0.113)	Loss 0.0017 (0.0021)	Prec@1 100.000 (99.998)	
Total train loss: 0.0021
Avg Loading time: 0.0022 seconds
Avg Batch time: 0.1126 seconds

Train time: 44.12693500518799
 * Prec@1 93.710 Prec@5 99.700 Loss 0.2272
Avg Loading time: 0.0271 seconds
Avg Batch time: 0.0623 seconds

Best acc: 93.770
--------------------------------------------------------------------------------
Test time: 5.479169130325317

Epoch: [31][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.010)	BT: 0.105 (0.120)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [31][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.107 (0.116)	Loss 0.0028 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [31][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.117 (0.115)	Loss 0.0027 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [31][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.123 (0.114)	Loss 0.0014 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [31][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.002)	BT: 0.109 (0.113)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.998)	
Total train loss: 0.0021
Avg Loading time: 0.0021 seconds
Avg Batch time: 0.1131 seconds

Train time: 44.31075119972229
 * Prec@1 93.740 Prec@5 99.710 Loss 0.2262
Avg Loading time: 0.0244 seconds
Avg Batch time: 0.0605 seconds

Best acc: 93.770
--------------------------------------------------------------------------------
Test time: 5.358490943908691

Epoch: [32][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.105 (0.119)	Loss 0.0014 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [32][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.118 (0.114)	Loss 0.0023 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [32][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.106 (0.112)	Loss 0.0016 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [32][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.002)	BT: 0.104 (0.111)	Loss 0.0028 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [32][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.002)	BT: 0.115 (0.111)	Loss 0.0022 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0018 seconds
Avg Batch time: 0.1111 seconds

Train time: 43.527159690856934
 * Prec@1 93.690 Prec@5 99.710 Loss 0.2252
Avg Loading time: 0.0254 seconds
Avg Batch time: 0.0587 seconds

Best acc: 93.770
--------------------------------------------------------------------------------
Test time: 5.185213565826416

Epoch: [33][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.106 (0.128)	Loss 0.0021 (0.0024)	Prec@1 100.000 (99.980)	
Epoch: [33][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.112 (0.118)	Loss 0.0012 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [33][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.120 (0.116)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.993)	
Epoch: [33][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.002)	BT: 0.106 (0.114)	Loss 0.0012 (0.0020)	Prec@1 100.000 (99.995)	
Epoch: [33][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.002)	BT: 0.108 (0.114)	Loss 0.0018 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0020 seconds
Avg Batch time: 0.1138 seconds

Train time: 44.58941316604614
 * Prec@1 93.690 Prec@5 99.730 Loss 0.2274
Avg Loading time: 0.0245 seconds
Avg Batch time: 0.0585 seconds

Best acc: 93.770
--------------------------------------------------------------------------------
Test time: 5.1878557205200195

Epoch: [34][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.124 (0.125)	Loss 0.0016 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [34][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.110 (0.117)	Loss 0.0010 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [34][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.115 (0.115)	Loss 0.0076 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [34][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.002)	BT: 0.116 (0.114)	Loss 0.0015 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [34][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.002)	BT: 0.103 (0.113)	Loss 0.0009 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0019 seconds
Avg Batch time: 0.1130 seconds

Train time: 44.26638865470886
 * Prec@1 93.770 Prec@5 99.710 Loss 0.2231
Avg Loading time: 0.0265 seconds
Avg Batch time: 0.0581 seconds

Best acc: 93.770
--------------------------------------------------------------------------------
Test time: 5.1703526973724365

Epoch: [35][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.108 (0.124)	Loss 0.0012 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [35][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.106 (0.118)	Loss 0.0017 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [35][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.106 (0.117)	Loss 0.0025 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [35][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.107 (0.114)	Loss 0.0019 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [35][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.002)	BT: 0.122 (0.114)	Loss 0.0008 (0.0021)	Prec@1 100.000 (99.988)	
Total train loss: 0.0021
Avg Loading time: 0.0023 seconds
Avg Batch time: 0.1144 seconds

Train time: 44.799551010131836
 * Prec@1 93.730 Prec@5 99.710 Loss 0.2252
Avg Loading time: 0.0276 seconds
Avg Batch time: 0.0612 seconds

Best acc: 93.770
--------------------------------------------------------------------------------
Test time: 5.40282940864563

Epoch: [36][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.109 (0.122)	Loss 0.0007 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [36][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.106 (0.115)	Loss 0.0014 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [36][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.107 (0.114)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [36][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.106 (0.114)	Loss 0.0009 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [36][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.002)	BT: 0.103 (0.113)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.998)	
Total train loss: 0.0021
Avg Loading time: 0.0023 seconds
Avg Batch time: 0.1133 seconds

Train time: 44.36026930809021
 * Prec@1 93.830 Prec@5 99.710 Loss 0.2252
Avg Loading time: 0.0275 seconds
Avg Batch time: 0.0612 seconds

Best acc: 93.830
--------------------------------------------------------------------------------
Test time: 5.856119871139526

Epoch: [37][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.112 (0.120)	Loss 0.0012 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [37][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.106 (0.115)	Loss 0.0014 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [37][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.105 (0.113)	Loss 0.0016 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [37][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.109 (0.114)	Loss 0.0016 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [37][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.002)	BT: 0.105 (0.113)	Loss 0.0019 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0023 seconds
Avg Batch time: 0.1129 seconds

Train time: 44.24613571166992
 * Prec@1 93.750 Prec@5 99.720 Loss 0.2246
Avg Loading time: 0.0287 seconds
Avg Batch time: 0.0627 seconds

Best acc: 93.830
--------------------------------------------------------------------------------
Test time: 5.508509397506714

Epoch: [38][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.009)	BT: 0.107 (0.123)	Loss 0.0043 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [38][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.103 (0.116)	Loss 0.0021 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [38][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.007)	BT: 0.110 (0.120)	Loss 0.0022 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [38][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.005)	BT: 0.117 (0.117)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [38][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.121 (0.117)	Loss 0.0010 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0043 seconds
Avg Batch time: 0.1171 seconds

Train time: 45.87794756889343
 * Prec@1 93.710 Prec@5 99.680 Loss 0.2252
Avg Loading time: 0.0261 seconds
Avg Batch time: 0.0601 seconds

Best acc: 93.830
--------------------------------------------------------------------------------
Test time: 5.311785936355591

Epoch: [39][77/391]	LR: 0.0008000000000000003	DT: 0.000 (0.011)	BT: 0.123 (0.120)	Loss 0.0008 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [39][155/391]	LR: 0.0008000000000000003	DT: 0.000 (0.006)	BT: 0.106 (0.119)	Loss 0.0013 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [39][233/391]	LR: 0.0008000000000000003	DT: 0.000 (0.004)	BT: 0.111 (0.116)	Loss 0.0019 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [39][311/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.120 (0.115)	Loss 0.0037 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [39][389/391]	LR: 0.0008000000000000003	DT: 0.000 (0.003)	BT: 0.113 (0.114)	Loss 0.0008 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0026 seconds
Avg Batch time: 0.1140 seconds

Train time: 44.65048313140869
 * Prec@1 93.860 Prec@5 99.730 Loss 0.2246
Avg Loading time: 0.0229 seconds
Avg Batch time: 0.0583 seconds

Best acc: 93.860
--------------------------------------------------------------------------------
Test time: 5.629087448120117

Epoch: [40][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.119 (0.121)	Loss 0.0020 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [40][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.106 (0.116)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [40][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.107 (0.113)	Loss 0.0014 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [40][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.002)	BT: 0.118 (0.114)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [40][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.002)	BT: 0.108 (0.113)	Loss 0.0007 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.0020 seconds
Avg Batch time: 0.1134 seconds

Train time: 44.4102578163147
 * Prec@1 93.890 Prec@5 99.690 Loss 0.2246
Avg Loading time: 0.0285 seconds
Avg Batch time: 0.0621 seconds

Best acc: 93.890
--------------------------------------------------------------------------------
Test time: 5.9304039478302

Epoch: [41][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.105 (0.121)	Loss 0.0028 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [41][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.105 (0.115)	Loss 0.0015 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [41][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.118 (0.113)	Loss 0.0012 (0.0022)	Prec@1 100.000 (99.993)	
Epoch: [41][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.117 (0.112)	Loss 0.0032 (0.0022)	Prec@1 100.000 (99.992)	
Epoch: [41][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.002)	BT: 0.105 (0.113)	Loss 0.0011 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0023 seconds
Avg Batch time: 0.1125 seconds

Train time: 44.07453155517578
 * Prec@1 93.830 Prec@5 99.720 Loss 0.2262
Avg Loading time: 0.0259 seconds
Avg Batch time: 0.0615 seconds

Best acc: 93.890
--------------------------------------------------------------------------------
Test time: 5.41840386390686

Epoch: [42][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.110 (0.120)	Loss 0.0027 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [42][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.106 (0.115)	Loss 0.0021 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [42][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.106 (0.113)	Loss 0.0015 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [42][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.002)	BT: 0.105 (0.112)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [42][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.002)	BT: 0.114 (0.112)	Loss 0.0039 (0.0019)	Prec@1 100.000 (100.000)	
Total train loss: 0.0019
Avg Loading time: 0.0020 seconds
Avg Batch time: 0.1118 seconds

Train time: 43.81829285621643
 * Prec@1 93.760 Prec@5 99.720 Loss 0.2274
Avg Loading time: 0.0254 seconds
Avg Batch time: 0.0607 seconds

Best acc: 93.890
--------------------------------------------------------------------------------
Test time: 5.376726865768433

Epoch: [43][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.116 (0.119)	Loss 0.0070 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [43][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.108 (0.115)	Loss 0.0009 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [43][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.106 (0.113)	Loss 0.0020 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [43][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.115 (0.113)	Loss 0.0013 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [43][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.002)	BT: 0.106 (0.113)	Loss 0.0014 (0.0020)	Prec@1 100.000 (99.996)	
Total train loss: 0.0020
Avg Loading time: 0.0021 seconds
Avg Batch time: 0.1127 seconds

Train time: 44.17117786407471
 * Prec@1 93.770 Prec@5 99.720 Loss 0.2236
Avg Loading time: 0.0233 seconds
Avg Batch time: 0.0602 seconds

Best acc: 93.890
--------------------------------------------------------------------------------
Test time: 5.318462133407593

Epoch: [44][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.009)	BT: 0.105 (0.121)	Loss 0.0010 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [44][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.112 (0.117)	Loss 0.0034 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [44][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.108 (0.115)	Loss 0.0033 (0.0021)	Prec@1 100.000 (99.993)	
Epoch: [44][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.002)	BT: 0.119 (0.113)	Loss 0.0016 (0.0021)	Prec@1 100.000 (99.992)	
Epoch: [44][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.002)	BT: 0.111 (0.113)	Loss 0.0020 (0.0021)	Prec@1 100.000 (99.994)	
Total train loss: 0.0021
Avg Loading time: 0.0020 seconds
Avg Batch time: 0.1125 seconds

Train time: 44.08751130104065
 * Prec@1 93.610 Prec@5 99.720 Loss 0.2296
Avg Loading time: 0.0249 seconds
Avg Batch time: 0.0566 seconds

Best acc: 93.890
--------------------------------------------------------------------------------
Test time: 5.042797565460205

Epoch: [45][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.012)	BT: 0.106 (0.119)	Loss 0.0043 (0.0022)	Prec@1 100.000 (100.000)	
Epoch: [45][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.111 (0.114)	Loss 0.0010 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [45][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.125 (0.115)	Loss 0.0035 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [45][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.109 (0.115)	Loss 0.0010 (0.0022)	Prec@1 100.000 (99.997)	
Epoch: [45][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.002)	BT: 0.111 (0.115)	Loss 0.0014 (0.0022)	Prec@1 100.000 (99.998)	
Total train loss: 0.0022
Avg Loading time: 0.0024 seconds
Avg Batch time: 0.1146 seconds

Train time: 44.902750730514526
 * Prec@1 93.750 Prec@5 99.720 Loss 0.2231
Avg Loading time: 0.0256 seconds
Avg Batch time: 0.0589 seconds

Best acc: 93.890
--------------------------------------------------------------------------------
Test time: 5.222573757171631

Epoch: [46][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.108 (0.122)	Loss 0.0011 (0.0018)	Prec@1 100.000 (100.000)	
Epoch: [46][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.106 (0.115)	Loss 0.0013 (0.0019)	Prec@1 100.000 (100.000)	
Epoch: [46][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.112 (0.114)	Loss 0.0018 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [46][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.118 (0.115)	Loss 0.0012 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [46][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.002)	BT: 0.106 (0.114)	Loss 0.0033 (0.0020)	Prec@1 100.000 (100.000)	
Total train loss: 0.0020
Avg Loading time: 0.0021 seconds
Avg Batch time: 0.1141 seconds

Train time: 44.706120014190674
 * Prec@1 93.770 Prec@5 99.710 Loss 0.2274
Avg Loading time: 0.0246 seconds
Avg Batch time: 0.0592 seconds

Best acc: 93.890
--------------------------------------------------------------------------------
Test time: 5.249289274215698

Epoch: [47][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.114 (0.121)	Loss 0.0023 (0.0021)	Prec@1 100.000 (99.990)	
Epoch: [47][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.117 (0.115)	Loss 0.0016 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [47][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.112 (0.113)	Loss 0.0055 (0.0021)	Prec@1 100.000 (99.997)	
Epoch: [47][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.110 (0.113)	Loss 0.0019 (0.0021)	Prec@1 100.000 (99.995)	
Epoch: [47][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.002)	BT: 0.116 (0.113)	Loss 0.0013 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0023 seconds
Avg Batch time: 0.1133 seconds

Train time: 44.39586281776428
 * Prec@1 93.670 Prec@5 99.710 Loss 0.2294
Avg Loading time: 0.0243 seconds
Avg Batch time: 0.0595 seconds

Best acc: 93.890
--------------------------------------------------------------------------------
Test time: 5.276841878890991

Epoch: [48][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.011)	BT: 0.109 (0.120)	Loss 0.0016 (0.0026)	Prec@1 100.000 (99.990)	
Epoch: [48][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.006)	BT: 0.125 (0.116)	Loss 0.0009 (0.0024)	Prec@1 100.000 (99.995)	
Epoch: [48][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.106 (0.115)	Loss 0.0018 (0.0023)	Prec@1 100.000 (99.997)	
Epoch: [48][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.105 (0.114)	Loss 0.0013 (0.0022)	Prec@1 100.000 (99.995)	
Epoch: [48][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.002)	BT: 0.123 (0.114)	Loss 0.0017 (0.0021)	Prec@1 100.000 (99.996)	
Total train loss: 0.0021
Avg Loading time: 0.0024 seconds
Avg Batch time: 0.1135 seconds

Train time: 44.47087049484253
 * Prec@1 93.770 Prec@5 99.720 Loss 0.2271
Avg Loading time: 0.0250 seconds
Avg Batch time: 0.0590 seconds

Best acc: 93.890
--------------------------------------------------------------------------------
Test time: 5.229020357131958

Epoch: [49][77/391]	LR: 0.00016000000000000007	DT: 0.000 (0.010)	BT: 0.120 (0.123)	Loss 0.0040 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [49][155/391]	LR: 0.00016000000000000007	DT: 0.000 (0.005)	BT: 0.111 (0.117)	Loss 0.0008 (0.0021)	Prec@1 100.000 (100.000)	
Epoch: [49][233/391]	LR: 0.00016000000000000007	DT: 0.000 (0.004)	BT: 0.112 (0.115)	Loss 0.0042 (0.0020)	Prec@1 100.000 (100.000)	
Epoch: [49][311/391]	LR: 0.00016000000000000007	DT: 0.000 (0.003)	BT: 0.112 (0.115)	Loss 0.0016 (0.0020)	Prec@1 100.000 (99.997)	
Epoch: [49][389/391]	LR: 0.00016000000000000007	DT: 0.000 (0.002)	BT: 0.104 (0.113)	Loss 0.0024 (0.0020)	Prec@1 100.000 (99.998)	
Total train loss: 0.0020
Avg Loading time: 0.0022 seconds
Avg Batch time: 0.1132 seconds

Train time: 44.32415437698364
 * Prec@1 93.680 Prec@5 99.730 Loss 0.2249
Avg Loading time: 0.0306 seconds
Avg Batch time: 0.0607 seconds

Best acc: 93.890
--------------------------------------------------------------------------------
Test time: 5.353531360626221

