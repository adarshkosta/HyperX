
      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b-lp/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_half_quant_all_w7b_a7b_best.pth.tar
          mode: rram
          workers: 8
          epochs: 40
          start_epoch: 0
          batch_size: 256
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          milestones: [8, 16, 24, 32]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 15
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_half_quant_all_w7b_a7b_best.pth.tar ...
Original model accuracy: 89.29999542236328
ResNet_cifar(
  (conv16): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (conv18): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu18): ReLU(inplace=True)
  (conv19): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu19): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (bn20): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=64, out_features=10, bias=False)
  (bn21): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 9.970 Prec@5 52.330 Loss inf
Pre-trained Prec@1 with 15 layers frozen: 9.969999313354492 	 Loss: inf

Starting training on SRAM layers...
Epoch: [0][38/196]	LR: 0.1	Loss 0.7798 (0.9931)	Prec@1 72.266 (68.159)	
Epoch: [0][77/196]	LR: 0.1	Loss 0.4932 (0.8171)	Prec@1 85.156 (73.062)	
Epoch: [0][116/196]	LR: 0.1	Loss 0.5098 (0.7355)	Prec@1 83.984 (75.504)	
Epoch: [0][155/196]	LR: 0.1	Loss 0.4785 (0.6856)	Prec@1 83.594 (77.133)	
Epoch: [0][194/196]	LR: 0.1	Loss 0.6479 (0.6547)	Prec@1 76.562 (78.101)	
Total train loss: 0.6545

Train time: 443.5988163948059
 * Prec@1 36.970 Prec@5 91.590 Loss 1.8965
Best acc: 36.970
--------------------------------------------------------------------------------
Test time: 447.4293100833893

Epoch: [1][38/196]	LR: 0.1	Loss 0.5425 (0.4701)	Prec@1 83.594 (84.044)	
Epoch: [1][77/196]	LR: 0.1	Loss 0.5356 (0.4623)	Prec@1 83.203 (84.155)	
Epoch: [1][116/196]	LR: 0.1	Loss 0.4871 (0.4569)	Prec@1 83.984 (84.345)	
Epoch: [1][155/196]	LR: 0.1	Loss 0.4409 (0.4514)	Prec@1 86.328 (84.570)	
Epoch: [1][194/196]	LR: 0.1	Loss 0.3977 (0.4470)	Prec@1 85.547 (84.673)	
Total train loss: 0.4469

Train time: 19.43255877494812
 * Prec@1 37.090 Prec@5 90.760 Loss 2.1621
Best acc: 37.090
--------------------------------------------------------------------------------
Test time: 23.44003391265869

Epoch: [2][38/196]	LR: 0.1	Loss 0.3936 (0.3978)	Prec@1 87.891 (86.398)	
Epoch: [2][77/196]	LR: 0.1	Loss 0.3850 (0.3938)	Prec@1 85.547 (86.709)	
Epoch: [2][116/196]	LR: 0.1	Loss 0.3159 (0.3962)	Prec@1 88.672 (86.562)	
Epoch: [2][155/196]	LR: 0.1	Loss 0.3750 (0.3993)	Prec@1 85.156 (86.383)	
Epoch: [2][194/196]	LR: 0.1	Loss 0.3604 (0.3988)	Prec@1 87.109 (86.452)	
Total train loss: 0.3989

Train time: 18.598710298538208
 * Prec@1 33.490 Prec@5 91.080 Loss 2.1895
Best acc: 37.090
--------------------------------------------------------------------------------
Test time: 21.893903017044067

Epoch: [3][38/196]	LR: 0.1	Loss 0.3145 (0.3374)	Prec@1 89.844 (88.922)	
Epoch: [3][77/196]	LR: 0.1	Loss 0.2986 (0.3436)	Prec@1 90.234 (88.482)	
Epoch: [3][116/196]	LR: 0.1	Loss 0.4553 (0.3517)	Prec@1 82.422 (88.114)	
Epoch: [3][155/196]	LR: 0.1	Loss 0.4539 (0.3544)	Prec@1 84.766 (87.938)	
Epoch: [3][194/196]	LR: 0.1	Loss 0.4111 (0.3575)	Prec@1 86.719 (87.831)	
Total train loss: 0.3576

Train time: 15.356528759002686
 * Prec@1 39.550 Prec@5 90.730 Loss 1.9873
Best acc: 39.550
--------------------------------------------------------------------------------
Test time: 19.775662899017334

Epoch: [4][38/196]	LR: 0.1	Loss 0.4841 (0.3276)	Prec@1 85.156 (88.732)	
Epoch: [4][77/196]	LR: 0.1	Loss 0.2874 (0.3239)	Prec@1 90.625 (89.027)	
Epoch: [4][116/196]	LR: 0.1	Loss 0.3203 (0.3267)	Prec@1 86.719 (88.849)	
Epoch: [4][155/196]	LR: 0.1	Loss 0.3779 (0.3269)	Prec@1 87.500 (88.797)	
Epoch: [4][194/196]	LR: 0.1	Loss 0.2607 (0.3291)	Prec@1 90.234 (88.670)	
Total train loss: 0.3292

Train time: 17.55845832824707
 * Prec@1 25.360 Prec@5 88.160 Loss 3.3477
Best acc: 39.550
--------------------------------------------------------------------------------
Test time: 21.54847240447998

Epoch: [5][38/196]	LR: 0.1	Loss 0.2332 (0.3104)	Prec@1 92.188 (89.473)	
Epoch: [5][77/196]	LR: 0.1	Loss 0.2720 (0.3068)	Prec@1 89.062 (89.403)	
Epoch: [5][116/196]	LR: 0.1	Loss 0.2800 (0.3084)	Prec@1 90.234 (89.353)	
Epoch: [5][155/196]	LR: 0.1	Loss 0.2434 (0.3106)	Prec@1 91.016 (89.245)	
Epoch: [5][194/196]	LR: 0.1	Loss 0.2556 (0.3071)	Prec@1 90.625 (89.369)	
Total train loss: 0.3073

Train time: 16.58779549598694
 * Prec@1 37.710 Prec@5 90.640 Loss 2.7266
Best acc: 39.550
--------------------------------------------------------------------------------
Test time: 21.095845937728882

Epoch: [6][38/196]	LR: 0.1	Loss 0.2722 (0.2696)	Prec@1 91.016 (90.655)	
Epoch: [6][77/196]	LR: 0.1	Loss 0.3159 (0.2690)	Prec@1 88.281 (90.670)	
Epoch: [6][116/196]	LR: 0.1	Loss 0.2854 (0.2786)	Prec@1 91.797 (90.335)	
Epoch: [6][155/196]	LR: 0.1	Loss 0.3362 (0.2816)	Prec@1 88.672 (90.227)	
Epoch: [6][194/196]	LR: 0.1	Loss 0.3047 (0.2874)	Prec@1 89.453 (89.988)	
Total train loss: 0.2873

Train time: 15.497594833374023
 * Prec@1 47.920 Prec@5 93.230 Loss 1.8271
Best acc: 47.920
--------------------------------------------------------------------------------
Test time: 19.462694883346558

Epoch: [7][38/196]	LR: 0.1	Loss 0.3003 (0.2687)	Prec@1 90.625 (90.725)	
Epoch: [7][77/196]	LR: 0.1	Loss 0.2354 (0.2593)	Prec@1 92.969 (91.231)	
Epoch: [7][116/196]	LR: 0.1	Loss 0.2141 (0.2614)	Prec@1 92.578 (91.086)	
Epoch: [7][155/196]	LR: 0.1	Loss 0.2751 (0.2613)	Prec@1 88.281 (91.003)	
Epoch: [7][194/196]	LR: 0.1	Loss 0.2507 (0.2660)	Prec@1 90.625 (90.833)	
Total train loss: 0.2665

Train time: 17.009820461273193
 * Prec@1 48.210 Prec@5 93.750 Loss 1.9023
Best acc: 48.210
--------------------------------------------------------------------------------
Test time: 21.98878312110901

Epoch: [8][38/196]	LR: 0.010000000000000002	Loss 0.2289 (0.2505)	Prec@1 91.406 (91.236)	
Epoch: [8][77/196]	LR: 0.010000000000000002	Loss 0.2830 (0.2445)	Prec@1 91.016 (91.567)	
Epoch: [8][116/196]	LR: 0.010000000000000002	Loss 0.2174 (0.2414)	Prec@1 92.578 (91.774)	
Epoch: [8][155/196]	LR: 0.010000000000000002	Loss 0.1992 (0.2396)	Prec@1 94.141 (91.864)	
Epoch: [8][194/196]	LR: 0.010000000000000002	Loss 0.3708 (0.2381)	Prec@1 87.500 (91.845)	
Total train loss: 0.2382

Train time: 14.517435312271118
 * Prec@1 50.120 Prec@5 94.330 Loss 1.7139
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 18.118008375167847

Epoch: [9][38/196]	LR: 0.010000000000000002	Loss 0.2703 (0.2237)	Prec@1 89.453 (92.548)	
Epoch: [9][77/196]	LR: 0.010000000000000002	Loss 0.2344 (0.2256)	Prec@1 92.188 (92.468)	
Epoch: [9][116/196]	LR: 0.010000000000000002	Loss 0.1827 (0.2266)	Prec@1 94.531 (92.438)	
Epoch: [9][155/196]	LR: 0.010000000000000002	Loss 0.2297 (0.2278)	Prec@1 92.188 (92.320)	
Epoch: [9][194/196]	LR: 0.010000000000000002	Loss 0.2202 (0.2296)	Prec@1 92.188 (92.202)	
Total train loss: 0.2297

Train time: 15.793768882751465
 * Prec@1 49.840 Prec@5 95.040 Loss 1.8525
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 20.0655779838562

Epoch: [10][38/196]	LR: 0.010000000000000002	Loss 0.2854 (0.2339)	Prec@1 91.016 (92.057)	
Epoch: [10][77/196]	LR: 0.010000000000000002	Loss 0.1952 (0.2320)	Prec@1 91.797 (92.057)	
Epoch: [10][116/196]	LR: 0.010000000000000002	Loss 0.2600 (0.2334)	Prec@1 93.359 (92.051)	
Epoch: [10][155/196]	LR: 0.010000000000000002	Loss 0.2144 (0.2317)	Prec@1 92.969 (92.102)	
Epoch: [10][194/196]	LR: 0.010000000000000002	Loss 0.1890 (0.2325)	Prec@1 94.141 (92.057)	
Total train loss: 0.2324

Train time: 16.49475908279419
 * Prec@1 49.060 Prec@5 93.970 Loss 1.7139
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 21.375906467437744

Epoch: [11][38/196]	LR: 0.010000000000000002	Loss 0.2595 (0.2251)	Prec@1 91.016 (92.398)	
Epoch: [11][77/196]	LR: 0.010000000000000002	Loss 0.2318 (0.2273)	Prec@1 92.188 (92.333)	
Epoch: [11][116/196]	LR: 0.010000000000000002	Loss 0.2491 (0.2293)	Prec@1 90.625 (92.281)	
Epoch: [11][155/196]	LR: 0.010000000000000002	Loss 0.1766 (0.2278)	Prec@1 95.312 (92.360)	
Epoch: [11][194/196]	LR: 0.010000000000000002	Loss 0.2324 (0.2278)	Prec@1 91.797 (92.338)	
Total train loss: 0.2277

Train time: 16.226174354553223
 * Prec@1 48.440 Prec@5 95.300 Loss 1.9346
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 20.717829942703247

Epoch: [12][38/196]	LR: 0.010000000000000002	Loss 0.1732 (0.2260)	Prec@1 94.922 (92.508)	
Epoch: [12][77/196]	LR: 0.010000000000000002	Loss 0.2500 (0.2228)	Prec@1 92.578 (92.658)	
Epoch: [12][116/196]	LR: 0.010000000000000002	Loss 0.2307 (0.2239)	Prec@1 91.797 (92.541)	
Epoch: [12][155/196]	LR: 0.010000000000000002	Loss 0.2981 (0.2248)	Prec@1 91.016 (92.410)	
Epoch: [12][194/196]	LR: 0.010000000000000002	Loss 0.1993 (0.2258)	Prec@1 93.359 (92.342)	
Total train loss: 0.2257

Train time: 17.799461126327515
 * Prec@1 47.850 Prec@5 94.460 Loss 1.9150
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 21.32331609725952

Epoch: [13][38/196]	LR: 0.010000000000000002	Loss 0.2255 (0.2233)	Prec@1 91.016 (92.208)	
Epoch: [13][77/196]	LR: 0.010000000000000002	Loss 0.1918 (0.2271)	Prec@1 93.359 (92.027)	
Epoch: [13][116/196]	LR: 0.010000000000000002	Loss 0.2632 (0.2309)	Prec@1 91.797 (92.031)	
Epoch: [13][155/196]	LR: 0.010000000000000002	Loss 0.2375 (0.2267)	Prec@1 91.406 (92.198)	
Epoch: [13][194/196]	LR: 0.010000000000000002	Loss 0.2417 (0.2282)	Prec@1 91.797 (92.163)	
Total train loss: 0.2281

Train time: 16.08158254623413
 * Prec@1 48.930 Prec@5 94.570 Loss 1.8291
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 20.902116298675537

Epoch: [14][38/196]	LR: 0.010000000000000002	Loss 0.2106 (0.2223)	Prec@1 92.578 (92.438)	
Epoch: [14][77/196]	LR: 0.010000000000000002	Loss 0.2159 (0.2229)	Prec@1 93.750 (92.518)	
Epoch: [14][116/196]	LR: 0.010000000000000002	Loss 0.1970 (0.2259)	Prec@1 93.359 (92.358)	
Epoch: [14][155/196]	LR: 0.010000000000000002	Loss 0.2186 (0.2311)	Prec@1 91.406 (92.215)	
Epoch: [14][194/196]	LR: 0.010000000000000002	Loss 0.2198 (0.2321)	Prec@1 92.578 (92.155)	
Total train loss: 0.2320

Train time: 15.8669273853302
 * Prec@1 48.140 Prec@5 94.060 Loss 1.7490
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 19.296072483062744

Epoch: [15][38/196]	LR: 0.010000000000000002	Loss 0.2125 (0.2234)	Prec@1 91.016 (92.528)	
Epoch: [15][77/196]	LR: 0.010000000000000002	Loss 0.2839 (0.2234)	Prec@1 90.625 (92.438)	
Epoch: [15][116/196]	LR: 0.010000000000000002	Loss 0.1807 (0.2245)	Prec@1 95.312 (92.354)	
Epoch: [15][155/196]	LR: 0.010000000000000002	Loss 0.2062 (0.2271)	Prec@1 92.969 (92.260)	
Epoch: [15][194/196]	LR: 0.010000000000000002	Loss 0.2213 (0.2290)	Prec@1 92.578 (92.202)	
Total train loss: 0.2292

Train time: 15.515277624130249
 * Prec@1 49.340 Prec@5 94.540 Loss 1.7588
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 18.894203424453735

Epoch: [16][38/196]	LR: 0.0010000000000000002	Loss 0.2423 (0.2353)	Prec@1 91.406 (91.957)	
Epoch: [16][77/196]	LR: 0.0010000000000000002	Loss 0.2151 (0.2325)	Prec@1 93.750 (92.142)	
Epoch: [16][116/196]	LR: 0.0010000000000000002	Loss 0.2178 (0.2294)	Prec@1 94.531 (92.244)	
Epoch: [16][155/196]	LR: 0.0010000000000000002	Loss 0.2534 (0.2309)	Prec@1 91.797 (92.140)	
Epoch: [16][194/196]	LR: 0.0010000000000000002	Loss 0.2145 (0.2289)	Prec@1 91.016 (92.250)	
Total train loss: 0.2290

Train time: 15.941337585449219
 * Prec@1 49.040 Prec@5 94.220 Loss 1.7520
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 18.636977434158325

Epoch: [17][38/196]	LR: 0.0010000000000000002	Loss 0.2588 (0.2319)	Prec@1 93.750 (92.017)	
Epoch: [17][77/196]	LR: 0.0010000000000000002	Loss 0.2505 (0.2273)	Prec@1 92.188 (92.433)	
Epoch: [17][116/196]	LR: 0.0010000000000000002	Loss 0.2124 (0.2304)	Prec@1 91.406 (92.214)	
Epoch: [17][155/196]	LR: 0.0010000000000000002	Loss 0.2800 (0.2301)	Prec@1 90.234 (92.205)	
Epoch: [17][194/196]	LR: 0.0010000000000000002	Loss 0.1689 (0.2289)	Prec@1 95.312 (92.252)	
Total train loss: 0.2287

Train time: 16.669559717178345
 * Prec@1 48.920 Prec@5 94.460 Loss 1.7314
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 20.486274242401123

Epoch: [18][38/196]	LR: 0.0010000000000000002	Loss 0.2434 (0.2225)	Prec@1 90.625 (92.438)	
Epoch: [18][77/196]	LR: 0.0010000000000000002	Loss 0.2021 (0.2269)	Prec@1 93.359 (92.478)	
Epoch: [18][116/196]	LR: 0.0010000000000000002	Loss 0.2445 (0.2279)	Prec@1 93.359 (92.331)	
Epoch: [18][155/196]	LR: 0.0010000000000000002	Loss 0.2300 (0.2278)	Prec@1 91.797 (92.263)	
Epoch: [18][194/196]	LR: 0.0010000000000000002	Loss 0.2517 (0.2284)	Prec@1 91.406 (92.300)	
Total train loss: 0.2290

Train time: 16.28408455848694
 * Prec@1 49.490 Prec@5 94.590 Loss 1.7236
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 19.341227531433105

Epoch: [19][38/196]	LR: 0.0010000000000000002	Loss 0.2727 (0.2248)	Prec@1 90.625 (92.358)	
Epoch: [19][77/196]	LR: 0.0010000000000000002	Loss 0.1556 (0.2232)	Prec@1 94.531 (92.313)	
Epoch: [19][116/196]	LR: 0.0010000000000000002	Loss 0.2363 (0.2232)	Prec@1 90.625 (92.291)	
Epoch: [19][155/196]	LR: 0.0010000000000000002	Loss 0.1963 (0.2260)	Prec@1 93.750 (92.245)	
Epoch: [19][194/196]	LR: 0.0010000000000000002	Loss 0.1577 (0.2270)	Prec@1 95.312 (92.254)	
Total train loss: 0.2271

Train time: 16.11297845840454
 * Prec@1 49.170 Prec@5 94.500 Loss 1.7275
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 20.439751386642456

Epoch: [20][38/196]	LR: 0.0010000000000000002	Loss 0.2014 (0.2356)	Prec@1 94.531 (91.897)	
Epoch: [20][77/196]	LR: 0.0010000000000000002	Loss 0.2710 (0.2290)	Prec@1 90.625 (92.102)	
Epoch: [20][116/196]	LR: 0.0010000000000000002	Loss 0.2639 (0.2302)	Prec@1 90.625 (92.191)	
Epoch: [20][155/196]	LR: 0.0010000000000000002	Loss 0.1962 (0.2288)	Prec@1 93.359 (92.210)	
Epoch: [20][194/196]	LR: 0.0010000000000000002	Loss 0.2367 (0.2286)	Prec@1 91.797 (92.294)	
Total train loss: 0.2287

Train time: 16.30430293083191
 * Prec@1 48.900 Prec@5 94.350 Loss 1.7695
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 19.52541446685791

Epoch: [21][38/196]	LR: 0.0010000000000000002	Loss 0.2393 (0.2346)	Prec@1 92.969 (91.887)	
Epoch: [21][77/196]	LR: 0.0010000000000000002	Loss 0.2292 (0.2284)	Prec@1 93.359 (92.213)	
Epoch: [21][116/196]	LR: 0.0010000000000000002	Loss 0.2195 (0.2302)	Prec@1 92.969 (92.147)	
Epoch: [21][155/196]	LR: 0.0010000000000000002	Loss 0.2366 (0.2309)	Prec@1 91.406 (92.122)	
Epoch: [21][194/196]	LR: 0.0010000000000000002	Loss 0.2120 (0.2288)	Prec@1 92.969 (92.222)	
Total train loss: 0.2289

Train time: 17.202661991119385
 * Prec@1 48.970 Prec@5 94.390 Loss 1.7500
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 21.598880767822266

Epoch: [22][38/196]	LR: 0.0010000000000000002	Loss 0.2651 (0.2345)	Prec@1 91.016 (92.238)	
Epoch: [22][77/196]	LR: 0.0010000000000000002	Loss 0.1993 (0.2381)	Prec@1 94.141 (92.032)	
Epoch: [22][116/196]	LR: 0.0010000000000000002	Loss 0.2986 (0.2337)	Prec@1 87.500 (92.024)	
Epoch: [22][155/196]	LR: 0.0010000000000000002	Loss 0.2159 (0.2296)	Prec@1 94.141 (92.182)	
Epoch: [22][194/196]	LR: 0.0010000000000000002	Loss 0.2030 (0.2285)	Prec@1 93.359 (92.276)	
Total train loss: 0.2287

Train time: 15.699289798736572
 * Prec@1 49.510 Prec@5 94.510 Loss 1.7295
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 18.68604278564453

Epoch: [23][38/196]	LR: 0.0010000000000000002	Loss 0.1504 (0.2374)	Prec@1 94.531 (92.047)	
Epoch: [23][77/196]	LR: 0.0010000000000000002	Loss 0.2358 (0.2319)	Prec@1 93.359 (92.288)	
Epoch: [23][116/196]	LR: 0.0010000000000000002	Loss 0.2354 (0.2295)	Prec@1 92.969 (92.234)	
Epoch: [23][155/196]	LR: 0.0010000000000000002	Loss 0.2283 (0.2270)	Prec@1 92.188 (92.333)	
Epoch: [23][194/196]	LR: 0.0010000000000000002	Loss 0.2559 (0.2275)	Prec@1 90.234 (92.342)	
Total train loss: 0.2275

Train time: 16.160014152526855
 * Prec@1 49.340 Prec@5 94.440 Loss 1.7520
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 20.618200063705444

Epoch: [24][38/196]	LR: 0.00010000000000000003	Loss 0.2646 (0.2269)	Prec@1 89.844 (92.208)	
Epoch: [24][77/196]	LR: 0.00010000000000000003	Loss 0.1853 (0.2243)	Prec@1 92.969 (92.323)	
Epoch: [24][116/196]	LR: 0.00010000000000000003	Loss 0.1849 (0.2268)	Prec@1 93.750 (92.171)	
Epoch: [24][155/196]	LR: 0.00010000000000000003	Loss 0.2056 (0.2277)	Prec@1 93.750 (92.220)	
Epoch: [24][194/196]	LR: 0.00010000000000000003	Loss 0.2097 (0.2288)	Prec@1 92.969 (92.185)	
Total train loss: 0.2289

Train time: 20.4849750995636
 * Prec@1 48.460 Prec@5 94.500 Loss 1.7812
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 23.817305326461792

Epoch: [25][38/196]	LR: 0.00010000000000000003	Loss 0.2183 (0.2252)	Prec@1 92.188 (92.338)	
Epoch: [25][77/196]	LR: 0.00010000000000000003	Loss 0.2678 (0.2264)	Prec@1 90.625 (92.268)	
Epoch: [25][116/196]	LR: 0.00010000000000000003	Loss 0.2438 (0.2293)	Prec@1 91.797 (92.164)	
Epoch: [25][155/196]	LR: 0.00010000000000000003	Loss 0.2429 (0.2293)	Prec@1 90.234 (92.160)	
Epoch: [25][194/196]	LR: 0.00010000000000000003	Loss 0.2451 (0.2284)	Prec@1 92.969 (92.224)	
Total train loss: 0.2283

Train time: 18.757633686065674
 * Prec@1 49.640 Prec@5 94.390 Loss 1.7236
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 23.285186052322388

Epoch: [26][38/196]	LR: 0.00010000000000000003	Loss 0.2191 (0.2265)	Prec@1 92.578 (92.268)	
Epoch: [26][77/196]	LR: 0.00010000000000000003	Loss 0.2201 (0.2259)	Prec@1 92.188 (92.273)	
Epoch: [26][116/196]	LR: 0.00010000000000000003	Loss 0.2698 (0.2244)	Prec@1 89.453 (92.324)	
Epoch: [26][155/196]	LR: 0.00010000000000000003	Loss 0.3269 (0.2258)	Prec@1 88.672 (92.298)	
Epoch: [26][194/196]	LR: 0.00010000000000000003	Loss 0.2908 (0.2275)	Prec@1 91.797 (92.258)	
Total train loss: 0.2278

Train time: 20.15269112586975
 * Prec@1 49.180 Prec@5 94.460 Loss 1.7373
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 24.530569553375244

Epoch: [27][38/196]	LR: 0.00010000000000000003	Loss 0.2161 (0.2289)	Prec@1 92.969 (92.288)	
Epoch: [27][77/196]	LR: 0.00010000000000000003	Loss 0.2190 (0.2289)	Prec@1 92.578 (92.208)	
Epoch: [27][116/196]	LR: 0.00010000000000000003	Loss 0.2776 (0.2308)	Prec@1 89.844 (92.177)	
Epoch: [27][155/196]	LR: 0.00010000000000000003	Loss 0.2203 (0.2302)	Prec@1 90.625 (92.193)	
Epoch: [27][194/196]	LR: 0.00010000000000000003	Loss 0.2086 (0.2272)	Prec@1 92.188 (92.268)	
Total train loss: 0.2272

Train time: 17.5099778175354
 * Prec@1 49.680 Prec@5 94.410 Loss 1.7012
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 20.880288124084473

Epoch: [28][38/196]	LR: 0.00010000000000000003	Loss 0.2043 (0.2260)	Prec@1 96.094 (92.308)	
Epoch: [28][77/196]	LR: 0.00010000000000000003	Loss 0.2590 (0.2304)	Prec@1 93.359 (92.193)	
Epoch: [28][116/196]	LR: 0.00010000000000000003	Loss 0.2188 (0.2298)	Prec@1 92.188 (92.198)	
Epoch: [28][155/196]	LR: 0.00010000000000000003	Loss 0.2037 (0.2282)	Prec@1 92.969 (92.255)	
Epoch: [28][194/196]	LR: 0.00010000000000000003	Loss 0.2340 (0.2290)	Prec@1 92.969 (92.234)	
Total train loss: 0.2290

Train time: 16.13283133506775
 * Prec@1 48.600 Prec@5 94.440 Loss 1.7812
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 19.365331888198853

Epoch: [29][38/196]	LR: 0.00010000000000000003	Loss 0.2118 (0.2324)	Prec@1 92.969 (92.338)	
Epoch: [29][77/196]	LR: 0.00010000000000000003	Loss 0.2607 (0.2341)	Prec@1 92.578 (92.112)	
Epoch: [29][116/196]	LR: 0.00010000000000000003	Loss 0.1794 (0.2292)	Prec@1 92.188 (92.221)	
Epoch: [29][155/196]	LR: 0.00010000000000000003	Loss 0.1951 (0.2279)	Prec@1 94.141 (92.253)	
Epoch: [29][194/196]	LR: 0.00010000000000000003	Loss 0.2578 (0.2283)	Prec@1 89.453 (92.240)	
Total train loss: 0.2282

Train time: 17.60512661933899
 * Prec@1 49.040 Prec@5 94.490 Loss 1.7441
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 21.665069341659546

Epoch: [30][38/196]	LR: 0.00010000000000000003	Loss 0.2603 (0.2348)	Prec@1 92.188 (91.987)	
Epoch: [30][77/196]	LR: 0.00010000000000000003	Loss 0.2423 (0.2288)	Prec@1 92.578 (92.182)	
Epoch: [30][116/196]	LR: 0.00010000000000000003	Loss 0.2164 (0.2293)	Prec@1 92.969 (92.201)	
Epoch: [30][155/196]	LR: 0.00010000000000000003	Loss 0.2515 (0.2303)	Prec@1 91.016 (92.182)	
Epoch: [30][194/196]	LR: 0.00010000000000000003	Loss 0.1888 (0.2294)	Prec@1 92.188 (92.192)	
Total train loss: 0.2295

Train time: 16.30804443359375
 * Prec@1 48.860 Prec@5 94.580 Loss 1.7676
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 19.748886346817017

Epoch: [31][38/196]	LR: 0.00010000000000000003	Loss 0.2126 (0.2275)	Prec@1 94.141 (92.298)	
Epoch: [31][77/196]	LR: 0.00010000000000000003	Loss 0.2522 (0.2301)	Prec@1 92.188 (92.278)	
Epoch: [31][116/196]	LR: 0.00010000000000000003	Loss 0.2178 (0.2285)	Prec@1 93.750 (92.304)	
Epoch: [31][155/196]	LR: 0.00010000000000000003	Loss 0.2245 (0.2284)	Prec@1 92.188 (92.263)	
Epoch: [31][194/196]	LR: 0.00010000000000000003	Loss 0.2212 (0.2289)	Prec@1 90.234 (92.274)	
Total train loss: 0.2290

Train time: 16.06594228744507
 * Prec@1 49.390 Prec@5 94.480 Loss 1.7314
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 19.435434818267822

Epoch: [32][38/196]	LR: 1.0000000000000004e-05	Loss 0.2269 (0.2328)	Prec@1 92.969 (91.967)	
Epoch: [32][77/196]	LR: 1.0000000000000004e-05	Loss 0.2603 (0.2345)	Prec@1 90.625 (92.047)	
Epoch: [32][116/196]	LR: 1.0000000000000004e-05	Loss 0.2942 (0.2324)	Prec@1 90.234 (92.064)	
Epoch: [32][155/196]	LR: 1.0000000000000004e-05	Loss 0.2493 (0.2292)	Prec@1 90.625 (92.238)	
Epoch: [32][194/196]	LR: 1.0000000000000004e-05	Loss 0.1783 (0.2273)	Prec@1 93.359 (92.312)	
Total train loss: 0.2273

Train time: 16.533570528030396
 * Prec@1 49.030 Prec@5 94.490 Loss 1.7617
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 20.483548641204834

Epoch: [33][38/196]	LR: 1.0000000000000004e-05	Loss 0.1841 (0.2358)	Prec@1 93.750 (92.298)	
Epoch: [33][77/196]	LR: 1.0000000000000004e-05	Loss 0.2056 (0.2283)	Prec@1 91.406 (92.503)	
Epoch: [33][116/196]	LR: 1.0000000000000004e-05	Loss 0.2551 (0.2305)	Prec@1 89.844 (92.194)	
Epoch: [33][155/196]	LR: 1.0000000000000004e-05	Loss 0.2454 (0.2296)	Prec@1 91.797 (92.177)	
Epoch: [33][194/196]	LR: 1.0000000000000004e-05	Loss 0.2040 (0.2279)	Prec@1 91.406 (92.248)	
Total train loss: 0.2280

Train time: 17.346669673919678
 * Prec@1 49.230 Prec@5 94.500 Loss 1.7344
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 20.586342334747314

Epoch: [34][38/196]	LR: 1.0000000000000004e-05	Loss 0.1980 (0.2273)	Prec@1 95.312 (92.348)	
Epoch: [34][77/196]	LR: 1.0000000000000004e-05	Loss 0.1812 (0.2257)	Prec@1 94.531 (92.413)	
Epoch: [34][116/196]	LR: 1.0000000000000004e-05	Loss 0.2335 (0.2283)	Prec@1 92.969 (92.334)	
Epoch: [34][155/196]	LR: 1.0000000000000004e-05	Loss 0.2234 (0.2263)	Prec@1 91.797 (92.403)	
Epoch: [34][194/196]	LR: 1.0000000000000004e-05	Loss 0.2947 (0.2271)	Prec@1 91.016 (92.382)	
Total train loss: 0.2275

Train time: 17.208335399627686
 * Prec@1 49.360 Prec@5 94.590 Loss 1.7393
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 20.505778312683105

Epoch: [35][38/196]	LR: 1.0000000000000004e-05	Loss 0.2542 (0.2392)	Prec@1 91.797 (92.218)	
Epoch: [35][77/196]	LR: 1.0000000000000004e-05	Loss 0.2876 (0.2284)	Prec@1 89.453 (92.428)	
Epoch: [35][116/196]	LR: 1.0000000000000004e-05	Loss 0.2047 (0.2286)	Prec@1 92.578 (92.264)	
Epoch: [35][155/196]	LR: 1.0000000000000004e-05	Loss 0.2876 (0.2289)	Prec@1 90.625 (92.265)	
Epoch: [35][194/196]	LR: 1.0000000000000004e-05	Loss 0.1864 (0.2290)	Prec@1 93.359 (92.256)	
Total train loss: 0.2291

Train time: 16.399532556533813
 * Prec@1 48.950 Prec@5 94.460 Loss 1.7549
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 20.26639461517334

Epoch: [36][38/196]	LR: 1.0000000000000004e-05	Loss 0.2639 (0.2363)	Prec@1 91.016 (91.817)	
Epoch: [36][77/196]	LR: 1.0000000000000004e-05	Loss 0.2634 (0.2331)	Prec@1 92.578 (91.992)	
Epoch: [36][116/196]	LR: 1.0000000000000004e-05	Loss 0.1909 (0.2298)	Prec@1 92.969 (92.111)	
Epoch: [36][155/196]	LR: 1.0000000000000004e-05	Loss 0.2927 (0.2284)	Prec@1 92.578 (92.177)	
Epoch: [36][194/196]	LR: 1.0000000000000004e-05	Loss 0.2494 (0.2294)	Prec@1 91.797 (92.123)	
Total train loss: 0.2296

Train time: 16.592512845993042
 * Prec@1 49.130 Prec@5 94.450 Loss 1.7490
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 20.28176784515381

Epoch: [37][38/196]	LR: 1.0000000000000004e-05	Loss 0.2795 (0.2302)	Prec@1 90.625 (92.147)	
Epoch: [37][77/196]	LR: 1.0000000000000004e-05	Loss 0.2257 (0.2310)	Prec@1 91.797 (92.127)	
Epoch: [37][116/196]	LR: 1.0000000000000004e-05	Loss 0.2783 (0.2320)	Prec@1 89.453 (92.051)	
Epoch: [37][155/196]	LR: 1.0000000000000004e-05	Loss 0.2418 (0.2305)	Prec@1 91.016 (92.137)	
Epoch: [37][194/196]	LR: 1.0000000000000004e-05	Loss 0.2563 (0.2291)	Prec@1 90.625 (92.177)	
Total train loss: 0.2292

Train time: 16.688713788986206
 * Prec@1 49.050 Prec@5 94.510 Loss 1.7500
Best acc: 50.120
--------------------------------------------------------------------------------
Test time: 20.119680881500244

Epoch: [38][38/196]	LR: 1.0000000000000004e-05	Loss 0.2778 (0.2176)	Prec@1 90.625 (92.648)	
Epoch: [38][77/196]	LR: 1.0000000000000004e-05	Loss 0.1447 (0.2200)	Prec@1 96.094 (92.643)	
Epoch: [38][116/196]	LR: 1.0000000000000004e-05	Loss 0.2727 (0.2260)	Prec@1 91.406 (92.411)	
Epoch: [38][155/196]	LR: 1.0000000000000004e-05	Loss 0.2296 (0.2264)	Prec@1 92.969 (92.348)	
Epoch: [38][194/196]	LR: 1.0000000000000004e-05	Loss 0.2786 (0.2267)	Prec@1 91.797 (92.352)	
Total train loss: 0.2268

Train time: 15.754353761672974
 * Prec@1 50.180 Prec@5 94.490 Loss 1.6914
Best acc: 50.180
--------------------------------------------------------------------------------
Test time: 19.617882013320923

Epoch: [39][38/196]	LR: 1.0000000000000004e-05	Loss 0.1742 (0.2267)	Prec@1 94.922 (92.488)	
Epoch: [39][77/196]	LR: 1.0000000000000004e-05	Loss 0.2445 (0.2312)	Prec@1 90.625 (92.112)	
Epoch: [39][116/196]	LR: 1.0000000000000004e-05	Loss 0.2749 (0.2305)	Prec@1 91.406 (92.184)	
Epoch: [39][155/196]	LR: 1.0000000000000004e-05	Loss 0.2148 (0.2294)	Prec@1 92.969 (92.220)	
Epoch: [39][194/196]	LR: 1.0000000000000004e-05	Loss 0.2969 (0.2303)	Prec@1 89.844 (92.151)	
Total train loss: 0.2303

Train time: 16.133675575256348
 * Prec@1 50.250 Prec@5 94.420 Loss 1.6699
Best acc: 50.250
--------------------------------------------------------------------------------
Test time: 19.41331124305725

