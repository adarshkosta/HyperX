
      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b-lp/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_half_quant_all_w7b_a7b_best.pth.tar
          mode: rram
          workers: 8
          epochs: 40
          start_epoch: 0
          batch_size: 256
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          milestones: [8, 16, 24, 32]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 17
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_half_quant_all_w7b_a7b_best.pth.tar ...
Original model accuracy: 89.29999542236328
ResNet_cifar(
  (conv18): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu18): ReLU(inplace=True)
  (conv19): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu19): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (bn20): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=64, out_features=10, bias=False)
  (bn21): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 11.600 Prec@5 56.150 Loss inf
Pre-trained Prec@1 with 17 layers frozen: 11.59999942779541 	 Loss: inf

Starting training on SRAM layers...
Epoch: [0][38/196]	LR: 0.1	Loss 0.6128 (0.8713)	Prec@1 79.297 (72.666)	
Epoch: [0][77/196]	LR: 0.1	Loss 0.5522 (0.7214)	Prec@1 81.641 (76.863)	
Epoch: [0][116/196]	LR: 0.1	Loss 0.4990 (0.6642)	Prec@1 82.031 (78.299)	
Epoch: [0][155/196]	LR: 0.1	Loss 0.4707 (0.6258)	Prec@1 85.156 (79.422)	
Epoch: [0][194/196]	LR: 0.1	Loss 0.5059 (0.5980)	Prec@1 83.984 (80.268)	
Total train loss: 0.5978

Train time: 336.1517083644867
 * Prec@1 51.770 Prec@5 96.060 Loss 1.6172
Best acc: 51.770
--------------------------------------------------------------------------------
Test time: 348.0826196670532

Epoch: [1][38/196]	LR: 0.1	Loss 0.4216 (0.4712)	Prec@1 86.719 (83.724)	
Epoch: [1][77/196]	LR: 0.1	Loss 0.3496 (0.4688)	Prec@1 88.672 (83.844)	
Epoch: [1][116/196]	LR: 0.1	Loss 0.4683 (0.4607)	Prec@1 83.594 (84.268)	
Epoch: [1][155/196]	LR: 0.1	Loss 0.4490 (0.4537)	Prec@1 85.156 (84.458)	
Epoch: [1][194/196]	LR: 0.1	Loss 0.5679 (0.4532)	Prec@1 82.031 (84.463)	
Total train loss: 0.4532

Train time: 30.78500485420227
 * Prec@1 54.260 Prec@5 95.400 Loss 1.5469
Best acc: 54.260
--------------------------------------------------------------------------------
Test time: 35.029789686203

Epoch: [2][38/196]	LR: 0.1	Loss 0.3064 (0.4307)	Prec@1 89.844 (85.317)	
Epoch: [2][77/196]	LR: 0.1	Loss 0.3640 (0.4213)	Prec@1 87.891 (85.387)	
Epoch: [2][116/196]	LR: 0.1	Loss 0.4355 (0.4114)	Prec@1 85.938 (85.764)	
Epoch: [2][155/196]	LR: 0.1	Loss 0.3691 (0.4062)	Prec@1 84.766 (85.900)	
Epoch: [2][194/196]	LR: 0.1	Loss 0.4170 (0.4063)	Prec@1 84.375 (85.946)	
Total train loss: 0.4063

Train time: 19.07439136505127
 * Prec@1 52.040 Prec@5 96.150 Loss 1.6445
Best acc: 54.260
--------------------------------------------------------------------------------
Test time: 22.483808279037476

Epoch: [3][38/196]	LR: 0.1	Loss 0.3916 (0.3883)	Prec@1 86.719 (86.538)	
Epoch: [3][77/196]	LR: 0.1	Loss 0.4067 (0.3833)	Prec@1 83.984 (86.794)	
Epoch: [3][116/196]	LR: 0.1	Loss 0.4377 (0.3833)	Prec@1 83.594 (86.765)	
Epoch: [3][155/196]	LR: 0.1	Loss 0.4053 (0.3831)	Prec@1 86.328 (86.781)	
Epoch: [3][194/196]	LR: 0.1	Loss 0.3606 (0.3826)	Prec@1 87.891 (86.795)	
Total train loss: 0.3827

Train time: 17.22430682182312
 * Prec@1 55.020 Prec@5 96.040 Loss 1.5840
Best acc: 55.020
--------------------------------------------------------------------------------
Test time: 21.572561502456665

Epoch: [4][38/196]	LR: 0.1	Loss 0.3542 (0.3676)	Prec@1 87.891 (87.580)	
Epoch: [4][77/196]	LR: 0.1	Loss 0.2881 (0.3707)	Prec@1 88.281 (87.515)	
Epoch: [4][116/196]	LR: 0.1	Loss 0.4404 (0.3724)	Prec@1 84.766 (87.310)	
Epoch: [4][155/196]	LR: 0.1	Loss 0.3413 (0.3697)	Prec@1 87.109 (87.372)	
Epoch: [4][194/196]	LR: 0.1	Loss 0.3682 (0.3685)	Prec@1 86.719 (87.420)	
Total train loss: 0.3685

Train time: 17.649049282073975
 * Prec@1 54.150 Prec@5 94.360 Loss 1.7471
Best acc: 55.020
--------------------------------------------------------------------------------
Test time: 21.274451732635498

Epoch: [5][38/196]	LR: 0.1	Loss 0.2847 (0.3543)	Prec@1 88.281 (87.750)	
Epoch: [5][77/196]	LR: 0.1	Loss 0.3738 (0.3565)	Prec@1 85.938 (87.730)	
Epoch: [5][116/196]	LR: 0.1	Loss 0.3560 (0.3566)	Prec@1 87.891 (87.851)	
Epoch: [5][155/196]	LR: 0.1	Loss 0.3979 (0.3593)	Prec@1 85.938 (87.805)	
Epoch: [5][194/196]	LR: 0.1	Loss 0.4434 (0.3590)	Prec@1 85.547 (87.762)	
Total train loss: 0.3589

Train time: 17.416736125946045
 * Prec@1 60.570 Prec@5 97.360 Loss 1.5244
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.648902893066406

Epoch: [6][38/196]	LR: 0.1	Loss 0.4062 (0.3430)	Prec@1 86.328 (88.331)	
Epoch: [6][77/196]	LR: 0.1	Loss 0.3274 (0.3455)	Prec@1 88.672 (88.271)	
Epoch: [6][116/196]	LR: 0.1	Loss 0.4314 (0.3451)	Prec@1 85.547 (88.201)	
Epoch: [6][155/196]	LR: 0.1	Loss 0.3740 (0.3446)	Prec@1 86.328 (88.186)	
Epoch: [6][194/196]	LR: 0.1	Loss 0.3955 (0.3478)	Prec@1 85.156 (88.101)	
Total train loss: 0.3480

Train time: 17.624706029891968
 * Prec@1 54.540 Prec@5 97.170 Loss 1.9277
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.16948962211609

Epoch: [7][38/196]	LR: 0.1	Loss 0.3264 (0.3302)	Prec@1 88.281 (88.702)	
Epoch: [7][77/196]	LR: 0.1	Loss 0.3374 (0.3441)	Prec@1 88.281 (88.351)	
Epoch: [7][116/196]	LR: 0.1	Loss 0.3757 (0.3441)	Prec@1 85.156 (88.245)	
Epoch: [7][155/196]	LR: 0.1	Loss 0.4104 (0.3504)	Prec@1 87.500 (87.993)	
Epoch: [7][194/196]	LR: 0.1	Loss 0.3362 (0.3529)	Prec@1 89.062 (87.891)	
Total train loss: 0.3528

Train time: 17.136329650878906
 * Prec@1 58.260 Prec@5 96.760 Loss 1.4688
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.2722430229187

Epoch: [8][38/196]	LR: 0.010000000000000002	Loss 0.2546 (0.3293)	Prec@1 90.625 (88.802)	
Epoch: [8][77/196]	LR: 0.010000000000000002	Loss 0.2837 (0.3285)	Prec@1 91.797 (88.852)	
Epoch: [8][116/196]	LR: 0.010000000000000002	Loss 0.2988 (0.3254)	Prec@1 89.453 (88.832)	
Epoch: [8][155/196]	LR: 0.010000000000000002	Loss 0.3586 (0.3255)	Prec@1 86.328 (88.785)	
Epoch: [8][194/196]	LR: 0.010000000000000002	Loss 0.3020 (0.3276)	Prec@1 91.797 (88.742)	
Total train loss: 0.3275

Train time: 17.40138530731201
 * Prec@1 55.760 Prec@5 96.520 Loss 1.8271
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 20.80568766593933

Epoch: [9][38/196]	LR: 0.010000000000000002	Loss 0.2969 (0.3225)	Prec@1 89.844 (89.253)	
Epoch: [9][77/196]	LR: 0.010000000000000002	Loss 0.3538 (0.3244)	Prec@1 87.500 (89.178)	
Epoch: [9][116/196]	LR: 0.010000000000000002	Loss 0.2917 (0.3247)	Prec@1 87.891 (89.022)	
Epoch: [9][155/196]	LR: 0.010000000000000002	Loss 0.3662 (0.3223)	Prec@1 88.672 (89.083)	
Epoch: [9][194/196]	LR: 0.010000000000000002	Loss 0.3608 (0.3242)	Prec@1 88.281 (88.924)	
Total train loss: 0.3241

Train time: 17.453601121902466
 * Prec@1 57.040 Prec@5 96.840 Loss 1.7266
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.83579993247986

Epoch: [10][38/196]	LR: 0.010000000000000002	Loss 0.3757 (0.3191)	Prec@1 85.938 (88.952)	
Epoch: [10][77/196]	LR: 0.010000000000000002	Loss 0.3521 (0.3206)	Prec@1 89.062 (88.982)	
Epoch: [10][116/196]	LR: 0.010000000000000002	Loss 0.3401 (0.3261)	Prec@1 86.719 (88.859)	
Epoch: [10][155/196]	LR: 0.010000000000000002	Loss 0.3530 (0.3239)	Prec@1 89.844 (88.922)	
Epoch: [10][194/196]	LR: 0.010000000000000002	Loss 0.3215 (0.3237)	Prec@1 87.891 (88.896)	
Total train loss: 0.3237

Train time: 17.450666904449463
 * Prec@1 56.810 Prec@5 96.760 Loss 1.7412
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.022779941558838

Epoch: [11][38/196]	LR: 0.010000000000000002	Loss 0.4001 (0.3210)	Prec@1 87.109 (88.892)	
Epoch: [11][77/196]	LR: 0.010000000000000002	Loss 0.2822 (0.3226)	Prec@1 92.188 (88.777)	
Epoch: [11][116/196]	LR: 0.010000000000000002	Loss 0.3428 (0.3203)	Prec@1 87.109 (88.872)	
Epoch: [11][155/196]	LR: 0.010000000000000002	Loss 0.2695 (0.3213)	Prec@1 91.016 (88.855)	
Epoch: [11][194/196]	LR: 0.010000000000000002	Loss 0.2979 (0.3225)	Prec@1 90.625 (88.882)	
Total train loss: 0.3226

Train time: 17.108947038650513
 * Prec@1 58.020 Prec@5 96.900 Loss 1.6895
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.34546685218811

Epoch: [12][38/196]	LR: 0.010000000000000002	Loss 0.2651 (0.3286)	Prec@1 92.578 (88.852)	
Epoch: [12][77/196]	LR: 0.010000000000000002	Loss 0.3708 (0.3289)	Prec@1 85.547 (88.712)	
Epoch: [12][116/196]	LR: 0.010000000000000002	Loss 0.3806 (0.3254)	Prec@1 87.109 (88.729)	
Epoch: [12][155/196]	LR: 0.010000000000000002	Loss 0.3167 (0.3270)	Prec@1 85.547 (88.677)	
Epoch: [12][194/196]	LR: 0.010000000000000002	Loss 0.3013 (0.3229)	Prec@1 90.625 (88.910)	
Total train loss: 0.3230

Train time: 17.526469230651855
 * Prec@1 57.700 Prec@5 96.790 Loss 1.6787
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 20.87113380432129

Epoch: [13][38/196]	LR: 0.010000000000000002	Loss 0.3313 (0.3169)	Prec@1 90.625 (89.293)	
Epoch: [13][77/196]	LR: 0.010000000000000002	Loss 0.3289 (0.3229)	Prec@1 89.062 (88.957)	
Epoch: [13][116/196]	LR: 0.010000000000000002	Loss 0.2908 (0.3187)	Prec@1 90.625 (89.099)	
Epoch: [13][155/196]	LR: 0.010000000000000002	Loss 0.3362 (0.3191)	Prec@1 87.500 (89.035)	
Epoch: [13][194/196]	LR: 0.010000000000000002	Loss 0.2998 (0.3214)	Prec@1 90.625 (88.984)	
Total train loss: 0.3217

Train time: 17.37437915802002
 * Prec@1 58.950 Prec@5 96.910 Loss 1.6025
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.86874032020569

Epoch: [14][38/196]	LR: 0.010000000000000002	Loss 0.3340 (0.3223)	Prec@1 88.672 (88.812)	
Epoch: [14][77/196]	LR: 0.010000000000000002	Loss 0.3108 (0.3219)	Prec@1 89.453 (88.912)	
Epoch: [14][116/196]	LR: 0.010000000000000002	Loss 0.3350 (0.3219)	Prec@1 87.109 (88.992)	
Epoch: [14][155/196]	LR: 0.010000000000000002	Loss 0.3882 (0.3244)	Prec@1 87.500 (88.927)	
Epoch: [14][194/196]	LR: 0.010000000000000002	Loss 0.2727 (0.3226)	Prec@1 91.406 (88.974)	
Total train loss: 0.3229

Train time: 18.915542125701904
 * Prec@1 58.910 Prec@5 96.770 Loss 1.6133
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 22.54213547706604

Epoch: [15][38/196]	LR: 0.010000000000000002	Loss 0.3137 (0.3245)	Prec@1 87.500 (88.742)	
Epoch: [15][77/196]	LR: 0.010000000000000002	Loss 0.3081 (0.3174)	Prec@1 88.672 (89.138)	
Epoch: [15][116/196]	LR: 0.010000000000000002	Loss 0.3630 (0.3206)	Prec@1 87.891 (88.942)	
Epoch: [15][155/196]	LR: 0.010000000000000002	Loss 0.3645 (0.3234)	Prec@1 85.938 (88.845)	
Epoch: [15][194/196]	LR: 0.010000000000000002	Loss 0.3320 (0.3226)	Prec@1 88.281 (88.852)	
Total train loss: 0.3229

Train time: 17.662702083587646
 * Prec@1 58.060 Prec@5 96.680 Loss 1.6797
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 22.117076873779297

Epoch: [16][38/196]	LR: 0.0010000000000000002	Loss 0.3928 (0.3260)	Prec@1 85.938 (88.922)	
Epoch: [16][77/196]	LR: 0.0010000000000000002	Loss 0.2971 (0.3231)	Prec@1 91.406 (89.068)	
Epoch: [16][116/196]	LR: 0.0010000000000000002	Loss 0.3633 (0.3239)	Prec@1 86.719 (88.999)	
Epoch: [16][155/196]	LR: 0.0010000000000000002	Loss 0.3362 (0.3222)	Prec@1 85.547 (89.070)	
Epoch: [16][194/196]	LR: 0.0010000000000000002	Loss 0.2688 (0.3252)	Prec@1 89.062 (88.870)	
Total train loss: 0.3254

Train time: 17.571712255477905
 * Prec@1 56.740 Prec@5 96.780 Loss 1.7500
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.121716737747192

Epoch: [17][38/196]	LR: 0.0010000000000000002	Loss 0.2544 (0.3051)	Prec@1 90.234 (89.673)	
Epoch: [17][77/196]	LR: 0.0010000000000000002	Loss 0.3147 (0.3138)	Prec@1 90.234 (89.393)	
Epoch: [17][116/196]	LR: 0.0010000000000000002	Loss 0.3076 (0.3180)	Prec@1 87.500 (89.186)	
Epoch: [17][155/196]	LR: 0.0010000000000000002	Loss 0.2776 (0.3216)	Prec@1 91.016 (89.025)	
Epoch: [17][194/196]	LR: 0.0010000000000000002	Loss 0.3372 (0.3207)	Prec@1 87.891 (89.052)	
Total train loss: 0.3208

Train time: 17.495060682296753
 * Prec@1 58.800 Prec@5 96.810 Loss 1.6064
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 22.002989768981934

Epoch: [18][38/196]	LR: 0.0010000000000000002	Loss 0.2754 (0.3209)	Prec@1 91.797 (89.002)	
Epoch: [18][77/196]	LR: 0.0010000000000000002	Loss 0.3772 (0.3210)	Prec@1 87.500 (88.857)	
Epoch: [18][116/196]	LR: 0.0010000000000000002	Loss 0.3352 (0.3209)	Prec@1 88.281 (88.879)	
Epoch: [18][155/196]	LR: 0.0010000000000000002	Loss 0.3748 (0.3218)	Prec@1 86.328 (88.895)	
Epoch: [18][194/196]	LR: 0.0010000000000000002	Loss 0.2244 (0.3215)	Prec@1 91.406 (88.866)	
Total train loss: 0.3215

Train time: 16.80731725692749
 * Prec@1 58.400 Prec@5 96.760 Loss 1.6377
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 20.504125356674194

Epoch: [19][38/196]	LR: 0.0010000000000000002	Loss 0.3562 (0.3237)	Prec@1 87.109 (88.822)	
Epoch: [19][77/196]	LR: 0.0010000000000000002	Loss 0.3503 (0.3226)	Prec@1 89.453 (88.927)	
Epoch: [19][116/196]	LR: 0.0010000000000000002	Loss 0.3264 (0.3221)	Prec@1 87.500 (88.912)	
Epoch: [19][155/196]	LR: 0.0010000000000000002	Loss 0.3687 (0.3209)	Prec@1 85.547 (88.985)	
Epoch: [19][194/196]	LR: 0.0010000000000000002	Loss 0.3369 (0.3205)	Prec@1 87.500 (88.984)	
Total train loss: 0.3205

Train time: 16.74891757965088
 * Prec@1 58.990 Prec@5 96.720 Loss 1.5908
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.12558102607727

Epoch: [20][38/196]	LR: 0.0010000000000000002	Loss 0.3181 (0.3215)	Prec@1 90.234 (88.962)	
Epoch: [20][77/196]	LR: 0.0010000000000000002	Loss 0.3489 (0.3173)	Prec@1 86.328 (89.032)	
Epoch: [20][116/196]	LR: 0.0010000000000000002	Loss 0.3164 (0.3204)	Prec@1 89.453 (88.972)	
Epoch: [20][155/196]	LR: 0.0010000000000000002	Loss 0.2379 (0.3231)	Prec@1 90.625 (88.910)	
Epoch: [20][194/196]	LR: 0.0010000000000000002	Loss 0.2688 (0.3211)	Prec@1 90.234 (89.036)	
Total train loss: 0.3213

Train time: 17.443023681640625
 * Prec@1 58.900 Prec@5 96.830 Loss 1.6074
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.136377334594727

Epoch: [21][38/196]	LR: 0.0010000000000000002	Loss 0.2720 (0.3312)	Prec@1 90.625 (88.452)	
Epoch: [21][77/196]	LR: 0.0010000000000000002	Loss 0.3350 (0.3184)	Prec@1 87.109 (88.812)	
Epoch: [21][116/196]	LR: 0.0010000000000000002	Loss 0.2930 (0.3177)	Prec@1 90.234 (88.946)	
Epoch: [21][155/196]	LR: 0.0010000000000000002	Loss 0.3938 (0.3200)	Prec@1 85.938 (88.942)	
Epoch: [21][194/196]	LR: 0.0010000000000000002	Loss 0.4084 (0.3221)	Prec@1 85.547 (88.872)	
Total train loss: 0.3221

Train time: 17.816469192504883
 * Prec@1 59.310 Prec@5 96.720 Loss 1.5781
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 22.266197443008423

Epoch: [22][38/196]	LR: 0.0010000000000000002	Loss 0.4038 (0.3255)	Prec@1 85.156 (88.992)	
Epoch: [22][77/196]	LR: 0.0010000000000000002	Loss 0.3025 (0.3210)	Prec@1 89.062 (89.143)	
Epoch: [22][116/196]	LR: 0.0010000000000000002	Loss 0.3652 (0.3196)	Prec@1 87.109 (89.123)	
Epoch: [22][155/196]	LR: 0.0010000000000000002	Loss 0.2542 (0.3225)	Prec@1 91.406 (88.952)	
Epoch: [22][194/196]	LR: 0.0010000000000000002	Loss 0.2759 (0.3229)	Prec@1 90.234 (89.032)	
Total train loss: 0.3229

Train time: 17.86174511909485
 * Prec@1 58.060 Prec@5 96.810 Loss 1.6543
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.417420148849487

Epoch: [23][38/196]	LR: 0.0010000000000000002	Loss 0.2849 (0.3101)	Prec@1 90.625 (89.363)	
Epoch: [23][77/196]	LR: 0.0010000000000000002	Loss 0.3669 (0.3187)	Prec@1 89.062 (89.163)	
Epoch: [23][116/196]	LR: 0.0010000000000000002	Loss 0.3972 (0.3186)	Prec@1 86.328 (89.113)	
Epoch: [23][155/196]	LR: 0.0010000000000000002	Loss 0.4009 (0.3196)	Prec@1 87.109 (89.065)	
Epoch: [23][194/196]	LR: 0.0010000000000000002	Loss 0.2375 (0.3211)	Prec@1 92.969 (88.984)	
Total train loss: 0.3213

Train time: 18.605197191238403
 * Prec@1 59.530 Prec@5 96.870 Loss 1.5723
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 23.953545808792114

Epoch: [24][38/196]	LR: 0.00010000000000000003	Loss 0.3491 (0.3217)	Prec@1 87.891 (88.962)	
Epoch: [24][77/196]	LR: 0.00010000000000000003	Loss 0.4492 (0.3242)	Prec@1 83.203 (88.902)	
Epoch: [24][116/196]	LR: 0.00010000000000000003	Loss 0.3333 (0.3214)	Prec@1 87.891 (88.999)	
Epoch: [24][155/196]	LR: 0.00010000000000000003	Loss 0.3274 (0.3213)	Prec@1 85.938 (88.940)	
Epoch: [24][194/196]	LR: 0.00010000000000000003	Loss 0.3516 (0.3219)	Prec@1 87.500 (88.942)	
Total train loss: 0.3218

Train time: 18.91462278366089
 * Prec@1 57.420 Prec@5 96.630 Loss 1.7012
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 22.712954998016357

Epoch: [25][38/196]	LR: 0.00010000000000000003	Loss 0.3713 (0.3202)	Prec@1 89.453 (89.253)	
Epoch: [25][77/196]	LR: 0.00010000000000000003	Loss 0.3091 (0.3218)	Prec@1 90.625 (89.183)	
Epoch: [25][116/196]	LR: 0.00010000000000000003	Loss 0.3574 (0.3226)	Prec@1 85.156 (88.972)	
Epoch: [25][155/196]	LR: 0.00010000000000000003	Loss 0.3523 (0.3230)	Prec@1 88.281 (89.020)	
Epoch: [25][194/196]	LR: 0.00010000000000000003	Loss 0.2527 (0.3219)	Prec@1 88.672 (89.010)	
Total train loss: 0.3220

Train time: 20.12100052833557
 * Prec@1 57.820 Prec@5 96.760 Loss 1.6846
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 24.229028940200806

Epoch: [26][38/196]	LR: 0.00010000000000000003	Loss 0.3162 (0.3320)	Prec@1 89.062 (88.411)	
Epoch: [26][77/196]	LR: 0.00010000000000000003	Loss 0.2827 (0.3296)	Prec@1 90.234 (88.527)	
Epoch: [26][116/196]	LR: 0.00010000000000000003	Loss 0.4106 (0.3241)	Prec@1 86.719 (88.856)	
Epoch: [26][155/196]	LR: 0.00010000000000000003	Loss 0.4219 (0.3223)	Prec@1 87.500 (88.932)	
Epoch: [26][194/196]	LR: 0.00010000000000000003	Loss 0.3020 (0.3228)	Prec@1 90.234 (88.948)	
Total train loss: 0.3226

Train time: 17.823904752731323
 * Prec@1 56.850 Prec@5 96.660 Loss 1.7666
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 22.000714778900146

Epoch: [27][38/196]	LR: 0.00010000000000000003	Loss 0.4326 (0.3222)	Prec@1 85.938 (89.163)	
Epoch: [27][77/196]	LR: 0.00010000000000000003	Loss 0.3638 (0.3248)	Prec@1 85.156 (88.792)	
Epoch: [27][116/196]	LR: 0.00010000000000000003	Loss 0.2378 (0.3192)	Prec@1 93.359 (89.039)	
Epoch: [27][155/196]	LR: 0.00010000000000000003	Loss 0.2490 (0.3200)	Prec@1 91.406 (89.007)	
Epoch: [27][194/196]	LR: 0.00010000000000000003	Loss 0.2878 (0.3201)	Prec@1 90.234 (88.972)	
Total train loss: 0.3202

Train time: 18.21182894706726
 * Prec@1 58.100 Prec@5 96.810 Loss 1.6611
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.871943950653076

Epoch: [28][38/196]	LR: 0.00010000000000000003	Loss 0.3564 (0.3234)	Prec@1 89.844 (88.972)	
Epoch: [28][77/196]	LR: 0.00010000000000000003	Loss 0.3601 (0.3221)	Prec@1 85.938 (88.932)	
Epoch: [28][116/196]	LR: 0.00010000000000000003	Loss 0.3567 (0.3220)	Prec@1 87.891 (88.876)	
Epoch: [28][155/196]	LR: 0.00010000000000000003	Loss 0.2961 (0.3220)	Prec@1 88.672 (88.852)	
Epoch: [28][194/196]	LR: 0.00010000000000000003	Loss 0.2678 (0.3214)	Prec@1 91.016 (88.928)	
Total train loss: 0.3212

Train time: 18.222576379776
 * Prec@1 58.500 Prec@5 96.710 Loss 1.6367
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 22.127395391464233

Epoch: [29][38/196]	LR: 0.00010000000000000003	Loss 0.3601 (0.3240)	Prec@1 89.062 (88.792)	
Epoch: [29][77/196]	LR: 0.00010000000000000003	Loss 0.3044 (0.3254)	Prec@1 89.844 (88.962)	
Epoch: [29][116/196]	LR: 0.00010000000000000003	Loss 0.2935 (0.3209)	Prec@1 91.406 (89.009)	
Epoch: [29][155/196]	LR: 0.00010000000000000003	Loss 0.3206 (0.3228)	Prec@1 88.672 (89.012)	
Epoch: [29][194/196]	LR: 0.00010000000000000003	Loss 0.3093 (0.3238)	Prec@1 90.625 (88.942)	
Total train loss: 0.3238

Train time: 17.49302363395691
 * Prec@1 57.170 Prec@5 96.560 Loss 1.7393
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.735706567764282

Epoch: [30][38/196]	LR: 0.00010000000000000003	Loss 0.3037 (0.3304)	Prec@1 89.062 (88.622)	
Epoch: [30][77/196]	LR: 0.00010000000000000003	Loss 0.3362 (0.3245)	Prec@1 87.891 (88.817)	
Epoch: [30][116/196]	LR: 0.00010000000000000003	Loss 0.2445 (0.3250)	Prec@1 91.016 (88.769)	
Epoch: [30][155/196]	LR: 0.00010000000000000003	Loss 0.3787 (0.3229)	Prec@1 86.719 (88.815)	
Epoch: [30][194/196]	LR: 0.00010000000000000003	Loss 0.2288 (0.3212)	Prec@1 91.797 (88.912)	
Total train loss: 0.3213

Train time: 17.84481382369995
 * Prec@1 59.520 Prec@5 96.780 Loss 1.5674
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.458919286727905

Epoch: [31][38/196]	LR: 0.00010000000000000003	Loss 0.4272 (0.3270)	Prec@1 85.156 (88.742)	
Epoch: [31][77/196]	LR: 0.00010000000000000003	Loss 0.2815 (0.3288)	Prec@1 90.625 (88.712)	
Epoch: [31][116/196]	LR: 0.00010000000000000003	Loss 0.3130 (0.3254)	Prec@1 91.016 (88.819)	
Epoch: [31][155/196]	LR: 0.00010000000000000003	Loss 0.3875 (0.3220)	Prec@1 85.547 (88.950)	
Epoch: [31][194/196]	LR: 0.00010000000000000003	Loss 0.2007 (0.3219)	Prec@1 92.969 (88.926)	
Total train loss: 0.3220

Train time: 17.153372049331665
 * Prec@1 58.760 Prec@5 96.780 Loss 1.6299
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.037790536880493

Epoch: [32][38/196]	LR: 1.0000000000000004e-05	Loss 0.2849 (0.3137)	Prec@1 90.234 (89.273)	
Epoch: [32][77/196]	LR: 1.0000000000000004e-05	Loss 0.3064 (0.3151)	Prec@1 88.672 (89.258)	
Epoch: [32][116/196]	LR: 1.0000000000000004e-05	Loss 0.2629 (0.3200)	Prec@1 92.578 (89.069)	
Epoch: [32][155/196]	LR: 1.0000000000000004e-05	Loss 0.2654 (0.3211)	Prec@1 90.625 (89.045)	
Epoch: [32][194/196]	LR: 1.0000000000000004e-05	Loss 0.2830 (0.3215)	Prec@1 91.016 (89.042)	
Total train loss: 0.3213

Train time: 17.84220838546753
 * Prec@1 57.830 Prec@5 96.680 Loss 1.6660
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.774940490722656

Epoch: [33][38/196]	LR: 1.0000000000000004e-05	Loss 0.3301 (0.3158)	Prec@1 88.672 (89.243)	
Epoch: [33][77/196]	LR: 1.0000000000000004e-05	Loss 0.3486 (0.3192)	Prec@1 87.109 (88.992)	
Epoch: [33][116/196]	LR: 1.0000000000000004e-05	Loss 0.3875 (0.3212)	Prec@1 88.281 (88.996)	
Epoch: [33][155/196]	LR: 1.0000000000000004e-05	Loss 0.3132 (0.3216)	Prec@1 89.062 (88.952)	
Epoch: [33][194/196]	LR: 1.0000000000000004e-05	Loss 0.3684 (0.3212)	Prec@1 86.719 (88.988)	
Total train loss: 0.3215

Train time: 17.482645273208618
 * Prec@1 59.500 Prec@5 96.760 Loss 1.5625
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.30881094932556

Epoch: [34][38/196]	LR: 1.0000000000000004e-05	Loss 0.3733 (0.3304)	Prec@1 87.891 (88.462)	
Epoch: [34][77/196]	LR: 1.0000000000000004e-05	Loss 0.2344 (0.3258)	Prec@1 91.406 (88.687)	
Epoch: [34][116/196]	LR: 1.0000000000000004e-05	Loss 0.2537 (0.3250)	Prec@1 91.406 (88.909)	
Epoch: [34][155/196]	LR: 1.0000000000000004e-05	Loss 0.2832 (0.3208)	Prec@1 89.844 (89.015)	
Epoch: [34][194/196]	LR: 1.0000000000000004e-05	Loss 0.3528 (0.3204)	Prec@1 83.594 (89.071)	
Total train loss: 0.3206

Train time: 17.755671501159668
 * Prec@1 56.520 Prec@5 96.660 Loss 1.7764
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.67435598373413

Epoch: [35][38/196]	LR: 1.0000000000000004e-05	Loss 0.3831 (0.3317)	Prec@1 85.938 (88.782)	
Epoch: [35][77/196]	LR: 1.0000000000000004e-05	Loss 0.3806 (0.3316)	Prec@1 87.500 (88.602)	
Epoch: [35][116/196]	LR: 1.0000000000000004e-05	Loss 0.3196 (0.3239)	Prec@1 90.234 (88.909)	
Epoch: [35][155/196]	LR: 1.0000000000000004e-05	Loss 0.3625 (0.3240)	Prec@1 87.500 (88.860)	
Epoch: [35][194/196]	LR: 1.0000000000000004e-05	Loss 0.2542 (0.3212)	Prec@1 92.578 (88.926)	
Total train loss: 0.3213

Train time: 17.597569227218628
 * Prec@1 58.660 Prec@5 96.730 Loss 1.6162
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.729203462600708

Epoch: [36][38/196]	LR: 1.0000000000000004e-05	Loss 0.3301 (0.3250)	Prec@1 89.453 (88.872)	
Epoch: [36][77/196]	LR: 1.0000000000000004e-05	Loss 0.2976 (0.3247)	Prec@1 89.453 (88.962)	
Epoch: [36][116/196]	LR: 1.0000000000000004e-05	Loss 0.4146 (0.3232)	Prec@1 86.719 (89.046)	
Epoch: [36][155/196]	LR: 1.0000000000000004e-05	Loss 0.3228 (0.3222)	Prec@1 87.500 (89.057)	
Epoch: [36][194/196]	LR: 1.0000000000000004e-05	Loss 0.3499 (0.3225)	Prec@1 87.109 (88.962)	
Total train loss: 0.3224

Train time: 17.97147035598755
 * Prec@1 58.640 Prec@5 96.740 Loss 1.6299
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.583083629608154

Epoch: [37][38/196]	LR: 1.0000000000000004e-05	Loss 0.2896 (0.3171)	Prec@1 89.453 (88.932)	
Epoch: [37][77/196]	LR: 1.0000000000000004e-05	Loss 0.3013 (0.3199)	Prec@1 89.844 (88.937)	
Epoch: [37][116/196]	LR: 1.0000000000000004e-05	Loss 0.3110 (0.3218)	Prec@1 87.891 (88.799)	
Epoch: [37][155/196]	LR: 1.0000000000000004e-05	Loss 0.2705 (0.3228)	Prec@1 88.281 (88.765)	
Epoch: [37][194/196]	LR: 1.0000000000000004e-05	Loss 0.4070 (0.3217)	Prec@1 85.938 (88.858)	
Total train loss: 0.3220

Train time: 17.81714177131653
 * Prec@1 59.600 Prec@5 96.890 Loss 1.5605
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.618695497512817

Epoch: [38][38/196]	LR: 1.0000000000000004e-05	Loss 0.3574 (0.3296)	Prec@1 87.891 (88.692)	
Epoch: [38][77/196]	LR: 1.0000000000000004e-05	Loss 0.3721 (0.3291)	Prec@1 89.844 (88.692)	
Epoch: [38][116/196]	LR: 1.0000000000000004e-05	Loss 0.2900 (0.3238)	Prec@1 91.016 (88.916)	
Epoch: [38][155/196]	LR: 1.0000000000000004e-05	Loss 0.3826 (0.3232)	Prec@1 87.109 (88.902)	
Epoch: [38][194/196]	LR: 1.0000000000000004e-05	Loss 0.5093 (0.3212)	Prec@1 86.328 (89.020)	
Total train loss: 0.3214

Train time: 17.06680154800415
 * Prec@1 57.440 Prec@5 96.650 Loss 1.7295
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 21.176963567733765

Epoch: [39][38/196]	LR: 1.0000000000000004e-05	Loss 0.2620 (0.3260)	Prec@1 89.844 (88.872)	
Epoch: [39][77/196]	LR: 1.0000000000000004e-05	Loss 0.3198 (0.3268)	Prec@1 88.672 (88.807)	
Epoch: [39][116/196]	LR: 1.0000000000000004e-05	Loss 0.3218 (0.3273)	Prec@1 91.016 (88.792)	
Epoch: [39][155/196]	LR: 1.0000000000000004e-05	Loss 0.3281 (0.3250)	Prec@1 89.844 (88.805)	
Epoch: [39][194/196]	LR: 1.0000000000000004e-05	Loss 0.4136 (0.3221)	Prec@1 86.719 (88.898)	
Total train loss: 0.3223

Train time: 17.039472341537476
 * Prec@1 58.910 Prec@5 96.670 Loss 1.6055
Best acc: 60.570
--------------------------------------------------------------------------------
Test time: 20.46409845352173

