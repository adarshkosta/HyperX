
      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b-lp/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_half_quant_all_w7b_a7b_best.pth.tar
          mode: rram
          workers: 8
          epochs: 40
          start_epoch: 0
          batch_size: 256
          lr: 0.1
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          milestones: [8, 16, 24, 32]
          loss: crossentropy
          optim: sgd
          dropout: 0.5
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 3
          frozen_layers: 13
DEVICE: cuda
GPU Id(s) being used: 3
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_half_quant_all_w7b_a7b_best.pth.tar ...
Original model accuracy: 89.29999542236328
ResNet_cifar(
  (conv14): QConv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu14): ReLU(inplace=True)
  (conv15): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Sequential(
    (0): QConv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (relu15): ReLU(inplace=True)
  (conv16): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu16): ReLU(inplace=True)
  (conv17): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu17): ReLU(inplace=True)
  (conv18): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu18): ReLU(inplace=True)
  (conv19): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu19): ReLU(inplace=True)
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (bn20): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): QLinear(in_features=64, out_features=10, bias=False)
  (bn21): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (logsoftmax): LogSoftmax(dim=1)
)
 * Prec@1 10.000 Prec@5 51.200 Loss inf
Pre-trained Prec@1 with 13 layers frozen: 10.0 	 Loss: inf

Starting training on SRAM layers...
Epoch: [0][38/196]	LR: 0.1	Loss 0.9116 (1.3461)	Prec@1 68.359 (55.409)	
Epoch: [0][77/196]	LR: 0.1	Loss 0.7349 (1.1147)	Prec@1 74.609 (62.124)	
Epoch: [0][116/196]	LR: 0.1	Loss 0.8330 (1.0038)	Prec@1 71.094 (65.698)	
Epoch: [0][155/196]	LR: 0.1	Loss 0.6377 (0.9248)	Prec@1 76.953 (68.414)	
Epoch: [0][194/196]	LR: 0.1	Loss 0.6973 (0.8757)	Prec@1 77.734 (70.098)	
Total train loss: 0.8754

Train time: 450.6842930316925
 * Prec@1 27.680 Prec@5 85.590 Loss 2.8887
Best acc: 27.680
--------------------------------------------------------------------------------
Test time: 455.8068675994873

Epoch: [1][38/196]	LR: 0.1	Loss 0.6426 (0.6459)	Prec@1 77.344 (77.744)	
Epoch: [1][77/196]	LR: 0.1	Loss 0.5571 (0.6236)	Prec@1 81.250 (78.656)	
Epoch: [1][116/196]	LR: 0.1	Loss 0.5366 (0.6105)	Prec@1 82.031 (79.100)	
Epoch: [1][155/196]	LR: 0.1	Loss 0.5483 (0.6033)	Prec@1 82.422 (79.274)	
Epoch: [1][194/196]	LR: 0.1	Loss 0.5005 (0.5937)	Prec@1 81.641 (79.637)	
Total train loss: 0.5934

Train time: 19.121094465255737
 * Prec@1 23.630 Prec@5 85.920 Loss 3.4375
Best acc: 27.680
--------------------------------------------------------------------------------
Test time: 23.969778060913086

Epoch: [2][38/196]	LR: 0.1	Loss 0.5425 (0.5242)	Prec@1 82.031 (82.081)	
Epoch: [2][77/196]	LR: 0.1	Loss 0.5054 (0.5318)	Prec@1 82.031 (81.871)	
Epoch: [2][116/196]	LR: 0.1	Loss 0.4556 (0.5285)	Prec@1 85.547 (82.088)	
Epoch: [2][155/196]	LR: 0.1	Loss 0.4521 (0.5236)	Prec@1 85.156 (82.131)	
Epoch: [2][194/196]	LR: 0.1	Loss 0.4624 (0.5206)	Prec@1 85.156 (82.216)	
Total train loss: 0.5205

Train time: 19.511793613433838
 * Prec@1 29.780 Prec@5 86.750 Loss 2.8711
Best acc: 29.780
--------------------------------------------------------------------------------
Test time: 24.237050533294678

Epoch: [3][38/196]	LR: 0.1	Loss 0.5322 (0.4778)	Prec@1 81.250 (84.014)	
Epoch: [3][77/196]	LR: 0.1	Loss 0.4656 (0.4802)	Prec@1 84.375 (83.764)	
Epoch: [3][116/196]	LR: 0.1	Loss 0.4004 (0.4739)	Prec@1 85.156 (83.958)	
Epoch: [3][155/196]	LR: 0.1	Loss 0.5356 (0.4756)	Prec@1 82.031 (83.874)	
Epoch: [3][194/196]	LR: 0.1	Loss 0.4390 (0.4745)	Prec@1 85.156 (83.968)	
Total train loss: 0.4744

Train time: 18.19385576248169
 * Prec@1 23.350 Prec@5 86.390 Loss 3.2188
Best acc: 29.780
--------------------------------------------------------------------------------
Test time: 21.90829634666443

Epoch: [4][38/196]	LR: 0.1	Loss 0.4441 (0.4388)	Prec@1 84.375 (85.116)	
Epoch: [4][77/196]	LR: 0.1	Loss 0.4333 (0.4477)	Prec@1 84.766 (84.791)	
Epoch: [4][116/196]	LR: 0.1	Loss 0.4949 (0.4480)	Prec@1 82.812 (84.672)	
Epoch: [4][155/196]	LR: 0.1	Loss 0.4224 (0.4469)	Prec@1 86.719 (84.713)	
Epoch: [4][194/196]	LR: 0.1	Loss 0.4656 (0.4484)	Prec@1 85.938 (84.768)	
Total train loss: 0.4484

Train time: 16.894246578216553
 * Prec@1 25.020 Prec@5 88.120 Loss 3.1758
Best acc: 29.780
--------------------------------------------------------------------------------
Test time: 21.263837337493896

Epoch: [5][38/196]	LR: 0.1	Loss 0.3997 (0.4258)	Prec@1 87.109 (85.677)	
Epoch: [5][77/196]	LR: 0.1	Loss 0.3374 (0.4202)	Prec@1 87.500 (85.637)	
Epoch: [5][116/196]	LR: 0.1	Loss 0.3691 (0.4198)	Prec@1 85.938 (85.590)	
Epoch: [5][155/196]	LR: 0.1	Loss 0.4253 (0.4245)	Prec@1 85.156 (85.554)	
Epoch: [5][194/196]	LR: 0.1	Loss 0.3796 (0.4265)	Prec@1 87.109 (85.433)	
Total train loss: 0.4266

Train time: 17.137523412704468
 * Prec@1 31.640 Prec@5 88.690 Loss 2.7891
Best acc: 31.640
--------------------------------------------------------------------------------
Test time: 21.65291976928711

Epoch: [6][38/196]	LR: 0.1	Loss 0.3997 (0.4092)	Prec@1 86.719 (85.807)	
Epoch: [6][77/196]	LR: 0.1	Loss 0.4878 (0.4058)	Prec@1 82.422 (86.053)	
Epoch: [6][116/196]	LR: 0.1	Loss 0.4255 (0.4057)	Prec@1 86.719 (86.071)	
Epoch: [6][155/196]	LR: 0.1	Loss 0.4424 (0.4071)	Prec@1 85.156 (86.053)	
Epoch: [6][194/196]	LR: 0.1	Loss 0.3232 (0.4081)	Prec@1 89.453 (86.042)	
Total train loss: 0.4082

Train time: 17.192138195037842
 * Prec@1 33.070 Prec@5 90.590 Loss 2.7832
Best acc: 33.070
--------------------------------------------------------------------------------
Test time: 21.567151069641113

Epoch: [7][38/196]	LR: 0.1	Loss 0.3958 (0.3791)	Prec@1 88.281 (87.039)	
Epoch: [7][77/196]	LR: 0.1	Loss 0.3748 (0.3792)	Prec@1 87.891 (87.044)	
Epoch: [7][116/196]	LR: 0.1	Loss 0.3362 (0.3838)	Prec@1 88.672 (86.836)	
Epoch: [7][155/196]	LR: 0.1	Loss 0.4565 (0.3919)	Prec@1 83.984 (86.538)	
Epoch: [7][194/196]	LR: 0.1	Loss 0.4084 (0.3949)	Prec@1 84.375 (86.446)	
Total train loss: 0.3949

Train time: 16.896130323410034
 * Prec@1 41.790 Prec@5 89.580 Loss 2.3945
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.48368811607361

Epoch: [8][38/196]	LR: 0.010000000000000002	Loss 0.3691 (0.3540)	Prec@1 86.328 (87.901)	
Epoch: [8][77/196]	LR: 0.010000000000000002	Loss 0.3176 (0.3592)	Prec@1 89.844 (87.790)	
Epoch: [8][116/196]	LR: 0.010000000000000002	Loss 0.4622 (0.3592)	Prec@1 83.984 (87.874)	
Epoch: [8][155/196]	LR: 0.010000000000000002	Loss 0.3542 (0.3618)	Prec@1 87.891 (87.798)	
Epoch: [8][194/196]	LR: 0.010000000000000002	Loss 0.3433 (0.3650)	Prec@1 88.672 (87.694)	
Total train loss: 0.3651

Train time: 16.17706036567688
 * Prec@1 31.030 Prec@5 89.270 Loss 2.5352
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.874459743499756

Epoch: [9][38/196]	LR: 0.010000000000000002	Loss 0.3589 (0.3682)	Prec@1 88.672 (87.540)	
Epoch: [9][77/196]	LR: 0.010000000000000002	Loss 0.4067 (0.3762)	Prec@1 86.328 (87.250)	
Epoch: [9][116/196]	LR: 0.010000000000000002	Loss 0.3772 (0.3749)	Prec@1 87.891 (87.166)	
Epoch: [9][155/196]	LR: 0.010000000000000002	Loss 0.4050 (0.3768)	Prec@1 88.281 (87.169)	
Epoch: [9][194/196]	LR: 0.010000000000000002	Loss 0.3794 (0.3758)	Prec@1 85.156 (87.232)	
Total train loss: 0.3760

Train time: 17.110862255096436
 * Prec@1 30.590 Prec@5 87.510 Loss 2.5879
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.699270963668823

Epoch: [10][38/196]	LR: 0.010000000000000002	Loss 0.4158 (0.4018)	Prec@1 84.375 (85.968)	
Epoch: [10][77/196]	LR: 0.010000000000000002	Loss 0.3201 (0.3844)	Prec@1 89.844 (86.664)	
Epoch: [10][116/196]	LR: 0.010000000000000002	Loss 0.3306 (0.3888)	Prec@1 89.453 (86.538)	
Epoch: [10][155/196]	LR: 0.010000000000000002	Loss 0.4893 (0.3915)	Prec@1 85.938 (86.508)	
Epoch: [10][194/196]	LR: 0.010000000000000002	Loss 0.3828 (0.3933)	Prec@1 87.500 (86.440)	
Total train loss: 0.3932

Train time: 16.695765256881714
 * Prec@1 25.900 Prec@5 85.930 Loss 3.0195
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.983859300613403

Epoch: [11][38/196]	LR: 0.010000000000000002	Loss 0.3225 (0.3903)	Prec@1 90.625 (86.929)	
Epoch: [11][77/196]	LR: 0.010000000000000002	Loss 0.3044 (0.4036)	Prec@1 90.234 (86.303)	
Epoch: [11][116/196]	LR: 0.010000000000000002	Loss 0.4561 (0.4034)	Prec@1 84.375 (86.328)	
Epoch: [11][155/196]	LR: 0.010000000000000002	Loss 0.4092 (0.4016)	Prec@1 86.328 (86.446)	
Epoch: [11][194/196]	LR: 0.010000000000000002	Loss 0.3257 (0.4020)	Prec@1 87.500 (86.384)	
Total train loss: 0.4023

Train time: 17.953481435775757
 * Prec@1 26.820 Prec@5 86.100 Loss 3.0254
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 22.915741443634033

Epoch: [12][38/196]	LR: 0.010000000000000002	Loss 0.4385 (0.4224)	Prec@1 82.812 (85.457)	
Epoch: [12][77/196]	LR: 0.010000000000000002	Loss 0.4241 (0.4156)	Prec@1 87.891 (85.712)	
Epoch: [12][116/196]	LR: 0.010000000000000002	Loss 0.3816 (0.4142)	Prec@1 86.328 (85.804)	
Epoch: [12][155/196]	LR: 0.010000000000000002	Loss 0.4241 (0.4148)	Prec@1 85.938 (85.720)	
Epoch: [12][194/196]	LR: 0.010000000000000002	Loss 0.4060 (0.4155)	Prec@1 85.156 (85.655)	
Total train loss: 0.4155

Train time: 16.854750394821167
 * Prec@1 22.460 Prec@5 82.770 Loss 3.4180
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.95532751083374

Epoch: [13][38/196]	LR: 0.010000000000000002	Loss 0.3633 (0.4126)	Prec@1 88.672 (85.897)	
Epoch: [13][77/196]	LR: 0.010000000000000002	Loss 0.4182 (0.4181)	Prec@1 84.766 (85.577)	
Epoch: [13][116/196]	LR: 0.010000000000000002	Loss 0.2881 (0.4171)	Prec@1 91.797 (85.537)	
Epoch: [13][155/196]	LR: 0.010000000000000002	Loss 0.3701 (0.4219)	Prec@1 87.500 (85.394)	
Epoch: [13][194/196]	LR: 0.010000000000000002	Loss 0.4756 (0.4250)	Prec@1 81.641 (85.270)	
Total train loss: 0.4251

Train time: 16.527771949768066
 * Prec@1 25.850 Prec@5 85.490 Loss 3.1836
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.20150351524353

Epoch: [14][38/196]	LR: 0.010000000000000002	Loss 0.5024 (0.4188)	Prec@1 82.812 (85.697)	
Epoch: [14][77/196]	LR: 0.010000000000000002	Loss 0.5127 (0.4201)	Prec@1 81.641 (85.447)	
Epoch: [14][116/196]	LR: 0.010000000000000002	Loss 0.3342 (0.4261)	Prec@1 88.672 (85.360)	
Epoch: [14][155/196]	LR: 0.010000000000000002	Loss 0.5098 (0.4266)	Prec@1 80.469 (85.261)	
Epoch: [14][194/196]	LR: 0.010000000000000002	Loss 0.4438 (0.4247)	Prec@1 85.547 (85.455)	
Total train loss: 0.4247

Train time: 16.511262893676758
 * Prec@1 26.670 Prec@5 85.360 Loss 3.0918
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.513147830963135

Epoch: [15][38/196]	LR: 0.010000000000000002	Loss 0.4131 (0.4255)	Prec@1 85.938 (85.357)	
Epoch: [15][77/196]	LR: 0.010000000000000002	Loss 0.4231 (0.4315)	Prec@1 85.156 (85.271)	
Epoch: [15][116/196]	LR: 0.010000000000000002	Loss 0.4229 (0.4242)	Prec@1 86.719 (85.483)	
Epoch: [15][155/196]	LR: 0.010000000000000002	Loss 0.5190 (0.4257)	Prec@1 82.422 (85.414)	
Epoch: [15][194/196]	LR: 0.010000000000000002	Loss 0.3916 (0.4252)	Prec@1 86.719 (85.401)	
Total train loss: 0.4251

Train time: 17.24116277694702
 * Prec@1 24.470 Prec@5 84.620 Loss 3.1895
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 19.72502875328064

Epoch: [16][38/196]	LR: 0.0010000000000000002	Loss 0.4224 (0.4227)	Prec@1 87.500 (85.777)	
Epoch: [16][77/196]	LR: 0.0010000000000000002	Loss 0.4265 (0.4249)	Prec@1 85.938 (85.552)	
Epoch: [16][116/196]	LR: 0.0010000000000000002	Loss 0.4182 (0.4235)	Prec@1 87.109 (85.564)	
Epoch: [16][155/196]	LR: 0.0010000000000000002	Loss 0.3916 (0.4227)	Prec@1 85.156 (85.577)	
Epoch: [16][194/196]	LR: 0.0010000000000000002	Loss 0.4275 (0.4236)	Prec@1 84.375 (85.537)	
Total train loss: 0.4235

Train time: 17.38310480117798
 * Prec@1 24.720 Prec@5 84.800 Loss 3.1816
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 21.902329921722412

Epoch: [17][38/196]	LR: 0.0010000000000000002	Loss 0.5488 (0.4317)	Prec@1 82.812 (85.286)	
Epoch: [17][77/196]	LR: 0.0010000000000000002	Loss 0.3848 (0.4316)	Prec@1 85.547 (85.286)	
Epoch: [17][116/196]	LR: 0.0010000000000000002	Loss 0.5894 (0.4263)	Prec@1 78.906 (85.367)	
Epoch: [17][155/196]	LR: 0.0010000000000000002	Loss 0.5220 (0.4244)	Prec@1 83.203 (85.417)	
Epoch: [17][194/196]	LR: 0.0010000000000000002	Loss 0.4839 (0.4235)	Prec@1 81.641 (85.475)	
Total train loss: 0.4233

Train time: 16.58985686302185
 * Prec@1 25.360 Prec@5 85.010 Loss 3.1387
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 19.660224676132202

Epoch: [18][38/196]	LR: 0.0010000000000000002	Loss 0.4375 (0.4296)	Prec@1 85.156 (85.347)	
Epoch: [18][77/196]	LR: 0.0010000000000000002	Loss 0.3923 (0.4286)	Prec@1 85.547 (85.362)	
Epoch: [18][116/196]	LR: 0.0010000000000000002	Loss 0.4709 (0.4236)	Prec@1 85.547 (85.640)	
Epoch: [18][155/196]	LR: 0.0010000000000000002	Loss 0.3958 (0.4227)	Prec@1 85.547 (85.700)	
Epoch: [18][194/196]	LR: 0.0010000000000000002	Loss 0.4905 (0.4228)	Prec@1 82.031 (85.633)	
Total train loss: 0.4231

Train time: 16.067811012268066
 * Prec@1 25.430 Prec@5 85.390 Loss 3.1055
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.064475059509277

Epoch: [19][38/196]	LR: 0.0010000000000000002	Loss 0.4219 (0.4257)	Prec@1 85.156 (85.327)	
Epoch: [19][77/196]	LR: 0.0010000000000000002	Loss 0.4927 (0.4239)	Prec@1 82.031 (85.367)	
Epoch: [19][116/196]	LR: 0.0010000000000000002	Loss 0.3857 (0.4244)	Prec@1 84.766 (85.363)	
Epoch: [19][155/196]	LR: 0.0010000000000000002	Loss 0.5098 (0.4238)	Prec@1 84.375 (85.369)	
Epoch: [19][194/196]	LR: 0.0010000000000000002	Loss 0.4351 (0.4230)	Prec@1 82.812 (85.399)	
Total train loss: 0.4230

Train time: 16.431674242019653
 * Prec@1 24.780 Prec@5 84.670 Loss 3.2305
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 19.72969913482666

Epoch: [20][38/196]	LR: 0.0010000000000000002	Loss 0.3750 (0.4295)	Prec@1 87.500 (85.266)	
Epoch: [20][77/196]	LR: 0.0010000000000000002	Loss 0.4460 (0.4261)	Prec@1 83.203 (85.387)	
Epoch: [20][116/196]	LR: 0.0010000000000000002	Loss 0.4150 (0.4259)	Prec@1 85.547 (85.410)	
Epoch: [20][155/196]	LR: 0.0010000000000000002	Loss 0.4365 (0.4258)	Prec@1 85.156 (85.472)	
Epoch: [20][194/196]	LR: 0.0010000000000000002	Loss 0.4041 (0.4239)	Prec@1 87.109 (85.487)	
Total train loss: 0.4240

Train time: 17.32802391052246
 * Prec@1 24.770 Prec@5 84.640 Loss 3.1953
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 21.363664865493774

Epoch: [21][38/196]	LR: 0.0010000000000000002	Loss 0.3638 (0.4068)	Prec@1 87.891 (86.048)	
Epoch: [21][77/196]	LR: 0.0010000000000000002	Loss 0.4919 (0.4184)	Prec@1 80.469 (85.467)	
Epoch: [21][116/196]	LR: 0.0010000000000000002	Loss 0.3569 (0.4245)	Prec@1 87.891 (85.246)	
Epoch: [21][155/196]	LR: 0.0010000000000000002	Loss 0.4583 (0.4264)	Prec@1 83.984 (85.276)	
Epoch: [21][194/196]	LR: 0.0010000000000000002	Loss 0.3674 (0.4235)	Prec@1 87.109 (85.493)	
Total train loss: 0.4236

Train time: 16.13605523109436
 * Prec@1 25.810 Prec@5 85.260 Loss 3.0645
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 18.99010992050171

Epoch: [22][38/196]	LR: 0.0010000000000000002	Loss 0.5166 (0.4214)	Prec@1 80.078 (85.737)	
Epoch: [22][77/196]	LR: 0.0010000000000000002	Loss 0.4177 (0.4244)	Prec@1 85.156 (85.577)	
Epoch: [22][116/196]	LR: 0.0010000000000000002	Loss 0.3938 (0.4218)	Prec@1 83.594 (85.647)	
Epoch: [22][155/196]	LR: 0.0010000000000000002	Loss 0.4788 (0.4235)	Prec@1 83.594 (85.567)	
Epoch: [22][194/196]	LR: 0.0010000000000000002	Loss 0.4731 (0.4236)	Prec@1 84.375 (85.585)	
Total train loss: 0.4239

Train time: 16.29975390434265
 * Prec@1 25.570 Prec@5 84.960 Loss 3.1191
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.385115385055542

Epoch: [23][38/196]	LR: 0.0010000000000000002	Loss 0.3831 (0.4219)	Prec@1 87.109 (85.387)	
Epoch: [23][77/196]	LR: 0.0010000000000000002	Loss 0.4375 (0.4246)	Prec@1 84.766 (85.557)	
Epoch: [23][116/196]	LR: 0.0010000000000000002	Loss 0.4658 (0.4237)	Prec@1 86.328 (85.524)	
Epoch: [23][155/196]	LR: 0.0010000000000000002	Loss 0.4270 (0.4257)	Prec@1 85.156 (85.369)	
Epoch: [23][194/196]	LR: 0.0010000000000000002	Loss 0.4590 (0.4247)	Prec@1 83.594 (85.445)	
Total train loss: 0.4247

Train time: 20.65021061897278
 * Prec@1 25.240 Prec@5 85.060 Loss 3.1406
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 24.003008365631104

Epoch: [24][38/196]	LR: 0.00010000000000000003	Loss 0.4731 (0.4180)	Prec@1 84.375 (85.777)	
Epoch: [24][77/196]	LR: 0.00010000000000000003	Loss 0.4060 (0.4270)	Prec@1 85.156 (85.417)	
Epoch: [24][116/196]	LR: 0.00010000000000000003	Loss 0.3645 (0.4241)	Prec@1 87.500 (85.427)	
Epoch: [24][155/196]	LR: 0.00010000000000000003	Loss 0.3899 (0.4241)	Prec@1 85.938 (85.364)	
Epoch: [24][194/196]	LR: 0.00010000000000000003	Loss 0.4534 (0.4229)	Prec@1 82.422 (85.407)	
Total train loss: 0.4228

Train time: 18.841906785964966
 * Prec@1 24.680 Prec@5 85.100 Loss 3.1719
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 23.384800672531128

Epoch: [25][38/196]	LR: 0.00010000000000000003	Loss 0.4304 (0.4312)	Prec@1 85.156 (85.086)	
Epoch: [25][77/196]	LR: 0.00010000000000000003	Loss 0.3813 (0.4235)	Prec@1 87.500 (85.442)	
Epoch: [25][116/196]	LR: 0.00010000000000000003	Loss 0.4536 (0.4286)	Prec@1 83.594 (85.190)	
Epoch: [25][155/196]	LR: 0.00010000000000000003	Loss 0.4573 (0.4256)	Prec@1 82.812 (85.327)	
Epoch: [25][194/196]	LR: 0.00010000000000000003	Loss 0.3811 (0.4241)	Prec@1 87.500 (85.487)	
Total train loss: 0.4240

Train time: 20.074411630630493
 * Prec@1 25.990 Prec@5 85.320 Loss 3.0684
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 24.319115161895752

Epoch: [26][38/196]	LR: 0.00010000000000000003	Loss 0.4658 (0.4254)	Prec@1 81.641 (85.357)	
Epoch: [26][77/196]	LR: 0.00010000000000000003	Loss 0.4595 (0.4254)	Prec@1 84.766 (85.327)	
Epoch: [26][116/196]	LR: 0.00010000000000000003	Loss 0.4797 (0.4203)	Prec@1 82.812 (85.520)	
Epoch: [26][155/196]	LR: 0.00010000000000000003	Loss 0.4531 (0.4225)	Prec@1 83.594 (85.437)	
Epoch: [26][194/196]	LR: 0.00010000000000000003	Loss 0.3699 (0.4229)	Prec@1 89.062 (85.441)	
Total train loss: 0.4231

Train time: 17.645588636398315
 * Prec@1 25.680 Prec@5 85.380 Loss 3.0625
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.79378366470337

Epoch: [27][38/196]	LR: 0.00010000000000000003	Loss 0.3030 (0.4097)	Prec@1 91.406 (86.228)	
Epoch: [27][77/196]	LR: 0.00010000000000000003	Loss 0.3577 (0.4149)	Prec@1 90.625 (85.998)	
Epoch: [27][116/196]	LR: 0.00010000000000000003	Loss 0.4900 (0.4196)	Prec@1 83.203 (85.690)	
Epoch: [27][155/196]	LR: 0.00010000000000000003	Loss 0.4243 (0.4218)	Prec@1 86.719 (85.717)	
Epoch: [27][194/196]	LR: 0.00010000000000000003	Loss 0.3923 (0.4222)	Prec@1 86.328 (85.675)	
Total train loss: 0.4228

Train time: 16.16482710838318
 * Prec@1 25.150 Prec@5 85.030 Loss 3.1992
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 19.376065015792847

Epoch: [28][38/196]	LR: 0.00010000000000000003	Loss 0.3884 (0.4259)	Prec@1 83.594 (85.507)	
Epoch: [28][77/196]	LR: 0.00010000000000000003	Loss 0.5356 (0.4309)	Prec@1 81.641 (85.382)	
Epoch: [28][116/196]	LR: 0.00010000000000000003	Loss 0.3528 (0.4246)	Prec@1 87.500 (85.473)	
Epoch: [28][155/196]	LR: 0.00010000000000000003	Loss 0.4568 (0.4234)	Prec@1 86.328 (85.537)	
Epoch: [28][194/196]	LR: 0.00010000000000000003	Loss 0.4534 (0.4233)	Prec@1 84.375 (85.535)	
Total train loss: 0.4233

Train time: 17.749324798583984
 * Prec@1 26.220 Prec@5 85.370 Loss 3.0430
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 21.629268646240234

Epoch: [29][38/196]	LR: 0.00010000000000000003	Loss 0.4314 (0.4277)	Prec@1 84.375 (85.667)	
Epoch: [29][77/196]	LR: 0.00010000000000000003	Loss 0.4053 (0.4283)	Prec@1 89.062 (85.452)	
Epoch: [29][116/196]	LR: 0.00010000000000000003	Loss 0.4355 (0.4259)	Prec@1 85.156 (85.544)	
Epoch: [29][155/196]	LR: 0.00010000000000000003	Loss 0.4849 (0.4229)	Prec@1 83.203 (85.640)	
Epoch: [29][194/196]	LR: 0.00010000000000000003	Loss 0.4651 (0.4246)	Prec@1 83.203 (85.487)	
Total train loss: 0.4247

Train time: 16.743424654006958
 * Prec@1 24.740 Prec@5 84.940 Loss 3.2012
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.012779474258423

Epoch: [30][38/196]	LR: 0.00010000000000000003	Loss 0.4180 (0.4110)	Prec@1 83.984 (85.867)	
Epoch: [30][77/196]	LR: 0.00010000000000000003	Loss 0.3997 (0.4164)	Prec@1 87.891 (85.742)	
Epoch: [30][116/196]	LR: 0.00010000000000000003	Loss 0.4602 (0.4199)	Prec@1 86.328 (85.647)	
Epoch: [30][155/196]	LR: 0.00010000000000000003	Loss 0.5171 (0.4186)	Prec@1 82.812 (85.640)	
Epoch: [30][194/196]	LR: 0.00010000000000000003	Loss 0.4253 (0.4238)	Prec@1 83.984 (85.525)	
Total train loss: 0.4240

Train time: 16.112653017044067
 * Prec@1 25.270 Prec@5 85.210 Loss 3.1387
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 19.31693172454834

Epoch: [31][38/196]	LR: 0.00010000000000000003	Loss 0.3828 (0.4178)	Prec@1 85.547 (85.747)	
Epoch: [31][77/196]	LR: 0.00010000000000000003	Loss 0.4631 (0.4247)	Prec@1 85.547 (85.301)	
Epoch: [31][116/196]	LR: 0.00010000000000000003	Loss 0.4075 (0.4247)	Prec@1 87.500 (85.417)	
Epoch: [31][155/196]	LR: 0.00010000000000000003	Loss 0.3635 (0.4222)	Prec@1 88.672 (85.497)	
Epoch: [31][194/196]	LR: 0.00010000000000000003	Loss 0.4841 (0.4230)	Prec@1 83.203 (85.483)	
Total train loss: 0.4230

Train time: 16.70578622817993
 * Prec@1 26.020 Prec@5 85.330 Loss 3.0762
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.409069776535034

Epoch: [32][38/196]	LR: 1.0000000000000004e-05	Loss 0.4290 (0.4188)	Prec@1 87.500 (85.978)	
Epoch: [32][77/196]	LR: 1.0000000000000004e-05	Loss 0.3945 (0.4179)	Prec@1 84.375 (85.807)	
Epoch: [32][116/196]	LR: 1.0000000000000004e-05	Loss 0.3884 (0.4168)	Prec@1 85.938 (85.891)	
Epoch: [32][155/196]	LR: 1.0000000000000004e-05	Loss 0.3264 (0.4222)	Prec@1 89.453 (85.637)	
Epoch: [32][194/196]	LR: 1.0000000000000004e-05	Loss 0.4880 (0.4223)	Prec@1 82.031 (85.597)	
Total train loss: 0.4223

Train time: 17.617780208587646
 * Prec@1 24.630 Prec@5 85.250 Loss 3.1562
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.587090492248535

Epoch: [33][38/196]	LR: 1.0000000000000004e-05	Loss 0.2979 (0.4181)	Prec@1 89.062 (85.707)	
Epoch: [33][77/196]	LR: 1.0000000000000004e-05	Loss 0.4741 (0.4226)	Prec@1 82.812 (85.482)	
Epoch: [33][116/196]	LR: 1.0000000000000004e-05	Loss 0.3423 (0.4222)	Prec@1 88.672 (85.473)	
Epoch: [33][155/196]	LR: 1.0000000000000004e-05	Loss 0.3660 (0.4209)	Prec@1 88.281 (85.494)	
Epoch: [33][194/196]	LR: 1.0000000000000004e-05	Loss 0.3494 (0.4223)	Prec@1 89.062 (85.559)	
Total train loss: 0.4225

Train time: 17.426191568374634
 * Prec@1 25.270 Prec@5 85.470 Loss 3.1094
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.50111746788025

Epoch: [34][38/196]	LR: 1.0000000000000004e-05	Loss 0.4316 (0.4291)	Prec@1 84.766 (85.086)	
Epoch: [34][77/196]	LR: 1.0000000000000004e-05	Loss 0.3547 (0.4181)	Prec@1 88.281 (85.527)	
Epoch: [34][116/196]	LR: 1.0000000000000004e-05	Loss 0.3464 (0.4178)	Prec@1 89.062 (85.687)	
Epoch: [34][155/196]	LR: 1.0000000000000004e-05	Loss 0.4512 (0.4202)	Prec@1 86.328 (85.619)	
Epoch: [34][194/196]	LR: 1.0000000000000004e-05	Loss 0.4692 (0.4225)	Prec@1 84.766 (85.527)	
Total train loss: 0.4225

Train time: 16.390088319778442
 * Prec@1 25.860 Prec@5 85.160 Loss 3.0840
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.270548582077026

Epoch: [35][38/196]	LR: 1.0000000000000004e-05	Loss 0.3889 (0.4222)	Prec@1 88.281 (85.577)	
Epoch: [35][77/196]	LR: 1.0000000000000004e-05	Loss 0.4749 (0.4217)	Prec@1 84.766 (85.752)	
Epoch: [35][116/196]	LR: 1.0000000000000004e-05	Loss 0.4583 (0.4216)	Prec@1 84.375 (85.640)	
Epoch: [35][155/196]	LR: 1.0000000000000004e-05	Loss 0.3450 (0.4227)	Prec@1 87.109 (85.589)	
Epoch: [35][194/196]	LR: 1.0000000000000004e-05	Loss 0.4836 (0.4225)	Prec@1 81.250 (85.547)	
Total train loss: 0.4227

Train time: 16.929093599319458
 * Prec@1 24.630 Prec@5 85.100 Loss 3.1934
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.18955945968628

Epoch: [36][38/196]	LR: 1.0000000000000004e-05	Loss 0.4480 (0.4204)	Prec@1 83.203 (85.657)	
Epoch: [36][77/196]	LR: 1.0000000000000004e-05	Loss 0.4019 (0.4224)	Prec@1 87.891 (85.497)	
Epoch: [36][116/196]	LR: 1.0000000000000004e-05	Loss 0.4316 (0.4239)	Prec@1 84.375 (85.467)	
Epoch: [36][155/196]	LR: 1.0000000000000004e-05	Loss 0.5059 (0.4259)	Prec@1 83.984 (85.372)	
Epoch: [36][194/196]	LR: 1.0000000000000004e-05	Loss 0.4202 (0.4238)	Prec@1 85.156 (85.523)	
Total train loss: 0.4239

Train time: 17.075936794281006
 * Prec@1 25.420 Prec@5 85.190 Loss 3.1055
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 20.134844064712524

Epoch: [37][38/196]	LR: 1.0000000000000004e-05	Loss 0.3455 (0.4303)	Prec@1 87.500 (84.956)	
Epoch: [37][77/196]	LR: 1.0000000000000004e-05	Loss 0.4485 (0.4284)	Prec@1 85.156 (85.296)	
Epoch: [37][116/196]	LR: 1.0000000000000004e-05	Loss 0.4697 (0.4281)	Prec@1 83.984 (85.327)	
Epoch: [37][155/196]	LR: 1.0000000000000004e-05	Loss 0.3752 (0.4270)	Prec@1 87.109 (85.339)	
Epoch: [37][194/196]	LR: 1.0000000000000004e-05	Loss 0.3916 (0.4240)	Prec@1 87.109 (85.383)	
Total train loss: 0.4240

Train time: 15.764373302459717
 * Prec@1 26.050 Prec@5 85.150 Loss 3.0586
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 19.72840189933777

Epoch: [38][38/196]	LR: 1.0000000000000004e-05	Loss 0.4390 (0.4211)	Prec@1 85.938 (85.637)	
Epoch: [38][77/196]	LR: 1.0000000000000004e-05	Loss 0.3813 (0.4166)	Prec@1 87.500 (85.667)	
Epoch: [38][116/196]	LR: 1.0000000000000004e-05	Loss 0.4282 (0.4227)	Prec@1 83.984 (85.453)	
Epoch: [38][155/196]	LR: 1.0000000000000004e-05	Loss 0.4307 (0.4227)	Prec@1 87.109 (85.564)	
Epoch: [38][194/196]	LR: 1.0000000000000004e-05	Loss 0.5161 (0.4222)	Prec@1 82.812 (85.541)	
Total train loss: 0.4224

Train time: 16.08144974708557
 * Prec@1 25.500 Prec@5 84.950 Loss 3.0898
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 19.34437322616577

Epoch: [39][38/196]	LR: 1.0000000000000004e-05	Loss 0.4480 (0.4299)	Prec@1 83.594 (85.327)	
Epoch: [39][77/196]	LR: 1.0000000000000004e-05	Loss 0.3718 (0.4191)	Prec@1 85.156 (85.742)	
Epoch: [39][116/196]	LR: 1.0000000000000004e-05	Loss 0.4102 (0.4242)	Prec@1 83.984 (85.610)	
Epoch: [39][155/196]	LR: 1.0000000000000004e-05	Loss 0.4805 (0.4236)	Prec@1 84.375 (85.597)	
Epoch: [39][194/196]	LR: 1.0000000000000004e-05	Loss 0.4021 (0.4250)	Prec@1 87.500 (85.541)	
Total train loss: 0.4252

Train time: 7.701723098754883
 * Prec@1 25.420 Prec@5 85.230 Loss 3.1367
Best acc: 41.790
--------------------------------------------------------------------------------
Test time: 9.688109874725342

