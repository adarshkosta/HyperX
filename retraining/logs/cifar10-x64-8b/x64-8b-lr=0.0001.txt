
      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.0001
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 1
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.580 Prec@5 99.660 Loss 0.3188
Pre-trained Prec@1 with 1 layers frozen: 91.57999420166016 	 Loss: 0.31884765625

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.0001	Loss 2.4629 (2.7078)	Prec@1 29.688 (26.302)	
Epoch: [0][155/391]	LR: 0.0001	Loss 2.0918 (2.5936)	Prec@1 29.688 (26.873)	
Epoch: [0][233/391]	LR: 0.0001	Loss 2.0137 (2.4743)	Prec@1 28.125 (28.058)	
Epoch: [0][311/391]	LR: 0.0001	Loss 2.6309 (2.4054)	Prec@1 24.219 (28.723)	
Epoch: [0][389/391]	LR: 0.0001	Loss 2.0137 (2.3450)	Prec@1 29.688 (29.369)	
Total train loss: 2.3456

Train time: 352.27556443214417
 * Prec@1 67.320 Prec@5 94.950 Loss 2.1113
Best acc: 67.320
--------------------------------------------------------------------------------
Test time: 355.14228105545044

Epoch: [1][77/391]	LR: 0.0001	Loss 2.0840 (2.0601)	Prec@1 28.125 (32.161)	
Epoch: [1][155/391]	LR: 0.0001	Loss 2.2188 (2.0509)	Prec@1 27.344 (32.232)	
Epoch: [1][233/391]	LR: 0.0001	Loss 1.7715 (2.0331)	Prec@1 37.500 (32.305)	
Epoch: [1][311/391]	LR: 0.0001	Loss 1.8330 (2.0131)	Prec@1 36.719 (32.449)	
Epoch: [1][389/391]	LR: 0.0001	Loss 1.7002 (2.0066)	Prec@1 38.281 (32.390)	
Total train loss: 2.0069

Train time: 19.50842261314392
 * Prec@1 71.230 Prec@5 96.160 Loss 1.8145
Best acc: 71.230
--------------------------------------------------------------------------------
Test time: 22.25708818435669

Epoch: [2][77/391]	LR: 0.0001	Loss 2.0195 (1.9449)	Prec@1 39.062 (32.362)	
Epoch: [2][155/391]	LR: 0.0001	Loss 2.3418 (1.9393)	Prec@1 21.094 (32.597)	
Epoch: [2][233/391]	LR: 0.0001	Loss 2.2500 (1.9297)	Prec@1 26.562 (32.896)	
Epoch: [2][311/391]	LR: 0.0001	Loss 1.6074 (1.9210)	Prec@1 37.500 (33.100)	
Epoch: [2][389/391]	LR: 0.0001	Loss 1.8828 (1.9140)	Prec@1 32.031 (33.175)	
Total train loss: 1.9143

Train time: 17.090207815170288
 * Prec@1 73.570 Prec@5 96.810 Loss 1.5771
Best acc: 73.570
--------------------------------------------------------------------------------
Test time: 19.02373456954956

Epoch: [3][77/391]	LR: 0.0001	Loss 1.7852 (1.9082)	Prec@1 37.500 (32.893)	
Epoch: [3][155/391]	LR: 0.0001	Loss 2.0898 (1.8770)	Prec@1 33.594 (33.814)	
Epoch: [3][233/391]	LR: 0.0001	Loss 2.0918 (1.8639)	Prec@1 28.906 (33.978)	
Epoch: [3][311/391]	LR: 0.0001	Loss 2.2715 (1.8584)	Prec@1 28.906 (33.992)	
Epoch: [3][389/391]	LR: 0.0001	Loss 1.7715 (1.8627)	Prec@1 35.938 (33.852)	
Total train loss: 1.8620

Train time: 17.187868118286133
 * Prec@1 76.000 Prec@5 97.280 Loss 1.3945
Best acc: 76.000
--------------------------------------------------------------------------------
Test time: 19.9225811958313

Epoch: [4][77/391]	LR: 0.0001	Loss 1.5205 (1.8288)	Prec@1 45.312 (34.405)	
Epoch: [4][155/391]	LR: 0.0001	Loss 1.7686 (1.8198)	Prec@1 33.594 (34.615)	
Epoch: [4][233/391]	LR: 0.0001	Loss 1.7598 (1.8203)	Prec@1 32.812 (34.442)	
Epoch: [4][311/391]	LR: 0.0001	Loss 2.3164 (1.8299)	Prec@1 25.781 (34.360)	
Epoch: [4][389/391]	LR: 0.0001	Loss 1.6328 (1.8241)	Prec@1 39.062 (34.421)	
Total train loss: 1.8241

Train time: 16.796095609664917
 * Prec@1 77.080 Prec@5 97.550 Loss 1.3301
Best acc: 77.080
--------------------------------------------------------------------------------
Test time: 18.707345008850098

Epoch: [5][77/391]	LR: 0.0001	Loss 1.4971 (1.7862)	Prec@1 44.531 (35.296)	
Epoch: [5][155/391]	LR: 0.0001	Loss 2.0488 (1.7866)	Prec@1 24.219 (35.106)	
Epoch: [5][233/391]	LR: 0.0001	Loss 2.0137 (1.8008)	Prec@1 32.812 (34.806)	
Epoch: [5][311/391]	LR: 0.0001	Loss 1.5957 (1.8012)	Prec@1 40.625 (34.756)	
Epoch: [5][389/391]	LR: 0.0001	Loss 1.8379 (1.7992)	Prec@1 34.375 (34.748)	
Total train loss: 1.7983

Train time: 18.967687129974365
 * Prec@1 78.020 Prec@5 97.820 Loss 1.2148
Best acc: 78.020
--------------------------------------------------------------------------------
Test time: 21.724106073379517

Epoch: [6][77/391]	LR: 0.0001	Loss 1.8594 (1.7705)	Prec@1 31.250 (35.226)	
Epoch: [6][155/391]	LR: 0.0001	Loss 1.7480 (1.7809)	Prec@1 34.375 (34.971)	
Epoch: [6][233/391]	LR: 0.0001	Loss 2.0332 (1.8017)	Prec@1 29.688 (34.796)	
Epoch: [6][311/391]	LR: 0.0001	Loss 1.6904 (1.7950)	Prec@1 33.594 (35.054)	
Epoch: [6][389/391]	LR: 0.0001	Loss 1.6221 (1.7861)	Prec@1 41.406 (35.260)	
Total train loss: 1.7861

Train time: 16.624038696289062
 * Prec@1 78.480 Prec@5 97.760 Loss 1.2217
Best acc: 78.480
--------------------------------------------------------------------------------
Test time: 18.51649808883667

Epoch: [7][77/391]	LR: 0.0001	Loss 1.7715 (1.7679)	Prec@1 38.281 (35.497)	
Epoch: [7][155/391]	LR: 0.0001	Loss 1.7490 (1.7630)	Prec@1 36.719 (35.372)	
Epoch: [7][233/391]	LR: 0.0001	Loss 1.7031 (1.7681)	Prec@1 41.406 (35.213)	
Epoch: [7][311/391]	LR: 0.0001	Loss 1.7627 (1.7658)	Prec@1 35.156 (35.209)	
Epoch: [7][389/391]	LR: 0.0001	Loss 1.7959 (1.7663)	Prec@1 36.719 (35.262)	
Total train loss: 1.7667

Train time: 16.498101234436035
 * Prec@1 79.510 Prec@5 98.040 Loss 1.1406
Best acc: 79.510
--------------------------------------------------------------------------------
Test time: 19.23332667350769

Epoch: [8][77/391]	LR: 0.0001	Loss 1.7129 (1.7801)	Prec@1 35.938 (35.006)	
Epoch: [8][155/391]	LR: 0.0001	Loss 1.6396 (1.7513)	Prec@1 38.281 (35.877)	
Epoch: [8][233/391]	LR: 0.0001	Loss 1.7061 (1.7500)	Prec@1 39.062 (35.854)	
Epoch: [8][311/391]	LR: 0.0001	Loss 1.7461 (1.7534)	Prec@1 32.031 (35.707)	
Epoch: [8][389/391]	LR: 0.0001	Loss 1.8457 (1.7569)	Prec@1 34.375 (35.489)	
Total train loss: 1.7569

Train time: 16.554437398910522
 * Prec@1 78.160 Prec@5 97.830 Loss 1.2607
Best acc: 79.510
--------------------------------------------------------------------------------
Test time: 18.42093276977539

Epoch: [9][77/391]	LR: 0.0001	Loss 1.7510 (1.7562)	Prec@1 38.281 (35.397)	
Epoch: [9][155/391]	LR: 0.0001	Loss 1.8984 (1.7411)	Prec@1 28.125 (35.722)	
Epoch: [9][233/391]	LR: 0.0001	Loss 1.6914 (1.7381)	Prec@1 42.969 (35.817)	
Epoch: [9][311/391]	LR: 0.0001	Loss 1.8291 (1.7444)	Prec@1 27.344 (35.569)	
Epoch: [9][389/391]	LR: 0.0001	Loss 1.9482 (1.7413)	Prec@1 31.250 (35.603)	
Total train loss: 1.7415

Train time: 16.978834867477417
 * Prec@1 79.390 Prec@5 98.120 Loss 1.1260
Best acc: 79.510
--------------------------------------------------------------------------------
Test time: 19.758434057235718

Epoch: [10][77/391]	LR: 0.0001	Loss 1.5908 (1.7304)	Prec@1 38.281 (36.158)	
Epoch: [10][155/391]	LR: 0.0001	Loss 1.9248 (1.7270)	Prec@1 24.219 (36.103)	
Epoch: [10][233/391]	LR: 0.0001	Loss 1.7979 (1.7349)	Prec@1 33.594 (35.984)	
Epoch: [10][311/391]	LR: 0.0001	Loss 1.5840 (1.7342)	Prec@1 36.719 (35.965)	
Epoch: [10][389/391]	LR: 0.0001	Loss 1.6191 (1.7307)	Prec@1 38.281 (36.030)	
Total train loss: 1.7308

Train time: 17.653127670288086
 * Prec@1 80.110 Prec@5 98.190 Loss 1.0996
Best acc: 80.110
--------------------------------------------------------------------------------
Test time: 19.694836616516113

Epoch: [11][77/391]	LR: 0.0001	Loss 1.9082 (1.7369)	Prec@1 32.031 (35.497)	
Epoch: [11][155/391]	LR: 0.0001	Loss 1.7188 (1.7419)	Prec@1 32.031 (35.437)	
Epoch: [11][233/391]	LR: 0.0001	Loss 1.5596 (1.7275)	Prec@1 37.500 (35.894)	
Epoch: [11][311/391]	LR: 0.0001	Loss 1.6973 (1.7228)	Prec@1 39.062 (36.018)	
Epoch: [11][389/391]	LR: 0.0001	Loss 1.7910 (1.7256)	Prec@1 31.250 (35.893)	
Total train loss: 1.7253

Train time: 17.719173431396484
 * Prec@1 80.600 Prec@5 98.150 Loss 1.0791
Best acc: 80.600
--------------------------------------------------------------------------------
Test time: 20.438868761062622

Epoch: [12][77/391]	LR: 0.0001	Loss 1.6084 (1.7238)	Prec@1 35.156 (35.958)	
Epoch: [12][155/391]	LR: 0.0001	Loss 1.9590 (1.7163)	Prec@1 32.812 (35.862)	
Epoch: [12][233/391]	LR: 0.0001	Loss 1.7373 (1.7163)	Prec@1 35.156 (35.894)	
Epoch: [12][311/391]	LR: 0.0001	Loss 1.5684 (1.7174)	Prec@1 44.531 (35.892)	
Epoch: [12][389/391]	LR: 0.0001	Loss 1.7256 (1.7194)	Prec@1 40.625 (35.897)	
Total train loss: 1.7207

Train time: 16.799309492111206
 * Prec@1 80.420 Prec@5 98.230 Loss 1.0947
Best acc: 80.600
--------------------------------------------------------------------------------
Test time: 18.7218120098114

Epoch: [13][77/391]	LR: 0.0001	Loss 1.7715 (1.7068)	Prec@1 39.062 (36.268)	
Epoch: [13][155/391]	LR: 0.0001	Loss 1.9648 (1.7212)	Prec@1 30.469 (35.802)	
Epoch: [13][233/391]	LR: 0.0001	Loss 1.6240 (1.7238)	Prec@1 38.281 (35.797)	
Epoch: [13][311/391]	LR: 0.0001	Loss 1.7568 (1.7126)	Prec@1 34.375 (36.053)	
Epoch: [13][389/391]	LR: 0.0001	Loss 1.9600 (1.7121)	Prec@1 28.906 (35.921)	
Total train loss: 1.7122

Train time: 16.461607933044434
 * Prec@1 80.960 Prec@5 98.330 Loss 1.0547
Best acc: 80.960
--------------------------------------------------------------------------------
Test time: 19.305845737457275

Epoch: [14][77/391]	LR: 0.0001	Loss 1.5078 (1.6954)	Prec@1 40.625 (36.679)	
Epoch: [14][155/391]	LR: 0.0001	Loss 1.6943 (1.6865)	Prec@1 36.719 (36.869)	
Epoch: [14][233/391]	LR: 0.0001	Loss 1.7529 (1.7003)	Prec@1 36.719 (36.325)	
Epoch: [14][311/391]	LR: 0.0001	Loss 2.3848 (1.7059)	Prec@1 20.312 (36.143)	
Epoch: [14][389/391]	LR: 0.0001	Loss 1.7891 (1.7024)	Prec@1 33.594 (36.284)	
Total train loss: 1.7027

Train time: 18.128573417663574
 * Prec@1 81.620 Prec@5 98.430 Loss 1.0068
Best acc: 81.620
--------------------------------------------------------------------------------
Test time: 20.100624561309814

Epoch: [15][77/391]	LR: 0.0001	Loss 1.7568 (1.6786)	Prec@1 36.719 (37.039)	
Epoch: [15][155/391]	LR: 0.0001	Loss 1.6660 (1.6887)	Prec@1 35.938 (36.558)	
Epoch: [15][233/391]	LR: 0.0001	Loss 1.5703 (1.7001)	Prec@1 38.281 (36.351)	
Epoch: [15][311/391]	LR: 0.0001	Loss 1.8887 (1.7029)	Prec@1 28.906 (36.251)	
Epoch: [15][389/391]	LR: 0.0001	Loss 1.6504 (1.7045)	Prec@1 35.938 (36.274)	
Total train loss: 1.7046

Train time: 16.51322102546692
 * Prec@1 82.030 Prec@5 98.480 Loss 0.9673
Best acc: 82.030
--------------------------------------------------------------------------------
Test time: 19.30807399749756

Epoch: [16][77/391]	LR: 0.0001	Loss 1.6484 (1.6998)	Prec@1 38.281 (36.248)	
Epoch: [16][155/391]	LR: 0.0001	Loss 1.7100 (1.7009)	Prec@1 31.250 (36.298)	
Epoch: [16][233/391]	LR: 0.0001	Loss 1.5879 (1.6986)	Prec@1 42.188 (36.395)	
Epoch: [16][311/391]	LR: 0.0001	Loss 1.7412 (1.6982)	Prec@1 37.500 (36.428)	
Epoch: [16][389/391]	LR: 0.0001	Loss 1.4971 (1.6954)	Prec@1 44.531 (36.607)	
Total train loss: 1.6961

Train time: 16.645732879638672
 * Prec@1 81.940 Prec@5 98.550 Loss 0.9639
Best acc: 82.030
--------------------------------------------------------------------------------
Test time: 18.593395471572876

Epoch: [17][77/391]	LR: 0.0001	Loss 1.6719 (1.6710)	Prec@1 35.156 (37.190)	
Epoch: [17][155/391]	LR: 0.0001	Loss 1.5811 (1.6820)	Prec@1 42.188 (36.939)	
Epoch: [17][233/391]	LR: 0.0001	Loss 1.8555 (1.6906)	Prec@1 32.812 (36.745)	
Epoch: [17][311/391]	LR: 0.0001	Loss 1.7266 (1.6899)	Prec@1 33.594 (36.711)	
Epoch: [17][389/391]	LR: 0.0001	Loss 1.6846 (1.6964)	Prec@1 41.406 (36.464)	
Total train loss: 1.6968

Train time: 17.292896270751953
 * Prec@1 81.930 Prec@5 98.390 Loss 1.0020
Best acc: 82.030
--------------------------------------------------------------------------------
Test time: 20.001386880874634

Epoch: [18][77/391]	LR: 0.0001	Loss 1.7910 (1.6937)	Prec@1 33.594 (36.629)	
Epoch: [18][155/391]	LR: 0.0001	Loss 1.7969 (1.6960)	Prec@1 37.500 (36.493)	
Epoch: [18][233/391]	LR: 0.0001	Loss 1.6582 (1.6813)	Prec@1 41.406 (37.003)	
Epoch: [18][311/391]	LR: 0.0001	Loss 1.6475 (1.6814)	Prec@1 35.938 (36.952)	
Epoch: [18][389/391]	LR: 0.0001	Loss 1.7441 (1.6848)	Prec@1 30.469 (36.751)	
Total train loss: 1.6853

Train time: 16.185265064239502
 * Prec@1 81.090 Prec@5 98.230 Loss 1.0732
Best acc: 82.030
--------------------------------------------------------------------------------
Test time: 18.118896484375

Epoch: [19][77/391]	LR: 0.0001	Loss 1.6309 (1.6577)	Prec@1 38.281 (37.901)	
Epoch: [19][155/391]	LR: 0.0001	Loss 1.7871 (1.6817)	Prec@1 32.812 (37.119)	
Epoch: [19][233/391]	LR: 0.0001	Loss 1.6123 (1.6736)	Prec@1 38.281 (37.210)	
Epoch: [19][311/391]	LR: 0.0001	Loss 1.8389 (1.6748)	Prec@1 28.906 (37.072)	
Epoch: [19][389/391]	LR: 0.0001	Loss 1.6416 (1.6839)	Prec@1 33.594 (36.751)	
Total train loss: 1.6836

Train time: 17.680817365646362
 * Prec@1 82.500 Prec@5 98.680 Loss 0.9546
Best acc: 82.500
--------------------------------------------------------------------------------
Test time: 20.402646780014038

Epoch: [20][77/391]	LR: 1e-05	Loss 1.4531 (1.6965)	Prec@1 45.312 (36.338)	
Epoch: [20][155/391]	LR: 1e-05	Loss 1.7129 (1.6882)	Prec@1 39.062 (36.533)	
Epoch: [20][233/391]	LR: 1e-05	Loss 1.9639 (1.6871)	Prec@1 28.125 (36.562)	
Epoch: [20][311/391]	LR: 1e-05	Loss 1.7197 (1.6844)	Prec@1 32.812 (36.478)	
Epoch: [20][389/391]	LR: 1e-05	Loss 1.5361 (1.6818)	Prec@1 41.406 (36.500)	
Total train loss: 1.6819

Train time: 16.998876333236694
 * Prec@1 83.260 Prec@5 98.650 Loss 0.8906
Best acc: 83.260
--------------------------------------------------------------------------------
Test time: 18.955271005630493

Epoch: [21][77/391]	LR: 1e-05	Loss 1.7422 (1.6986)	Prec@1 35.156 (36.288)	
Epoch: [21][155/391]	LR: 1e-05	Loss 1.7676 (1.6906)	Prec@1 35.156 (36.584)	
Epoch: [21][233/391]	LR: 1e-05	Loss 1.8867 (1.6895)	Prec@1 32.031 (36.448)	
Epoch: [21][311/391]	LR: 1e-05	Loss 1.7168 (1.6914)	Prec@1 31.250 (36.398)	
Epoch: [21][389/391]	LR: 1e-05	Loss 1.5547 (1.6857)	Prec@1 40.625 (36.548)	
Total train loss: 1.6858

Train time: 17.824137210845947
 * Prec@1 82.960 Prec@5 98.680 Loss 0.9121
Best acc: 83.260
--------------------------------------------------------------------------------
Test time: 20.551209211349487

Epoch: [22][77/391]	LR: 1e-05	Loss 1.4854 (1.6841)	Prec@1 41.406 (36.068)	
Epoch: [22][155/391]	LR: 1e-05	Loss 1.8457 (1.6967)	Prec@1 31.250 (36.128)	
Epoch: [22][233/391]	LR: 1e-05	Loss 1.4531 (1.6825)	Prec@1 43.750 (36.625)	
Epoch: [22][311/391]	LR: 1e-05	Loss 1.4561 (1.6897)	Prec@1 41.406 (36.483)	
Epoch: [22][389/391]	LR: 1e-05	Loss 1.7500 (1.6848)	Prec@1 36.719 (36.623)	
Total train loss: 1.6849

Train time: 17.46689534187317
 * Prec@1 82.690 Prec@5 98.590 Loss 0.9375
Best acc: 83.260
--------------------------------------------------------------------------------
Test time: 19.446173191070557

Epoch: [23][77/391]	LR: 1e-05	Loss 1.7656 (1.7063)	Prec@1 33.594 (35.747)	
Epoch: [23][155/391]	LR: 1e-05	Loss 1.7471 (1.6968)	Prec@1 38.281 (36.158)	
Epoch: [23][233/391]	LR: 1e-05	Loss 1.6416 (1.6961)	Prec@1 39.844 (36.345)	
Epoch: [23][311/391]	LR: 1e-05	Loss 1.6611 (1.6876)	Prec@1 35.938 (36.476)	
Epoch: [23][389/391]	LR: 1e-05	Loss 1.6045 (1.6844)	Prec@1 33.594 (36.490)	
Total train loss: 1.6849

Train time: 16.451905488967896
 * Prec@1 83.100 Prec@5 98.620 Loss 0.9072
Best acc: 83.260
--------------------------------------------------------------------------------
Test time: 19.206695795059204

Epoch: [24][77/391]	LR: 1e-05	Loss 2.1641 (1.7046)	Prec@1 25.000 (35.978)	
Epoch: [24][155/391]	LR: 1e-05	Loss 1.5752 (1.6928)	Prec@1 43.750 (36.323)	
Epoch: [24][233/391]	LR: 1e-05	Loss 1.6709 (1.6904)	Prec@1 35.156 (36.442)	
Epoch: [24][311/391]	LR: 1e-05	Loss 1.7480 (1.6879)	Prec@1 33.594 (36.508)	
Epoch: [24][389/391]	LR: 1e-05	Loss 1.8477 (1.6859)	Prec@1 32.812 (36.532)	
Total train loss: 1.6858

Train time: 16.944721221923828
 * Prec@1 82.440 Prec@5 98.620 Loss 0.9502
Best acc: 83.260
--------------------------------------------------------------------------------
Test time: 18.874930381774902


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.0001
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 3
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.580 Prec@5 99.670 Loss 0.3181
Pre-trained Prec@1 with 3 layers frozen: 91.57999420166016 	 Loss: 0.318115234375

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.0001	Loss 2.4941 (2.8981)	Prec@1 30.469 (25.170)	
Epoch: [0][155/391]	LR: 0.0001	Loss 2.3672 (2.6906)	Prec@1 24.219 (26.387)	
Epoch: [0][233/391]	LR: 0.0001	Loss 2.5391 (2.5695)	Prec@1 30.469 (27.521)	
Epoch: [0][311/391]	LR: 0.0001	Loss 1.9531 (2.4978)	Prec@1 42.188 (28.160)	
Epoch: [0][389/391]	LR: 0.0001	Loss 2.5391 (2.4344)	Prec@1 18.750 (28.808)	
Total train loss: 2.4340

Train time: 207.6018888950348
 * Prec@1 64.830 Prec@5 93.830 Loss 2.4531
Best acc: 64.830
--------------------------------------------------------------------------------
Test time: 210.2421875

Epoch: [1][77/391]	LR: 0.0001	Loss 1.9668 (2.1048)	Prec@1 32.812 (32.081)	
Epoch: [1][155/391]	LR: 0.0001	Loss 2.2246 (2.0925)	Prec@1 24.219 (32.151)	
Epoch: [1][233/391]	LR: 0.0001	Loss 2.0352 (2.1010)	Prec@1 36.719 (31.771)	
Epoch: [1][311/391]	LR: 0.0001	Loss 2.4199 (2.0822)	Prec@1 25.000 (31.916)	
Epoch: [1][389/391]	LR: 0.0001	Loss 1.9014 (2.0720)	Prec@1 32.031 (31.887)	
Total train loss: 2.0726

Train time: 16.377910137176514
 * Prec@1 71.020 Prec@5 96.100 Loss 1.8525
Best acc: 71.020
--------------------------------------------------------------------------------
Test time: 18.73029088973999

Epoch: [2][77/391]	LR: 0.0001	Loss 1.9414 (1.9526)	Prec@1 34.375 (33.043)	
Epoch: [2][155/391]	LR: 0.0001	Loss 1.6943 (1.9616)	Prec@1 36.719 (33.008)	
Epoch: [2][233/391]	LR: 0.0001	Loss 1.7559 (1.9654)	Prec@1 35.938 (32.946)	
Epoch: [2][311/391]	LR: 0.0001	Loss 2.2070 (1.9657)	Prec@1 24.219 (32.918)	
Epoch: [2][389/391]	LR: 0.0001	Loss 1.9795 (1.9552)	Prec@1 26.562 (33.145)	
Total train loss: 1.9548

Train time: 17.405162572860718
 * Prec@1 71.850 Prec@5 96.420 Loss 1.7744
Best acc: 71.850
--------------------------------------------------------------------------------
Test time: 19.303383588790894

Epoch: [3][77/391]	LR: 0.0001	Loss 1.8945 (1.9268)	Prec@1 35.938 (32.903)	
Epoch: [3][155/391]	LR: 0.0001	Loss 1.5986 (1.9117)	Prec@1 38.281 (33.148)	
Epoch: [3][233/391]	LR: 0.0001	Loss 2.0840 (1.9057)	Prec@1 25.000 (33.317)	
Epoch: [3][311/391]	LR: 0.0001	Loss 1.7363 (1.8920)	Prec@1 31.250 (33.644)	
Epoch: [3][389/391]	LR: 0.0001	Loss 1.9336 (1.8917)	Prec@1 32.031 (33.496)	
Total train loss: 1.8918

Train time: 16.174171686172485
 * Prec@1 73.500 Prec@5 96.650 Loss 1.6318
Best acc: 73.500
--------------------------------------------------------------------------------
Test time: 18.8793363571167

Epoch: [4][77/391]	LR: 0.0001	Loss 1.9268 (1.8598)	Prec@1 38.281 (34.425)	
Epoch: [4][155/391]	LR: 0.0001	Loss 1.5029 (1.8693)	Prec@1 42.969 (33.929)	
Epoch: [4][233/391]	LR: 0.0001	Loss 1.8379 (1.8575)	Prec@1 35.156 (34.235)	
Epoch: [4][311/391]	LR: 0.0001	Loss 2.0547 (1.8609)	Prec@1 28.125 (34.072)	
Epoch: [4][389/391]	LR: 0.0001	Loss 1.9805 (1.8548)	Prec@1 27.344 (34.165)	
Total train loss: 1.8548

Train time: 16.928704738616943
 * Prec@1 75.050 Prec@5 97.390 Loss 1.5049
Best acc: 75.050
--------------------------------------------------------------------------------
Test time: 18.78006863594055

Epoch: [5][77/391]	LR: 0.0001	Loss 1.8242 (1.8162)	Prec@1 29.688 (35.276)	
Epoch: [5][155/391]	LR: 0.0001	Loss 1.6709 (1.8195)	Prec@1 39.844 (34.956)	
Epoch: [5][233/391]	LR: 0.0001	Loss 1.5391 (1.8113)	Prec@1 41.406 (34.862)	
Epoch: [5][311/391]	LR: 0.0001	Loss 2.0957 (1.8274)	Prec@1 35.156 (34.605)	
Epoch: [5][389/391]	LR: 0.0001	Loss 1.6982 (1.8316)	Prec@1 34.375 (34.389)	
Total train loss: 1.8317

Train time: 17.737815141677856
 * Prec@1 76.320 Prec@5 97.320 Loss 1.4014
Best acc: 76.320
--------------------------------------------------------------------------------
Test time: 20.015363454818726

Epoch: [6][77/391]	LR: 0.0001	Loss 2.2637 (1.8323)	Prec@1 28.125 (34.295)	
Epoch: [6][155/391]	LR: 0.0001	Loss 1.6318 (1.8184)	Prec@1 36.719 (34.891)	
Epoch: [6][233/391]	LR: 0.0001	Loss 1.7051 (1.8291)	Prec@1 39.844 (34.699)	
Epoch: [6][311/391]	LR: 0.0001	Loss 1.8447 (1.8139)	Prec@1 32.812 (34.873)	
Epoch: [6][389/391]	LR: 0.0001	Loss 1.9424 (1.8118)	Prec@1 31.250 (34.858)	
Total train loss: 1.8112

Train time: 16.485361099243164
 * Prec@1 77.880 Prec@5 97.830 Loss 1.2598
Best acc: 77.880
--------------------------------------------------------------------------------
Test time: 18.76058340072632

Epoch: [7][77/391]	LR: 0.0001	Loss 1.6748 (1.8288)	Prec@1 38.281 (33.804)	
Epoch: [7][155/391]	LR: 0.0001	Loss 1.8887 (1.8100)	Prec@1 32.812 (34.340)	
Epoch: [7][233/391]	LR: 0.0001	Loss 1.6455 (1.8005)	Prec@1 38.281 (34.736)	
Epoch: [7][311/391]	LR: 0.0001	Loss 1.6562 (1.7937)	Prec@1 36.719 (34.898)	
Epoch: [7][389/391]	LR: 0.0001	Loss 1.8525 (1.7903)	Prec@1 35.938 (34.980)	
Total train loss: 1.7905

Train time: 16.16293168067932
 * Prec@1 78.340 Prec@5 97.840 Loss 1.2354
Best acc: 78.340
--------------------------------------------------------------------------------
Test time: 18.46050214767456

Epoch: [8][77/391]	LR: 0.0001	Loss 1.4238 (1.7585)	Prec@1 43.750 (35.246)	
Epoch: [8][155/391]	LR: 0.0001	Loss 1.7412 (1.7751)	Prec@1 35.938 (35.311)	
Epoch: [8][233/391]	LR: 0.0001	Loss 1.7480 (1.7834)	Prec@1 33.594 (35.046)	
Epoch: [8][311/391]	LR: 0.0001	Loss 2.0273 (1.7783)	Prec@1 31.250 (35.191)	
Epoch: [8][389/391]	LR: 0.0001	Loss 1.6611 (1.7779)	Prec@1 37.500 (35.264)	
Total train loss: 1.7777

Train time: 16.642720460891724
 * Prec@1 78.410 Prec@5 97.850 Loss 1.2549
Best acc: 78.410
--------------------------------------------------------------------------------
Test time: 18.483068704605103

Epoch: [9][77/391]	LR: 0.0001	Loss 1.6387 (1.7641)	Prec@1 40.625 (34.916)	
Epoch: [9][155/391]	LR: 0.0001	Loss 1.7900 (1.7525)	Prec@1 30.469 (35.266)	
Epoch: [9][233/391]	LR: 0.0001	Loss 1.8740 (1.7546)	Prec@1 34.375 (35.383)	
Epoch: [9][311/391]	LR: 0.0001	Loss 1.4004 (1.7518)	Prec@1 44.531 (35.527)	
Epoch: [9][389/391]	LR: 0.0001	Loss 1.4951 (1.7569)	Prec@1 42.969 (35.393)	
Total train loss: 1.7572

Train time: 17.0209379196167
 * Prec@1 79.750 Prec@5 98.120 Loss 1.1426
Best acc: 79.750
--------------------------------------------------------------------------------
Test time: 19.69288659095764

Epoch: [10][77/391]	LR: 0.0001	Loss 1.8555 (1.7590)	Prec@1 36.719 (35.497)	
Epoch: [10][155/391]	LR: 0.0001	Loss 1.9092 (1.7674)	Prec@1 30.469 (35.347)	
Epoch: [10][233/391]	LR: 0.0001	Loss 1.8691 (1.7728)	Prec@1 28.906 (35.176)	
Epoch: [10][311/391]	LR: 0.0001	Loss 1.8213 (1.7605)	Prec@1 34.375 (35.377)	
Epoch: [10][389/391]	LR: 0.0001	Loss 1.6572 (1.7569)	Prec@1 36.719 (35.475)	
Total train loss: 1.7566

Train time: 16.244473934173584
 * Prec@1 80.180 Prec@5 98.170 Loss 1.1006
Best acc: 80.180
--------------------------------------------------------------------------------
Test time: 18.252315998077393

Epoch: [11][77/391]	LR: 0.0001	Loss 2.2793 (1.7461)	Prec@1 30.469 (35.387)	
Epoch: [11][155/391]	LR: 0.0001	Loss 1.7451 (1.7431)	Prec@1 32.031 (35.271)	
Epoch: [11][233/391]	LR: 0.0001	Loss 1.5684 (1.7484)	Prec@1 40.625 (35.337)	
Epoch: [11][311/391]	LR: 0.0001	Loss 1.7363 (1.7503)	Prec@1 34.375 (35.397)	
Epoch: [11][389/391]	LR: 0.0001	Loss 1.7520 (1.7473)	Prec@1 33.594 (35.559)	
Total train loss: 1.7477

Train time: 18.050332069396973
 * Prec@1 79.560 Prec@5 98.230 Loss 1.1172
Best acc: 80.180
--------------------------------------------------------------------------------
Test time: 20.24449324607849

Epoch: [12][77/391]	LR: 0.0001	Loss 1.6426 (1.7180)	Prec@1 42.188 (35.837)	
Epoch: [12][155/391]	LR: 0.0001	Loss 1.7471 (1.7397)	Prec@1 39.062 (35.417)	
Epoch: [12][233/391]	LR: 0.0001	Loss 1.9062 (1.7342)	Prec@1 30.469 (35.604)	
Epoch: [12][311/391]	LR: 0.0001	Loss 1.4854 (1.7338)	Prec@1 44.531 (35.614)	
Epoch: [12][389/391]	LR: 0.0001	Loss 2.0195 (1.7331)	Prec@1 25.781 (35.557)	
Total train loss: 1.7329

Train time: 18.238442182540894
 * Prec@1 78.770 Prec@5 97.990 Loss 1.2266
Best acc: 80.180
--------------------------------------------------------------------------------
Test time: 20.618225812911987

Epoch: [13][77/391]	LR: 0.0001	Loss 1.7783 (1.7307)	Prec@1 34.375 (35.867)	
Epoch: [13][155/391]	LR: 0.0001	Loss 1.7256 (1.7285)	Prec@1 37.500 (35.948)	
Epoch: [13][233/391]	LR: 0.0001	Loss 1.7012 (1.7313)	Prec@1 40.625 (35.984)	
Epoch: [13][311/391]	LR: 0.0001	Loss 1.7568 (1.7304)	Prec@1 34.375 (35.907)	
Epoch: [13][389/391]	LR: 0.0001	Loss 1.7441 (1.7287)	Prec@1 34.375 (35.998)	
Total train loss: 1.7287

Train time: 17.42134928703308
 * Prec@1 80.200 Prec@5 98.180 Loss 1.0889
Best acc: 80.200
--------------------------------------------------------------------------------
Test time: 19.652907848358154

Epoch: [14][77/391]	LR: 0.0001	Loss 1.6963 (1.7200)	Prec@1 39.062 (36.599)	
Epoch: [14][155/391]	LR: 0.0001	Loss 1.5566 (1.7246)	Prec@1 41.406 (36.043)	
Epoch: [14][233/391]	LR: 0.0001	Loss 1.6689 (1.7248)	Prec@1 31.250 (36.131)	
Epoch: [14][311/391]	LR: 0.0001	Loss 1.7354 (1.7286)	Prec@1 37.500 (35.902)	
Epoch: [14][389/391]	LR: 0.0001	Loss 1.5869 (1.7278)	Prec@1 42.188 (35.865)	
Total train loss: 1.7281

Train time: 16.701091051101685
 * Prec@1 80.530 Prec@5 98.150 Loss 1.1133
Best acc: 80.530
--------------------------------------------------------------------------------
Test time: 18.631208419799805

Epoch: [15][77/391]	LR: 0.0001	Loss 1.7686 (1.6862)	Prec@1 35.156 (36.929)	
Epoch: [15][155/391]	LR: 0.0001	Loss 1.5918 (1.7154)	Prec@1 37.500 (36.013)	
Epoch: [15][233/391]	LR: 0.0001	Loss 2.2441 (1.7105)	Prec@1 28.906 (36.238)	
Epoch: [15][311/391]	LR: 0.0001	Loss 1.9336 (1.7148)	Prec@1 30.469 (36.063)	
Epoch: [15][389/391]	LR: 0.0001	Loss 1.8115 (1.7170)	Prec@1 33.594 (36.132)	
Total train loss: 1.7168

Train time: 16.238636255264282
 * Prec@1 80.870 Prec@5 98.180 Loss 1.0664
Best acc: 80.870
--------------------------------------------------------------------------------
Test time: 18.94007706642151

Epoch: [16][77/391]	LR: 0.0001	Loss 1.5371 (1.7256)	Prec@1 38.281 (35.998)	
Epoch: [16][155/391]	LR: 0.0001	Loss 2.0273 (1.7223)	Prec@1 27.344 (36.118)	
Epoch: [16][233/391]	LR: 0.0001	Loss 1.7842 (1.7215)	Prec@1 34.375 (36.108)	
Epoch: [16][311/391]	LR: 0.0001	Loss 1.7236 (1.7157)	Prec@1 31.250 (36.243)	
Epoch: [16][389/391]	LR: 0.0001	Loss 1.6230 (1.7124)	Prec@1 35.156 (36.262)	
Total train loss: 1.7123

Train time: 16.2891788482666
 * Prec@1 81.830 Prec@5 98.380 Loss 0.9712
Best acc: 81.830
--------------------------------------------------------------------------------
Test time: 18.197927236557007

Epoch: [17][77/391]	LR: 0.0001	Loss 1.6279 (1.7194)	Prec@1 38.281 (36.218)	
Epoch: [17][155/391]	LR: 0.0001	Loss 1.7080 (1.7058)	Prec@1 38.281 (36.589)	
Epoch: [17][233/391]	LR: 0.0001	Loss 1.5156 (1.7079)	Prec@1 40.625 (36.198)	
Epoch: [17][311/391]	LR: 0.0001	Loss 1.5977 (1.6994)	Prec@1 36.719 (36.476)	
Epoch: [17][389/391]	LR: 0.0001	Loss 1.6377 (1.7065)	Prec@1 39.844 (36.288)	
Total train loss: 1.7067

Train time: 15.920702457427979
 * Prec@1 80.980 Prec@5 98.420 Loss 1.0322
Best acc: 81.830
--------------------------------------------------------------------------------
Test time: 18.155914783477783

Epoch: [18][77/391]	LR: 0.0001	Loss 1.7432 (1.6953)	Prec@1 35.156 (36.268)	
Epoch: [18][155/391]	LR: 0.0001	Loss 1.6162 (1.6988)	Prec@1 42.969 (36.393)	
Epoch: [18][233/391]	LR: 0.0001	Loss 1.6914 (1.7111)	Prec@1 39.062 (36.024)	
Epoch: [18][311/391]	LR: 0.0001	Loss 1.5127 (1.7072)	Prec@1 39.844 (36.145)	
Epoch: [18][389/391]	LR: 0.0001	Loss 1.6602 (1.7010)	Prec@1 34.375 (36.276)	
Total train loss: 1.7012

Train time: 17.70231008529663
 * Prec@1 81.610 Prec@5 98.480 Loss 1.0088
Best acc: 81.830
--------------------------------------------------------------------------------
Test time: 19.94422745704651

Epoch: [19][77/391]	LR: 0.0001	Loss 1.7783 (1.7082)	Prec@1 35.156 (36.108)	
Epoch: [19][155/391]	LR: 0.0001	Loss 1.6201 (1.7018)	Prec@1 39.062 (36.193)	
Epoch: [19][233/391]	LR: 0.0001	Loss 1.7949 (1.7034)	Prec@1 28.906 (36.225)	
Epoch: [19][311/391]	LR: 0.0001	Loss 1.4639 (1.6988)	Prec@1 43.750 (36.308)	
Epoch: [19][389/391]	LR: 0.0001	Loss 1.4961 (1.6972)	Prec@1 44.531 (36.288)	
Total train loss: 1.6976

Train time: 17.20754861831665
 * Prec@1 82.510 Prec@5 98.580 Loss 0.9312
Best acc: 82.510
--------------------------------------------------------------------------------
Test time: 19.573455095291138

Epoch: [20][77/391]	LR: 1e-05	Loss 1.6846 (1.7182)	Prec@1 38.281 (35.927)	
Epoch: [20][155/391]	LR: 1e-05	Loss 1.7549 (1.7026)	Prec@1 33.594 (36.413)	
Epoch: [20][233/391]	LR: 1e-05	Loss 1.6270 (1.6959)	Prec@1 45.312 (36.535)	
Epoch: [20][311/391]	LR: 1e-05	Loss 1.8867 (1.6919)	Prec@1 31.250 (36.571)	
Epoch: [20][389/391]	LR: 1e-05	Loss 1.9062 (1.6903)	Prec@1 28.125 (36.777)	
Total train loss: 1.6910

Train time: 17.356319427490234
 * Prec@1 81.150 Prec@5 98.430 Loss 1.0088
Best acc: 82.510
--------------------------------------------------------------------------------
Test time: 19.425850868225098

Epoch: [21][77/391]	LR: 1e-05	Loss 1.6934 (1.6793)	Prec@1 30.469 (36.949)	
Epoch: [21][155/391]	LR: 1e-05	Loss 1.7520 (1.6954)	Prec@1 35.938 (36.493)	
Epoch: [21][233/391]	LR: 1e-05	Loss 1.5137 (1.6993)	Prec@1 43.750 (36.398)	
Epoch: [21][311/391]	LR: 1e-05	Loss 1.8428 (1.6940)	Prec@1 35.156 (36.556)	
Epoch: [21][389/391]	LR: 1e-05	Loss 1.7012 (1.7000)	Prec@1 36.719 (36.358)	
Total train loss: 1.6997

Train time: 15.885173320770264
 * Prec@1 81.510 Prec@5 98.460 Loss 1.0000
Best acc: 82.510
--------------------------------------------------------------------------------
Test time: 18.696070194244385

Epoch: [22][77/391]	LR: 1e-05	Loss 1.6875 (1.6909)	Prec@1 33.594 (36.589)	
Epoch: [22][155/391]	LR: 1e-05	Loss 1.6006 (1.6987)	Prec@1 36.719 (36.203)	
Epoch: [22][233/391]	LR: 1e-05	Loss 1.3398 (1.6912)	Prec@1 51.562 (36.428)	
Epoch: [22][311/391]	LR: 1e-05	Loss 1.9678 (1.6959)	Prec@1 28.906 (36.276)	
Epoch: [22][389/391]	LR: 1e-05	Loss 1.5322 (1.6927)	Prec@1 42.969 (36.446)	
Total train loss: 1.6931

Train time: 16.938504934310913
 * Prec@1 81.270 Prec@5 98.420 Loss 1.0059
Best acc: 82.510
--------------------------------------------------------------------------------
Test time: 18.866373777389526

Epoch: [23][77/391]	LR: 1e-05	Loss 1.7549 (1.6843)	Prec@1 35.156 (36.899)	
Epoch: [23][155/391]	LR: 1e-05	Loss 1.5674 (1.6957)	Prec@1 40.625 (36.253)	
Epoch: [23][233/391]	LR: 1e-05	Loss 1.5938 (1.7011)	Prec@1 42.188 (36.124)	
Epoch: [23][311/391]	LR: 1e-05	Loss 1.6182 (1.7009)	Prec@1 45.312 (36.128)	
Epoch: [23][389/391]	LR: 1e-05	Loss 1.6650 (1.6942)	Prec@1 34.375 (36.430)	
Total train loss: 1.6944

Train time: 16.97097373008728
 * Prec@1 82.330 Prec@5 98.570 Loss 0.9282
Best acc: 82.510
--------------------------------------------------------------------------------
Test time: 19.353372812271118

Epoch: [24][77/391]	LR: 1e-05	Loss 1.5869 (1.6890)	Prec@1 44.531 (36.098)	
Epoch: [24][155/391]	LR: 1e-05	Loss 1.6738 (1.6906)	Prec@1 34.375 (36.433)	
Epoch: [24][233/391]	LR: 1e-05	Loss 1.7920 (1.6958)	Prec@1 32.812 (36.445)	
Epoch: [24][311/391]	LR: 1e-05	Loss 1.7891 (1.6895)	Prec@1 35.938 (36.726)	
Epoch: [24][389/391]	LR: 1e-05	Loss 1.5205 (1.6936)	Prec@1 43.750 (36.611)	
Total train loss: 1.6933

Train time: 16.9999258518219
 * Prec@1 81.860 Prec@5 98.560 Loss 0.9590
Best acc: 82.510
--------------------------------------------------------------------------------
Test time: 19.38683319091797


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.0001
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 5
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.510 Prec@5 99.650 Loss 0.3188
Pre-trained Prec@1 with 5 layers frozen: 91.50999450683594 	 Loss: 0.31884765625

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.0001	Loss 2.6523 (2.7345)	Prec@1 24.219 (26.573)	
Epoch: [0][155/391]	LR: 0.0001	Loss 2.2578 (2.5918)	Prec@1 27.344 (27.544)	
Epoch: [0][233/391]	LR: 0.0001	Loss 2.4121 (2.4782)	Prec@1 21.094 (28.259)	
Epoch: [0][311/391]	LR: 0.0001	Loss 2.0273 (2.3961)	Prec@1 32.031 (29.132)	
Epoch: [0][389/391]	LR: 0.0001	Loss 2.1992 (2.3575)	Prec@1 28.906 (29.303)	
Total train loss: 2.3573

Train time: 78.07144975662231
 * Prec@1 67.240 Prec@5 94.940 Loss 2.1992
Best acc: 67.240
--------------------------------------------------------------------------------
Test time: 81.2563807964325

Epoch: [1][77/391]	LR: 0.0001	Loss 2.1270 (2.0954)	Prec@1 32.031 (31.651)	
Epoch: [1][155/391]	LR: 0.0001	Loss 1.9971 (2.0692)	Prec@1 38.281 (32.056)	
Epoch: [1][233/391]	LR: 0.0001	Loss 1.7510 (2.0526)	Prec@1 36.719 (32.348)	
Epoch: [1][311/391]	LR: 0.0001	Loss 2.0625 (2.0464)	Prec@1 31.250 (32.307)	
Epoch: [1][389/391]	LR: 0.0001	Loss 2.3301 (2.0364)	Prec@1 27.344 (32.386)	
Total train loss: 2.0358

Train time: 14.847432136535645
 * Prec@1 71.600 Prec@5 96.270 Loss 1.7324
Best acc: 71.600
--------------------------------------------------------------------------------
Test time: 17.1123526096344

Epoch: [2][77/391]	LR: 0.0001	Loss 1.9756 (1.8970)	Prec@1 32.031 (34.565)	
Epoch: [2][155/391]	LR: 0.0001	Loss 1.8115 (1.9302)	Prec@1 35.938 (33.669)	
Epoch: [2][233/391]	LR: 0.0001	Loss 2.0488 (1.9369)	Prec@1 30.469 (33.350)	
Epoch: [2][311/391]	LR: 0.0001	Loss 2.0176 (1.9402)	Prec@1 34.375 (33.253)	
Epoch: [2][389/391]	LR: 0.0001	Loss 2.0566 (1.9337)	Prec@1 29.688 (33.203)	
Total train loss: 1.9336

Train time: 15.30629301071167
 * Prec@1 74.970 Prec@5 97.050 Loss 1.5146
Best acc: 74.970
--------------------------------------------------------------------------------
Test time: 17.219993591308594

Epoch: [3][77/391]	LR: 0.0001	Loss 2.2285 (1.8859)	Prec@1 29.688 (33.704)	
Epoch: [3][155/391]	LR: 0.0001	Loss 1.4658 (1.8946)	Prec@1 48.438 (33.619)	
Epoch: [3][233/391]	LR: 0.0001	Loss 1.7949 (1.8833)	Prec@1 41.406 (33.884)	
Epoch: [3][311/391]	LR: 0.0001	Loss 1.8594 (1.8844)	Prec@1 33.594 (33.909)	
Epoch: [3][389/391]	LR: 0.0001	Loss 1.9531 (1.8803)	Prec@1 30.469 (33.882)	
Total train loss: 1.8806

Train time: 15.276604890823364
 * Prec@1 76.260 Prec@5 97.540 Loss 1.4141
Best acc: 76.260
--------------------------------------------------------------------------------
Test time: 17.509629487991333

Epoch: [4][77/391]	LR: 0.0001	Loss 1.8301 (1.8704)	Prec@1 36.719 (34.305)	
Epoch: [4][155/391]	LR: 0.0001	Loss 1.7793 (1.8548)	Prec@1 34.375 (34.145)	
Epoch: [4][233/391]	LR: 0.0001	Loss 2.1270 (1.8481)	Prec@1 26.562 (34.372)	
Epoch: [4][311/391]	LR: 0.0001	Loss 2.4434 (1.8464)	Prec@1 25.781 (34.433)	
Epoch: [4][389/391]	LR: 0.0001	Loss 1.9180 (1.8416)	Prec@1 37.500 (34.469)	
Total train loss: 1.8421

Train time: 15.78507685661316
 * Prec@1 77.400 Prec@5 97.840 Loss 1.3125
Best acc: 77.400
--------------------------------------------------------------------------------
Test time: 18.030200958251953

Epoch: [5][77/391]	LR: 0.0001	Loss 1.8242 (1.8104)	Prec@1 32.812 (35.086)	
Epoch: [5][155/391]	LR: 0.0001	Loss 1.6836 (1.8210)	Prec@1 40.625 (34.445)	
Epoch: [5][233/391]	LR: 0.0001	Loss 1.8350 (1.8177)	Prec@1 37.500 (34.742)	
Epoch: [5][311/391]	LR: 0.0001	Loss 1.5225 (1.8150)	Prec@1 39.062 (34.711)	
Epoch: [5][389/391]	LR: 0.0001	Loss 1.7783 (1.8098)	Prec@1 33.594 (34.816)	
Total train loss: 1.8099

Train time: 16.135440349578857
 * Prec@1 78.470 Prec@5 98.070 Loss 1.2461
Best acc: 78.470
--------------------------------------------------------------------------------
Test time: 18.368507623672485

Epoch: [6][77/391]	LR: 0.0001	Loss 2.0195 (1.7931)	Prec@1 24.219 (34.886)	
Epoch: [6][155/391]	LR: 0.0001	Loss 1.5947 (1.7851)	Prec@1 39.062 (35.322)	
Epoch: [6][233/391]	LR: 0.0001	Loss 1.9199 (1.7821)	Prec@1 28.906 (35.220)	
Epoch: [6][311/391]	LR: 0.0001	Loss 1.9385 (1.7870)	Prec@1 28.125 (35.161)	
Epoch: [6][389/391]	LR: 0.0001	Loss 1.8135 (1.7876)	Prec@1 32.812 (35.062)	
Total train loss: 1.7871

Train time: 15.69472050666809
 * Prec@1 79.850 Prec@5 98.290 Loss 1.1006
Best acc: 79.850
--------------------------------------------------------------------------------
Test time: 17.59207510948181

Epoch: [7][77/391]	LR: 0.0001	Loss 1.7012 (1.7895)	Prec@1 30.469 (34.595)	
Epoch: [7][155/391]	LR: 0.0001	Loss 1.8232 (1.7603)	Prec@1 35.938 (35.547)	
Epoch: [7][233/391]	LR: 0.0001	Loss 1.8438 (1.7602)	Prec@1 33.594 (35.520)	
Epoch: [7][311/391]	LR: 0.0001	Loss 1.9717 (1.7655)	Prec@1 30.469 (35.544)	
Epoch: [7][389/391]	LR: 0.0001	Loss 1.7676 (1.7688)	Prec@1 32.031 (35.417)	
Total train loss: 1.7688

Train time: 16.19737672805786
 * Prec@1 79.580 Prec@5 98.190 Loss 1.1553
Best acc: 79.850
--------------------------------------------------------------------------------
Test time: 18.51113772392273

Epoch: [8][77/391]	LR: 0.0001	Loss 1.8545 (1.7519)	Prec@1 26.562 (35.587)	
Epoch: [8][155/391]	LR: 0.0001	Loss 1.8711 (1.7450)	Prec@1 32.812 (35.827)	
Epoch: [8][233/391]	LR: 0.0001	Loss 1.6025 (1.7511)	Prec@1 39.062 (35.687)	
Epoch: [8][311/391]	LR: 0.0001	Loss 1.7441 (1.7529)	Prec@1 34.375 (35.612)	
Epoch: [8][389/391]	LR: 0.0001	Loss 1.9473 (1.7525)	Prec@1 28.906 (35.741)	
Total train loss: 1.7518

Train time: 15.17084789276123
 * Prec@1 81.140 Prec@5 98.510 Loss 1.0234
Best acc: 81.140
--------------------------------------------------------------------------------
Test time: 17.461966037750244

Epoch: [9][77/391]	LR: 0.0001	Loss 1.4678 (1.7398)	Prec@1 41.406 (36.198)	
Epoch: [9][155/391]	LR: 0.0001	Loss 1.6396 (1.7278)	Prec@1 38.281 (35.993)	
Epoch: [9][233/391]	LR: 0.0001	Loss 1.8086 (1.7325)	Prec@1 28.906 (35.771)	
Epoch: [9][311/391]	LR: 0.0001	Loss 2.0059 (1.7402)	Prec@1 32.031 (35.727)	
Epoch: [9][389/391]	LR: 0.0001	Loss 1.8096 (1.7384)	Prec@1 36.719 (35.831)	
Total train loss: 1.7386

Train time: 16.788541555404663
 * Prec@1 80.430 Prec@5 98.240 Loss 1.1133
Best acc: 81.140
--------------------------------------------------------------------------------
Test time: 19.127521514892578

Epoch: [10][77/391]	LR: 0.0001	Loss 1.6758 (1.7274)	Prec@1 35.938 (36.098)	
Epoch: [10][155/391]	LR: 0.0001	Loss 1.9658 (1.7352)	Prec@1 28.906 (35.927)	
Epoch: [10][233/391]	LR: 0.0001	Loss 1.6758 (1.7284)	Prec@1 34.375 (36.021)	
Epoch: [10][311/391]	LR: 0.0001	Loss 1.8672 (1.7287)	Prec@1 30.469 (35.907)	
Epoch: [10][389/391]	LR: 0.0001	Loss 1.5840 (1.7340)	Prec@1 37.500 (35.763)	
Total train loss: 1.7347

Train time: 14.91996169090271
 * Prec@1 80.450 Prec@5 98.390 Loss 1.1113
Best acc: 81.140
--------------------------------------------------------------------------------
Test time: 16.867490530014038

Epoch: [11][77/391]	LR: 0.0001	Loss 1.5234 (1.7239)	Prec@1 39.844 (36.018)	
Epoch: [11][155/391]	LR: 0.0001	Loss 1.6836 (1.7211)	Prec@1 38.281 (36.128)	
Epoch: [11][233/391]	LR: 0.0001	Loss 1.5322 (1.7239)	Prec@1 42.188 (36.031)	
Epoch: [11][311/391]	LR: 0.0001	Loss 1.8936 (1.7275)	Prec@1 34.375 (35.885)	
Epoch: [11][389/391]	LR: 0.0001	Loss 1.6396 (1.7250)	Prec@1 35.156 (35.986)	
Total train loss: 1.7249

Train time: 15.315351486206055
 * Prec@1 81.490 Prec@5 98.560 Loss 1.0186
Best acc: 81.490
--------------------------------------------------------------------------------
Test time: 17.5800199508667

Epoch: [12][77/391]	LR: 0.0001	Loss 1.7451 (1.7124)	Prec@1 36.719 (36.589)	
Epoch: [12][155/391]	LR: 0.0001	Loss 1.9590 (1.7192)	Prec@1 28.906 (36.243)	
Epoch: [12][233/391]	LR: 0.0001	Loss 1.6230 (1.7146)	Prec@1 39.062 (36.341)	
Epoch: [12][311/391]	LR: 0.0001	Loss 1.6816 (1.7138)	Prec@1 35.938 (36.446)	
Epoch: [12][389/391]	LR: 0.0001	Loss 1.7529 (1.7173)	Prec@1 32.031 (36.322)	
Total train loss: 1.7174

Train time: 15.678646326065063
 * Prec@1 80.700 Prec@5 98.440 Loss 1.1006
Best acc: 81.490
--------------------------------------------------------------------------------
Test time: 18.070478677749634

Epoch: [13][77/391]	LR: 0.0001	Loss 1.6270 (1.6997)	Prec@1 39.062 (36.869)	
Epoch: [13][155/391]	LR: 0.0001	Loss 1.7275 (1.7188)	Prec@1 37.500 (35.782)	
Epoch: [13][233/391]	LR: 0.0001	Loss 1.7891 (1.7191)	Prec@1 35.156 (35.877)	
Epoch: [13][311/391]	LR: 0.0001	Loss 2.0117 (1.7140)	Prec@1 30.469 (36.083)	
Epoch: [13][389/391]	LR: 0.0001	Loss 1.8418 (1.7143)	Prec@1 35.156 (36.108)	
Total train loss: 1.7145

Train time: 15.016395807266235
 * Prec@1 81.750 Prec@5 98.520 Loss 1.0068
Best acc: 81.750
--------------------------------------------------------------------------------
Test time: 17.246349573135376

Epoch: [14][77/391]	LR: 0.0001	Loss 1.6660 (1.7416)	Prec@1 30.469 (35.357)	
Epoch: [14][155/391]	LR: 0.0001	Loss 1.8311 (1.7212)	Prec@1 30.469 (36.068)	
Epoch: [14][233/391]	LR: 0.0001	Loss 1.5596 (1.7028)	Prec@1 38.281 (36.438)	
Epoch: [14][311/391]	LR: 0.0001	Loss 1.5820 (1.7060)	Prec@1 37.500 (36.341)	
Epoch: [14][389/391]	LR: 0.0001	Loss 1.7021 (1.7065)	Prec@1 40.625 (36.256)	
Total train loss: 1.7068

Train time: 15.89280104637146
 * Prec@1 81.270 Prec@5 98.470 Loss 1.0732
Best acc: 81.750
--------------------------------------------------------------------------------
Test time: 17.816298961639404

Epoch: [15][77/391]	LR: 0.0001	Loss 1.4922 (1.6864)	Prec@1 41.406 (36.609)	
Epoch: [15][155/391]	LR: 0.0001	Loss 1.7363 (1.6980)	Prec@1 35.156 (36.433)	
Epoch: [15][233/391]	LR: 0.0001	Loss 1.6230 (1.7044)	Prec@1 38.281 (36.255)	
Epoch: [15][311/391]	LR: 0.0001	Loss 1.9980 (1.7034)	Prec@1 25.781 (36.341)	
Epoch: [15][389/391]	LR: 0.0001	Loss 1.5830 (1.7046)	Prec@1 42.188 (36.306)	
Total train loss: 1.7042

Train time: 15.975945472717285
 * Prec@1 82.330 Prec@5 98.620 Loss 0.9697
Best acc: 82.330
--------------------------------------------------------------------------------
Test time: 18.309457540512085

Epoch: [16][77/391]	LR: 0.0001	Loss 1.6143 (1.6900)	Prec@1 35.156 (36.478)	
Epoch: [16][155/391]	LR: 0.0001	Loss 1.7939 (1.6890)	Prec@1 33.594 (36.614)	
Epoch: [16][233/391]	LR: 0.0001	Loss 1.5879 (1.6975)	Prec@1 38.281 (36.482)	
Epoch: [16][311/391]	LR: 0.0001	Loss 1.6562 (1.6952)	Prec@1 42.188 (36.609)	
Epoch: [16][389/391]	LR: 0.0001	Loss 1.6895 (1.7000)	Prec@1 34.375 (36.492)	
Total train loss: 1.7004

Train time: 15.711101531982422
 * Prec@1 82.530 Prec@5 98.510 Loss 0.9502
Best acc: 82.530
--------------------------------------------------------------------------------
Test time: 18.020824670791626

Epoch: [17][77/391]	LR: 0.0001	Loss 1.7178 (1.6919)	Prec@1 37.500 (36.098)	
Epoch: [17][155/391]	LR: 0.0001	Loss 1.5977 (1.6950)	Prec@1 40.625 (36.108)	
Epoch: [17][233/391]	LR: 0.0001	Loss 1.7998 (1.6960)	Prec@1 32.812 (36.271)	
Epoch: [17][311/391]	LR: 0.0001	Loss 1.7314 (1.6956)	Prec@1 41.406 (36.341)	
Epoch: [17][389/391]	LR: 0.0001	Loss 1.6426 (1.6926)	Prec@1 37.500 (36.448)	
Total train loss: 1.6921

Train time: 15.672006368637085
 * Prec@1 82.670 Prec@5 98.770 Loss 0.9087
Best acc: 82.670
--------------------------------------------------------------------------------
Test time: 17.968042850494385

Epoch: [18][77/391]	LR: 0.0001	Loss 1.5811 (1.6685)	Prec@1 37.500 (37.740)	
Epoch: [18][155/391]	LR: 0.0001	Loss 1.6572 (1.6857)	Prec@1 36.719 (36.884)	
Epoch: [18][233/391]	LR: 0.0001	Loss 1.9014 (1.6874)	Prec@1 28.125 (36.772)	
Epoch: [18][311/391]	LR: 0.0001	Loss 1.5625 (1.6861)	Prec@1 42.969 (36.784)	
Epoch: [18][389/391]	LR: 0.0001	Loss 1.6406 (1.6858)	Prec@1 42.188 (36.789)	
Total train loss: 1.6855

Train time: 16.590672492980957
 * Prec@1 82.730 Prec@5 98.630 Loss 0.9497
Best acc: 82.730
--------------------------------------------------------------------------------
Test time: 18.467545747756958

Epoch: [19][77/391]	LR: 0.0001	Loss 1.6201 (1.6873)	Prec@1 35.938 (36.759)	
Epoch: [19][155/391]	LR: 0.0001	Loss 1.4199 (1.6850)	Prec@1 44.531 (36.729)	
Epoch: [19][233/391]	LR: 0.0001	Loss 1.9180 (1.6813)	Prec@1 29.688 (36.942)	
Epoch: [19][311/391]	LR: 0.0001	Loss 1.7695 (1.6821)	Prec@1 34.375 (36.892)	
Epoch: [19][389/391]	LR: 0.0001	Loss 1.9092 (1.6840)	Prec@1 35.938 (36.835)	
Total train loss: 1.6840

Train time: 16.181668043136597
 * Prec@1 82.110 Prec@5 98.610 Loss 0.9810
Best acc: 82.730
--------------------------------------------------------------------------------
Test time: 18.441080808639526

Epoch: [20][77/391]	LR: 1e-05	Loss 1.6953 (1.6724)	Prec@1 34.375 (37.260)	
Epoch: [20][155/391]	LR: 1e-05	Loss 1.5742 (1.6864)	Prec@1 36.719 (36.709)	
Epoch: [20][233/391]	LR: 1e-05	Loss 1.7090 (1.6838)	Prec@1 38.281 (36.715)	
Epoch: [20][311/391]	LR: 1e-05	Loss 1.8516 (1.6825)	Prec@1 33.594 (36.744)	
Epoch: [20][389/391]	LR: 1e-05	Loss 1.6709 (1.6821)	Prec@1 37.500 (36.759)	
Total train loss: 1.6820

Train time: 16.367091178894043
 * Prec@1 82.550 Prec@5 98.630 Loss 0.9463
Best acc: 82.730
--------------------------------------------------------------------------------
Test time: 18.645416498184204

Epoch: [21][77/391]	LR: 1e-05	Loss 1.3594 (1.6744)	Prec@1 46.875 (37.139)	
Epoch: [21][155/391]	LR: 1e-05	Loss 1.6250 (1.6803)	Prec@1 40.625 (36.689)	
Epoch: [21][233/391]	LR: 1e-05	Loss 1.7637 (1.6758)	Prec@1 34.375 (36.796)	
Epoch: [21][311/391]	LR: 1e-05	Loss 2.2812 (1.6747)	Prec@1 22.656 (36.801)	
Epoch: [21][389/391]	LR: 1e-05	Loss 1.8398 (1.6795)	Prec@1 32.812 (36.546)	
Total train loss: 1.6799

Train time: 16.623624086380005
 * Prec@1 81.830 Prec@5 98.510 Loss 1.0059
Best acc: 82.730
--------------------------------------------------------------------------------
Test time: 18.90359926223755

Epoch: [22][77/391]	LR: 1e-05	Loss 1.5215 (1.6754)	Prec@1 42.969 (37.099)	
Epoch: [22][155/391]	LR: 1e-05	Loss 1.5967 (1.6917)	Prec@1 38.281 (36.533)	
Epoch: [22][233/391]	LR: 1e-05	Loss 1.8770 (1.6845)	Prec@1 28.125 (36.572)	
Epoch: [22][311/391]	LR: 1e-05	Loss 1.6328 (1.6835)	Prec@1 39.062 (36.564)	
Epoch: [22][389/391]	LR: 1e-05	Loss 1.6836 (1.6796)	Prec@1 36.719 (36.785)	
Total train loss: 1.6796

Train time: 14.537535429000854
 * Prec@1 83.250 Prec@5 98.810 Loss 0.8887
Best acc: 83.250
--------------------------------------------------------------------------------
Test time: 16.39712691307068

Epoch: [23][77/391]	LR: 1e-05	Loss 1.3906 (1.6500)	Prec@1 43.750 (38.241)	
Epoch: [23][155/391]	LR: 1e-05	Loss 1.9678 (1.6722)	Prec@1 31.250 (37.265)	
Epoch: [23][233/391]	LR: 1e-05	Loss 1.6719 (1.6745)	Prec@1 30.469 (37.029)	
Epoch: [23][311/391]	LR: 1e-05	Loss 1.8799 (1.6751)	Prec@1 25.781 (36.864)	
Epoch: [23][389/391]	LR: 1e-05	Loss 1.7256 (1.6818)	Prec@1 33.594 (36.633)	
Total train loss: 1.6824

Train time: 14.449588537216187
 * Prec@1 81.710 Prec@5 98.540 Loss 1.0137
Best acc: 83.250
--------------------------------------------------------------------------------
Test time: 16.699373960494995

Epoch: [24][77/391]	LR: 1e-05	Loss 1.5557 (1.6641)	Prec@1 40.625 (36.999)	
Epoch: [24][155/391]	LR: 1e-05	Loss 1.5703 (1.6755)	Prec@1 40.625 (37.059)	
Epoch: [24][233/391]	LR: 1e-05	Loss 1.7480 (1.6800)	Prec@1 35.156 (36.735)	
Epoch: [24][311/391]	LR: 1e-05	Loss 1.6279 (1.6792)	Prec@1 39.062 (36.719)	
Epoch: [24][389/391]	LR: 1e-05	Loss 1.6025 (1.6867)	Prec@1 39.844 (36.534)	
Total train loss: 1.6867

Train time: 15.055253028869629
 * Prec@1 82.280 Prec@5 98.660 Loss 0.9751
Best acc: 83.250
--------------------------------------------------------------------------------
Test time: 17.214824676513672


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.0001
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 7
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.490 Prec@5 99.640 Loss 0.3176
Pre-trained Prec@1 with 7 layers frozen: 91.48999786376953 	 Loss: 0.317626953125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.0001	Loss 3.0762 (2.8720)	Prec@1 24.219 (24.800)	
Epoch: [0][155/391]	LR: 0.0001	Loss 2.9512 (2.6554)	Prec@1 19.531 (26.783)	
Epoch: [0][233/391]	LR: 0.0001	Loss 1.7920 (2.5354)	Prec@1 33.594 (27.724)	
Epoch: [0][311/391]	LR: 0.0001	Loss 2.0176 (2.4351)	Prec@1 28.125 (28.441)	
Epoch: [0][389/391]	LR: 0.0001	Loss 2.0234 (2.3861)	Prec@1 32.812 (28.768)	
Total train loss: 2.3856

Train time: 89.45073056221008
 * Prec@1 68.210 Prec@5 94.910 Loss 2.1641
Best acc: 68.210
--------------------------------------------------------------------------------
Test time: 92.25307273864746

Epoch: [1][77/391]	LR: 0.0001	Loss 2.3184 (2.1482)	Prec@1 24.219 (29.698)	
Epoch: [1][155/391]	LR: 0.0001	Loss 2.1113 (2.0805)	Prec@1 28.125 (31.275)	
Epoch: [1][233/391]	LR: 0.0001	Loss 2.2266 (2.0604)	Prec@1 26.562 (31.674)	
Epoch: [1][311/391]	LR: 0.0001	Loss 2.1367 (2.0524)	Prec@1 30.469 (31.836)	
Epoch: [1][389/391]	LR: 0.0001	Loss 1.8838 (2.0398)	Prec@1 32.812 (31.885)	
Total train loss: 2.0393

Train time: 14.105618476867676
 * Prec@1 72.850 Prec@5 96.360 Loss 1.7041
Best acc: 72.850
--------------------------------------------------------------------------------
Test time: 16.315751314163208

Epoch: [2][77/391]	LR: 0.0001	Loss 1.8652 (1.9471)	Prec@1 35.156 (33.073)	
Epoch: [2][155/391]	LR: 0.0001	Loss 1.7812 (1.9363)	Prec@1 32.031 (32.948)	
Epoch: [2][233/391]	LR: 0.0001	Loss 1.8145 (1.9397)	Prec@1 39.844 (33.170)	
Epoch: [2][311/391]	LR: 0.0001	Loss 2.0293 (1.9273)	Prec@1 29.688 (33.338)	
Epoch: [2][389/391]	LR: 0.0001	Loss 1.6445 (1.9296)	Prec@1 41.406 (33.193)	
Total train loss: 1.9296

Train time: 14.363577842712402
 * Prec@1 73.840 Prec@5 96.890 Loss 1.6045
Best acc: 73.840
--------------------------------------------------------------------------------
Test time: 16.25094175338745

Epoch: [3][77/391]	LR: 0.0001	Loss 1.6582 (1.8959)	Prec@1 38.281 (33.444)	
Epoch: [3][155/391]	LR: 0.0001	Loss 1.5605 (1.8798)	Prec@1 37.500 (33.759)	
Epoch: [3][233/391]	LR: 0.0001	Loss 1.7998 (1.8755)	Prec@1 35.156 (33.767)	
Epoch: [3][311/391]	LR: 0.0001	Loss 1.9814 (1.8700)	Prec@1 33.594 (33.799)	
Epoch: [3][389/391]	LR: 0.0001	Loss 2.0254 (1.8762)	Prec@1 28.125 (33.618)	
Total train loss: 1.8757

Train time: 14.203793048858643
 * Prec@1 76.630 Prec@5 97.410 Loss 1.3750
Best acc: 76.630
--------------------------------------------------------------------------------
Test time: 16.442145109176636

Epoch: [4][77/391]	LR: 0.0001	Loss 2.2715 (1.8454)	Prec@1 29.688 (33.974)	
Epoch: [4][155/391]	LR: 0.0001	Loss 1.6641 (1.8376)	Prec@1 37.500 (33.999)	
Epoch: [4][233/391]	LR: 0.0001	Loss 1.7881 (1.8371)	Prec@1 35.156 (34.201)	
Epoch: [4][311/391]	LR: 0.0001	Loss 1.5723 (1.8326)	Prec@1 41.406 (34.342)	
Epoch: [4][389/391]	LR: 0.0001	Loss 1.9844 (1.8359)	Prec@1 31.250 (34.343)	
Total train loss: 1.8359

Train time: 13.961702585220337
 * Prec@1 76.730 Prec@5 97.510 Loss 1.3877
Best acc: 76.730
--------------------------------------------------------------------------------
Test time: 16.357257604599

Epoch: [5][77/391]	LR: 0.0001	Loss 1.6611 (1.8088)	Prec@1 42.969 (34.465)	
Epoch: [5][155/391]	LR: 0.0001	Loss 1.7139 (1.8200)	Prec@1 39.062 (34.360)	
Epoch: [5][233/391]	LR: 0.0001	Loss 1.8428 (1.8190)	Prec@1 33.594 (34.425)	
Epoch: [5][311/391]	LR: 0.0001	Loss 1.6738 (1.8188)	Prec@1 37.500 (34.625)	
Epoch: [5][389/391]	LR: 0.0001	Loss 1.6221 (1.8165)	Prec@1 38.281 (34.653)	
Total train loss: 1.8171

Train time: 13.689258337020874
 * Prec@1 77.570 Prec@5 97.740 Loss 1.3027
Best acc: 77.570
--------------------------------------------------------------------------------
Test time: 16.129765033721924

Epoch: [6][77/391]	LR: 0.0001	Loss 1.7529 (1.7983)	Prec@1 36.719 (34.856)	
Epoch: [6][155/391]	LR: 0.0001	Loss 1.6611 (1.7923)	Prec@1 35.938 (34.966)	
Epoch: [6][233/391]	LR: 0.0001	Loss 1.5146 (1.7962)	Prec@1 42.969 (34.886)	
Epoch: [6][311/391]	LR: 0.0001	Loss 2.0430 (1.7936)	Prec@1 32.812 (34.963)	
Epoch: [6][389/391]	LR: 0.0001	Loss 2.2031 (1.7992)	Prec@1 26.562 (34.924)	
Total train loss: 1.7988

Train time: 13.729369640350342
 * Prec@1 78.840 Prec@5 97.850 Loss 1.1982
Best acc: 78.840
--------------------------------------------------------------------------------
Test time: 15.634548664093018

Epoch: [7][77/391]	LR: 0.0001	Loss 1.9229 (1.8450)	Prec@1 39.844 (33.674)	
Epoch: [7][155/391]	LR: 0.0001	Loss 1.7109 (1.8091)	Prec@1 35.938 (34.706)	
Epoch: [7][233/391]	LR: 0.0001	Loss 1.8994 (1.8037)	Prec@1 31.250 (34.826)	
Epoch: [7][311/391]	LR: 0.0001	Loss 1.7295 (1.7943)	Prec@1 38.281 (35.061)	
Epoch: [7][389/391]	LR: 0.0001	Loss 1.8545 (1.7920)	Prec@1 32.812 (35.088)	
Total train loss: 1.7922

Train time: 13.800774335861206
 * Prec@1 79.580 Prec@5 98.230 Loss 1.1396
Best acc: 79.580
--------------------------------------------------------------------------------
Test time: 16.21467113494873

Epoch: [8][77/391]	LR: 0.0001	Loss 1.7041 (1.7693)	Prec@1 39.062 (36.228)	
Epoch: [8][155/391]	LR: 0.0001	Loss 1.9219 (1.7798)	Prec@1 32.031 (35.602)	
Epoch: [8][233/391]	LR: 0.0001	Loss 1.8291 (1.7778)	Prec@1 30.469 (35.463)	
Epoch: [8][311/391]	LR: 0.0001	Loss 1.8691 (1.7807)	Prec@1 35.156 (35.261)	
Epoch: [8][389/391]	LR: 0.0001	Loss 1.4561 (1.7839)	Prec@1 42.188 (35.258)	
Total train loss: 1.7841

Train time: 13.334251642227173
 * Prec@1 79.730 Prec@5 98.130 Loss 1.1309
Best acc: 79.730
--------------------------------------------------------------------------------
Test time: 15.697906494140625

Epoch: [9][77/391]	LR: 0.0001	Loss 1.9297 (1.7881)	Prec@1 32.812 (34.986)	
Epoch: [9][155/391]	LR: 0.0001	Loss 1.7500 (1.7660)	Prec@1 35.938 (35.362)	
Epoch: [9][233/391]	LR: 0.0001	Loss 1.8105 (1.7567)	Prec@1 32.812 (35.413)	
Epoch: [9][311/391]	LR: 0.0001	Loss 1.6514 (1.7553)	Prec@1 36.719 (35.387)	
Epoch: [9][389/391]	LR: 0.0001	Loss 1.7627 (1.7526)	Prec@1 40.625 (35.541)	
Total train loss: 1.7526

Train time: 13.20430588722229
 * Prec@1 80.700 Prec@5 98.400 Loss 1.0498
Best acc: 80.700
--------------------------------------------------------------------------------
Test time: 15.678713083267212

Epoch: [10][77/391]	LR: 0.0001	Loss 1.6846 (1.7856)	Prec@1 35.156 (34.886)	
Epoch: [10][155/391]	LR: 0.0001	Loss 1.8174 (1.7747)	Prec@1 35.156 (35.161)	
Epoch: [10][233/391]	LR: 0.0001	Loss 1.6338 (1.7564)	Prec@1 36.719 (35.680)	
Epoch: [10][311/391]	LR: 0.0001	Loss 1.9668 (1.7526)	Prec@1 34.375 (35.717)	
Epoch: [10][389/391]	LR: 0.0001	Loss 1.5479 (1.7518)	Prec@1 42.188 (35.739)	
Total train loss: 1.7519

Train time: 12.777093410491943
 * Prec@1 80.790 Prec@5 98.330 Loss 1.0508
Best acc: 80.790
--------------------------------------------------------------------------------
Test time: 14.701020002365112

Epoch: [11][77/391]	LR: 0.0001	Loss 1.6035 (1.7203)	Prec@1 39.062 (36.228)	
Epoch: [11][155/391]	LR: 0.0001	Loss 1.5566 (1.7184)	Prec@1 39.062 (36.388)	
Epoch: [11][233/391]	LR: 0.0001	Loss 1.4346 (1.7371)	Prec@1 46.094 (35.847)	
Epoch: [11][311/391]	LR: 0.0001	Loss 1.6172 (1.7438)	Prec@1 39.844 (35.667)	
Epoch: [11][389/391]	LR: 0.0001	Loss 1.3818 (1.7407)	Prec@1 48.438 (35.735)	
Total train loss: 1.7408

Train time: 13.256001710891724
 * Prec@1 81.190 Prec@5 98.460 Loss 1.0352
Best acc: 81.190
--------------------------------------------------------------------------------
Test time: 15.55717158317566

Epoch: [12][77/391]	LR: 0.0001	Loss 1.7129 (1.7225)	Prec@1 32.812 (36.629)	
Epoch: [12][155/391]	LR: 0.0001	Loss 1.4619 (1.7196)	Prec@1 42.188 (36.298)	
Epoch: [12][233/391]	LR: 0.0001	Loss 1.7881 (1.7215)	Prec@1 37.500 (36.278)	
Epoch: [12][311/391]	LR: 0.0001	Loss 1.9678 (1.7305)	Prec@1 28.125 (36.165)	
Epoch: [12][389/391]	LR: 0.0001	Loss 1.8027 (1.7337)	Prec@1 29.688 (35.895)	
Total train loss: 1.7344

Train time: 13.136290788650513
 * Prec@1 80.190 Prec@5 98.290 Loss 1.0889
Best acc: 81.190
--------------------------------------------------------------------------------
Test time: 15.387087345123291

Epoch: [13][77/391]	LR: 0.0001	Loss 1.5977 (1.7063)	Prec@1 39.844 (36.128)	
Epoch: [13][155/391]	LR: 0.0001	Loss 1.5898 (1.7083)	Prec@1 46.094 (36.258)	
Epoch: [13][233/391]	LR: 0.0001	Loss 1.8311 (1.7240)	Prec@1 32.031 (35.817)	
Epoch: [13][311/391]	LR: 0.0001	Loss 1.6992 (1.7230)	Prec@1 35.938 (35.840)	
Epoch: [13][389/391]	LR: 0.0001	Loss 1.7090 (1.7201)	Prec@1 35.156 (35.925)	
Total train loss: 1.7206

Train time: 13.143410921096802
 * Prec@1 82.020 Prec@5 98.510 Loss 0.9688
Best acc: 82.020
--------------------------------------------------------------------------------
Test time: 15.53534197807312

Epoch: [14][77/391]	LR: 0.0001	Loss 1.7939 (1.7095)	Prec@1 28.906 (36.428)	
Epoch: [14][155/391]	LR: 0.0001	Loss 1.9463 (1.7170)	Prec@1 28.906 (36.468)	
Epoch: [14][233/391]	LR: 0.0001	Loss 1.9248 (1.7243)	Prec@1 30.469 (36.168)	
Epoch: [14][311/391]	LR: 0.0001	Loss 1.6504 (1.7210)	Prec@1 36.719 (36.188)	
Epoch: [14][389/391]	LR: 0.0001	Loss 1.8984 (1.7253)	Prec@1 38.281 (36.074)	
Total train loss: 1.7255

Train time: 13.665639162063599
 * Prec@1 81.030 Prec@5 98.400 Loss 1.0459
Best acc: 82.020
--------------------------------------------------------------------------------
Test time: 15.623847723007202

Epoch: [15][77/391]	LR: 0.0001	Loss 1.7666 (1.7163)	Prec@1 37.500 (35.978)	
Epoch: [15][155/391]	LR: 0.0001	Loss 1.9219 (1.7207)	Prec@1 31.250 (36.133)	
Epoch: [15][233/391]	LR: 0.0001	Loss 1.7354 (1.7241)	Prec@1 34.375 (35.837)	
Epoch: [15][311/391]	LR: 0.0001	Loss 1.8906 (1.7234)	Prec@1 32.031 (35.802)	
Epoch: [15][389/391]	LR: 0.0001	Loss 1.8916 (1.7193)	Prec@1 32.812 (35.958)	
Total train loss: 1.7192

Train time: 13.177406549453735
 * Prec@1 81.390 Prec@5 98.540 Loss 0.9990
Best acc: 82.020
--------------------------------------------------------------------------------
Test time: 15.50581169128418

Epoch: [16][77/391]	LR: 0.0001	Loss 1.5732 (1.7245)	Prec@1 38.281 (35.687)	
Epoch: [16][155/391]	LR: 0.0001	Loss 1.6055 (1.7166)	Prec@1 40.625 (36.128)	
Epoch: [16][233/391]	LR: 0.0001	Loss 1.6113 (1.7170)	Prec@1 41.406 (36.018)	
Epoch: [16][311/391]	LR: 0.0001	Loss 1.6035 (1.7149)	Prec@1 37.500 (36.170)	
Epoch: [16][389/391]	LR: 0.0001	Loss 1.6133 (1.7149)	Prec@1 36.719 (36.114)	
Total train loss: 1.7148

Train time: 12.831638097763062
 * Prec@1 82.270 Prec@5 98.540 Loss 0.9512
Best acc: 82.270
--------------------------------------------------------------------------------
Test time: 15.128825902938843

Epoch: [17][77/391]	LR: 0.0001	Loss 1.8320 (1.6990)	Prec@1 35.938 (36.378)	
Epoch: [17][155/391]	LR: 0.0001	Loss 1.5137 (1.7167)	Prec@1 44.531 (35.963)	
Epoch: [17][233/391]	LR: 0.0001	Loss 1.7852 (1.7102)	Prec@1 28.906 (36.058)	
Epoch: [17][311/391]	LR: 0.0001	Loss 2.0273 (1.7033)	Prec@1 30.469 (36.271)	
Epoch: [17][389/391]	LR: 0.0001	Loss 1.5518 (1.7044)	Prec@1 39.062 (36.296)	
Total train loss: 1.7053

Train time: 13.147815704345703
 * Prec@1 81.950 Prec@5 98.580 Loss 0.9639
Best acc: 82.270
--------------------------------------------------------------------------------
Test time: 15.442328214645386

Epoch: [18][77/391]	LR: 0.0001	Loss 1.5469 (1.7300)	Prec@1 40.625 (35.897)	
Epoch: [18][155/391]	LR: 0.0001	Loss 1.8105 (1.7242)	Prec@1 33.594 (35.827)	
Epoch: [18][233/391]	LR: 0.0001	Loss 1.7266 (1.7073)	Prec@1 34.375 (36.124)	
Epoch: [18][311/391]	LR: 0.0001	Loss 1.8213 (1.7085)	Prec@1 31.250 (36.170)	
Epoch: [18][389/391]	LR: 0.0001	Loss 1.4258 (1.7057)	Prec@1 45.312 (36.236)	
Total train loss: 1.7060

Train time: 13.280484676361084
 * Prec@1 82.340 Prec@5 98.660 Loss 0.9458
Best acc: 82.340
--------------------------------------------------------------------------------
Test time: 15.298610210418701

Epoch: [19][77/391]	LR: 0.0001	Loss 1.3867 (1.7041)	Prec@1 51.562 (36.749)	
Epoch: [19][155/391]	LR: 0.0001	Loss 1.6738 (1.6989)	Prec@1 35.938 (36.599)	
Epoch: [19][233/391]	LR: 0.0001	Loss 1.5498 (1.7010)	Prec@1 40.625 (36.465)	
Epoch: [19][311/391]	LR: 0.0001	Loss 1.6475 (1.7046)	Prec@1 31.250 (36.338)	
Epoch: [19][389/391]	LR: 0.0001	Loss 1.8408 (1.6997)	Prec@1 32.031 (36.318)	
Total train loss: 1.6998

Train time: 13.103004217147827
 * Prec@1 82.780 Prec@5 98.660 Loss 0.9136
Best acc: 82.780
--------------------------------------------------------------------------------
Test time: 15.402456521987915

Epoch: [20][77/391]	LR: 1e-05	Loss 1.7588 (1.7078)	Prec@1 35.156 (36.398)	
Epoch: [20][155/391]	LR: 1e-05	Loss 1.7637 (1.6883)	Prec@1 32.031 (36.819)	
Epoch: [20][233/391]	LR: 1e-05	Loss 1.5879 (1.6964)	Prec@1 39.062 (36.465)	
Epoch: [20][311/391]	LR: 1e-05	Loss 1.7227 (1.6970)	Prec@1 33.594 (36.461)	
Epoch: [20][389/391]	LR: 1e-05	Loss 1.5498 (1.6975)	Prec@1 41.406 (36.458)	
Total train loss: 1.6976

Train time: 12.970099687576294
 * Prec@1 82.710 Prec@5 98.680 Loss 0.9185
Best acc: 82.780
--------------------------------------------------------------------------------
Test time: 15.30219578742981

Epoch: [21][77/391]	LR: 1e-05	Loss 1.9707 (1.7181)	Prec@1 28.906 (36.478)	
Epoch: [21][155/391]	LR: 1e-05	Loss 1.5488 (1.6941)	Prec@1 42.188 (36.899)	
Epoch: [21][233/391]	LR: 1e-05	Loss 1.7686 (1.6969)	Prec@1 31.250 (36.685)	
Epoch: [21][311/391]	LR: 1e-05	Loss 1.5625 (1.6932)	Prec@1 43.750 (36.756)	
Epoch: [21][389/391]	LR: 1e-05	Loss 1.3516 (1.6963)	Prec@1 46.875 (36.689)	
Total train loss: 1.6966

Train time: 13.21020221710205
 * Prec@1 81.780 Prec@5 98.560 Loss 0.9761
Best acc: 82.780
--------------------------------------------------------------------------------
Test time: 15.59415602684021

Epoch: [22][77/391]	LR: 1e-05	Loss 1.9121 (1.6932)	Prec@1 27.344 (36.078)	
Epoch: [22][155/391]	LR: 1e-05	Loss 1.8213 (1.6905)	Prec@1 31.250 (36.108)	
Epoch: [22][233/391]	LR: 1e-05	Loss 1.6436 (1.6950)	Prec@1 40.625 (36.211)	
Epoch: [22][311/391]	LR: 1e-05	Loss 1.6094 (1.6921)	Prec@1 37.500 (36.448)	
Epoch: [22][389/391]	LR: 1e-05	Loss 1.8896 (1.6932)	Prec@1 33.594 (36.398)	
Total train loss: 1.6935

Train time: 13.262688159942627
 * Prec@1 82.770 Prec@5 98.610 Loss 0.9146
Best acc: 82.780
--------------------------------------------------------------------------------
Test time: 15.13281798362732

Epoch: [23][77/391]	LR: 1e-05	Loss 1.6504 (1.6738)	Prec@1 35.156 (37.650)	
Epoch: [23][155/391]	LR: 1e-05	Loss 1.6426 (1.6852)	Prec@1 35.938 (37.159)	
Epoch: [23][233/391]	LR: 1e-05	Loss 1.4561 (1.6911)	Prec@1 41.406 (36.836)	
Epoch: [23][311/391]	LR: 1e-05	Loss 1.7559 (1.6923)	Prec@1 31.250 (36.839)	
Epoch: [23][389/391]	LR: 1e-05	Loss 1.8232 (1.6990)	Prec@1 30.469 (36.573)	
Total train loss: 1.6987

Train time: 12.98852276802063
 * Prec@1 82.120 Prec@5 98.670 Loss 0.9346
Best acc: 82.780
--------------------------------------------------------------------------------
Test time: 15.38487434387207

Epoch: [24][77/391]	LR: 1e-05	Loss 1.6016 (1.7256)	Prec@1 39.062 (35.637)	
Epoch: [24][155/391]	LR: 1e-05	Loss 1.4893 (1.7009)	Prec@1 46.875 (36.333)	
Epoch: [24][233/391]	LR: 1e-05	Loss 1.8047 (1.7043)	Prec@1 34.375 (36.148)	
Epoch: [24][311/391]	LR: 1e-05	Loss 1.5342 (1.6981)	Prec@1 40.625 (36.366)	
Epoch: [24][389/391]	LR: 1e-05	Loss 1.7168 (1.6967)	Prec@1 30.469 (36.370)	
Total train loss: 1.6967

Train time: 13.15581488609314
 * Prec@1 83.820 Prec@5 98.810 Loss 0.8311
Best acc: 83.820
--------------------------------------------------------------------------------
Test time: 15.483309030532837


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.0001
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 9
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.420 Prec@5 99.640 Loss 0.3250
Pre-trained Prec@1 with 9 layers frozen: 91.41999816894531 	 Loss: 0.324951171875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.0001	Loss 2.5117 (2.5758)	Prec@1 21.875 (26.472)	
Epoch: [0][155/391]	LR: 0.0001	Loss 2.1270 (2.4263)	Prec@1 35.156 (27.870)	
Epoch: [0][233/391]	LR: 0.0001	Loss 1.8711 (2.3142)	Prec@1 39.844 (29.274)	
Epoch: [0][311/391]	LR: 0.0001	Loss 1.8564 (2.2550)	Prec@1 34.375 (29.953)	
Epoch: [0][389/391]	LR: 0.0001	Loss 2.1445 (2.2038)	Prec@1 27.344 (30.601)	
Total train loss: 2.2033

Train time: 70.53598117828369
 * Prec@1 74.930 Prec@5 96.650 Loss 1.4287
Best acc: 74.930
--------------------------------------------------------------------------------
Test time: 73.13530397415161

Epoch: [1][77/391]	LR: 0.0001	Loss 1.8350 (1.9760)	Prec@1 32.812 (32.943)	
Epoch: [1][155/391]	LR: 0.0001	Loss 2.3516 (1.9568)	Prec@1 30.469 (33.223)	
Epoch: [1][233/391]	LR: 0.0001	Loss 1.8613 (1.9505)	Prec@1 32.031 (33.120)	
Epoch: [1][311/391]	LR: 0.0001	Loss 2.0078 (1.9491)	Prec@1 33.594 (33.038)	
Epoch: [1][389/391]	LR: 0.0001	Loss 2.3379 (1.9403)	Prec@1 30.469 (33.191)	
Total train loss: 1.9404

Train time: 10.996357202529907
 * Prec@1 77.410 Prec@5 97.260 Loss 1.2588
Best acc: 77.410
--------------------------------------------------------------------------------
Test time: 13.139002084732056

Epoch: [2][77/391]	LR: 0.0001	Loss 2.0195 (1.8681)	Prec@1 31.250 (34.766)	
Epoch: [2][155/391]	LR: 0.0001	Loss 1.9033 (1.8870)	Prec@1 32.812 (34.105)	
Epoch: [2][233/391]	LR: 0.0001	Loss 1.9248 (1.8829)	Prec@1 28.906 (34.181)	
Epoch: [2][311/391]	LR: 0.0001	Loss 2.0820 (1.8796)	Prec@1 24.219 (34.047)	
Epoch: [2][389/391]	LR: 0.0001	Loss 1.8389 (1.8718)	Prec@1 37.500 (34.211)	
Total train loss: 1.8715

Train time: 10.908502340316772
 * Prec@1 78.690 Prec@5 97.620 Loss 1.1611
Best acc: 78.690
--------------------------------------------------------------------------------
Test time: 12.699084520339966

Epoch: [3][77/391]	LR: 0.0001	Loss 2.0254 (1.8248)	Prec@1 37.500 (35.306)	
Epoch: [3][155/391]	LR: 0.0001	Loss 1.8359 (1.8229)	Prec@1 35.156 (34.931)	
Epoch: [3][233/391]	LR: 0.0001	Loss 1.9756 (1.8322)	Prec@1 32.031 (34.819)	
Epoch: [3][311/391]	LR: 0.0001	Loss 2.0781 (1.8308)	Prec@1 28.125 (34.801)	
Epoch: [3][389/391]	LR: 0.0001	Loss 1.7656 (1.8309)	Prec@1 37.500 (34.738)	
Total train loss: 1.8310

Train time: 11.559556722640991
 * Prec@1 80.090 Prec@5 97.860 Loss 1.0713
Best acc: 80.090
--------------------------------------------------------------------------------
Test time: 13.776482820510864

Epoch: [4][77/391]	LR: 0.0001	Loss 1.5938 (1.8275)	Prec@1 41.406 (34.375)	
Epoch: [4][155/391]	LR: 0.0001	Loss 1.5654 (1.8182)	Prec@1 39.062 (34.610)	
Epoch: [4][233/391]	LR: 0.0001	Loss 1.6318 (1.8137)	Prec@1 37.500 (34.702)	
Epoch: [4][311/391]	LR: 0.0001	Loss 1.6719 (1.8133)	Prec@1 39.844 (34.746)	
Epoch: [4][389/391]	LR: 0.0001	Loss 1.6152 (1.8029)	Prec@1 37.500 (34.932)	
Total train loss: 1.8030

Train time: 10.996046781539917
 * Prec@1 80.780 Prec@5 97.890 Loss 1.0156
Best acc: 80.780
--------------------------------------------------------------------------------
Test time: 12.77717137336731

Epoch: [5][77/391]	LR: 0.0001	Loss 2.0898 (1.7908)	Prec@1 31.250 (34.405)	
Epoch: [5][155/391]	LR: 0.0001	Loss 1.8164 (1.7857)	Prec@1 39.844 (34.786)	
Epoch: [5][233/391]	LR: 0.0001	Loss 1.6387 (1.7813)	Prec@1 39.844 (35.053)	
Epoch: [5][311/391]	LR: 0.0001	Loss 1.6348 (1.7834)	Prec@1 37.500 (35.001)	
Epoch: [5][389/391]	LR: 0.0001	Loss 1.4834 (1.7812)	Prec@1 42.188 (35.102)	
Total train loss: 1.7820

Train time: 11.322961330413818
 * Prec@1 80.820 Prec@5 98.250 Loss 0.9951
Best acc: 80.820
--------------------------------------------------------------------------------
Test time: 13.948696374893188

Epoch: [6][77/391]	LR: 0.0001	Loss 1.7754 (1.7586)	Prec@1 35.938 (35.677)	
Epoch: [6][155/391]	LR: 0.0001	Loss 1.7129 (1.7704)	Prec@1 35.938 (35.056)	
Epoch: [6][233/391]	LR: 0.0001	Loss 1.7002 (1.7759)	Prec@1 37.500 (34.976)	
Epoch: [6][311/391]	LR: 0.0001	Loss 2.0098 (1.7726)	Prec@1 30.469 (35.126)	
Epoch: [6][389/391]	LR: 0.0001	Loss 1.6113 (1.7663)	Prec@1 37.500 (35.236)	
Total train loss: 1.7667

Train time: 10.862090826034546
 * Prec@1 81.120 Prec@5 98.170 Loss 1.0244
Best acc: 81.120
--------------------------------------------------------------------------------
Test time: 12.584797143936157

Epoch: [7][77/391]	LR: 0.0001	Loss 2.0352 (1.7717)	Prec@1 24.219 (34.766)	
Epoch: [7][155/391]	LR: 0.0001	Loss 1.7324 (1.7595)	Prec@1 37.500 (35.427)	
Epoch: [7][233/391]	LR: 0.0001	Loss 1.8428 (1.7527)	Prec@1 31.250 (35.470)	
Epoch: [7][311/391]	LR: 0.0001	Loss 1.9951 (1.7606)	Prec@1 28.125 (35.294)	
Epoch: [7][389/391]	LR: 0.0001	Loss 1.7998 (1.7516)	Prec@1 33.594 (35.555)	
Total train loss: 1.7515

Train time: 10.552762508392334
 * Prec@1 82.050 Prec@5 98.500 Loss 0.9272
Best acc: 82.050
--------------------------------------------------------------------------------
Test time: 12.688126802444458

Epoch: [8][77/391]	LR: 0.0001	Loss 1.5840 (1.7375)	Prec@1 37.500 (35.917)	
Epoch: [8][155/391]	LR: 0.0001	Loss 1.7227 (1.7342)	Prec@1 37.500 (35.752)	
Epoch: [8][233/391]	LR: 0.0001	Loss 1.8018 (1.7460)	Prec@1 29.688 (35.493)	
Epoch: [8][311/391]	LR: 0.0001	Loss 1.6885 (1.7480)	Prec@1 37.500 (35.532)	
Epoch: [8][389/391]	LR: 0.0001	Loss 1.9238 (1.7460)	Prec@1 34.375 (35.619)	
Total train loss: 1.7458

Train time: 10.860474109649658
 * Prec@1 82.080 Prec@5 98.590 Loss 0.9390
Best acc: 82.080
--------------------------------------------------------------------------------
Test time: 12.610172271728516

Epoch: [9][77/391]	LR: 0.0001	Loss 1.8340 (1.7657)	Prec@1 32.031 (35.076)	
Epoch: [9][155/391]	LR: 0.0001	Loss 1.9170 (1.7461)	Prec@1 33.594 (35.472)	
Epoch: [9][233/391]	LR: 0.0001	Loss 1.6152 (1.7462)	Prec@1 40.625 (35.654)	
Epoch: [9][311/391]	LR: 0.0001	Loss 1.9463 (1.7343)	Prec@1 27.344 (36.070)	
Epoch: [9][389/391]	LR: 0.0001	Loss 2.0645 (1.7379)	Prec@1 23.438 (35.835)	
Total train loss: 1.7376

Train time: 10.84156084060669
 * Prec@1 81.630 Prec@5 98.510 Loss 0.9634
Best acc: 82.080
--------------------------------------------------------------------------------
Test time: 13.025978565216064

Epoch: [10][77/391]	LR: 0.0001	Loss 1.4395 (1.7351)	Prec@1 42.969 (35.717)	
Epoch: [10][155/391]	LR: 0.0001	Loss 1.7139 (1.7298)	Prec@1 37.500 (35.642)	
Epoch: [10][233/391]	LR: 0.0001	Loss 1.9580 (1.7294)	Prec@1 33.594 (35.737)	
Epoch: [10][311/391]	LR: 0.0001	Loss 1.7051 (1.7295)	Prec@1 37.500 (35.740)	
Epoch: [10][389/391]	LR: 0.0001	Loss 1.6924 (1.7264)	Prec@1 38.281 (35.903)	
Total train loss: 1.7270

Train time: 11.001862525939941
 * Prec@1 82.800 Prec@5 98.500 Loss 0.9009
Best acc: 82.800
--------------------------------------------------------------------------------
Test time: 13.155367136001587

Epoch: [11][77/391]	LR: 0.0001	Loss 1.6045 (1.7207)	Prec@1 39.844 (36.138)	
Epoch: [11][155/391]	LR: 0.0001	Loss 1.7842 (1.7141)	Prec@1 28.906 (36.298)	
Epoch: [11][233/391]	LR: 0.0001	Loss 1.5498 (1.7189)	Prec@1 41.406 (36.084)	
Epoch: [11][311/391]	LR: 0.0001	Loss 1.7363 (1.7199)	Prec@1 35.156 (35.960)	
Epoch: [11][389/391]	LR: 0.0001	Loss 1.5781 (1.7159)	Prec@1 39.844 (36.014)	
Total train loss: 1.7164

Train time: 10.826982498168945
 * Prec@1 82.950 Prec@5 98.590 Loss 0.8735
Best acc: 82.950
--------------------------------------------------------------------------------
Test time: 12.979424238204956

Epoch: [12][77/391]	LR: 0.0001	Loss 1.7266 (1.7386)	Prec@1 37.500 (35.477)	
Epoch: [12][155/391]	LR: 0.0001	Loss 1.6953 (1.7465)	Prec@1 37.500 (35.306)	
Epoch: [12][233/391]	LR: 0.0001	Loss 1.7598 (1.7287)	Prec@1 35.938 (35.834)	
Epoch: [12][311/391]	LR: 0.0001	Loss 1.7412 (1.7251)	Prec@1 34.375 (35.965)	
Epoch: [12][389/391]	LR: 0.0001	Loss 1.6035 (1.7178)	Prec@1 41.406 (36.120)	
Total train loss: 1.7180

Train time: 10.953283548355103
 * Prec@1 84.030 Prec@5 98.750 Loss 0.8140
Best acc: 84.030
--------------------------------------------------------------------------------
Test time: 12.720783948898315

Epoch: [13][77/391]	LR: 0.0001	Loss 1.7158 (1.6971)	Prec@1 36.719 (36.739)	
Epoch: [13][155/391]	LR: 0.0001	Loss 1.8340 (1.6952)	Prec@1 35.156 (36.574)	
Epoch: [13][233/391]	LR: 0.0001	Loss 1.8984 (1.7036)	Prec@1 35.156 (36.362)	
Epoch: [13][311/391]	LR: 0.0001	Loss 1.7510 (1.7070)	Prec@1 40.625 (36.203)	
Epoch: [13][389/391]	LR: 0.0001	Loss 1.7109 (1.7079)	Prec@1 36.719 (36.200)	
Total train loss: 1.7082

Train time: 10.765146493911743
 * Prec@1 83.500 Prec@5 98.730 Loss 0.8657
Best acc: 84.030
--------------------------------------------------------------------------------
Test time: 12.956210374832153

Epoch: [14][77/391]	LR: 0.0001	Loss 1.6523 (1.7191)	Prec@1 35.938 (36.739)	
Epoch: [14][155/391]	LR: 0.0001	Loss 1.5820 (1.7114)	Prec@1 42.969 (36.543)	
Epoch: [14][233/391]	LR: 0.0001	Loss 1.6611 (1.7131)	Prec@1 36.719 (36.138)	
Epoch: [14][311/391]	LR: 0.0001	Loss 1.7881 (1.7055)	Prec@1 37.500 (36.313)	
Epoch: [14][389/391]	LR: 0.0001	Loss 1.7969 (1.7043)	Prec@1 33.594 (36.290)	
Total train loss: 1.7041

Train time: 11.146684646606445
 * Prec@1 84.100 Prec@5 98.720 Loss 0.8145
Best acc: 84.100
--------------------------------------------------------------------------------
Test time: 12.87123703956604

Epoch: [15][77/391]	LR: 0.0001	Loss 1.8730 (1.6907)	Prec@1 30.469 (36.388)	
Epoch: [15][155/391]	LR: 0.0001	Loss 1.6201 (1.6994)	Prec@1 41.406 (36.223)	
Epoch: [15][233/391]	LR: 0.0001	Loss 1.6133 (1.7046)	Prec@1 38.281 (36.014)	
Epoch: [15][311/391]	LR: 0.0001	Loss 1.6396 (1.6994)	Prec@1 40.625 (36.251)	
Epoch: [15][389/391]	LR: 0.0001	Loss 1.8252 (1.7008)	Prec@1 30.469 (36.240)	
Total train loss: 1.7012

Train time: 10.991049766540527
 * Prec@1 83.180 Prec@5 98.700 Loss 0.8711
Best acc: 84.100
--------------------------------------------------------------------------------
Test time: 13.606529474258423

Epoch: [16][77/391]	LR: 0.0001	Loss 1.7598 (1.6737)	Prec@1 33.594 (37.069)	
Epoch: [16][155/391]	LR: 0.0001	Loss 1.6260 (1.6813)	Prec@1 41.406 (36.969)	
Epoch: [16][233/391]	LR: 0.0001	Loss 1.6338 (1.6848)	Prec@1 36.719 (36.959)	
Epoch: [16][311/391]	LR: 0.0001	Loss 1.5586 (1.6960)	Prec@1 37.500 (36.654)	
Epoch: [16][389/391]	LR: 0.0001	Loss 1.7666 (1.6978)	Prec@1 33.594 (36.520)	
Total train loss: 1.6979

Train time: 10.65708613395691
 * Prec@1 83.620 Prec@5 98.740 Loss 0.8408
Best acc: 84.100
--------------------------------------------------------------------------------
Test time: 12.45338225364685

Epoch: [17][77/391]	LR: 0.0001	Loss 1.7363 (1.6891)	Prec@1 41.406 (35.998)	
Epoch: [17][155/391]	LR: 0.0001	Loss 1.8311 (1.6853)	Prec@1 33.594 (36.453)	
Epoch: [17][233/391]	LR: 0.0001	Loss 1.5898 (1.6907)	Prec@1 37.500 (36.438)	
Epoch: [17][311/391]	LR: 0.0001	Loss 1.6250 (1.6950)	Prec@1 39.844 (36.358)	
Epoch: [17][389/391]	LR: 0.0001	Loss 1.8799 (1.6961)	Prec@1 28.125 (36.386)	
Total train loss: 1.6966

Train time: 10.952313423156738
 * Prec@1 83.350 Prec@5 98.740 Loss 0.8569
Best acc: 84.100
--------------------------------------------------------------------------------
Test time: 13.06498384475708

Epoch: [18][77/391]	LR: 0.0001	Loss 1.6963 (1.6615)	Prec@1 32.812 (37.149)	
Epoch: [18][155/391]	LR: 0.0001	Loss 1.6553 (1.6802)	Prec@1 37.500 (36.689)	
Epoch: [18][233/391]	LR: 0.0001	Loss 1.8467 (1.6837)	Prec@1 30.469 (36.672)	
Epoch: [18][311/391]	LR: 0.0001	Loss 1.7891 (1.6858)	Prec@1 31.250 (36.674)	
Epoch: [18][389/391]	LR: 0.0001	Loss 2.0781 (1.6848)	Prec@1 26.562 (36.795)	
Total train loss: 1.6853

Train time: 10.989060640335083
 * Prec@1 83.570 Prec@5 98.760 Loss 0.8521
Best acc: 84.100
--------------------------------------------------------------------------------
Test time: 12.734944105148315

Epoch: [19][77/391]	LR: 0.0001	Loss 1.6025 (1.7045)	Prec@1 33.594 (35.927)	
Epoch: [19][155/391]	LR: 0.0001	Loss 1.7734 (1.6988)	Prec@1 34.375 (36.128)	
Epoch: [19][233/391]	LR: 0.0001	Loss 1.5977 (1.6818)	Prec@1 38.281 (36.822)	
Epoch: [19][311/391]	LR: 0.0001	Loss 1.5146 (1.6839)	Prec@1 40.625 (36.794)	
Epoch: [19][389/391]	LR: 0.0001	Loss 1.5781 (1.6866)	Prec@1 42.188 (36.773)	
Total train loss: 1.6863

Train time: 10.784073114395142
 * Prec@1 84.420 Prec@5 98.830 Loss 0.7998
Best acc: 84.420
--------------------------------------------------------------------------------
Test time: 12.988511323928833

Epoch: [20][77/391]	LR: 1e-05	Loss 1.7500 (1.6887)	Prec@1 35.156 (36.589)	
Epoch: [20][155/391]	LR: 1e-05	Loss 1.9512 (1.6932)	Prec@1 27.344 (36.373)	
Epoch: [20][233/391]	LR: 1e-05	Loss 1.9512 (1.6902)	Prec@1 26.562 (36.542)	
Epoch: [20][311/391]	LR: 1e-05	Loss 1.7939 (1.6895)	Prec@1 30.469 (36.541)	
Epoch: [20][389/391]	LR: 1e-05	Loss 1.6680 (1.6861)	Prec@1 31.250 (36.567)	
Total train loss: 1.6862

Train time: 10.802246570587158
 * Prec@1 84.180 Prec@5 98.850 Loss 0.8154
Best acc: 84.420
--------------------------------------------------------------------------------
Test time: 12.934799671173096

Epoch: [21][77/391]	LR: 1e-05	Loss 1.5557 (1.6828)	Prec@1 39.844 (36.799)	
Epoch: [21][155/391]	LR: 1e-05	Loss 1.5889 (1.6804)	Prec@1 36.719 (36.894)	
Epoch: [21][233/391]	LR: 1e-05	Loss 1.6709 (1.6808)	Prec@1 35.938 (36.946)	
Epoch: [21][311/391]	LR: 1e-05	Loss 1.6895 (1.6779)	Prec@1 34.375 (37.144)	
Epoch: [21][389/391]	LR: 1e-05	Loss 1.5498 (1.6839)	Prec@1 40.625 (36.829)	
Total train loss: 1.6837

Train time: 10.883554935455322
 * Prec@1 84.370 Prec@5 98.890 Loss 0.8013
Best acc: 84.420
--------------------------------------------------------------------------------
Test time: 13.047410488128662

Epoch: [22][77/391]	LR: 1e-05	Loss 1.7432 (1.7023)	Prec@1 34.375 (35.917)	
Epoch: [22][155/391]	LR: 1e-05	Loss 2.2383 (1.6924)	Prec@1 22.656 (36.258)	
Epoch: [22][233/391]	LR: 1e-05	Loss 1.5918 (1.6838)	Prec@1 42.969 (36.602)	
Epoch: [22][311/391]	LR: 1e-05	Loss 1.7041 (1.6796)	Prec@1 34.375 (36.856)	
Epoch: [22][389/391]	LR: 1e-05	Loss 1.6348 (1.6858)	Prec@1 42.188 (36.737)	
Total train loss: 1.6859

Train time: 10.480107307434082
 * Prec@1 84.360 Prec@5 99.010 Loss 0.7822
Best acc: 84.420
--------------------------------------------------------------------------------
Test time: 12.269309759140015

Epoch: [23][77/391]	LR: 1e-05	Loss 1.6924 (1.7075)	Prec@1 32.812 (36.288)	
Epoch: [23][155/391]	LR: 1e-05	Loss 1.6504 (1.6911)	Prec@1 34.375 (36.493)	
Epoch: [23][233/391]	LR: 1e-05	Loss 1.6982 (1.6938)	Prec@1 35.156 (36.565)	
Epoch: [23][311/391]	LR: 1e-05	Loss 1.3633 (1.6922)	Prec@1 44.531 (36.609)	
Epoch: [23][389/391]	LR: 1e-05	Loss 1.7588 (1.6877)	Prec@1 36.719 (36.777)	
Total train loss: 1.6875

Train time: 10.3612220287323
 * Prec@1 84.350 Prec@5 98.990 Loss 0.7808
Best acc: 84.420
--------------------------------------------------------------------------------
Test time: 12.49643087387085

Epoch: [24][77/391]	LR: 1e-05	Loss 1.5664 (1.6508)	Prec@1 38.281 (37.931)	
Epoch: [24][155/391]	LR: 1e-05	Loss 1.5957 (1.6682)	Prec@1 39.062 (37.215)	
Epoch: [24][233/391]	LR: 1e-05	Loss 1.6719 (1.6807)	Prec@1 37.500 (36.702)	
Epoch: [24][311/391]	LR: 1e-05	Loss 1.3887 (1.6848)	Prec@1 50.781 (36.561)	
Epoch: [24][389/391]	LR: 1e-05	Loss 1.5674 (1.6878)	Prec@1 39.844 (36.442)	
Total train loss: 1.6874

Train time: 10.667380332946777
 * Prec@1 85.110 Prec@5 98.950 Loss 0.7573
Best acc: 85.110
--------------------------------------------------------------------------------
Test time: 12.446887493133545


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.0001
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 11
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.400 Prec@5 99.600 Loss 0.3262
Pre-trained Prec@1 with 11 layers frozen: 91.39999389648438 	 Loss: 0.326171875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.0001	Loss 2.0273 (2.5372)	Prec@1 34.375 (26.863)	
Epoch: [0][155/391]	LR: 0.0001	Loss 2.4121 (2.3715)	Prec@1 27.344 (28.786)	
Epoch: [0][233/391]	LR: 0.0001	Loss 1.9395 (2.2961)	Prec@1 32.031 (29.374)	
Epoch: [0][311/391]	LR: 0.0001	Loss 1.6797 (2.2379)	Prec@1 42.188 (29.980)	
Epoch: [0][389/391]	LR: 0.0001	Loss 1.8115 (2.1877)	Prec@1 35.156 (30.577)	
Total train loss: 2.1873

Train time: 79.92245578765869
 * Prec@1 74.320 Prec@5 96.940 Loss 1.4463
Best acc: 74.320
--------------------------------------------------------------------------------
Test time: 82.56489658355713

Epoch: [1][77/391]	LR: 0.0001	Loss 1.7832 (1.9493)	Prec@1 35.938 (33.333)	
Epoch: [1][155/391]	LR: 0.0001	Loss 2.0469 (1.9284)	Prec@1 28.906 (33.514)	
Epoch: [1][233/391]	LR: 0.0001	Loss 1.4082 (1.9334)	Prec@1 50.000 (33.383)	
Epoch: [1][311/391]	LR: 0.0001	Loss 1.7773 (1.9172)	Prec@1 40.625 (33.599)	
Epoch: [1][389/391]	LR: 0.0001	Loss 1.8613 (1.9132)	Prec@1 35.938 (33.618)	
Total train loss: 1.9134

Train time: 9.288670778274536
 * Prec@1 78.240 Prec@5 97.760 Loss 1.1816
Best acc: 78.240
--------------------------------------------------------------------------------
Test time: 11.139801502227783

Epoch: [2][77/391]	LR: 0.0001	Loss 2.1172 (1.8601)	Prec@1 34.375 (35.276)	
Epoch: [2][155/391]	LR: 0.0001	Loss 1.8994 (1.8501)	Prec@1 30.469 (35.126)	
Epoch: [2][233/391]	LR: 0.0001	Loss 2.1953 (1.8519)	Prec@1 32.031 (34.809)	
Epoch: [2][311/391]	LR: 0.0001	Loss 1.8574 (1.8484)	Prec@1 36.719 (34.718)	
Epoch: [2][389/391]	LR: 0.0001	Loss 1.8555 (1.8446)	Prec@1 35.938 (34.685)	
Total train loss: 1.8449

Train time: 8.883866548538208
 * Prec@1 80.370 Prec@5 98.220 Loss 1.0459
Best acc: 80.370
--------------------------------------------------------------------------------
Test time: 11.08236813545227

Epoch: [3][77/391]	LR: 0.0001	Loss 1.8408 (1.8104)	Prec@1 33.594 (34.535)	
Epoch: [3][155/391]	LR: 0.0001	Loss 1.9111 (1.8195)	Prec@1 28.125 (34.550)	
Epoch: [3][233/391]	LR: 0.0001	Loss 1.6924 (1.8124)	Prec@1 35.938 (34.862)	
Epoch: [3][311/391]	LR: 0.0001	Loss 1.9160 (1.8121)	Prec@1 35.938 (34.868)	
Epoch: [3][389/391]	LR: 0.0001	Loss 1.8877 (1.8087)	Prec@1 30.469 (34.964)	
Total train loss: 1.8091

Train time: 9.165043115615845
 * Prec@1 80.560 Prec@5 98.420 Loss 1.0244
Best acc: 80.560
--------------------------------------------------------------------------------
Test time: 10.919784784317017

Epoch: [4][77/391]	LR: 0.0001	Loss 1.7607 (1.8037)	Prec@1 39.062 (34.716)	
Epoch: [4][155/391]	LR: 0.0001	Loss 1.7686 (1.7966)	Prec@1 35.156 (34.801)	
Epoch: [4][233/391]	LR: 0.0001	Loss 1.7939 (1.7911)	Prec@1 36.719 (35.176)	
Epoch: [4][311/391]	LR: 0.0001	Loss 1.6201 (1.7875)	Prec@1 36.719 (35.221)	
Epoch: [4][389/391]	LR: 0.0001	Loss 1.8838 (1.7845)	Prec@1 28.906 (35.268)	
Total train loss: 1.7848

Train time: 9.698205709457397
 * Prec@1 81.090 Prec@5 98.470 Loss 1.0078
Best acc: 81.090
--------------------------------------------------------------------------------
Test time: 11.917953491210938

Epoch: [5][77/391]	LR: 0.0001	Loss 1.6533 (1.7663)	Prec@1 39.062 (35.607)	
Epoch: [5][155/391]	LR: 0.0001	Loss 2.0488 (1.7791)	Prec@1 32.812 (35.176)	
Epoch: [5][233/391]	LR: 0.0001	Loss 1.7744 (1.7710)	Prec@1 32.812 (35.417)	
Epoch: [5][311/391]	LR: 0.0001	Loss 1.9316 (1.7685)	Prec@1 30.469 (35.519)	
Epoch: [5][389/391]	LR: 0.0001	Loss 1.9209 (1.7652)	Prec@1 35.938 (35.541)	
Total train loss: 1.7659

Train time: 9.085157632827759
 * Prec@1 82.020 Prec@5 98.580 Loss 0.9536
Best acc: 82.020
--------------------------------------------------------------------------------
Test time: 10.893706321716309

Epoch: [6][77/391]	LR: 0.0001	Loss 1.7510 (1.7362)	Prec@1 31.250 (35.968)	
Epoch: [6][155/391]	LR: 0.0001	Loss 1.7861 (1.7502)	Prec@1 33.594 (35.862)	
Epoch: [6][233/391]	LR: 0.0001	Loss 1.8096 (1.7541)	Prec@1 38.281 (35.574)	
Epoch: [6][311/391]	LR: 0.0001	Loss 1.7461 (1.7479)	Prec@1 34.375 (35.650)	
Epoch: [6][389/391]	LR: 0.0001	Loss 1.6982 (1.7463)	Prec@1 37.500 (35.685)	
Total train loss: 1.7462

Train time: 9.421023845672607
 * Prec@1 82.830 Prec@5 98.740 Loss 0.8770
Best acc: 82.830
--------------------------------------------------------------------------------
Test time: 12.01017713546753

Epoch: [7][77/391]	LR: 0.0001	Loss 1.7070 (1.7428)	Prec@1 31.250 (35.547)	
Epoch: [7][155/391]	LR: 0.0001	Loss 1.9365 (1.7450)	Prec@1 28.906 (35.382)	
Epoch: [7][233/391]	LR: 0.0001	Loss 1.7490 (1.7397)	Prec@1 36.719 (35.567)	
Epoch: [7][311/391]	LR: 0.0001	Loss 1.8174 (1.7348)	Prec@1 31.250 (35.742)	
Epoch: [7][389/391]	LR: 0.0001	Loss 1.6475 (1.7291)	Prec@1 35.156 (35.817)	
Total train loss: 1.7288

Train time: 9.517611980438232
 * Prec@1 83.200 Prec@5 98.820 Loss 0.8599
Best acc: 83.200
--------------------------------------------------------------------------------
Test time: 11.358383893966675

Epoch: [8][77/391]	LR: 0.0001	Loss 1.6299 (1.7281)	Prec@1 39.844 (35.978)	
Epoch: [8][155/391]	LR: 0.0001	Loss 1.7246 (1.7235)	Prec@1 34.375 (35.948)	
Epoch: [8][233/391]	LR: 0.0001	Loss 1.7002 (1.7295)	Prec@1 33.594 (35.687)	
Epoch: [8][311/391]	LR: 0.0001	Loss 1.6553 (1.7224)	Prec@1 37.500 (35.940)	
Epoch: [8][389/391]	LR: 0.0001	Loss 1.5166 (1.7232)	Prec@1 39.844 (35.885)	
Total train loss: 1.7232

Train time: 9.307553768157959
 * Prec@1 83.280 Prec@5 98.840 Loss 0.8550
Best acc: 83.280
--------------------------------------------------------------------------------
Test time: 11.452979803085327

Epoch: [9][77/391]	LR: 0.0001	Loss 1.6475 (1.7470)	Prec@1 33.594 (34.746)	
Epoch: [9][155/391]	LR: 0.0001	Loss 1.6641 (1.7412)	Prec@1 36.719 (35.126)	
Epoch: [9][233/391]	LR: 0.0001	Loss 2.0898 (1.7260)	Prec@1 27.344 (35.570)	
Epoch: [9][311/391]	LR: 0.0001	Loss 2.0488 (1.7239)	Prec@1 28.125 (35.845)	
Epoch: [9][389/391]	LR: 0.0001	Loss 1.6738 (1.7197)	Prec@1 37.500 (35.948)	
Total train loss: 1.7195

Train time: 9.406672954559326
 * Prec@1 83.650 Prec@5 98.950 Loss 0.8271
Best acc: 83.650
--------------------------------------------------------------------------------
Test time: 11.223121166229248

Epoch: [10][77/391]	LR: 0.0001	Loss 1.7588 (1.7237)	Prec@1 31.250 (35.737)	
Epoch: [10][155/391]	LR: 0.0001	Loss 1.6182 (1.7107)	Prec@1 36.719 (35.993)	
Epoch: [10][233/391]	LR: 0.0001	Loss 1.4502 (1.7146)	Prec@1 44.531 (35.981)	
Epoch: [10][311/391]	LR: 0.0001	Loss 1.5059 (1.7149)	Prec@1 45.312 (36.010)	
Epoch: [10][389/391]	LR: 0.0001	Loss 1.5166 (1.7065)	Prec@1 42.969 (36.298)	
Total train loss: 1.7068

Train time: 9.071903944015503
 * Prec@1 84.030 Prec@5 98.860 Loss 0.8081
Best acc: 84.030
--------------------------------------------------------------------------------
Test time: 11.187637329101562

Epoch: [11][77/391]	LR: 0.0001	Loss 1.9521 (1.7035)	Prec@1 30.469 (36.378)	
Epoch: [11][155/391]	LR: 0.0001	Loss 1.6182 (1.6928)	Prec@1 39.062 (36.654)	
Epoch: [11][233/391]	LR: 0.0001	Loss 1.8506 (1.7040)	Prec@1 31.250 (36.121)	
Epoch: [11][311/391]	LR: 0.0001	Loss 1.7012 (1.7019)	Prec@1 39.062 (36.266)	
Epoch: [11][389/391]	LR: 0.0001	Loss 1.7451 (1.6998)	Prec@1 35.938 (36.248)	
Total train loss: 1.6999

Train time: 9.031053304672241
 * Prec@1 83.500 Prec@5 98.820 Loss 0.8535
Best acc: 84.030
--------------------------------------------------------------------------------
Test time: 10.769696235656738

Epoch: [12][77/391]	LR: 0.0001	Loss 1.6914 (1.6997)	Prec@1 34.375 (36.278)	
Epoch: [12][155/391]	LR: 0.0001	Loss 1.8623 (1.6951)	Prec@1 27.344 (36.674)	
Epoch: [12][233/391]	LR: 0.0001	Loss 2.0879 (1.6973)	Prec@1 33.594 (36.669)	
Epoch: [12][311/391]	LR: 0.0001	Loss 1.6719 (1.7037)	Prec@1 38.281 (36.451)	
Epoch: [12][389/391]	LR: 0.0001	Loss 1.7422 (1.7039)	Prec@1 32.812 (36.456)	
Total train loss: 1.7035

Train time: 8.661710977554321
 * Prec@1 83.050 Prec@5 98.840 Loss 0.8647
Best acc: 84.030
--------------------------------------------------------------------------------
Test time: 11.433700323104858

Epoch: [13][77/391]	LR: 0.0001	Loss 1.7070 (1.6821)	Prec@1 35.156 (36.689)	
Epoch: [13][155/391]	LR: 0.0001	Loss 1.5996 (1.6774)	Prec@1 38.281 (36.899)	
Epoch: [13][233/391]	LR: 0.0001	Loss 1.6592 (1.6939)	Prec@1 35.938 (36.438)	
Epoch: [13][311/391]	LR: 0.0001	Loss 1.7012 (1.6934)	Prec@1 33.594 (36.441)	
Epoch: [13][389/391]	LR: 0.0001	Loss 1.6055 (1.6909)	Prec@1 35.938 (36.534)	
Total train loss: 1.6912

Train time: 8.662438154220581
 * Prec@1 83.890 Prec@5 98.820 Loss 0.8345
Best acc: 84.030
--------------------------------------------------------------------------------
Test time: 10.447583675384521

Epoch: [14][77/391]	LR: 0.0001	Loss 1.6328 (1.6847)	Prec@1 33.594 (36.378)	
Epoch: [14][155/391]	LR: 0.0001	Loss 1.5898 (1.6873)	Prec@1 36.719 (36.604)	
Epoch: [14][233/391]	LR: 0.0001	Loss 1.6064 (1.6836)	Prec@1 39.844 (36.572)	
Epoch: [14][311/391]	LR: 0.0001	Loss 1.5596 (1.6904)	Prec@1 39.844 (36.453)	
Epoch: [14][389/391]	LR: 0.0001	Loss 1.6279 (1.6869)	Prec@1 39.062 (36.542)	
Total train loss: 1.6876

Train time: 9.734798669815063
 * Prec@1 83.750 Prec@5 98.950 Loss 0.8086
Best acc: 84.030
--------------------------------------------------------------------------------
Test time: 11.848307847976685

Epoch: [15][77/391]	LR: 0.0001	Loss 1.5625 (1.6798)	Prec@1 39.062 (36.749)	
Epoch: [15][155/391]	LR: 0.0001	Loss 1.6855 (1.6755)	Prec@1 32.031 (37.029)	
Epoch: [15][233/391]	LR: 0.0001	Loss 1.7373 (1.6767)	Prec@1 37.500 (36.926)	
Epoch: [15][311/391]	LR: 0.0001	Loss 1.6357 (1.6817)	Prec@1 38.281 (36.821)	
Epoch: [15][389/391]	LR: 0.0001	Loss 1.6270 (1.6850)	Prec@1 38.281 (36.689)	
Total train loss: 1.6849

Train time: 9.040671110153198
 * Prec@1 84.220 Prec@5 98.970 Loss 0.8013
Best acc: 84.220
--------------------------------------------------------------------------------
Test time: 10.905969142913818

Epoch: [16][77/391]	LR: 0.0001	Loss 1.5859 (1.6836)	Prec@1 39.062 (36.689)	
Epoch: [16][155/391]	LR: 0.0001	Loss 1.7422 (1.6818)	Prec@1 33.594 (36.428)	
Epoch: [16][233/391]	LR: 0.0001	Loss 1.8115 (1.6839)	Prec@1 32.031 (36.629)	
Epoch: [16][311/391]	LR: 0.0001	Loss 1.9688 (1.6898)	Prec@1 28.906 (36.448)	
Epoch: [16][389/391]	LR: 0.0001	Loss 1.7148 (1.6874)	Prec@1 35.156 (36.462)	
Total train loss: 1.6877

Train time: 9.123775243759155
 * Prec@1 84.310 Prec@5 99.030 Loss 0.7876
Best acc: 84.310
--------------------------------------------------------------------------------
Test time: 11.247529983520508

Epoch: [17][77/391]	LR: 0.0001	Loss 1.6523 (1.6948)	Prec@1 37.500 (36.589)	
Epoch: [17][155/391]	LR: 0.0001	Loss 1.7656 (1.6872)	Prec@1 32.812 (36.614)	
Epoch: [17][233/391]	LR: 0.0001	Loss 1.6982 (1.6962)	Prec@1 36.719 (36.321)	
Epoch: [17][311/391]	LR: 0.0001	Loss 1.9453 (1.6895)	Prec@1 25.781 (36.366)	
Epoch: [17][389/391]	LR: 0.0001	Loss 1.9248 (1.6845)	Prec@1 30.469 (36.462)	
Total train loss: 1.6848

Train time: 9.422352313995361
 * Prec@1 83.970 Prec@5 98.950 Loss 0.8149
Best acc: 84.310
--------------------------------------------------------------------------------
Test time: 11.256669521331787

Epoch: [18][77/391]	LR: 0.0001	Loss 1.5986 (1.6958)	Prec@1 37.500 (36.488)	
Epoch: [18][155/391]	LR: 0.0001	Loss 1.9385 (1.6916)	Prec@1 27.344 (36.398)	
Epoch: [18][233/391]	LR: 0.0001	Loss 1.5303 (1.6852)	Prec@1 41.406 (36.338)	
Epoch: [18][311/391]	LR: 0.0001	Loss 1.6475 (1.6774)	Prec@1 37.500 (36.614)	
Epoch: [18][389/391]	LR: 0.0001	Loss 1.8545 (1.6719)	Prec@1 30.469 (36.799)	
Total train loss: 1.6719

Train time: 9.199395895004272
 * Prec@1 84.630 Prec@5 98.980 Loss 0.7817
Best acc: 84.630
--------------------------------------------------------------------------------
Test time: 11.908767223358154

Epoch: [19][77/391]	LR: 0.0001	Loss 1.6338 (1.6775)	Prec@1 37.500 (36.949)	
Epoch: [19][155/391]	LR: 0.0001	Loss 1.7480 (1.6779)	Prec@1 33.594 (36.824)	
Epoch: [19][233/391]	LR: 0.0001	Loss 1.5732 (1.6681)	Prec@1 42.969 (37.073)	
Epoch: [19][311/391]	LR: 0.0001	Loss 1.6709 (1.6700)	Prec@1 32.812 (36.972)	
Epoch: [19][389/391]	LR: 0.0001	Loss 1.9502 (1.6740)	Prec@1 32.812 (36.885)	
Total train loss: 1.6739

Train time: 9.18213701248169
 * Prec@1 84.410 Prec@5 98.870 Loss 0.7979
Best acc: 84.630
--------------------------------------------------------------------------------
Test time: 10.96345567703247

Epoch: [20][77/391]	LR: 1e-05	Loss 1.7549 (1.6688)	Prec@1 31.250 (36.709)	
Epoch: [20][155/391]	LR: 1e-05	Loss 1.5635 (1.6575)	Prec@1 39.844 (37.029)	
Epoch: [20][233/391]	LR: 1e-05	Loss 1.6797 (1.6627)	Prec@1 35.938 (37.063)	
Epoch: [20][311/391]	LR: 1e-05	Loss 1.5156 (1.6639)	Prec@1 37.500 (36.919)	
Epoch: [20][389/391]	LR: 1e-05	Loss 1.6416 (1.6672)	Prec@1 39.062 (36.815)	
Total train loss: 1.6682

Train time: 9.110329866409302
 * Prec@1 84.140 Prec@5 99.010 Loss 0.8091
Best acc: 84.630
--------------------------------------------------------------------------------
Test time: 11.222310781478882

Epoch: [21][77/391]	LR: 1e-05	Loss 1.9395 (1.6851)	Prec@1 31.250 (36.288)	
Epoch: [21][155/391]	LR: 1e-05	Loss 1.7100 (1.6692)	Prec@1 36.719 (36.769)	
Epoch: [21][233/391]	LR: 1e-05	Loss 1.5625 (1.6691)	Prec@1 41.406 (36.809)	
Epoch: [21][311/391]	LR: 1e-05	Loss 1.6836 (1.6710)	Prec@1 34.375 (36.831)	
Epoch: [21][389/391]	LR: 1e-05	Loss 1.8193 (1.6714)	Prec@1 32.812 (36.831)	
Total train loss: 1.6715

Train time: 9.122251987457275
 * Prec@1 84.160 Prec@5 98.920 Loss 0.7886
Best acc: 84.630
--------------------------------------------------------------------------------
Test time: 10.90797472000122

Epoch: [22][77/391]	LR: 1e-05	Loss 1.6680 (1.6920)	Prec@1 32.812 (36.028)	
Epoch: [22][155/391]	LR: 1e-05	Loss 2.0469 (1.6720)	Prec@1 35.156 (36.704)	
Epoch: [22][233/391]	LR: 1e-05	Loss 1.5684 (1.6670)	Prec@1 43.750 (36.912)	
Epoch: [22][311/391]	LR: 1e-05	Loss 1.7266 (1.6725)	Prec@1 32.031 (36.724)	
Epoch: [22][389/391]	LR: 1e-05	Loss 1.5029 (1.6751)	Prec@1 40.625 (36.675)	
Total train loss: 1.6753

Train time: 9.343544960021973
 * Prec@1 84.770 Prec@5 99.060 Loss 0.7676
Best acc: 84.770
--------------------------------------------------------------------------------
Test time: 11.491183042526245

Epoch: [23][77/391]	LR: 1e-05	Loss 1.6357 (1.6587)	Prec@1 36.719 (36.569)	
Epoch: [23][155/391]	LR: 1e-05	Loss 1.4697 (1.6733)	Prec@1 40.625 (36.533)	
Epoch: [23][233/391]	LR: 1e-05	Loss 1.6123 (1.6710)	Prec@1 38.281 (36.899)	
Epoch: [23][311/391]	LR: 1e-05	Loss 1.7686 (1.6741)	Prec@1 35.938 (36.771)	
Epoch: [23][389/391]	LR: 1e-05	Loss 1.7314 (1.6758)	Prec@1 32.812 (36.831)	
Total train loss: 1.6754

Train time: 8.864040613174438
 * Prec@1 85.140 Prec@5 99.120 Loss 0.7388
Best acc: 85.140
--------------------------------------------------------------------------------
Test time: 10.665673017501831

Epoch: [24][77/391]	LR: 1e-05	Loss 1.6611 (1.6877)	Prec@1 38.281 (37.119)	
Epoch: [24][155/391]	LR: 1e-05	Loss 1.6758 (1.6748)	Prec@1 37.500 (37.200)	
Epoch: [24][233/391]	LR: 1e-05	Loss 1.6729 (1.6825)	Prec@1 35.938 (36.869)	
Epoch: [24][311/391]	LR: 1e-05	Loss 1.7227 (1.6821)	Prec@1 39.062 (36.701)	
Epoch: [24][389/391]	LR: 1e-05	Loss 1.6240 (1.6804)	Prec@1 36.719 (36.743)	
Total train loss: 1.6806

Train time: 9.288455247879028
 * Prec@1 84.600 Prec@5 98.990 Loss 0.7725
Best acc: 85.140
--------------------------------------------------------------------------------
Test time: 11.765569686889648


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.0001
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 13
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.350 Prec@5 99.630 Loss 0.3262
Pre-trained Prec@1 with 13 layers frozen: 91.3499984741211 	 Loss: 0.326171875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.0001	Loss 2.5039 (2.4034)	Prec@1 26.562 (28.546)	
Epoch: [0][155/391]	LR: 0.0001	Loss 2.6074 (2.3145)	Prec@1 26.562 (29.132)	
Epoch: [0][233/391]	LR: 0.0001	Loss 2.1230 (2.2357)	Prec@1 28.125 (30.252)	
Epoch: [0][311/391]	LR: 0.0001	Loss 1.8398 (2.1949)	Prec@1 37.500 (30.471)	
Epoch: [0][389/391]	LR: 0.0001	Loss 2.0762 (2.1518)	Prec@1 28.125 (30.970)	
Total train loss: 2.1516

Train time: 210.79514455795288
 * Prec@1 72.980 Prec@5 96.510 Loss 1.5449
Best acc: 72.980
--------------------------------------------------------------------------------
Test time: 213.25194382667542

Epoch: [1][77/391]	LR: 0.0001	Loss 2.0918 (1.9817)	Prec@1 25.781 (33.183)	
Epoch: [1][155/391]	LR: 0.0001	Loss 1.6025 (1.9436)	Prec@1 43.750 (33.489)	
Epoch: [1][233/391]	LR: 0.0001	Loss 1.8164 (1.9275)	Prec@1 33.594 (33.423)	
Epoch: [1][311/391]	LR: 0.0001	Loss 2.4609 (1.9222)	Prec@1 21.875 (33.351)	
Epoch: [1][389/391]	LR: 0.0001	Loss 1.7969 (1.9127)	Prec@1 29.688 (33.452)	
Total train loss: 1.9127

Train time: 10.001629829406738
 * Prec@1 78.060 Prec@5 98.060 Loss 1.1436
Best acc: 78.060
--------------------------------------------------------------------------------
Test time: 12.115158557891846

Epoch: [2][77/391]	LR: 0.0001	Loss 1.8096 (1.8564)	Prec@1 35.156 (34.455)	
Epoch: [2][155/391]	LR: 0.0001	Loss 1.7998 (1.8470)	Prec@1 36.719 (34.440)	
Epoch: [2][233/391]	LR: 0.0001	Loss 2.1113 (1.8467)	Prec@1 30.469 (34.408)	
Epoch: [2][311/391]	LR: 0.0001	Loss 1.9209 (1.8411)	Prec@1 30.469 (34.490)	
Epoch: [2][389/391]	LR: 0.0001	Loss 1.6377 (1.8417)	Prec@1 36.719 (34.371)	
Total train loss: 1.8414

Train time: 8.90773892402649
 * Prec@1 79.750 Prec@5 98.290 Loss 1.0645
Best acc: 79.750
--------------------------------------------------------------------------------
Test time: 10.74769139289856

Epoch: [3][77/391]	LR: 0.0001	Loss 1.8574 (1.8159)	Prec@1 35.938 (34.736)	
Epoch: [3][155/391]	LR: 0.0001	Loss 1.6143 (1.8155)	Prec@1 36.719 (34.370)	
Epoch: [3][233/391]	LR: 0.0001	Loss 1.7178 (1.8063)	Prec@1 35.156 (34.692)	
Epoch: [3][311/391]	LR: 0.0001	Loss 1.6719 (1.8048)	Prec@1 35.156 (34.786)	
Epoch: [3][389/391]	LR: 0.0001	Loss 1.7354 (1.7984)	Prec@1 32.031 (34.940)	
Total train loss: 1.7990

Train time: 8.522652626037598
 * Prec@1 80.140 Prec@5 98.400 Loss 1.0254
Best acc: 80.140
--------------------------------------------------------------------------------
Test time: 10.801054000854492

Epoch: [4][77/391]	LR: 0.0001	Loss 1.7393 (1.7919)	Prec@1 32.812 (34.816)	
Epoch: [4][155/391]	LR: 0.0001	Loss 1.5850 (1.7781)	Prec@1 46.875 (35.251)	
Epoch: [4][233/391]	LR: 0.0001	Loss 1.8672 (1.7709)	Prec@1 31.250 (35.400)	
Epoch: [4][311/391]	LR: 0.0001	Loss 1.8066 (1.7753)	Prec@1 39.062 (35.439)	
Epoch: [4][389/391]	LR: 0.0001	Loss 1.5195 (1.7733)	Prec@1 43.750 (35.405)	
Total train loss: 1.7729

Train time: 8.390419006347656
 * Prec@1 81.350 Prec@5 98.610 Loss 0.9673
Best acc: 81.350
--------------------------------------------------------------------------------
Test time: 10.257408380508423

Epoch: [5][77/391]	LR: 0.0001	Loss 1.7236 (1.7811)	Prec@1 38.281 (35.086)	
Epoch: [5][155/391]	LR: 0.0001	Loss 1.8496 (1.7759)	Prec@1 34.375 (35.332)	
Epoch: [5][233/391]	LR: 0.0001	Loss 1.7441 (1.7650)	Prec@1 37.500 (35.427)	
Epoch: [5][311/391]	LR: 0.0001	Loss 1.5361 (1.7627)	Prec@1 43.750 (35.414)	
Epoch: [5][389/391]	LR: 0.0001	Loss 1.8184 (1.7552)	Prec@1 32.031 (35.545)	
Total train loss: 1.7552

Train time: 9.651212930679321
 * Prec@1 80.560 Prec@5 98.570 Loss 1.0215
Best acc: 81.350
--------------------------------------------------------------------------------
Test time: 11.883177518844604

Epoch: [6][77/391]	LR: 0.0001	Loss 1.7412 (1.7309)	Prec@1 33.594 (36.378)	
Epoch: [6][155/391]	LR: 0.0001	Loss 1.7803 (1.7303)	Prec@1 32.812 (36.368)	
Epoch: [6][233/391]	LR: 0.0001	Loss 1.7021 (1.7292)	Prec@1 37.500 (36.288)	
Epoch: [6][311/391]	LR: 0.0001	Loss 1.5557 (1.7344)	Prec@1 43.750 (36.000)	
Epoch: [6][389/391]	LR: 0.0001	Loss 1.6367 (1.7414)	Prec@1 38.281 (35.667)	
Total train loss: 1.7413

Train time: 8.054449558258057
 * Prec@1 81.570 Prec@5 98.780 Loss 0.9375
Best acc: 81.570
--------------------------------------------------------------------------------
Test time: 10.20871114730835

Epoch: [7][77/391]	LR: 0.0001	Loss 1.8096 (1.7517)	Prec@1 28.125 (35.226)	
Epoch: [7][155/391]	LR: 0.0001	Loss 1.7236 (1.7307)	Prec@1 30.469 (35.958)	
Epoch: [7][233/391]	LR: 0.0001	Loss 1.7227 (1.7336)	Prec@1 32.031 (35.697)	
Epoch: [7][311/391]	LR: 0.0001	Loss 1.5127 (1.7324)	Prec@1 42.969 (35.847)	
Epoch: [7][389/391]	LR: 0.0001	Loss 1.6963 (1.7298)	Prec@1 34.375 (35.891)	
Total train loss: 1.7302

Train time: 9.04781436920166
 * Prec@1 81.780 Prec@5 98.730 Loss 0.9482
Best acc: 81.780
--------------------------------------------------------------------------------
Test time: 11.241695165634155

Epoch: [8][77/391]	LR: 0.0001	Loss 1.5977 (1.7371)	Prec@1 40.625 (35.917)	
Epoch: [8][155/391]	LR: 0.0001	Loss 1.5752 (1.7270)	Prec@1 38.281 (36.273)	
Epoch: [8][233/391]	LR: 0.0001	Loss 1.5869 (1.7264)	Prec@1 39.844 (36.008)	
Epoch: [8][311/391]	LR: 0.0001	Loss 1.8594 (1.7240)	Prec@1 25.000 (36.013)	
Epoch: [8][389/391]	LR: 0.0001	Loss 1.9248 (1.7229)	Prec@1 28.906 (36.078)	
Total train loss: 1.7233

Train time: 8.783214092254639
 * Prec@1 83.170 Prec@5 98.850 Loss 0.8599
Best acc: 83.170
--------------------------------------------------------------------------------
Test time: 10.506428718566895

Epoch: [9][77/391]	LR: 0.0001	Loss 1.7891 (1.7061)	Prec@1 37.500 (36.328)	
Epoch: [9][155/391]	LR: 0.0001	Loss 1.5889 (1.7128)	Prec@1 38.281 (36.113)	
Epoch: [9][233/391]	LR: 0.0001	Loss 1.8125 (1.7007)	Prec@1 32.812 (36.351)	
Epoch: [9][311/391]	LR: 0.0001	Loss 1.8545 (1.7053)	Prec@1 35.156 (36.266)	
Epoch: [9][389/391]	LR: 0.0001	Loss 1.6943 (1.7089)	Prec@1 33.594 (36.030)	
Total train loss: 1.7091

Train time: 7.915844202041626
 * Prec@1 83.170 Prec@5 98.990 Loss 0.8418
Best acc: 83.170
--------------------------------------------------------------------------------
Test time: 10.023534774780273

Epoch: [10][77/391]	LR: 0.0001	Loss 1.7861 (1.7205)	Prec@1 32.812 (36.418)	
Epoch: [10][155/391]	LR: 0.0001	Loss 1.5234 (1.7028)	Prec@1 40.625 (36.468)	
Epoch: [10][233/391]	LR: 0.0001	Loss 1.8828 (1.7016)	Prec@1 29.688 (36.415)	
Epoch: [10][311/391]	LR: 0.0001	Loss 1.6143 (1.7017)	Prec@1 38.281 (36.463)	
Epoch: [10][389/391]	LR: 0.0001	Loss 1.7686 (1.7035)	Prec@1 35.938 (36.458)	
Total train loss: 1.7044

Train time: 7.963687419891357
 * Prec@1 82.700 Prec@5 98.850 Loss 0.8823
Best acc: 83.170
--------------------------------------------------------------------------------
Test time: 9.787169218063354

Epoch: [11][77/391]	LR: 0.0001	Loss 1.6123 (1.6998)	Prec@1 41.406 (36.318)	
Epoch: [11][155/391]	LR: 0.0001	Loss 1.6182 (1.6957)	Prec@1 36.719 (36.564)	
Epoch: [11][233/391]	LR: 0.0001	Loss 1.5879 (1.6992)	Prec@1 38.281 (36.542)	
Epoch: [11][311/391]	LR: 0.0001	Loss 1.8525 (1.6985)	Prec@1 31.250 (36.491)	
Epoch: [11][389/391]	LR: 0.0001	Loss 1.8516 (1.6984)	Prec@1 32.812 (36.504)	
Total train loss: 1.6984

Train time: 7.843728542327881
 * Prec@1 82.340 Prec@5 98.960 Loss 0.9048
Best acc: 83.170
--------------------------------------------------------------------------------
Test time: 10.09567928314209

Epoch: [12][77/391]	LR: 0.0001	Loss 1.9297 (1.6895)	Prec@1 29.688 (36.679)	
Epoch: [12][155/391]	LR: 0.0001	Loss 1.7705 (1.6848)	Prec@1 30.469 (36.679)	
Epoch: [12][233/391]	LR: 0.0001	Loss 1.6562 (1.6915)	Prec@1 35.938 (36.428)	
Epoch: [12][311/391]	LR: 0.0001	Loss 1.7178 (1.6927)	Prec@1 37.500 (36.481)	
Epoch: [12][389/391]	LR: 0.0001	Loss 1.4902 (1.6936)	Prec@1 42.969 (36.444)	
Total train loss: 1.6937

Train time: 7.702958822250366
 * Prec@1 83.530 Prec@5 98.990 Loss 0.8481
Best acc: 83.530
--------------------------------------------------------------------------------
Test time: 10.063576221466064

Epoch: [13][77/391]	LR: 0.0001	Loss 1.6494 (1.6795)	Prec@1 35.938 (36.679)	
Epoch: [13][155/391]	LR: 0.0001	Loss 1.5781 (1.6836)	Prec@1 41.406 (36.709)	
Epoch: [13][233/391]	LR: 0.0001	Loss 1.9258 (1.6804)	Prec@1 30.469 (36.745)	
Epoch: [13][311/391]	LR: 0.0001	Loss 1.5029 (1.6858)	Prec@1 44.531 (36.651)	
Epoch: [13][389/391]	LR: 0.0001	Loss 1.8018 (1.6895)	Prec@1 36.719 (36.510)	
Total train loss: 1.6897

Train time: 9.559755086898804
 * Prec@1 83.240 Prec@5 98.970 Loss 0.8423
Best acc: 83.530
--------------------------------------------------------------------------------
Test time: 11.746320724487305

Epoch: [14][77/391]	LR: 0.0001	Loss 1.7061 (1.6977)	Prec@1 35.938 (36.418)	
Epoch: [14][155/391]	LR: 0.0001	Loss 1.5684 (1.6916)	Prec@1 39.844 (36.513)	
Epoch: [14][233/391]	LR: 0.0001	Loss 1.5049 (1.6930)	Prec@1 41.406 (36.452)	
Epoch: [14][311/391]	LR: 0.0001	Loss 1.5264 (1.6903)	Prec@1 42.188 (36.684)	
Epoch: [14][389/391]	LR: 0.0001	Loss 1.9023 (1.6911)	Prec@1 31.250 (36.733)	
Total train loss: 1.6913

Train time: 8.224427223205566
 * Prec@1 83.370 Prec@5 98.960 Loss 0.8442
Best acc: 83.530
--------------------------------------------------------------------------------
Test time: 9.920531988143921

Epoch: [15][77/391]	LR: 0.0001	Loss 1.6484 (1.6747)	Prec@1 35.938 (37.059)	
Epoch: [15][155/391]	LR: 0.0001	Loss 1.7080 (1.6878)	Prec@1 37.500 (36.609)	
Epoch: [15][233/391]	LR: 0.0001	Loss 1.5400 (1.6804)	Prec@1 39.062 (36.695)	
Epoch: [15][311/391]	LR: 0.0001	Loss 1.9209 (1.6800)	Prec@1 32.812 (36.781)	
Epoch: [15][389/391]	LR: 0.0001	Loss 1.4756 (1.6862)	Prec@1 43.750 (36.659)	
Total train loss: 1.6863

Train time: 8.400135278701782
 * Prec@1 84.360 Prec@5 99.020 Loss 0.7705
Best acc: 84.360
--------------------------------------------------------------------------------
Test time: 10.595518589019775

Epoch: [16][77/391]	LR: 0.0001	Loss 1.6172 (1.6725)	Prec@1 39.062 (37.099)	
Epoch: [16][155/391]	LR: 0.0001	Loss 1.6826 (1.6801)	Prec@1 34.375 (36.939)	
Epoch: [16][233/391]	LR: 0.0001	Loss 1.8574 (1.6725)	Prec@1 27.344 (37.129)	
Epoch: [16][311/391]	LR: 0.0001	Loss 1.7002 (1.6771)	Prec@1 35.156 (36.922)	
Epoch: [16][389/391]	LR: 0.0001	Loss 1.4668 (1.6771)	Prec@1 45.312 (36.955)	
Total train loss: 1.6771

Train time: 9.19163703918457
 * Prec@1 84.410 Prec@5 99.100 Loss 0.8037
Best acc: 84.410
--------------------------------------------------------------------------------
Test time: 10.97438907623291

Epoch: [17][77/391]	LR: 0.0001	Loss 1.6611 (1.6805)	Prec@1 36.719 (37.069)	
Epoch: [17][155/391]	LR: 0.0001	Loss 1.8154 (1.6731)	Prec@1 31.250 (37.009)	
Epoch: [17][233/391]	LR: 0.0001	Loss 1.5859 (1.6769)	Prec@1 39.062 (36.882)	
Epoch: [17][311/391]	LR: 0.0001	Loss 1.8105 (1.6788)	Prec@1 28.906 (36.776)	
Epoch: [17][389/391]	LR: 0.0001	Loss 1.6357 (1.6778)	Prec@1 36.719 (36.851)	
Total train loss: 1.6778

Train time: 8.89428424835205
 * Prec@1 84.740 Prec@5 99.110 Loss 0.7646
Best acc: 84.740
--------------------------------------------------------------------------------
Test time: 11.184695482254028

Epoch: [18][77/391]	LR: 0.0001	Loss 1.7998 (1.6689)	Prec@1 32.031 (37.019)	
Epoch: [18][155/391]	LR: 0.0001	Loss 1.6865 (1.6713)	Prec@1 35.156 (37.064)	
Epoch: [18][233/391]	LR: 0.0001	Loss 1.6475 (1.6734)	Prec@1 37.500 (36.832)	
Epoch: [18][311/391]	LR: 0.0001	Loss 1.7471 (1.6769)	Prec@1 35.938 (36.816)	
Epoch: [18][389/391]	LR: 0.0001	Loss 1.6826 (1.6734)	Prec@1 35.938 (36.889)	
Total train loss: 1.6731

Train time: 8.550858497619629
 * Prec@1 84.840 Prec@5 99.180 Loss 0.7344
Best acc: 84.840
--------------------------------------------------------------------------------
Test time: 10.710453510284424

Epoch: [19][77/391]	LR: 0.0001	Loss 1.6650 (1.6722)	Prec@1 39.062 (37.190)	
Epoch: [19][155/391]	LR: 0.0001	Loss 1.7832 (1.6808)	Prec@1 33.594 (36.909)	
Epoch: [19][233/391]	LR: 0.0001	Loss 1.5752 (1.6748)	Prec@1 40.625 (36.862)	
Epoch: [19][311/391]	LR: 0.0001	Loss 1.7578 (1.6720)	Prec@1 35.938 (36.871)	
Epoch: [19][389/391]	LR: 0.0001	Loss 1.6709 (1.6739)	Prec@1 36.719 (36.827)	
Total train loss: 1.6736

Train time: 8.575320959091187
 * Prec@1 84.580 Prec@5 99.160 Loss 0.7812
Best acc: 84.840
--------------------------------------------------------------------------------
Test time: 10.756689548492432

Epoch: [20][77/391]	LR: 1e-05	Loss 1.6064 (1.6684)	Prec@1 39.062 (37.109)	
Epoch: [20][155/391]	LR: 1e-05	Loss 1.8232 (1.6766)	Prec@1 35.156 (36.879)	
Epoch: [20][233/391]	LR: 1e-05	Loss 1.4990 (1.6735)	Prec@1 45.312 (37.003)	
Epoch: [20][311/391]	LR: 1e-05	Loss 1.6953 (1.6737)	Prec@1 35.156 (36.932)	
Epoch: [20][389/391]	LR: 1e-05	Loss 1.7061 (1.6703)	Prec@1 36.719 (36.935)	
Total train loss: 1.6704

Train time: 8.617013692855835
 * Prec@1 84.510 Prec@5 99.130 Loss 0.7734
Best acc: 84.840
--------------------------------------------------------------------------------
Test time: 10.397246360778809

Epoch: [21][77/391]	LR: 1e-05	Loss 1.5811 (1.6616)	Prec@1 36.719 (36.789)	
Epoch: [21][155/391]	LR: 1e-05	Loss 1.7393 (1.6881)	Prec@1 35.938 (36.483)	
Epoch: [21][233/391]	LR: 1e-05	Loss 1.8594 (1.6717)	Prec@1 33.594 (36.952)	
Epoch: [21][311/391]	LR: 1e-05	Loss 1.6123 (1.6652)	Prec@1 39.062 (37.124)	
Epoch: [21][389/391]	LR: 1e-05	Loss 1.8613 (1.6693)	Prec@1 30.469 (36.869)	
Total train loss: 1.6699

Train time: 8.32769775390625
 * Prec@1 83.780 Prec@5 99.070 Loss 0.8188
Best acc: 84.840
--------------------------------------------------------------------------------
Test time: 10.499300241470337

Epoch: [22][77/391]	LR: 1e-05	Loss 1.8506 (1.6675)	Prec@1 32.031 (36.849)	
Epoch: [22][155/391]	LR: 1e-05	Loss 1.6006 (1.6715)	Prec@1 34.375 (36.664)	
Epoch: [22][233/391]	LR: 1e-05	Loss 1.6543 (1.6751)	Prec@1 35.156 (36.745)	
Epoch: [22][311/391]	LR: 1e-05	Loss 1.5820 (1.6806)	Prec@1 39.844 (36.571)	
Epoch: [22][389/391]	LR: 1e-05	Loss 1.6924 (1.6750)	Prec@1 35.156 (36.777)	
Total train loss: 1.6750

Train time: 8.504297733306885
 * Prec@1 84.910 Prec@5 99.160 Loss 0.7632
Best acc: 84.910
--------------------------------------------------------------------------------
Test time: 10.240504741668701

Epoch: [23][77/391]	LR: 1e-05	Loss 1.6953 (1.6841)	Prec@1 30.469 (36.729)	
Epoch: [23][155/391]	LR: 1e-05	Loss 1.6484 (1.6787)	Prec@1 38.281 (36.839)	
Epoch: [23][233/391]	LR: 1e-05	Loss 1.5918 (1.6773)	Prec@1 35.938 (36.789)	
Epoch: [23][311/391]	LR: 1e-05	Loss 1.6904 (1.6745)	Prec@1 34.375 (36.784)	
Epoch: [23][389/391]	LR: 1e-05	Loss 1.5986 (1.6712)	Prec@1 39.844 (36.837)	
Total train loss: 1.6714

Train time: 7.814145088195801
 * Prec@1 84.610 Prec@5 99.150 Loss 0.7744
Best acc: 84.910
--------------------------------------------------------------------------------
Test time: 10.087952613830566

Epoch: [24][77/391]	LR: 1e-05	Loss 1.6768 (1.6360)	Prec@1 31.250 (37.620)	
Epoch: [24][155/391]	LR: 1e-05	Loss 1.7168 (1.6584)	Prec@1 33.594 (37.109)	
Epoch: [24][233/391]	LR: 1e-05	Loss 1.6953 (1.6651)	Prec@1 33.594 (36.912)	
Epoch: [24][311/391]	LR: 1e-05	Loss 1.7666 (1.6698)	Prec@1 32.812 (36.796)	
Epoch: [24][389/391]	LR: 1e-05	Loss 1.7402 (1.6729)	Prec@1 34.375 (36.631)	
Total train loss: 1.6730

Train time: 7.9757795333862305
 * Prec@1 84.300 Prec@5 99.130 Loss 0.7788
Best acc: 84.910
--------------------------------------------------------------------------------
Test time: 10.168960809707642


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.0001
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 15
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.350 Prec@5 99.640 Loss 0.3293
Pre-trained Prec@1 with 15 layers frozen: 91.3499984741211 	 Loss: 0.329345703125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.0001	Loss 2.0293 (1.9572)	Prec@1 30.469 (34.235)	
Epoch: [0][155/391]	LR: 0.0001	Loss 1.8047 (1.9058)	Prec@1 36.719 (35.532)	
Epoch: [0][233/391]	LR: 0.0001	Loss 2.2676 (1.8811)	Prec@1 22.656 (35.764)	
Epoch: [0][311/391]	LR: 0.0001	Loss 1.9404 (1.8538)	Prec@1 32.812 (36.163)	
Epoch: [0][389/391]	LR: 0.0001	Loss 1.7021 (1.8382)	Prec@1 35.156 (36.176)	
Total train loss: 1.8386

Train time: 205.17399525642395
 * Prec@1 83.550 Prec@5 98.540 Loss 0.8950
Best acc: 83.550
--------------------------------------------------------------------------------
Test time: 207.797260761261

Epoch: [1][77/391]	LR: 0.0001	Loss 1.6914 (1.7588)	Prec@1 38.281 (36.819)	
Epoch: [1][155/391]	LR: 0.0001	Loss 1.6914 (1.7466)	Prec@1 43.750 (36.854)	
Epoch: [1][233/391]	LR: 0.0001	Loss 1.7510 (1.7364)	Prec@1 35.938 (37.213)	
Epoch: [1][311/391]	LR: 0.0001	Loss 1.7021 (1.7339)	Prec@1 35.156 (37.112)	
Epoch: [1][389/391]	LR: 0.0001	Loss 1.8887 (1.7308)	Prec@1 28.125 (37.061)	
Total train loss: 1.7311

Train time: 10.227804899215698
 * Prec@1 84.860 Prec@5 98.600 Loss 0.8320
Best acc: 84.860
--------------------------------------------------------------------------------
Test time: 12.417685270309448

Epoch: [2][77/391]	LR: 0.0001	Loss 1.7471 (1.6940)	Prec@1 39.844 (37.871)	
Epoch: [2][155/391]	LR: 0.0001	Loss 1.7148 (1.7010)	Prec@1 41.406 (37.510)	
Epoch: [2][233/391]	LR: 0.0001	Loss 1.5547 (1.6978)	Prec@1 39.062 (37.417)	
Epoch: [2][311/391]	LR: 0.0001	Loss 1.5020 (1.7023)	Prec@1 42.188 (37.200)	
Epoch: [2][389/391]	LR: 0.0001	Loss 2.2402 (1.6965)	Prec@1 22.656 (37.356)	
Total train loss: 1.6966

Train time: 7.308546304702759
 * Prec@1 85.690 Prec@5 98.840 Loss 0.8140
Best acc: 85.690
--------------------------------------------------------------------------------
Test time: 9.094244480133057

Epoch: [3][77/391]	LR: 0.0001	Loss 1.5498 (1.6796)	Prec@1 41.406 (37.690)	
Epoch: [3][155/391]	LR: 0.0001	Loss 1.4922 (1.6778)	Prec@1 46.094 (37.370)	
Epoch: [3][233/391]	LR: 0.0001	Loss 1.8770 (1.6753)	Prec@1 28.125 (37.427)	
Epoch: [3][311/391]	LR: 0.0001	Loss 1.9307 (1.6737)	Prec@1 28.906 (37.510)	
Epoch: [3][389/391]	LR: 0.0001	Loss 1.6758 (1.6708)	Prec@1 39.062 (37.692)	
Total train loss: 1.6709

Train time: 7.751657962799072
 * Prec@1 85.980 Prec@5 98.810 Loss 0.7617
Best acc: 85.980
--------------------------------------------------------------------------------
Test time: 9.943061351776123

Epoch: [4][77/391]	LR: 0.0001	Loss 1.7227 (1.6588)	Prec@1 39.062 (37.931)	
Epoch: [4][155/391]	LR: 0.0001	Loss 1.6406 (1.6663)	Prec@1 38.281 (37.665)	
Epoch: [4][233/391]	LR: 0.0001	Loss 1.4189 (1.6605)	Prec@1 48.438 (37.871)	
Epoch: [4][311/391]	LR: 0.0001	Loss 1.6279 (1.6616)	Prec@1 39.062 (37.826)	
Epoch: [4][389/391]	LR: 0.0001	Loss 1.7217 (1.6602)	Prec@1 34.375 (37.764)	
Total train loss: 1.6601

Train time: 7.239349126815796
 * Prec@1 86.250 Prec@5 98.940 Loss 0.7725
Best acc: 86.250
--------------------------------------------------------------------------------
Test time: 9.03177523612976

Epoch: [5][77/391]	LR: 0.0001	Loss 1.6289 (1.6443)	Prec@1 41.406 (37.560)	
Epoch: [5][155/391]	LR: 0.0001	Loss 1.7969 (1.6482)	Prec@1 35.156 (37.565)	
Epoch: [5][233/391]	LR: 0.0001	Loss 1.5713 (1.6459)	Prec@1 45.312 (37.664)	
Epoch: [5][311/391]	LR: 0.0001	Loss 1.7656 (1.6473)	Prec@1 32.812 (37.563)	
Epoch: [5][389/391]	LR: 0.0001	Loss 1.6729 (1.6443)	Prec@1 36.719 (37.724)	
Total train loss: 1.6441

Train time: 7.291209936141968
 * Prec@1 87.490 Prec@5 99.140 Loss 0.6826
Best acc: 87.490
--------------------------------------------------------------------------------
Test time: 9.533633708953857

Epoch: [6][77/391]	LR: 0.0001	Loss 1.5479 (1.6494)	Prec@1 42.969 (37.650)	
Epoch: [6][155/391]	LR: 0.0001	Loss 1.5088 (1.6427)	Prec@1 43.750 (37.805)	
Epoch: [6][233/391]	LR: 0.0001	Loss 1.6514 (1.6397)	Prec@1 39.844 (38.071)	
Epoch: [6][311/391]	LR: 0.0001	Loss 1.7031 (1.6404)	Prec@1 33.594 (37.978)	
Epoch: [6][389/391]	LR: 0.0001	Loss 1.6582 (1.6371)	Prec@1 34.375 (38.019)	
Total train loss: 1.6372

Train time: 7.355298042297363
 * Prec@1 87.210 Prec@5 99.140 Loss 0.6958
Best acc: 87.490
--------------------------------------------------------------------------------
Test time: 9.136924743652344

Epoch: [7][77/391]	LR: 0.0001	Loss 1.6338 (1.6315)	Prec@1 41.406 (38.381)	
Epoch: [7][155/391]	LR: 0.0001	Loss 1.7061 (1.6329)	Prec@1 32.031 (38.121)	
Epoch: [7][233/391]	LR: 0.0001	Loss 1.6055 (1.6311)	Prec@1 39.844 (38.251)	
Epoch: [7][311/391]	LR: 0.0001	Loss 1.6094 (1.6287)	Prec@1 34.375 (38.226)	
Epoch: [7][389/391]	LR: 0.0001	Loss 1.8730 (1.6345)	Prec@1 27.344 (38.047)	
Total train loss: 1.6349

Train time: 7.641648054122925
 * Prec@1 86.450 Prec@5 99.020 Loss 0.7354
Best acc: 87.490
--------------------------------------------------------------------------------
Test time: 10.117212295532227

Epoch: [8][77/391]	LR: 0.0001	Loss 1.7432 (1.6525)	Prec@1 35.156 (37.490)	
Epoch: [8][155/391]	LR: 0.0001	Loss 1.6426 (1.6489)	Prec@1 39.062 (37.490)	
Epoch: [8][233/391]	LR: 0.0001	Loss 1.5381 (1.6443)	Prec@1 39.844 (37.677)	
Epoch: [8][311/391]	LR: 0.0001	Loss 1.5586 (1.6377)	Prec@1 39.844 (37.931)	
Epoch: [8][389/391]	LR: 0.0001	Loss 1.5205 (1.6341)	Prec@1 42.188 (37.999)	
Total train loss: 1.6343

Train time: 8.127938270568848
 * Prec@1 87.460 Prec@5 99.150 Loss 0.6914
Best acc: 87.490
--------------------------------------------------------------------------------
Test time: 9.94262409210205

Epoch: [9][77/391]	LR: 0.0001	Loss 1.4131 (1.6092)	Prec@1 46.094 (39.213)	
Epoch: [9][155/391]	LR: 0.0001	Loss 1.5645 (1.6052)	Prec@1 42.969 (39.158)	
Epoch: [9][233/391]	LR: 0.0001	Loss 1.6846 (1.6126)	Prec@1 37.500 (38.782)	
Epoch: [9][311/391]	LR: 0.0001	Loss 1.6201 (1.6167)	Prec@1 37.500 (38.624)	
Epoch: [9][389/391]	LR: 0.0001	Loss 1.5596 (1.6260)	Prec@1 39.062 (38.215)	
Total train loss: 1.6258

Train time: 7.450009822845459
 * Prec@1 87.250 Prec@5 99.160 Loss 0.7056
Best acc: 87.490
--------------------------------------------------------------------------------
Test time: 9.564192295074463

Epoch: [10][77/391]	LR: 0.0001	Loss 1.3604 (1.6225)	Prec@1 48.438 (38.251)	
Epoch: [10][155/391]	LR: 0.0001	Loss 1.6670 (1.6094)	Prec@1 40.625 (38.627)	
Epoch: [10][233/391]	LR: 0.0001	Loss 1.6602 (1.6168)	Prec@1 35.156 (38.285)	
Epoch: [10][311/391]	LR: 0.0001	Loss 1.5879 (1.6207)	Prec@1 39.062 (38.154)	
Epoch: [10][389/391]	LR: 0.0001	Loss 1.5293 (1.6240)	Prec@1 42.188 (38.119)	
Total train loss: 1.6238

Train time: 7.1370017528533936
 * Prec@1 87.280 Prec@5 99.170 Loss 0.6689
Best acc: 87.490
--------------------------------------------------------------------------------
Test time: 8.911237955093384

Epoch: [11][77/391]	LR: 0.0001	Loss 1.5908 (1.6264)	Prec@1 41.406 (37.831)	
Epoch: [11][155/391]	LR: 0.0001	Loss 1.5156 (1.6165)	Prec@1 42.188 (38.171)	
Epoch: [11][233/391]	LR: 0.0001	Loss 1.8545 (1.6194)	Prec@1 32.031 (38.114)	
Epoch: [11][311/391]	LR: 0.0001	Loss 1.4531 (1.6174)	Prec@1 42.188 (38.108)	
Epoch: [11][389/391]	LR: 0.0001	Loss 1.6797 (1.6178)	Prec@1 32.031 (38.073)	
Total train loss: 1.6179

Train time: 7.151334524154663
 * Prec@1 87.600 Prec@5 99.280 Loss 0.6733
Best acc: 87.600
--------------------------------------------------------------------------------
Test time: 9.29587697982788

Epoch: [12][77/391]	LR: 0.0001	Loss 1.6650 (1.6232)	Prec@1 39.062 (37.951)	
Epoch: [12][155/391]	LR: 0.0001	Loss 1.4922 (1.6320)	Prec@1 39.844 (37.640)	
Epoch: [12][233/391]	LR: 0.0001	Loss 1.7256 (1.6256)	Prec@1 32.812 (37.847)	
Epoch: [12][311/391]	LR: 0.0001	Loss 1.5654 (1.6198)	Prec@1 39.062 (38.081)	
Epoch: [12][389/391]	LR: 0.0001	Loss 1.6133 (1.6186)	Prec@1 37.500 (38.173)	
Total train loss: 1.6183

Train time: 7.180183172225952
 * Prec@1 87.330 Prec@5 99.180 Loss 0.6958
Best acc: 87.600
--------------------------------------------------------------------------------
Test time: 8.824782848358154

Epoch: [13][77/391]	LR: 0.0001	Loss 1.6123 (1.6035)	Prec@1 38.281 (38.722)	
Epoch: [13][155/391]	LR: 0.0001	Loss 1.7266 (1.6120)	Prec@1 29.688 (38.381)	
Epoch: [13][233/391]	LR: 0.0001	Loss 1.5732 (1.6136)	Prec@1 39.062 (38.348)	
Epoch: [13][311/391]	LR: 0.0001	Loss 1.6211 (1.6127)	Prec@1 37.500 (38.284)	
Epoch: [13][389/391]	LR: 0.0001	Loss 1.7100 (1.6129)	Prec@1 32.031 (38.181)	
Total train loss: 1.6129

Train time: 7.411611795425415
 * Prec@1 87.740 Prec@5 99.210 Loss 0.6689
Best acc: 87.740
--------------------------------------------------------------------------------
Test time: 9.634367227554321

Epoch: [14][77/391]	LR: 0.0001	Loss 1.5625 (1.6297)	Prec@1 39.062 (37.200)	
Epoch: [14][155/391]	LR: 0.0001	Loss 1.5107 (1.6213)	Prec@1 42.188 (37.951)	
Epoch: [14][233/391]	LR: 0.0001	Loss 1.6787 (1.6177)	Prec@1 37.500 (38.204)	
Epoch: [14][311/391]	LR: 0.0001	Loss 1.4854 (1.6172)	Prec@1 42.969 (38.239)	
Epoch: [14][389/391]	LR: 0.0001	Loss 1.5400 (1.6152)	Prec@1 42.969 (38.387)	
Total train loss: 1.6150

Train time: 7.7377402782440186
 * Prec@1 87.960 Prec@5 99.190 Loss 0.6445
Best acc: 87.960
--------------------------------------------------------------------------------
Test time: 9.886464595794678

Epoch: [15][77/391]	LR: 0.0001	Loss 1.6504 (1.6370)	Prec@1 36.719 (37.580)	
Epoch: [15][155/391]	LR: 0.0001	Loss 1.5449 (1.6114)	Prec@1 39.844 (38.467)	
Epoch: [15][233/391]	LR: 0.0001	Loss 1.7275 (1.6079)	Prec@1 37.500 (38.592)	
Epoch: [15][311/391]	LR: 0.0001	Loss 1.4746 (1.6135)	Prec@1 43.750 (38.482)	
Epoch: [15][389/391]	LR: 0.0001	Loss 1.6973 (1.6153)	Prec@1 35.156 (38.500)	
Total train loss: 1.6158

Train time: 8.19689416885376
 * Prec@1 87.750 Prec@5 99.210 Loss 0.6606
Best acc: 87.960
--------------------------------------------------------------------------------
Test time: 10.380674839019775

Epoch: [16][77/391]	LR: 0.0001	Loss 1.8457 (1.6072)	Prec@1 32.812 (38.742)	
Epoch: [16][155/391]	LR: 0.0001	Loss 1.7188 (1.6161)	Prec@1 34.375 (38.436)	
Epoch: [16][233/391]	LR: 0.0001	Loss 1.6670 (1.6086)	Prec@1 32.031 (38.508)	
Epoch: [16][311/391]	LR: 0.0001	Loss 1.8701 (1.6117)	Prec@1 34.375 (38.379)	
Epoch: [16][389/391]	LR: 0.0001	Loss 1.6904 (1.6126)	Prec@1 35.938 (38.379)	
Total train loss: 1.6125

Train time: 7.476094484329224
 * Prec@1 87.830 Prec@5 99.210 Loss 0.6714
Best acc: 87.960
--------------------------------------------------------------------------------
Test time: 9.26010012626648

Epoch: [17][77/391]	LR: 0.0001	Loss 1.7207 (1.6190)	Prec@1 32.812 (37.851)	
Epoch: [17][155/391]	LR: 0.0001	Loss 1.6113 (1.6078)	Prec@1 39.844 (38.166)	
Epoch: [17][233/391]	LR: 0.0001	Loss 1.6191 (1.6104)	Prec@1 36.719 (38.151)	
Epoch: [17][311/391]	LR: 0.0001	Loss 1.4385 (1.6094)	Prec@1 44.531 (38.244)	
Epoch: [17][389/391]	LR: 0.0001	Loss 1.7803 (1.6079)	Prec@1 28.125 (38.283)	
Total train loss: 1.6076

Train time: 7.2490150928497314
 * Prec@1 88.100 Prec@5 99.210 Loss 0.6333
Best acc: 88.100
--------------------------------------------------------------------------------
Test time: 9.319039106369019

Epoch: [18][77/391]	LR: 0.0001	Loss 1.5020 (1.6148)	Prec@1 43.750 (38.231)	
Epoch: [18][155/391]	LR: 0.0001	Loss 1.6504 (1.6062)	Prec@1 41.406 (38.997)	
Epoch: [18][233/391]	LR: 0.0001	Loss 1.3701 (1.6073)	Prec@1 46.875 (38.805)	
Epoch: [18][311/391]	LR: 0.0001	Loss 2.0469 (1.6099)	Prec@1 28.125 (38.594)	
Epoch: [18][389/391]	LR: 0.0001	Loss 1.5645 (1.6100)	Prec@1 35.938 (38.544)	
Total train loss: 1.6097

Train time: 7.321346759796143
 * Prec@1 88.150 Prec@5 99.220 Loss 0.6367
Best acc: 88.150
--------------------------------------------------------------------------------
Test time: 9.000043869018555

Epoch: [19][77/391]	LR: 0.0001	Loss 1.5938 (1.6146)	Prec@1 41.406 (38.662)	
Epoch: [19][155/391]	LR: 0.0001	Loss 1.6455 (1.6114)	Prec@1 36.719 (38.487)	
Epoch: [19][233/391]	LR: 0.0001	Loss 1.6533 (1.6140)	Prec@1 37.500 (38.218)	
Epoch: [19][311/391]	LR: 0.0001	Loss 1.5488 (1.6075)	Prec@1 39.844 (38.424)	
Epoch: [19][389/391]	LR: 0.0001	Loss 1.5029 (1.6085)	Prec@1 39.844 (38.444)	
Total train loss: 1.6086

Train time: 7.303556680679321
 * Prec@1 88.030 Prec@5 99.250 Loss 0.6392
Best acc: 88.150
--------------------------------------------------------------------------------
Test time: 9.401742935180664

Epoch: [20][77/391]	LR: 1e-05	Loss 1.6631 (1.6110)	Prec@1 37.500 (38.161)	
Epoch: [20][155/391]	LR: 1e-05	Loss 1.6191 (1.6140)	Prec@1 35.938 (38.211)	
Epoch: [20][233/391]	LR: 1e-05	Loss 1.5713 (1.6114)	Prec@1 35.938 (38.094)	
Epoch: [20][311/391]	LR: 1e-05	Loss 1.5098 (1.6096)	Prec@1 41.406 (38.379)	
Epoch: [20][389/391]	LR: 1e-05	Loss 1.5898 (1.6073)	Prec@1 39.062 (38.446)	
Total train loss: 1.6073

Train time: 7.267370939254761
 * Prec@1 88.200 Prec@5 99.260 Loss 0.6426
Best acc: 88.200
--------------------------------------------------------------------------------
Test time: 9.042079210281372

Epoch: [21][77/391]	LR: 1e-05	Loss 1.6885 (1.5931)	Prec@1 33.594 (38.892)	
Epoch: [21][155/391]	LR: 1e-05	Loss 1.4004 (1.5896)	Prec@1 45.312 (39.002)	
Epoch: [21][233/391]	LR: 1e-05	Loss 1.6152 (1.5965)	Prec@1 40.625 (39.006)	
Epoch: [21][311/391]	LR: 1e-05	Loss 1.5947 (1.6033)	Prec@1 39.062 (38.722)	
Epoch: [21][389/391]	LR: 1e-05	Loss 1.7100 (1.6060)	Prec@1 34.375 (38.554)	
Total train loss: 1.6060

Train time: 7.602519989013672
 * Prec@1 87.630 Prec@5 99.170 Loss 0.6914
Best acc: 88.200
--------------------------------------------------------------------------------
Test time: 10.115818500518799

Epoch: [22][77/391]	LR: 1e-05	Loss 1.3887 (1.5902)	Prec@1 49.219 (38.702)	
Epoch: [22][155/391]	LR: 1e-05	Loss 1.3516 (1.6038)	Prec@1 46.875 (38.457)	
Epoch: [22][233/391]	LR: 1e-05	Loss 1.7559 (1.6073)	Prec@1 33.594 (38.472)	
Epoch: [22][311/391]	LR: 1e-05	Loss 1.5898 (1.6031)	Prec@1 40.625 (38.632)	
Epoch: [22][389/391]	LR: 1e-05	Loss 1.4492 (1.6055)	Prec@1 43.750 (38.594)	
Total train loss: 1.6054

Train time: 7.924449920654297
 * Prec@1 88.040 Prec@5 99.160 Loss 0.6494
Best acc: 88.200
--------------------------------------------------------------------------------
Test time: 9.632839441299438

Epoch: [23][77/391]	LR: 1e-05	Loss 1.6299 (1.6189)	Prec@1 39.062 (37.640)	
Epoch: [23][155/391]	LR: 1e-05	Loss 1.7266 (1.6175)	Prec@1 32.812 (37.790)	
Epoch: [23][233/391]	LR: 1e-05	Loss 1.5342 (1.6061)	Prec@1 44.531 (38.301)	
Epoch: [23][311/391]	LR: 1e-05	Loss 1.4336 (1.5972)	Prec@1 44.531 (38.722)	
Epoch: [23][389/391]	LR: 1e-05	Loss 1.6562 (1.6088)	Prec@1 41.406 (38.494)	
Total train loss: 1.6095

Train time: 7.348912239074707
 * Prec@1 87.960 Prec@5 99.190 Loss 0.6646
Best acc: 88.200
--------------------------------------------------------------------------------
Test time: 9.573724269866943

Epoch: [24][77/391]	LR: 1e-05	Loss 1.6270 (1.6349)	Prec@1 35.938 (37.911)	
Epoch: [24][155/391]	LR: 1e-05	Loss 1.6348 (1.6163)	Prec@1 36.719 (38.697)	
Epoch: [24][233/391]	LR: 1e-05	Loss 1.5215 (1.6102)	Prec@1 42.188 (38.739)	
Epoch: [24][311/391]	LR: 1e-05	Loss 1.4814 (1.6093)	Prec@1 40.625 (38.662)	
Epoch: [24][389/391]	LR: 1e-05	Loss 1.5986 (1.6100)	Prec@1 42.969 (38.614)	
Total train loss: 1.6104

Train time: 7.330724000930786
 * Prec@1 88.290 Prec@5 99.300 Loss 0.6265
Best acc: 88.290
--------------------------------------------------------------------------------
Test time: 9.088468790054321


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.0001
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 17
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.330 Prec@5 99.620 Loss 0.3279
Pre-trained Prec@1 with 17 layers frozen: 91.32999420166016 	 Loss: 0.327880859375

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.0001	Loss 1.9053 (1.8069)	Prec@1 33.594 (38.021)	
Epoch: [0][155/391]	LR: 0.0001	Loss 1.7285 (1.7881)	Prec@1 35.938 (37.956)	
Epoch: [0][233/391]	LR: 0.0001	Loss 1.7285 (1.7687)	Prec@1 40.625 (38.044)	
Epoch: [0][311/391]	LR: 0.0001	Loss 1.7070 (1.7562)	Prec@1 37.500 (38.023)	
Epoch: [0][389/391]	LR: 0.0001	Loss 1.5957 (1.7466)	Prec@1 40.625 (38.057)	
Total train loss: 1.7464

Train time: 129.82525038719177
 * Prec@1 87.190 Prec@5 98.950 Loss 0.6689
Best acc: 87.190
--------------------------------------------------------------------------------
Test time: 132.49198651313782

Epoch: [1][77/391]	LR: 0.0001	Loss 1.6709 (1.7173)	Prec@1 39.062 (37.370)	
Epoch: [1][155/391]	LR: 0.0001	Loss 1.7217 (1.6982)	Prec@1 35.938 (37.946)	
Epoch: [1][233/391]	LR: 0.0001	Loss 1.6445 (1.6933)	Prec@1 38.281 (38.044)	
Epoch: [1][311/391]	LR: 0.0001	Loss 1.5605 (1.6842)	Prec@1 42.969 (38.246)	
Epoch: [1][389/391]	LR: 0.0001	Loss 1.4951 (1.6785)	Prec@1 44.531 (38.281)	
Total train loss: 1.6784

Train time: 9.85464596748352
 * Prec@1 87.450 Prec@5 99.060 Loss 0.6587
Best acc: 87.450
--------------------------------------------------------------------------------
Test time: 12.185600280761719

Epoch: [2][77/391]	LR: 0.0001	Loss 1.8486 (1.6489)	Prec@1 29.688 (38.181)	
Epoch: [2][155/391]	LR: 0.0001	Loss 1.6074 (1.6573)	Prec@1 40.625 (38.021)	
Epoch: [2][233/391]	LR: 0.0001	Loss 1.7998 (1.6550)	Prec@1 29.688 (38.208)	
Epoch: [2][311/391]	LR: 0.0001	Loss 1.5771 (1.6576)	Prec@1 38.281 (38.021)	
Epoch: [2][389/391]	LR: 0.0001	Loss 1.6973 (1.6493)	Prec@1 37.500 (38.319)	
Total train loss: 1.6491

Train time: 7.514794826507568
 * Prec@1 87.560 Prec@5 99.000 Loss 0.6377
Best acc: 87.560
--------------------------------------------------------------------------------
Test time: 9.239089250564575

Epoch: [3][77/391]	LR: 0.0001	Loss 1.5586 (1.6317)	Prec@1 42.188 (38.542)	
Epoch: [3][155/391]	LR: 0.0001	Loss 1.6357 (1.6277)	Prec@1 35.156 (38.822)	
Epoch: [3][233/391]	LR: 0.0001	Loss 1.6406 (1.6293)	Prec@1 38.281 (38.752)	
Epoch: [3][311/391]	LR: 0.0001	Loss 1.5195 (1.6305)	Prec@1 41.406 (38.634)	
Epoch: [3][389/391]	LR: 0.0001	Loss 1.7656 (1.6357)	Prec@1 35.938 (38.427)	
Total train loss: 1.6360

Train time: 7.469075918197632
 * Prec@1 87.320 Prec@5 99.020 Loss 0.6802
Best acc: 87.560
--------------------------------------------------------------------------------
Test time: 9.675348043441772

Epoch: [4][77/391]	LR: 0.0001	Loss 1.3594 (1.6157)	Prec@1 47.656 (38.121)	
Epoch: [4][155/391]	LR: 0.0001	Loss 1.5957 (1.6271)	Prec@1 38.281 (38.091)	
Epoch: [4][233/391]	LR: 0.0001	Loss 1.5527 (1.6243)	Prec@1 41.406 (38.191)	
Epoch: [4][311/391]	LR: 0.0001	Loss 1.6016 (1.6297)	Prec@1 37.500 (38.123)	
Epoch: [4][389/391]	LR: 0.0001	Loss 1.5693 (1.6278)	Prec@1 39.062 (38.297)	
Total train loss: 1.6275

Train time: 7.281511545181274
 * Prec@1 87.660 Prec@5 99.160 Loss 0.6348
Best acc: 87.660
--------------------------------------------------------------------------------
Test time: 8.981667518615723

Epoch: [5][77/391]	LR: 0.0001	Loss 1.5410 (1.6131)	Prec@1 39.844 (38.892)	
Epoch: [5][155/391]	LR: 0.0001	Loss 1.4551 (1.6193)	Prec@1 41.406 (38.637)	
Epoch: [5][233/391]	LR: 0.0001	Loss 2.0117 (1.6281)	Prec@1 26.562 (38.395)	
Epoch: [5][311/391]	LR: 0.0001	Loss 1.5879 (1.6224)	Prec@1 35.156 (38.497)	
Epoch: [5][389/391]	LR: 0.0001	Loss 1.3740 (1.6184)	Prec@1 43.750 (38.548)	
Total train loss: 1.6190

Train time: 7.2992634773254395
 * Prec@1 87.630 Prec@5 99.110 Loss 0.6396
Best acc: 87.660
--------------------------------------------------------------------------------
Test time: 9.390491724014282

Epoch: [6][77/391]	LR: 0.0001	Loss 1.6221 (1.5994)	Prec@1 37.500 (38.902)	
Epoch: [6][155/391]	LR: 0.0001	Loss 1.5615 (1.6078)	Prec@1 42.188 (38.682)	
Epoch: [6][233/391]	LR: 0.0001	Loss 1.7207 (1.6129)	Prec@1 34.375 (38.458)	
Epoch: [6][311/391]	LR: 0.0001	Loss 1.5781 (1.6162)	Prec@1 36.719 (38.274)	
Epoch: [6][389/391]	LR: 0.0001	Loss 1.6924 (1.6133)	Prec@1 35.938 (38.391)	
Total train loss: 1.6132

Train time: 7.447666168212891
 * Prec@1 87.680 Prec@5 99.090 Loss 0.6538
Best acc: 87.680
--------------------------------------------------------------------------------
Test time: 9.247211217880249

Epoch: [7][77/391]	LR: 0.0001	Loss 1.6162 (1.6088)	Prec@1 36.719 (38.662)	
Epoch: [7][155/391]	LR: 0.0001	Loss 1.2998 (1.6149)	Prec@1 47.656 (38.512)	
Epoch: [7][233/391]	LR: 0.0001	Loss 1.5820 (1.6107)	Prec@1 41.406 (38.612)	
Epoch: [7][311/391]	LR: 0.0001	Loss 1.5537 (1.6125)	Prec@1 38.281 (38.529)	
Epoch: [7][389/391]	LR: 0.0001	Loss 1.4805 (1.6125)	Prec@1 44.531 (38.528)	
Total train loss: 1.6129

Train time: 7.457610845565796
 * Prec@1 87.550 Prec@5 99.110 Loss 0.6519
Best acc: 87.680
--------------------------------------------------------------------------------
Test time: 10.086660861968994

Epoch: [8][77/391]	LR: 0.0001	Loss 1.6016 (1.6057)	Prec@1 37.500 (38.552)	
Epoch: [8][155/391]	LR: 0.0001	Loss 1.4873 (1.6051)	Prec@1 44.531 (38.547)	
Epoch: [8][233/391]	LR: 0.0001	Loss 1.3379 (1.6036)	Prec@1 48.438 (38.665)	
Epoch: [8][311/391]	LR: 0.0001	Loss 1.5146 (1.6051)	Prec@1 42.969 (38.582)	
Epoch: [8][389/391]	LR: 0.0001	Loss 1.7520 (1.6097)	Prec@1 35.156 (38.411)	
Total train loss: 1.6099

Train time: 7.965090036392212
 * Prec@1 87.760 Prec@5 99.120 Loss 0.6543
Best acc: 87.760
--------------------------------------------------------------------------------
Test time: 9.707868814468384

Epoch: [9][77/391]	LR: 0.0001	Loss 1.5361 (1.6062)	Prec@1 41.406 (38.251)	
Epoch: [9][155/391]	LR: 0.0001	Loss 1.6592 (1.6029)	Prec@1 40.625 (38.597)	
Epoch: [9][233/391]	LR: 0.0001	Loss 1.6074 (1.6034)	Prec@1 39.062 (38.495)	
Epoch: [9][311/391]	LR: 0.0001	Loss 1.5244 (1.6041)	Prec@1 42.188 (38.594)	
Epoch: [9][389/391]	LR: 0.0001	Loss 1.5713 (1.6020)	Prec@1 43.750 (38.666)	
Total train loss: 1.6021

Train time: 7.422612428665161
 * Prec@1 87.820 Prec@5 99.160 Loss 0.6377
Best acc: 87.820
--------------------------------------------------------------------------------
Test time: 9.561848640441895

Epoch: [10][77/391]	LR: 0.0001	Loss 1.3828 (1.6086)	Prec@1 43.750 (38.762)	
Epoch: [10][155/391]	LR: 0.0001	Loss 1.6338 (1.6120)	Prec@1 35.156 (38.492)	
Epoch: [10][233/391]	LR: 0.0001	Loss 1.4375 (1.6116)	Prec@1 42.969 (38.408)	
Epoch: [10][311/391]	LR: 0.0001	Loss 1.6611 (1.6063)	Prec@1 38.281 (38.609)	
Epoch: [10][389/391]	LR: 0.0001	Loss 1.6699 (1.6071)	Prec@1 35.156 (38.628)	
Total train loss: 1.6071

Train time: 7.126742839813232
 * Prec@1 88.010 Prec@5 99.180 Loss 0.6274
Best acc: 88.010
--------------------------------------------------------------------------------
Test time: 8.878121614456177

Epoch: [11][77/391]	LR: 0.0001	Loss 1.3594 (1.6087)	Prec@1 45.312 (38.442)	
Epoch: [11][155/391]	LR: 0.0001	Loss 1.8115 (1.6029)	Prec@1 31.250 (38.577)	
Epoch: [11][233/391]	LR: 0.0001	Loss 1.5684 (1.6016)	Prec@1 36.719 (38.638)	
Epoch: [11][311/391]	LR: 0.0001	Loss 1.6504 (1.6054)	Prec@1 37.500 (38.564)	
Epoch: [11][389/391]	LR: 0.0001	Loss 1.5830 (1.6002)	Prec@1 39.062 (38.722)	
Total train loss: 1.6003

Train time: 7.187377691268921
 * Prec@1 88.030 Prec@5 99.210 Loss 0.6152
Best acc: 88.030
--------------------------------------------------------------------------------
Test time: 9.258457660675049

Epoch: [12][77/391]	LR: 0.0001	Loss 1.6074 (1.6083)	Prec@1 39.062 (38.111)	
Epoch: [12][155/391]	LR: 0.0001	Loss 1.7461 (1.6077)	Prec@1 33.594 (38.266)	
Epoch: [12][233/391]	LR: 0.0001	Loss 1.4404 (1.6085)	Prec@1 43.750 (38.351)	
Epoch: [12][311/391]	LR: 0.0001	Loss 1.5439 (1.6079)	Prec@1 37.500 (38.361)	
Epoch: [12][389/391]	LR: 0.0001	Loss 1.6611 (1.6038)	Prec@1 36.719 (38.466)	
Total train loss: 1.6038

Train time: 7.316492557525635
 * Prec@1 88.140 Prec@5 99.220 Loss 0.6226
Best acc: 88.140
--------------------------------------------------------------------------------
Test time: 9.061541318893433

Epoch: [13][77/391]	LR: 0.0001	Loss 1.5215 (1.6013)	Prec@1 41.406 (38.482)	
Epoch: [13][155/391]	LR: 0.0001	Loss 1.5322 (1.5965)	Prec@1 41.406 (38.862)	
Epoch: [13][233/391]	LR: 0.0001	Loss 1.5889 (1.5912)	Prec@1 38.281 (39.103)	
Epoch: [13][311/391]	LR: 0.0001	Loss 1.5693 (1.5957)	Prec@1 39.062 (38.850)	
Epoch: [13][389/391]	LR: 0.0001	Loss 1.6738 (1.5975)	Prec@1 39.062 (38.782)	
Total train loss: 1.5977

Train time: 7.13084864616394
 * Prec@1 88.010 Prec@5 99.180 Loss 0.6406
Best acc: 88.140
--------------------------------------------------------------------------------
Test time: 9.21017336845398

Epoch: [14][77/391]	LR: 0.0001	Loss 1.5352 (1.6043)	Prec@1 41.406 (38.652)	
Epoch: [14][155/391]	LR: 0.0001	Loss 1.6426 (1.6117)	Prec@1 38.281 (38.497)	
Epoch: [14][233/391]	LR: 0.0001	Loss 1.5068 (1.6068)	Prec@1 42.188 (38.762)	
Epoch: [14][311/391]	LR: 0.0001	Loss 1.5811 (1.6067)	Prec@1 42.188 (38.757)	
Epoch: [14][389/391]	LR: 0.0001	Loss 1.7744 (1.6034)	Prec@1 32.812 (38.846)	
Total train loss: 1.6031

Train time: 7.288400650024414
 * Prec@1 88.310 Prec@5 99.260 Loss 0.6001
Best acc: 88.310
--------------------------------------------------------------------------------
Test time: 9.417803525924683

Epoch: [15][77/391]	LR: 0.0001	Loss 1.6328 (1.5876)	Prec@1 37.500 (39.083)	
Epoch: [15][155/391]	LR: 0.0001	Loss 1.4092 (1.5936)	Prec@1 43.750 (38.917)	
Epoch: [15][233/391]	LR: 0.0001	Loss 1.4102 (1.6011)	Prec@1 47.656 (38.759)	
Epoch: [15][311/391]	LR: 0.0001	Loss 1.5811 (1.5983)	Prec@1 39.844 (38.742)	
Epoch: [15][389/391]	LR: 0.0001	Loss 1.5615 (1.5964)	Prec@1 38.281 (38.754)	
Total train loss: 1.5965

Train time: 7.940541982650757
 * Prec@1 88.250 Prec@5 99.270 Loss 0.6182
Best acc: 88.310
--------------------------------------------------------------------------------
Test time: 10.231797456741333

Epoch: [16][77/391]	LR: 0.0001	Loss 1.5068 (1.6087)	Prec@1 40.625 (37.851)	
Epoch: [16][155/391]	LR: 0.0001	Loss 1.5215 (1.5949)	Prec@1 39.844 (38.727)	
Epoch: [16][233/391]	LR: 0.0001	Loss 1.5771 (1.5936)	Prec@1 39.062 (38.812)	
Epoch: [16][311/391]	LR: 0.0001	Loss 1.6982 (1.5982)	Prec@1 32.031 (38.497)	
Epoch: [16][389/391]	LR: 0.0001	Loss 1.6123 (1.5973)	Prec@1 33.594 (38.494)	
Total train loss: 1.5971

Train time: 7.083056449890137
 * Prec@1 88.210 Prec@5 99.220 Loss 0.6162
Best acc: 88.310
--------------------------------------------------------------------------------
Test time: 8.732006072998047

Epoch: [17][77/391]	LR: 0.0001	Loss 1.6113 (1.6025)	Prec@1 38.281 (38.882)	
Epoch: [17][155/391]	LR: 0.0001	Loss 1.5693 (1.5933)	Prec@1 37.500 (39.022)	
Epoch: [17][233/391]	LR: 0.0001	Loss 1.7344 (1.5940)	Prec@1 34.375 (38.942)	
Epoch: [17][311/391]	LR: 0.0001	Loss 1.5293 (1.5954)	Prec@1 42.969 (38.890)	
Epoch: [17][389/391]	LR: 0.0001	Loss 1.5195 (1.5954)	Prec@1 40.625 (38.842)	
Total train loss: 1.5951

Train time: 7.226411819458008
 * Prec@1 88.200 Prec@5 99.230 Loss 0.6211
Best acc: 88.310
--------------------------------------------------------------------------------
Test time: 9.592970371246338

Epoch: [18][77/391]	LR: 0.0001	Loss 1.6348 (1.5946)	Prec@1 38.281 (38.982)	
Epoch: [18][155/391]	LR: 0.0001	Loss 1.5947 (1.5834)	Prec@1 37.500 (39.203)	
Epoch: [18][233/391]	LR: 0.0001	Loss 1.6836 (1.5840)	Prec@1 35.156 (39.052)	
Epoch: [18][311/391]	LR: 0.0001	Loss 1.5762 (1.5920)	Prec@1 39.062 (38.797)	
Epoch: [18][389/391]	LR: 0.0001	Loss 1.4424 (1.5923)	Prec@1 43.750 (38.818)	
Total train loss: 1.5922

Train time: 7.34485650062561
 * Prec@1 88.560 Prec@5 99.250 Loss 0.6089
Best acc: 88.560
--------------------------------------------------------------------------------
Test time: 9.025077819824219

Epoch: [19][77/391]	LR: 0.0001	Loss 1.4961 (1.5994)	Prec@1 46.875 (38.892)	
Epoch: [19][155/391]	LR: 0.0001	Loss 1.5713 (1.5921)	Prec@1 41.406 (38.722)	
Epoch: [19][233/391]	LR: 0.0001	Loss 1.6943 (1.5955)	Prec@1 35.938 (38.568)	
Epoch: [19][311/391]	LR: 0.0001	Loss 1.5781 (1.5970)	Prec@1 39.844 (38.504)	
Epoch: [19][389/391]	LR: 0.0001	Loss 1.5684 (1.5958)	Prec@1 35.938 (38.640)	
Total train loss: 1.5957

Train time: 7.263745546340942
 * Prec@1 88.480 Prec@5 99.300 Loss 0.5977
Best acc: 88.560
--------------------------------------------------------------------------------
Test time: 9.330835103988647

Epoch: [20][77/391]	LR: 1e-05	Loss 1.8193 (1.5970)	Prec@1 30.469 (38.792)	
Epoch: [20][155/391]	LR: 1e-05	Loss 1.5117 (1.5922)	Prec@1 41.406 (38.932)	
Epoch: [20][233/391]	LR: 1e-05	Loss 1.5986 (1.5984)	Prec@1 38.281 (38.719)	
Epoch: [20][311/391]	LR: 1e-05	Loss 1.6543 (1.5968)	Prec@1 35.938 (38.749)	
Epoch: [20][389/391]	LR: 1e-05	Loss 1.4600 (1.5954)	Prec@1 42.188 (38.846)	
Total train loss: 1.5955

Train time: 7.220795392990112
 * Prec@1 88.450 Prec@5 99.300 Loss 0.5962
Best acc: 88.560
--------------------------------------------------------------------------------
Test time: 8.91257905960083

Epoch: [21][77/391]	LR: 1e-05	Loss 1.6533 (1.5787)	Prec@1 34.375 (38.972)	
Epoch: [21][155/391]	LR: 1e-05	Loss 1.2715 (1.5797)	Prec@1 53.125 (39.078)	
Epoch: [21][233/391]	LR: 1e-05	Loss 1.6240 (1.5850)	Prec@1 34.375 (38.949)	
Epoch: [21][311/391]	LR: 1e-05	Loss 1.6797 (1.5942)	Prec@1 34.375 (38.609)	
Epoch: [21][389/391]	LR: 1e-05	Loss 1.6074 (1.5965)	Prec@1 38.281 (38.524)	
Total train loss: 1.5967

Train time: 7.433365821838379
 * Prec@1 88.400 Prec@5 99.260 Loss 0.5991
Best acc: 88.560
--------------------------------------------------------------------------------
Test time: 10.027947902679443

Epoch: [22][77/391]	LR: 1e-05	Loss 1.6006 (1.6140)	Prec@1 35.938 (38.021)	
Epoch: [22][155/391]	LR: 1e-05	Loss 1.6914 (1.6003)	Prec@1 39.844 (38.442)	
Epoch: [22][233/391]	LR: 1e-05	Loss 1.5449 (1.5945)	Prec@1 42.969 (38.732)	
Epoch: [22][311/391]	LR: 1e-05	Loss 1.6025 (1.5989)	Prec@1 38.281 (38.604)	
Epoch: [22][389/391]	LR: 1e-05	Loss 1.4648 (1.5968)	Prec@1 44.531 (38.660)	
Total train loss: 1.5965

Train time: 7.844040632247925
 * Prec@1 88.520 Prec@5 99.290 Loss 0.5791
Best acc: 88.560
--------------------------------------------------------------------------------
Test time: 9.5727698802948

Epoch: [23][77/391]	LR: 1e-05	Loss 1.6445 (1.5872)	Prec@1 37.500 (39.052)	
Epoch: [23][155/391]	LR: 1e-05	Loss 1.6357 (1.5896)	Prec@1 37.500 (39.093)	
Epoch: [23][233/391]	LR: 1e-05	Loss 1.5273 (1.5895)	Prec@1 41.406 (39.049)	
Epoch: [23][311/391]	LR: 1e-05	Loss 1.6816 (1.5949)	Prec@1 36.719 (38.905)	
Epoch: [23][389/391]	LR: 1e-05	Loss 1.5918 (1.5991)	Prec@1 37.500 (38.668)	
Total train loss: 1.5991

Train time: 7.308873176574707
 * Prec@1 88.430 Prec@5 99.200 Loss 0.6157
Best acc: 88.560
--------------------------------------------------------------------------------
Test time: 9.466618299484253

Epoch: [24][77/391]	LR: 1e-05	Loss 1.5371 (1.5958)	Prec@1 46.094 (39.233)	
Epoch: [24][155/391]	LR: 1e-05	Loss 2.0332 (1.6059)	Prec@1 26.562 (38.602)	
Epoch: [24][233/391]	LR: 1e-05	Loss 1.5625 (1.6024)	Prec@1 41.406 (38.425)	
Epoch: [24][311/391]	LR: 1e-05	Loss 1.7383 (1.5994)	Prec@1 32.031 (38.519)	
Epoch: [24][389/391]	LR: 1e-05	Loss 1.4268 (1.5963)	Prec@1 39.844 (38.682)	
Total train loss: 1.5962

Train time: 7.215022087097168
 * Prec@1 88.640 Prec@5 99.250 Loss 0.5874
Best acc: 88.640
--------------------------------------------------------------------------------
Test time: 8.91188645362854


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.0001
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 19
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.370 Prec@5 99.620 Loss 0.3276
Pre-trained Prec@1 with 19 layers frozen: 91.3699951171875 	 Loss: 0.32763671875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.0001	Loss 1.5059 (1.7130)	Prec@1 46.094 (39.573)	
Epoch: [0][155/391]	LR: 0.0001	Loss 1.7227 (1.7141)	Prec@1 32.812 (39.027)	
Epoch: [0][233/391]	LR: 0.0001	Loss 1.7705 (1.6916)	Prec@1 35.938 (39.530)	
Epoch: [0][311/391]	LR: 0.0001	Loss 1.6152 (1.6828)	Prec@1 41.406 (39.631)	
Epoch: [0][389/391]	LR: 0.0001	Loss 1.6133 (1.6746)	Prec@1 41.406 (39.571)	
Total train loss: 1.6746

Train time: 61.74414300918579
 * Prec@1 91.360 Prec@5 99.570 Loss 0.4788
Best acc: 91.360
--------------------------------------------------------------------------------
Test time: 64.82682037353516

Epoch: [1][77/391]	LR: 0.0001	Loss 1.6436 (1.6236)	Prec@1 39.062 (39.964)	
Epoch: [1][155/391]	LR: 0.0001	Loss 1.6895 (1.6310)	Prec@1 34.375 (39.438)	
Epoch: [1][233/391]	LR: 0.0001	Loss 1.7109 (1.6242)	Prec@1 36.719 (39.600)	
Epoch: [1][311/391]	LR: 0.0001	Loss 1.5312 (1.6288)	Prec@1 43.750 (39.243)	
Epoch: [1][389/391]	LR: 0.0001	Loss 1.5986 (1.6228)	Prec@1 39.844 (39.477)	
Total train loss: 1.6228

Train time: 9.430878400802612
 * Prec@1 91.590 Prec@5 99.650 Loss 0.4680
Best acc: 91.590
--------------------------------------------------------------------------------
Test time: 11.421370267868042

Epoch: [2][77/391]	LR: 0.0001	Loss 1.6572 (1.6133)	Prec@1 40.625 (39.663)	
Epoch: [2][155/391]	LR: 0.0001	Loss 1.5908 (1.6093)	Prec@1 38.281 (39.608)	
Epoch: [2][233/391]	LR: 0.0001	Loss 1.6807 (1.6036)	Prec@1 34.375 (39.911)	
Epoch: [2][311/391]	LR: 0.0001	Loss 1.5889 (1.6039)	Prec@1 41.406 (39.801)	
Epoch: [2][389/391]	LR: 0.0001	Loss 1.5908 (1.6033)	Prec@1 42.188 (39.690)	
Total train loss: 1.6032

Train time: 7.106127738952637
 * Prec@1 91.690 Prec@5 99.640 Loss 0.4529
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 8.955891370773315

Epoch: [3][77/391]	LR: 0.0001	Loss 1.4453 (1.6047)	Prec@1 43.750 (39.002)	
Epoch: [3][155/391]	LR: 0.0001	Loss 1.6182 (1.6009)	Prec@1 36.719 (39.263)	
Epoch: [3][233/391]	LR: 0.0001	Loss 1.4824 (1.5970)	Prec@1 46.094 (39.543)	
Epoch: [3][311/391]	LR: 0.0001	Loss 1.5195 (1.5967)	Prec@1 42.969 (39.463)	
Epoch: [3][389/391]	LR: 0.0001	Loss 1.7197 (1.5914)	Prec@1 35.938 (39.611)	
Total train loss: 1.5916

Train time: 7.943264484405518
 * Prec@1 91.620 Prec@5 99.650 Loss 0.4675
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 10.006237983703613

Epoch: [4][77/391]	LR: 0.0001	Loss 1.5693 (1.5894)	Prec@1 37.500 (39.573)	
Epoch: [4][155/391]	LR: 0.0001	Loss 1.6035 (1.5880)	Prec@1 39.062 (39.663)	
Epoch: [4][233/391]	LR: 0.0001	Loss 1.6152 (1.5911)	Prec@1 40.625 (39.463)	
Epoch: [4][311/391]	LR: 0.0001	Loss 1.6523 (1.5867)	Prec@1 35.938 (39.591)	
Epoch: [4][389/391]	LR: 0.0001	Loss 1.5977 (1.5824)	Prec@1 37.500 (39.694)	
Total train loss: 1.5820

Train time: 7.411982774734497
 * Prec@1 91.510 Prec@5 99.660 Loss 0.4612
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.391746997833252

Epoch: [5][77/391]	LR: 0.0001	Loss 1.5352 (1.6031)	Prec@1 40.625 (38.712)	
Epoch: [5][155/391]	LR: 0.0001	Loss 1.3838 (1.5788)	Prec@1 46.094 (39.824)	
Epoch: [5][233/391]	LR: 0.0001	Loss 1.6670 (1.5757)	Prec@1 32.812 (39.967)	
Epoch: [5][311/391]	LR: 0.0001	Loss 1.5254 (1.5778)	Prec@1 40.625 (39.891)	
Epoch: [5][389/391]	LR: 0.0001	Loss 1.6602 (1.5767)	Prec@1 36.719 (39.774)	
Total train loss: 1.5768

Train time: 7.633313894271851
 * Prec@1 91.460 Prec@5 99.660 Loss 0.4731
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.632540941238403

Epoch: [6][77/391]	LR: 0.0001	Loss 1.6240 (1.5772)	Prec@1 35.938 (39.523)	
Epoch: [6][155/391]	LR: 0.0001	Loss 1.4453 (1.5817)	Prec@1 44.531 (39.508)	
Epoch: [6][233/391]	LR: 0.0001	Loss 1.7109 (1.5797)	Prec@1 32.812 (39.630)	
Epoch: [6][311/391]	LR: 0.0001	Loss 1.6396 (1.5729)	Prec@1 35.938 (39.734)	
Epoch: [6][389/391]	LR: 0.0001	Loss 1.5254 (1.5719)	Prec@1 43.750 (39.653)	
Total train loss: 1.5721

Train time: 7.584609031677246
 * Prec@1 91.600 Prec@5 99.650 Loss 0.4617
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.553486347198486

Epoch: [7][77/391]	LR: 0.0001	Loss 1.3916 (1.5755)	Prec@1 46.875 (39.804)	
Epoch: [7][155/391]	LR: 0.0001	Loss 1.6846 (1.5710)	Prec@1 38.281 (40.009)	
Epoch: [7][233/391]	LR: 0.0001	Loss 1.4482 (1.5715)	Prec@1 47.656 (39.947)	
Epoch: [7][311/391]	LR: 0.0001	Loss 1.5840 (1.5717)	Prec@1 35.156 (39.859)	
Epoch: [7][389/391]	LR: 0.0001	Loss 1.4893 (1.5695)	Prec@1 43.750 (39.806)	
Total train loss: 1.5697

Train time: 7.334975957870483
 * Prec@1 91.420 Prec@5 99.660 Loss 0.4636
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.848766565322876

Epoch: [8][77/391]	LR: 0.0001	Loss 1.6270 (1.5654)	Prec@1 38.281 (39.804)	
Epoch: [8][155/391]	LR: 0.0001	Loss 1.6924 (1.5681)	Prec@1 32.812 (39.478)	
Epoch: [8][233/391]	LR: 0.0001	Loss 1.4541 (1.5693)	Prec@1 45.312 (39.517)	
Epoch: [8][311/391]	LR: 0.0001	Loss 1.7812 (1.5705)	Prec@1 33.594 (39.433)	
Epoch: [8][389/391]	LR: 0.0001	Loss 1.6182 (1.5694)	Prec@1 35.938 (39.513)	
Total train loss: 1.5693

Train time: 7.5915772914886475
 * Prec@1 91.350 Prec@5 99.660 Loss 0.4895
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.536470651626587

Epoch: [9][77/391]	LR: 0.0001	Loss 1.6064 (1.5707)	Prec@1 36.719 (39.223)	
Epoch: [9][155/391]	LR: 0.0001	Loss 1.6016 (1.5651)	Prec@1 40.625 (39.563)	
Epoch: [9][233/391]	LR: 0.0001	Loss 1.3584 (1.5705)	Prec@1 44.531 (39.443)	
Epoch: [9][311/391]	LR: 0.0001	Loss 1.4326 (1.5669)	Prec@1 44.531 (39.521)	
Epoch: [9][389/391]	LR: 0.0001	Loss 1.5674 (1.5675)	Prec@1 39.844 (39.511)	
Total train loss: 1.5676

Train time: 7.338045358657837
 * Prec@1 91.510 Prec@5 99.660 Loss 0.4839
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.414887189865112

Epoch: [10][77/391]	LR: 0.0001	Loss 1.6807 (1.5338)	Prec@1 33.594 (40.996)	
Epoch: [10][155/391]	LR: 0.0001	Loss 1.3896 (1.5518)	Prec@1 46.875 (40.460)	
Epoch: [10][233/391]	LR: 0.0001	Loss 1.6631 (1.5601)	Prec@1 35.938 (40.194)	
Epoch: [10][311/391]	LR: 0.0001	Loss 1.6572 (1.5635)	Prec@1 32.031 (40.099)	
Epoch: [10][389/391]	LR: 0.0001	Loss 1.4258 (1.5648)	Prec@1 42.188 (39.926)	
Total train loss: 1.5648

Train time: 7.36480975151062
 * Prec@1 91.410 Prec@5 99.680 Loss 0.4663
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.240999460220337

Epoch: [11][77/391]	LR: 0.0001	Loss 1.5791 (1.5658)	Prec@1 38.281 (39.734)	
Epoch: [11][155/391]	LR: 0.0001	Loss 1.6191 (1.5602)	Prec@1 38.281 (39.794)	
Epoch: [11][233/391]	LR: 0.0001	Loss 1.6016 (1.5710)	Prec@1 34.375 (39.430)	
Epoch: [11][311/391]	LR: 0.0001	Loss 1.6943 (1.5664)	Prec@1 39.844 (39.628)	
Epoch: [11][389/391]	LR: 0.0001	Loss 1.5840 (1.5644)	Prec@1 38.281 (39.710)	
Total train loss: 1.5646

Train time: 7.253156900405884
 * Prec@1 91.510 Prec@5 99.680 Loss 0.4795
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.153602838516235

Epoch: [12][77/391]	LR: 0.0001	Loss 1.6582 (1.5489)	Prec@1 37.500 (40.455)	
Epoch: [12][155/391]	LR: 0.0001	Loss 1.4893 (1.5493)	Prec@1 38.281 (40.360)	
Epoch: [12][233/391]	LR: 0.0001	Loss 1.5732 (1.5609)	Prec@1 41.406 (39.854)	
Epoch: [12][311/391]	LR: 0.0001	Loss 1.8916 (1.5664)	Prec@1 30.469 (39.548)	
Epoch: [12][389/391]	LR: 0.0001	Loss 1.6514 (1.5637)	Prec@1 36.719 (39.651)	
Total train loss: 1.5635

Train time: 7.655799150466919
 * Prec@1 91.350 Prec@5 99.700 Loss 0.4695
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.615030288696289

Epoch: [13][77/391]	LR: 0.0001	Loss 1.5752 (1.5607)	Prec@1 35.938 (39.904)	
Epoch: [13][155/391]	LR: 0.0001	Loss 1.4375 (1.5703)	Prec@1 46.094 (39.633)	
Epoch: [13][233/391]	LR: 0.0001	Loss 1.7969 (1.5683)	Prec@1 36.719 (39.633)	
Epoch: [13][311/391]	LR: 0.0001	Loss 1.4951 (1.5640)	Prec@1 43.750 (39.746)	
Epoch: [13][389/391]	LR: 0.0001	Loss 1.4814 (1.5642)	Prec@1 45.312 (39.702)	
Total train loss: 1.5641

Train time: 7.2716755867004395
 * Prec@1 91.340 Prec@5 99.690 Loss 0.4731
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.427390336990356

Epoch: [14][77/391]	LR: 0.0001	Loss 1.5762 (1.5685)	Prec@1 39.062 (39.363)	
Epoch: [14][155/391]	LR: 0.0001	Loss 1.4463 (1.5544)	Prec@1 42.969 (39.929)	
Epoch: [14][233/391]	LR: 0.0001	Loss 1.6562 (1.5642)	Prec@1 35.938 (39.640)	
Epoch: [14][311/391]	LR: 0.0001	Loss 1.4971 (1.5641)	Prec@1 37.500 (39.706)	
Epoch: [14][389/391]	LR: 0.0001	Loss 1.5283 (1.5629)	Prec@1 39.062 (39.728)	
Total train loss: 1.5628

Train time: 7.394765138626099
 * Prec@1 91.110 Prec@5 99.710 Loss 0.4641
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.690972089767456

Epoch: [15][77/391]	LR: 0.0001	Loss 1.4951 (1.5424)	Prec@1 41.406 (40.405)	
Epoch: [15][155/391]	LR: 0.0001	Loss 1.5693 (1.5585)	Prec@1 40.625 (39.809)	
Epoch: [15][233/391]	LR: 0.0001	Loss 1.5381 (1.5575)	Prec@1 42.188 (39.810)	
Epoch: [15][311/391]	LR: 0.0001	Loss 1.4160 (1.5576)	Prec@1 44.531 (39.754)	
Epoch: [15][389/391]	LR: 0.0001	Loss 1.6943 (1.5633)	Prec@1 35.938 (39.581)	
Total train loss: 1.5633

Train time: 7.583741188049316
 * Prec@1 91.470 Prec@5 99.680 Loss 0.4668
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.557887077331543

Epoch: [16][77/391]	LR: 0.0001	Loss 1.5654 (1.5648)	Prec@1 42.188 (39.433)	
Epoch: [16][155/391]	LR: 0.0001	Loss 1.6523 (1.5648)	Prec@1 38.281 (39.528)	
Epoch: [16][233/391]	LR: 0.0001	Loss 1.8291 (1.5680)	Prec@1 32.812 (39.463)	
Epoch: [16][311/391]	LR: 0.0001	Loss 1.6201 (1.5651)	Prec@1 38.281 (39.488)	
Epoch: [16][389/391]	LR: 0.0001	Loss 1.3984 (1.5650)	Prec@1 45.312 (39.415)	
Total train loss: 1.5647

Train time: 7.232351541519165
 * Prec@1 91.510 Prec@5 99.690 Loss 0.4585
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.081839084625244

Epoch: [17][77/391]	LR: 0.0001	Loss 1.3281 (1.5713)	Prec@1 46.875 (39.073)	
Epoch: [17][155/391]	LR: 0.0001	Loss 1.5703 (1.5669)	Prec@1 39.844 (39.488)	
Epoch: [17][233/391]	LR: 0.0001	Loss 1.5391 (1.5615)	Prec@1 39.062 (39.610)	
Epoch: [17][311/391]	LR: 0.0001	Loss 1.5332 (1.5596)	Prec@1 42.969 (39.704)	
Epoch: [17][389/391]	LR: 0.0001	Loss 1.6523 (1.5620)	Prec@1 35.938 (39.597)	
Total train loss: 1.5617

Train time: 7.298073053359985
 * Prec@1 91.490 Prec@5 99.680 Loss 0.4644
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.33154821395874

Epoch: [18][77/391]	LR: 0.0001	Loss 1.5918 (1.5680)	Prec@1 39.062 (39.603)	
Epoch: [18][155/391]	LR: 0.0001	Loss 1.6309 (1.5667)	Prec@1 32.812 (39.638)	
Epoch: [18][233/391]	LR: 0.0001	Loss 1.5293 (1.5669)	Prec@1 39.062 (39.550)	
Epoch: [18][311/391]	LR: 0.0001	Loss 1.5645 (1.5621)	Prec@1 39.062 (39.643)	
Epoch: [18][389/391]	LR: 0.0001	Loss 1.5605 (1.5602)	Prec@1 34.375 (39.643)	
Total train loss: 1.5603

Train time: 7.391071796417236
 * Prec@1 91.490 Prec@5 99.710 Loss 0.4636
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.304787635803223

Epoch: [19][77/391]	LR: 0.0001	Loss 1.5723 (1.5629)	Prec@1 36.719 (40.064)	
Epoch: [19][155/391]	LR: 0.0001	Loss 1.5312 (1.5643)	Prec@1 42.188 (39.994)	
Epoch: [19][233/391]	LR: 0.0001	Loss 1.5430 (1.5610)	Prec@1 42.188 (39.854)	
Epoch: [19][311/391]	LR: 0.0001	Loss 1.5791 (1.5596)	Prec@1 40.625 (39.891)	
Epoch: [19][389/391]	LR: 0.0001	Loss 1.7510 (1.5607)	Prec@1 32.812 (39.786)	
Total train loss: 1.5606

Train time: 7.395820617675781
 * Prec@1 91.480 Prec@5 99.690 Loss 0.4604
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.42664909362793

Epoch: [20][77/391]	LR: 1e-05	Loss 1.5479 (1.5740)	Prec@1 39.062 (39.233)	
Epoch: [20][155/391]	LR: 1e-05	Loss 1.5547 (1.5657)	Prec@1 41.406 (39.418)	
Epoch: [20][233/391]	LR: 1e-05	Loss 1.5225 (1.5606)	Prec@1 41.406 (39.640)	
Epoch: [20][311/391]	LR: 1e-05	Loss 1.5654 (1.5620)	Prec@1 40.625 (39.558)	
Epoch: [20][389/391]	LR: 1e-05	Loss 1.8750 (1.5616)	Prec@1 28.125 (39.623)	
Total train loss: 1.5621

Train time: 7.374293327331543
 * Prec@1 91.470 Prec@5 99.690 Loss 0.4761
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.374374151229858

Epoch: [21][77/391]	LR: 1e-05	Loss 1.4492 (1.5688)	Prec@1 43.750 (39.323)	
Epoch: [21][155/391]	LR: 1e-05	Loss 1.3848 (1.5608)	Prec@1 46.875 (39.583)	
Epoch: [21][233/391]	LR: 1e-05	Loss 1.5039 (1.5619)	Prec@1 39.844 (39.543)	
Epoch: [21][311/391]	LR: 1e-05	Loss 1.6318 (1.5638)	Prec@1 33.594 (39.601)	
Epoch: [21][389/391]	LR: 1e-05	Loss 1.3926 (1.5619)	Prec@1 44.531 (39.698)	
Total train loss: 1.5622

Train time: 7.402968406677246
 * Prec@1 91.420 Prec@5 99.710 Loss 0.4585
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.823599100112915

Epoch: [22][77/391]	LR: 1e-05	Loss 1.7422 (1.5521)	Prec@1 29.688 (40.004)	
Epoch: [22][155/391]	LR: 1e-05	Loss 1.5645 (1.5587)	Prec@1 41.406 (39.874)	
Epoch: [22][233/391]	LR: 1e-05	Loss 1.5742 (1.5630)	Prec@1 36.719 (39.717)	
Epoch: [22][311/391]	LR: 1e-05	Loss 1.5186 (1.5623)	Prec@1 37.500 (39.618)	
Epoch: [22][389/391]	LR: 1e-05	Loss 1.4873 (1.5624)	Prec@1 38.281 (39.637)	
Total train loss: 1.5623

Train time: 7.706118106842041
 * Prec@1 91.590 Prec@5 99.700 Loss 0.4585
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.763298988342285

Epoch: [23][77/391]	LR: 1e-05	Loss 1.6885 (1.5581)	Prec@1 30.469 (40.024)	
Epoch: [23][155/391]	LR: 1e-05	Loss 1.6934 (1.5623)	Prec@1 35.938 (39.704)	
Epoch: [23][233/391]	LR: 1e-05	Loss 1.3125 (1.5601)	Prec@1 51.562 (39.887)	
Epoch: [23][311/391]	LR: 1e-05	Loss 1.3516 (1.5586)	Prec@1 48.438 (39.826)	
Epoch: [23][389/391]	LR: 1e-05	Loss 1.4932 (1.5614)	Prec@1 39.062 (39.722)	
Total train loss: 1.5616

Train time: 7.178904294967651
 * Prec@1 91.600 Prec@5 99.680 Loss 0.4631
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.171083927154541

Epoch: [24][77/391]	LR: 1e-05	Loss 1.6699 (1.5771)	Prec@1 35.938 (39.283)	
Epoch: [24][155/391]	LR: 1e-05	Loss 1.5000 (1.5615)	Prec@1 41.406 (39.884)	
Epoch: [24][233/391]	LR: 1e-05	Loss 1.6855 (1.5622)	Prec@1 39.062 (39.947)	
Epoch: [24][311/391]	LR: 1e-05	Loss 1.5254 (1.5634)	Prec@1 40.625 (39.756)	
Epoch: [24][389/391]	LR: 1e-05	Loss 1.5264 (1.5633)	Prec@1 44.531 (39.718)	
Total train loss: 1.5636

Train time: 7.6580188274383545
 * Prec@1 91.310 Prec@5 99.680 Loss 0.4668
Best acc: 91.690
--------------------------------------------------------------------------------
Test time: 9.606769800186157

