
      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 1
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.580 Prec@5 99.660 Loss 0.3188
Pre-trained Prec@1 with 1 layers frozen: 91.57999420166016 	 Loss: 0.31884765625

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.01	Loss 1.5811 (1.8123)	Prec@1 40.625 (34.806)	
Epoch: [0][155/391]	LR: 0.01	Loss 1.5039 (1.7309)	Prec@1 44.531 (35.722)	
Epoch: [0][233/391]	LR: 0.01	Loss 1.6748 (1.6869)	Prec@1 36.719 (36.502)	
Epoch: [0][311/391]	LR: 0.01	Loss 1.7871 (1.6615)	Prec@1 29.688 (37.039)	
Epoch: [0][389/391]	LR: 0.01	Loss 1.6680 (1.6455)	Prec@1 38.281 (37.362)	
Total train loss: 1.6457

Train time: 55.98045873641968
 * Prec@1 89.200 Prec@5 99.390 Loss 0.3723
Best acc: 89.200
--------------------------------------------------------------------------------
Test time: 60.81280541419983

Epoch: [1][77/391]	LR: 0.01	Loss 1.6484 (1.5602)	Prec@1 35.156 (39.473)	
Epoch: [1][155/391]	LR: 0.01	Loss 1.5361 (1.5594)	Prec@1 39.062 (39.558)	
Epoch: [1][233/391]	LR: 0.01	Loss 1.4502 (1.5574)	Prec@1 44.531 (39.553)	
Epoch: [1][311/391]	LR: 0.01	Loss 1.5000 (1.5559)	Prec@1 42.969 (39.603)	
Epoch: [1][389/391]	LR: 0.01	Loss 1.3984 (1.5602)	Prec@1 46.875 (39.381)	
Total train loss: 1.5602

Train time: 24.366710662841797
 * Prec@1 89.320 Prec@5 99.730 Loss 0.3801
Best acc: 89.320
--------------------------------------------------------------------------------
Test time: 28.9165518283844

Epoch: [2][77/391]	LR: 0.01	Loss 1.4961 (1.5715)	Prec@1 41.406 (39.593)	
Epoch: [2][155/391]	LR: 0.01	Loss 1.6963 (1.5607)	Prec@1 35.156 (39.653)	
Epoch: [2][233/391]	LR: 0.01	Loss 1.6562 (1.5515)	Prec@1 35.938 (39.941)	
Epoch: [2][311/391]	LR: 0.01	Loss 1.4854 (1.5477)	Prec@1 40.625 (39.949)	
Epoch: [2][389/391]	LR: 0.01	Loss 1.4961 (1.5477)	Prec@1 41.406 (39.844)	
Total train loss: 1.5479

Train time: 24.26980209350586
 * Prec@1 89.960 Prec@5 99.560 Loss 0.3743
Best acc: 89.960
--------------------------------------------------------------------------------
Test time: 28.496659994125366

Epoch: [3][77/391]	LR: 0.01	Loss 1.4219 (1.5480)	Prec@1 47.656 (39.613)	
Epoch: [3][155/391]	LR: 0.01	Loss 1.6260 (1.5406)	Prec@1 36.719 (40.094)	
Epoch: [3][233/391]	LR: 0.01	Loss 1.6582 (1.5381)	Prec@1 36.719 (40.244)	
Epoch: [3][311/391]	LR: 0.01	Loss 1.6299 (1.5381)	Prec@1 39.062 (40.247)	
Epoch: [3][389/391]	LR: 0.01	Loss 1.4688 (1.5417)	Prec@1 45.312 (40.152)	
Total train loss: 1.5414

Train time: 24.828726291656494
 * Prec@1 90.020 Prec@5 99.600 Loss 0.3752
Best acc: 90.020
--------------------------------------------------------------------------------
Test time: 28.505162000656128

Epoch: [4][77/391]	LR: 0.01	Loss 1.3145 (1.5419)	Prec@1 46.094 (39.974)	
Epoch: [4][155/391]	LR: 0.01	Loss 1.5459 (1.5343)	Prec@1 41.406 (40.219)	
Epoch: [4][233/391]	LR: 0.01	Loss 1.5703 (1.5373)	Prec@1 37.500 (40.118)	
Epoch: [4][311/391]	LR: 0.01	Loss 1.7197 (1.5406)	Prec@1 34.375 (40.117)	
Epoch: [4][389/391]	LR: 0.01	Loss 1.4600 (1.5386)	Prec@1 44.531 (40.188)	
Total train loss: 1.5385

Train time: 24.424423694610596
 * Prec@1 90.290 Prec@5 99.580 Loss 0.3589
Best acc: 90.290
--------------------------------------------------------------------------------
Test time: 28.520711183547974

Epoch: [5][77/391]	LR: 0.01	Loss 1.4355 (1.5210)	Prec@1 44.531 (40.905)	
Epoch: [5][155/391]	LR: 0.01	Loss 1.6670 (1.5239)	Prec@1 32.031 (40.971)	
Epoch: [5][233/391]	LR: 0.01	Loss 1.5537 (1.5328)	Prec@1 38.281 (40.585)	
Epoch: [5][311/391]	LR: 0.01	Loss 1.4365 (1.5350)	Prec@1 43.750 (40.472)	
Epoch: [5][389/391]	LR: 0.01	Loss 1.6172 (1.5359)	Prec@1 41.406 (40.355)	
Total train loss: 1.5353

Train time: 23.49570655822754
 * Prec@1 90.420 Prec@5 99.600 Loss 0.3660
Best acc: 90.420
--------------------------------------------------------------------------------
Test time: 27.15550398826599

Epoch: [6][77/391]	LR: 0.01	Loss 1.5820 (1.5240)	Prec@1 37.500 (40.785)	
Epoch: [6][155/391]	LR: 0.01	Loss 1.5781 (1.5332)	Prec@1 39.062 (40.224)	
Epoch: [6][233/391]	LR: 0.01	Loss 1.6035 (1.5394)	Prec@1 39.844 (39.967)	
Epoch: [6][311/391]	LR: 0.01	Loss 1.5400 (1.5382)	Prec@1 39.844 (40.114)	
Epoch: [6][389/391]	LR: 0.01	Loss 1.5176 (1.5345)	Prec@1 39.844 (40.308)	
Total train loss: 1.5346

Train time: 23.105722188949585
 * Prec@1 90.620 Prec@5 99.600 Loss 0.3594
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 27.36560034751892

Epoch: [7][77/391]	LR: 0.01	Loss 1.4043 (1.5230)	Prec@1 45.312 (40.695)	
Epoch: [7][155/391]	LR: 0.01	Loss 1.5498 (1.5262)	Prec@1 39.844 (40.485)	
Epoch: [7][233/391]	LR: 0.01	Loss 1.5020 (1.5328)	Prec@1 43.750 (40.214)	
Epoch: [7][311/391]	LR: 0.01	Loss 1.5605 (1.5321)	Prec@1 39.844 (40.287)	
Epoch: [7][389/391]	LR: 0.01	Loss 1.5078 (1.5320)	Prec@1 42.188 (40.335)	
Total train loss: 1.5321

Train time: 23.417834520339966
 * Prec@1 90.340 Prec@5 99.470 Loss 0.3799
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 26.890175104141235

Epoch: [8][77/391]	LR: 0.01	Loss 1.4990 (1.5409)	Prec@1 42.188 (40.084)	
Epoch: [8][155/391]	LR: 0.01	Loss 1.4854 (1.5306)	Prec@1 42.969 (40.325)	
Epoch: [8][233/391]	LR: 0.01	Loss 1.5107 (1.5274)	Prec@1 39.844 (40.315)	
Epoch: [8][311/391]	LR: 0.01	Loss 1.5908 (1.5307)	Prec@1 36.719 (40.254)	
Epoch: [8][389/391]	LR: 0.01	Loss 1.5654 (1.5333)	Prec@1 37.500 (40.198)	
Total train loss: 1.5333

Train time: 21.532367706298828
 * Prec@1 90.050 Prec@5 99.450 Loss 0.4016
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 25.482720375061035

Epoch: [9][77/391]	LR: 0.01	Loss 1.6162 (1.5388)	Prec@1 41.406 (40.224)	
Epoch: [9][155/391]	LR: 0.01	Loss 1.6641 (1.5311)	Prec@1 37.500 (40.705)	
Epoch: [9][233/391]	LR: 0.01	Loss 1.5420 (1.5272)	Prec@1 37.500 (40.739)	
Epoch: [9][311/391]	LR: 0.01	Loss 1.6846 (1.5311)	Prec@1 32.812 (40.590)	
Epoch: [9][389/391]	LR: 0.01	Loss 1.6494 (1.5308)	Prec@1 37.500 (40.613)	
Total train loss: 1.5310

Train time: 21.519063234329224
 * Prec@1 90.130 Prec@5 99.390 Loss 0.4009
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 24.873013734817505

Epoch: [10][77/391]	LR: 0.01	Loss 1.4297 (1.5327)	Prec@1 46.875 (40.224)	
Epoch: [10][155/391]	LR: 0.01	Loss 1.7070 (1.5283)	Prec@1 36.719 (40.480)	
Epoch: [10][233/391]	LR: 0.01	Loss 1.5332 (1.5324)	Prec@1 42.969 (40.325)	
Epoch: [10][311/391]	LR: 0.01	Loss 1.5117 (1.5328)	Prec@1 43.750 (40.284)	
Epoch: [10][389/391]	LR: 0.01	Loss 1.5635 (1.5299)	Prec@1 41.406 (40.441)	
Total train loss: 1.5301

Train time: 21.226537466049194
 * Prec@1 90.040 Prec@5 99.520 Loss 0.3933
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 25.372816562652588

Epoch: [11][77/391]	LR: 0.01	Loss 1.5596 (1.5340)	Prec@1 42.188 (40.335)	
Epoch: [11][155/391]	LR: 0.01	Loss 1.5742 (1.5345)	Prec@1 44.531 (40.320)	
Epoch: [11][233/391]	LR: 0.01	Loss 1.4209 (1.5270)	Prec@1 42.969 (40.789)	
Epoch: [11][311/391]	LR: 0.01	Loss 1.4902 (1.5289)	Prec@1 40.625 (40.733)	
Epoch: [11][389/391]	LR: 0.01	Loss 1.5312 (1.5286)	Prec@1 42.969 (40.747)	
Total train loss: 1.5283

Train time: 20.793285846710205
 * Prec@1 90.440 Prec@5 99.520 Loss 0.3862
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 24.297135829925537

Epoch: [12][77/391]	LR: 0.01	Loss 1.5117 (1.5280)	Prec@1 42.969 (40.605)	
Epoch: [12][155/391]	LR: 0.01	Loss 1.6045 (1.5271)	Prec@1 35.156 (40.475)	
Epoch: [12][233/391]	LR: 0.01	Loss 1.6113 (1.5267)	Prec@1 38.281 (40.548)	
Epoch: [12][311/391]	LR: 0.01	Loss 1.4580 (1.5265)	Prec@1 41.406 (40.542)	
Epoch: [12][389/391]	LR: 0.01	Loss 1.4951 (1.5292)	Prec@1 44.531 (40.485)	
Total train loss: 1.5293

Train time: 21.18804383277893
 * Prec@1 90.250 Prec@5 99.530 Loss 0.3828
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 24.950056076049805

Epoch: [13][77/391]	LR: 0.01	Loss 1.4756 (1.5275)	Prec@1 42.188 (40.785)	
Epoch: [13][155/391]	LR: 0.01	Loss 1.6094 (1.5345)	Prec@1 40.625 (40.405)	
Epoch: [13][233/391]	LR: 0.01	Loss 1.4707 (1.5334)	Prec@1 42.969 (40.301)	
Epoch: [13][311/391]	LR: 0.01	Loss 1.5498 (1.5264)	Prec@1 39.062 (40.570)	
Epoch: [13][389/391]	LR: 0.01	Loss 1.6543 (1.5290)	Prec@1 32.812 (40.479)	
Total train loss: 1.5289

Train time: 21.45986270904541
 * Prec@1 90.240 Prec@5 99.420 Loss 0.3894
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 24.866487741470337

Epoch: [14][77/391]	LR: 0.01	Loss 1.3203 (1.5198)	Prec@1 48.438 (40.885)	
Epoch: [14][155/391]	LR: 0.01	Loss 1.4492 (1.5181)	Prec@1 43.750 (40.981)	
Epoch: [14][233/391]	LR: 0.01	Loss 1.5303 (1.5243)	Prec@1 42.188 (40.742)	
Epoch: [14][311/391]	LR: 0.01	Loss 1.7930 (1.5292)	Prec@1 32.812 (40.527)	
Epoch: [14][389/391]	LR: 0.01	Loss 1.5811 (1.5281)	Prec@1 39.062 (40.425)	
Total train loss: 1.5283

Train time: 21.0434467792511
 * Prec@1 90.540 Prec@5 99.490 Loss 0.3716
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 24.974693059921265

Epoch: [15][77/391]	LR: 0.01	Loss 1.5986 (1.5108)	Prec@1 38.281 (40.956)	
Epoch: [15][155/391]	LR: 0.01	Loss 1.4971 (1.5209)	Prec@1 43.750 (40.935)	
Epoch: [15][233/391]	LR: 0.01	Loss 1.4297 (1.5267)	Prec@1 45.312 (40.602)	
Epoch: [15][311/391]	LR: 0.01	Loss 1.6104 (1.5286)	Prec@1 37.500 (40.530)	
Epoch: [15][389/391]	LR: 0.01	Loss 1.4951 (1.5289)	Prec@1 41.406 (40.455)	
Total train loss: 1.5288

Train time: 20.85833168029785
 * Prec@1 90.220 Prec@5 99.430 Loss 0.3845
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 24.723206281661987

Epoch: [16][77/391]	LR: 0.01	Loss 1.5098 (1.5270)	Prec@1 41.406 (40.485)	
Epoch: [16][155/391]	LR: 0.01	Loss 1.5664 (1.5343)	Prec@1 39.062 (40.024)	
Epoch: [16][233/391]	LR: 0.01	Loss 1.4121 (1.5321)	Prec@1 41.406 (40.164)	
Epoch: [16][311/391]	LR: 0.01	Loss 1.4453 (1.5302)	Prec@1 44.531 (40.252)	
Epoch: [16][389/391]	LR: 0.01	Loss 1.4434 (1.5265)	Prec@1 44.531 (40.495)	
Total train loss: 1.5269

Train time: 21.388246536254883
 * Prec@1 90.210 Prec@5 99.450 Loss 0.3953
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 25.662542581558228

Epoch: [17][77/391]	LR: 0.01	Loss 1.5156 (1.5199)	Prec@1 42.188 (40.465)	
Epoch: [17][155/391]	LR: 0.01	Loss 1.3877 (1.5177)	Prec@1 46.875 (40.675)	
Epoch: [17][233/391]	LR: 0.01	Loss 1.6416 (1.5239)	Prec@1 38.281 (40.375)	
Epoch: [17][311/391]	LR: 0.01	Loss 1.5518 (1.5250)	Prec@1 38.281 (40.325)	
Epoch: [17][389/391]	LR: 0.01	Loss 1.4922 (1.5284)	Prec@1 39.844 (40.194)	
Total train loss: 1.5286

Train time: 21.43917441368103
 * Prec@1 90.320 Prec@5 99.420 Loss 0.3933
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 24.702827215194702

Epoch: [18][77/391]	LR: 0.01	Loss 1.5078 (1.5287)	Prec@1 42.969 (40.685)	
Epoch: [18][155/391]	LR: 0.01	Loss 1.5771 (1.5305)	Prec@1 41.406 (40.515)	
Epoch: [18][233/391]	LR: 0.01	Loss 1.5498 (1.5232)	Prec@1 42.188 (40.819)	
Epoch: [18][311/391]	LR: 0.01	Loss 1.5107 (1.5230)	Prec@1 38.281 (40.695)	
Epoch: [18][389/391]	LR: 0.01	Loss 1.6240 (1.5265)	Prec@1 38.281 (40.607)	
Total train loss: 1.5267

Train time: 21.794749975204468
 * Prec@1 90.480 Prec@5 99.440 Loss 0.3945
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 25.956060886383057

Epoch: [19][77/391]	LR: 0.01	Loss 1.5732 (1.5127)	Prec@1 41.406 (41.316)	
Epoch: [19][155/391]	LR: 0.01	Loss 1.6631 (1.5295)	Prec@1 35.938 (40.720)	
Epoch: [19][233/391]	LR: 0.01	Loss 1.4971 (1.5212)	Prec@1 41.406 (40.986)	
Epoch: [19][311/391]	LR: 0.01	Loss 1.6299 (1.5231)	Prec@1 34.375 (40.888)	
Epoch: [19][389/391]	LR: 0.01	Loss 1.5342 (1.5267)	Prec@1 41.406 (40.773)	
Total train loss: 1.5266

Train time: 22.473758697509766
 * Prec@1 90.380 Prec@5 99.430 Loss 0.3870
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 26.435513734817505

Epoch: [20][77/391]	LR: 0.001	Loss 1.3965 (1.5267)	Prec@1 46.875 (40.325)	
Epoch: [20][155/391]	LR: 0.001	Loss 1.4590 (1.5267)	Prec@1 42.969 (40.405)	
Epoch: [20][233/391]	LR: 0.001	Loss 1.6162 (1.5269)	Prec@1 37.500 (40.368)	
Epoch: [20][311/391]	LR: 0.001	Loss 1.5527 (1.5279)	Prec@1 42.188 (40.365)	
Epoch: [20][389/391]	LR: 0.001	Loss 1.4824 (1.5256)	Prec@1 39.844 (40.417)	
Total train loss: 1.5254

Train time: 23.942729949951172
 * Prec@1 90.490 Prec@5 99.440 Loss 0.3806
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 28.760069847106934

Epoch: [21][77/391]	LR: 0.001	Loss 1.4531 (1.5340)	Prec@1 42.969 (40.465)	
Epoch: [21][155/391]	LR: 0.001	Loss 1.5576 (1.5255)	Prec@1 41.406 (40.615)	
Epoch: [21][233/391]	LR: 0.001	Loss 1.6338 (1.5279)	Prec@1 35.938 (40.338)	
Epoch: [21][311/391]	LR: 0.001	Loss 1.5850 (1.5263)	Prec@1 36.719 (40.304)	
Epoch: [21][389/391]	LR: 0.001	Loss 1.4629 (1.5262)	Prec@1 45.312 (40.266)	
Total train loss: 1.5261

Train time: 24.068444967269897
 * Prec@1 90.450 Prec@5 99.470 Loss 0.3833
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 27.7231125831604

Epoch: [22][77/391]	LR: 0.001	Loss 1.3555 (1.5264)	Prec@1 44.531 (40.545)	
Epoch: [22][155/391]	LR: 0.001	Loss 1.6094 (1.5316)	Prec@1 36.719 (40.234)	
Epoch: [22][233/391]	LR: 0.001	Loss 1.3916 (1.5263)	Prec@1 48.438 (40.341)	
Epoch: [22][311/391]	LR: 0.001	Loss 1.3916 (1.5293)	Prec@1 46.094 (40.267)	
Epoch: [22][389/391]	LR: 0.001	Loss 1.5859 (1.5253)	Prec@1 37.500 (40.451)	
Total train loss: 1.5252

Train time: 24.319618225097656
 * Prec@1 90.350 Prec@5 99.490 Loss 0.3845
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 29.180859327316284

Epoch: [23][77/391]	LR: 0.001	Loss 1.5840 (1.5307)	Prec@1 38.281 (40.465)	
Epoch: [23][155/391]	LR: 0.001	Loss 1.5596 (1.5240)	Prec@1 42.188 (40.775)	
Epoch: [23][233/391]	LR: 0.001	Loss 1.4902 (1.5256)	Prec@1 43.750 (40.592)	
Epoch: [23][311/391]	LR: 0.001	Loss 1.6221 (1.5239)	Prec@1 33.594 (40.710)	
Epoch: [23][389/391]	LR: 0.001	Loss 1.5498 (1.5247)	Prec@1 40.625 (40.671)	
Total train loss: 1.5248

Train time: 24.267061710357666
 * Prec@1 90.610 Prec@5 99.470 Loss 0.3833
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 28.08160948753357

Epoch: [24][77/391]	LR: 0.001	Loss 1.7061 (1.5357)	Prec@1 29.688 (40.144)	
Epoch: [24][155/391]	LR: 0.001	Loss 1.4287 (1.5241)	Prec@1 43.750 (40.620)	
Epoch: [24][233/391]	LR: 0.001	Loss 1.5889 (1.5261)	Prec@1 37.500 (40.518)	
Epoch: [24][311/391]	LR: 0.001	Loss 1.6426 (1.5253)	Prec@1 35.156 (40.592)	
Epoch: [24][389/391]	LR: 0.001	Loss 1.6367 (1.5247)	Prec@1 35.938 (40.671)	
Total train loss: 1.5248

Train time: 25.90202283859253
 * Prec@1 90.460 Prec@5 99.410 Loss 0.3948
Best acc: 90.620
--------------------------------------------------------------------------------
Test time: 30.203269481658936


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 3
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.580 Prec@5 99.670 Loss 0.3181
Pre-trained Prec@1 with 3 layers frozen: 91.57999420166016 	 Loss: 0.318115234375

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.01	Loss 1.6055 (1.8913)	Prec@1 36.719 (32.472)	
Epoch: [0][155/391]	LR: 0.01	Loss 1.6875 (1.7598)	Prec@1 35.156 (34.771)	
Epoch: [0][233/391]	LR: 0.01	Loss 1.5498 (1.7044)	Prec@1 39.062 (35.924)	
Epoch: [0][311/391]	LR: 0.01	Loss 1.4902 (1.6743)	Prec@1 43.750 (36.671)	
Epoch: [0][389/391]	LR: 0.01	Loss 1.7256 (1.6550)	Prec@1 28.906 (37.055)	
Total train loss: 1.6551

Train time: 43.746241331100464
 * Prec@1 88.060 Prec@5 99.530 Loss 0.4021
Best acc: 88.060
--------------------------------------------------------------------------------
Test time: 48.832987785339355

Epoch: [1][77/391]	LR: 0.01	Loss 1.5332 (1.5482)	Prec@1 41.406 (40.044)	
Epoch: [1][155/391]	LR: 0.01	Loss 1.5664 (1.5477)	Prec@1 42.969 (39.899)	
Epoch: [1][233/391]	LR: 0.01	Loss 1.4863 (1.5571)	Prec@1 41.406 (39.607)	
Epoch: [1][311/391]	LR: 0.01	Loss 1.6240 (1.5574)	Prec@1 38.281 (39.548)	
Epoch: [1][389/391]	LR: 0.01	Loss 1.5430 (1.5589)	Prec@1 39.844 (39.455)	
Total train loss: 1.5590

Train time: 22.76111078262329
 * Prec@1 89.060 Prec@5 99.490 Loss 0.3875
Best acc: 89.060
--------------------------------------------------------------------------------
Test time: 26.873870849609375

Epoch: [2][77/391]	LR: 0.01	Loss 1.5332 (1.5418)	Prec@1 42.188 (40.094)	
Epoch: [2][155/391]	LR: 0.01	Loss 1.3418 (1.5434)	Prec@1 46.094 (40.034)	
Epoch: [2][233/391]	LR: 0.01	Loss 1.4277 (1.5480)	Prec@1 40.625 (39.854)	
Epoch: [2][311/391]	LR: 0.01	Loss 1.8027 (1.5503)	Prec@1 25.000 (39.739)	
Epoch: [2][389/391]	LR: 0.01	Loss 1.8271 (1.5470)	Prec@1 27.344 (39.892)	
Total train loss: 1.5469

Train time: 23.633545398712158
 * Prec@1 89.720 Prec@5 99.370 Loss 0.3762
Best acc: 89.720
--------------------------------------------------------------------------------
Test time: 27.85446548461914

Epoch: [3][77/391]	LR: 0.01	Loss 1.5166 (1.5426)	Prec@1 40.625 (40.094)	
Epoch: [3][155/391]	LR: 0.01	Loss 1.4541 (1.5382)	Prec@1 41.406 (40.259)	
Epoch: [3][233/391]	LR: 0.01	Loss 1.6484 (1.5414)	Prec@1 35.156 (40.084)	
Epoch: [3][311/391]	LR: 0.01	Loss 1.6113 (1.5372)	Prec@1 39.844 (40.289)	
Epoch: [3][389/391]	LR: 0.01	Loss 1.5898 (1.5409)	Prec@1 39.062 (40.188)	
Total train loss: 1.5410

Train time: 23.09254479408264
 * Prec@1 89.540 Prec@5 99.490 Loss 0.3955
Best acc: 89.720
--------------------------------------------------------------------------------
Test time: 27.44100546836853

Epoch: [4][77/391]	LR: 0.01	Loss 1.6738 (1.5442)	Prec@1 34.375 (39.874)	
Epoch: [4][155/391]	LR: 0.01	Loss 1.3721 (1.5421)	Prec@1 48.438 (39.884)	
Epoch: [4][233/391]	LR: 0.01	Loss 1.4814 (1.5365)	Prec@1 42.969 (40.087)	
Epoch: [4][311/391]	LR: 0.01	Loss 1.6318 (1.5391)	Prec@1 34.375 (39.974)	
Epoch: [4][389/391]	LR: 0.01	Loss 1.6377 (1.5361)	Prec@1 35.938 (40.096)	
Total train loss: 1.5364

Train time: 23.021265506744385
 * Prec@1 90.180 Prec@5 99.540 Loss 0.3835
Best acc: 90.180
--------------------------------------------------------------------------------
Test time: 27.33492612838745

Epoch: [5][77/391]	LR: 0.01	Loss 1.5811 (1.5103)	Prec@1 36.719 (41.296)	
Epoch: [5][155/391]	LR: 0.01	Loss 1.5068 (1.5218)	Prec@1 44.531 (40.760)	
Epoch: [5][233/391]	LR: 0.01	Loss 1.4062 (1.5239)	Prec@1 45.312 (40.642)	
Epoch: [5][311/391]	LR: 0.01	Loss 1.5693 (1.5323)	Prec@1 39.062 (40.330)	
Epoch: [5][389/391]	LR: 0.01	Loss 1.5566 (1.5371)	Prec@1 38.281 (40.076)	
Total train loss: 1.5371

Train time: 22.64102578163147
 * Prec@1 89.350 Prec@5 99.480 Loss 0.3943
Best acc: 90.180
--------------------------------------------------------------------------------
Test time: 26.964805126190186

Epoch: [6][77/391]	LR: 0.01	Loss 1.6367 (1.5529)	Prec@1 35.156 (39.804)	
Epoch: [6][155/391]	LR: 0.01	Loss 1.5205 (1.5340)	Prec@1 38.281 (40.455)	
Epoch: [6][233/391]	LR: 0.01	Loss 1.4893 (1.5373)	Prec@1 40.625 (40.124)	
Epoch: [6][311/391]	LR: 0.01	Loss 1.5029 (1.5349)	Prec@1 39.844 (40.262)	
Epoch: [6][389/391]	LR: 0.01	Loss 1.7412 (1.5360)	Prec@1 34.375 (40.310)	
Total train loss: 1.5357

Train time: 18.619963884353638
 * Prec@1 90.110 Prec@5 99.450 Loss 0.3923
Best acc: 90.180
--------------------------------------------------------------------------------
Test time: 21.565377950668335

Epoch: [7][77/391]	LR: 0.01	Loss 1.4814 (1.5487)	Prec@1 42.188 (39.333)	
Epoch: [7][155/391]	LR: 0.01	Loss 1.6650 (1.5444)	Prec@1 35.938 (39.759)	
Epoch: [7][233/391]	LR: 0.01	Loss 1.4414 (1.5368)	Prec@1 44.531 (40.081)	
Epoch: [7][311/391]	LR: 0.01	Loss 1.4727 (1.5356)	Prec@1 42.188 (40.179)	
Epoch: [7][389/391]	LR: 0.01	Loss 1.5225 (1.5325)	Prec@1 39.062 (40.304)	
Total train loss: 1.5326

Train time: 25.43460440635681
 * Prec@1 90.070 Prec@5 99.480 Loss 0.3855
Best acc: 90.180
--------------------------------------------------------------------------------
Test time: 30.020418643951416

Epoch: [8][77/391]	LR: 0.01	Loss 1.3662 (1.5309)	Prec@1 46.875 (40.184)	
Epoch: [8][155/391]	LR: 0.01	Loss 1.4775 (1.5322)	Prec@1 39.062 (40.425)	
Epoch: [8][233/391]	LR: 0.01	Loss 1.5078 (1.5345)	Prec@1 47.656 (40.378)	
Epoch: [8][311/391]	LR: 0.01	Loss 1.6836 (1.5340)	Prec@1 32.812 (40.420)	
Epoch: [8][389/391]	LR: 0.01	Loss 1.5361 (1.5320)	Prec@1 38.281 (40.479)	
Total train loss: 1.5319

Train time: 25.93813991546631
 * Prec@1 90.250 Prec@5 99.510 Loss 0.3931
Best acc: 90.250
--------------------------------------------------------------------------------
Test time: 30.795769929885864

Epoch: [9][77/391]	LR: 0.01	Loss 1.4814 (1.5308)	Prec@1 44.531 (39.924)	
Epoch: [9][155/391]	LR: 0.01	Loss 1.5947 (1.5281)	Prec@1 42.969 (40.375)	
Epoch: [9][233/391]	LR: 0.01	Loss 1.5752 (1.5299)	Prec@1 39.844 (40.224)	
Epoch: [9][311/391]	LR: 0.01	Loss 1.3418 (1.5275)	Prec@1 47.656 (40.395)	
Epoch: [9][389/391]	LR: 0.01	Loss 1.4102 (1.5306)	Prec@1 46.094 (40.242)	
Total train loss: 1.5306

Train time: 22.192891597747803
 * Prec@1 90.020 Prec@5 99.430 Loss 0.3877
Best acc: 90.250
--------------------------------------------------------------------------------
Test time: 24.742891550064087

Epoch: [10][77/391]	LR: 0.01	Loss 1.5234 (1.5289)	Prec@1 39.844 (40.435)	
Epoch: [10][155/391]	LR: 0.01	Loss 1.6133 (1.5328)	Prec@1 35.938 (40.014)	
Epoch: [10][233/391]	LR: 0.01	Loss 1.5420 (1.5352)	Prec@1 35.938 (39.944)	
Epoch: [10][311/391]	LR: 0.01	Loss 1.6709 (1.5320)	Prec@1 39.062 (40.172)	
Epoch: [10][389/391]	LR: 0.01	Loss 1.5791 (1.5309)	Prec@1 41.406 (40.266)	
Total train loss: 1.5308

Train time: 25.22083616256714
 * Prec@1 90.420 Prec@5 99.410 Loss 0.3799
Best acc: 90.420
--------------------------------------------------------------------------------
Test time: 29.41933035850525

Epoch: [11][77/391]	LR: 0.01	Loss 1.6533 (1.5294)	Prec@1 38.281 (40.515)	
Epoch: [11][155/391]	LR: 0.01	Loss 1.5908 (1.5327)	Prec@1 39.062 (40.485)	
Epoch: [11][233/391]	LR: 0.01	Loss 1.3662 (1.5306)	Prec@1 47.656 (40.532)	
Epoch: [11][311/391]	LR: 0.01	Loss 1.5225 (1.5315)	Prec@1 40.625 (40.522)	
Epoch: [11][389/391]	LR: 0.01	Loss 1.5576 (1.5297)	Prec@1 41.406 (40.515)	
Total train loss: 1.5299

Train time: 23.15797519683838
 * Prec@1 90.440 Prec@5 99.510 Loss 0.3718
Best acc: 90.440
--------------------------------------------------------------------------------
Test time: 27.038205862045288

Epoch: [12][77/391]	LR: 0.01	Loss 1.4873 (1.5312)	Prec@1 41.406 (40.425)	
Epoch: [12][155/391]	LR: 0.01	Loss 1.4873 (1.5376)	Prec@1 42.188 (39.979)	
Epoch: [12][233/391]	LR: 0.01	Loss 1.6045 (1.5321)	Prec@1 37.500 (40.097)	
Epoch: [12][311/391]	LR: 0.01	Loss 1.4092 (1.5299)	Prec@1 42.188 (40.322)	
Epoch: [12][389/391]	LR: 0.01	Loss 1.6924 (1.5298)	Prec@1 32.812 (40.294)	
Total train loss: 1.5297

Train time: 21.938335418701172
 * Prec@1 89.910 Prec@5 99.440 Loss 0.4033
Best acc: 90.440
--------------------------------------------------------------------------------
Test time: 26.14796495437622

Epoch: [13][77/391]	LR: 0.01	Loss 1.4941 (1.5226)	Prec@1 41.406 (40.915)	
Epoch: [13][155/391]	LR: 0.01	Loss 1.5371 (1.5251)	Prec@1 40.625 (40.475)	
Epoch: [13][233/391]	LR: 0.01	Loss 1.6279 (1.5280)	Prec@1 36.719 (40.375)	
Epoch: [13][311/391]	LR: 0.01	Loss 1.5801 (1.5282)	Prec@1 36.719 (40.462)	
Epoch: [13][389/391]	LR: 0.01	Loss 1.5381 (1.5283)	Prec@1 39.844 (40.541)	
Total train loss: 1.5284

Train time: 22.9230055809021
 * Prec@1 89.750 Prec@5 99.470 Loss 0.4072
Best acc: 90.440
--------------------------------------------------------------------------------
Test time: 26.87884759902954

Epoch: [14][77/391]	LR: 0.01	Loss 1.5596 (1.5163)	Prec@1 35.938 (40.765)	
Epoch: [14][155/391]	LR: 0.01	Loss 1.4600 (1.5245)	Prec@1 46.875 (40.445)	
Epoch: [14][233/391]	LR: 0.01	Loss 1.5850 (1.5228)	Prec@1 40.625 (40.658)	
Epoch: [14][311/391]	LR: 0.01	Loss 1.4873 (1.5278)	Prec@1 42.188 (40.455)	
Epoch: [14][389/391]	LR: 0.01	Loss 1.3184 (1.5293)	Prec@1 50.781 (40.405)	
Total train loss: 1.5294

Train time: 22.82958459854126
 * Prec@1 90.060 Prec@5 99.410 Loss 0.4045
Best acc: 90.440
--------------------------------------------------------------------------------
Test time: 26.942919492721558

Epoch: [15][77/391]	LR: 0.01	Loss 1.5498 (1.5104)	Prec@1 41.406 (41.366)	
Epoch: [15][155/391]	LR: 0.01	Loss 1.4668 (1.5250)	Prec@1 41.406 (40.630)	
Epoch: [15][233/391]	LR: 0.01	Loss 1.6904 (1.5221)	Prec@1 37.500 (40.772)	
Epoch: [15][311/391]	LR: 0.01	Loss 1.6270 (1.5263)	Prec@1 39.062 (40.567)	
Epoch: [15][389/391]	LR: 0.01	Loss 1.6006 (1.5273)	Prec@1 39.062 (40.529)	
Total train loss: 1.5273

Train time: 22.712761163711548
 * Prec@1 90.300 Prec@5 99.390 Loss 0.3831
Best acc: 90.440
--------------------------------------------------------------------------------
Test time: 26.605133533477783

Epoch: [16][77/391]	LR: 0.01	Loss 1.4590 (1.5321)	Prec@1 40.625 (40.254)	
Epoch: [16][155/391]	LR: 0.01	Loss 1.6348 (1.5292)	Prec@1 39.062 (40.385)	
Epoch: [16][233/391]	LR: 0.01	Loss 1.6318 (1.5271)	Prec@1 38.281 (40.628)	
Epoch: [16][311/391]	LR: 0.01	Loss 1.4707 (1.5264)	Prec@1 43.750 (40.602)	
Epoch: [16][389/391]	LR: 0.01	Loss 1.5420 (1.5274)	Prec@1 39.062 (40.555)	
Total train loss: 1.5275

Train time: 22.13649296760559
 * Prec@1 90.330 Prec@5 99.390 Loss 0.3816
Best acc: 90.440
--------------------------------------------------------------------------------
Test time: 26.703670263290405

Epoch: [17][77/391]	LR: 0.01	Loss 1.4961 (1.5283)	Prec@1 41.406 (40.264)	
Epoch: [17][155/391]	LR: 0.01	Loss 1.4326 (1.5247)	Prec@1 46.094 (40.635)	
Epoch: [17][233/391]	LR: 0.01	Loss 1.4512 (1.5287)	Prec@1 41.406 (40.618)	
Epoch: [17][311/391]	LR: 0.01	Loss 1.5342 (1.5245)	Prec@1 42.188 (40.705)	
Epoch: [17][389/391]	LR: 0.01	Loss 1.4385 (1.5284)	Prec@1 44.531 (40.465)	
Total train loss: 1.5285

Train time: 22.25923776626587
 * Prec@1 89.910 Prec@5 99.500 Loss 0.3865
Best acc: 90.440
--------------------------------------------------------------------------------
Test time: 26.863741874694824

Epoch: [18][77/391]	LR: 0.01	Loss 1.5566 (1.5164)	Prec@1 41.406 (40.515)	
Epoch: [18][155/391]	LR: 0.01	Loss 1.4990 (1.5261)	Prec@1 42.969 (40.360)	
Epoch: [18][233/391]	LR: 0.01	Loss 1.5234 (1.5314)	Prec@1 40.625 (40.261)	
Epoch: [18][311/391]	LR: 0.01	Loss 1.3887 (1.5313)	Prec@1 46.094 (40.309)	
Epoch: [18][389/391]	LR: 0.01	Loss 1.5430 (1.5273)	Prec@1 38.281 (40.525)	
Total train loss: 1.5275

Train time: 22.50992226600647
 * Prec@1 90.150 Prec@5 99.440 Loss 0.3875
Best acc: 90.440
--------------------------------------------------------------------------------
Test time: 26.41998529434204

Epoch: [19][77/391]	LR: 0.01	Loss 1.5850 (1.5310)	Prec@1 36.719 (40.304)	
Epoch: [19][155/391]	LR: 0.01	Loss 1.5146 (1.5259)	Prec@1 37.500 (40.460)	
Epoch: [19][233/391]	LR: 0.01	Loss 1.5938 (1.5266)	Prec@1 35.156 (40.555)	
Epoch: [19][311/391]	LR: 0.01	Loss 1.3906 (1.5267)	Prec@1 46.094 (40.515)	
Epoch: [19][389/391]	LR: 0.01	Loss 1.4160 (1.5265)	Prec@1 42.188 (40.495)	
Total train loss: 1.5266

Train time: 22.561469554901123
 * Prec@1 89.960 Prec@5 99.470 Loss 0.3977
Best acc: 90.440
--------------------------------------------------------------------------------
Test time: 26.859371185302734

Epoch: [20][77/391]	LR: 0.001	Loss 1.6279 (1.5442)	Prec@1 33.594 (40.014)	
Epoch: [20][155/391]	LR: 0.001	Loss 1.5400 (1.5322)	Prec@1 37.500 (40.229)	
Epoch: [20][233/391]	LR: 0.001	Loss 1.3145 (1.5295)	Prec@1 50.781 (40.355)	
Epoch: [20][311/391]	LR: 0.001	Loss 1.6699 (1.5264)	Prec@1 34.375 (40.407)	
Epoch: [20][389/391]	LR: 0.001	Loss 1.6094 (1.5244)	Prec@1 32.031 (40.475)	
Total train loss: 1.5247

Train time: 22.91034746170044
 * Prec@1 89.970 Prec@5 99.400 Loss 0.3992
Best acc: 90.440
--------------------------------------------------------------------------------
Test time: 26.975003719329834

Epoch: [21][77/391]	LR: 0.001	Loss 1.6074 (1.5123)	Prec@1 38.281 (41.006)	
Epoch: [21][155/391]	LR: 0.001	Loss 1.5107 (1.5217)	Prec@1 39.844 (40.390)	
Epoch: [21][233/391]	LR: 0.001	Loss 1.4561 (1.5232)	Prec@1 40.625 (40.441)	
Epoch: [21][311/391]	LR: 0.001	Loss 1.5869 (1.5217)	Prec@1 40.625 (40.537)	
Epoch: [21][389/391]	LR: 0.001	Loss 1.5508 (1.5258)	Prec@1 41.406 (40.483)	
Total train loss: 1.5256

Train time: 22.710314512252808
 * Prec@1 90.110 Prec@5 99.400 Loss 0.4004
Best acc: 90.440
--------------------------------------------------------------------------------
Test time: 27.02288794517517

Epoch: [22][77/391]	LR: 0.001	Loss 1.5479 (1.5224)	Prec@1 39.062 (40.264)	
Epoch: [22][155/391]	LR: 0.001	Loss 1.4746 (1.5256)	Prec@1 42.969 (40.510)	
Epoch: [22][233/391]	LR: 0.001	Loss 1.3018 (1.5212)	Prec@1 52.344 (40.765)	
Epoch: [22][311/391]	LR: 0.001	Loss 1.6934 (1.5236)	Prec@1 34.375 (40.660)	
Epoch: [22][389/391]	LR: 0.001	Loss 1.5156 (1.5240)	Prec@1 40.625 (40.621)	
Total train loss: 1.5242

Train time: 22.23369026184082
 * Prec@1 90.000 Prec@5 99.420 Loss 0.3975
Best acc: 90.440
--------------------------------------------------------------------------------
Test time: 26.03333616256714

Epoch: [23][77/391]	LR: 0.001	Loss 1.4775 (1.5122)	Prec@1 42.188 (41.176)	
Epoch: [23][155/391]	LR: 0.001	Loss 1.4766 (1.5232)	Prec@1 39.062 (40.570)	
Epoch: [23][233/391]	LR: 0.001	Loss 1.4209 (1.5283)	Prec@1 42.969 (40.294)	
Epoch: [23][311/391]	LR: 0.001	Loss 1.3857 (1.5278)	Prec@1 46.094 (40.337)	
Epoch: [23][389/391]	LR: 0.001	Loss 1.4805 (1.5247)	Prec@1 45.312 (40.471)	
Total train loss: 1.5247

Train time: 22.679577112197876
 * Prec@1 90.190 Prec@5 99.410 Loss 0.3848
Best acc: 90.440
--------------------------------------------------------------------------------
Test time: 27.112447023391724

Epoch: [24][77/391]	LR: 0.001	Loss 1.4082 (1.5296)	Prec@1 46.094 (40.194)	
Epoch: [24][155/391]	LR: 0.001	Loss 1.5312 (1.5285)	Prec@1 35.938 (40.244)	
Epoch: [24][233/391]	LR: 0.001	Loss 1.6816 (1.5271)	Prec@1 35.156 (40.405)	
Epoch: [24][311/391]	LR: 0.001	Loss 1.5127 (1.5229)	Prec@1 40.625 (40.615)	
Epoch: [24][389/391]	LR: 0.001	Loss 1.4004 (1.5249)	Prec@1 44.531 (40.565)	
Total train loss: 1.5245

Train time: 22.968802452087402
 * Prec@1 90.420 Prec@5 99.460 Loss 0.3843
Best acc: 90.440
--------------------------------------------------------------------------------
Test time: 27.298776149749756


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 5
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.510 Prec@5 99.650 Loss 0.3188
Pre-trained Prec@1 with 5 layers frozen: 91.50999450683594 	 Loss: 0.31884765625

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.01	Loss 1.6846 (1.8296)	Prec@1 36.719 (34.245)	
Epoch: [0][155/391]	LR: 0.01	Loss 1.5801 (1.7304)	Prec@1 40.625 (35.752)	
Epoch: [0][233/391]	LR: 0.01	Loss 1.8213 (1.6848)	Prec@1 27.344 (36.462)	
Epoch: [0][311/391]	LR: 0.01	Loss 1.5439 (1.6565)	Prec@1 37.500 (37.242)	
Epoch: [0][389/391]	LR: 0.01	Loss 1.6201 (1.6438)	Prec@1 38.281 (37.476)	
Total train loss: 1.6439

Train time: 41.87294960021973
 * Prec@1 88.830 Prec@5 99.470 Loss 0.3889
Best acc: 88.830
--------------------------------------------------------------------------------
Test time: 46.318410873413086

Epoch: [1][77/391]	LR: 0.01	Loss 1.5361 (1.5617)	Prec@1 40.625 (39.383)	
Epoch: [1][155/391]	LR: 0.01	Loss 1.5391 (1.5568)	Prec@1 36.719 (39.518)	
Epoch: [1][233/391]	LR: 0.01	Loss 1.4258 (1.5551)	Prec@1 46.875 (39.640)	
Epoch: [1][311/391]	LR: 0.01	Loss 1.6230 (1.5593)	Prec@1 37.500 (39.506)	
Epoch: [1][389/391]	LR: 0.01	Loss 1.7568 (1.5596)	Prec@1 31.250 (39.481)	
Total train loss: 1.5595

Train time: 23.83483648300171
 * Prec@1 89.370 Prec@5 99.640 Loss 0.3809
Best acc: 89.370
--------------------------------------------------------------------------------
Test time: 28.363484144210815

Epoch: [2][77/391]	LR: 0.01	Loss 1.5791 (1.5211)	Prec@1 41.406 (40.825)	
Epoch: [2][155/391]	LR: 0.01	Loss 1.5117 (1.5337)	Prec@1 42.969 (40.695)	
Epoch: [2][233/391]	LR: 0.01	Loss 1.5918 (1.5403)	Prec@1 39.844 (40.398)	
Epoch: [2][311/391]	LR: 0.01	Loss 1.5459 (1.5444)	Prec@1 38.281 (40.092)	
Epoch: [2][389/391]	LR: 0.01	Loss 1.5723 (1.5478)	Prec@1 38.281 (39.972)	
Total train loss: 1.5478

Train time: 23.143521785736084
 * Prec@1 90.150 Prec@5 99.580 Loss 0.3701
Best acc: 90.150
--------------------------------------------------------------------------------
Test time: 27.522088289260864

Epoch: [3][77/391]	LR: 0.01	Loss 1.6523 (1.5372)	Prec@1 35.156 (39.914)	
Epoch: [3][155/391]	LR: 0.01	Loss 1.3105 (1.5416)	Prec@1 51.562 (39.914)	
Epoch: [3][233/391]	LR: 0.01	Loss 1.4326 (1.5379)	Prec@1 42.969 (40.338)	
Epoch: [3][311/391]	LR: 0.01	Loss 1.5459 (1.5411)	Prec@1 41.406 (40.237)	
Epoch: [3][389/391]	LR: 0.01	Loss 1.5137 (1.5418)	Prec@1 39.062 (40.132)	
Total train loss: 1.5417

Train time: 23.326420783996582
 * Prec@1 90.250 Prec@5 99.520 Loss 0.3779
Best acc: 90.250
--------------------------------------------------------------------------------
Test time: 27.530557870864868

Epoch: [4][77/391]	LR: 0.01	Loss 1.4658 (1.5460)	Prec@1 39.844 (39.974)	
Epoch: [4][155/391]	LR: 0.01	Loss 1.4004 (1.5395)	Prec@1 43.750 (40.039)	
Epoch: [4][233/391]	LR: 0.01	Loss 1.5869 (1.5397)	Prec@1 35.938 (40.077)	
Epoch: [4][311/391]	LR: 0.01	Loss 1.7207 (1.5397)	Prec@1 32.812 (40.144)	
Epoch: [4][389/391]	LR: 0.01	Loss 1.5537 (1.5387)	Prec@1 39.062 (40.212)	
Total train loss: 1.5391

Train time: 22.866000175476074
 * Prec@1 90.150 Prec@5 99.530 Loss 0.3792
Best acc: 90.250
--------------------------------------------------------------------------------
Test time: 27.079328060150146

Epoch: [5][77/391]	LR: 0.01	Loss 1.5742 (1.5296)	Prec@1 39.062 (41.006)	
Epoch: [5][155/391]	LR: 0.01	Loss 1.5615 (1.5373)	Prec@1 35.938 (40.500)	
Epoch: [5][233/391]	LR: 0.01	Loss 1.5488 (1.5382)	Prec@1 39.844 (40.351)	
Epoch: [5][311/391]	LR: 0.01	Loss 1.3672 (1.5363)	Prec@1 46.875 (40.309)	
Epoch: [5][389/391]	LR: 0.01	Loss 1.5195 (1.5356)	Prec@1 39.844 (40.361)	
Total train loss: 1.5354

Train time: 22.579529762268066
 * Prec@1 89.780 Prec@5 99.340 Loss 0.3928
Best acc: 90.250
--------------------------------------------------------------------------------
Test time: 26.851351022720337

Epoch: [6][77/391]	LR: 0.01	Loss 1.7920 (1.5348)	Prec@1 28.906 (40.074)	
Epoch: [6][155/391]	LR: 0.01	Loss 1.4131 (1.5319)	Prec@1 45.312 (40.194)	
Epoch: [6][233/391]	LR: 0.01	Loss 1.6230 (1.5310)	Prec@1 34.375 (40.224)	
Epoch: [6][311/391]	LR: 0.01	Loss 1.7090 (1.5334)	Prec@1 39.844 (40.229)	
Epoch: [6][389/391]	LR: 0.01	Loss 1.5830 (1.5342)	Prec@1 39.062 (40.228)	
Total train loss: 1.5337

Train time: 22.811822652816772
 * Prec@1 90.100 Prec@5 99.510 Loss 0.3782
Best acc: 90.250
--------------------------------------------------------------------------------
Test time: 27.308478355407715

Epoch: [7][77/391]	LR: 0.01	Loss 1.5439 (1.5400)	Prec@1 41.406 (40.104)	
Epoch: [7][155/391]	LR: 0.01	Loss 1.5293 (1.5248)	Prec@1 39.062 (40.635)	
Epoch: [7][233/391]	LR: 0.01	Loss 1.5986 (1.5285)	Prec@1 38.281 (40.488)	
Epoch: [7][311/391]	LR: 0.01	Loss 1.5420 (1.5288)	Prec@1 43.750 (40.600)	
Epoch: [7][389/391]	LR: 0.01	Loss 1.6133 (1.5320)	Prec@1 38.281 (40.523)	
Total train loss: 1.5319

Train time: 22.83268451690674
 * Prec@1 90.250 Prec@5 99.520 Loss 0.3733
Best acc: 90.250
--------------------------------------------------------------------------------
Test time: 27.443551063537598

Epoch: [8][77/391]	LR: 0.01	Loss 1.6807 (1.5311)	Prec@1 38.281 (40.935)	
Epoch: [8][155/391]	LR: 0.01	Loss 1.7295 (1.5302)	Prec@1 33.594 (40.630)	
Epoch: [8][233/391]	LR: 0.01	Loss 1.4287 (1.5330)	Prec@1 42.969 (40.471)	
Epoch: [8][311/391]	LR: 0.01	Loss 1.5527 (1.5333)	Prec@1 38.281 (40.427)	
Epoch: [8][389/391]	LR: 0.01	Loss 1.6455 (1.5322)	Prec@1 34.375 (40.515)	
Total train loss: 1.5318

Train time: 22.367952823638916
 * Prec@1 89.990 Prec@5 99.420 Loss 0.3972
Best acc: 90.250
--------------------------------------------------------------------------------
Test time: 26.518346548080444

Epoch: [9][77/391]	LR: 0.01	Loss 1.4307 (1.5213)	Prec@1 42.188 (41.026)	
Epoch: [9][155/391]	LR: 0.01	Loss 1.5635 (1.5261)	Prec@1 36.719 (40.510)	
Epoch: [9][233/391]	LR: 0.01	Loss 1.6660 (1.5292)	Prec@1 34.375 (40.535)	
Epoch: [9][311/391]	LR: 0.01	Loss 1.5928 (1.5313)	Prec@1 40.625 (40.500)	
Epoch: [9][389/391]	LR: 0.01	Loss 1.5674 (1.5301)	Prec@1 35.938 (40.491)	
Total train loss: 1.5303

Train time: 22.804417371749878
 * Prec@1 89.820 Prec@5 99.410 Loss 0.3984
Best acc: 90.250
--------------------------------------------------------------------------------
Test time: 27.239012718200684

Epoch: [10][77/391]	LR: 0.01	Loss 1.5576 (1.5267)	Prec@1 39.844 (40.765)	
Epoch: [10][155/391]	LR: 0.01	Loss 1.7080 (1.5266)	Prec@1 34.375 (40.865)	
Epoch: [10][233/391]	LR: 0.01	Loss 1.5967 (1.5247)	Prec@1 37.500 (40.932)	
Epoch: [10][311/391]	LR: 0.01	Loss 1.5967 (1.5281)	Prec@1 35.156 (40.703)	
Epoch: [10][389/391]	LR: 0.01	Loss 1.4443 (1.5302)	Prec@1 42.969 (40.577)	
Total train loss: 1.5306

Train time: 22.960707187652588
 * Prec@1 90.270 Prec@5 99.430 Loss 0.3833
Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 27.151451110839844

Epoch: [11][77/391]	LR: 0.01	Loss 1.3711 (1.5238)	Prec@1 46.875 (40.755)	
Epoch: [11][155/391]	LR: 0.01	Loss 1.5547 (1.5243)	Prec@1 36.719 (40.920)	
Epoch: [11][233/391]	LR: 0.01	Loss 1.4268 (1.5292)	Prec@1 44.531 (40.712)	
Epoch: [11][311/391]	LR: 0.01	Loss 1.6094 (1.5295)	Prec@1 39.062 (40.680)	
Epoch: [11][389/391]	LR: 0.01	Loss 1.5146 (1.5290)	Prec@1 43.750 (40.671)	
Total train loss: 1.5289

Train time: 22.921550750732422
 * Prec@1 89.820 Prec@5 99.430 Loss 0.4109
Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 27.187434434890747

Epoch: [12][77/391]	LR: 0.01	Loss 1.5645 (1.5380)	Prec@1 41.406 (40.385)	
Epoch: [12][155/391]	LR: 0.01	Loss 1.6709 (1.5317)	Prec@1 37.500 (40.680)	
Epoch: [12][233/391]	LR: 0.01	Loss 1.5049 (1.5322)	Prec@1 42.969 (40.749)	
Epoch: [12][311/391]	LR: 0.01	Loss 1.5146 (1.5294)	Prec@1 43.750 (40.795)	
Epoch: [12][389/391]	LR: 0.01	Loss 1.4971 (1.5291)	Prec@1 42.188 (40.761)	
Total train loss: 1.5292

Train time: 22.78842043876648
 * Prec@1 89.930 Prec@5 99.460 Loss 0.3904
Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 27.692970275878906

Epoch: [13][77/391]	LR: 0.01	Loss 1.4697 (1.5219)	Prec@1 41.406 (40.745)	
Epoch: [13][155/391]	LR: 0.01	Loss 1.6670 (1.5352)	Prec@1 39.062 (40.199)	
Epoch: [13][233/391]	LR: 0.01	Loss 1.5098 (1.5354)	Prec@1 42.188 (40.168)	
Epoch: [13][311/391]	LR: 0.01	Loss 1.6738 (1.5317)	Prec@1 35.156 (40.292)	
Epoch: [13][389/391]	LR: 0.01	Loss 1.5947 (1.5302)	Prec@1 39.844 (40.308)	
Total train loss: 1.5300

Train time: 23.706008911132812
 * Prec@1 90.210 Prec@5 99.430 Loss 0.3953
Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 28.96519374847412

Epoch: [14][77/391]	LR: 0.01	Loss 1.6299 (1.5483)	Prec@1 32.031 (39.543)	
Epoch: [14][155/391]	LR: 0.01	Loss 1.5723 (1.5387)	Prec@1 39.062 (40.114)	
Epoch: [14][233/391]	LR: 0.01	Loss 1.4463 (1.5287)	Prec@1 43.750 (40.478)	
Epoch: [14][311/391]	LR: 0.01	Loss 1.4561 (1.5297)	Prec@1 39.062 (40.522)	
Epoch: [14][389/391]	LR: 0.01	Loss 1.4775 (1.5290)	Prec@1 46.094 (40.533)	
Total train loss: 1.5293

Train time: 25.479036331176758
 * Prec@1 89.550 Prec@5 99.450 Loss 0.4094
Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 30.03036618232727

Epoch: [15][77/391]	LR: 0.01	Loss 1.4492 (1.5122)	Prec@1 48.438 (41.236)	
Epoch: [15][155/391]	LR: 0.01	Loss 1.5010 (1.5219)	Prec@1 40.625 (40.720)	
Epoch: [15][233/391]	LR: 0.01	Loss 1.4268 (1.5272)	Prec@1 44.531 (40.455)	
Epoch: [15][311/391]	LR: 0.01	Loss 1.6924 (1.5278)	Prec@1 35.938 (40.582)	
Epoch: [15][389/391]	LR: 0.01	Loss 1.4521 (1.5287)	Prec@1 45.312 (40.509)	
Total train loss: 1.5284

Train time: 24.35824155807495
 * Prec@1 89.880 Prec@5 99.480 Loss 0.3904
Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 28.746512413024902

Epoch: [16][77/391]	LR: 0.01	Loss 1.5293 (1.5323)	Prec@1 37.500 (40.054)	
Epoch: [16][155/391]	LR: 0.01	Loss 1.4922 (1.5313)	Prec@1 44.531 (40.269)	
Epoch: [16][233/391]	LR: 0.01	Loss 1.5186 (1.5295)	Prec@1 41.406 (40.311)	
Epoch: [16][311/391]	LR: 0.01	Loss 1.3506 (1.5291)	Prec@1 49.219 (40.420)	
Epoch: [16][389/391]	LR: 0.01	Loss 1.4844 (1.5281)	Prec@1 41.406 (40.467)	
Total train loss: 1.5284

Train time: 25.310237169265747
 * Prec@1 89.910 Prec@5 99.490 Loss 0.4099
Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 30.734753370285034

Epoch: [17][77/391]	LR: 0.01	Loss 1.4082 (1.5349)	Prec@1 47.656 (39.924)	
Epoch: [17][155/391]	LR: 0.01	Loss 1.4346 (1.5380)	Prec@1 48.438 (39.994)	
Epoch: [17][233/391]	LR: 0.01	Loss 1.6455 (1.5349)	Prec@1 32.031 (40.081)	
Epoch: [17][311/391]	LR: 0.01	Loss 1.4219 (1.5336)	Prec@1 43.750 (40.212)	
Epoch: [17][389/391]	LR: 0.01	Loss 1.3994 (1.5286)	Prec@1 48.438 (40.511)	
Total train loss: 1.5282

Train time: 27.033167600631714
 * Prec@1 90.150 Prec@5 99.450 Loss 0.3904
Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 33.255666732788086

Epoch: [18][77/391]	LR: 0.01	Loss 1.4893 (1.5131)	Prec@1 42.969 (41.416)	
Epoch: [18][155/391]	LR: 0.01	Loss 1.6094 (1.5292)	Prec@1 37.500 (40.700)	
Epoch: [18][233/391]	LR: 0.01	Loss 1.7002 (1.5308)	Prec@1 33.594 (40.565)	
Epoch: [18][311/391]	LR: 0.01	Loss 1.4229 (1.5288)	Prec@1 44.531 (40.620)	
Epoch: [18][389/391]	LR: 0.01	Loss 1.5527 (1.5278)	Prec@1 35.156 (40.729)	
Total train loss: 1.5277

Train time: 26.629194021224976
 * Prec@1 90.090 Prec@5 99.380 Loss 0.3982
Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 32.404685497283936

Epoch: [19][77/391]	LR: 0.01	Loss 1.5244 (1.5265)	Prec@1 41.406 (40.495)	
Epoch: [19][155/391]	LR: 0.01	Loss 1.3477 (1.5267)	Prec@1 47.656 (40.495)	
Epoch: [19][233/391]	LR: 0.01	Loss 1.7061 (1.5240)	Prec@1 32.812 (40.632)	
Epoch: [19][311/391]	LR: 0.01	Loss 1.5693 (1.5255)	Prec@1 39.062 (40.607)	
Epoch: [19][389/391]	LR: 0.01	Loss 1.7051 (1.5271)	Prec@1 33.594 (40.477)	
Total train loss: 1.5272

Train time: 25.897510528564453
 * Prec@1 90.150 Prec@5 99.350 Loss 0.4033
Best acc: 90.270
--------------------------------------------------------------------------------
Test time: 31.407917976379395

Epoch: [20][77/391]	LR: 0.001	Loss 1.5742 (1.5225)	Prec@1 38.281 (41.046)	
Epoch: [20][155/391]	LR: 0.001	Loss 1.5000 (1.5261)	Prec@1 42.969 (40.865)	
Epoch: [20][233/391]	LR: 0.001	Loss 1.5488 (1.5268)	Prec@1 39.844 (40.769)	
Epoch: [20][311/391]	LR: 0.001	Loss 1.5859 (1.5264)	Prec@1 37.500 (40.638)	
Epoch: [20][389/391]	LR: 0.001	Loss 1.4443 (1.5256)	Prec@1 44.531 (40.651)	
Total train loss: 1.5255

Train time: 25.511276245117188
 * Prec@1 90.310 Prec@5 99.450 Loss 0.3860
Best acc: 90.310
--------------------------------------------------------------------------------
Test time: 30.620776891708374

Epoch: [21][77/391]	LR: 0.001	Loss 1.2881 (1.5200)	Prec@1 50.000 (40.655)	
Epoch: [21][155/391]	LR: 0.001	Loss 1.4043 (1.5263)	Prec@1 44.531 (40.540)	
Epoch: [21][233/391]	LR: 0.001	Loss 1.5381 (1.5243)	Prec@1 39.062 (40.572)	
Epoch: [21][311/391]	LR: 0.001	Loss 1.8105 (1.5214)	Prec@1 28.906 (40.675)	
Epoch: [21][389/391]	LR: 0.001	Loss 1.5684 (1.5251)	Prec@1 39.844 (40.571)	
Total train loss: 1.5253

Train time: 25.167649030685425
 * Prec@1 90.090 Prec@5 99.390 Loss 0.3894
Best acc: 90.310
--------------------------------------------------------------------------------
Test time: 29.53290319442749

Epoch: [22][77/391]	LR: 0.001	Loss 1.3799 (1.5214)	Prec@1 48.438 (40.465)	
Epoch: [22][155/391]	LR: 0.001	Loss 1.5137 (1.5331)	Prec@1 42.188 (40.139)	
Epoch: [22][233/391]	LR: 0.001	Loss 1.6445 (1.5304)	Prec@1 39.844 (40.341)	
Epoch: [22][311/391]	LR: 0.001	Loss 1.4404 (1.5281)	Prec@1 43.750 (40.457)	
Epoch: [22][389/391]	LR: 0.001	Loss 1.4854 (1.5252)	Prec@1 40.625 (40.545)	
Total train loss: 1.5251

Train time: 22.67051672935486
 * Prec@1 90.310 Prec@5 99.460 Loss 0.3792
Best acc: 90.310
--------------------------------------------------------------------------------
Test time: 26.699604034423828

Epoch: [23][77/391]	LR: 0.001	Loss 1.3096 (1.5006)	Prec@1 48.438 (41.667)	
Epoch: [23][155/391]	LR: 0.001	Loss 1.6992 (1.5133)	Prec@1 35.156 (40.935)	
Epoch: [23][233/391]	LR: 0.001	Loss 1.5078 (1.5185)	Prec@1 43.750 (40.752)	
Epoch: [23][311/391]	LR: 0.001	Loss 1.7109 (1.5193)	Prec@1 32.812 (40.770)	
Epoch: [23][389/391]	LR: 0.001	Loss 1.4971 (1.5245)	Prec@1 40.625 (40.575)	
Total train loss: 1.5249

Train time: 23.630650997161865
 * Prec@1 90.310 Prec@5 99.440 Loss 0.3916
Best acc: 90.310
--------------------------------------------------------------------------------
Test time: 28.10883927345276

Epoch: [24][77/391]	LR: 0.001	Loss 1.4795 (1.5112)	Prec@1 43.750 (41.026)	
Epoch: [24][155/391]	LR: 0.001	Loss 1.4443 (1.5147)	Prec@1 45.312 (40.900)	
Epoch: [24][233/391]	LR: 0.001	Loss 1.6172 (1.5194)	Prec@1 37.500 (40.715)	
Epoch: [24][311/391]	LR: 0.001	Loss 1.4189 (1.5203)	Prec@1 45.312 (40.753)	
Epoch: [24][389/391]	LR: 0.001	Loss 1.4365 (1.5246)	Prec@1 44.531 (40.565)	
Total train loss: 1.5245

Train time: 22.290775775909424
 * Prec@1 90.160 Prec@5 99.470 Loss 0.3884
Best acc: 90.310
--------------------------------------------------------------------------------
Test time: 26.592527151107788


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 7
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.490 Prec@5 99.640 Loss 0.3176
Pre-trained Prec@1 with 7 layers frozen: 91.48999786376953 	 Loss: 0.317626953125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.01	Loss 1.5898 (1.8173)	Prec@1 39.062 (34.295)	
Epoch: [0][155/391]	LR: 0.01	Loss 1.9170 (1.7138)	Prec@1 26.562 (35.927)	
Epoch: [0][233/391]	LR: 0.01	Loss 1.4277 (1.6720)	Prec@1 42.188 (36.675)	
Epoch: [0][311/391]	LR: 0.01	Loss 1.5479 (1.6482)	Prec@1 41.406 (37.210)	
Epoch: [0][389/391]	LR: 0.01	Loss 1.6191 (1.6379)	Prec@1 37.500 (37.408)	
Total train loss: 1.6378

Train time: 40.88632535934448
 * Prec@1 89.840 Prec@5 99.600 Loss 0.3542
Best acc: 89.840
--------------------------------------------------------------------------------
Test time: 45.49597430229187

Epoch: [1][77/391]	LR: 0.01	Loss 1.6318 (1.5766)	Prec@1 38.281 (38.972)	
Epoch: [1][155/391]	LR: 0.01	Loss 1.5820 (1.5627)	Prec@1 36.719 (39.293)	
Epoch: [1][233/391]	LR: 0.01	Loss 1.7324 (1.5582)	Prec@1 31.250 (39.380)	
Epoch: [1][311/391]	LR: 0.01	Loss 1.6533 (1.5582)	Prec@1 36.719 (39.413)	
Epoch: [1][389/391]	LR: 0.01	Loss 1.4736 (1.5591)	Prec@1 42.969 (39.353)	
Total train loss: 1.5590

Train time: 22.4083354473114
 * Prec@1 90.120 Prec@5 99.670 Loss 0.3479
Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 26.834325790405273

Epoch: [2][77/391]	LR: 0.01	Loss 1.4629 (1.5448)	Prec@1 42.969 (40.304)	
Epoch: [2][155/391]	LR: 0.01	Loss 1.5459 (1.5385)	Prec@1 41.406 (40.415)	
Epoch: [2][233/391]	LR: 0.01	Loss 1.4463 (1.5402)	Prec@1 48.438 (40.361)	
Epoch: [2][311/391]	LR: 0.01	Loss 1.6025 (1.5395)	Prec@1 36.719 (40.360)	
Epoch: [2][389/391]	LR: 0.01	Loss 1.3672 (1.5456)	Prec@1 44.531 (40.050)	
Total train loss: 1.5458

Train time: 21.994124174118042
 * Prec@1 90.010 Prec@5 99.610 Loss 0.3638
Best acc: 90.120
--------------------------------------------------------------------------------
Test time: 26.27638292312622

Epoch: [3][77/391]	LR: 0.01	Loss 1.4756 (1.5439)	Prec@1 42.188 (39.804)	
Epoch: [3][155/391]	LR: 0.01	Loss 1.4160 (1.5385)	Prec@1 44.531 (40.204)	
Epoch: [3][233/391]	LR: 0.01	Loss 1.4209 (1.5382)	Prec@1 46.094 (40.391)	
Epoch: [3][311/391]	LR: 0.01	Loss 1.5439 (1.5402)	Prec@1 38.281 (40.294)	
Epoch: [3][389/391]	LR: 0.01	Loss 1.6963 (1.5414)	Prec@1 36.719 (40.238)	
Total train loss: 1.5411

Train time: 21.35044288635254
 * Prec@1 90.160 Prec@5 99.570 Loss 0.3799
Best acc: 90.160
--------------------------------------------------------------------------------
Test time: 25.88065505027771

Epoch: [4][77/391]	LR: 0.01	Loss 1.6660 (1.5394)	Prec@1 37.500 (39.874)	
Epoch: [4][155/391]	LR: 0.01	Loss 1.4414 (1.5324)	Prec@1 45.312 (40.430)	
Epoch: [4][233/391]	LR: 0.01	Loss 1.4443 (1.5319)	Prec@1 42.969 (40.365)	
Epoch: [4][311/391]	LR: 0.01	Loss 1.4541 (1.5337)	Prec@1 41.406 (40.365)	
Epoch: [4][389/391]	LR: 0.01	Loss 1.5615 (1.5360)	Prec@1 34.375 (40.282)	
Total train loss: 1.5361

Train time: 21.60604453086853
 * Prec@1 90.220 Prec@5 99.490 Loss 0.4001
Best acc: 90.220
--------------------------------------------------------------------------------
Test time: 26.2762348651886

Epoch: [5][77/391]	LR: 0.01	Loss 1.5693 (1.5329)	Prec@1 36.719 (40.234)	
Epoch: [5][155/391]	LR: 0.01	Loss 1.4863 (1.5328)	Prec@1 40.625 (40.279)	
Epoch: [5][233/391]	LR: 0.01	Loss 1.5068 (1.5343)	Prec@1 40.625 (40.241)	
Epoch: [5][311/391]	LR: 0.01	Loss 1.4883 (1.5336)	Prec@1 40.625 (40.267)	
Epoch: [5][389/391]	LR: 0.01	Loss 1.4473 (1.5342)	Prec@1 38.281 (40.304)	
Total train loss: 1.5345

Train time: 23.637071132659912
 * Prec@1 90.160 Prec@5 99.520 Loss 0.3877
Best acc: 90.220
--------------------------------------------------------------------------------
Test time: 28.155755281448364

Epoch: [6][77/391]	LR: 0.01	Loss 1.4902 (1.5337)	Prec@1 42.969 (40.415)	
Epoch: [6][155/391]	LR: 0.01	Loss 1.5762 (1.5296)	Prec@1 36.719 (40.695)	
Epoch: [6][233/391]	LR: 0.01	Loss 1.4541 (1.5330)	Prec@1 43.750 (40.481)	
Epoch: [6][311/391]	LR: 0.01	Loss 1.5283 (1.5315)	Prec@1 39.844 (40.522)	
Epoch: [6][389/391]	LR: 0.01	Loss 1.6602 (1.5333)	Prec@1 34.375 (40.357)	
Total train loss: 1.5330

Train time: 24.02941656112671
 * Prec@1 90.170 Prec@5 99.520 Loss 0.3916
Best acc: 90.220
--------------------------------------------------------------------------------
Test time: 28.87047290802002

Epoch: [7][77/391]	LR: 0.01	Loss 1.5527 (1.5566)	Prec@1 36.719 (39.293)	
Epoch: [7][155/391]	LR: 0.01	Loss 1.6211 (1.5441)	Prec@1 38.281 (40.139)	
Epoch: [7][233/391]	LR: 0.01	Loss 1.6299 (1.5424)	Prec@1 38.281 (40.191)	
Epoch: [7][311/391]	LR: 0.01	Loss 1.5537 (1.5369)	Prec@1 38.281 (40.327)	
Epoch: [7][389/391]	LR: 0.01	Loss 1.5586 (1.5337)	Prec@1 37.500 (40.575)	
Total train loss: 1.5337

Train time: 22.737895488739014
 * Prec@1 90.480 Prec@5 99.480 Loss 0.3701
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 27.884227514266968

Epoch: [8][77/391]	LR: 0.01	Loss 1.5107 (1.5263)	Prec@1 39.844 (40.795)	
Epoch: [8][155/391]	LR: 0.01	Loss 1.5957 (1.5282)	Prec@1 36.719 (40.755)	
Epoch: [8][233/391]	LR: 0.01	Loss 1.5557 (1.5309)	Prec@1 36.719 (40.718)	
Epoch: [8][311/391]	LR: 0.01	Loss 1.4922 (1.5321)	Prec@1 41.406 (40.605)	
Epoch: [8][389/391]	LR: 0.01	Loss 1.3779 (1.5328)	Prec@1 46.875 (40.473)	
Total train loss: 1.5328

Train time: 25.850471019744873
 * Prec@1 90.060 Prec@5 99.440 Loss 0.4077
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 31.393694400787354

Epoch: [9][77/391]	LR: 0.01	Loss 1.6104 (1.5404)	Prec@1 39.062 (40.174)	
Epoch: [9][155/391]	LR: 0.01	Loss 1.6338 (1.5360)	Prec@1 34.375 (40.204)	
Epoch: [9][233/391]	LR: 0.01	Loss 1.5479 (1.5330)	Prec@1 41.406 (40.365)	
Epoch: [9][311/391]	LR: 0.01	Loss 1.5088 (1.5326)	Prec@1 40.625 (40.405)	
Epoch: [9][389/391]	LR: 0.01	Loss 1.3730 (1.5290)	Prec@1 46.094 (40.527)	
Total train loss: 1.5290

Train time: 27.029842138290405
 * Prec@1 90.280 Prec@5 99.480 Loss 0.3884
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 32.45890235900879

Epoch: [10][77/391]	LR: 0.01	Loss 1.5166 (1.5506)	Prec@1 39.062 (39.603)	
Epoch: [10][155/391]	LR: 0.01	Loss 1.5264 (1.5424)	Prec@1 39.844 (40.039)	
Epoch: [10][233/391]	LR: 0.01	Loss 1.4336 (1.5314)	Prec@1 45.312 (40.431)	
Epoch: [10][311/391]	LR: 0.01	Loss 1.6572 (1.5301)	Prec@1 35.938 (40.475)	
Epoch: [10][389/391]	LR: 0.01	Loss 1.4512 (1.5308)	Prec@1 42.188 (40.463)	
Total train loss: 1.5310

Train time: 26.385600805282593
 * Prec@1 90.390 Prec@5 99.460 Loss 0.3840
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 32.222530126571655

Epoch: [11][77/391]	LR: 0.01	Loss 1.5420 (1.5176)	Prec@1 36.719 (41.056)	
Epoch: [11][155/391]	LR: 0.01	Loss 1.3730 (1.5127)	Prec@1 46.875 (41.386)	
Epoch: [11][233/391]	LR: 0.01	Loss 1.3857 (1.5262)	Prec@1 46.094 (40.889)	
Epoch: [11][311/391]	LR: 0.01	Loss 1.4424 (1.5294)	Prec@1 42.969 (40.693)	
Epoch: [11][389/391]	LR: 0.01	Loss 1.3721 (1.5288)	Prec@1 49.219 (40.691)	
Total train loss: 1.5288

Train time: 25.8869309425354
 * Prec@1 89.550 Prec@5 99.520 Loss 0.4160
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 31.24739646911621

Epoch: [12][77/391]	LR: 0.01	Loss 1.5928 (1.5185)	Prec@1 37.500 (40.986)	
Epoch: [12][155/391]	LR: 0.01	Loss 1.3789 (1.5229)	Prec@1 45.312 (40.725)	
Epoch: [12][233/391]	LR: 0.01	Loss 1.5537 (1.5223)	Prec@1 38.281 (40.692)	
Epoch: [12][311/391]	LR: 0.01	Loss 1.7422 (1.5252)	Prec@1 32.031 (40.547)	
Epoch: [12][389/391]	LR: 0.01	Loss 1.5889 (1.5295)	Prec@1 36.719 (40.377)	
Total train loss: 1.5298

Train time: 26.306617975234985
 * Prec@1 90.110 Prec@5 99.500 Loss 0.4001
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 32.05719184875488

Epoch: [13][77/391]	LR: 0.01	Loss 1.4121 (1.5297)	Prec@1 45.312 (40.635)	
Epoch: [13][155/391]	LR: 0.01	Loss 1.3896 (1.5269)	Prec@1 44.531 (40.790)	
Epoch: [13][233/391]	LR: 0.01	Loss 1.5898 (1.5341)	Prec@1 35.938 (40.471)	
Epoch: [13][311/391]	LR: 0.01	Loss 1.5391 (1.5323)	Prec@1 40.625 (40.482)	
Epoch: [13][389/391]	LR: 0.01	Loss 1.5283 (1.5291)	Prec@1 41.406 (40.575)	
Total train loss: 1.5292

Train time: 22.44572687149048
 * Prec@1 90.240 Prec@5 99.450 Loss 0.3857
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 26.585588932037354

Epoch: [14][77/391]	LR: 0.01	Loss 1.6396 (1.5179)	Prec@1 35.156 (40.575)	
Epoch: [14][155/391]	LR: 0.01	Loss 1.7139 (1.5257)	Prec@1 33.594 (40.760)	
Epoch: [14][233/391]	LR: 0.01	Loss 1.6602 (1.5314)	Prec@1 32.812 (40.592)	
Epoch: [14][311/391]	LR: 0.01	Loss 1.4648 (1.5279)	Prec@1 42.188 (40.755)	
Epoch: [14][389/391]	LR: 0.01	Loss 1.6230 (1.5296)	Prec@1 35.156 (40.591)	
Total train loss: 1.5296

Train time: 21.469175577163696
 * Prec@1 90.240 Prec@5 99.440 Loss 0.3967
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 26.388517141342163

Epoch: [15][77/391]	LR: 0.01	Loss 1.6006 (1.5246)	Prec@1 42.188 (40.865)	
Epoch: [15][155/391]	LR: 0.01	Loss 1.6631 (1.5228)	Prec@1 35.938 (40.961)	
Epoch: [15][233/391]	LR: 0.01	Loss 1.5244 (1.5267)	Prec@1 44.531 (40.779)	
Epoch: [15][311/391]	LR: 0.01	Loss 1.6006 (1.5291)	Prec@1 39.062 (40.645)	
Epoch: [15][389/391]	LR: 0.01	Loss 1.5723 (1.5287)	Prec@1 33.594 (40.681)	
Total train loss: 1.5285

Train time: 20.576987981796265
 * Prec@1 90.020 Prec@5 99.480 Loss 0.4087
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 24.788846731185913

Epoch: [16][77/391]	LR: 0.01	Loss 1.5146 (1.5342)	Prec@1 42.188 (40.274)	
Epoch: [16][155/391]	LR: 0.01	Loss 1.4336 (1.5268)	Prec@1 45.312 (40.520)	
Epoch: [16][233/391]	LR: 0.01	Loss 1.4922 (1.5295)	Prec@1 45.312 (40.501)	
Epoch: [16][311/391]	LR: 0.01	Loss 1.5361 (1.5270)	Prec@1 39.062 (40.572)	
Epoch: [16][389/391]	LR: 0.01	Loss 1.5146 (1.5286)	Prec@1 42.969 (40.509)	
Total train loss: 1.5286

Train time: 21.05480456352234
 * Prec@1 90.220 Prec@5 99.410 Loss 0.4082
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 25.22003936767578

Epoch: [17][77/391]	LR: 0.01	Loss 1.5840 (1.5293)	Prec@1 41.406 (40.415)	
Epoch: [17][155/391]	LR: 0.01	Loss 1.5225 (1.5351)	Prec@1 36.719 (40.059)	
Epoch: [17][233/391]	LR: 0.01	Loss 1.6162 (1.5297)	Prec@1 36.719 (40.418)	
Epoch: [17][311/391]	LR: 0.01	Loss 1.6484 (1.5264)	Prec@1 35.938 (40.552)	
Epoch: [17][389/391]	LR: 0.01	Loss 1.4746 (1.5275)	Prec@1 42.188 (40.603)	
Total train loss: 1.5278

Train time: 20.90167760848999
 * Prec@1 90.210 Prec@5 99.420 Loss 0.4001
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 25.696744680404663

Epoch: [18][77/391]	LR: 0.01	Loss 1.5264 (1.5414)	Prec@1 40.625 (39.914)	
Epoch: [18][155/391]	LR: 0.01	Loss 1.5869 (1.5375)	Prec@1 38.281 (39.954)	
Epoch: [18][233/391]	LR: 0.01	Loss 1.5137 (1.5284)	Prec@1 39.844 (40.415)	
Epoch: [18][311/391]	LR: 0.01	Loss 1.6523 (1.5288)	Prec@1 35.938 (40.452)	
Epoch: [18][389/391]	LR: 0.01	Loss 1.3525 (1.5273)	Prec@1 50.000 (40.481)	
Total train loss: 1.5275

Train time: 21.38370704650879
 * Prec@1 89.400 Prec@5 99.360 Loss 0.4419
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 26.033190727233887

Epoch: [19][77/391]	LR: 0.01	Loss 1.3555 (1.5212)	Prec@1 44.531 (40.855)	
Epoch: [19][155/391]	LR: 0.01	Loss 1.5889 (1.5223)	Prec@1 39.062 (40.805)	
Epoch: [19][233/391]	LR: 0.01	Loss 1.4385 (1.5259)	Prec@1 45.312 (40.678)	
Epoch: [19][311/391]	LR: 0.01	Loss 1.5723 (1.5287)	Prec@1 41.406 (40.592)	
Epoch: [19][389/391]	LR: 0.01	Loss 1.5918 (1.5271)	Prec@1 35.938 (40.683)	
Total train loss: 1.5271

Train time: 21.21063232421875
 * Prec@1 89.820 Prec@5 99.430 Loss 0.4111
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 25.288769245147705

Epoch: [20][77/391]	LR: 0.001	Loss 1.5889 (1.5292)	Prec@1 36.719 (40.825)	
Epoch: [20][155/391]	LR: 0.001	Loss 1.5967 (1.5213)	Prec@1 39.062 (41.006)	
Epoch: [20][233/391]	LR: 0.001	Loss 1.5322 (1.5279)	Prec@1 39.844 (40.695)	
Epoch: [20][311/391]	LR: 0.001	Loss 1.5850 (1.5267)	Prec@1 35.156 (40.685)	
Epoch: [20][389/391]	LR: 0.001	Loss 1.4541 (1.5257)	Prec@1 46.094 (40.691)	
Total train loss: 1.5259

Train time: 21.220544815063477
 * Prec@1 90.070 Prec@5 99.450 Loss 0.3958
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 25.681731700897217

Epoch: [21][77/391]	LR: 0.001	Loss 1.7168 (1.5397)	Prec@1 31.250 (39.814)	
Epoch: [21][155/391]	LR: 0.001	Loss 1.5088 (1.5215)	Prec@1 38.281 (40.390)	
Epoch: [21][233/391]	LR: 0.001	Loss 1.5830 (1.5267)	Prec@1 35.938 (40.388)	
Epoch: [21][311/391]	LR: 0.001	Loss 1.4922 (1.5232)	Prec@1 37.500 (40.532)	
Epoch: [21][389/391]	LR: 0.001	Loss 1.3496 (1.5247)	Prec@1 49.219 (40.495)	
Total train loss: 1.5248

Train time: 21.216322898864746
 * Prec@1 90.010 Prec@5 99.440 Loss 0.4045
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 25.636992931365967

Epoch: [22][77/391]	LR: 0.001	Loss 1.6953 (1.5337)	Prec@1 32.031 (40.395)	
Epoch: [22][155/391]	LR: 0.001	Loss 1.5869 (1.5301)	Prec@1 35.156 (40.590)	
Epoch: [22][233/391]	LR: 0.001	Loss 1.5117 (1.5264)	Prec@1 41.406 (40.612)	
Epoch: [22][311/391]	LR: 0.001	Loss 1.5918 (1.5245)	Prec@1 38.281 (40.605)	
Epoch: [22][389/391]	LR: 0.001	Loss 1.6494 (1.5251)	Prec@1 36.719 (40.591)	
Total train loss: 1.5251

Train time: 21.758650064468384
 * Prec@1 90.110 Prec@5 99.440 Loss 0.4009
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 26.284297227859497

Epoch: [23][77/391]	LR: 0.001	Loss 1.5596 (1.5005)	Prec@1 37.500 (41.727)	
Epoch: [23][155/391]	LR: 0.001	Loss 1.5723 (1.5145)	Prec@1 39.844 (40.870)	
Epoch: [23][233/391]	LR: 0.001	Loss 1.3477 (1.5218)	Prec@1 48.438 (40.635)	
Epoch: [23][311/391]	LR: 0.001	Loss 1.5439 (1.5200)	Prec@1 41.406 (40.753)	
Epoch: [23][389/391]	LR: 0.001	Loss 1.6162 (1.5248)	Prec@1 38.281 (40.507)	
Total train loss: 1.5248

Train time: 22.598549127578735
 * Prec@1 90.180 Prec@5 99.450 Loss 0.3989
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 27.14839243888855

Epoch: [24][77/391]	LR: 0.001	Loss 1.4814 (1.5422)	Prec@1 42.188 (39.683)	
Epoch: [24][155/391]	LR: 0.001	Loss 1.4072 (1.5240)	Prec@1 42.188 (40.530)	
Epoch: [24][233/391]	LR: 0.001	Loss 1.5723 (1.5274)	Prec@1 39.062 (40.441)	
Epoch: [24][311/391]	LR: 0.001	Loss 1.4248 (1.5252)	Prec@1 44.531 (40.450)	
Epoch: [24][389/391]	LR: 0.001	Loss 1.5635 (1.5258)	Prec@1 37.500 (40.395)	
Total train loss: 1.5256

Train time: 22.961079359054565
 * Prec@1 90.370 Prec@5 99.450 Loss 0.3901
Best acc: 90.480
--------------------------------------------------------------------------------
Test time: 27.778941869735718


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 9
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.420 Prec@5 99.640 Loss 0.3250
Pre-trained Prec@1 with 9 layers frozen: 91.41999816894531 	 Loss: 0.324951171875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.01	Loss 1.7832 (1.7662)	Prec@1 30.469 (35.457)	
Epoch: [0][155/391]	LR: 0.01	Loss 1.5625 (1.7002)	Prec@1 41.406 (36.273)	
Epoch: [0][233/391]	LR: 0.01	Loss 1.5322 (1.6615)	Prec@1 38.281 (37.039)	
Epoch: [0][311/391]	LR: 0.01	Loss 1.5283 (1.6429)	Prec@1 37.500 (37.370)	
Epoch: [0][389/391]	LR: 0.01	Loss 1.6064 (1.6273)	Prec@1 37.500 (37.776)	
Total train loss: 1.6272

Train time: 42.12750220298767
 * Prec@1 89.810 Prec@5 99.540 Loss 0.3557
Best acc: 89.810
--------------------------------------------------------------------------------
Test time: 47.446274280548096

Epoch: [1][77/391]	LR: 0.01	Loss 1.5254 (1.5511)	Prec@1 39.062 (39.874)	
Epoch: [1][155/391]	LR: 0.01	Loss 1.5400 (1.5494)	Prec@1 39.062 (40.014)	
Epoch: [1][233/391]	LR: 0.01	Loss 1.5654 (1.5530)	Prec@1 39.844 (39.764)	
Epoch: [1][311/391]	LR: 0.01	Loss 1.5586 (1.5546)	Prec@1 37.500 (39.759)	
Epoch: [1][389/391]	LR: 0.01	Loss 1.6006 (1.5552)	Prec@1 36.719 (39.675)	
Total train loss: 1.5552

Train time: 23.488088369369507
 * Prec@1 89.820 Prec@5 99.520 Loss 0.3594
Best acc: 89.820
--------------------------------------------------------------------------------
Test time: 27.765397310256958

Epoch: [2][77/391]	LR: 0.01	Loss 1.6016 (1.5351)	Prec@1 35.156 (40.355)	
Epoch: [2][155/391]	LR: 0.01	Loss 1.5527 (1.5464)	Prec@1 42.188 (39.909)	
Epoch: [2][233/391]	LR: 0.01	Loss 1.6523 (1.5448)	Prec@1 34.375 (40.017)	
Epoch: [2][311/391]	LR: 0.01	Loss 1.6709 (1.5452)	Prec@1 39.844 (39.991)	
Epoch: [2][389/391]	LR: 0.01	Loss 1.5947 (1.5451)	Prec@1 39.062 (39.972)	
Total train loss: 1.5449

Train time: 20.354260683059692
 * Prec@1 89.650 Prec@5 99.600 Loss 0.3745
Best acc: 89.820
--------------------------------------------------------------------------------
Test time: 24.948486804962158

Epoch: [3][77/391]	LR: 0.01	Loss 1.6357 (1.5348)	Prec@1 33.594 (39.804)	
Epoch: [3][155/391]	LR: 0.01	Loss 1.4912 (1.5371)	Prec@1 42.969 (40.079)	
Epoch: [3][233/391]	LR: 0.01	Loss 1.5410 (1.5377)	Prec@1 38.281 (40.121)	
Epoch: [3][311/391]	LR: 0.01	Loss 1.6807 (1.5394)	Prec@1 32.812 (40.059)	
Epoch: [3][389/391]	LR: 0.01	Loss 1.4678 (1.5409)	Prec@1 40.625 (39.960)	
Total train loss: 1.5410

Train time: 19.812901258468628
 * Prec@1 90.460 Prec@5 99.640 Loss 0.3792
Best acc: 90.460
--------------------------------------------------------------------------------
Test time: 24.23660945892334

Epoch: [4][77/391]	LR: 0.01	Loss 1.3320 (1.5598)	Prec@1 53.125 (39.603)	
Epoch: [4][155/391]	LR: 0.01	Loss 1.5635 (1.5477)	Prec@1 34.375 (39.934)	
Epoch: [4][233/391]	LR: 0.01	Loss 1.4492 (1.5457)	Prec@1 41.406 (39.880)	
Epoch: [4][311/391]	LR: 0.01	Loss 1.4805 (1.5415)	Prec@1 40.625 (40.059)	
Epoch: [4][389/391]	LR: 0.01	Loss 1.4102 (1.5370)	Prec@1 43.750 (40.194)	
Total train loss: 1.5369

Train time: 19.771228790283203
 * Prec@1 90.630 Prec@5 99.540 Loss 0.3618
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 23.65553379058838

Epoch: [5][77/391]	LR: 0.01	Loss 1.7510 (1.5429)	Prec@1 32.812 (39.513)	
Epoch: [5][155/391]	LR: 0.01	Loss 1.5039 (1.5402)	Prec@1 41.406 (39.789)	
Epoch: [5][233/391]	LR: 0.01	Loss 1.4346 (1.5354)	Prec@1 41.406 (40.124)	
Epoch: [5][311/391]	LR: 0.01	Loss 1.4561 (1.5374)	Prec@1 45.312 (40.154)	
Epoch: [5][389/391]	LR: 0.01	Loss 1.3906 (1.5343)	Prec@1 45.312 (40.244)	
Total train loss: 1.5346

Train time: 19.591461181640625
 * Prec@1 89.760 Prec@5 99.620 Loss 0.4021
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 23.14606761932373

Epoch: [6][77/391]	LR: 0.01	Loss 1.4922 (1.5214)	Prec@1 40.625 (41.156)	
Epoch: [6][155/391]	LR: 0.01	Loss 1.5166 (1.5320)	Prec@1 43.750 (40.565)	
Epoch: [6][233/391]	LR: 0.01	Loss 1.4746 (1.5323)	Prec@1 43.750 (40.598)	
Epoch: [6][311/391]	LR: 0.01	Loss 1.6162 (1.5319)	Prec@1 35.156 (40.560)	
Epoch: [6][389/391]	LR: 0.01	Loss 1.4648 (1.5321)	Prec@1 46.094 (40.509)	
Total train loss: 1.5324

Train time: 20.154803037643433
 * Prec@1 90.290 Prec@5 99.480 Loss 0.3811
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 24.808212757110596

Epoch: [7][77/391]	LR: 0.01	Loss 1.7939 (1.5371)	Prec@1 26.562 (40.254)	
Epoch: [7][155/391]	LR: 0.01	Loss 1.4678 (1.5316)	Prec@1 41.406 (40.560)	
Epoch: [7][233/391]	LR: 0.01	Loss 1.5752 (1.5315)	Prec@1 36.719 (40.532)	
Epoch: [7][311/391]	LR: 0.01	Loss 1.5918 (1.5357)	Prec@1 32.812 (40.309)	
Epoch: [7][389/391]	LR: 0.01	Loss 1.4844 (1.5318)	Prec@1 42.188 (40.481)	
Total train loss: 1.5319

Train time: 19.05109977722168
 * Prec@1 90.230 Prec@5 99.570 Loss 0.3792
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 23.54970693588257

Epoch: [8][77/391]	LR: 0.01	Loss 1.4658 (1.5189)	Prec@1 39.062 (40.525)	
Epoch: [8][155/391]	LR: 0.01	Loss 1.5166 (1.5234)	Prec@1 43.750 (40.585)	
Epoch: [8][233/391]	LR: 0.01	Loss 1.6689 (1.5306)	Prec@1 32.812 (40.405)	
Epoch: [8][311/391]	LR: 0.01	Loss 1.5830 (1.5330)	Prec@1 38.281 (40.387)	
Epoch: [8][389/391]	LR: 0.01	Loss 1.5928 (1.5306)	Prec@1 37.500 (40.429)	
Total train loss: 1.5307

Train time: 19.513506412506104
 * Prec@1 90.060 Prec@5 99.510 Loss 0.3977
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 23.52124857902527

Epoch: [9][77/391]	LR: 0.01	Loss 1.5752 (1.5370)	Prec@1 39.062 (40.114)	
Epoch: [9][155/391]	LR: 0.01	Loss 1.6191 (1.5274)	Prec@1 36.719 (40.455)	
Epoch: [9][233/391]	LR: 0.01	Loss 1.5273 (1.5301)	Prec@1 39.062 (40.264)	
Epoch: [9][311/391]	LR: 0.01	Loss 1.6084 (1.5247)	Prec@1 39.844 (40.575)	
Epoch: [9][389/391]	LR: 0.01	Loss 1.6797 (1.5303)	Prec@1 32.812 (40.369)	
Total train loss: 1.5303

Train time: 18.998971700668335
 * Prec@1 90.340 Prec@5 99.480 Loss 0.3889
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 23.166206121444702

Epoch: [10][77/391]	LR: 0.01	Loss 1.3398 (1.5295)	Prec@1 49.219 (40.665)	
Epoch: [10][155/391]	LR: 0.01	Loss 1.4531 (1.5307)	Prec@1 42.969 (40.505)	
Epoch: [10][233/391]	LR: 0.01	Loss 1.5674 (1.5287)	Prec@1 39.844 (40.545)	
Epoch: [10][311/391]	LR: 0.01	Loss 1.4531 (1.5313)	Prec@1 46.094 (40.395)	
Epoch: [10][389/391]	LR: 0.01	Loss 1.5439 (1.5302)	Prec@1 39.062 (40.385)	
Total train loss: 1.5302

Train time: 19.563942909240723
 * Prec@1 90.570 Prec@5 99.450 Loss 0.3835
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 23.891031503677368

Epoch: [11][77/391]	LR: 0.01	Loss 1.5361 (1.5295)	Prec@1 39.844 (40.485)	
Epoch: [11][155/391]	LR: 0.01	Loss 1.6553 (1.5247)	Prec@1 33.594 (40.735)	
Epoch: [11][233/391]	LR: 0.01	Loss 1.4736 (1.5281)	Prec@1 39.062 (40.518)	
Epoch: [11][311/391]	LR: 0.01	Loss 1.5938 (1.5310)	Prec@1 35.938 (40.360)	
Epoch: [11][389/391]	LR: 0.01	Loss 1.4326 (1.5289)	Prec@1 41.406 (40.437)	
Total train loss: 1.5292

Train time: 19.42141819000244
 * Prec@1 90.290 Prec@5 99.470 Loss 0.3936
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 23.58130955696106

Epoch: [12][77/391]	LR: 0.01	Loss 1.5312 (1.5372)	Prec@1 39.062 (39.573)	
Epoch: [12][155/391]	LR: 0.01	Loss 1.4639 (1.5397)	Prec@1 41.406 (39.663)	
Epoch: [12][233/391]	LR: 0.01	Loss 1.4951 (1.5346)	Prec@1 41.406 (39.924)	
Epoch: [12][311/391]	LR: 0.01	Loss 1.5312 (1.5323)	Prec@1 42.188 (40.094)	
Epoch: [12][389/391]	LR: 0.01	Loss 1.4248 (1.5295)	Prec@1 42.969 (40.294)	
Total train loss: 1.5294

Train time: 19.43722701072693
 * Prec@1 90.230 Prec@5 99.460 Loss 0.3938
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 23.984917163848877

Epoch: [13][77/391]	LR: 0.01	Loss 1.4951 (1.5246)	Prec@1 39.844 (40.695)	
Epoch: [13][155/391]	LR: 0.01	Loss 1.5850 (1.5227)	Prec@1 36.719 (40.810)	
Epoch: [13][233/391]	LR: 0.01	Loss 1.5654 (1.5284)	Prec@1 39.844 (40.572)	
Epoch: [13][311/391]	LR: 0.01	Loss 1.4307 (1.5295)	Prec@1 43.750 (40.452)	
Epoch: [13][389/391]	LR: 0.01	Loss 1.5000 (1.5297)	Prec@1 42.969 (40.485)	
Total train loss: 1.5299

Train time: 19.581961631774902
 * Prec@1 90.220 Prec@5 99.430 Loss 0.4021
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 23.860292434692383

Epoch: [14][77/391]	LR: 0.01	Loss 1.4922 (1.5306)	Prec@1 41.406 (40.375)	
Epoch: [14][155/391]	LR: 0.01	Loss 1.4805 (1.5289)	Prec@1 43.750 (40.500)	
Epoch: [14][233/391]	LR: 0.01	Loss 1.6113 (1.5355)	Prec@1 34.375 (40.178)	
Epoch: [14][311/391]	LR: 0.01	Loss 1.5264 (1.5303)	Prec@1 42.969 (40.365)	
Epoch: [14][389/391]	LR: 0.01	Loss 1.4805 (1.5282)	Prec@1 40.625 (40.423)	
Total train loss: 1.5281

Train time: 20.122767210006714
 * Prec@1 90.350 Prec@5 99.430 Loss 0.3848
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 24.0265691280365

Epoch: [15][77/391]	LR: 0.01	Loss 1.5947 (1.5249)	Prec@1 37.500 (40.875)	
Epoch: [15][155/391]	LR: 0.01	Loss 1.4268 (1.5303)	Prec@1 45.312 (40.520)	
Epoch: [15][233/391]	LR: 0.01	Loss 1.5117 (1.5329)	Prec@1 42.188 (40.388)	
Epoch: [15][311/391]	LR: 0.01	Loss 1.5361 (1.5293)	Prec@1 37.500 (40.490)	
Epoch: [15][389/391]	LR: 0.01	Loss 1.6279 (1.5282)	Prec@1 38.281 (40.465)	
Total train loss: 1.5283

Train time: 19.733158349990845
 * Prec@1 90.360 Prec@5 99.450 Loss 0.4111
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 23.666133880615234

Epoch: [16][77/391]	LR: 0.01	Loss 1.6045 (1.5230)	Prec@1 39.844 (40.335)	
Epoch: [16][155/391]	LR: 0.01	Loss 1.4746 (1.5220)	Prec@1 44.531 (40.680)	
Epoch: [16][233/391]	LR: 0.01	Loss 1.5820 (1.5218)	Prec@1 37.500 (40.668)	
Epoch: [16][311/391]	LR: 0.01	Loss 1.4766 (1.5266)	Prec@1 46.094 (40.545)	
Epoch: [16][389/391]	LR: 0.01	Loss 1.4941 (1.5281)	Prec@1 40.625 (40.505)	
Total train loss: 1.5284

Train time: 19.612826824188232
 * Prec@1 90.280 Prec@5 99.420 Loss 0.3889
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 23.746338844299316

Epoch: [17][77/391]	LR: 0.01	Loss 1.4834 (1.5256)	Prec@1 40.625 (41.096)	
Epoch: [17][155/391]	LR: 0.01	Loss 1.5771 (1.5247)	Prec@1 38.281 (40.961)	
Epoch: [17][233/391]	LR: 0.01	Loss 1.5059 (1.5265)	Prec@1 41.406 (40.718)	
Epoch: [17][311/391]	LR: 0.01	Loss 1.4541 (1.5287)	Prec@1 46.094 (40.628)	
Epoch: [17][389/391]	LR: 0.01	Loss 1.7158 (1.5280)	Prec@1 32.031 (40.629)	
Total train loss: 1.5279

Train time: 20.125759601593018
 * Prec@1 90.320 Prec@5 99.510 Loss 0.3992
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 24.706262588500977

Epoch: [18][77/391]	LR: 0.01	Loss 1.5762 (1.5222)	Prec@1 36.719 (40.625)	
Epoch: [18][155/391]	LR: 0.01	Loss 1.6338 (1.5310)	Prec@1 38.281 (40.425)	
Epoch: [18][233/391]	LR: 0.01	Loss 1.7305 (1.5319)	Prec@1 32.031 (40.298)	
Epoch: [18][311/391]	LR: 0.01	Loss 1.5488 (1.5300)	Prec@1 42.969 (40.415)	
Epoch: [18][389/391]	LR: 0.01	Loss 1.6641 (1.5280)	Prec@1 34.375 (40.435)	
Total train loss: 1.5282

Train time: 19.195383548736572
 * Prec@1 90.060 Prec@5 99.570 Loss 0.4067
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 23.012681484222412

Epoch: [19][77/391]	LR: 0.01	Loss 1.4795 (1.5439)	Prec@1 42.188 (40.024)	
Epoch: [19][155/391]	LR: 0.01	Loss 1.5957 (1.5427)	Prec@1 35.938 (39.824)	
Epoch: [19][233/391]	LR: 0.01	Loss 1.4551 (1.5249)	Prec@1 42.969 (40.558)	
Epoch: [19][311/391]	LR: 0.01	Loss 1.4160 (1.5258)	Prec@1 43.750 (40.557)	
Epoch: [19][389/391]	LR: 0.01	Loss 1.5225 (1.5275)	Prec@1 43.750 (40.489)	
Total train loss: 1.5273

Train time: 18.47567892074585
 * Prec@1 90.240 Prec@5 99.420 Loss 0.4009
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 22.329277515411377

Epoch: [20][77/391]	LR: 0.001	Loss 1.5322 (1.5270)	Prec@1 44.531 (40.855)	
Epoch: [20][155/391]	LR: 0.001	Loss 1.6621 (1.5304)	Prec@1 33.594 (40.585)	
Epoch: [20][233/391]	LR: 0.001	Loss 1.6416 (1.5264)	Prec@1 37.500 (40.909)	
Epoch: [20][311/391]	LR: 0.001	Loss 1.5605 (1.5271)	Prec@1 35.938 (40.775)	
Epoch: [20][389/391]	LR: 0.001	Loss 1.6006 (1.5268)	Prec@1 36.719 (40.697)	
Total train loss: 1.5269

Train time: 18.823063611984253
 * Prec@1 90.240 Prec@5 99.500 Loss 0.4031
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 22.790834665298462

Epoch: [21][77/391]	LR: 0.001	Loss 1.4219 (1.5310)	Prec@1 44.531 (40.525)	
Epoch: [21][155/391]	LR: 0.001	Loss 1.4932 (1.5217)	Prec@1 40.625 (40.775)	
Epoch: [21][233/391]	LR: 0.001	Loss 1.4648 (1.5216)	Prec@1 40.625 (40.805)	
Epoch: [21][311/391]	LR: 0.001	Loss 1.5605 (1.5194)	Prec@1 36.719 (40.976)	
Epoch: [21][389/391]	LR: 0.001	Loss 1.4609 (1.5246)	Prec@1 46.094 (40.679)	
Total train loss: 1.5245

Train time: 17.97845196723938
 * Prec@1 90.470 Prec@5 99.450 Loss 0.3872
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 21.665070295333862

Epoch: [22][77/391]	LR: 0.001	Loss 1.5654 (1.5498)	Prec@1 39.844 (39.663)	
Epoch: [22][155/391]	LR: 0.001	Loss 1.7949 (1.5371)	Prec@1 35.156 (40.094)	
Epoch: [22][233/391]	LR: 0.001	Loss 1.5498 (1.5321)	Prec@1 40.625 (40.238)	
Epoch: [22][311/391]	LR: 0.001	Loss 1.5400 (1.5245)	Prec@1 38.281 (40.527)	
Epoch: [22][389/391]	LR: 0.001	Loss 1.4375 (1.5255)	Prec@1 46.875 (40.529)	
Total train loss: 1.5255

Train time: 18.82934546470642
 * Prec@1 90.350 Prec@5 99.520 Loss 0.3899
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 22.81011724472046

Epoch: [23][77/391]	LR: 0.001	Loss 1.6182 (1.5465)	Prec@1 38.281 (39.663)	
Epoch: [23][155/391]	LR: 0.001	Loss 1.5654 (1.5331)	Prec@1 35.938 (40.179)	
Epoch: [23][233/391]	LR: 0.001	Loss 1.5742 (1.5293)	Prec@1 42.188 (40.271)	
Epoch: [23][311/391]	LR: 0.001	Loss 1.2461 (1.5280)	Prec@1 53.125 (40.380)	
Epoch: [23][389/391]	LR: 0.001	Loss 1.5713 (1.5250)	Prec@1 36.719 (40.497)	
Total train loss: 1.5249

Train time: 13.89210319519043
 * Prec@1 90.320 Prec@5 99.500 Loss 0.3865
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 16.55198311805725

Epoch: [24][77/391]	LR: 0.001	Loss 1.5156 (1.4949)	Prec@1 39.844 (41.807)	
Epoch: [24][155/391]	LR: 0.001	Loss 1.5098 (1.5128)	Prec@1 41.406 (41.141)	
Epoch: [24][233/391]	LR: 0.001	Loss 1.5000 (1.5225)	Prec@1 40.625 (40.722)	
Epoch: [24][311/391]	LR: 0.001	Loss 1.2715 (1.5241)	Prec@1 50.000 (40.695)	
Epoch: [24][389/391]	LR: 0.001	Loss 1.4482 (1.5253)	Prec@1 45.312 (40.651)	
Total train loss: 1.5249

Train time: 17.634711503982544
 * Prec@1 90.430 Prec@5 99.450 Loss 0.3835
Best acc: 90.630
--------------------------------------------------------------------------------
Test time: 22.123358488082886


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 11
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.400 Prec@5 99.600 Loss 0.3262
Pre-trained Prec@1 with 11 layers frozen: 91.39999389648438 	 Loss: 0.326171875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.01	Loss 1.5264 (1.7189)	Prec@1 39.062 (36.038)	
Epoch: [0][155/391]	LR: 0.01	Loss 1.7002 (1.6573)	Prec@1 35.156 (37.159)	
Epoch: [0][233/391]	LR: 0.01	Loss 1.5732 (1.6391)	Prec@1 42.188 (37.480)	
Epoch: [0][311/391]	LR: 0.01	Loss 1.4570 (1.6248)	Prec@1 43.750 (37.768)	
Epoch: [0][389/391]	LR: 0.01	Loss 1.5205 (1.6128)	Prec@1 41.406 (38.045)	
Total train loss: 1.6130

Train time: 31.29992175102234
 * Prec@1 89.830 Prec@5 99.590 Loss 0.3577
Best acc: 89.830
--------------------------------------------------------------------------------
Test time: 36.517568588256836

Epoch: [1][77/391]	LR: 0.01	Loss 1.5342 (1.5540)	Prec@1 38.281 (39.343)	
Epoch: [1][155/391]	LR: 0.01	Loss 1.6357 (1.5523)	Prec@1 34.375 (39.513)	
Epoch: [1][233/391]	LR: 0.01	Loss 1.2090 (1.5540)	Prec@1 53.906 (39.590)	
Epoch: [1][311/391]	LR: 0.01	Loss 1.2959 (1.5510)	Prec@1 53.906 (39.668)	
Epoch: [1][389/391]	LR: 0.01	Loss 1.5068 (1.5525)	Prec@1 38.281 (39.595)	
Total train loss: 1.5524

Train time: 14.882227182388306
 * Prec@1 90.190 Prec@5 99.510 Loss 0.3577
Best acc: 90.190
--------------------------------------------------------------------------------
Test time: 20.682483673095703

Epoch: [2][77/391]	LR: 0.01	Loss 1.6934 (1.5399)	Prec@1 30.469 (39.884)	
Epoch: [2][155/391]	LR: 0.01	Loss 1.5469 (1.5377)	Prec@1 38.281 (40.365)	
Epoch: [2][233/391]	LR: 0.01	Loss 1.6035 (1.5410)	Prec@1 36.719 (40.294)	
Epoch: [2][311/391]	LR: 0.01	Loss 1.5244 (1.5411)	Prec@1 41.406 (40.247)	
Epoch: [2][389/391]	LR: 0.01	Loss 1.5098 (1.5433)	Prec@1 42.188 (40.168)	
Total train loss: 1.5432

Train time: 19.699453353881836
 * Prec@1 90.600 Prec@5 99.560 Loss 0.3562
Best acc: 90.600
--------------------------------------------------------------------------------
Test time: 23.628057956695557

Epoch: [3][77/391]	LR: 0.01	Loss 1.5244 (1.5380)	Prec@1 44.531 (40.385)	
Epoch: [3][155/391]	LR: 0.01	Loss 1.6172 (1.5386)	Prec@1 35.938 (40.294)	
Epoch: [3][233/391]	LR: 0.01	Loss 1.4873 (1.5378)	Prec@1 41.406 (40.398)	
Epoch: [3][311/391]	LR: 0.01	Loss 1.5449 (1.5394)	Prec@1 41.406 (40.335)	
Epoch: [3][389/391]	LR: 0.01	Loss 1.5303 (1.5390)	Prec@1 43.750 (40.361)	
Total train loss: 1.5392

Train time: 19.11785650253296
 * Prec@1 90.790 Prec@5 99.510 Loss 0.3577
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 23.28474521636963

Epoch: [4][77/391]	LR: 0.01	Loss 1.4932 (1.5489)	Prec@1 44.531 (39.643)	
Epoch: [4][155/391]	LR: 0.01	Loss 1.5732 (1.5436)	Prec@1 35.938 (39.869)	
Epoch: [4][233/391]	LR: 0.01	Loss 1.5127 (1.5359)	Prec@1 40.625 (40.184)	
Epoch: [4][311/391]	LR: 0.01	Loss 1.4561 (1.5356)	Prec@1 45.312 (40.252)	
Epoch: [4][389/391]	LR: 0.01	Loss 1.6562 (1.5365)	Prec@1 35.938 (40.210)	
Total train loss: 1.5369

Train time: 18.716132402420044
 * Prec@1 90.280 Prec@5 99.590 Loss 0.3743
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 22.57128930091858

Epoch: [5][77/391]	LR: 0.01	Loss 1.3984 (1.5421)	Prec@1 46.875 (40.024)	
Epoch: [5][155/391]	LR: 0.01	Loss 1.5176 (1.5370)	Prec@1 41.406 (40.239)	
Epoch: [5][233/391]	LR: 0.01	Loss 1.5332 (1.5330)	Prec@1 43.750 (40.455)	
Epoch: [5][311/391]	LR: 0.01	Loss 1.6699 (1.5345)	Prec@1 35.938 (40.475)	
Epoch: [5][389/391]	LR: 0.01	Loss 1.5625 (1.5347)	Prec@1 38.281 (40.387)	
Total train loss: 1.5348

Train time: 18.31325364112854
 * Prec@1 90.510 Prec@5 99.540 Loss 0.3667
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 21.878101348876953

Epoch: [6][77/391]	LR: 0.01	Loss 1.6025 (1.5240)	Prec@1 40.625 (40.645)	
Epoch: [6][155/391]	LR: 0.01	Loss 1.5537 (1.5310)	Prec@1 39.062 (40.565)	
Epoch: [6][233/391]	LR: 0.01	Loss 1.4971 (1.5350)	Prec@1 40.625 (40.368)	
Epoch: [6][311/391]	LR: 0.01	Loss 1.5938 (1.5345)	Prec@1 37.500 (40.472)	
Epoch: [6][389/391]	LR: 0.01	Loss 1.5322 (1.5335)	Prec@1 41.406 (40.471)	
Total train loss: 1.5335

Train time: 18.495633602142334
 * Prec@1 90.310 Prec@5 99.450 Loss 0.3623
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 22.332838535308838

Epoch: [7][77/391]	LR: 0.01	Loss 1.5693 (1.5443)	Prec@1 41.406 (39.694)	
Epoch: [7][155/391]	LR: 0.01	Loss 1.5088 (1.5415)	Prec@1 40.625 (39.849)	
Epoch: [7][233/391]	LR: 0.01	Loss 1.5381 (1.5388)	Prec@1 40.625 (39.967)	
Epoch: [7][311/391]	LR: 0.01	Loss 1.5918 (1.5358)	Prec@1 38.281 (40.187)	
Epoch: [7][389/391]	LR: 0.01	Loss 1.5205 (1.5312)	Prec@1 38.281 (40.379)	
Total train loss: 1.5310

Train time: 17.80072593688965
 * Prec@1 90.260 Prec@5 99.580 Loss 0.3809
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 21.443148374557495

Epoch: [8][77/391]	LR: 0.01	Loss 1.5049 (1.5316)	Prec@1 39.062 (40.575)	
Epoch: [8][155/391]	LR: 0.01	Loss 1.5723 (1.5312)	Prec@1 39.062 (40.515)	
Epoch: [8][233/391]	LR: 0.01	Loss 1.5889 (1.5371)	Prec@1 38.281 (40.318)	
Epoch: [8][311/391]	LR: 0.01	Loss 1.5186 (1.5303)	Prec@1 42.188 (40.570)	
Epoch: [8][389/391]	LR: 0.01	Loss 1.4707 (1.5315)	Prec@1 39.062 (40.591)	
Total train loss: 1.5316

Train time: 18.4961097240448
 * Prec@1 90.340 Prec@5 99.520 Loss 0.3638
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 22.513510704040527

Epoch: [9][77/391]	LR: 0.01	Loss 1.5537 (1.5500)	Prec@1 41.406 (39.593)	
Epoch: [9][155/391]	LR: 0.01	Loss 1.4268 (1.5441)	Prec@1 46.875 (39.979)	
Epoch: [9][233/391]	LR: 0.01	Loss 1.6680 (1.5363)	Prec@1 35.938 (40.204)	
Epoch: [9][311/391]	LR: 0.01	Loss 1.6230 (1.5325)	Prec@1 32.812 (40.332)	
Epoch: [9][389/391]	LR: 0.01	Loss 1.4268 (1.5315)	Prec@1 45.312 (40.351)	
Total train loss: 1.5314

Train time: 18.363129138946533
 * Prec@1 90.410 Prec@5 99.520 Loss 0.3757
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 22.63001036643982

Epoch: [10][77/391]	LR: 0.01	Loss 1.5928 (1.5492)	Prec@1 37.500 (39.764)	
Epoch: [10][155/391]	LR: 0.01	Loss 1.5195 (1.5366)	Prec@1 39.844 (40.350)	
Epoch: [10][233/391]	LR: 0.01	Loss 1.3740 (1.5365)	Prec@1 48.438 (40.361)	
Epoch: [10][311/391]	LR: 0.01	Loss 1.4131 (1.5362)	Prec@1 42.969 (40.340)	
Epoch: [10][389/391]	LR: 0.01	Loss 1.4238 (1.5293)	Prec@1 44.531 (40.649)	
Total train loss: 1.5292

Train time: 17.81267476081848
 * Prec@1 90.490 Prec@5 99.450 Loss 0.3792
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 22.054651260375977

Epoch: [11][77/391]	LR: 0.01	Loss 1.6885 (1.5311)	Prec@1 34.375 (40.875)	
Epoch: [11][155/391]	LR: 0.01	Loss 1.4395 (1.5266)	Prec@1 45.312 (40.840)	
Epoch: [11][233/391]	LR: 0.01	Loss 1.6738 (1.5310)	Prec@1 34.375 (40.548)	
Epoch: [11][311/391]	LR: 0.01	Loss 1.5186 (1.5284)	Prec@1 42.188 (40.628)	
Epoch: [11][389/391]	LR: 0.01	Loss 1.4766 (1.5285)	Prec@1 42.188 (40.597)	
Total train loss: 1.5288

Train time: 18.15635395050049
 * Prec@1 90.350 Prec@5 99.510 Loss 0.3938
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 22.057785511016846

Epoch: [12][77/391]	LR: 0.01	Loss 1.5352 (1.5241)	Prec@1 38.281 (40.695)	
Epoch: [12][155/391]	LR: 0.01	Loss 1.7510 (1.5192)	Prec@1 39.844 (41.016)	
Epoch: [12][233/391]	LR: 0.01	Loss 1.5762 (1.5219)	Prec@1 39.062 (40.889)	
Epoch: [12][311/391]	LR: 0.01	Loss 1.5654 (1.5273)	Prec@1 38.281 (40.545)	
Epoch: [12][389/391]	LR: 0.01	Loss 1.6299 (1.5291)	Prec@1 37.500 (40.545)	
Total train loss: 1.5287

Train time: 17.88618803024292
 * Prec@1 90.230 Prec@5 99.510 Loss 0.3931
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 21.826599836349487

Epoch: [13][77/391]	LR: 0.01	Loss 1.5977 (1.5199)	Prec@1 39.062 (40.665)	
Epoch: [13][155/391]	LR: 0.01	Loss 1.4951 (1.5204)	Prec@1 42.969 (40.755)	
Epoch: [13][233/391]	LR: 0.01	Loss 1.5508 (1.5296)	Prec@1 39.844 (40.418)	
Epoch: [13][311/391]	LR: 0.01	Loss 1.4717 (1.5300)	Prec@1 41.406 (40.382)	
Epoch: [13][389/391]	LR: 0.01	Loss 1.5137 (1.5282)	Prec@1 42.188 (40.507)	
Total train loss: 1.5284

Train time: 17.872212409973145
 * Prec@1 90.200 Prec@5 99.400 Loss 0.4067
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 21.699387073516846

Epoch: [14][77/391]	LR: 0.01	Loss 1.4961 (1.5265)	Prec@1 42.969 (40.795)	
Epoch: [14][155/391]	LR: 0.01	Loss 1.4590 (1.5290)	Prec@1 40.625 (40.405)	
Epoch: [14][233/391]	LR: 0.01	Loss 1.4609 (1.5285)	Prec@1 45.312 (40.418)	
Epoch: [14][311/391]	LR: 0.01	Loss 1.4756 (1.5296)	Prec@1 46.094 (40.492)	
Epoch: [14][389/391]	LR: 0.01	Loss 1.5664 (1.5276)	Prec@1 37.500 (40.515)	
Total train loss: 1.5281

Train time: 18.627737998962402
 * Prec@1 90.300 Prec@5 99.390 Loss 0.3914
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 22.55134630203247

Epoch: [15][77/391]	LR: 0.01	Loss 1.4609 (1.5272)	Prec@1 43.750 (40.375)	
Epoch: [15][155/391]	LR: 0.01	Loss 1.5088 (1.5184)	Prec@1 42.188 (40.710)	
Epoch: [15][233/391]	LR: 0.01	Loss 1.5039 (1.5209)	Prec@1 40.625 (40.501)	
Epoch: [15][311/391]	LR: 0.01	Loss 1.4922 (1.5239)	Prec@1 42.969 (40.480)	
Epoch: [15][389/391]	LR: 0.01	Loss 1.5322 (1.5276)	Prec@1 41.406 (40.240)	
Total train loss: 1.5276

Train time: 18.877840042114258
 * Prec@1 90.020 Prec@5 99.450 Loss 0.3948
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 22.779781818389893

Epoch: [16][77/391]	LR: 0.01	Loss 1.4404 (1.5218)	Prec@1 44.531 (40.485)	
Epoch: [16][155/391]	LR: 0.01	Loss 1.5928 (1.5229)	Prec@1 35.938 (40.510)	
Epoch: [16][233/391]	LR: 0.01	Loss 1.5869 (1.5244)	Prec@1 38.281 (40.405)	
Epoch: [16][311/391]	LR: 0.01	Loss 1.6895 (1.5303)	Prec@1 32.812 (40.182)	
Epoch: [16][389/391]	LR: 0.01	Loss 1.5078 (1.5280)	Prec@1 40.625 (40.341)	
Total train loss: 1.5281

Train time: 18.82236671447754
 * Prec@1 90.100 Prec@5 99.540 Loss 0.3865
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 22.789564609527588

Epoch: [17][77/391]	LR: 0.01	Loss 1.5811 (1.5324)	Prec@1 39.844 (40.405)	
Epoch: [17][155/391]	LR: 0.01	Loss 1.6729 (1.5285)	Prec@1 37.500 (40.600)	
Epoch: [17][233/391]	LR: 0.01	Loss 1.5557 (1.5351)	Prec@1 36.719 (40.231)	
Epoch: [17][311/391]	LR: 0.01	Loss 1.7627 (1.5319)	Prec@1 29.688 (40.390)	
Epoch: [17][389/391]	LR: 0.01	Loss 1.6162 (1.5273)	Prec@1 37.500 (40.573)	
Total train loss: 1.5275

Train time: 17.959686517715454
 * Prec@1 90.120 Prec@5 99.470 Loss 0.3909
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 21.934248685836792

Epoch: [18][77/391]	LR: 0.01	Loss 1.5439 (1.5393)	Prec@1 36.719 (40.204)	
Epoch: [18][155/391]	LR: 0.01	Loss 1.7490 (1.5407)	Prec@1 29.688 (40.044)	
Epoch: [18][233/391]	LR: 0.01	Loss 1.4160 (1.5354)	Prec@1 44.531 (40.144)	
Epoch: [18][311/391]	LR: 0.01	Loss 1.4531 (1.5306)	Prec@1 44.531 (40.435)	
Epoch: [18][389/391]	LR: 0.01	Loss 1.6475 (1.5267)	Prec@1 37.500 (40.681)	
Total train loss: 1.5269

Train time: 18.423229694366455
 * Prec@1 90.150 Prec@5 99.470 Loss 0.3867
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 22.348000288009644

Epoch: [19][77/391]	LR: 0.01	Loss 1.5615 (1.5192)	Prec@1 37.500 (40.655)	
Epoch: [19][155/391]	LR: 0.01	Loss 1.6289 (1.5284)	Prec@1 39.062 (40.415)	
Epoch: [19][233/391]	LR: 0.01	Loss 1.4258 (1.5227)	Prec@1 42.969 (40.648)	
Epoch: [19][311/391]	LR: 0.01	Loss 1.5928 (1.5240)	Prec@1 38.281 (40.678)	
Epoch: [19][389/391]	LR: 0.01	Loss 1.5664 (1.5269)	Prec@1 37.500 (40.495)	
Total train loss: 1.5271

Train time: 18.47359275817871
 * Prec@1 90.220 Prec@5 99.480 Loss 0.3884
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 22.56597352027893

Epoch: [20][77/391]	LR: 0.001	Loss 1.5674 (1.5283)	Prec@1 39.062 (40.795)	
Epoch: [20][155/391]	LR: 0.001	Loss 1.4902 (1.5196)	Prec@1 39.062 (40.900)	
Epoch: [20][233/391]	LR: 0.001	Loss 1.4883 (1.5224)	Prec@1 40.625 (40.779)	
Epoch: [20][311/391]	LR: 0.001	Loss 1.4834 (1.5236)	Prec@1 44.531 (40.718)	
Epoch: [20][389/391]	LR: 0.001	Loss 1.5830 (1.5250)	Prec@1 38.281 (40.691)	
Total train loss: 1.5255

Train time: 18.46104621887207
 * Prec@1 90.320 Prec@5 99.430 Loss 0.3899
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 22.260757207870483

Epoch: [21][77/391]	LR: 0.001	Loss 1.5635 (1.5244)	Prec@1 35.156 (40.395)	
Epoch: [21][155/391]	LR: 0.001	Loss 1.5146 (1.5201)	Prec@1 41.406 (40.570)	
Epoch: [21][233/391]	LR: 0.001	Loss 1.4414 (1.5228)	Prec@1 44.531 (40.421)	
Epoch: [21][311/391]	LR: 0.001	Loss 1.5059 (1.5231)	Prec@1 44.531 (40.633)	
Epoch: [21][389/391]	LR: 0.001	Loss 1.6064 (1.5245)	Prec@1 36.719 (40.595)	
Total train loss: 1.5246

Train time: 18.307637691497803
 * Prec@1 90.390 Prec@5 99.480 Loss 0.3853
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 22.048022270202637

Epoch: [22][77/391]	LR: 0.001	Loss 1.6221 (1.5326)	Prec@1 34.375 (40.595)	
Epoch: [22][155/391]	LR: 0.001	Loss 1.5664 (1.5226)	Prec@1 43.750 (40.981)	
Epoch: [22][233/391]	LR: 0.001	Loss 1.4971 (1.5201)	Prec@1 38.281 (41.032)	
Epoch: [22][311/391]	LR: 0.001	Loss 1.6250 (1.5247)	Prec@1 36.719 (40.835)	
Epoch: [22][389/391]	LR: 0.001	Loss 1.3691 (1.5248)	Prec@1 47.656 (40.787)	
Total train loss: 1.5248

Train time: 18.800172805786133
 * Prec@1 90.410 Prec@5 99.520 Loss 0.3821
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 22.97431468963623

Epoch: [23][77/391]	LR: 0.001	Loss 1.6074 (1.5197)	Prec@1 35.156 (40.665)	
Epoch: [23][155/391]	LR: 0.001	Loss 1.3760 (1.5245)	Prec@1 42.969 (40.465)	
Epoch: [23][233/391]	LR: 0.001	Loss 1.5439 (1.5192)	Prec@1 39.844 (40.705)	
Epoch: [23][311/391]	LR: 0.001	Loss 1.5527 (1.5230)	Prec@1 38.281 (40.630)	
Epoch: [23][389/391]	LR: 0.001	Loss 1.6221 (1.5253)	Prec@1 35.938 (40.543)	
Total train loss: 1.5250

Train time: 18.145233154296875
 * Prec@1 90.340 Prec@5 99.520 Loss 0.3767
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 21.876371383666992

Epoch: [24][77/391]	LR: 0.001	Loss 1.5156 (1.5121)	Prec@1 45.312 (41.256)	
Epoch: [24][155/391]	LR: 0.001	Loss 1.5352 (1.5143)	Prec@1 41.406 (40.915)	
Epoch: [24][233/391]	LR: 0.001	Loss 1.4619 (1.5214)	Prec@1 43.750 (40.652)	
Epoch: [24][311/391]	LR: 0.001	Loss 1.5312 (1.5221)	Prec@1 38.281 (40.525)	
Epoch: [24][389/391]	LR: 0.001	Loss 1.5449 (1.5255)	Prec@1 39.062 (40.393)	
Total train loss: 1.5253

Train time: 18.26962947845459
 * Prec@1 90.360 Prec@5 99.480 Loss 0.3816
Best acc: 90.790
--------------------------------------------------------------------------------
Test time: 21.94766068458557


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 13
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.350 Prec@5 99.630 Loss 0.3262
Pre-trained Prec@1 with 13 layers frozen: 91.3499984741211 	 Loss: 0.326171875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.01	Loss 1.6729 (1.7075)	Prec@1 35.156 (36.809)	
Epoch: [0][155/391]	LR: 0.01	Loss 1.5693 (1.6570)	Prec@1 35.938 (37.545)	
Epoch: [0][233/391]	LR: 0.01	Loss 1.5225 (1.6235)	Prec@1 42.188 (38.208)	
Epoch: [0][311/391]	LR: 0.01	Loss 1.4902 (1.6157)	Prec@1 39.062 (38.214)	
Epoch: [0][389/391]	LR: 0.01	Loss 1.6162 (1.6047)	Prec@1 38.281 (38.421)	
Total train loss: 1.6049

Train time: 28.642462968826294
 * Prec@1 90.040 Prec@5 99.560 Loss 0.3577
Best acc: 90.040
--------------------------------------------------------------------------------
Test time: 32.951215744018555

Epoch: [1][77/391]	LR: 0.01	Loss 1.7041 (1.5567)	Prec@1 34.375 (39.363)	
Epoch: [1][155/391]	LR: 0.01	Loss 1.4053 (1.5463)	Prec@1 46.094 (39.633)	
Epoch: [1][233/391]	LR: 0.01	Loss 1.5996 (1.5474)	Prec@1 36.719 (39.620)	
Epoch: [1][311/391]	LR: 0.01	Loss 1.7686 (1.5504)	Prec@1 36.719 (39.586)	
Epoch: [1][389/391]	LR: 0.01	Loss 1.5791 (1.5501)	Prec@1 36.719 (39.603)	
Total train loss: 1.5501

Train time: 19.416078805923462
 * Prec@1 90.320 Prec@5 99.640 Loss 0.3477
Best acc: 90.320
--------------------------------------------------------------------------------
Test time: 23.5012423992157

Epoch: [2][77/391]	LR: 0.01	Loss 1.5000 (1.5391)	Prec@1 42.969 (40.415)	
Epoch: [2][155/391]	LR: 0.01	Loss 1.5840 (1.5389)	Prec@1 35.938 (40.390)	
Epoch: [2][233/391]	LR: 0.01	Loss 1.6162 (1.5445)	Prec@1 38.281 (40.011)	
Epoch: [2][311/391]	LR: 0.01	Loss 1.5986 (1.5440)	Prec@1 39.844 (39.976)	
Epoch: [2][389/391]	LR: 0.01	Loss 1.4893 (1.5432)	Prec@1 42.188 (40.032)	
Total train loss: 1.5431

Train time: 17.669450998306274
 * Prec@1 90.170 Prec@5 99.520 Loss 0.3843
Best acc: 90.320
--------------------------------------------------------------------------------
Test time: 21.348817110061646

Epoch: [3][77/391]	LR: 0.01	Loss 1.5469 (1.5354)	Prec@1 39.062 (40.535)	
Epoch: [3][155/391]	LR: 0.01	Loss 1.4834 (1.5429)	Prec@1 42.188 (40.139)	
Epoch: [3][233/391]	LR: 0.01	Loss 1.5664 (1.5390)	Prec@1 39.062 (40.304)	
Epoch: [3][311/391]	LR: 0.01	Loss 1.5332 (1.5383)	Prec@1 39.062 (40.289)	
Epoch: [3][389/391]	LR: 0.01	Loss 1.6045 (1.5365)	Prec@1 39.844 (40.365)	
Total train loss: 1.5366

Train time: 17.041279315948486
 * Prec@1 90.500 Prec@5 99.600 Loss 0.3657
Best acc: 90.500
--------------------------------------------------------------------------------
Test time: 21.441569566726685

Epoch: [4][77/391]	LR: 0.01	Loss 1.5791 (1.5368)	Prec@1 39.062 (40.375)	
Epoch: [4][155/391]	LR: 0.01	Loss 1.4355 (1.5339)	Prec@1 41.406 (40.380)	
Epoch: [4][233/391]	LR: 0.01	Loss 1.5762 (1.5340)	Prec@1 37.500 (40.298)	
Epoch: [4][311/391]	LR: 0.01	Loss 1.4404 (1.5354)	Prec@1 45.312 (40.284)	
Epoch: [4][389/391]	LR: 0.01	Loss 1.4209 (1.5355)	Prec@1 46.875 (40.252)	
Total train loss: 1.5353

Train time: 17.158123254776
 * Prec@1 90.580 Prec@5 99.560 Loss 0.3682
Best acc: 90.580
--------------------------------------------------------------------------------
Test time: 20.75788903236389

Epoch: [5][77/391]	LR: 0.01	Loss 1.4756 (1.5352)	Prec@1 40.625 (40.435)	
Epoch: [5][155/391]	LR: 0.01	Loss 1.5576 (1.5378)	Prec@1 38.281 (40.199)	
Epoch: [5][233/391]	LR: 0.01	Loss 1.4854 (1.5360)	Prec@1 41.406 (40.345)	
Epoch: [5][311/391]	LR: 0.01	Loss 1.4619 (1.5356)	Prec@1 40.625 (40.332)	
Epoch: [5][389/391]	LR: 0.01	Loss 1.6211 (1.5335)	Prec@1 39.062 (40.393)	
Total train loss: 1.5336

Train time: 17.373719930648804
 * Prec@1 90.490 Prec@5 99.560 Loss 0.3735
Best acc: 90.580
--------------------------------------------------------------------------------
Test time: 20.84513783454895

Epoch: [6][77/391]	LR: 0.01	Loss 1.5508 (1.5189)	Prec@1 35.938 (40.705)	
Epoch: [6][155/391]	LR: 0.01	Loss 1.5039 (1.5200)	Prec@1 42.969 (40.650)	
Epoch: [6][233/391]	LR: 0.01	Loss 1.5449 (1.5213)	Prec@1 39.844 (40.658)	
Epoch: [6][311/391]	LR: 0.01	Loss 1.3232 (1.5271)	Prec@1 48.438 (40.385)	
Epoch: [6][389/391]	LR: 0.01	Loss 1.5352 (1.5319)	Prec@1 42.188 (40.200)	
Total train loss: 1.5319

Train time: 18.024916887283325
 * Prec@1 90.510 Prec@5 99.590 Loss 0.3811
Best acc: 90.580
--------------------------------------------------------------------------------
Test time: 21.712491273880005

Epoch: [7][77/391]	LR: 0.01	Loss 1.6836 (1.5430)	Prec@1 33.594 (40.024)	
Epoch: [7][155/391]	LR: 0.01	Loss 1.5635 (1.5304)	Prec@1 38.281 (40.450)	
Epoch: [7][233/391]	LR: 0.01	Loss 1.5684 (1.5321)	Prec@1 39.844 (40.525)	
Epoch: [7][311/391]	LR: 0.01	Loss 1.2998 (1.5322)	Prec@1 47.656 (40.517)	
Epoch: [7][389/391]	LR: 0.01	Loss 1.5869 (1.5314)	Prec@1 39.062 (40.515)	
Total train loss: 1.5317

Train time: 17.821739196777344
 * Prec@1 90.730 Prec@5 99.450 Loss 0.3794
Best acc: 90.730
--------------------------------------------------------------------------------
Test time: 21.619367122650146

Epoch: [8][77/391]	LR: 0.01	Loss 1.3447 (1.5374)	Prec@1 47.656 (40.385)	
Epoch: [8][155/391]	LR: 0.01	Loss 1.5195 (1.5326)	Prec@1 40.625 (40.585)	
Epoch: [8][233/391]	LR: 0.01	Loss 1.4111 (1.5338)	Prec@1 46.094 (40.395)	
Epoch: [8][311/391]	LR: 0.01	Loss 1.6367 (1.5334)	Prec@1 33.594 (40.380)	
Epoch: [8][389/391]	LR: 0.01	Loss 1.6123 (1.5307)	Prec@1 35.156 (40.515)	
Total train loss: 1.5308

Train time: 16.829598903656006
 * Prec@1 90.830 Prec@5 99.490 Loss 0.3728
Best acc: 90.830
--------------------------------------------------------------------------------
Test time: 20.437997341156006

Epoch: [9][77/391]	LR: 0.01	Loss 1.5713 (1.5219)	Prec@1 41.406 (40.595)	
Epoch: [9][155/391]	LR: 0.01	Loss 1.4590 (1.5273)	Prec@1 41.406 (40.274)	
Epoch: [9][233/391]	LR: 0.01	Loss 1.6377 (1.5239)	Prec@1 35.156 (40.508)	
Epoch: [9][311/391]	LR: 0.01	Loss 1.5840 (1.5260)	Prec@1 39.062 (40.447)	
Epoch: [9][389/391]	LR: 0.01	Loss 1.5840 (1.5305)	Prec@1 34.375 (40.337)	
Total train loss: 1.5305

Train time: 17.72440767288208
 * Prec@1 90.730 Prec@5 99.600 Loss 0.3743
Best acc: 90.830
--------------------------------------------------------------------------------
Test time: 21.637916088104248

Epoch: [10][77/391]	LR: 0.01	Loss 1.5967 (1.5363)	Prec@1 36.719 (40.304)	
Epoch: [10][155/391]	LR: 0.01	Loss 1.3896 (1.5270)	Prec@1 45.312 (40.605)	
Epoch: [10][233/391]	LR: 0.01	Loss 1.7158 (1.5263)	Prec@1 33.594 (40.642)	
Epoch: [10][311/391]	LR: 0.01	Loss 1.4785 (1.5274)	Prec@1 40.625 (40.557)	
Epoch: [10][389/391]	LR: 0.01	Loss 1.5801 (1.5294)	Prec@1 40.625 (40.447)	
Total train loss: 1.5298

Train time: 17.56933355331421
 * Prec@1 90.700 Prec@5 99.560 Loss 0.3882
Best acc: 90.830
--------------------------------------------------------------------------------
Test time: 21.573389768600464

Epoch: [11][77/391]	LR: 0.01	Loss 1.3652 (1.5280)	Prec@1 50.000 (40.565)	
Epoch: [11][155/391]	LR: 0.01	Loss 1.4980 (1.5264)	Prec@1 42.969 (40.760)	
Epoch: [11][233/391]	LR: 0.01	Loss 1.4209 (1.5290)	Prec@1 47.656 (40.635)	
Epoch: [11][311/391]	LR: 0.01	Loss 1.6465 (1.5285)	Prec@1 35.156 (40.678)	
Epoch: [11][389/391]	LR: 0.01	Loss 1.6445 (1.5286)	Prec@1 35.156 (40.653)	
Total train loss: 1.5286

Train time: 16.508021593093872
 * Prec@1 90.370 Prec@5 99.490 Loss 0.3953
Best acc: 90.830
--------------------------------------------------------------------------------
Test time: 20.506779193878174

Epoch: [12][77/391]	LR: 0.01	Loss 1.6748 (1.5264)	Prec@1 33.594 (40.655)	
Epoch: [12][155/391]	LR: 0.01	Loss 1.5283 (1.5251)	Prec@1 39.844 (40.760)	
Epoch: [12][233/391]	LR: 0.01	Loss 1.5117 (1.5310)	Prec@1 40.625 (40.458)	
Epoch: [12][311/391]	LR: 0.01	Loss 1.5459 (1.5272)	Prec@1 42.188 (40.482)	
Epoch: [12][389/391]	LR: 0.01	Loss 1.3965 (1.5290)	Prec@1 42.969 (40.511)	
Total train loss: 1.5290

Train time: 17.98908829689026
 * Prec@1 90.390 Prec@5 99.510 Loss 0.3838
Best acc: 90.830
--------------------------------------------------------------------------------
Test time: 21.79136371612549

Epoch: [13][77/391]	LR: 0.01	Loss 1.5469 (1.5168)	Prec@1 42.969 (41.136)	
Epoch: [13][155/391]	LR: 0.01	Loss 1.3320 (1.5182)	Prec@1 45.312 (41.051)	
Epoch: [13][233/391]	LR: 0.01	Loss 1.6904 (1.5215)	Prec@1 35.938 (40.785)	
Epoch: [13][311/391]	LR: 0.01	Loss 1.4609 (1.5264)	Prec@1 43.750 (40.605)	
Epoch: [13][389/391]	LR: 0.01	Loss 1.6543 (1.5283)	Prec@1 35.156 (40.569)	
Total train loss: 1.5283

Train time: 17.323712587356567
 * Prec@1 90.600 Prec@5 99.460 Loss 0.3950
Best acc: 90.830
--------------------------------------------------------------------------------
Test time: 21.324241876602173

Epoch: [14][77/391]	LR: 0.01	Loss 1.5166 (1.5373)	Prec@1 42.188 (40.355)	
Epoch: [14][155/391]	LR: 0.01	Loss 1.3936 (1.5285)	Prec@1 46.094 (40.585)	
Epoch: [14][233/391]	LR: 0.01	Loss 1.4062 (1.5335)	Prec@1 46.875 (40.325)	
Epoch: [14][311/391]	LR: 0.01	Loss 1.4482 (1.5303)	Prec@1 41.406 (40.470)	
Epoch: [14][389/391]	LR: 0.01	Loss 1.6123 (1.5289)	Prec@1 35.156 (40.507)	
Total train loss: 1.5291

Train time: 16.50386357307434
 * Prec@1 90.510 Prec@5 99.520 Loss 0.4045
Best acc: 90.830
--------------------------------------------------------------------------------
Test time: 20.128795385360718

Epoch: [15][77/391]	LR: 0.01	Loss 1.5039 (1.5280)	Prec@1 42.969 (40.535)	
Epoch: [15][155/391]	LR: 0.01	Loss 1.5479 (1.5310)	Prec@1 41.406 (40.450)	
Epoch: [15][233/391]	LR: 0.01	Loss 1.4648 (1.5259)	Prec@1 43.750 (40.658)	
Epoch: [15][311/391]	LR: 0.01	Loss 1.5303 (1.5241)	Prec@1 40.625 (40.698)	
Epoch: [15][389/391]	LR: 0.01	Loss 1.4551 (1.5281)	Prec@1 42.188 (40.509)	
Total train loss: 1.5281

Train time: 17.053728103637695
 * Prec@1 90.560 Prec@5 99.480 Loss 0.3889
Best acc: 90.830
--------------------------------------------------------------------------------
Test time: 20.92804479598999

Epoch: [16][77/391]	LR: 0.01	Loss 1.4648 (1.5246)	Prec@1 41.406 (40.495)	
Epoch: [16][155/391]	LR: 0.01	Loss 1.5225 (1.5305)	Prec@1 40.625 (40.154)	
Epoch: [16][233/391]	LR: 0.01	Loss 1.5938 (1.5260)	Prec@1 39.062 (40.525)	
Epoch: [16][311/391]	LR: 0.01	Loss 1.4570 (1.5268)	Prec@1 39.844 (40.552)	
Epoch: [16][389/391]	LR: 0.01	Loss 1.2988 (1.5277)	Prec@1 48.438 (40.587)	
Total train loss: 1.5277

Train time: 18.081470012664795
 * Prec@1 90.290 Prec@5 99.530 Loss 0.3965
Best acc: 90.830
--------------------------------------------------------------------------------
Test time: 22.072704792022705

Epoch: [17][77/391]	LR: 0.01	Loss 1.5723 (1.5289)	Prec@1 39.062 (40.214)	
Epoch: [17][155/391]	LR: 0.01	Loss 1.5459 (1.5266)	Prec@1 38.281 (40.540)	
Epoch: [17][233/391]	LR: 0.01	Loss 1.4609 (1.5277)	Prec@1 41.406 (40.488)	
Epoch: [17][311/391]	LR: 0.01	Loss 1.7246 (1.5291)	Prec@1 30.469 (40.510)	
Epoch: [17][389/391]	LR: 0.01	Loss 1.4932 (1.5270)	Prec@1 42.188 (40.641)	
Total train loss: 1.5271

Train time: 17.05182719230652
 * Prec@1 90.720 Prec@5 99.510 Loss 0.3779
Best acc: 90.830
--------------------------------------------------------------------------------
Test time: 20.73055648803711

Epoch: [18][77/391]	LR: 0.01	Loss 1.6445 (1.5196)	Prec@1 35.938 (40.565)	
Epoch: [18][155/391]	LR: 0.01	Loss 1.4893 (1.5214)	Prec@1 44.531 (40.565)	
Epoch: [18][233/391]	LR: 0.01	Loss 1.5664 (1.5257)	Prec@1 41.406 (40.575)	
Epoch: [18][311/391]	LR: 0.01	Loss 1.5869 (1.5272)	Prec@1 38.281 (40.552)	
Epoch: [18][389/391]	LR: 0.01	Loss 1.6162 (1.5262)	Prec@1 37.500 (40.565)	
Total train loss: 1.5260

Train time: 17.57293391227722
 * Prec@1 90.890 Prec@5 99.480 Loss 0.3745
Best acc: 90.890
--------------------------------------------------------------------------------
Test time: 21.51191759109497

Epoch: [19][77/391]	LR: 0.01	Loss 1.5459 (1.5319)	Prec@1 42.188 (39.934)	
Epoch: [19][155/391]	LR: 0.01	Loss 1.5273 (1.5341)	Prec@1 40.625 (40.204)	
Epoch: [19][233/391]	LR: 0.01	Loss 1.4570 (1.5307)	Prec@1 42.188 (40.331)	
Epoch: [19][311/391]	LR: 0.01	Loss 1.5557 (1.5271)	Prec@1 39.844 (40.517)	
Epoch: [19][389/391]	LR: 0.01	Loss 1.5557 (1.5277)	Prec@1 37.500 (40.485)	
Total train loss: 1.5275

Train time: 18.33431315422058
 * Prec@1 90.530 Prec@5 99.460 Loss 0.3921
Best acc: 90.890
--------------------------------------------------------------------------------
Test time: 21.963845252990723

Epoch: [20][77/391]	LR: 0.001	Loss 1.4531 (1.5184)	Prec@1 42.969 (40.835)	
Epoch: [20][155/391]	LR: 0.001	Loss 1.5713 (1.5263)	Prec@1 39.844 (40.570)	
Epoch: [20][233/391]	LR: 0.001	Loss 1.3701 (1.5298)	Prec@1 45.312 (40.315)	
Epoch: [20][311/391]	LR: 0.001	Loss 1.4072 (1.5275)	Prec@1 46.875 (40.447)	
Epoch: [20][389/391]	LR: 0.001	Loss 1.4834 (1.5259)	Prec@1 39.844 (40.497)	
Total train loss: 1.5259

Train time: 17.24684762954712
 * Prec@1 90.580 Prec@5 99.440 Loss 0.3901
Best acc: 90.890
--------------------------------------------------------------------------------
Test time: 21.110862255096436

Epoch: [21][77/391]	LR: 0.001	Loss 1.5020 (1.5263)	Prec@1 41.406 (40.555)	
Epoch: [21][155/391]	LR: 0.001	Loss 1.6055 (1.5369)	Prec@1 36.719 (40.159)	
Epoch: [21][233/391]	LR: 0.001	Loss 1.7129 (1.5249)	Prec@1 34.375 (40.598)	
Epoch: [21][311/391]	LR: 0.001	Loss 1.4990 (1.5199)	Prec@1 42.969 (40.755)	
Epoch: [21][389/391]	LR: 0.001	Loss 1.7158 (1.5249)	Prec@1 32.812 (40.511)	
Total train loss: 1.5252

Train time: 17.267456531524658
 * Prec@1 90.350 Prec@5 99.460 Loss 0.4031
Best acc: 90.890
--------------------------------------------------------------------------------
Test time: 20.334601163864136

Epoch: [22][77/391]	LR: 0.001	Loss 1.6094 (1.5286)	Prec@1 37.500 (40.234)	
Epoch: [22][155/391]	LR: 0.001	Loss 1.5156 (1.5262)	Prec@1 42.969 (40.340)	
Epoch: [22][233/391]	LR: 0.001	Loss 1.5898 (1.5268)	Prec@1 36.719 (40.288)	
Epoch: [22][311/391]	LR: 0.001	Loss 1.4014 (1.5285)	Prec@1 50.000 (40.217)	
Epoch: [22][389/391]	LR: 0.001	Loss 1.5000 (1.5255)	Prec@1 39.062 (40.473)	
Total train loss: 1.5254

Train time: 17.332302570343018
 * Prec@1 90.630 Prec@5 99.470 Loss 0.3870
Best acc: 90.890
--------------------------------------------------------------------------------
Test time: 21.212687730789185

Epoch: [23][77/391]	LR: 0.001	Loss 1.6016 (1.5395)	Prec@1 37.500 (40.114)	
Epoch: [23][155/391]	LR: 0.001	Loss 1.5215 (1.5279)	Prec@1 40.625 (40.400)	
Epoch: [23][233/391]	LR: 0.001	Loss 1.5205 (1.5315)	Prec@1 40.625 (40.291)	
Epoch: [23][311/391]	LR: 0.001	Loss 1.5830 (1.5261)	Prec@1 38.281 (40.530)	
Epoch: [23][389/391]	LR: 0.001	Loss 1.4434 (1.5247)	Prec@1 42.969 (40.679)	
Total train loss: 1.5247

Train time: 16.857449054718018
 * Prec@1 90.600 Prec@5 99.460 Loss 0.3931
Best acc: 90.890
--------------------------------------------------------------------------------
Test time: 20.6175217628479

Epoch: [24][77/391]	LR: 0.001	Loss 1.5645 (1.5012)	Prec@1 42.188 (41.376)	
Epoch: [24][155/391]	LR: 0.001	Loss 1.5176 (1.5155)	Prec@1 39.062 (40.865)	
Epoch: [24][233/391]	LR: 0.001	Loss 1.5801 (1.5198)	Prec@1 35.156 (40.638)	
Epoch: [24][311/391]	LR: 0.001	Loss 1.4658 (1.5246)	Prec@1 39.844 (40.420)	
Epoch: [24][389/391]	LR: 0.001	Loss 1.6201 (1.5252)	Prec@1 39.844 (40.529)	
Total train loss: 1.5252

Train time: 17.513134717941284
 * Prec@1 90.510 Prec@5 99.500 Loss 0.3857
Best acc: 90.890
--------------------------------------------------------------------------------
Test time: 21.31477379798889


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 15
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.350 Prec@5 99.640 Loss 0.3293
Pre-trained Prec@1 with 15 layers frozen: 91.3499984741211 	 Loss: 0.329345703125

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.01	Loss 1.6250 (1.6693)	Prec@1 36.719 (37.360)	
Epoch: [0][155/391]	LR: 0.01	Loss 1.5137 (1.6215)	Prec@1 42.188 (38.326)	
Epoch: [0][233/391]	LR: 0.01	Loss 1.8047 (1.6053)	Prec@1 30.469 (38.568)	
Epoch: [0][311/391]	LR: 0.01	Loss 1.6836 (1.5919)	Prec@1 38.281 (38.877)	
Epoch: [0][389/391]	LR: 0.01	Loss 1.6562 (1.5867)	Prec@1 39.062 (38.996)	
Total train loss: 1.5870

Train time: 22.7933931350708
 * Prec@1 90.430 Prec@5 99.640 Loss 0.3899
Best acc: 90.430
--------------------------------------------------------------------------------
Test time: 27.04172158241272

Epoch: [1][77/391]	LR: 0.01	Loss 1.5654 (1.5535)	Prec@1 39.844 (39.263)	
Epoch: [1][155/391]	LR: 0.01	Loss 1.5078 (1.5487)	Prec@1 41.406 (39.348)	
Epoch: [1][233/391]	LR: 0.01	Loss 1.5723 (1.5424)	Prec@1 38.281 (39.747)	
Epoch: [1][311/391]	LR: 0.01	Loss 1.5615 (1.5433)	Prec@1 35.156 (39.784)	
Epoch: [1][389/391]	LR: 0.01	Loss 1.6582 (1.5450)	Prec@1 34.375 (39.677)	
Total train loss: 1.5452

Train time: 17.48267364501953
 * Prec@1 90.680 Prec@5 99.580 Loss 0.3750
Best acc: 90.680
--------------------------------------------------------------------------------
Test time: 21.292590141296387

Epoch: [2][77/391]	LR: 0.01	Loss 1.5068 (1.5283)	Prec@1 41.406 (40.986)	
Epoch: [2][155/391]	LR: 0.01	Loss 1.5146 (1.5348)	Prec@1 39.062 (40.565)	
Epoch: [2][233/391]	LR: 0.01	Loss 1.4443 (1.5387)	Prec@1 44.531 (40.311)	
Epoch: [2][311/391]	LR: 0.01	Loss 1.3799 (1.5410)	Prec@1 48.438 (40.194)	
Epoch: [2][389/391]	LR: 0.01	Loss 1.8223 (1.5399)	Prec@1 30.469 (40.146)	
Total train loss: 1.5400

Train time: 17.23592209815979
 * Prec@1 91.060 Prec@5 99.590 Loss 0.3669
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 20.664302587509155

Epoch: [3][77/391]	LR: 0.01	Loss 1.5068 (1.5212)	Prec@1 39.844 (40.996)	
Epoch: [3][155/391]	LR: 0.01	Loss 1.3174 (1.5367)	Prec@1 48.438 (40.380)	
Epoch: [3][233/391]	LR: 0.01	Loss 1.7451 (1.5358)	Prec@1 31.250 (40.415)	
Epoch: [3][311/391]	LR: 0.01	Loss 1.6953 (1.5388)	Prec@1 35.938 (40.337)	
Epoch: [3][389/391]	LR: 0.01	Loss 1.6016 (1.5369)	Prec@1 38.281 (40.371)	
Total train loss: 1.5369

Train time: 16.354074716567993
 * Prec@1 90.960 Prec@5 99.580 Loss 0.3694
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 20.079008102416992

Epoch: [4][77/391]	LR: 0.01	Loss 1.6045 (1.5292)	Prec@1 36.719 (40.094)	
Epoch: [4][155/391]	LR: 0.01	Loss 1.5137 (1.5341)	Prec@1 42.969 (40.315)	
Epoch: [4][233/391]	LR: 0.01	Loss 1.3955 (1.5336)	Prec@1 45.312 (40.495)	
Epoch: [4][311/391]	LR: 0.01	Loss 1.5449 (1.5344)	Prec@1 41.406 (40.455)	
Epoch: [4][389/391]	LR: 0.01	Loss 1.5967 (1.5348)	Prec@1 38.281 (40.413)	
Total train loss: 1.5349

Train time: 16.952191591262817
 * Prec@1 90.660 Prec@5 99.620 Loss 0.3892
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 20.374208450317383

Epoch: [5][77/391]	LR: 0.01	Loss 1.5107 (1.5262)	Prec@1 41.406 (41.086)	
Epoch: [5][155/391]	LR: 0.01	Loss 1.6357 (1.5318)	Prec@1 39.062 (40.540)	
Epoch: [5][233/391]	LR: 0.01	Loss 1.4590 (1.5304)	Prec@1 41.406 (40.555)	
Epoch: [5][311/391]	LR: 0.01	Loss 1.5986 (1.5336)	Prec@1 35.156 (40.445)	
Epoch: [5][389/391]	LR: 0.01	Loss 1.6182 (1.5336)	Prec@1 35.938 (40.447)	
Total train loss: 1.5334

Train time: 16.217444896697998
 * Prec@1 90.740 Prec@5 99.590 Loss 0.3755
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 19.609405755996704

Epoch: [6][77/391]	LR: 0.01	Loss 1.5156 (1.5400)	Prec@1 40.625 (40.054)	
Epoch: [6][155/391]	LR: 0.01	Loss 1.3662 (1.5339)	Prec@1 50.000 (40.244)	
Epoch: [6][233/391]	LR: 0.01	Loss 1.5234 (1.5298)	Prec@1 41.406 (40.535)	
Epoch: [6][311/391]	LR: 0.01	Loss 1.5391 (1.5332)	Prec@1 41.406 (40.437)	
Epoch: [6][389/391]	LR: 0.01	Loss 1.5410 (1.5312)	Prec@1 44.531 (40.497)	
Total train loss: 1.5311

Train time: 15.343299865722656
 * Prec@1 90.700 Prec@5 99.520 Loss 0.3789
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 18.84315776824951

Epoch: [7][77/391]	LR: 0.01	Loss 1.3984 (1.5289)	Prec@1 47.656 (40.785)	
Epoch: [7][155/391]	LR: 0.01	Loss 1.5791 (1.5295)	Prec@1 38.281 (40.700)	
Epoch: [7][233/391]	LR: 0.01	Loss 1.5156 (1.5287)	Prec@1 42.188 (40.655)	
Epoch: [7][311/391]	LR: 0.01	Loss 1.5947 (1.5287)	Prec@1 38.281 (40.587)	
Epoch: [7][389/391]	LR: 0.01	Loss 1.6855 (1.5308)	Prec@1 30.469 (40.491)	
Total train loss: 1.5310

Train time: 16.009466648101807
 * Prec@1 90.650 Prec@5 99.530 Loss 0.3984
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 19.839736461639404

Epoch: [8][77/391]	LR: 0.01	Loss 1.6748 (1.5414)	Prec@1 32.812 (39.954)	
Epoch: [8][155/391]	LR: 0.01	Loss 1.6094 (1.5420)	Prec@1 39.844 (39.939)	
Epoch: [8][233/391]	LR: 0.01	Loss 1.4219 (1.5361)	Prec@1 47.656 (40.294)	
Epoch: [8][311/391]	LR: 0.01	Loss 1.5205 (1.5325)	Prec@1 39.062 (40.415)	
Epoch: [8][389/391]	LR: 0.01	Loss 1.4375 (1.5306)	Prec@1 42.188 (40.457)	
Total train loss: 1.5306

Train time: 16.295266151428223
 * Prec@1 90.760 Prec@5 99.480 Loss 0.3784
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 19.756750106811523

Epoch: [9][77/391]	LR: 0.01	Loss 1.3906 (1.5169)	Prec@1 43.750 (40.755)	
Epoch: [9][155/391]	LR: 0.01	Loss 1.4941 (1.5165)	Prec@1 42.188 (40.770)	
Epoch: [9][233/391]	LR: 0.01	Loss 1.5205 (1.5207)	Prec@1 42.969 (40.528)	
Epoch: [9][311/391]	LR: 0.01	Loss 1.5742 (1.5230)	Prec@1 33.594 (40.487)	
Epoch: [9][389/391]	LR: 0.01	Loss 1.5459 (1.5306)	Prec@1 42.188 (40.248)	
Total train loss: 1.5302

Train time: 15.513342380523682
 * Prec@1 90.530 Prec@5 99.550 Loss 0.3877
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 18.926380157470703

Epoch: [10][77/391]	LR: 0.01	Loss 1.3418 (1.5133)	Prec@1 47.656 (41.146)	
Epoch: [10][155/391]	LR: 0.01	Loss 1.4531 (1.5200)	Prec@1 42.188 (40.765)	
Epoch: [10][233/391]	LR: 0.01	Loss 1.5791 (1.5295)	Prec@1 36.719 (40.405)	
Epoch: [10][311/391]	LR: 0.01	Loss 1.5137 (1.5297)	Prec@1 41.406 (40.405)	
Epoch: [10][389/391]	LR: 0.01	Loss 1.4561 (1.5300)	Prec@1 39.062 (40.292)	
Total train loss: 1.5298

Train time: 16.09231948852539
 * Prec@1 90.480 Prec@5 99.510 Loss 0.3914
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 19.292030096054077

Epoch: [11][77/391]	LR: 0.01	Loss 1.5049 (1.5402)	Prec@1 43.750 (40.264)	
Epoch: [11][155/391]	LR: 0.01	Loss 1.4648 (1.5298)	Prec@1 42.969 (40.570)	
Epoch: [11][233/391]	LR: 0.01	Loss 1.7412 (1.5298)	Prec@1 31.250 (40.522)	
Epoch: [11][311/391]	LR: 0.01	Loss 1.4336 (1.5295)	Prec@1 43.750 (40.540)	
Epoch: [11][389/391]	LR: 0.01	Loss 1.6406 (1.5298)	Prec@1 33.594 (40.449)	
Total train loss: 1.5299

Train time: 16.236923694610596
 * Prec@1 90.710 Prec@5 99.530 Loss 0.3845
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 20.07987666130066

Epoch: [12][77/391]	LR: 0.01	Loss 1.5693 (1.5270)	Prec@1 39.844 (40.585)	
Epoch: [12][155/391]	LR: 0.01	Loss 1.3760 (1.5362)	Prec@1 43.750 (40.294)	
Epoch: [12][233/391]	LR: 0.01	Loss 1.6387 (1.5353)	Prec@1 39.844 (40.294)	
Epoch: [12][311/391]	LR: 0.01	Loss 1.3799 (1.5298)	Prec@1 44.531 (40.525)	
Epoch: [12][389/391]	LR: 0.01	Loss 1.5830 (1.5292)	Prec@1 39.062 (40.549)	
Total train loss: 1.5289

Train time: 15.865219593048096
 * Prec@1 90.660 Prec@5 99.480 Loss 0.3928
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 19.469324827194214

Epoch: [13][77/391]	LR: 0.01	Loss 1.5381 (1.5193)	Prec@1 41.406 (40.855)	
Epoch: [13][155/391]	LR: 0.01	Loss 1.6406 (1.5261)	Prec@1 33.594 (40.450)	
Epoch: [13][233/391]	LR: 0.01	Loss 1.5107 (1.5269)	Prec@1 42.188 (40.441)	
Epoch: [13][311/391]	LR: 0.01	Loss 1.6182 (1.5279)	Prec@1 36.719 (40.485)	
Epoch: [13][389/391]	LR: 0.01	Loss 1.6309 (1.5285)	Prec@1 37.500 (40.411)	
Total train loss: 1.5285

Train time: 16.315192699432373
 * Prec@1 90.720 Prec@5 99.540 Loss 0.3757
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 19.886439323425293

Epoch: [14][77/391]	LR: 0.01	Loss 1.4951 (1.5487)	Prec@1 41.406 (39.784)	
Epoch: [14][155/391]	LR: 0.01	Loss 1.4854 (1.5365)	Prec@1 40.625 (40.154)	
Epoch: [14][233/391]	LR: 0.01	Loss 1.5264 (1.5312)	Prec@1 37.500 (40.398)	
Epoch: [14][311/391]	LR: 0.01	Loss 1.4492 (1.5301)	Prec@1 42.969 (40.492)	
Epoch: [14][389/391]	LR: 0.01	Loss 1.4814 (1.5285)	Prec@1 42.188 (40.543)	
Total train loss: 1.5284

Train time: 15.605279922485352
 * Prec@1 90.730 Prec@5 99.500 Loss 0.3760
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 19.461421728134155

Epoch: [15][77/391]	LR: 0.01	Loss 1.5234 (1.5409)	Prec@1 39.844 (39.623)	
Epoch: [15][155/391]	LR: 0.01	Loss 1.4756 (1.5260)	Prec@1 44.531 (40.274)	
Epoch: [15][233/391]	LR: 0.01	Loss 1.5938 (1.5240)	Prec@1 36.719 (40.311)	
Epoch: [15][311/391]	LR: 0.01	Loss 1.4561 (1.5272)	Prec@1 44.531 (40.269)	
Epoch: [15][389/391]	LR: 0.01	Loss 1.5215 (1.5284)	Prec@1 37.500 (40.282)	
Total train loss: 1.5288

Train time: 15.966442346572876
 * Prec@1 90.460 Prec@5 99.540 Loss 0.3955
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 19.71688675880432

Epoch: [16][77/391]	LR: 0.01	Loss 1.6777 (1.5119)	Prec@1 32.812 (41.356)	
Epoch: [16][155/391]	LR: 0.01	Loss 1.5254 (1.5251)	Prec@1 39.062 (40.525)	
Epoch: [16][233/391]	LR: 0.01	Loss 1.6074 (1.5228)	Prec@1 38.281 (40.672)	
Epoch: [16][311/391]	LR: 0.01	Loss 1.6230 (1.5250)	Prec@1 38.281 (40.567)	
Epoch: [16][389/391]	LR: 0.01	Loss 1.5400 (1.5281)	Prec@1 41.406 (40.451)	
Total train loss: 1.5280

Train time: 16.660266399383545
 * Prec@1 90.450 Prec@5 99.480 Loss 0.4060
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 20.221418857574463

Epoch: [17][77/391]	LR: 0.01	Loss 1.5254 (1.5407)	Prec@1 37.500 (39.964)	
Epoch: [17][155/391]	LR: 0.01	Loss 1.5137 (1.5307)	Prec@1 39.844 (40.259)	
Epoch: [17][233/391]	LR: 0.01	Loss 1.5889 (1.5293)	Prec@1 37.500 (40.238)	
Epoch: [17][311/391]	LR: 0.01	Loss 1.3760 (1.5279)	Prec@1 45.312 (40.357)	
Epoch: [17][389/391]	LR: 0.01	Loss 1.7188 (1.5272)	Prec@1 31.250 (40.335)	
Total train loss: 1.5270

Train time: 16.52937889099121
 * Prec@1 90.710 Prec@5 99.520 Loss 0.3875
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 19.925999402999878

Epoch: [18][77/391]	LR: 0.01	Loss 1.3926 (1.5277)	Prec@1 45.312 (40.124)	
Epoch: [18][155/391]	LR: 0.01	Loss 1.4590 (1.5213)	Prec@1 46.875 (40.640)	
Epoch: [18][233/391]	LR: 0.01	Loss 1.3711 (1.5245)	Prec@1 46.875 (40.615)	
Epoch: [18][311/391]	LR: 0.01	Loss 1.6455 (1.5264)	Prec@1 32.031 (40.387)	
Epoch: [18][389/391]	LR: 0.01	Loss 1.4883 (1.5275)	Prec@1 42.969 (40.411)	
Total train loss: 1.5271

Train time: 15.994492292404175
 * Prec@1 90.660 Prec@5 99.440 Loss 0.3877
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 19.904330492019653

Epoch: [19][77/391]	LR: 0.01	Loss 1.5264 (1.5228)	Prec@1 42.969 (40.545)	
Epoch: [19][155/391]	LR: 0.01	Loss 1.5723 (1.5267)	Prec@1 42.969 (40.345)	
Epoch: [19][233/391]	LR: 0.01	Loss 1.6240 (1.5328)	Prec@1 39.844 (40.238)	
Epoch: [19][311/391]	LR: 0.01	Loss 1.5166 (1.5281)	Prec@1 39.062 (40.330)	
Epoch: [19][389/391]	LR: 0.01	Loss 1.4561 (1.5274)	Prec@1 43.750 (40.505)	
Total train loss: 1.5275

Train time: 16.59372305870056
 * Prec@1 90.310 Prec@5 99.390 Loss 0.4028
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 20.211097478866577

Epoch: [20][77/391]	LR: 0.001	Loss 1.5928 (1.5297)	Prec@1 39.062 (40.395)	
Epoch: [20][155/391]	LR: 0.001	Loss 1.5391 (1.5313)	Prec@1 37.500 (40.385)	
Epoch: [20][233/391]	LR: 0.001	Loss 1.5371 (1.5304)	Prec@1 36.719 (40.411)	
Epoch: [20][311/391]	LR: 0.001	Loss 1.4512 (1.5285)	Prec@1 40.625 (40.465)	
Epoch: [20][389/391]	LR: 0.001	Loss 1.5117 (1.5257)	Prec@1 41.406 (40.559)	
Total train loss: 1.5258

Train time: 16.247867345809937
 * Prec@1 90.290 Prec@5 99.400 Loss 0.4043
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 19.78191113471985

Epoch: [21][77/391]	LR: 0.001	Loss 1.6377 (1.5210)	Prec@1 36.719 (40.665)	
Epoch: [21][155/391]	LR: 0.001	Loss 1.3516 (1.5178)	Prec@1 44.531 (40.825)	
Epoch: [21][233/391]	LR: 0.001	Loss 1.4941 (1.5194)	Prec@1 41.406 (40.775)	
Epoch: [21][311/391]	LR: 0.001	Loss 1.5840 (1.5239)	Prec@1 39.062 (40.743)	
Epoch: [21][389/391]	LR: 0.001	Loss 1.6426 (1.5256)	Prec@1 34.375 (40.663)	
Total train loss: 1.5256

Train time: 16.44072937965393
 * Prec@1 90.380 Prec@5 99.410 Loss 0.4131
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 20.224842309951782

Epoch: [22][77/391]	LR: 0.001	Loss 1.3828 (1.5172)	Prec@1 44.531 (40.635)	
Epoch: [22][155/391]	LR: 0.001	Loss 1.3525 (1.5264)	Prec@1 47.656 (40.325)	
Epoch: [22][233/391]	LR: 0.001	Loss 1.5723 (1.5245)	Prec@1 36.719 (40.471)	
Epoch: [22][311/391]	LR: 0.001	Loss 1.4766 (1.5221)	Prec@1 42.188 (40.590)	
Epoch: [22][389/391]	LR: 0.001	Loss 1.4199 (1.5251)	Prec@1 46.094 (40.395)	
Total train loss: 1.5252

Train time: 15.589558601379395
 * Prec@1 90.400 Prec@5 99.410 Loss 0.3994
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 19.304153442382812

Epoch: [23][77/391]	LR: 0.001	Loss 1.5361 (1.5377)	Prec@1 39.844 (40.184)	
Epoch: [23][155/391]	LR: 0.001	Loss 1.6738 (1.5385)	Prec@1 33.594 (40.214)	
Epoch: [23][233/391]	LR: 0.001	Loss 1.5303 (1.5269)	Prec@1 45.312 (40.585)	
Epoch: [23][311/391]	LR: 0.001	Loss 1.3701 (1.5197)	Prec@1 46.875 (40.835)	
Epoch: [23][389/391]	LR: 0.001	Loss 1.4775 (1.5244)	Prec@1 45.312 (40.651)	
Total train loss: 1.5247

Train time: 16.351649284362793
 * Prec@1 90.350 Prec@5 99.410 Loss 0.4033
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 20.190830945968628

Epoch: [24][77/391]	LR: 0.001	Loss 1.5488 (1.5401)	Prec@1 38.281 (40.014)	
Epoch: [24][155/391]	LR: 0.001	Loss 1.5801 (1.5264)	Prec@1 37.500 (40.750)	
Epoch: [24][233/391]	LR: 0.001	Loss 1.4912 (1.5233)	Prec@1 43.750 (40.825)	
Epoch: [24][311/391]	LR: 0.001	Loss 1.4834 (1.5225)	Prec@1 40.625 (40.638)	
Epoch: [24][389/391]	LR: 0.001	Loss 1.5742 (1.5251)	Prec@1 44.531 (40.617)	
Total train loss: 1.5253

Train time: 16.236868858337402
 * Prec@1 90.600 Prec@5 99.440 Loss 0.3894
Best acc: 91.060
--------------------------------------------------------------------------------
Test time: 20.03571844100952


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 17
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.330 Prec@5 99.620 Loss 0.3279
Pre-trained Prec@1 with 17 layers frozen: 91.32999420166016 	 Loss: 0.327880859375

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.01	Loss 1.6807 (1.5938)	Prec@1 40.625 (39.583)	
Epoch: [0][155/391]	LR: 0.01	Loss 1.6338 (1.5789)	Prec@1 32.031 (39.408)	
Epoch: [0][233/391]	LR: 0.01	Loss 1.5703 (1.5709)	Prec@1 37.500 (39.553)	
Epoch: [0][311/391]	LR: 0.01	Loss 1.5918 (1.5712)	Prec@1 39.844 (39.421)	
Epoch: [0][389/391]	LR: 0.01	Loss 1.5039 (1.5666)	Prec@1 42.969 (39.533)	
Total train loss: 1.5665

Train time: 23.022950172424316
 * Prec@1 90.940 Prec@5 99.500 Loss 0.3984
Best acc: 90.940
--------------------------------------------------------------------------------
Test time: 27.024816751480103

Epoch: [1][77/391]	LR: 0.01	Loss 1.6289 (1.5589)	Prec@1 39.062 (39.934)	
Epoch: [1][155/391]	LR: 0.01	Loss 1.6143 (1.5503)	Prec@1 36.719 (39.944)	
Epoch: [1][233/391]	LR: 0.01	Loss 1.5684 (1.5492)	Prec@1 36.719 (39.901)	
Epoch: [1][311/391]	LR: 0.01	Loss 1.5039 (1.5466)	Prec@1 39.844 (39.934)	
Epoch: [1][389/391]	LR: 0.01	Loss 1.4316 (1.5454)	Prec@1 46.875 (39.904)	
Total train loss: 1.5455

Train time: 17.01531434059143
 * Prec@1 90.970 Prec@5 99.590 Loss 0.3689
Best acc: 90.970
--------------------------------------------------------------------------------
Test time: 20.574878454208374

Epoch: [2][77/391]	LR: 0.01	Loss 1.7012 (1.5433)	Prec@1 34.375 (40.054)	
Epoch: [2][155/391]	LR: 0.01	Loss 1.5127 (1.5472)	Prec@1 42.969 (39.854)	
Epoch: [2][233/391]	LR: 0.01	Loss 1.6758 (1.5426)	Prec@1 34.375 (40.097)	
Epoch: [2][311/391]	LR: 0.01	Loss 1.5410 (1.5472)	Prec@1 41.406 (39.876)	
Epoch: [2][389/391]	LR: 0.01	Loss 1.5889 (1.5419)	Prec@1 40.625 (39.956)	
Total train loss: 1.5415

Train time: 16.41503143310547
 * Prec@1 91.210 Prec@5 99.520 Loss 0.3569
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.863729238510132

Epoch: [3][77/391]	LR: 0.01	Loss 1.4883 (1.5280)	Prec@1 39.844 (40.385)	
Epoch: [3][155/391]	LR: 0.01	Loss 1.6035 (1.5271)	Prec@1 37.500 (40.460)	
Epoch: [3][233/391]	LR: 0.01	Loss 1.5381 (1.5281)	Prec@1 38.281 (40.575)	
Epoch: [3][311/391]	LR: 0.01	Loss 1.3545 (1.5311)	Prec@1 50.000 (40.507)	
Epoch: [3][389/391]	LR: 0.01	Loss 1.6426 (1.5382)	Prec@1 39.844 (40.180)	
Total train loss: 1.5384

Train time: 15.000873804092407
 * Prec@1 91.080 Prec@5 99.600 Loss 0.3740
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 18.55671215057373

Epoch: [4][77/391]	LR: 0.01	Loss 1.3730 (1.5263)	Prec@1 45.312 (40.745)	
Epoch: [4][155/391]	LR: 0.01	Loss 1.5352 (1.5355)	Prec@1 39.844 (40.500)	
Epoch: [4][233/391]	LR: 0.01	Loss 1.4795 (1.5336)	Prec@1 41.406 (40.385)	
Epoch: [4][311/391]	LR: 0.01	Loss 1.4990 (1.5367)	Prec@1 44.531 (40.407)	
Epoch: [4][389/391]	LR: 0.01	Loss 1.5439 (1.5361)	Prec@1 39.844 (40.339)	
Total train loss: 1.5359

Train time: 15.991495847702026
 * Prec@1 91.060 Prec@5 99.610 Loss 0.3599
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.474522352218628

Epoch: [5][77/391]	LR: 0.01	Loss 1.5518 (1.5354)	Prec@1 39.844 (40.545)	
Epoch: [5][155/391]	LR: 0.01	Loss 1.3926 (1.5400)	Prec@1 43.750 (40.239)	
Epoch: [5][233/391]	LR: 0.01	Loss 1.7275 (1.5427)	Prec@1 32.031 (40.198)	
Epoch: [5][311/391]	LR: 0.01	Loss 1.5713 (1.5362)	Prec@1 38.281 (40.435)	
Epoch: [5][389/391]	LR: 0.01	Loss 1.3164 (1.5358)	Prec@1 50.000 (40.363)	
Total train loss: 1.5360

Train time: 15.2060546875
 * Prec@1 91.140 Prec@5 99.550 Loss 0.3635
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 18.719813346862793

Epoch: [6][77/391]	LR: 0.01	Loss 1.5908 (1.5218)	Prec@1 38.281 (41.176)	
Epoch: [6][155/391]	LR: 0.01	Loss 1.4980 (1.5261)	Prec@1 39.062 (40.941)	
Epoch: [6][233/391]	LR: 0.01	Loss 1.6797 (1.5317)	Prec@1 35.938 (40.688)	
Epoch: [6][311/391]	LR: 0.01	Loss 1.5791 (1.5357)	Prec@1 40.625 (40.497)	
Epoch: [6][389/391]	LR: 0.01	Loss 1.5879 (1.5346)	Prec@1 38.281 (40.473)	
Total train loss: 1.5345

Train time: 15.453326225280762
 * Prec@1 90.980 Prec@5 99.550 Loss 0.3748
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.105703115463257

Epoch: [7][77/391]	LR: 0.01	Loss 1.5566 (1.5320)	Prec@1 42.188 (40.495)	
Epoch: [7][155/391]	LR: 0.01	Loss 1.2705 (1.5354)	Prec@1 51.562 (40.299)	
Epoch: [7][233/391]	LR: 0.01	Loss 1.5215 (1.5336)	Prec@1 41.406 (40.421)	
Epoch: [7][311/391]	LR: 0.01	Loss 1.5068 (1.5338)	Prec@1 39.844 (40.405)	
Epoch: [7][389/391]	LR: 0.01	Loss 1.4678 (1.5346)	Prec@1 43.750 (40.367)	
Total train loss: 1.5348

Train time: 15.88675832748413
 * Prec@1 90.960 Prec@5 99.510 Loss 0.3782
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.395861625671387

Epoch: [8][77/391]	LR: 0.01	Loss 1.5898 (1.5364)	Prec@1 35.938 (40.445)	
Epoch: [8][155/391]	LR: 0.01	Loss 1.4570 (1.5336)	Prec@1 44.531 (40.395)	
Epoch: [8][233/391]	LR: 0.01	Loss 1.3330 (1.5298)	Prec@1 47.656 (40.485)	
Epoch: [8][311/391]	LR: 0.01	Loss 1.4590 (1.5305)	Prec@1 42.188 (40.575)	
Epoch: [8][389/391]	LR: 0.01	Loss 1.6660 (1.5331)	Prec@1 37.500 (40.537)	
Total train loss: 1.5333

Train time: 15.126569747924805
 * Prec@1 91.000 Prec@5 99.530 Loss 0.3796
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 18.81835627555847

Epoch: [9][77/391]	LR: 0.01	Loss 1.4590 (1.5359)	Prec@1 43.750 (40.274)	
Epoch: [9][155/391]	LR: 0.01	Loss 1.4678 (1.5352)	Prec@1 45.312 (40.294)	
Epoch: [9][233/391]	LR: 0.01	Loss 1.5049 (1.5357)	Prec@1 41.406 (40.281)	
Epoch: [9][311/391]	LR: 0.01	Loss 1.4424 (1.5345)	Prec@1 46.094 (40.274)	
Epoch: [9][389/391]	LR: 0.01	Loss 1.4365 (1.5312)	Prec@1 46.875 (40.353)	
Total train loss: 1.5312

Train time: 15.477054119110107
 * Prec@1 90.800 Prec@5 99.470 Loss 0.3789
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.18281388282776

Epoch: [10][77/391]	LR: 0.01	Loss 1.3701 (1.5258)	Prec@1 42.188 (40.755)	
Epoch: [10][155/391]	LR: 0.01	Loss 1.5049 (1.5338)	Prec@1 40.625 (40.380)	
Epoch: [10][233/391]	LR: 0.01	Loss 1.3906 (1.5353)	Prec@1 47.656 (40.408)	
Epoch: [10][311/391]	LR: 0.01	Loss 1.6094 (1.5336)	Prec@1 39.844 (40.415)	
Epoch: [10][389/391]	LR: 0.01	Loss 1.6572 (1.5328)	Prec@1 32.812 (40.461)	
Total train loss: 1.5328

Train time: 15.082435131072998
 * Prec@1 90.850 Prec@5 99.530 Loss 0.3826
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 18.27499771118164

Epoch: [11][77/391]	LR: 0.01	Loss 1.3057 (1.5424)	Prec@1 47.656 (39.683)	
Epoch: [11][155/391]	LR: 0.01	Loss 1.7422 (1.5365)	Prec@1 32.812 (39.939)	
Epoch: [11][233/391]	LR: 0.01	Loss 1.5684 (1.5347)	Prec@1 38.281 (40.161)	
Epoch: [11][311/391]	LR: 0.01	Loss 1.5488 (1.5367)	Prec@1 39.844 (40.217)	
Epoch: [11][389/391]	LR: 0.01	Loss 1.5010 (1.5309)	Prec@1 41.406 (40.501)	
Total train loss: 1.5310

Train time: 15.475212335586548
 * Prec@1 90.980 Prec@5 99.510 Loss 0.3789
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.11993145942688

Epoch: [12][77/391]	LR: 0.01	Loss 1.5215 (1.5326)	Prec@1 39.062 (40.575)	
Epoch: [12][155/391]	LR: 0.01	Loss 1.7275 (1.5333)	Prec@1 33.594 (40.400)	
Epoch: [12][233/391]	LR: 0.01	Loss 1.4131 (1.5352)	Prec@1 46.094 (40.308)	
Epoch: [12][311/391]	LR: 0.01	Loss 1.4707 (1.5332)	Prec@1 44.531 (40.320)	
Epoch: [12][389/391]	LR: 0.01	Loss 1.5518 (1.5310)	Prec@1 39.844 (40.433)	
Total train loss: 1.5309

Train time: 15.230696678161621
 * Prec@1 90.790 Prec@5 99.480 Loss 0.3938
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.099596977233887

Epoch: [13][77/391]	LR: 0.01	Loss 1.4473 (1.5348)	Prec@1 43.750 (40.274)	
Epoch: [13][155/391]	LR: 0.01	Loss 1.4961 (1.5304)	Prec@1 41.406 (40.430)	
Epoch: [13][233/391]	LR: 0.01	Loss 1.5654 (1.5262)	Prec@1 40.625 (40.712)	
Epoch: [13][311/391]	LR: 0.01	Loss 1.5137 (1.5282)	Prec@1 41.406 (40.600)	
Epoch: [13][389/391]	LR: 0.01	Loss 1.5732 (1.5301)	Prec@1 39.062 (40.517)	
Total train loss: 1.5303

Train time: 15.190745115280151
 * Prec@1 90.750 Prec@5 99.510 Loss 0.3953
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.199465036392212

Epoch: [14][77/391]	LR: 0.01	Loss 1.4102 (1.5330)	Prec@1 45.312 (40.605)	
Epoch: [14][155/391]	LR: 0.01	Loss 1.6064 (1.5368)	Prec@1 38.281 (40.385)	
Epoch: [14][233/391]	LR: 0.01	Loss 1.3975 (1.5322)	Prec@1 45.312 (40.458)	
Epoch: [14][311/391]	LR: 0.01	Loss 1.5020 (1.5327)	Prec@1 42.969 (40.412)	
Epoch: [14][389/391]	LR: 0.01	Loss 1.6230 (1.5311)	Prec@1 34.375 (40.497)	
Total train loss: 1.5310

Train time: 15.570958614349365
 * Prec@1 91.080 Prec@5 99.490 Loss 0.3723
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 18.97091507911682

Epoch: [15][77/391]	LR: 0.01	Loss 1.5791 (1.5253)	Prec@1 37.500 (40.144)	
Epoch: [15][155/391]	LR: 0.01	Loss 1.3945 (1.5305)	Prec@1 46.875 (40.294)	
Epoch: [15][233/391]	LR: 0.01	Loss 1.3574 (1.5320)	Prec@1 46.094 (40.274)	
Epoch: [15][311/391]	LR: 0.01	Loss 1.5674 (1.5300)	Prec@1 38.281 (40.362)	
Epoch: [15][389/391]	LR: 0.01	Loss 1.4580 (1.5299)	Prec@1 42.969 (40.405)	
Total train loss: 1.5298

Train time: 15.967555522918701
 * Prec@1 90.980 Prec@5 99.470 Loss 0.3896
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.70960235595703

Epoch: [16][77/391]	LR: 0.01	Loss 1.3789 (1.5368)	Prec@1 47.656 (40.184)	
Epoch: [16][155/391]	LR: 0.01	Loss 1.4170 (1.5310)	Prec@1 43.750 (40.355)	
Epoch: [16][233/391]	LR: 0.01	Loss 1.5342 (1.5295)	Prec@1 40.625 (40.401)	
Epoch: [16][311/391]	LR: 0.01	Loss 1.6123 (1.5306)	Prec@1 41.406 (40.357)	
Epoch: [16][389/391]	LR: 0.01	Loss 1.5781 (1.5301)	Prec@1 35.938 (40.401)	
Total train loss: 1.5299

Train time: 15.11955189704895
 * Prec@1 90.970 Prec@5 99.440 Loss 0.3977
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 18.84826946258545

Epoch: [17][77/391]	LR: 0.01	Loss 1.5449 (1.5384)	Prec@1 40.625 (40.194)	
Epoch: [17][155/391]	LR: 0.01	Loss 1.5508 (1.5313)	Prec@1 39.844 (40.445)	
Epoch: [17][233/391]	LR: 0.01	Loss 1.6533 (1.5327)	Prec@1 39.062 (40.485)	
Epoch: [17][311/391]	LR: 0.01	Loss 1.4590 (1.5304)	Prec@1 44.531 (40.487)	
Epoch: [17][389/391]	LR: 0.01	Loss 1.5215 (1.5295)	Prec@1 37.500 (40.569)	
Total train loss: 1.5293

Train time: 16.269697427749634
 * Prec@1 90.650 Prec@5 99.480 Loss 0.3882
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.97260308265686

Epoch: [18][77/391]	LR: 0.01	Loss 1.6074 (1.5261)	Prec@1 36.719 (40.695)	
Epoch: [18][155/391]	LR: 0.01	Loss 1.5566 (1.5178)	Prec@1 39.062 (41.051)	
Epoch: [18][233/391]	LR: 0.01	Loss 1.6006 (1.5224)	Prec@1 35.156 (40.869)	
Epoch: [18][311/391]	LR: 0.01	Loss 1.5605 (1.5285)	Prec@1 37.500 (40.740)	
Epoch: [18][389/391]	LR: 0.01	Loss 1.4414 (1.5291)	Prec@1 44.531 (40.635)	
Total train loss: 1.5291

Train time: 15.886022329330444
 * Prec@1 90.720 Prec@5 99.470 Loss 0.3899
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.398374557495117

Epoch: [19][77/391]	LR: 0.01	Loss 1.3662 (1.5336)	Prec@1 49.219 (40.375)	
Epoch: [19][155/391]	LR: 0.01	Loss 1.4844 (1.5262)	Prec@1 43.750 (40.745)	
Epoch: [19][233/391]	LR: 0.01	Loss 1.5586 (1.5298)	Prec@1 38.281 (40.441)	
Epoch: [19][311/391]	LR: 0.01	Loss 1.5459 (1.5300)	Prec@1 39.062 (40.567)	
Epoch: [19][389/391]	LR: 0.01	Loss 1.4414 (1.5291)	Prec@1 46.875 (40.567)	
Total train loss: 1.5291

Train time: 15.725956439971924
 * Prec@1 90.860 Prec@5 99.410 Loss 0.3899
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.00537133216858

Epoch: [20][77/391]	LR: 0.001	Loss 1.6514 (1.5297)	Prec@1 37.500 (40.665)	
Epoch: [20][155/391]	LR: 0.001	Loss 1.4873 (1.5245)	Prec@1 42.188 (40.575)	
Epoch: [20][233/391]	LR: 0.001	Loss 1.5674 (1.5281)	Prec@1 37.500 (40.608)	
Epoch: [20][311/391]	LR: 0.001	Loss 1.6348 (1.5283)	Prec@1 35.156 (40.663)	
Epoch: [20][389/391]	LR: 0.001	Loss 1.4551 (1.5277)	Prec@1 42.188 (40.627)	
Total train loss: 1.5277

Train time: 16.22763729095459
 * Prec@1 90.850 Prec@5 99.480 Loss 0.3840
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.84157681465149

Epoch: [21][77/391]	LR: 0.001	Loss 1.6436 (1.5159)	Prec@1 34.375 (41.326)	
Epoch: [21][155/391]	LR: 0.001	Loss 1.2588 (1.5161)	Prec@1 50.781 (41.251)	
Epoch: [21][233/391]	LR: 0.001	Loss 1.5518 (1.5182)	Prec@1 39.062 (41.069)	
Epoch: [21][311/391]	LR: 0.001	Loss 1.6191 (1.5246)	Prec@1 35.938 (40.760)	
Epoch: [21][389/391]	LR: 0.001	Loss 1.5869 (1.5271)	Prec@1 37.500 (40.637)	
Total train loss: 1.5270

Train time: 16.519757986068726
 * Prec@1 90.960 Prec@5 99.470 Loss 0.3870
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 20.221988201141357

Epoch: [22][77/391]	LR: 0.001	Loss 1.5391 (1.5407)	Prec@1 39.062 (39.954)	
Epoch: [22][155/391]	LR: 0.001	Loss 1.4619 (1.5276)	Prec@1 41.406 (40.485)	
Epoch: [22][233/391]	LR: 0.001	Loss 1.5039 (1.5233)	Prec@1 44.531 (40.665)	
Epoch: [22][311/391]	LR: 0.001	Loss 1.5098 (1.5264)	Prec@1 41.406 (40.525)	
Epoch: [22][389/391]	LR: 0.001	Loss 1.3760 (1.5268)	Prec@1 47.656 (40.507)	
Total train loss: 1.5266

Train time: 15.442190408706665
 * Prec@1 90.990 Prec@5 99.510 Loss 0.3862
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.04985499382019

Epoch: [23][77/391]	LR: 0.001	Loss 1.5615 (1.5150)	Prec@1 39.844 (40.805)	
Epoch: [23][155/391]	LR: 0.001	Loss 1.6035 (1.5172)	Prec@1 38.281 (40.815)	
Epoch: [23][233/391]	LR: 0.001	Loss 1.4883 (1.5190)	Prec@1 41.406 (40.705)	
Epoch: [23][311/391]	LR: 0.001	Loss 1.5889 (1.5231)	Prec@1 39.844 (40.597)	
Epoch: [23][389/391]	LR: 0.001	Loss 1.5469 (1.5268)	Prec@1 39.062 (40.461)	
Total train loss: 1.5268

Train time: 15.54902195930481
 * Prec@1 90.870 Prec@5 99.460 Loss 0.3953
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.244215488433838

Epoch: [24][77/391]	LR: 0.001	Loss 1.4951 (1.5223)	Prec@1 42.188 (40.635)	
Epoch: [24][155/391]	LR: 0.001	Loss 1.7998 (1.5314)	Prec@1 28.906 (40.244)	
Epoch: [24][233/391]	LR: 0.001	Loss 1.4502 (1.5312)	Prec@1 42.188 (40.304)	
Epoch: [24][311/391]	LR: 0.001	Loss 1.5986 (1.5286)	Prec@1 40.625 (40.412)	
Epoch: [24][389/391]	LR: 0.001	Loss 1.3604 (1.5261)	Prec@1 46.875 (40.519)	
Total train loss: 1.5261

Train time: 16.34794306755066
 * Prec@1 90.750 Prec@5 99.460 Loss 0.3850
Best acc: 91.210
--------------------------------------------------------------------------------
Test time: 19.656715631484985


      ==> Arguments:
          dataset: cifar10
          model: resnet20
          load_dir: /home/nano01/a/esoufler/activations/x64-8b/
          savedir: ../pretrained_models/frozen/x64-8b/
          pretrained: ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar
          mode: rram
          workers: 8
          epochs: 25
          start_epoch: 0
          batch_size: 128
          lr: 0.01
          momentum: 0.9
          weight_decay: 0.0001
          gamma: 0.1
          a_bit: 8
          af_bit: 4
          w_bit: 8
          wf_bit: 6
          milestones: [20, 30, 40, 50]
          loss: crossentropy
          optim: sgd
          print_freq: 5
          resume: 
          evaluate: False
          half: True
          save_every: 10
          gpus: 1
          frozen_layers: 19
DEVICE: cuda
GPU Id(s) being used: 1
==> Building model for resnet20 ...
==> Initializing model with pre-trained parameters ...
==> Load pretrained model form ../pretrained_models/ideal/resnet20qfp_cifar10_i8b4f_w8b6f.pth.tar ...
Original model accuracy: 91.64999389648438
 * Prec@1 91.370 Prec@5 99.620 Loss 0.3276
Pre-trained Prec@1 with 19 layers frozen: 91.3699951171875 	 Loss: 0.32763671875

Starting training on SRAM layers...
Epoch: [0][77/391]	LR: 0.01	Loss 1.4287 (1.5735)	Prec@1 40.625 (39.493)	
Epoch: [0][155/391]	LR: 0.01	Loss 1.6387 (1.5801)	Prec@1 39.062 (39.258)	
Epoch: [0][233/391]	LR: 0.01	Loss 1.6113 (1.5646)	Prec@1 35.938 (39.663)	
Epoch: [0][311/391]	LR: 0.01	Loss 1.4951 (1.5630)	Prec@1 46.094 (39.726)	
Epoch: [0][389/391]	LR: 0.01	Loss 1.5449 (1.5617)	Prec@1 40.625 (39.702)	
Total train loss: 1.5619

Train time: 23.46487021446228
 * Prec@1 91.140 Prec@5 99.670 Loss 0.4265
Best acc: 91.140
--------------------------------------------------------------------------------
Test time: 26.892157793045044

Epoch: [1][77/391]	LR: 0.01	Loss 1.6191 (1.5418)	Prec@1 40.625 (40.224)	
Epoch: [1][155/391]	LR: 0.01	Loss 1.6543 (1.5527)	Prec@1 36.719 (39.879)	
Epoch: [1][233/391]	LR: 0.01	Loss 1.6738 (1.5502)	Prec@1 34.375 (39.931)	
Epoch: [1][311/391]	LR: 0.01	Loss 1.4736 (1.5561)	Prec@1 40.625 (39.739)	
Epoch: [1][389/391]	LR: 0.01	Loss 1.5225 (1.5529)	Prec@1 45.312 (39.842)	
Total train loss: 1.5529

Train time: 17.37948226928711
 * Prec@1 91.340 Prec@5 99.670 Loss 0.3804
Best acc: 91.340
--------------------------------------------------------------------------------
Test time: 21.089274406433105

Epoch: [2][77/391]	LR: 0.01	Loss 1.5771 (1.5526)	Prec@1 35.938 (39.543)	
Epoch: [2][155/391]	LR: 0.01	Loss 1.5195 (1.5496)	Prec@1 39.844 (39.694)	
Epoch: [2][233/391]	LR: 0.01	Loss 1.6416 (1.5456)	Prec@1 35.156 (39.987)	
Epoch: [2][311/391]	LR: 0.01	Loss 1.5488 (1.5483)	Prec@1 42.188 (39.806)	
Epoch: [2][389/391]	LR: 0.01	Loss 1.5576 (1.5488)	Prec@1 41.406 (39.760)	
Total train loss: 1.5486

Train time: 15.40744924545288
 * Prec@1 91.350 Prec@5 99.640 Loss 0.3535
Best acc: 91.350
--------------------------------------------------------------------------------
Test time: 18.845892906188965

Epoch: [3][77/391]	LR: 0.01	Loss 1.4131 (1.5586)	Prec@1 45.312 (39.293)	
Epoch: [3][155/391]	LR: 0.01	Loss 1.5781 (1.5542)	Prec@1 41.406 (39.668)	
Epoch: [3][233/391]	LR: 0.01	Loss 1.4883 (1.5511)	Prec@1 42.969 (39.790)	
Epoch: [3][311/391]	LR: 0.01	Loss 1.5049 (1.5506)	Prec@1 42.188 (39.806)	
Epoch: [3][389/391]	LR: 0.01	Loss 1.6885 (1.5468)	Prec@1 39.062 (39.944)	
Total train loss: 1.5469

Train time: 14.907484292984009
 * Prec@1 91.080 Prec@5 99.620 Loss 0.3557
Best acc: 91.350
--------------------------------------------------------------------------------
Test time: 18.389729976654053

Epoch: [4][77/391]	LR: 0.01	Loss 1.5244 (1.5491)	Prec@1 40.625 (39.503)	
Epoch: [4][155/391]	LR: 0.01	Loss 1.5215 (1.5494)	Prec@1 39.062 (39.673)	
Epoch: [4][233/391]	LR: 0.01	Loss 1.6123 (1.5526)	Prec@1 36.719 (39.603)	
Epoch: [4][311/391]	LR: 0.01	Loss 1.6318 (1.5496)	Prec@1 40.625 (39.774)	
Epoch: [4][389/391]	LR: 0.01	Loss 1.5850 (1.5462)	Prec@1 36.719 (39.932)	
Total train loss: 1.5458

Train time: 15.87880563735962
 * Prec@1 91.290 Prec@5 99.620 Loss 0.3350
Best acc: 91.350
--------------------------------------------------------------------------------
Test time: 19.165260076522827

Epoch: [5][77/391]	LR: 0.01	Loss 1.4355 (1.5693)	Prec@1 41.406 (38.732)	
Epoch: [5][155/391]	LR: 0.01	Loss 1.3848 (1.5473)	Prec@1 46.875 (39.824)	
Epoch: [5][233/391]	LR: 0.01	Loss 1.6562 (1.5424)	Prec@1 39.062 (40.124)	
Epoch: [5][311/391]	LR: 0.01	Loss 1.5205 (1.5446)	Prec@1 39.062 (40.052)	
Epoch: [5][389/391]	LR: 0.01	Loss 1.6299 (1.5441)	Prec@1 32.812 (40.006)	
Total train loss: 1.5442

Train time: 15.655100584030151
 * Prec@1 91.260 Prec@5 99.650 Loss 0.3416
Best acc: 91.350
--------------------------------------------------------------------------------
Test time: 19.18161392211914

Epoch: [6][77/391]	LR: 0.01	Loss 1.6016 (1.5459)	Prec@1 35.938 (39.734)	
Epoch: [6][155/391]	LR: 0.01	Loss 1.4229 (1.5510)	Prec@1 45.312 (39.553)	
Epoch: [6][233/391]	LR: 0.01	Loss 1.6641 (1.5508)	Prec@1 32.812 (39.607)	
Epoch: [6][311/391]	LR: 0.01	Loss 1.6143 (1.5454)	Prec@1 36.719 (39.796)	
Epoch: [6][389/391]	LR: 0.01	Loss 1.5264 (1.5444)	Prec@1 40.625 (39.820)	
Total train loss: 1.5445

Train time: 16.148618459701538
 * Prec@1 91.370 Prec@5 99.620 Loss 0.3291
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 19.481844425201416

Epoch: [7][77/391]	LR: 0.01	Loss 1.3730 (1.5504)	Prec@1 48.438 (40.054)	
Epoch: [7][155/391]	LR: 0.01	Loss 1.6523 (1.5456)	Prec@1 32.812 (39.994)	
Epoch: [7][233/391]	LR: 0.01	Loss 1.4639 (1.5454)	Prec@1 44.531 (39.830)	
Epoch: [7][311/391]	LR: 0.01	Loss 1.5801 (1.5458)	Prec@1 35.156 (39.871)	
Epoch: [7][389/391]	LR: 0.01	Loss 1.4961 (1.5436)	Prec@1 42.188 (40.006)	
Total train loss: 1.5437

Train time: 15.62664246559143
 * Prec@1 91.340 Prec@5 99.610 Loss 0.3311
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 19.537333011627197

Epoch: [8][77/391]	LR: 0.01	Loss 1.5762 (1.5336)	Prec@1 37.500 (40.264)	
Epoch: [8][155/391]	LR: 0.01	Loss 1.6455 (1.5399)	Prec@1 34.375 (39.864)	
Epoch: [8][233/391]	LR: 0.01	Loss 1.4531 (1.5433)	Prec@1 44.531 (39.837)	
Epoch: [8][311/391]	LR: 0.01	Loss 1.7129 (1.5453)	Prec@1 32.031 (39.876)	
Epoch: [8][389/391]	LR: 0.01	Loss 1.6064 (1.5442)	Prec@1 40.625 (39.914)	
Total train loss: 1.5440

Train time: 15.272185802459717
 * Prec@1 91.100 Prec@5 99.600 Loss 0.3438
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 18.92950129508972

Epoch: [9][77/391]	LR: 0.01	Loss 1.5527 (1.5499)	Prec@1 36.719 (39.814)	
Epoch: [9][155/391]	LR: 0.01	Loss 1.5664 (1.5434)	Prec@1 35.156 (39.934)	
Epoch: [9][233/391]	LR: 0.01	Loss 1.3633 (1.5472)	Prec@1 44.531 (39.717)	
Epoch: [9][311/391]	LR: 0.01	Loss 1.4023 (1.5435)	Prec@1 46.094 (39.731)	
Epoch: [9][389/391]	LR: 0.01	Loss 1.5547 (1.5437)	Prec@1 40.625 (39.842)	
Total train loss: 1.5438

Train time: 15.303438663482666
 * Prec@1 91.330 Prec@5 99.630 Loss 0.3298
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 19.017486333847046

Epoch: [10][77/391]	LR: 0.01	Loss 1.6680 (1.5164)	Prec@1 32.031 (40.976)	
Epoch: [10][155/391]	LR: 0.01	Loss 1.4043 (1.5312)	Prec@1 43.750 (40.495)	
Epoch: [10][233/391]	LR: 0.01	Loss 1.6680 (1.5394)	Prec@1 35.938 (40.158)	
Epoch: [10][311/391]	LR: 0.01	Loss 1.6328 (1.5427)	Prec@1 38.281 (40.149)	
Epoch: [10][389/391]	LR: 0.01	Loss 1.4277 (1.5431)	Prec@1 45.312 (40.120)	
Total train loss: 1.5430

Train time: 15.791067361831665
 * Prec@1 91.150 Prec@5 99.620 Loss 0.3308
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 19.197691679000854

Epoch: [11][77/391]	LR: 0.01	Loss 1.5635 (1.5447)	Prec@1 38.281 (40.104)	
Epoch: [11][155/391]	LR: 0.01	Loss 1.5967 (1.5402)	Prec@1 35.938 (40.224)	
Epoch: [11][233/391]	LR: 0.01	Loss 1.6016 (1.5502)	Prec@1 37.500 (39.780)	
Epoch: [11][311/391]	LR: 0.01	Loss 1.6221 (1.5453)	Prec@1 39.844 (40.052)	
Epoch: [11][389/391]	LR: 0.01	Loss 1.5820 (1.5432)	Prec@1 35.938 (40.202)	
Total train loss: 1.5434

Train time: 15.530019044876099
 * Prec@1 91.130 Prec@5 99.580 Loss 0.3372
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 19.361496925354004

Epoch: [12][77/391]	LR: 0.01	Loss 1.6113 (1.5274)	Prec@1 37.500 (40.735)	
Epoch: [12][155/391]	LR: 0.01	Loss 1.4912 (1.5271)	Prec@1 42.969 (40.455)	
Epoch: [12][233/391]	LR: 0.01	Loss 1.5029 (1.5391)	Prec@1 46.094 (40.034)	
Epoch: [12][311/391]	LR: 0.01	Loss 1.7812 (1.5456)	Prec@1 29.688 (39.786)	
Epoch: [12][389/391]	LR: 0.01	Loss 1.6396 (1.5431)	Prec@1 39.062 (39.948)	
Total train loss: 1.5429

Train time: 15.602043867111206
 * Prec@1 91.210 Prec@5 99.660 Loss 0.3362
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 18.87340521812439

Epoch: [13][77/391]	LR: 0.01	Loss 1.5713 (1.5369)	Prec@1 37.500 (40.445)	
Epoch: [13][155/391]	LR: 0.01	Loss 1.4199 (1.5481)	Prec@1 46.094 (39.854)	
Epoch: [13][233/391]	LR: 0.01	Loss 1.6699 (1.5463)	Prec@1 35.938 (39.877)	
Epoch: [13][311/391]	LR: 0.01	Loss 1.4346 (1.5430)	Prec@1 41.406 (39.999)	
Epoch: [13][389/391]	LR: 0.01	Loss 1.4326 (1.5436)	Prec@1 44.531 (39.908)	
Total train loss: 1.5434

Train time: 14.739139080047607
 * Prec@1 91.120 Prec@5 99.610 Loss 0.3394
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 18.588947772979736

Epoch: [14][77/391]	LR: 0.01	Loss 1.5264 (1.5446)	Prec@1 39.844 (39.834)	
Epoch: [14][155/391]	LR: 0.01	Loss 1.4004 (1.5348)	Prec@1 46.875 (40.365)	
Epoch: [14][233/391]	LR: 0.01	Loss 1.6416 (1.5449)	Prec@1 37.500 (39.937)	
Epoch: [14][311/391]	LR: 0.01	Loss 1.4922 (1.5447)	Prec@1 43.750 (39.974)	
Epoch: [14][389/391]	LR: 0.01	Loss 1.5342 (1.5432)	Prec@1 39.844 (40.010)	
Total train loss: 1.5432

Train time: 14.565524578094482
 * Prec@1 91.110 Prec@5 99.630 Loss 0.3320
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 17.978119373321533

Epoch: [15][77/391]	LR: 0.01	Loss 1.4814 (1.5251)	Prec@1 41.406 (40.745)	
Epoch: [15][155/391]	LR: 0.01	Loss 1.5654 (1.5403)	Prec@1 36.719 (39.919)	
Epoch: [15][233/391]	LR: 0.01	Loss 1.5244 (1.5399)	Prec@1 42.969 (40.094)	
Epoch: [15][311/391]	LR: 0.01	Loss 1.4092 (1.5388)	Prec@1 49.219 (40.207)	
Epoch: [15][389/391]	LR: 0.01	Loss 1.6807 (1.5434)	Prec@1 35.938 (39.982)	
Total train loss: 1.5434

Train time: 15.998162269592285
 * Prec@1 91.240 Prec@5 99.590 Loss 0.3311
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 19.270501613616943

Epoch: [16][77/391]	LR: 0.01	Loss 1.5303 (1.5433)	Prec@1 39.062 (40.345)	
Epoch: [16][155/391]	LR: 0.01	Loss 1.6562 (1.5427)	Prec@1 33.594 (40.144)	
Epoch: [16][233/391]	LR: 0.01	Loss 1.7725 (1.5464)	Prec@1 33.594 (39.927)	
Epoch: [16][311/391]	LR: 0.01	Loss 1.6182 (1.5440)	Prec@1 41.406 (39.994)	
Epoch: [16][389/391]	LR: 0.01	Loss 1.4053 (1.5439)	Prec@1 45.312 (39.954)	
Total train loss: 1.5436

Train time: 14.77520227432251
 * Prec@1 91.270 Prec@5 99.590 Loss 0.3274
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 18.4352285861969

Epoch: [17][77/391]	LR: 0.01	Loss 1.3408 (1.5499)	Prec@1 46.875 (39.483)	
Epoch: [17][155/391]	LR: 0.01	Loss 1.5371 (1.5486)	Prec@1 39.844 (39.653)	
Epoch: [17][233/391]	LR: 0.01	Loss 1.4834 (1.5429)	Prec@1 42.969 (40.114)	
Epoch: [17][311/391]	LR: 0.01	Loss 1.4805 (1.5411)	Prec@1 42.969 (40.247)	
Epoch: [17][389/391]	LR: 0.01	Loss 1.6143 (1.5431)	Prec@1 35.156 (40.120)	
Total train loss: 1.5428

Train time: 16.118988513946533
 * Prec@1 91.240 Prec@5 99.580 Loss 0.3279
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 19.804460763931274

Epoch: [18][77/391]	LR: 0.01	Loss 1.5752 (1.5484)	Prec@1 35.938 (39.714)	
Epoch: [18][155/391]	LR: 0.01	Loss 1.6211 (1.5487)	Prec@1 35.156 (39.653)	
Epoch: [18][233/391]	LR: 0.01	Loss 1.4873 (1.5494)	Prec@1 40.625 (39.630)	
Epoch: [18][311/391]	LR: 0.01	Loss 1.5195 (1.5443)	Prec@1 42.969 (39.901)	
Epoch: [18][389/391]	LR: 0.01	Loss 1.5596 (1.5421)	Prec@1 36.719 (40.008)	
Total train loss: 1.5421

Train time: 14.651954174041748
 * Prec@1 91.330 Prec@5 99.640 Loss 0.3296
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 17.43622899055481

Epoch: [19][77/391]	LR: 0.01	Loss 1.5703 (1.5431)	Prec@1 36.719 (39.774)	
Epoch: [19][155/391]	LR: 0.01	Loss 1.5078 (1.5436)	Prec@1 42.969 (39.804)	
Epoch: [19][233/391]	LR: 0.01	Loss 1.5596 (1.5413)	Prec@1 39.062 (40.097)	
Epoch: [19][311/391]	LR: 0.01	Loss 1.5205 (1.5407)	Prec@1 41.406 (40.137)	
Epoch: [19][389/391]	LR: 0.01	Loss 1.7549 (1.5422)	Prec@1 28.906 (40.112)	
Total train loss: 1.5420

Train time: 8.119379043579102
 * Prec@1 91.320 Prec@5 99.620 Loss 0.3323
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 10.274368047714233

Epoch: [20][77/391]	LR: 0.001	Loss 1.5479 (1.5518)	Prec@1 40.625 (39.523)	
Epoch: [20][155/391]	LR: 0.001	Loss 1.5342 (1.5441)	Prec@1 42.969 (39.899)	
Epoch: [20][233/391]	LR: 0.001	Loss 1.5088 (1.5404)	Prec@1 42.188 (39.977)	
Epoch: [20][311/391]	LR: 0.001	Loss 1.5713 (1.5416)	Prec@1 37.500 (39.941)	
Epoch: [20][389/391]	LR: 0.001	Loss 1.7881 (1.5411)	Prec@1 27.344 (39.988)	
Total train loss: 1.5414

Train time: 10.245647668838501
 * Prec@1 91.220 Prec@5 99.600 Loss 0.3416
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 14.7203049659729

Epoch: [21][77/391]	LR: 0.001	Loss 1.4199 (1.5502)	Prec@1 46.094 (39.744)	
Epoch: [21][155/391]	LR: 0.001	Loss 1.3691 (1.5402)	Prec@1 47.656 (40.214)	
Epoch: [21][233/391]	LR: 0.001	Loss 1.4688 (1.5411)	Prec@1 44.531 (40.044)	
Epoch: [21][311/391]	LR: 0.001	Loss 1.6104 (1.5419)	Prec@1 38.281 (40.039)	
Epoch: [21][389/391]	LR: 0.001	Loss 1.3799 (1.5405)	Prec@1 46.094 (40.090)	
Total train loss: 1.5406

Train time: 17.417726755142212
 * Prec@1 91.320 Prec@5 99.630 Loss 0.3337
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 21.36841917037964

Epoch: [22][77/391]	LR: 0.001	Loss 1.7402 (1.5337)	Prec@1 31.250 (40.325)	
Epoch: [22][155/391]	LR: 0.001	Loss 1.5527 (1.5383)	Prec@1 42.188 (39.924)	
Epoch: [22][233/391]	LR: 0.001	Loss 1.5635 (1.5410)	Prec@1 41.406 (39.760)	
Epoch: [22][311/391]	LR: 0.001	Loss 1.4961 (1.5407)	Prec@1 42.188 (39.759)	
Epoch: [22][389/391]	LR: 0.001	Loss 1.4990 (1.5411)	Prec@1 39.844 (39.852)	
Total train loss: 1.5410

Train time: 18.385055780410767
 * Prec@1 91.330 Prec@5 99.650 Loss 0.3320
Best acc: 91.370
--------------------------------------------------------------------------------
Test time: 22.56174945831299

Epoch: [23][77/391]	LR: 0.001	Loss 1.6816 (1.5422)	Prec@1 38.281 (40.064)	
Epoch: [23][155/391]	LR: 0.001	Loss 1.6582 (1.5413)	Prec@1 35.938 (39.994)	
Epoch: [23][233/391]	LR: 0.001	Loss 1.3232 (1.5399)	Prec@1 46.094 (39.977)	
Epoch: [23][311/391]	LR: 0.001	Loss 1.3633 (1.5381)	Prec@1 49.219 (40.064)	
Epoch: [23][389/391]	LR: 0.001	Loss 1.4297 (1.5409)	Prec@1 39.844 (39.992)	
Total train loss: 1.5410

Train time: 17.547794580459595
 * Prec@1 91.460 Prec@5 99.600 Loss 0.3337
Best acc: 91.460
--------------------------------------------------------------------------------
Test time: 21.69742250442505

Epoch: [24][77/391]	LR: 0.001	Loss 1.6494 (1.5545)	Prec@1 37.500 (39.273)	
Epoch: [24][155/391]	LR: 0.001	Loss 1.4580 (1.5392)	Prec@1 39.844 (39.909)	
Epoch: [24][233/391]	LR: 0.001	Loss 1.6689 (1.5390)	Prec@1 39.062 (39.981)	
Epoch: [24][311/391]	LR: 0.001	Loss 1.5322 (1.5406)	Prec@1 40.625 (39.969)	
Epoch: [24][389/391]	LR: 0.001	Loss 1.4512 (1.5408)	Prec@1 44.531 (39.892)	
Total train loss: 1.5410

Train time: 9.5495765209198
 * Prec@1 91.170 Prec@5 99.580 Loss 0.3374
Best acc: 91.460
--------------------------------------------------------------------------------
Test time: 12.597188472747803

